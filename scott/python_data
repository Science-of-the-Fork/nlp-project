,repo_name,url,language,readme_content
0,jackfrued/Python-100-Days,https://github.com/jackfrued/Python-100-Days/blob/master/README.md,Python,"Python - 100å¤©ä»æ–°æ‰‹åˆ°å¤§å¸ˆä½œè€…ï¼šéª†æ˜Šè¯´æ˜ï¼šä»é¡¹ç›®ä¸Šçº¿åˆ°è·å¾—8w+æ˜Ÿæ ‡ä»¥æ¥ï¼Œä¸€ç›´æ”¶åˆ°åé¦ˆè¯´åŸºç¡€éƒ¨åˆ†ï¼ˆå‰15å¤©çš„å†…å®¹ï¼‰å¯¹æ–°æ‰‹æ¥è¯´æ˜¯æ¯”è¾ƒå›°éš¾çš„ï¼Œå»ºè®®æœ‰é…å¥—è§†é¢‘è¿›è¡Œè®²è§£ã€‚æœ€è¿‘æŠŠåŸºç¡€éƒ¨åˆ†çš„å†…å®¹é‡æ–°åˆ¶ä½œäº†ä¸€ä¸ªåä¸ºâ€œPython-Core-50-Coursesâ€çš„é¡¹ç›®ï¼Œç”¨æ›´ä¸ºç®€å•é€šä¿—çš„æ–¹å¼é‡å†™äº†è¿™éƒ¨åˆ†å†…å®¹å¹¶é™„å¸¦äº†è§†é¢‘è®²è§£ï¼Œåˆå­¦è€…å¯ä»¥å…³æ³¨ä¸‹è¿™ä¸ªæ–°é¡¹ç›®ã€‚å¦‚æœéœ€è¦PythonåŸºç¡€è§†é¢‘ï¼Œå¯ä»¥åœ¨â€œBç«™â€æœç´¢ã€ŠPythoné›¶åŸºç¡€å¿«é€Ÿä¸Šæ‰‹ã€‹ï¼Œè¿™å¥—è§†é¢‘æ˜¯æˆ‘è®²è¯¾çš„æ—¶å€™å½•åˆ¶çš„éšå ‚è§†é¢‘ï¼Œç”»è´¨å°šå¯ã€éŸ³è´¨ä¸€èˆ¬ï¼Œä½†æ˜¯å¯¹åˆå­¦è€…åº”è¯¥ä¼šæœ‰äº›å¸®åŠ©ï¼Œæ¬¢è¿å¤§å®¶ç•™è¨€ã€è¯„è®ºã€å‘å¼¹å¹•ã€‚å­¦ä¹ ä¹‹åè§‰å¾—æœ‰æ”¶è·çš„å°ä¼™ä¼´å¯ä»¥â€œä¸€é”®ä¸‰è¿â€æ¥æ”¯æŒUPä¸»ï¼ˆåƒé”‹Pythonï¼‰ã€‚å›½å†…ç”¨æˆ·å¦‚æœè®¿é—®GitHubæ¯”è¾ƒæ…¢çš„è¯ï¼Œå¯ä»¥å…³æ³¨æˆ‘çš„çŸ¥ä¹å·Python-Jackï¼Œä¸Šé¢çš„â€œä»é›¶å¼€å§‹å­¦Pythonâ€ä¸“æ æ¯”è¾ƒé€‚åˆåˆå­¦è€…ï¼Œå…¶ä»–çš„ä¸“æ ä¹Ÿåœ¨æŒç»­åˆ›ä½œå’Œæ›´æ–°ä¸­ï¼Œæ¬¢è¿å¤§å®¶å…³æ³¨å¹¶ç‚¹èµè¯„è®ºã€‚åˆ›ä½œä¸æ˜“ï¼Œæ„Ÿè°¢å¤§å®¶çš„æ‰“èµæ”¯æŒï¼Œè¿™äº›é’±ä¸ä¼šç”¨äºä¸ªäººæ¶ˆè´¹ï¼ˆä¾‹å¦‚ï¼šè´­ä¹°å’–å•¡ï¼‰ï¼Œè€Œæ˜¯é€šè¿‡è…¾è®¯å…¬ç›Šã€ç¾å›¢å…¬ç›Šã€æ°´æ»´ç­¹ç­‰å¹³å°æèµ ç»™éœ€è¦å¸®åŠ©çš„äººï¼ˆç‚¹å‡»äº†è§£æèµ æƒ…å†µï¼‰ã€‚éœ€è¦åŠ å…¥QQå­¦ä¹ ç¾¤çš„å¯ä»¥æ‰«æä¸‹é¢çš„äºŒç»´ç ï¼Œä¸‰ä¸ªç¾¤åŠ ä¸€ä¸ªå³å¯ï¼Œä¸è¦é‡å¤è¿›ç¾¤ã€‚å­¦ä¹ ç¾¤ä¼šä¸ºå¤§å®¶æä¾›å­¦ä¹ èµ„æºå’Œé—®é¢˜è§£ç­”ï¼Œå¦‚æœæœ‰Pythonä½“éªŒè¯¾å’Œè¡Œä¸šå…¬å¼€è¯¾ä¼šæå‰åœ¨ç¾¤é‡Œé€šçŸ¥å¤§å®¶ï¼Œæ¬¢è¿å¤§å®¶åŠ å…¥ã€‚é¡¹ç›®â€œDay80~90â€éƒ¨åˆ†ç›®å‰ä»åœ¨åˆ›ä½œä¸­ï¼Œå› ä¸ºä½œè€…å¹³æ—¶ä¹ŸæŒ¤ä¸å‡ºå¤ªå¤šæ—¶é—´æ¥å†™æ–‡æ¡£ï¼Œå› æ­¤æ›´æ–°çš„é€Ÿåº¦æ¯”è¾ƒç¼“æ…¢ï¼Œæ„Ÿè°¢å¤§å®¶çš„ç†è§£ã€‚Pythonåº”ç”¨é¢†åŸŸå’ŒèŒä¸šå‘å±•åˆ†æç®€å•çš„è¯´ï¼ŒPythonæ˜¯ä¸€ä¸ªâ€œä¼˜é›…â€ã€â€œæ˜ç¡®â€ã€â€œç®€å•â€çš„ç¼–ç¨‹è¯­è¨€ã€‚å­¦ä¹ æ›²çº¿ä½ï¼Œéä¸“ä¸šäººå£«ä¹Ÿèƒ½ä¸Šæ‰‹å¼€æºç³»ç»Ÿï¼Œæ‹¥æœ‰å¼ºå¤§çš„ç”Ÿæ€åœˆè§£é‡Šå‹è¯­è¨€ï¼Œå®Œç¾çš„å¹³å°å¯ç§»æ¤æ€§åŠ¨æ€ç±»å‹è¯­è¨€ï¼Œæ”¯æŒé¢å‘å¯¹è±¡å’Œå‡½æ•°å¼ç¼–ç¨‹ä»£ç è§„èŒƒç¨‹åº¦é«˜ï¼Œå¯è¯»æ€§å¼ºPythonåœ¨ä»¥ä¸‹é¢†åŸŸéƒ½æœ‰ç”¨æ­¦ä¹‹åœ°ã€‚åç«¯å¼€å‘ - Python / Java / Go / PHPDevOps - Python / Shell / Rubyæ•°æ®é‡‡é›† - Python / C++ / Javaé‡åŒ–äº¤æ˜“ - Python / C++ / Ræ•°æ®ç§‘å­¦ - Python / R / Julia / Matlabæœºå™¨å­¦ä¹  - Python / R / C++ / Juliaè‡ªåŠ¨åŒ–æµ‹è¯• - Python / Shellä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œæ ¹æ®ä¸ªäººçš„å–œå¥½å’ŒèŒä¸šè§„åˆ’ï¼Œå¯ä»¥é€‰æ‹©çš„å°±ä¸šé¢†åŸŸä¹Ÿéå¸¸å¤šã€‚Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼ˆæœåŠ¡å™¨ã€äº‘å¹³å°ã€æ•°æ®æ¥å£ï¼‰Pythonè¿ç»´å·¥ç¨‹å¸ˆï¼ˆè‡ªåŠ¨åŒ–è¿ç»´ã€SREã€DevOpsï¼‰Pythonæ•°æ®åˆ†æå¸ˆï¼ˆæ•°æ®åˆ†æã€å•†ä¸šæ™ºèƒ½ã€æ•°å­—åŒ–è¿è¥ï¼‰Pythonæ•°æ®æŒ–æ˜å·¥ç¨‹å¸ˆï¼ˆæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€ç®—æ³•ä¸“å®¶ï¼‰Pythonçˆ¬è™«å·¥ç¨‹å¸ˆPythonæµ‹è¯•å·¥ç¨‹å¸ˆï¼ˆè‡ªåŠ¨åŒ–æµ‹è¯•ã€æµ‹è¯•å¼€å‘ï¼‰è¯´æ˜ï¼šç›®å‰ï¼Œæ•°æ®åˆ†æå’Œæ•°æ®æŒ–æ˜æ˜¯éå¸¸çƒ­é—¨çš„æ–¹å‘ï¼Œå› ä¸ºä¸ç®¡æ˜¯äº’è”ç½‘è¡Œä¸šè¿˜æ˜¯ä¼ ç»Ÿè¡Œä¸šéƒ½å·²ç»ç§¯ç´¯äº†å¤§é‡çš„æ•°æ®ï¼Œå„è¡Œå„ä¸šéƒ½éœ€è¦æ•°æ®åˆ†æå¸ˆä»å·²æœ‰çš„æ•°æ®ä¸­å‘ç°æ›´å¤šçš„å•†ä¸šä»·å€¼ï¼Œä»è€Œä¸ºä¼ä¸šçš„å†³ç­–æä¾›æ•°æ®çš„æ”¯æ’‘ï¼Œè¿™å°±æ˜¯æ‰€è°“çš„æ•°æ®é©±åŠ¨å†³ç­–ã€‚ç»™åˆå­¦è€…çš„å‡ ä¸ªå»ºè®®ï¼šMake English as your working language. ï¼ˆè®©è‹±è¯­æˆä¸ºä½ çš„å·¥ä½œè¯­è¨€ï¼‰Practice makes perfect. ï¼ˆç†Ÿèƒ½ç”Ÿå·§ï¼‰All experience comes from mistakes. ï¼ˆæ‰€æœ‰çš„ç»éªŒéƒ½æºäºä½ çŠ¯è¿‡çš„é”™è¯¯ï¼‰Don't be one of the leeches. ï¼ˆä¸è¦å½“ä¼¸æ‰‹å…šï¼‰Either outstanding or out. ï¼ˆè¦ä¹ˆå‡ºä¼—ï¼Œè¦ä¹ˆå‡ºå±€ï¼‰Day01~15 - Pythonè¯­è¨€åŸºç¡€Day01 - åˆè¯†PythonPythonç®€ä»‹ - Pythonçš„å†å² / Pythonçš„ä¼˜ç¼ºç‚¹ / Pythonçš„åº”ç”¨é¢†åŸŸæ­å»ºç¼–ç¨‹ç¯å¢ƒ - Windowsç¯å¢ƒ / Linuxç¯å¢ƒ / MacOSç¯å¢ƒä»ç»ˆç«¯è¿è¡ŒPythonç¨‹åº - Hello, world / printå‡½æ•° / è¿è¡Œç¨‹åºä½¿ç”¨IDLE - äº¤äº’å¼ç¯å¢ƒ(REPL) / ç¼–å†™å¤šè¡Œä»£ç  / è¿è¡Œç¨‹åº / é€€å‡ºIDLEæ³¨é‡Š - æ³¨é‡Šçš„ä½œç”¨ / å•è¡Œæ³¨é‡Š / å¤šè¡Œæ³¨é‡ŠDay02 - è¯­è¨€å…ƒç´ ç¨‹åºå’Œè¿›åˆ¶ - æŒ‡ä»¤å’Œç¨‹åº / å†¯è¯ºä¾æ›¼æœº / äºŒè¿›åˆ¶å’Œåè¿›åˆ¶ / å…«è¿›åˆ¶å’Œåå…­è¿›åˆ¶å˜é‡å’Œç±»å‹ - å˜é‡çš„å‘½å / å˜é‡çš„ä½¿ç”¨ / inputå‡½æ•° / æ£€æŸ¥å˜é‡ç±»å‹ / ç±»å‹è½¬æ¢æ•°å­—å’Œå­—ç¬¦ä¸² - æ•´æ•° / æµ®ç‚¹æ•° / å¤æ•° / å­—ç¬¦ä¸² / å­—ç¬¦ä¸²åŸºæœ¬æ“ä½œ / å­—ç¬¦ç¼–ç è¿ç®—ç¬¦ - æ•°å­¦è¿ç®—ç¬¦ / èµ‹å€¼è¿ç®—ç¬¦ / æ¯”è¾ƒè¿ç®—ç¬¦ / é€»è¾‘è¿ç®—ç¬¦ / èº«ä»½è¿ç®—ç¬¦ / è¿ç®—ç¬¦çš„ä¼˜å…ˆçº§åº”ç”¨æ¡ˆä¾‹ - åæ°æ¸©åº¦è½¬æ¢æˆæ‘„æ°æ¸©åº¦ / è¾“å…¥åœ†çš„åŠå¾„è®¡ç®—å‘¨é•¿å’Œé¢ç§¯ / è¾“å…¥å¹´ä»½åˆ¤æ–­æ˜¯å¦æ˜¯é—°å¹´Day03 - åˆ†æ”¯ç»“æ„åˆ†æ”¯ç»“æ„çš„åº”ç”¨åœºæ™¯ - æ¡ä»¶ / ç¼©è¿› / ä»£ç å— / æµç¨‹å›¾ifè¯­å¥ - ç®€å•çš„if / if-elseç»“æ„ / if-elif-elseç»“æ„ / åµŒå¥—çš„ifåº”ç”¨æ¡ˆä¾‹ - ç”¨æˆ·èº«ä»½éªŒè¯ / è‹±åˆ¶å•ä½ä¸å…¬åˆ¶å•ä½äº’æ¢ / æ·éª°å­å†³å®šåšä»€ä¹ˆ / ç™¾åˆ†åˆ¶æˆç»©è½¬ç­‰çº§åˆ¶ / åˆ†æ®µå‡½æ•°æ±‚å€¼ / è¾“å…¥ä¸‰æ¡è¾¹çš„é•¿åº¦å¦‚æœèƒ½æ„æˆä¸‰è§’å½¢å°±è®¡ç®—å‘¨é•¿å’Œé¢ç§¯Day04 - å¾ªç¯ç»“æ„å¾ªç¯ç»“æ„çš„åº”ç”¨åœºæ™¯ - æ¡ä»¶ / ç¼©è¿› / ä»£ç å— / æµç¨‹å›¾whileå¾ªç¯ - åŸºæœ¬ç»“æ„ / breakè¯­å¥ / continueè¯­å¥forå¾ªç¯ - åŸºæœ¬ç»“æ„ / rangeç±»å‹ / å¾ªç¯ä¸­çš„åˆ†æ”¯ç»“æ„ / åµŒå¥—çš„å¾ªç¯ / æå‰ç»“æŸç¨‹åºåº”ç”¨æ¡ˆä¾‹ - 1~100æ±‚å’Œ / åˆ¤æ–­ç´ æ•° / çŒœæ•°å­—æ¸¸æˆ / æ‰“å°ä¹ä¹è¡¨ / æ‰“å°ä¸‰è§’å½¢å›¾æ¡ˆ / çŒ´å­åƒæ¡ƒ / ç™¾é’±ç™¾é¸¡Day05 - æ„é€ ç¨‹åºé€»è¾‘ç»å…¸æ¡ˆä¾‹ï¼šæ°´ä»™èŠ±æ•° / ç™¾é’±ç™¾é¸¡ / CrapsèµŒåšæ¸¸æˆç»ƒä¹ é¢˜ç›®ï¼šæ–æ³¢é‚£å¥‘æ•°åˆ— / å®Œç¾æ•° / ç´ æ•°Day06 - å‡½æ•°å’Œæ¨¡å—çš„ä½¿ç”¨å‡½æ•°çš„ä½œç”¨ - ä»£ç çš„åå‘³é“ / ç”¨å‡½æ•°å°è£…åŠŸèƒ½æ¨¡å—å®šä¹‰å‡½æ•° - defå…³é”®å­— / å‡½æ•°å / å‚æ•°åˆ—è¡¨ / returnè¯­å¥ / è°ƒç”¨è‡ªå®šä¹‰å‡½æ•°è°ƒç”¨å‡½æ•° - Pythonå†…ç½®å‡½æ•° /  å¯¼å…¥æ¨¡å—å’Œå‡½æ•°å‡½æ•°çš„å‚æ•° - é»˜è®¤å‚æ•° / å¯å˜å‚æ•° / å…³é”®å­—å‚æ•° / å‘½åå…³é”®å­—å‚æ•°å‡½æ•°çš„è¿”å›å€¼ - æ²¡æœ‰è¿”å›å€¼  / è¿”å›å•ä¸ªå€¼ / è¿”å›å¤šä¸ªå€¼ä½œç”¨åŸŸé—®é¢˜ - å±€éƒ¨ä½œç”¨åŸŸ / åµŒå¥—ä½œç”¨åŸŸ / å…¨å±€ä½œç”¨åŸŸ / å†…ç½®ä½œç”¨åŸŸ / å’Œä½œç”¨åŸŸç›¸å…³çš„å…³é”®å­—ç”¨æ¨¡å—ç®¡ç†å‡½æ•° - æ¨¡å—çš„æ¦‚å¿µ / ç”¨è‡ªå®šä¹‰æ¨¡å—ç®¡ç†å‡½æ•° / å‘½åå†²çªçš„æ—¶å€™ä¼šæ€æ ·ï¼ˆåŒä¸€ä¸ªæ¨¡å—å’Œä¸åŒçš„æ¨¡å—ï¼‰Day07 - å­—ç¬¦ä¸²å’Œå¸¸ç”¨æ•°æ®ç»“æ„å­—ç¬¦ä¸²çš„ä½¿ç”¨ - è®¡ç®—é•¿åº¦ / ä¸‹æ ‡è¿ç®— / åˆ‡ç‰‡ / å¸¸ç”¨æ–¹æ³•åˆ—è¡¨åŸºæœ¬ç”¨æ³• - å®šä¹‰åˆ—è¡¨ / ç”¨ä¸‹è¡¨è®¿é—®å…ƒç´  / ä¸‹æ ‡è¶Šç•Œ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  / ä¿®æ”¹å…ƒç´  / åˆ‡ç‰‡ / å¾ªç¯éå†åˆ—è¡¨å¸¸ç”¨æ“ä½œ - è¿æ¥ / å¤åˆ¶(å¤åˆ¶å…ƒç´ å’Œå¤åˆ¶æ•°ç»„) / é•¿åº¦ / æ’åº / å€’è½¬ / æŸ¥æ‰¾ç”Ÿæˆåˆ—è¡¨ - ä½¿ç”¨rangeåˆ›å»ºæ•°å­—åˆ—è¡¨ / ç”Ÿæˆè¡¨è¾¾å¼ / ç”Ÿæˆå™¨å…ƒç»„çš„ä½¿ç”¨ - å®šä¹‰å…ƒç»„ / ä½¿ç”¨å…ƒç»„ä¸­çš„å€¼ / ä¿®æ”¹å…ƒç»„å˜é‡ / å…ƒç»„å’Œåˆ—è¡¨è½¬æ¢é›†åˆåŸºæœ¬ç”¨æ³• - é›†åˆå’Œåˆ—è¡¨çš„åŒºåˆ« /  åˆ›å»ºé›†åˆ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  /  æ¸…ç©ºé›†åˆå¸¸ç”¨æ“ä½œ - äº¤é›† / å¹¶é›† / å·®é›† / å¯¹ç§°å·® / å­é›† / è¶…é›†å­—å…¸çš„åŸºæœ¬ç”¨æ³• - å­—å…¸çš„ç‰¹ç‚¹ / åˆ›å»ºå­—å…¸ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  / å–å€¼ / æ¸…ç©ºå­—å…¸å¸¸ç”¨æ“ä½œ - keysæ–¹æ³• / valuesæ–¹æ³• / itemsæ–¹æ³• / setdefaultæ–¹æ³•åŸºç¡€ç»ƒä¹  - è·‘é©¬ç¯æ•ˆæœ / åˆ—è¡¨æ‰¾æœ€å¤§å…ƒç´  / ç»Ÿè®¡è€ƒè¯•æˆç»©çš„å¹³å‡åˆ† / Fibonacciæ•°åˆ— / æ¨è¾‰ä¸‰è§’ç»¼åˆæ¡ˆä¾‹ - åŒè‰²çƒé€‰å· / äº•å­—æ£‹Day08 - é¢å‘å¯¹è±¡ç¼–ç¨‹åŸºç¡€ç±»å’Œå¯¹è±¡ - ä»€ä¹ˆæ˜¯ç±» / ä»€ä¹ˆæ˜¯å¯¹è±¡ / é¢å‘å¯¹è±¡å…¶ä»–ç›¸å…³æ¦‚å¿µå®šä¹‰ç±» - åŸºæœ¬ç»“æ„ / å±æ€§å’Œæ–¹æ³• / æ„é€ å™¨ / ææ„å™¨ / __str__æ–¹æ³•ä½¿ç”¨å¯¹è±¡ - åˆ›å»ºå¯¹è±¡ / ç»™å¯¹è±¡å‘æ¶ˆæ¯é¢å‘å¯¹è±¡çš„å››å¤§æ”¯æŸ± - æŠ½è±¡ / å°è£… / ç»§æ‰¿ / å¤šæ€åŸºç¡€ç»ƒä¹  - å®šä¹‰å­¦ç”Ÿç±» / å®šä¹‰æ—¶é’Ÿç±» / å®šä¹‰å›¾å½¢ç±» / å®šä¹‰æ±½è½¦ç±»Day09 - é¢å‘å¯¹è±¡è¿›é˜¶å±æ€§ - ç±»å±æ€§ / å®ä¾‹å±æ€§ / å±æ€§è®¿é—®å™¨ / å±æ€§ä¿®æ”¹å™¨ / å±æ€§åˆ é™¤å™¨ / ä½¿ç”¨__slots__ç±»ä¸­çš„æ–¹æ³• - å®ä¾‹æ–¹æ³• / ç±»æ–¹æ³• / é™æ€æ–¹æ³•è¿ç®—ç¬¦é‡è½½ - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__ç±»(çš„å¯¹è±¡)ä¹‹é—´çš„å…³ç³» - å…³è” / ç»§æ‰¿ / ä¾èµ–ç»§æ‰¿å’Œå¤šæ€ - ä»€ä¹ˆæ˜¯ç»§æ‰¿ / ç»§æ‰¿çš„è¯­æ³• / è°ƒç”¨çˆ¶ç±»æ–¹æ³• / æ–¹æ³•é‡å†™ / ç±»å‹åˆ¤å®š / å¤šé‡ç»§æ‰¿ / è±å½¢ç»§æ‰¿(é’»çŸ³ç»§æ‰¿)å’ŒC3ç®—æ³•ç»¼åˆæ¡ˆä¾‹ - å·¥èµ„ç»“ç®—ç³»ç»Ÿ / å›¾ä¹¦è‡ªåŠ¨æŠ˜æ‰£ç³»ç»Ÿ / è‡ªå®šä¹‰åˆ†æ•°ç±»Day10 - å›¾å½¢ç”¨æˆ·ç•Œé¢å’Œæ¸¸æˆå¼€å‘ä½¿ç”¨tkinterå¼€å‘GUIç¨‹åºä½¿ç”¨pygameä¸‰æ–¹åº“å¼€å‘æ¸¸æˆåº”ç”¨â€œå¤§çƒåƒå°çƒâ€æ¸¸æˆDay11 - æ–‡ä»¶å’Œå¼‚å¸¸è¯»æ–‡ä»¶ - è¯»å–æ•´ä¸ªæ–‡ä»¶ / é€è¡Œè¯»å– / æ–‡ä»¶è·¯å¾„å†™æ–‡ä»¶ - è¦†ç›–å†™å…¥ / è¿½åŠ å†™å…¥ / æ–‡æœ¬æ–‡ä»¶ / äºŒè¿›åˆ¶æ–‡ä»¶å¼‚å¸¸å¤„ç† - å¼‚å¸¸æœºåˆ¶çš„é‡è¦æ€§ / try-exceptä»£ç å— / elseä»£ç å— / finallyä»£ç å— / å†…ç½®å¼‚å¸¸ç±»å‹ / å¼‚å¸¸æ ˆ / raiseè¯­å¥æ•°æ®æŒä¹…åŒ– - CSVæ–‡ä»¶æ¦‚è¿° / csvæ¨¡å—çš„åº”ç”¨ / JSONæ•°æ®æ ¼å¼ / jsonæ¨¡å—çš„åº”ç”¨Day12 - å­—ç¬¦ä¸²å’Œæ­£åˆ™è¡¨è¾¾å¼å­—ç¬¦ä¸²é«˜çº§æ“ä½œ - è½¬ä¹‰å­—ç¬¦ / åŸå§‹å­—ç¬¦ä¸² / å¤šè¡Œå­—ç¬¦ä¸² / inå’Œnot inè¿ç®—ç¬¦ / is_xxxæ–¹æ³• / joinå’Œsplitæ–¹æ³• / stripç›¸å…³æ–¹æ³• / pyperclipæ¨¡å— / ä¸å˜å­—ç¬¦ä¸²å’Œå¯å˜å­—ç¬¦ä¸² / StringIOçš„ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å…¥é—¨ - æ­£åˆ™è¡¨è¾¾å¼çš„ä½œç”¨ / å…ƒå­—ç¬¦ / è½¬ä¹‰ / é‡è¯ / åˆ†ç»„ / é›¶å®½æ–­è¨€ /è´ªå©ªåŒ¹é…ä¸æƒ°æ€§åŒ¹é…æ‡’æƒ° / ä½¿ç”¨reæ¨¡å—å®ç°æ­£åˆ™è¡¨è¾¾å¼æ“ä½œï¼ˆåŒ¹é…ã€æœç´¢ã€æ›¿æ¢ã€æ•è·ï¼‰ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ - reæ¨¡å— / compileå‡½æ•° / groupå’Œgroupsæ–¹æ³• / matchæ–¹æ³• / searchæ–¹æ³• / findallå’Œfinditeræ–¹æ³• / subå’Œsubnæ–¹æ³• / splitæ–¹æ³•åº”ç”¨æ¡ˆä¾‹ - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼éªŒè¯è¾“å…¥çš„å­—ç¬¦ä¸²Day13 - è¿›ç¨‹å’Œçº¿ç¨‹è¿›ç¨‹å’Œçº¿ç¨‹çš„æ¦‚å¿µ - ä»€ä¹ˆæ˜¯è¿›ç¨‹ / ä»€ä¹ˆæ˜¯çº¿ç¨‹ / å¤šçº¿ç¨‹çš„åº”ç”¨åœºæ™¯ä½¿ç”¨è¿›ç¨‹ - forkå‡½æ•° / multiprocessingæ¨¡å— / è¿›ç¨‹æ±  / è¿›ç¨‹é—´é€šä¿¡ä½¿ç”¨çº¿ç¨‹ -  threadingæ¨¡å— / Threadç±» / RLockç±» / Conditionç±» / çº¿ç¨‹æ± Day14 - ç½‘ç»œç¼–ç¨‹å…¥é—¨å’Œç½‘ç»œåº”ç”¨å¼€å‘è®¡ç®—æœºç½‘ç»œåŸºç¡€ - è®¡ç®—æœºç½‘ç»œå‘å±•å² / â€œTCP-IPâ€æ¨¡å‹ / IPåœ°å€ / ç«¯å£ / åè®® / å…¶ä»–ç›¸å…³æ¦‚å¿µç½‘ç»œåº”ç”¨æ¨¡å¼ - â€œå®¢æˆ·ç«¯-æœåŠ¡å™¨â€æ¨¡å¼ / â€œæµè§ˆå™¨-æœåŠ¡å™¨â€æ¨¡å¼åŸºäºHTTPåè®®è®¿é—®ç½‘ç»œèµ„æº - ç½‘ç»œAPIæ¦‚è¿° / è®¿é—®URL / requestsä¸‰æ–¹åº“ / è§£æJSONæ ¼å¼æ•°æ®Pythonç½‘ç»œç¼–ç¨‹ - å¥—æ¥å­—çš„æ¦‚å¿µ / socketæ¨¡å— /  socketå‡½æ•° / åˆ›å»ºTCPæœåŠ¡å™¨ / åˆ›å»ºTCPå®¢æˆ·ç«¯ / åˆ›å»ºUDPæœåŠ¡å™¨ / åˆ›å»ºUDPå®¢æˆ·ç«¯ç”µå­é‚®ä»¶ - SMTPåè®® / POP3åè®® / IMAPåè®® / smtplibæ¨¡å— / poplibæ¨¡å— / imaplibæ¨¡å—çŸ­ä¿¡æœåŠ¡ - è°ƒç”¨çŸ­ä¿¡æœåŠ¡ç½‘å…³Day15 - å›¾åƒå’Œæ–‡æ¡£å¤„ç†ç”¨Pillowå¤„ç†å›¾ç‰‡ - å›¾ç‰‡è¯»å†™ / å›¾ç‰‡åˆæˆ / å‡ ä½•å˜æ¢ / è‰²å½©è½¬æ¢ / æ»¤é•œæ•ˆæœè¯»å†™Wordæ–‡æ¡£ - æ–‡æœ¬å†…å®¹çš„å¤„ç† / æ®µè½ / é¡µçœ‰å’Œé¡µè„š / æ ·å¼çš„å¤„ç†è¯»å†™Excelæ–‡ä»¶ - xlrd / xlwt / openpyxlDay16~Day20 - Pythonè¯­è¨€è¿›é˜¶ å¸¸ç”¨æ•°æ®ç»“æ„å‡½æ•°çš„é«˜çº§ç”¨æ³• - â€œä¸€ç­‰å…¬æ°‘â€ / é«˜é˜¶å‡½æ•° / Lambdaå‡½æ•° / ä½œç”¨åŸŸå’Œé—­åŒ… / è£…é¥°å™¨é¢å‘å¯¹è±¡é«˜çº§çŸ¥è¯† - â€œä¸‰å¤§æ”¯æŸ±â€ / ç±»ä¸ç±»ä¹‹é—´çš„å…³ç³» / åƒåœ¾å›æ”¶ / é­”æœ¯å±æ€§å’Œæ–¹æ³• / æ··å…¥ / å…ƒç±» / é¢å‘å¯¹è±¡è®¾è®¡åŸåˆ™ / GoFè®¾è®¡æ¨¡å¼è¿­ä»£å™¨å’Œç”Ÿæˆå™¨ - ç›¸å…³é­”æœ¯æ–¹æ³• / åˆ›å»ºç”Ÿæˆå™¨çš„ä¸¤ç§æ–¹å¼ /å¹¶å‘å’Œå¼‚æ­¥ç¼–ç¨‹ - å¤šçº¿ç¨‹ / å¤šè¿›ç¨‹ / å¼‚æ­¥IO / asyncå’ŒawaitDay21~30 - Webå‰ç«¯å…¥é—¨ç”¨HTMLæ ‡ç­¾æ‰¿è½½é¡µé¢å†…å®¹ç”¨CSSæ¸²æŸ“é¡µé¢ç”¨JavaScriptå¤„ç†äº¤äº’å¼è¡Œä¸ºjQueryå…¥é—¨å’Œæé«˜Vue.jså…¥é—¨Elementçš„ä½¿ç”¨Bootstrapçš„ä½¿ç”¨Day31~35 - ç©è½¬Linuxæ“ä½œç³»ç»Ÿæ“ä½œç³»ç»Ÿå‘å±•å²å’ŒLinuxæ¦‚è¿°LinuxåŸºç¡€å‘½ä»¤Linuxä¸­çš„å®ç”¨ç¨‹åºLinuxçš„æ–‡ä»¶ç³»ç»ŸVimç¼–è¾‘å™¨çš„åº”ç”¨ç¯å¢ƒå˜é‡å’ŒShellç¼–ç¨‹è½¯ä»¶çš„å®‰è£…å’ŒæœåŠ¡çš„é…ç½®ç½‘ç»œè®¿é—®å’Œç®¡ç†å…¶ä»–ç›¸å…³å†…å®¹Day36~40 - æ•°æ®åº“åŸºç¡€å’Œè¿›é˜¶å…³ç³»å‹æ•°æ®åº“æ¦‚è¿°MySQLçš„å®‰è£…å’Œä½¿ç”¨SQLçš„ä½¿ç”¨DDL - æ•°æ®å®šä¹‰è¯­è¨€ - create / drop / alterDML - æ•°æ®æ“ä½œè¯­è¨€ - insert / delete / updateDQL - æ•°æ®æŸ¥è¯¢è¯­è¨€ - selectDCL - æ•°æ®æ§åˆ¶è¯­è¨€ - grant / revokeMySQLæ–°ç‰¹æ€§çª—å£å‡½æ•°çš„åº”ç”¨JSONæ•°æ®ç±»å‹ç›¸å…³çŸ¥è¯†æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§è§†å›¾ã€å‡½æ•°ã€è¿‡ç¨‹ã€è§¦å‘å™¨äº‹åŠ¡å’Œé”æ‰§è¡Œè®¡åˆ’å’Œç´¢å¼•èŒƒå¼ç†è®ºå’ŒåèŒƒå¼è®¾è®¡åœ¨Pythonä¸­æ“ä½œMySQLDay41~55 - å®æˆ˜DjangoDay41 - Djangoå¿«é€Ÿä¸Šæ‰‹Webåº”ç”¨å·¥ä½œæœºåˆ¶HTTPè¯·æ±‚å’Œå“åº”Djangoæ¡†æ¶æ¦‚è¿°5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹Day42 - æ·±å…¥æ¨¡å‹å…³ç³»å‹æ•°æ®åº“é…ç½®ä½¿ç”¨ORMå®Œæˆå¯¹æ¨¡å‹çš„CRUDæ“ä½œç®¡ç†åå°çš„ä½¿ç”¨Djangoæ¨¡å‹æœ€ä½³å®è·µæ¨¡å‹å®šä¹‰å‚è€ƒDay43 - é™æ€èµ„æºå’ŒAjaxè¯·æ±‚åŠ è½½é™æ€èµ„æºAjaxæ¦‚è¿°ç”¨Ajaxå®ç°æŠ•ç¥¨åŠŸèƒ½Day44 - Cookieå’ŒSessionå®ç°ç”¨æˆ·è·Ÿè¸ªcookieå’Œsessionçš„å…³ç³»Djangoæ¡†æ¶å¯¹sessionçš„æ”¯æŒè§†å›¾å‡½æ•°ä¸­çš„cookieè¯»å†™æ“ä½œDay45 - æŠ¥è¡¨å’Œæ—¥å¿—é€šè¿‡HttpResponseä¿®æ”¹å“åº”å¤´ä½¿ç”¨StreamingHttpResponseå¤„ç†å¤§æ–‡ä»¶ä½¿ç”¨xlwtç”ŸæˆExcelæŠ¥è¡¨ä½¿ç”¨reportlabç”ŸæˆPDFæŠ¥è¡¨ä½¿ç”¨EChartsç”Ÿæˆå‰ç«¯å›¾è¡¨Day46 - æ—¥å¿—å’Œè°ƒè¯•å·¥å…·æ é…ç½®æ—¥å¿—é…ç½®Django-Debug-Toolbarä¼˜åŒ–ORMä»£ç Day47 - ä¸­é—´ä»¶çš„åº”ç”¨ä»€ä¹ˆæ˜¯ä¸­é—´ä»¶Djangoæ¡†æ¶å†…ç½®çš„ä¸­é—´ä»¶è‡ªå®šä¹‰ä¸­é—´ä»¶åŠå…¶åº”ç”¨åœºæ™¯Day48 - å‰åç«¯åˆ†ç¦»å¼€å‘å…¥é—¨è¿”å›JSONæ ¼å¼çš„æ•°æ®ç”¨Vue.jsæ¸²æŸ“é¡µé¢Day49 - RESTfulæ¶æ„å’ŒDRFå…¥é—¨Day50 - RESTfulæ¶æ„å’ŒDRFè¿›é˜¶Day51 - ä½¿ç”¨ç¼“å­˜ç½‘ç«™ä¼˜åŒ–ç¬¬ä¸€å®šå¾‹åœ¨Djangoé¡¹ç›®ä¸­ä½¿ç”¨Redisæä¾›ç¼“å­˜æœåŠ¡åœ¨è§†å›¾å‡½æ•°ä¸­è¯»å†™ç¼“å­˜ä½¿ç”¨è£…é¥°å™¨å®ç°é¡µé¢ç¼“å­˜ä¸ºæ•°æ®æ¥å£æä¾›ç¼“å­˜æœåŠ¡Day52 - æ¥å…¥ä¸‰æ–¹å¹³å°æ–‡ä»¶ä¸Šä¼ è¡¨å•æ§ä»¶å’Œå›¾ç‰‡æ–‡ä»¶é¢„è§ˆæœåŠ¡å™¨ç«¯å¦‚ä½•å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶Day53 - å¼‚æ­¥ä»»åŠ¡å’Œå®šæ—¶ä»»åŠ¡ç½‘ç«™ä¼˜åŒ–ç¬¬äºŒå®šå¾‹é…ç½®æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡åœ¨é¡¹ç›®ä¸­ä½¿ç”¨Celeryå®ç°ä»»åŠ¡å¼‚æ­¥åŒ–åœ¨é¡¹ç›®ä¸­ä½¿ç”¨Celeryå®ç°å®šæ—¶ä»»åŠ¡Day54 - å•å…ƒæµ‹è¯•Day55 - é¡¹ç›®ä¸Šçº¿Pythonä¸­çš„å•å…ƒæµ‹è¯•Djangoæ¡†æ¶å¯¹å•å…ƒæµ‹è¯•çš„æ”¯æŒä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿé…ç½®å’Œä½¿ç”¨uWSGIåŠ¨é™åˆ†ç¦»å’ŒNginxé…ç½®é…ç½®HTTPSé…ç½®åŸŸåè§£æDay56~60 - ç”¨FastAPIå¼€å‘æ•°æ®æ¥å£FastAPIäº”åˆ†é’Ÿä¸Šæ‰‹è¯·æ±‚å’Œå“åº”æ¥å…¥å…³ç³»å‹æ•°æ®åº“ä¾èµ–æ³¨å…¥ä¸­é—´ä»¶å¼‚æ­¥åŒ–è™šæ‹ŸåŒ–éƒ¨ç½²ï¼ˆDockerï¼‰é¡¹ç›®å®æˆ˜ï¼šè½¦è¾†è¿ç« æŸ¥è¯¢é¡¹ç›®Day61~65 - çˆ¬è™«å¼€å‘Day61 - ç½‘ç»œæ•°æ®é‡‡é›†æ¦‚è¿°ç½‘ç»œçˆ¬è™«çš„æ¦‚å¿µåŠå…¶åº”ç”¨é¢†åŸŸç½‘ç»œçˆ¬è™«çš„åˆæ³•æ€§æ¢è®¨å¼€å‘ç½‘ç»œçˆ¬è™«çš„ç›¸å…³å·¥å…·ä¸€ä¸ªçˆ¬è™«ç¨‹åºçš„æ„æˆDay62 - æ•°æ®æŠ“å–å’Œè§£æä½¿ç”¨requestsä¸‰æ–¹åº“å®ç°æ•°æ®æŠ“å–é¡µé¢è§£æçš„ä¸‰ç§æ–¹å¼æ­£åˆ™è¡¨è¾¾å¼è§£æXPathè§£æCSSé€‰æ‹©å™¨è§£æDay63 - Pythonä¸­çš„å¹¶å‘ç¼–ç¨‹å¤šçº¿ç¨‹å¤šè¿›ç¨‹å¼‚æ­¥I/ODay64 - ä½¿ç”¨SeleniumæŠ“å–ç½‘é¡µåŠ¨æ€å†…å®¹Day65 - çˆ¬è™«æ¡†æ¶Scrapyç®€ä»‹Day66~80 - æ•°æ®åˆ†æDay66 - æ•°æ®åˆ†ææ¦‚è¿°Day67 - ç¯å¢ƒå‡†å¤‡Day68 - NumPyçš„åº”ç”¨-1Day69 - NumPyçš„åº”ç”¨-2Day70 - Pandasçš„åº”ç”¨-1Day71 - Pandasçš„åº”ç”¨-2Day72 - Pandasçš„åº”ç”¨-3Day73 - Pandasçš„åº”ç”¨-4Day74 - Pandasçš„åº”ç”¨-5Day75 - æ•°æ®å¯è§†åŒ–-1Day76 - æ•°æ®å¯è§†åŒ–-2Day77 - æ¦‚ç‡ç»Ÿè®¡åŸºç¡€Day78 - æ–¹å·®åˆ†æå’Œå‚æ•°ä¼°è®¡Day79 - ç›¸å…³å’Œå›å½’Day80 - æ•°æ®åˆ†ææ–¹æ³•è®ºDay81~90 - æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ Day81 - æœºå™¨å­¦ä¹ åŸºç¡€Day82 - kæœ€è¿‘é‚»åˆ†ç±»Day83 - å†³ç­–æ ‘Day84 - è´å¶æ–¯åˆ†ç±»Day85 - æ”¯æŒå‘é‡æœºDay86 - K-å‡å€¼èšç±»Day87 - å›å½’åˆ†æDay88 - æ·±åº¦å­¦ä¹ å…¥é—¨Day89 - PyTorchæ¦‚è¿°Day90 - PyTorchå®æˆ˜Day91~100 - å›¢é˜Ÿé¡¹ç›®å¼€å‘ç¬¬91å¤©ï¼šå›¢é˜Ÿé¡¹ç›®å¼€å‘çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆè½¯ä»¶è¿‡ç¨‹æ¨¡å‹ç»å…¸è¿‡ç¨‹æ¨¡å‹ï¼ˆç€‘å¸ƒæ¨¡å‹ï¼‰å¯è¡Œæ€§åˆ†æï¼ˆç ”ç©¶åšè¿˜æ˜¯ä¸åšï¼‰ï¼Œè¾“å‡ºã€Šå¯è¡Œæ€§åˆ†ææŠ¥å‘Šã€‹ã€‚éœ€æ±‚åˆ†æï¼ˆç ”ç©¶åšä»€ä¹ˆï¼‰ï¼Œè¾“å‡ºã€Šéœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦ã€‹å’Œäº§å“ç•Œé¢åŸå‹å›¾ã€‚æ¦‚è¦è®¾è®¡å’Œè¯¦ç»†è®¾è®¡ï¼Œè¾“å‡ºæ¦‚å¿µæ¨¡å‹å›¾ï¼ˆERå›¾ï¼‰ã€ç‰©ç†æ¨¡å‹å›¾ã€ç±»å›¾ã€æ—¶åºå›¾ç­‰ã€‚ç¼–ç  / æµ‹è¯•ã€‚ä¸Šçº¿ / ç»´æŠ¤ã€‚ç€‘å¸ƒæ¨¡å‹æœ€å¤§çš„ç¼ºç‚¹æ˜¯æ— æ³•æ‹¥æŠ±éœ€æ±‚å˜åŒ–ï¼Œæ•´å¥—æµç¨‹ç»“æŸåæ‰èƒ½çœ‹åˆ°äº§å“ï¼Œå›¢é˜Ÿå£«æ°”ä½è½ã€‚æ•æ·å¼€å‘ï¼ˆScrumï¼‰- äº§å“æ‰€æœ‰è€…ã€Scrum Masterã€ç ”å‘äººå‘˜ - Sprintäº§å“çš„Backlogï¼ˆç”¨æˆ·æ•…äº‹ã€äº§å“åŸå‹ï¼‰ã€‚è®¡åˆ’ä¼šè®®ï¼ˆè¯„ä¼°å’Œé¢„ç®—ï¼‰ã€‚æ—¥å¸¸å¼€å‘ï¼ˆç«™ç«‹ä¼šè®®ã€ç•ªèŒ„å·¥ä½œæ³•ã€ç»“å¯¹ç¼–ç¨‹ã€æµ‹è¯•å…ˆè¡Œã€ä»£ç é‡æ„â€¦â€¦ï¼‰ã€‚ä¿®å¤bugï¼ˆé—®é¢˜æè¿°ã€é‡ç°æ­¥éª¤ã€æµ‹è¯•äººå‘˜ã€è¢«æŒ‡æ´¾äººï¼‰ã€‚å‘å¸ƒç‰ˆæœ¬ã€‚è¯„å®¡ä¼šè®®ï¼ˆShowcaseï¼Œç”¨æˆ·éœ€è¦å‚ä¸ï¼‰ã€‚å›é¡¾ä¼šè®®ï¼ˆå¯¹å½“å‰è¿­ä»£å‘¨æœŸåšä¸€ä¸ªæ€»ç»“ï¼‰ã€‚è¡¥å……ï¼šæ•æ·è½¯ä»¶å¼€å‘å®£è¨€ä¸ªä½“å’Œäº’åŠ¨ é«˜äº æµç¨‹å’Œå·¥å…·å·¥ä½œçš„è½¯ä»¶ é«˜äº è¯¦å°½çš„æ–‡æ¡£å®¢æˆ·åˆä½œ é«˜äº åˆåŒè°ˆåˆ¤å“åº”å˜åŒ– é«˜äº éµå¾ªè®¡åˆ’è§’è‰²ï¼šäº§å“æ‰€æœ‰è€…ï¼ˆå†³å®šåšä»€ä¹ˆï¼Œèƒ½å¯¹éœ€æ±‚æ‹æ¿çš„äººï¼‰ã€å›¢é˜Ÿè´Ÿè´£äººï¼ˆè§£å†³å„ç§é—®é¢˜ï¼Œä¸“æ³¨å¦‚ä½•æ›´å¥½çš„å·¥ä½œï¼Œå±è”½å¤–éƒ¨å¯¹å¼€å‘å›¢é˜Ÿçš„å½±å“ï¼‰ã€å¼€å‘å›¢é˜Ÿï¼ˆé¡¹ç›®æ‰§è¡Œäººå‘˜ï¼Œå…·ä½“æŒ‡å¼€å‘äººå‘˜å’Œæµ‹è¯•äººå‘˜ï¼‰ã€‚å‡†å¤‡å·¥ä½œï¼šå•†ä¸šæ¡ˆä¾‹å’Œèµ„é‡‘ã€åˆåŒã€æ†§æ†¬ã€åˆå§‹äº§å“éœ€æ±‚ã€åˆå§‹å‘å¸ƒè®¡åˆ’ã€å…¥è‚¡ã€ç»„å»ºå›¢é˜Ÿã€‚æ•æ·å›¢é˜Ÿé€šå¸¸äººæ•°ä¸º8-10äººã€‚å·¥ä½œé‡ä¼°ç®—ï¼šå°†å¼€å‘ä»»åŠ¡é‡åŒ–ï¼ŒåŒ…æ‹¬åŸå‹ã€Logoè®¾è®¡ã€UIè®¾è®¡ã€å‰ç«¯å¼€å‘ç­‰ï¼Œå°½é‡æŠŠæ¯ä¸ªå·¥ä½œåˆ†è§£åˆ°æœ€å°ä»»åŠ¡é‡ï¼Œæœ€å°ä»»åŠ¡é‡æ ‡å‡†ä¸ºå·¥ä½œæ—¶é—´ä¸èƒ½è¶…è¿‡ä¸¤å¤©ï¼Œç„¶åä¼°ç®—æ€»ä½“é¡¹ç›®æ—¶é—´ã€‚æŠŠæ¯ä¸ªä»»åŠ¡éƒ½è´´åœ¨çœ‹æ¿ä¸Šé¢ï¼Œçœ‹æ¿ä¸Šåˆ†ä¸‰éƒ¨åˆ†ï¼što doï¼ˆå¾…å®Œæˆï¼‰ã€in progressï¼ˆè¿›è¡Œä¸­ï¼‰å’Œdoneï¼ˆå·²å®Œæˆï¼‰ã€‚é¡¹ç›®å›¢é˜Ÿç»„å»ºå›¢é˜Ÿçš„æ„æˆå’Œè§’è‰²è¯´æ˜ï¼šè°¢è°¢ä»˜ç¥¥è‹±å¥³å£«å¸®åŠ©æˆ‘ç»˜åˆ¶äº†ä¸‹é¢è¿™å¼ ç²¾ç¾çš„å…¬å¸ç»„ç»‡æ¶æ„å›¾ã€‚ç¼–ç¨‹è§„èŒƒå’Œä»£ç å®¡æŸ¥ï¼ˆflake8ã€pylintï¼‰Pythonä¸­çš„ä¸€äº›â€œæƒ¯ä¾‹â€ï¼ˆè¯·å‚è€ƒã€ŠPythonæƒ¯ä¾‹-å¦‚ä½•ç¼–å†™Pythonicçš„ä»£ç ã€‹ï¼‰å½±å“ä»£ç å¯è¯»æ€§çš„åŸå› ï¼šä»£ç æ³¨é‡Šå¤ªå°‘æˆ–è€…æ²¡æœ‰æ³¨é‡Šä»£ç ç ´åäº†è¯­è¨€çš„æœ€ä½³å®è·µåæ¨¡å¼ç¼–ç¨‹ï¼ˆæ„å¤§åˆ©é¢ä»£ç ã€å¤åˆ¶-é»è´´ç¼–ç¨‹ã€è‡ªè´Ÿç¼–ç¨‹ã€â€¦â€¦ï¼‰å›¢é˜Ÿå¼€å‘å·¥å…·ä»‹ç»ç‰ˆæœ¬æ§åˆ¶ï¼šGitã€Mercuryç¼ºé™·ç®¡ç†ï¼šGitlabã€Redmineæ•æ·é—­ç¯å·¥å…·ï¼šç¦…é“ã€JIRAæŒç»­é›†æˆï¼šJenkinsã€Travis-CIè¯·å‚è€ƒã€Šå›¢é˜Ÿé¡¹ç›®å¼€å‘çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆã€‹ã€‚é¡¹ç›®é€‰é¢˜å’Œç†è§£ä¸šåŠ¡é€‰é¢˜èŒƒå›´è®¾å®šCMSï¼ˆç”¨æˆ·ç«¯ï¼‰ï¼šæ–°é—»èšåˆç½‘ç«™ã€é—®ç­”/åˆ†äº«ç¤¾åŒºã€å½±è¯„/ä¹¦è¯„ç½‘ç«™ç­‰ã€‚MISï¼ˆç”¨æˆ·ç«¯+ç®¡ç†ç«¯ï¼‰ï¼šKMSã€KPIè€ƒæ ¸ç³»ç»Ÿã€HRSã€CRMç³»ç»Ÿã€ä¾›åº”é“¾ç³»ç»Ÿã€ä»“å‚¨ç®¡ç†ç³»ç»Ÿç­‰ã€‚Appåå°ï¼ˆç®¡ç†ç«¯+æ•°æ®æ¥å£ï¼‰ï¼šäºŒæ‰‹äº¤æ˜“ç±»ã€æŠ¥åˆŠæ‚å¿—ç±»ã€å°ä¼—ç”µå•†ç±»ã€æ–°é—»èµ„è®¯ç±»ã€æ—…æ¸¸ç±»ã€ç¤¾äº¤ç±»ã€é˜…è¯»ç±»ç­‰ã€‚å…¶ä»–ç±»å‹ï¼šè‡ªèº«è¡Œä¸šèƒŒæ™¯å’Œå·¥ä½œç»éªŒã€ä¸šåŠ¡å®¹æ˜“ç†è§£å’ŒæŠŠæ§ã€‚éœ€æ±‚ç†è§£ã€æ¨¡å—åˆ’åˆ†å’Œä»»åŠ¡åˆ†é…éœ€æ±‚ç†è§£ï¼šå¤´è„‘é£æš´å’Œç«å“åˆ†æã€‚æ¨¡å—åˆ’åˆ†ï¼šç”»æ€ç»´å¯¼å›¾ï¼ˆXMindï¼‰ï¼Œæ¯ä¸ªæ¨¡å—æ˜¯ä¸€ä¸ªæèŠ‚ç‚¹ï¼Œæ¯ä¸ªå…·ä½“çš„åŠŸèƒ½æ˜¯ä¸€ä¸ªå¶èŠ‚ç‚¹ï¼ˆç”¨åŠ¨è¯è¡¨è¿°ï¼‰ï¼Œéœ€è¦ç¡®ä¿æ¯ä¸ªå¶èŠ‚ç‚¹æ— æ³•å†ç”Ÿå‡ºæ–°èŠ‚ç‚¹ï¼Œç¡®å®šæ¯ä¸ªå¶å­èŠ‚ç‚¹çš„é‡è¦æ€§ã€ä¼˜å…ˆçº§å’Œå·¥ä½œé‡ã€‚ä»»åŠ¡åˆ†é…ï¼šç”±é¡¹ç›®è´Ÿè´£äººæ ¹æ®ä¸Šé¢çš„æŒ‡æ ‡ä¸ºæ¯ä¸ªå›¢é˜Ÿæˆå‘˜åˆ†é…ä»»åŠ¡ã€‚åˆ¶å®šé¡¹ç›®è¿›åº¦è¡¨ï¼ˆæ¯æ—¥æ›´æ–°ï¼‰æ¨¡å—åŠŸèƒ½äººå‘˜çŠ¶æ€å®Œæˆå·¥æ—¶è®¡åˆ’å¼€å§‹å®é™…å¼€å§‹è®¡åˆ’ç»“æŸå®é™…ç»“æŸå¤‡æ³¨è¯„è®ºæ·»åŠ è¯„è®ºç‹å¤§é”¤æ­£åœ¨è¿›è¡Œ50%42018/8/72018/8/7åˆ é™¤è¯„è®ºç‹å¤§é”¤ç­‰å¾…0%22018/8/72018/8/7æŸ¥çœ‹è¯„è®ºç™½å…ƒèŠ³æ­£åœ¨è¿›è¡Œ20%42018/8/72018/8/7éœ€è¦è¿›è¡Œä»£ç å®¡æŸ¥è¯„è®ºæŠ•ç¥¨ç™½å…ƒèŠ³ç­‰å¾…0%42018/8/82018/8/8OOADå’Œæ•°æ®åº“è®¾è®¡UMLï¼ˆç»Ÿä¸€å»ºæ¨¡è¯­è¨€ï¼‰çš„ç±»å›¾é€šè¿‡æ¨¡å‹åˆ›å»ºè¡¨ï¼ˆæ­£å‘å·¥ç¨‹ï¼‰ï¼Œä¾‹å¦‚åœ¨Djangoé¡¹ç›®ä¸­å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤åˆ›å»ºäºŒç»´è¡¨ã€‚python manage.py makemigrations apppython manage.py migrateä½¿ç”¨PowerDesignerç»˜åˆ¶ç‰©ç†æ¨¡å‹å›¾ã€‚é€šè¿‡æ•°æ®è¡¨åˆ›å»ºæ¨¡å‹ï¼ˆåå‘å·¥ç¨‹ï¼‰ï¼Œä¾‹å¦‚åœ¨Djangoé¡¹ç›®ä¸­å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤ç”Ÿæˆæ¨¡å‹ã€‚python manage.py inspectdb > app/models.pyç¬¬92å¤©ï¼šDockerå®¹å™¨è¯¦è§£Dockerç®€ä»‹å®‰è£…Dockerä½¿ç”¨Dockeråˆ›å»ºå®¹å™¨ï¼ˆNginxã€MySQLã€Redisã€Gitlabã€Jenkinsï¼‰æ„å»ºDockeré•œåƒï¼ˆDockerfileçš„ç¼–å†™å’Œç›¸å…³æŒ‡ä»¤ï¼‰å®¹å™¨ç¼–æ’ï¼ˆDocker-composeï¼‰é›†ç¾¤ç®¡ç†ï¼ˆKubernetesï¼‰ç¬¬93å¤©ï¼šMySQLæ€§èƒ½ä¼˜åŒ–ç¬¬94å¤©ï¼šç½‘ç»œAPIæ¥å£è®¾è®¡ç¬¬95å¤©ï¼š[ä½¿ç”¨Djangoå¼€å‘å•†ä¸šé¡¹ç›®](./Day91-100/95.ä½¿ç”¨Djangoå¼€å‘å•†ä¸šé¡¹\tç›®.md)é¡¹ç›®å¼€å‘ä¸­çš„å…¬å…±é—®é¢˜æ•°æ®åº“çš„é…ç½®ï¼ˆå¤šæ•°æ®åº“ã€ä¸»ä»å¤åˆ¶ã€æ•°æ®åº“è·¯ç”±ï¼‰ç¼“å­˜çš„é…ç½®ï¼ˆåˆ†åŒºç¼“å­˜ã€é”®è®¾ç½®ã€è¶…æ—¶è®¾ç½®ã€ä¸»ä»å¤åˆ¶ã€æ•…éšœæ¢å¤ï¼ˆå“¨å…µï¼‰ï¼‰æ—¥å¿—çš„é…ç½®åˆ†æå’Œè°ƒè¯•ï¼ˆDjango-Debug-ToolBarï¼‰å¥½ç”¨çš„Pythonæ¨¡å—ï¼ˆæ—¥æœŸè®¡ç®—ã€å›¾åƒå¤„ç†ã€æ•°æ®åŠ å¯†ã€ä¸‰æ–¹APIï¼‰REST APIè®¾è®¡RESTfulæ¶æ„ç†è§£RESTfulæ¶æ„RESTful APIè®¾è®¡æŒ‡å—RESTful APIæœ€ä½³å®è·µAPIæ¥å£æ–‡æ¡£çš„æ’°å†™RAP2YAPIdjango-REST-frameworkçš„åº”ç”¨é¡¹ç›®ä¸­çš„é‡ç‚¹éš¾ç‚¹å‰–æä½¿ç”¨ç¼“å­˜ç¼“è§£æ•°æ®åº“å‹åŠ› - Redisä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—åšè§£è€¦åˆå’Œå‰Šå³° - Celery + RabbitMQç¬¬96å¤©ï¼šè½¯ä»¶æµ‹è¯•å’Œè‡ªåŠ¨åŒ–æµ‹è¯•å•å…ƒæµ‹è¯•æµ‹è¯•çš„ç§ç±»ç¼–å†™å•å…ƒæµ‹è¯•ï¼ˆunittestã€pytestã€nose2ã€toxã€ddtã€â€¦â€¦ï¼‰æµ‹è¯•è¦†ç›–ç‡ï¼ˆcoverageï¼‰Djangoé¡¹ç›®éƒ¨ç½²éƒ¨ç½²å‰çš„å‡†å¤‡å·¥ä½œå…³é”®è®¾ç½®ï¼ˆSECRET_KEY / DEBUG / ALLOWED_HOSTS / ç¼“å­˜ / æ•°æ®åº“ï¼‰HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECUREæ—¥å¿—ç›¸å…³é…ç½®Linuxå¸¸ç”¨å‘½ä»¤å›é¡¾Linuxå¸¸ç”¨æœåŠ¡çš„å®‰è£…å’Œé…ç½®uWSGI/Gunicornå’ŒNginxçš„ä½¿ç”¨Gunicornå’ŒuWSGIçš„æ¯”è¾ƒå¯¹äºä¸éœ€è¦å¤§é‡å®šåˆ¶åŒ–çš„ç®€å•åº”ç”¨ç¨‹åºï¼ŒGunicornæ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ï¼ŒuWSGIçš„å­¦ä¹ æ›²çº¿æ¯”Gunicornè¦é™¡å³­å¾—å¤šï¼ŒGunicornçš„é»˜è®¤å‚æ•°å°±å·²ç»èƒ½å¤Ÿé€‚åº”å¤§å¤šæ•°åº”ç”¨ç¨‹åºã€‚uWSGIæ”¯æŒå¼‚æ„éƒ¨ç½²ã€‚ç”±äºNginxæœ¬èº«æ”¯æŒuWSGIï¼Œåœ¨çº¿ä¸Šä¸€èˆ¬éƒ½å°†Nginxå’ŒuWSGIæ†ç»‘åœ¨ä¸€èµ·éƒ¨ç½²ï¼Œè€Œä¸”uWSGIå±äºåŠŸèƒ½é½å…¨ä¸”é«˜åº¦å®šåˆ¶çš„WSGIä¸­é—´ä»¶ã€‚åœ¨æ€§èƒ½ä¸Šï¼ŒGunicornå’ŒuWSGIå…¶å®è¡¨ç°ç›¸å½“ã€‚ä½¿ç”¨è™šæ‹ŸåŒ–æŠ€æœ¯ï¼ˆDockerï¼‰éƒ¨ç½²æµ‹è¯•ç¯å¢ƒå’Œç”Ÿäº§ç¯å¢ƒæ€§èƒ½æµ‹è¯•ABçš„ä½¿ç”¨SQLslapçš„ä½¿ç”¨sysbenchçš„ä½¿ç”¨è‡ªåŠ¨åŒ–æµ‹è¯•ä½¿ç”¨Shellå’ŒPythonè¿›è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•ä½¿ç”¨Seleniumå®ç°è‡ªåŠ¨åŒ–æµ‹è¯•Selenium IDESelenium WebDriverSelenium Remote Controlæµ‹è¯•å·¥å…·Robot Frameworkä»‹ç»ç¬¬97å¤©ï¼šç”µå•†ç½‘ç«™æŠ€æœ¯è¦ç‚¹å‰–æç¬¬98å¤©ï¼šé¡¹ç›®éƒ¨ç½²ä¸Šçº¿å’Œæ€§èƒ½è°ƒä¼˜MySQLæ•°æ®åº“è°ƒä¼˜WebæœåŠ¡å™¨æ€§èƒ½ä¼˜åŒ–Nginxè´Ÿè½½å‡è¡¡é…ç½®Keepalivedå®ç°é«˜å¯ç”¨ä»£ç æ€§èƒ½è°ƒä¼˜å¤šçº¿ç¨‹å¼‚æ­¥åŒ–é™æ€èµ„æºè®¿é—®ä¼˜åŒ–äº‘å­˜å‚¨CDNç¬¬99å¤©ï¼šé¢è¯•ä¸­çš„å…¬å…±é—®é¢˜ç¬¬100å¤©ï¼šPythoné¢è¯•é¢˜å®å½•"
1,Significant-Gravitas/Auto-GPT,https://github.com/Significant-Gravitas/Auto-GPT/blob/master/README.md,Python,"Auto-GPT: An Autonomous GPT-4 ExperimentğŸ’¡ Get help - Q&A or Discord ğŸ’¬ğŸ”´ USE stable not master ğŸ”´Download the latest stable release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.The master branch is under heavy development and may often be in a broken state.Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \""thoughts\"", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI. Demo April 16th 2023               AutoGPTDemo_Subs_WithoutFinalScreen.mp4          Demo made by Blake WerlingerğŸš€ FeaturesğŸŒ Internet access for searches and information gatheringğŸ’¾ Long-term and short-term memory managementğŸ§  GPT-4 instances for text generationğŸ”— Access to popular websites and platformsğŸ—ƒï¸ File storage and summarization with GPT-3.5ğŸ”Œ Extensibility with PluginsQuickstartCheck out the wikiGet an OpenAI API KeyDownload the latest releaseFollow the installation instructionsConfigure any additional features you want, or install some pluginsRun the appPlease see the documentation for full setup instructions and configuration options.ğŸ“– Documentationâš™ï¸ SetupğŸ’» UsageğŸ”Œ PluginsConfigurationğŸ” Web SearchğŸ§  MemoryğŸ—£ï¸ Voice (TTS)ğŸ–¼ï¸ Image Generation ğŸ’– Help Fund Auto-GPT's Development ğŸ’–If you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help to push the boundaries of fully autonomous AI!Your support is greatly appreciated. Development of this free, open-source project is made possible by all the contributors and sponsors. If you'd like to sponsor this project and have your avatar or company logo appear below click here.                Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âš ï¸ LimitationsThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:Not a polished application or product, just an experimentMay not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!Quite expensive to run, so set and monitor your API key limits with OpenAI!ğŸ›¡ DisclaimerThis project, Auto-GPT, is an experimental application and is provided \""as-is\"" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.The developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.Please note that the use of the GPT-4 language model can be expensive due to its token usage. By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.As an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.By using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.ğŸ¦ Connect with Us on TwitterStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.Developer: Follow @siggravitas for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!        "
2,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
3,pallets/flask,https://github.com/pallets/flask/blob/main/README.rst,Python,"FlaskFlask is a lightweight WSGI web application framework. It is designedto make getting started quick and easy, with the ability to scale up tocomplex applications. It began as a simple wrapper around Werkzeugand Jinja and has become one of the most popular Python webapplication frameworks.Flask offers suggestions, but doesn't enforce any dependencies orproject layout. It is up to the developer to choose the tools andlibraries they want to use. There are many extensions provided by thecommunity that make adding new functionality easy.InstallingInstall and update using pip:$ pip install -U FlaskA Simple Example# save this as app.pyfrom flask import Flaskapp = Flask(__name__)@app.route(\""/\"")def hello():    return \""Hello, World!\""$ flask run  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)ContributingFor guidance on setting up a development environment and how to make acontribution to Flask, see the contributing guidelines.DonateThe Pallets organization develops and supports Flask and the librariesit uses. In order to grow the community of contributors and users, andallow the maintainers to devote more time to the projects, pleasedonate today.LinksDocumentation: https://flask.palletsprojects.com/Changes: https://flask.palletsprojects.com/changes/PyPI Releases: https://pypi.org/project/Flask/Source Code: https://github.com/pallets/flask/Issue Tracker: https://github.com/pallets/flask/issues/Chat: https://discord.gg/pallets"
4,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.âš ï¸ IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!âš ï¸ IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means youâ€™ve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the projectâ€™s direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a projectâ€™s website for a â€œteamâ€ page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participantsâ€™ behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, â€œHow do Iâ€¦â€œ or â€œWhat do you think aboutâ€¦â€œ instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
5,apachecn/ailearning,https://github.com/apachecn/ailearning/blob/master/README.md,Python,"                                AI learningåè®®ï¼šCC BY-NC-SA 4.0ä¸€ç§æ–°æŠ€æœ¯ä¸€æ—¦å¼€å§‹æµè¡Œï¼Œä½ è¦ä¹ˆåä¸Šå‹è·¯æœºï¼Œè¦ä¹ˆæˆä¸ºé“ºè·¯çŸ³ã€‚â€”â€”Stewart Brandåœ¨çº¿é˜…è¯»åœ¨çº¿é˜…è¯»ï¼ˆv1ï¼‰QuantLearningApacheCN ä¸­æ–‡ç¿»è¯‘ç»„ 713436582ApacheCN å­¦ä¹ èµ„æºæ³¨: å¹¿å‘Šä½åˆä½œ(ç‰©ç¾ä»·å»‰)ï¼Œè¯·è”ç³» apachecn@163.comè·¯çº¿å›¾å…¥é—¨åªçœ‹: æ­¥éª¤ 1 => 2 => 3ï¼Œä½ å¯ä»¥å½“å¤§ç‰›ï¼ä¸­çº§è¡¥å…… - èµ„æ–™åº“: https://github.com/apachecn/ai-roadmapè¡¥å……ç®—æ³•åˆ·é¢˜: https://www.ixigua.com/pseries/6822642486343631363/é¢è¯•æ±‚èŒ: https://www.ixigua.com/pseries/6822563009391493636/æœºå™¨å­¦ä¹ å®æˆ˜: https://www.ixigua.com/pseries/6822816341615968772/NLPæ•™å­¦è§†é¢‘: https://www.ixigua.com/pseries/6828241431295951373/AIå¸¸ç”¨å‡½æ•°è¯´æ˜: https://github.com/apachecn/AiLearning/tree/master/AIå¸¸ç”¨å‡½æ•°è¯´æ˜.md1.æœºå™¨å­¦ä¹  - åŸºç¡€æ”¯æŒç‰ˆæœ¬VersionSupported3.6.xâŒ2.7.xâœ…æ³¨æ„äº‹é¡¹:æœºå™¨å­¦ä¹ å®æˆ˜: ä»…ä»…åªæ˜¯å­¦ä¹ ï¼Œè¯·ä½¿ç”¨ python 2.7.x ç‰ˆæœ¬ ï¼ˆ3.6.x åªæ˜¯ä¿®æ”¹äº†éƒ¨åˆ†ï¼‰åŸºæœ¬ä»‹ç»èµ„æ–™æ¥æº: Machine Learning in Action(æœºå™¨å­¦ä¹ å®æˆ˜-ä¸ªäººç¬”è®°)ç»Ÿä¸€æ•°æ®åœ°å€: https://github.com/apachecn/dataç™¾åº¦äº‘æ‰“åŒ…åœ°å€: apachecn/data#3ä¹¦ç±ä¸‹è½½åœ°å€: https://github.com/apachecn/data/tree/master/bookæœºå™¨å­¦ä¹ ä¸‹è½½åœ°å€: https://github.com/apachecn/data/tree/master/æœºå™¨å­¦ä¹ æ·±åº¦å­¦ä¹ æ•°æ®åœ°å€: https://github.com/apachecn/data/tree/master/æ·±åº¦å­¦ä¹ æ¨èç³»ç»Ÿæ•°æ®åœ°å€: https://github.com/apachecn/data/tree/master/æ¨èç³»ç»Ÿè§†é¢‘ç½‘ç«™: ä¼˜é…· ï¼bilibili / Acfun / ç½‘æ˜“äº‘è¯¾å ‚ï¼Œå¯ç›´æ¥åœ¨çº¿æ’­æ”¾ã€‚ï¼ˆæœ€ä¸‹æ–¹æœ‰ç›¸åº”é“¾æ¥ï¼‰-- æ¨è çº¢è‰²çŸ³å¤´: å°æ¹¾å¤§å­¦æ—è½©ç”°æœºå™¨å­¦ä¹ ç¬”è®°-- æ¨è æœºå™¨å­¦ä¹ ç¬”è®°: https://feisky.xyz/machine-learningå­¦ä¹ æ–‡æ¡£æ¨¡å—ç« èŠ‚ç±»å‹è´Ÿè´£äºº(GitHub)QQæœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 1 ç« : æœºå™¨å­¦ä¹ åŸºç¡€ä»‹ç»@æ¯›çº¢åŠ¨1306014226æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 2 ç« : KNN è¿‘é‚»ç®—æ³•åˆ†ç±»@å°¤æ°¸æ±Ÿ279393323æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 3 ç« : å†³ç­–æ ‘åˆ†ç±»@æ™¯æ¶›844300439æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 4 ç« : æœ´ç´ è´å¶æ–¯åˆ†ç±»@wnma3mz@åˆ†æ1003324213244970749æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 5 ç« : Logisticå›å½’åˆ†ç±»@å¾®å…‰åŒå°˜529925688æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 6 ç« : SVM æ”¯æŒå‘é‡æœºåˆ†ç±»@ç‹å¾·çº¢934969547ç½‘ä¸Šç»„åˆå†…å®¹ç¬¬ 7 ç« : é›†æˆæ–¹æ³•ï¼ˆéšæœºæ£®æ—å’Œ AdaBoostï¼‰åˆ†ç±»@ç‰‡åˆ»529815144æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 8 ç« : å›å½’å›å½’@å¾®å…‰åŒå°˜529925688æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 9 ç« : æ ‘å›å½’å›å½’@å¾®å…‰åŒå°˜529925688æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 10 ç« : K-Means èšç±»èšç±»@å¾æ˜­æ¸…827106588æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 11 ç« : åˆ©ç”¨ Apriori ç®—æ³•è¿›è¡Œå…³è”åˆ†æé¢‘ç¹é¡¹é›†@åˆ˜æµ·é£1049498972æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 12 ç« : FP-growth é«˜æ•ˆå‘ç°é¢‘ç¹é¡¹é›†é¢‘ç¹é¡¹é›†@ç¨‹å¨842725815æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 13 ç« : åˆ©ç”¨ PCA æ¥ç®€åŒ–æ•°æ®å·¥å…·@å»–ç«‹å¨Ÿ835670618æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 14 ç« : åˆ©ç”¨ SVD æ¥ç®€åŒ–æ•°æ®å·¥å…·@å¼ ä¿Šçš“714974242æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 15 ç« : å¤§æ•°æ®ä¸ MapReduceå·¥å…·@wnma3mz1003324213Mlé¡¹ç›®å®æˆ˜ç¬¬ 16 ç« : æ¨èç³»ç»Ÿï¼ˆå·²è¿ç§»ï¼‰é¡¹ç›®æ¨èç³»ç»Ÿï¼ˆè¿ç§»ååœ°å€ï¼‰ç¬¬ä¸€æœŸçš„æ€»ç»“2017-04-08: ç¬¬ä¸€æœŸçš„æ€»ç»“æ€»ç»“æ€»ç»“529815144ç½‘ç«™è§†é¢‘çŸ¥ä¹é—®ç­”-çˆ†ç‚¸å•¦-æœºå™¨å­¦ä¹ è¯¥æ€ä¹ˆå…¥é—¨ï¼Ÿå½“ç„¶æˆ‘çŸ¥é“ï¼Œç¬¬ä¸€å¥å°±ä¼šè¢«åæ§½ï¼Œå› ä¸ºç§‘ç­å‡ºèº«çš„äººï¼Œä¸å±‘çš„åäº†ä¸€å£å”¾æ²«ï¼Œè¯´å‚»Xï¼Œè¿˜è¯„è®º Andrew Ng çš„è§†é¢‘ã€‚ã€‚æˆ‘è¿˜çŸ¥é“è¿˜æœ‰ä¸€éƒ¨åˆ†äººï¼Œçœ‹ Andrew Ng çš„è§†é¢‘å°±æ˜¯çœ‹ä¸æ‡‚ï¼Œé‚£ç¥ç§˜çš„æ•°å­¦æ¨å¯¼ï¼Œé‚£è¿·ä¹‹å¾®ç¬‘çš„è‹±æ–‡ç‰ˆçš„æ•™å­¦ï¼Œæˆ‘ä½•å°åˆä¸æ˜¯è¿™æ ·èµ°è¿‡æ¥çš„ï¼Ÿï¼Ÿ æˆ‘çš„å¿ƒå¯èƒ½æ¯”ä½ ä»¬éƒ½ç—›ï¼Œå› ä¸ºæˆ‘åœ¨ç½‘ä¸Šæ”¶è—è¿‡ä¸Š10éƒ¨ã€Šæœºå™¨å­¦ä¹ ã€‹ç›¸å…³è§†é¢‘ï¼Œå¤–åŠ å›½å†…æœ¬åœŸé£æ ¼çš„æ•™ç¨‹: 7æœˆ+å°è±¡ ç­‰ç­‰ï¼Œæˆ‘éƒ½å¾ˆéš¾å»å¬æ‡‚ï¼Œç›´åˆ°æœ‰ä¸€å¤©ï¼Œè¢«ä¸€ä¸ªç™¾åº¦çš„é«˜çº§ç®—æ³•åˆ†æå¸ˆæ¨èè¯´: ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹è¿˜ä¸é”™ï¼Œé€šä¿—æ˜“æ‡‚ï¼Œä½ å»è¯•è¯•ï¼Ÿï¼Ÿæˆ‘è¯•äº†è¯•ï¼Œè¿˜å¥½æˆ‘çš„PythonåŸºç¡€å’Œè°ƒè¯•èƒ½åŠ›è¿˜ä¸é”™ï¼ŒåŸºæœ¬ä¸Šä»£ç éƒ½è°ƒè¯•è¿‡ä¸€éï¼Œå¾ˆå¤šé«˜å¤§ä¸Šçš„ \""ç†è®º+æ¨å¯¼\""ï¼Œåœ¨æˆ‘çœ¼ä¸­å˜æˆäº†å‡ ä¸ª \""åŠ å‡ä¹˜é™¤+å¾ªç¯\""ï¼Œæˆ‘æƒ³è¿™ä¸å°±æ˜¯åƒæˆ‘è¿™æ ·çš„ç¨‹åºå‘˜æƒ³è¦çš„å…¥é—¨æ•™ç¨‹ä¹ˆï¼Ÿå¾ˆå¤šç¨‹åºå‘˜è¯´æœºå™¨å­¦ä¹  TM å¤ªéš¾å­¦äº†ï¼Œæ˜¯çš„ï¼ŒçœŸ TM éš¾å­¦ï¼Œæˆ‘æƒ³æœ€éš¾çš„æ˜¯: æ²¡æœ‰ä¸€æœ¬åƒã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹é‚£æ ·çš„ä½œè€…æ„¿æ„ä»¥ç¨‹åºå‘˜ Coding è§’åº¦å»ç»™å¤§å®¶è®²è§£ï¼ï¼æœ€è¿‘å‡ å¤©ï¼ŒGitHub æ¶¨äº† 300é¢— starï¼ŒåŠ ç¾¤çš„200äººï¼Œ ç°åœ¨è¿˜åœ¨ä¸æ–­çš„å¢åŠ ++ï¼Œæˆ‘æƒ³å¤§å®¶å¯èƒ½éƒ½æ˜¯æ„ŸåŒèº«å—å§ï¼å¾ˆå¤šæƒ³å…¥é—¨æ–°æ‰‹å°±æ˜¯è¢«å¿½æ‚ ç€æ”¶è—æ”¶è—å†æ”¶è—ï¼Œä½†æ˜¯æœ€åè¿˜æ˜¯ä»€ä¹ˆéƒ½æ²¡æœ‰å­¦åˆ°ï¼Œä¹Ÿå°±æ˜¯\""èµ„æºæ”¶è—å®¶\""ï¼Œä¹Ÿè®¸æ–°æ‰‹è¦çš„å°±æ˜¯ MachineLearning(æœºå™¨å­¦ä¹ ) å­¦ä¹ è·¯çº¿å›¾ã€‚æ²¡é”™ï¼Œæˆ‘å¯ä»¥ç»™ä½ ä»¬çš„ä¸€ä»½ï¼Œå› ä¸ºæˆ‘ä»¬è¿˜é€šè¿‡è§†é¢‘è®°å½•ä¸‹æ¥æˆ‘ä»¬çš„å­¦ä¹ è¿‡ç¨‹ã€‚æ°´å¹³å½“ç„¶ä¹Ÿæœ‰é™ï¼Œä¸è¿‡å¯¹äºæ–°æ‰‹å…¥é—¨ï¼Œç»å¯¹æ²¡é—®é¢˜ï¼Œå¦‚æœä½ è¿˜ä¸ä¼šï¼Œé‚£ç®—æˆ‘è¾“ï¼ï¼è§†é¢‘æ€ä¹ˆçœ‹ï¼Ÿç†è®ºç§‘ç­å‡ºèº«-å»ºè®®å»å­¦ä¹  Andrew Ng çš„è§†é¢‘ï¼ˆNg çš„è§†é¢‘ç»å¯¹æ˜¯æƒå¨ï¼Œè¿™ä¸ªæ¯‹åº¸ç½®ç–‘ï¼‰ç¼–ç èƒ½åŠ›å¼º - å»ºè®®çœ‹æˆ‘ä»¬çš„ã€Šæœºå™¨å­¦ä¹ å®æˆ˜-æ•™å­¦ç‰ˆã€‹ç¼–ç èƒ½åŠ›å¼± - å»ºè®®çœ‹æˆ‘ä»¬çš„ã€Šæœºå™¨å­¦ä¹ å®æˆ˜-è®¨è®ºç‰ˆã€‹ï¼Œä¸è¿‡åœ¨çœ‹ç†è®ºçš„æ—¶å€™ï¼Œçœ‹ æ•™å­¦ç‰ˆ-ç†è®ºéƒ¨åˆ†ï¼›è®¨è®ºç‰ˆçš„åºŸè¯å¤ªå¤šï¼Œä¸è¿‡åœ¨è®²è§£ä»£ç çš„æ—¶å€™æ˜¯ä¸€è¡Œä¸€è¡Œè®²è§£çš„ï¼›æ‰€ä»¥ï¼Œæ ¹æ®è‡ªå·±çš„éœ€æ±‚ï¼Œè‡ªç”±çš„ç»„åˆã€‚ã€å…è´¹ã€‘æ•°å­¦æ•™å­¦è§†é¢‘ - å¯æ±—å­¦é™¢ å…¥é—¨ç¯‡@äºæŒ¯æ¢“ æ¨è: å¯æ±—å­¦é™¢-ç½‘æ˜“å…¬å¼€è¯¾æ¦‚ç‡ç»Ÿè®¡çº¿æ€§ä»£æ•°å¯æ±—å­¦é™¢(æ¦‚ç‡)å¯æ±—å­¦é™¢(ç»Ÿè®¡å­¦)å¯æ±—å­¦é™¢(çº¿æ€§ä»£æ•°)æœºå™¨å­¦ä¹ è§†é¢‘ - ApacheCN æ•™å­¦ç‰ˆAcFunBç«™ä¼˜é…·ç½‘æ˜“äº‘è¯¾å ‚ã€å…è´¹ã€‘æœºå™¨/æ·±åº¦å­¦ä¹ è§†é¢‘ - å´æ©è¾¾æœºå™¨å­¦ä¹ æ·±åº¦å­¦ä¹ å´æ©è¾¾æœºå™¨å­¦ä¹ ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ 2.æ·±åº¦å­¦ä¹ æ”¯æŒç‰ˆæœ¬VersionSupported3.6.xâœ…2.7.xâŒå…¥é—¨åŸºç¡€åå‘ä¼ é€’: https://www.cnblogs.com/charlotte77/p/5629865.htmlCNNåŸç†: http://www.cnblogs.com/charlotte77/p/7759802.htmlRNNåŸç†: https://blog.csdn.net/qq_39422642/article/details/78676567LSTMåŸç†: https://blog.csdn.net/weixin_42111770/article/details/80900575Pytorch - æ•™ç¨‹-- å¾…æ›´æ–°TensorFlow 2.0 - æ•™ç¨‹-- å¾…æ›´æ–°ç›®å½•ç»“æ„:å®‰è£…æŒ‡å—Keras å¿«é€Ÿå…¥é—¨å®æˆ˜é¡¹ç›® 1 ç”µå½±æƒ…æ„Ÿåˆ†ç±»å®æˆ˜é¡¹ç›® 2 æ±½è½¦ç‡ƒæ²¹æ•ˆç‡å®æˆ˜é¡¹ç›® 3 ä¼˜åŒ– è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆå®æˆ˜é¡¹ç›® 4 å¤è¯—è¯è‡ªåŠ¨ç”Ÿæˆåˆ‡åˆ†ï¼ˆåˆ†è¯ï¼‰è¯æ€§æ ‡æ³¨å‘½åå®ä½“è¯†åˆ«å¥æ³•åˆ†æWordNetå¯ä»¥è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªåŒä¹‰è¯è¯å…¸è¯å¹²æå–ï¼ˆstemmingï¼‰ä¸è¯å½¢è¿˜åŸï¼ˆlemmatizationï¼‰https://www.biaodianfu.com/nltk.html/ampTensorFlow 2.0å­¦ä¹ ç½‘å€https://github.com/lyhue1991/eat_tensorflow2_in_30_days3.è‡ªç„¶è¯­è¨€å¤„ç†æ”¯æŒç‰ˆæœ¬VersionSupported3.6.xâœ…2.7.xâŒå­¦ä¹ è¿‡ç¨‹ä¸­-å†…å¿ƒå¤æ‚çš„å˜åŒ–ï¼ï¼ï¼è‡ªä»å­¦ä¹ NLPä»¥åï¼Œæ‰å‘ç°å›½å†…ä¸å›½å¤–çš„å…¸å‹åŒºåˆ«:1. å¯¹èµ„æºçš„æ€åº¦æ˜¯å®Œå…¨ç›¸åçš„:  1) å›½å†…: å°±å¥½åƒä¸ºäº†åæ°”ï¼Œä¸¾åŠå·¥ä½œè£…é€¼çš„ä¼šè®®ï¼Œå°±æ˜¯æ²¡æœ‰å¹²è´§ï¼Œå…¨éƒ¨éƒ½æ˜¯è±¡å¾æ€§çš„PPTä»‹ç»ï¼Œä¸æ˜¯é’ˆå¯¹åœ¨åšçš„å„ä½  2ï¼‰å›½å¤–: å°±å¥½åƒæ˜¯ä¸ºäº†æ¨åŠ¨nlpè¿›æ­¥ä¸€æ ·ï¼Œåˆ†äº«è€…å„ç§å¹²è´§èµ„æ–™å’Œå…·ä½“çš„å®ç°ã€‚ï¼ˆç‰¹åˆ«æ˜¯: pythonè‡ªç„¶è¯­è¨€å¤„ç†ï¼‰2. è®ºæ–‡çš„å®ç°:   1) å„ç§é«˜å¤§ä¸Šçš„è®ºæ–‡å®ç°ï¼Œå´è¿˜æ˜¯æ²¡çœ‹åˆ°ä¸€ä¸ªåƒæ ·çš„GitHubé¡¹ç›®ï¼ï¼ˆå¯èƒ½æˆ‘çš„æœç´¢èƒ½åŠ›å·®äº†ç‚¹ï¼Œä¸€ç›´æ²¡æ‰¾åˆ°ï¼‰  2ï¼‰å›½å¤–å°±ä¸ä¸¾ä¾‹äº†ï¼Œæˆ‘çœ‹ä¸æ‡‚ï¼3. å¼€æºçš„æ¡†æ¶  1ï¼‰å›½å¤–çš„å¼€æºæ¡†æ¶:  tensorflow/pytorch æ–‡æ¡£+æ•™ç¨‹+è§†é¢‘ï¼ˆå®˜æ–¹æä¾›ï¼‰  2) å›½å†…çš„å¼€æºæ¡†æ¶: é¢é¢ï¼Œè¿˜çœŸä¸¾ä¾‹ä¸å‡ºæ¥ï¼ä½†æ˜¯ç‰›é€¼å¹å¾—ä¸æ¯”å›½å¤–å·®ï¼ï¼ˆMXNetè™½ç„¶æœ‰ä¼—å¤šå›½äººå‚ä¸å¼€å‘ï¼Œä½†ä¸èƒ½ç®—æ˜¯å›½å†…å¼€æºæ¡†æ¶ã€‚åŸºäºMXNetçš„åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ (http://zh.d2l.ai & https://discuss.gluon.ai/t/topic/753)ä¸­æ–‡æ•™ç¨‹,å·²ç»ç”±æ²ç¥(ææ²)ä»¥åŠé˜¿æ–¯é¡¿Â·å¼ è®²æˆå½•åˆ¶ï¼Œå…¬å¼€å‘å¸ƒ(æ–‡æ¡£+ç¬¬ä¸€å­£æ•™ç¨‹+è§†é¢‘ï¼‰ã€‚)æ¯ä¸€æ¬¡æ·±å…¥éƒ½è¦å»ç¿»å¢™ï¼Œæ¯ä¸€æ¬¡æ·±å…¥éƒ½è¦Googleï¼Œæ¯ä¸€æ¬¡çœ‹ç€å›½å†…çš„è¯´: å“ˆå·¥å¤§ã€è®¯é£ã€ä¸­ç§‘å¤§ã€ç™¾åº¦ã€é˜¿é‡Œå¤šç‰›é€¼ï¼Œä½†æ˜¯èµ„æ–™è¿˜æ˜¯å¾—å›½å¤–å»æ‰¾ï¼æœ‰æ—¶å€™çœŸçš„æŒºæ¨çš„ï¼çœŸçš„æœ‰ç‚¹ç§ä¸èµ·è‡ªå·±å›½å†…çš„æŠ€æœ¯ç¯å¢ƒï¼å½“ç„¶è°¢è°¢å›½å†…å¾ˆå¤šåšå®¢å¤§ä½¬ï¼Œç‰¹åˆ«æ˜¯ä¸€äº›å…¥é—¨çš„Demoå’ŒåŸºæœ¬æ¦‚å¿µã€‚ã€æ·±å…¥çš„æ°´å¹³æœ‰é™ï¼Œæ²¡çœ‹æ‡‚ã€‘ã€å…¥é—¨é¡»çŸ¥ã€‘å¿…é¡»äº†è§£: https://github.com/apachecn/AiLearning/tree/master/nlpã€å…¥é—¨æ•™ç¨‹ã€‘å¼ºçƒˆæ¨è: PyTorch è‡ªç„¶è¯­è¨€å¤„ç†: https://github.com/apachecn/NLP-with-PyTorchPython è‡ªç„¶è¯­è¨€å¤„ç† ç¬¬äºŒç‰ˆ: https://usyiyi.github.io/nlp-py-2e-zhæ¨èä¸€ä¸ªliuhuanyongå¤§ä½¬æ•´ç†çš„nlpå…¨é¢çŸ¥è¯†ä½“ç³»: https://liuhuanyong.github.ioå¼€æº - è¯å‘é‡åº“é›†åˆ:https://www.cnblogs.com/Darwin2000/p/5786984.htmlhttps://ai.tencent.com/ailab/nlp/embedding.htmlhttps://blog.csdn.net/xiezj007/article/details/85073890https://github.com/Embedding/Chinese-Word-Vectorshttps://github.com/brightmart/nlp_chinese_corpushttps://github.com/codemayq/chinese_chatbot_corpushttps://github.com/candlewill/Dialog_Corpus1.ä½¿ç”¨åœºæ™¯ ï¼ˆç™¾åº¦å…¬å¼€è¯¾ï¼‰ç¬¬ä¸€éƒ¨åˆ† å…¥é—¨ä»‹ç»1.) è‡ªç„¶è¯­è¨€å¤„ç†å…¥é—¨ä»‹ç»ç¬¬äºŒéƒ¨åˆ† æœºå™¨ç¿»è¯‘2.) æœºå™¨ç¿»è¯‘ç¬¬ä¸‰éƒ¨åˆ† ç¯‡ç« åˆ†æ3.1.) ç¯‡ç« åˆ†æ-å†…å®¹æ¦‚è¿°3.2.) ç¯‡ç« åˆ†æ-å†…å®¹æ ‡ç­¾3.3.) ç¯‡ç« åˆ†æ-æƒ…æ„Ÿåˆ†æ3.4.) ç¯‡ç« åˆ†æ-è‡ªåŠ¨æ‘˜è¦ç¬¬å››éƒ¨åˆ† UNIT-è¯­è¨€ç†è§£ä¸äº¤äº’æŠ€æœ¯4.) UNIT-è¯­è¨€ç†è§£ä¸äº¤äº’æŠ€æœ¯åº”ç”¨é¢†åŸŸä¸­æ–‡åˆ†è¯:æ„å»ºDAGå›¾åŠ¨æ€è§„åˆ’æŸ¥æ‰¾ï¼Œç»¼åˆæ­£åå‘ï¼ˆæ­£å‘åŠ æƒåå‘è¾“å‡ºï¼‰æ±‚å¾—DAGæœ€å¤§æ¦‚ç‡è·¯å¾„ä½¿ç”¨äº†SBMEè¯­æ–™è®­ç»ƒäº†ä¸€å¥— HMM + Viterbi æ¨¡å‹ï¼Œè§£å†³æœªç™»å½•è¯é—®é¢˜1.æ–‡æœ¬åˆ†ç±»ï¼ˆText Classificationï¼‰æ–‡æœ¬åˆ†ç±»æ˜¯æŒ‡æ ‡è®°å¥å­æˆ–æ–‡æ¡£ï¼Œä¾‹å¦‚ç”µå­é‚®ä»¶åƒåœ¾é‚®ä»¶åˆ†ç±»å’Œæƒ…æ„Ÿåˆ†æã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…æ–‡æœ¬åˆ†ç±»æ•°æ®é›†ã€‚è·¯é€ç¤¾Newswireä¸»é¢˜åˆ†ç±»ï¼ˆè·¯é€ç¤¾-21578ï¼‰ã€‚1987å¹´è·¯é€ç¤¾å‡ºç°çš„ä¸€ç³»åˆ—æ–°é—»æ–‡ä»¶ï¼ŒæŒ‰ç±»åˆ«ç¼–åˆ¶ç´¢å¼•ã€‚å¦è§RCV1ï¼ŒRCV2å’ŒTRC2ã€‚IMDBç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ç±»ï¼ˆæ–¯å¦ç¦ï¼‰ã€‚æ¥è‡ªç½‘ç«™imdb.comçš„ä¸€ç³»åˆ—ç”µå½±è¯„è®ºåŠå…¶ç§¯ææˆ–æ¶ˆæçš„æƒ…ç»ªã€‚æ–°é—»ç»„ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ç±»ï¼ˆåº·å¥ˆå°”ï¼‰ã€‚æ¥è‡ªç½‘ç«™imdb.comçš„ä¸€ç³»åˆ—ç”µå½±è¯„è®ºåŠå…¶ç§¯ææˆ–æ¶ˆæçš„æƒ…ç»ªã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…å¸–å­:å•æ ‡ç­¾æ–‡æœ¬åˆ†ç±»çš„æ•°æ®é›†ã€‚æƒ…æ„Ÿåˆ†ææ¯”èµ›åœ°å€: https://www.kaggle.com/c/word2vec-nlp-tutorialæ–¹æ¡ˆä¸€(0.86): WordCount + æœ´ç´  Bayesæ–¹æ¡ˆäºŒ(0.94): LDA + åˆ†ç±»æ¨¡å‹ï¼ˆknn/å†³ç­–æ ‘/é€»è¾‘å›å½’/svm/xgboost/éšæœºæ£®æ—ï¼‰a) å†³ç­–æ ‘æ•ˆæœä¸æ˜¯å¾ˆå¥½ï¼Œè¿™ç§è¿ç»­ç‰¹å¾ä¸å¤ªé€‚åˆçš„b) é€šè¿‡å‚æ•°è°ƒæ•´ 200 ä¸ªtopicï¼Œä¿¡æ¯é‡ä¿å­˜æ•ˆæœè¾ƒä¼˜ï¼ˆè®¡ç®—ä¸»é¢˜ï¼‰æ–¹æ¡ˆä¸‰(0.72): word2vec + CNNè¯´å®è¯: æ²¡æœ‰ä¸€ä¸ªå¥½çš„æœºå™¨ï¼Œæ˜¯è°ƒä¸å‡ºæ¥ä¸€ä¸ªå¥½çš„ç»“æœ (: é€ƒé€šè¿‡AUC æ¥è¯„ä¼°æ¨¡å‹çš„æ•ˆæœ2.è¯­è¨€æ¨¡å‹ï¼ˆLanguage Modelingï¼‰è¯­è¨€å»ºæ¨¡æ¶‰åŠå¼€å‘ä¸€ç§ç»Ÿè®¡æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹å¥å­ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯æˆ–ä¸€ä¸ªå•è¯ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚å®ƒæ˜¯è¯­éŸ³è¯†åˆ«å’Œæœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ä¸­çš„å‰ç½®ä»»åŠ¡ã€‚å®ƒæ˜¯è¯­éŸ³è¯†åˆ«å’Œæœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ä¸­çš„å‰ç½®ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…è¯­è¨€å»ºæ¨¡æ•°æ®é›†ã€‚å¤è…¾å ¡é¡¹ç›®ï¼Œä¸€ç³»åˆ—å…è´¹ä¹¦ç±ï¼Œå¯ä»¥ç”¨çº¯æ–‡æœ¬æ£€ç´¢å„ç§è¯­è¨€ã€‚è¿˜æœ‰æ›´å¤šæ­£å¼çš„è¯­æ–™åº“å¾—åˆ°äº†å¾ˆå¥½çš„ç ”ç©¶; ä¾‹å¦‚:å¸ƒæœ—å¤§å­¦ç°ä»£ç¾å›½è‹±è¯­æ ‡å‡†è¯­æ–™åº“ã€‚å¤§é‡è‹±è¯­å•è¯æ ·æœ¬ã€‚è°·æ­Œ10äº¿å­—è¯­æ–™åº“ã€‚æ–°è¯å‘ç°ä¸­æ–‡åˆ†è¯æ–°è¯å‘ç°python3åˆ©ç”¨äº’ä¿¡æ¯å’Œå·¦å³ä¿¡æ¯ç†µçš„ä¸­æ–‡åˆ†è¯æ–°è¯å‘ç°https://github.com/zhanzecheng/Chinese_segment_augmentå¥å­ç›¸ä¼¼åº¦è¯†åˆ«é¡¹ç›®åœ°å€: https://www.kaggle.com/c/quora-question-pairsè§£å†³æ–¹æ¡ˆ: word2vec + Bi-GRUæ–‡æœ¬çº é”™bi-gram + levenshtein3.å›¾åƒå­—å¹•ï¼ˆImage Captioningï¼‰mageå­—å¹•æ˜¯ä¸ºç»™å®šå›¾åƒç”Ÿæˆæ–‡æœ¬æè¿°çš„ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…å›¾åƒå­—å¹•æ•°æ®é›†ã€‚ä¸Šä¸‹æ–‡ä¸­çš„å…¬å…±å¯¹è±¡ï¼ˆCOCOï¼‰ã€‚åŒ…å«è¶…è¿‡12ä¸‡å¼ å¸¦æè¿°çš„å›¾åƒçš„é›†åˆFlickr 8Kã€‚ä»flickr.comè·å–çš„8åƒä¸ªæè¿°å›¾åƒçš„é›†åˆã€‚Flickr 30Kã€‚ä»flickr.comè·å–çš„3ä¸‡ä¸ªæè¿°å›¾åƒçš„é›†åˆã€‚æ¬²äº†è§£æ›´å¤šï¼Œè¯·çœ‹å¸–å­:æ¢ç´¢å›¾åƒå­—å¹•æ•°æ®é›†ï¼Œ2016å¹´4.æœºå™¨ç¿»è¯‘ï¼ˆMachine Translationï¼‰æœºå™¨ç¿»è¯‘æ˜¯å°†æ–‡æœ¬ä»ä¸€ç§è¯­è¨€ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€çš„ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…æœºå™¨ç¿»è¯‘æ•°æ®é›†ã€‚åŠ æ‹¿å¤§ç¬¬36å±Šè®®ä¼šçš„åè°ƒå›½ä¼šè®®å‘˜ã€‚æˆå¯¹çš„è‹±è¯­å’Œæ³•è¯­å¥å­ã€‚æ¬§æ´²è®®ä¼šè¯‰è®¼å¹³è¡Œè¯­æ–™åº“1996-2011ã€‚å¥å­å¯¹ä¸€å¥—æ¬§æ´²è¯­è¨€ã€‚æœ‰å¤§é‡æ ‡å‡†æ•°æ®é›†ç”¨äºå¹´åº¦æœºå™¨ç¿»è¯‘æŒ‘æˆ˜; çœ‹åˆ°:ç»Ÿè®¡æœºå™¨ç¿»è¯‘æœºå™¨ç¿»è¯‘Encoder + Decoder(Attention)å‚è€ƒæ¡ˆä¾‹: http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html5.é—®ç­”ç³»ç»Ÿï¼ˆQuestion Answeringï¼‰é—®ç­”æ˜¯ä¸€é¡¹ä»»åŠ¡ï¼Œå…¶ä¸­æä¾›äº†ä¸€ä¸ªå¥å­æˆ–æ–‡æœ¬æ ·æœ¬ï¼Œä»ä¸­æå‡ºé—®é¢˜å¹¶ä¸”å¿…é¡»å›ç­”é—®é¢˜ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…é—®é¢˜å›ç­”æ•°æ®é›†ã€‚æ–¯å¦ç¦é—®é¢˜å›ç­”æ•°æ®é›†ï¼ˆSQuADï¼‰ã€‚å›ç­”æœ‰å…³ç»´åŸºç™¾ç§‘æ–‡ç« çš„é—®é¢˜ã€‚Deepmindé—®é¢˜å›ç­”è¯­æ–™åº“ã€‚ä»æ¯æ—¥é‚®æŠ¥å›ç­”æœ‰å…³æ–°é—»æ–‡ç« çš„é—®é¢˜ã€‚äºšé©¬é€Šé—®ç­”æ•°æ®ã€‚å›ç­”æœ‰å…³äºšé©¬é€Šäº§å“çš„é—®é¢˜ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…å¸–å­:æ•°æ®é›†: æˆ‘å¦‚ä½•è·å¾—é—®ç­”ç½‘ç«™çš„è¯­æ–™åº“ï¼Œå¦‚Quoraæˆ–Yahoo Answersæˆ–Stack Overflowæ¥åˆ†æç­”æ¡ˆè´¨é‡ï¼Ÿ6.è¯­éŸ³è¯†åˆ«ï¼ˆSpeech Recognitionï¼‰è¯­éŸ³è¯†åˆ«æ˜¯å°†å£è¯­çš„éŸ³é¢‘è½¬æ¢ä¸ºäººç±»å¯è¯»æ–‡æœ¬çš„ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…è¯­éŸ³è¯†åˆ«æ•°æ®é›†ã€‚TIMITå£°å­¦ - è¯­éŸ³è¿ç»­è¯­éŸ³è¯­æ–™åº“ã€‚ä¸æ˜¯å…è´¹çš„ï¼Œä½†å› å…¶å¹¿æ³›ä½¿ç”¨è€Œä¸Šå¸‚ã€‚å£è¯­ç¾å›½è‹±è¯­å’Œç›¸å…³çš„è½¬å½•ã€‚VoxForgeã€‚ç”¨äºæ„å»ºç”¨äºè¯­éŸ³è¯†åˆ«çš„å¼€æºæ•°æ®åº“çš„é¡¹ç›®ã€‚LibriSpeech ASRè¯­æ–™åº“ã€‚ä»LibriVoxæ”¶é›†çš„å¤§é‡è‹±è¯­æœ‰å£°è¯»ç‰©ã€‚7.è‡ªåŠ¨æ–‡æ‘˜ï¼ˆDocument Summarizationï¼‰æ–‡æ¡£æ‘˜è¦æ˜¯åˆ›å»ºè¾ƒå¤§æ–‡æ¡£çš„ç®€çŸ­æœ‰æ„ä¹‰æè¿°çš„ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…æ–‡æ¡£æ‘˜è¦æ•°æ®é›†ã€‚æ³•å¾‹æ¡ˆä¾‹æŠ¥å‘Šæ•°æ®é›†ã€‚æ”¶é›†äº†4000ä»½æ³•å¾‹æ¡ˆä»¶åŠå…¶æ‘˜è¦ã€‚TIPSTERæ–‡æœ¬æ‘˜è¦è¯„ä¼°ä¼šè®®è¯­æ–™åº“ã€‚æ”¶é›†äº†è¿‘200ä»½æ–‡ä»¶åŠå…¶æ‘˜è¦ã€‚è‹±è¯­æ–°é—»æ–‡æœ¬çš„AQUAINTè¯­æ–™åº“ã€‚ä¸æ˜¯å…è´¹çš„ï¼Œè€Œæ˜¯å¹¿æ³›ä½¿ç”¨çš„ã€‚æ–°é—»æ–‡ç« çš„è¯­æ–™åº“ã€‚æ¬²äº†è§£æ›´å¤šä¿¡æ¯:æ–‡æ¡£ç†è§£ä¼šè®®ï¼ˆDUCï¼‰ä»»åŠ¡ã€‚åœ¨å“ªé‡Œå¯ä»¥æ‰¾åˆ°ç”¨äºæ–‡æœ¬æ‘˜è¦çš„è‰¯å¥½æ•°æ®é›†ï¼Ÿå‘½åå®ä½“è¯†åˆ«Bi-LSTM CRFå‚è€ƒæ¡ˆä¾‹: http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.htmlCRFæ¨èæ–‡æ¡£: https://www.jianshu.com/p/55755fc649b1æ–‡æœ¬æ‘˜è¦æŠ½å–å¼word2vec + textrankword2vecæ¨èæ–‡æ¡£: https://www.zhihu.com/question/44832436/answer/266068967textrankæ¨èæ–‡æ¡£: https://blog.csdn.net/BaiHuaXiu123/article/details/77847232Graphå›¾è®¡ç®—ã€æ…¢æ…¢æ›´æ–°ã€‘æ•°æ®é›†: https://github.com/apachecn/data/tree/master/graphå­¦ä¹ èµ„æ–™: spark graphXå®æˆ˜.pdf ã€æ–‡ä»¶å¤ªå¤§ä¸æ–¹ä¾¿æä¾›ï¼Œè‡ªå·±ç™¾åº¦ã€‘çŸ¥è¯†å›¾è°±çŸ¥è¯†å›¾è°±ï¼Œæˆ‘åªè®¤ SimmerChan: ã€çŸ¥è¯†å›¾è°±-ç»™AIè£…ä¸ªå¤§è„‘ã€‘è¯´å®è¯ï¼Œæˆ‘æ˜¯çœ‹è¿™åšä¸»è€å“¥å†™çš„åšå®¢é•¿å¤§çš„ï¼Œå†™çš„çœŸçš„æ˜¯æ·±å…¥æµ…å‡ºã€‚æˆ‘å¾ˆå–œæ¬¢ï¼Œæ‰€ä»¥å°±åˆ†äº«ç»™å¤§å®¶ï¼Œå¸Œæœ›ä½ ä»¬ä¹Ÿå–œæ¬¢ã€‚è¿›ä¸€æ­¥é˜…è¯»å¦‚æœæ‚¨å¸Œæœ›æ›´æ·±å…¥ï¼Œæœ¬èŠ‚æä¾›äº†å…¶ä»–æ•°æ®é›†åˆ—è¡¨ã€‚ç»´åŸºç™¾ç§‘ç ”ç©¶ä¸­ä½¿ç”¨çš„æ–‡æœ¬æ•°æ®é›†æ•°æ®é›†: è®¡ç®—è¯­è¨€å­¦å®¶å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶äººå‘˜ä½¿ç”¨çš„ä¸»è¦æ–‡æœ¬è¯­æ–™åº“æ˜¯ä»€ä¹ˆï¼Ÿæ–¯å¦ç¦ç»Ÿè®¡è‡ªç„¶è¯­è¨€å¤„ç†è¯­æ–™åº“æŒ‰å­—æ¯é¡ºåºæ’åˆ—çš„NLPæ•°æ®é›†åˆ—è¡¨è¯¥æœºæ„NLTKåœ¨DL4Jä¸Šæ‰“å¼€æ·±åº¦å­¦ä¹ æ•°æ®NLPæ•°æ®é›†å›½å†…å¼€æ”¾æ•°æ®é›†: https://bosonnlp.com/dev/resourceå‚è€ƒæ¯”èµ›æ”¶é›†å¹³å°pbharrin/machinelearninginactionML Masteryè‡´è°¢æœ€è¿‘æ— æ„æ”¶åˆ°ç¾¤å‹æ¨é€çš„é“¾æ¥ï¼Œå‘ç°å¾—åˆ°å¤§ä½¬é«˜åº¦çš„è®¤å¯ï¼Œå¹¶åœ¨çƒ­å¿ƒçš„æ¨å¹¿ã€‚åœ¨æ­¤æ„Ÿè°¢:é‡å­ä½äººå·¥æ™ºèƒ½å‰æ²¿è®²ä¹ èµåŠ©æˆ‘ä»¬"
6,hankcs/HanLP,https://github.com/hankcs/HanLP/blob/master/README.md,Python,"HanLP: Han Language Processing                                                                                   ä¸­æ–‡ |    æ—¥æœ¬èª |    Docs |    ForumThe multilingual NLP library for researchers and companies, built on PyTorch and TensorFlow 2.x, for advancingstate-of-the-art deep learning techniques in both academia and industry. HanLP was designed from day one to beefficient, user-friendly and extendable.Thanks to open-access corpora like Universal Dependencies and OntoNotes, HanLP 2.1 now offers 10 joint tasks on 130languages: tokenization, lemmatization, part-of-speech tagging, token feature extraction, dependency parsing,constituency parsing, semantic role labeling, semantic dependency parsing, abstract meaning representation (AMR)parsing.For end users, HanLP offers light-weighted RESTful APIs and native Python APIs.RESTful APIsTiny packages in several KBs for agile development and mobile applications. Although anonymous users are welcomed, anauth key is suggestedand a free one can be applied here underthe CC BY-NC-SA 4.0 license.  Click to expand tutorials for RESTful APIsPythonpip install hanlp_restfulCreate a client with our API endpoint and your auth.from hanlp_restful import HanLPClientHanLP = HanLPClient('https://hanlp.hankcs.com/api', auth=None, language='mul') # mul: multilingual, zh: ChineseJavaInsert the following dependency into your pom.xml.<dependency>  <groupId>com.hankcs.hanlp.restful</groupId>  <artifactId>hanlp-restful</artifactId>  <version>0.0.15</version></dependency>Create a client with our API endpoint and your auth.HanLPClient HanLP = new HanLPClient(\""https://hanlp.hankcs.com/api\"", null, \""mul\""); // mul: multilingual, zh: ChineseQuick StartNo matter which language you use, the same interface can be used to parse a document.HanLP.parse(    \""In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments. 2021å¹´ã€HanLPv2.1ã¯æ¬¡ä¸–ä»£ã®æœ€å…ˆç«¯å¤šè¨€èªNLPæŠ€è¡“ã‚’æœ¬ç•ªç’°å¢ƒã«å°å…¥ã—ã¾ã™ã€‚2021å¹´ HanLPv2.1ä¸ºç”Ÿäº§ç¯å¢ƒå¸¦æ¥æ¬¡ä¸–ä»£æœ€å…ˆè¿›çš„å¤šè¯­ç§NLPæŠ€æœ¯ã€‚\"")See docs for visualization, annotation guidelines and more details.Native APIspip install hanlpHanLP requires Python 3.6 or later. GPU/TPU is suggested but not mandatory.Quick Startimport hanlpHanLP = hanlp.load(hanlp.pretrained.mtl.UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_XLMR_BASE)print(HanLP(['In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments.',             '2021å¹´ã€HanLPv2.1ã¯æ¬¡ä¸–ä»£ã®æœ€å…ˆç«¯å¤šè¨€èªNLPæŠ€è¡“ã‚’æœ¬ç•ªç’°å¢ƒã«å°å…¥ã—ã¾ã™ã€‚',             '2021å¹´ HanLPv2.1ä¸ºç”Ÿäº§ç¯å¢ƒå¸¦æ¥æ¬¡ä¸–ä»£æœ€å…ˆè¿›çš„å¤šè¯­ç§NLPæŠ€æœ¯ã€‚']))In particular, the Python HanLPClient can also be used as a callable function following the same semantics.See docs for visualization, annotation guidelines and more details.To process Chinese or Japanese, HanLP provides mono-lingual models in each language which significantly outperform themulti-lingual model. See docs for the list of models.Train Your Own ModelsTo write DL models is not hard, the real hard thing is to write a model able to reproduce the scores in papers. Thesnippet below shows how to surpass the state-of-the-art tokenizer in 6 minutes.tokenizer = TransformerTaggingTokenizer()save_dir = 'data/model/cws/sighan2005_pku_bert_base_96.7'tokenizer.fit(    SIGHAN2005_PKU_TRAIN_ALL,    SIGHAN2005_PKU_TEST,  # Conventionally, no devset is used. See Tian et al. (2020).    save_dir,    'bert-base-chinese',    max_seq_len=300,    char_level=True,    hard_constraint=True,    sampler_builder=SortingSamplerBuilder(batch_size=32),    epochs=3,    adam_epsilon=1e-6,    warmup_steps=0.1,    weight_decay=0.01,    word_dropout=0.1,    seed=1660853059,)tokenizer.evaluate(SIGHAN2005_PKU_TEST, save_dir)The result is guaranteed to be 96.73 as the random seed is fixed. Different from some overclaiming papers andprojects, HanLP promises every single digit in our scores is reproducible. Any issues on reproducibility will be treatedand solved as a top-priority fatal bug.PerformanceThe performance of multi-task learning models is shown in the following table.langcorporamodeltokposnerdepconsrlsdplemfeaamrfinecoarsectbpku863udpkumsraontonotesSemEval16DMPASPSDmulUD2.7OntoNotes5small98.62----93.23--74.4279.1076.8570.63-91.1993.6785.3487.7184.51-base98.97----90.32--80.3278.7471.2373.63-92.6096.0481.1985.0882.13-zhopensmall97.25-96.66-----95.0084.5787.6273.4084.57------base97.50-97.07-----96.0487.1189.8477.7887.11------closesmall96.7095.9396.8797.5695.05-96.2295.7476.7984.4488.1375.8174.28------base97.5296.4496.9997.5995.29-96.4895.7277.7785.2988.5776.5273.76------ernie96.9597.2996.7697.6495.22-97.3196.4777.9585.6789.1778.5174.10------Multi-task learning models often under-perform their single-task learning counterparts according to our latestresearch. Similarly, mono-lingual models often outperform multi-lingual models. Therefore, we strongly recommend theuse of a single-task mono-lingual model if you aretargeting at high accuracy instead of faster speed.A state-of-the-art AMR model has been released.CitingIf you use HanLP in your research, please cite this repository.@inproceedings{he-choi-2021-stem,    title = \""The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders\"",    author = \""He, Han and Choi, Jinho D.\"",    booktitle = \""Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\"",    month = nov,    year = \""2021\"",    address = \""Online and Punta Cana, Dominican Republic\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://aclanthology.org/2021.emnlp-main.451\"",    pages = \""5555--5577\"",    abstract = \""Multi-task learning with transformer encoders (MTL) has emerged as a powerful technique to improve performance on closely-related tasks for both accuracy and efficiency while a question still remains whether or not it would perform as well on tasks that are distinct in nature. We first present MTL results on five NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over single-task learning. We then conduct an extensive pruning analysis to show that a certain set of attention heads get claimed by most tasks during MTL, who interfere with one another to fine-tune those heads for their own objectives. Based on this finding, we propose the Stem Cell Hypothesis to reveal the existence of attention heads naturally talented for many tasks that cannot be jointly trained to create adequate embeddings for all of those tasks. Finally, we design novel parameter-free probes to justify our hypothesis and demonstrate how attention heads are transformed across the five tasks during MTL through label analysis.\"",}LicenseCodesHanLP is licensed under Apache License 2.0. You can use HanLP in your commercial products for free. We wouldappreciate it if you add a link to HanLP on your website.ModelsUnless otherwise specified, all models in HanLP are licensedunder  CC BY-NC-SA 4.0.Referenceshttps://hanlp.hankcs.com/docs/references.html"
7,vagabond-systems/jpmc-task-1,https://github.com/vagabond-systems/jpmc-task-1/blob/main/README.md,Python,JPMC Task 1Starter repo for task 1 of the JPMC software engineering program
8,langchain-ai/langchain,https://github.com/langchain-ai/langchain/blob/master/README.md,Python,"ğŸ¦œï¸ğŸ”— LangChainâš¡ Building applications with LLMs through composability âš¡Looking for the JS/TS version? Check out LangChain.js.Production Support: As you move your LangChains into production, we'd love to offer more hands-on support.Fill out this form to share more about what you're building, and our team will get in touch.ğŸš¨Breaking Changes for select chains (SQLDatabase) on 7/28/23In an effort to make langchain leaner and safer, we are moving select chains to langchain_experimental.This migration has already started, but we are remaining backwards compatible until 7/28.On that date, we will remove functionality from langchain.Read more about the motivation and the progress here.Read how to migrate your code here.Quick Installpip install langchainorpip install langsmith && conda install langchain -c conda-forgeğŸ¤” What is this?Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. However, using these LLMs in isolation is often insufficient for creating a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.This library aims to assist in the development of those types of applications. Common examples of these applications include:â“ Question Answering over specific documentsDocumentationEnd-to-end Example: Question Answering over Notion DatabaseğŸ’¬ ChatbotsDocumentationEnd-to-end Example: Chat-LangChainğŸ¤– AgentsDocumentationEnd-to-end Example: GPT+WolframAlphağŸ“– DocumentationPlease see here for full documentation on:Getting started (installation, setting up the environment, simple examples)How-To examples (demos, integrations, helper functions)Reference (full API docs)Resources (high-level explanation of core concepts)ğŸš€ What can this help with?There are six main areas that LangChain is designed to help with.These are, in increasing order of complexity:ğŸ“ƒ LLMs and Prompts:This includes prompt management, prompt optimization, a generic interface for all LLMs, and common utilities for working with LLMs.ğŸ”— Chains:Chains go beyond a single LLM call and involve sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.ğŸ“š Data Augmented Generation:Data Augmented Generation involves specific types of chains that first interact with an external data source to fetch data for use in the generation step. Examples include summarization of long pieces of text and question/answering over specific data sources.ğŸ¤– Agents:Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end-to-end agents.ğŸ§  Memory:Memory refers to persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.ğŸ§ Evaluation:[BETA] Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this.For more information on these concepts, please see our full documentation.ğŸ’ ContributingAs an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.For detailed information on how to contribute, see here."
9,XX-net/XX-Net,https://github.com/XX-net/XX-Net/blob/master/README.md,Python,"ğŸš€ XX-Net (ç¿»å¢™VPN)è¿™æ˜¯ä¸€ä¸ªå¯é çš„ç¿»å¢™ç³»ç»Ÿï¼Œå·²ç»è¿ç»­è¿è¡Œ 8 å¹´ï¼æˆ‘ä»¬ä¸å»ç ”ç©¶å¢™æœ‰ä»€ä¹ˆç¼ºé™·ï¼Œå› ä¸ºæ‰€æœ‰çš„ç¼ºé™·éƒ½ä¼šè¢«æ…¢æ…¢çš„è¡¥ä¸Šã€‚æˆ‘ä»¬çš„ç­–ç•¥æ˜¯åŒ–èº«ä¸ºæ™®é€šæµé‡ï¼Œå®Œå…¨æ— æ³•åŒºåˆ†ï¼Œæœ€ç»ˆéšèº«åœ¨èŒ«èŒ«çš„ç½‘ç»œè¿æ¥ä¸­ã€‚ã€‚ã€‚ğŸ”Œ åŠŸèƒ½ç‰¹æ€§æ”¯æŒå¤šå¹³å°ï¼š Android/iOS/Windows/Mac/Linuxé‡‡ç”¨ç‹¬ç‰¹çš„æ··æ·†ç®—æ³•ï¼Œè®©æ‚¨çš„æµé‡åœ¨ç½‘ç»œä¸­æ— æ³•è¢«è¯†åˆ«å¼€æºç»¿è‰²è½¯ä»¶ï¼Œæ— éœ€å®‰è£…ï¼Œå¯ä»¥æ”¯æŒå¤šå°è®¾å¤‡åŒæ—¶è¿æ¥æ¨¡æ‹ŸChromeæµè§ˆå™¨è¡Œä¸ºï¼Œå®Œå…¨æ— æ³•è¯†åˆ«ï¼Œç¨³å®šç¿»å¢™å†…ç½® ChatGPTï¼Œæ¯ä¸ªå¥—é¤èµ é€ ChatGPT-3.5 ä¸€ç™¾ä¸‡tokenå®˜ç½‘ä¸‹è½½: https://xx-net.comTelegram: https://t.me/xxnetshareTwitter: https://twitter.com/XXNetDevä¸­æ–‡å¸®åŠ©æ–‡æ¡£ Â  Â  Â English Document Â  Â  Â ÙØ§Ø±Ø³ÛŒ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒæœ€æ–°å…¬å‘Šï¼š2023-08-15æ–°ç‰ˆ 5.5.0, æå‡è¿æ¥æ€§èƒ½5.1.0ï¼Œå†…ç½®ChatGPTåŸæ¥æ˜¯4.x.x è€ç‰ˆæœ¬çš„ï¼Œéœ€è¦é‡æ–°ä¸‹è½½æ–°ç‰ˆå®‰è£…ï¼Œä¸èƒ½åº”ç”¨å†…å‡çº§ã€‚æç¤ºï¼šæœ‰é—®é¢˜è¯·å…ˆçœ‹Wikiæ–‡æ¡£æé—® å‰ï¼Œè¯·å…ˆçœ‹æœ€è¿‘è®¨è®ºä¸»é¢˜ ï¼Œé¿å…é‡å¤å‘é—®ã€‚"
10,jackfrued/Python-100-Days,https://github.com/jackfrued/Python-100-Days/blob/master/README.md,Python,"Python - 100å¤©ä»æ–°æ‰‹åˆ°å¤§å¸ˆä½œè€…ï¼šéª†æ˜Šè¯´æ˜ï¼šä»é¡¹ç›®ä¸Šçº¿åˆ°è·å¾—8w+æ˜Ÿæ ‡ä»¥æ¥ï¼Œä¸€ç›´æ”¶åˆ°åé¦ˆè¯´åŸºç¡€éƒ¨åˆ†ï¼ˆå‰15å¤©çš„å†…å®¹ï¼‰å¯¹æ–°æ‰‹æ¥è¯´æ˜¯æ¯”è¾ƒå›°éš¾çš„ï¼Œå»ºè®®æœ‰é…å¥—è§†é¢‘è¿›è¡Œè®²è§£ã€‚æœ€è¿‘æŠŠåŸºç¡€éƒ¨åˆ†çš„å†…å®¹é‡æ–°åˆ¶ä½œäº†ä¸€ä¸ªåä¸ºâ€œPython-Core-50-Coursesâ€çš„é¡¹ç›®ï¼Œç”¨æ›´ä¸ºç®€å•é€šä¿—çš„æ–¹å¼é‡å†™äº†è¿™éƒ¨åˆ†å†…å®¹å¹¶é™„å¸¦äº†è§†é¢‘è®²è§£ï¼Œåˆå­¦è€…å¯ä»¥å…³æ³¨ä¸‹è¿™ä¸ªæ–°é¡¹ç›®ã€‚å¦‚æœéœ€è¦PythonåŸºç¡€è§†é¢‘ï¼Œå¯ä»¥åœ¨â€œBç«™â€æœç´¢ã€ŠPythoné›¶åŸºç¡€å¿«é€Ÿä¸Šæ‰‹ã€‹ï¼Œè¿™å¥—è§†é¢‘æ˜¯æˆ‘è®²è¯¾çš„æ—¶å€™å½•åˆ¶çš„éšå ‚è§†é¢‘ï¼Œç”»è´¨å°šå¯ã€éŸ³è´¨ä¸€èˆ¬ï¼Œä½†æ˜¯å¯¹åˆå­¦è€…åº”è¯¥ä¼šæœ‰äº›å¸®åŠ©ï¼Œæ¬¢è¿å¤§å®¶ç•™è¨€ã€è¯„è®ºã€å‘å¼¹å¹•ã€‚å­¦ä¹ ä¹‹åè§‰å¾—æœ‰æ”¶è·çš„å°ä¼™ä¼´å¯ä»¥â€œä¸€é”®ä¸‰è¿â€æ¥æ”¯æŒUPä¸»ï¼ˆåƒé”‹Pythonï¼‰ã€‚å›½å†…ç”¨æˆ·å¦‚æœè®¿é—®GitHubæ¯”è¾ƒæ…¢çš„è¯ï¼Œå¯ä»¥å…³æ³¨æˆ‘çš„çŸ¥ä¹å·Python-Jackï¼Œä¸Šé¢çš„â€œä»é›¶å¼€å§‹å­¦Pythonâ€ä¸“æ æ¯”è¾ƒé€‚åˆåˆå­¦è€…ï¼Œå…¶ä»–çš„ä¸“æ ä¹Ÿåœ¨æŒç»­åˆ›ä½œå’Œæ›´æ–°ä¸­ï¼Œæ¬¢è¿å¤§å®¶å…³æ³¨å¹¶ç‚¹èµè¯„è®ºã€‚åˆ›ä½œä¸æ˜“ï¼Œæ„Ÿè°¢å¤§å®¶çš„æ‰“èµæ”¯æŒï¼Œè¿™äº›é’±ä¸ä¼šç”¨äºä¸ªäººæ¶ˆè´¹ï¼ˆä¾‹å¦‚ï¼šè´­ä¹°å’–å•¡ï¼‰ï¼Œè€Œæ˜¯é€šè¿‡è…¾è®¯å…¬ç›Šã€ç¾å›¢å…¬ç›Šã€æ°´æ»´ç­¹ç­‰å¹³å°æèµ ç»™éœ€è¦å¸®åŠ©çš„äººï¼ˆç‚¹å‡»äº†è§£æèµ æƒ…å†µï¼‰ã€‚éœ€è¦åŠ å…¥QQå­¦ä¹ ç¾¤çš„å¯ä»¥æ‰«æä¸‹é¢çš„äºŒç»´ç ï¼Œä¸‰ä¸ªç¾¤åŠ ä¸€ä¸ªå³å¯ï¼Œä¸è¦é‡å¤è¿›ç¾¤ã€‚å­¦ä¹ ç¾¤ä¼šä¸ºå¤§å®¶æä¾›å­¦ä¹ èµ„æºå’Œé—®é¢˜è§£ç­”ï¼Œå¦‚æœæœ‰Pythonä½“éªŒè¯¾å’Œè¡Œä¸šå…¬å¼€è¯¾ä¼šæå‰åœ¨ç¾¤é‡Œé€šçŸ¥å¤§å®¶ï¼Œæ¬¢è¿å¤§å®¶åŠ å…¥ã€‚é¡¹ç›®â€œDay80~90â€éƒ¨åˆ†ç›®å‰ä»åœ¨åˆ›ä½œä¸­ï¼Œå› ä¸ºä½œè€…å¹³æ—¶ä¹ŸæŒ¤ä¸å‡ºå¤ªå¤šæ—¶é—´æ¥å†™æ–‡æ¡£ï¼Œå› æ­¤æ›´æ–°çš„é€Ÿåº¦æ¯”è¾ƒç¼“æ…¢ï¼Œæ„Ÿè°¢å¤§å®¶çš„ç†è§£ã€‚Pythonåº”ç”¨é¢†åŸŸå’ŒèŒä¸šå‘å±•åˆ†æç®€å•çš„è¯´ï¼ŒPythonæ˜¯ä¸€ä¸ªâ€œä¼˜é›…â€ã€â€œæ˜ç¡®â€ã€â€œç®€å•â€çš„ç¼–ç¨‹è¯­è¨€ã€‚å­¦ä¹ æ›²çº¿ä½ï¼Œéä¸“ä¸šäººå£«ä¹Ÿèƒ½ä¸Šæ‰‹å¼€æºç³»ç»Ÿï¼Œæ‹¥æœ‰å¼ºå¤§çš„ç”Ÿæ€åœˆè§£é‡Šå‹è¯­è¨€ï¼Œå®Œç¾çš„å¹³å°å¯ç§»æ¤æ€§åŠ¨æ€ç±»å‹è¯­è¨€ï¼Œæ”¯æŒé¢å‘å¯¹è±¡å’Œå‡½æ•°å¼ç¼–ç¨‹ä»£ç è§„èŒƒç¨‹åº¦é«˜ï¼Œå¯è¯»æ€§å¼ºPythonåœ¨ä»¥ä¸‹é¢†åŸŸéƒ½æœ‰ç”¨æ­¦ä¹‹åœ°ã€‚åç«¯å¼€å‘ - Python / Java / Go / PHPDevOps - Python / Shell / Rubyæ•°æ®é‡‡é›† - Python / C++ / Javaé‡åŒ–äº¤æ˜“ - Python / C++ / Ræ•°æ®ç§‘å­¦ - Python / R / Julia / Matlabæœºå™¨å­¦ä¹  - Python / R / C++ / Juliaè‡ªåŠ¨åŒ–æµ‹è¯• - Python / Shellä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œæ ¹æ®ä¸ªäººçš„å–œå¥½å’ŒèŒä¸šè§„åˆ’ï¼Œå¯ä»¥é€‰æ‹©çš„å°±ä¸šé¢†åŸŸä¹Ÿéå¸¸å¤šã€‚Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼ˆæœåŠ¡å™¨ã€äº‘å¹³å°ã€æ•°æ®æ¥å£ï¼‰Pythonè¿ç»´å·¥ç¨‹å¸ˆï¼ˆè‡ªåŠ¨åŒ–è¿ç»´ã€SREã€DevOpsï¼‰Pythonæ•°æ®åˆ†æå¸ˆï¼ˆæ•°æ®åˆ†æã€å•†ä¸šæ™ºèƒ½ã€æ•°å­—åŒ–è¿è¥ï¼‰Pythonæ•°æ®æŒ–æ˜å·¥ç¨‹å¸ˆï¼ˆæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€ç®—æ³•ä¸“å®¶ï¼‰Pythonçˆ¬è™«å·¥ç¨‹å¸ˆPythonæµ‹è¯•å·¥ç¨‹å¸ˆï¼ˆè‡ªåŠ¨åŒ–æµ‹è¯•ã€æµ‹è¯•å¼€å‘ï¼‰è¯´æ˜ï¼šç›®å‰ï¼Œæ•°æ®åˆ†æå’Œæ•°æ®æŒ–æ˜æ˜¯éå¸¸çƒ­é—¨çš„æ–¹å‘ï¼Œå› ä¸ºä¸ç®¡æ˜¯äº’è”ç½‘è¡Œä¸šè¿˜æ˜¯ä¼ ç»Ÿè¡Œä¸šéƒ½å·²ç»ç§¯ç´¯äº†å¤§é‡çš„æ•°æ®ï¼Œå„è¡Œå„ä¸šéƒ½éœ€è¦æ•°æ®åˆ†æå¸ˆä»å·²æœ‰çš„æ•°æ®ä¸­å‘ç°æ›´å¤šçš„å•†ä¸šä»·å€¼ï¼Œä»è€Œä¸ºä¼ä¸šçš„å†³ç­–æä¾›æ•°æ®çš„æ”¯æ’‘ï¼Œè¿™å°±æ˜¯æ‰€è°“çš„æ•°æ®é©±åŠ¨å†³ç­–ã€‚ç»™åˆå­¦è€…çš„å‡ ä¸ªå»ºè®®ï¼šMake English as your working language. ï¼ˆè®©è‹±è¯­æˆä¸ºä½ çš„å·¥ä½œè¯­è¨€ï¼‰Practice makes perfect. ï¼ˆç†Ÿèƒ½ç”Ÿå·§ï¼‰All experience comes from mistakes. ï¼ˆæ‰€æœ‰çš„ç»éªŒéƒ½æºäºä½ çŠ¯è¿‡çš„é”™è¯¯ï¼‰Don't be one of the leeches. ï¼ˆä¸è¦å½“ä¼¸æ‰‹å…šï¼‰Either outstanding or out. ï¼ˆè¦ä¹ˆå‡ºä¼—ï¼Œè¦ä¹ˆå‡ºå±€ï¼‰Day01~15 - Pythonè¯­è¨€åŸºç¡€Day01 - åˆè¯†PythonPythonç®€ä»‹ - Pythonçš„å†å² / Pythonçš„ä¼˜ç¼ºç‚¹ / Pythonçš„åº”ç”¨é¢†åŸŸæ­å»ºç¼–ç¨‹ç¯å¢ƒ - Windowsç¯å¢ƒ / Linuxç¯å¢ƒ / MacOSç¯å¢ƒä»ç»ˆç«¯è¿è¡ŒPythonç¨‹åº - Hello, world / printå‡½æ•° / è¿è¡Œç¨‹åºä½¿ç”¨IDLE - äº¤äº’å¼ç¯å¢ƒ(REPL) / ç¼–å†™å¤šè¡Œä»£ç  / è¿è¡Œç¨‹åº / é€€å‡ºIDLEæ³¨é‡Š - æ³¨é‡Šçš„ä½œç”¨ / å•è¡Œæ³¨é‡Š / å¤šè¡Œæ³¨é‡ŠDay02 - è¯­è¨€å…ƒç´ ç¨‹åºå’Œè¿›åˆ¶ - æŒ‡ä»¤å’Œç¨‹åº / å†¯è¯ºä¾æ›¼æœº / äºŒè¿›åˆ¶å’Œåè¿›åˆ¶ / å…«è¿›åˆ¶å’Œåå…­è¿›åˆ¶å˜é‡å’Œç±»å‹ - å˜é‡çš„å‘½å / å˜é‡çš„ä½¿ç”¨ / inputå‡½æ•° / æ£€æŸ¥å˜é‡ç±»å‹ / ç±»å‹è½¬æ¢æ•°å­—å’Œå­—ç¬¦ä¸² - æ•´æ•° / æµ®ç‚¹æ•° / å¤æ•° / å­—ç¬¦ä¸² / å­—ç¬¦ä¸²åŸºæœ¬æ“ä½œ / å­—ç¬¦ç¼–ç è¿ç®—ç¬¦ - æ•°å­¦è¿ç®—ç¬¦ / èµ‹å€¼è¿ç®—ç¬¦ / æ¯”è¾ƒè¿ç®—ç¬¦ / é€»è¾‘è¿ç®—ç¬¦ / èº«ä»½è¿ç®—ç¬¦ / è¿ç®—ç¬¦çš„ä¼˜å…ˆçº§åº”ç”¨æ¡ˆä¾‹ - åæ°æ¸©åº¦è½¬æ¢æˆæ‘„æ°æ¸©åº¦ / è¾“å…¥åœ†çš„åŠå¾„è®¡ç®—å‘¨é•¿å’Œé¢ç§¯ / è¾“å…¥å¹´ä»½åˆ¤æ–­æ˜¯å¦æ˜¯é—°å¹´Day03 - åˆ†æ”¯ç»“æ„åˆ†æ”¯ç»“æ„çš„åº”ç”¨åœºæ™¯ - æ¡ä»¶ / ç¼©è¿› / ä»£ç å— / æµç¨‹å›¾ifè¯­å¥ - ç®€å•çš„if / if-elseç»“æ„ / if-elif-elseç»“æ„ / åµŒå¥—çš„ifåº”ç”¨æ¡ˆä¾‹ - ç”¨æˆ·èº«ä»½éªŒè¯ / è‹±åˆ¶å•ä½ä¸å…¬åˆ¶å•ä½äº’æ¢ / æ·éª°å­å†³å®šåšä»€ä¹ˆ / ç™¾åˆ†åˆ¶æˆç»©è½¬ç­‰çº§åˆ¶ / åˆ†æ®µå‡½æ•°æ±‚å€¼ / è¾“å…¥ä¸‰æ¡è¾¹çš„é•¿åº¦å¦‚æœèƒ½æ„æˆä¸‰è§’å½¢å°±è®¡ç®—å‘¨é•¿å’Œé¢ç§¯Day04 - å¾ªç¯ç»“æ„å¾ªç¯ç»“æ„çš„åº”ç”¨åœºæ™¯ - æ¡ä»¶ / ç¼©è¿› / ä»£ç å— / æµç¨‹å›¾whileå¾ªç¯ - åŸºæœ¬ç»“æ„ / breakè¯­å¥ / continueè¯­å¥forå¾ªç¯ - åŸºæœ¬ç»“æ„ / rangeç±»å‹ / å¾ªç¯ä¸­çš„åˆ†æ”¯ç»“æ„ / åµŒå¥—çš„å¾ªç¯ / æå‰ç»“æŸç¨‹åºåº”ç”¨æ¡ˆä¾‹ - 1~100æ±‚å’Œ / åˆ¤æ–­ç´ æ•° / çŒœæ•°å­—æ¸¸æˆ / æ‰“å°ä¹ä¹è¡¨ / æ‰“å°ä¸‰è§’å½¢å›¾æ¡ˆ / çŒ´å­åƒæ¡ƒ / ç™¾é’±ç™¾é¸¡Day05 - æ„é€ ç¨‹åºé€»è¾‘ç»å…¸æ¡ˆä¾‹ï¼šæ°´ä»™èŠ±æ•° / ç™¾é’±ç™¾é¸¡ / CrapsèµŒåšæ¸¸æˆç»ƒä¹ é¢˜ç›®ï¼šæ–æ³¢é‚£å¥‘æ•°åˆ— / å®Œç¾æ•° / ç´ æ•°Day06 - å‡½æ•°å’Œæ¨¡å—çš„ä½¿ç”¨å‡½æ•°çš„ä½œç”¨ - ä»£ç çš„åå‘³é“ / ç”¨å‡½æ•°å°è£…åŠŸèƒ½æ¨¡å—å®šä¹‰å‡½æ•° - defå…³é”®å­— / å‡½æ•°å / å‚æ•°åˆ—è¡¨ / returnè¯­å¥ / è°ƒç”¨è‡ªå®šä¹‰å‡½æ•°è°ƒç”¨å‡½æ•° - Pythonå†…ç½®å‡½æ•° /  å¯¼å…¥æ¨¡å—å’Œå‡½æ•°å‡½æ•°çš„å‚æ•° - é»˜è®¤å‚æ•° / å¯å˜å‚æ•° / å…³é”®å­—å‚æ•° / å‘½åå…³é”®å­—å‚æ•°å‡½æ•°çš„è¿”å›å€¼ - æ²¡æœ‰è¿”å›å€¼  / è¿”å›å•ä¸ªå€¼ / è¿”å›å¤šä¸ªå€¼ä½œç”¨åŸŸé—®é¢˜ - å±€éƒ¨ä½œç”¨åŸŸ / åµŒå¥—ä½œç”¨åŸŸ / å…¨å±€ä½œç”¨åŸŸ / å†…ç½®ä½œç”¨åŸŸ / å’Œä½œç”¨åŸŸç›¸å…³çš„å…³é”®å­—ç”¨æ¨¡å—ç®¡ç†å‡½æ•° - æ¨¡å—çš„æ¦‚å¿µ / ç”¨è‡ªå®šä¹‰æ¨¡å—ç®¡ç†å‡½æ•° / å‘½åå†²çªçš„æ—¶å€™ä¼šæ€æ ·ï¼ˆåŒä¸€ä¸ªæ¨¡å—å’Œä¸åŒçš„æ¨¡å—ï¼‰Day07 - å­—ç¬¦ä¸²å’Œå¸¸ç”¨æ•°æ®ç»“æ„å­—ç¬¦ä¸²çš„ä½¿ç”¨ - è®¡ç®—é•¿åº¦ / ä¸‹æ ‡è¿ç®— / åˆ‡ç‰‡ / å¸¸ç”¨æ–¹æ³•åˆ—è¡¨åŸºæœ¬ç”¨æ³• - å®šä¹‰åˆ—è¡¨ / ç”¨ä¸‹è¡¨è®¿é—®å…ƒç´  / ä¸‹æ ‡è¶Šç•Œ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  / ä¿®æ”¹å…ƒç´  / åˆ‡ç‰‡ / å¾ªç¯éå†åˆ—è¡¨å¸¸ç”¨æ“ä½œ - è¿æ¥ / å¤åˆ¶(å¤åˆ¶å…ƒç´ å’Œå¤åˆ¶æ•°ç»„) / é•¿åº¦ / æ’åº / å€’è½¬ / æŸ¥æ‰¾ç”Ÿæˆåˆ—è¡¨ - ä½¿ç”¨rangeåˆ›å»ºæ•°å­—åˆ—è¡¨ / ç”Ÿæˆè¡¨è¾¾å¼ / ç”Ÿæˆå™¨å…ƒç»„çš„ä½¿ç”¨ - å®šä¹‰å…ƒç»„ / ä½¿ç”¨å…ƒç»„ä¸­çš„å€¼ / ä¿®æ”¹å…ƒç»„å˜é‡ / å…ƒç»„å’Œåˆ—è¡¨è½¬æ¢é›†åˆåŸºæœ¬ç”¨æ³• - é›†åˆå’Œåˆ—è¡¨çš„åŒºåˆ« /  åˆ›å»ºé›†åˆ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  /  æ¸…ç©ºé›†åˆå¸¸ç”¨æ“ä½œ - äº¤é›† / å¹¶é›† / å·®é›† / å¯¹ç§°å·® / å­é›† / è¶…é›†å­—å…¸çš„åŸºæœ¬ç”¨æ³• - å­—å…¸çš„ç‰¹ç‚¹ / åˆ›å»ºå­—å…¸ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  / å–å€¼ / æ¸…ç©ºå­—å…¸å¸¸ç”¨æ“ä½œ - keysæ–¹æ³• / valuesæ–¹æ³• / itemsæ–¹æ³• / setdefaultæ–¹æ³•åŸºç¡€ç»ƒä¹  - è·‘é©¬ç¯æ•ˆæœ / åˆ—è¡¨æ‰¾æœ€å¤§å…ƒç´  / ç»Ÿè®¡è€ƒè¯•æˆç»©çš„å¹³å‡åˆ† / Fibonacciæ•°åˆ— / æ¨è¾‰ä¸‰è§’ç»¼åˆæ¡ˆä¾‹ - åŒè‰²çƒé€‰å· / äº•å­—æ£‹Day08 - é¢å‘å¯¹è±¡ç¼–ç¨‹åŸºç¡€ç±»å’Œå¯¹è±¡ - ä»€ä¹ˆæ˜¯ç±» / ä»€ä¹ˆæ˜¯å¯¹è±¡ / é¢å‘å¯¹è±¡å…¶ä»–ç›¸å…³æ¦‚å¿µå®šä¹‰ç±» - åŸºæœ¬ç»“æ„ / å±æ€§å’Œæ–¹æ³• / æ„é€ å™¨ / ææ„å™¨ / __str__æ–¹æ³•ä½¿ç”¨å¯¹è±¡ - åˆ›å»ºå¯¹è±¡ / ç»™å¯¹è±¡å‘æ¶ˆæ¯é¢å‘å¯¹è±¡çš„å››å¤§æ”¯æŸ± - æŠ½è±¡ / å°è£… / ç»§æ‰¿ / å¤šæ€åŸºç¡€ç»ƒä¹  - å®šä¹‰å­¦ç”Ÿç±» / å®šä¹‰æ—¶é’Ÿç±» / å®šä¹‰å›¾å½¢ç±» / å®šä¹‰æ±½è½¦ç±»Day09 - é¢å‘å¯¹è±¡è¿›é˜¶å±æ€§ - ç±»å±æ€§ / å®ä¾‹å±æ€§ / å±æ€§è®¿é—®å™¨ / å±æ€§ä¿®æ”¹å™¨ / å±æ€§åˆ é™¤å™¨ / ä½¿ç”¨__slots__ç±»ä¸­çš„æ–¹æ³• - å®ä¾‹æ–¹æ³• / ç±»æ–¹æ³• / é™æ€æ–¹æ³•è¿ç®—ç¬¦é‡è½½ - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__ç±»(çš„å¯¹è±¡)ä¹‹é—´çš„å…³ç³» - å…³è” / ç»§æ‰¿ / ä¾èµ–ç»§æ‰¿å’Œå¤šæ€ - ä»€ä¹ˆæ˜¯ç»§æ‰¿ / ç»§æ‰¿çš„è¯­æ³• / è°ƒç”¨çˆ¶ç±»æ–¹æ³• / æ–¹æ³•é‡å†™ / ç±»å‹åˆ¤å®š / å¤šé‡ç»§æ‰¿ / è±å½¢ç»§æ‰¿(é’»çŸ³ç»§æ‰¿)å’ŒC3ç®—æ³•ç»¼åˆæ¡ˆä¾‹ - å·¥èµ„ç»“ç®—ç³»ç»Ÿ / å›¾ä¹¦è‡ªåŠ¨æŠ˜æ‰£ç³»ç»Ÿ / è‡ªå®šä¹‰åˆ†æ•°ç±»Day10 - å›¾å½¢ç”¨æˆ·ç•Œé¢å’Œæ¸¸æˆå¼€å‘ä½¿ç”¨tkinterå¼€å‘GUIç¨‹åºä½¿ç”¨pygameä¸‰æ–¹åº“å¼€å‘æ¸¸æˆåº”ç”¨â€œå¤§çƒåƒå°çƒâ€æ¸¸æˆDay11 - æ–‡ä»¶å’Œå¼‚å¸¸è¯»æ–‡ä»¶ - è¯»å–æ•´ä¸ªæ–‡ä»¶ / é€è¡Œè¯»å– / æ–‡ä»¶è·¯å¾„å†™æ–‡ä»¶ - è¦†ç›–å†™å…¥ / è¿½åŠ å†™å…¥ / æ–‡æœ¬æ–‡ä»¶ / äºŒè¿›åˆ¶æ–‡ä»¶å¼‚å¸¸å¤„ç† - å¼‚å¸¸æœºåˆ¶çš„é‡è¦æ€§ / try-exceptä»£ç å— / elseä»£ç å— / finallyä»£ç å— / å†…ç½®å¼‚å¸¸ç±»å‹ / å¼‚å¸¸æ ˆ / raiseè¯­å¥æ•°æ®æŒä¹…åŒ– - CSVæ–‡ä»¶æ¦‚è¿° / csvæ¨¡å—çš„åº”ç”¨ / JSONæ•°æ®æ ¼å¼ / jsonæ¨¡å—çš„åº”ç”¨Day12 - å­—ç¬¦ä¸²å’Œæ­£åˆ™è¡¨è¾¾å¼å­—ç¬¦ä¸²é«˜çº§æ“ä½œ - è½¬ä¹‰å­—ç¬¦ / åŸå§‹å­—ç¬¦ä¸² / å¤šè¡Œå­—ç¬¦ä¸² / inå’Œnot inè¿ç®—ç¬¦ / is_xxxæ–¹æ³• / joinå’Œsplitæ–¹æ³• / stripç›¸å…³æ–¹æ³• / pyperclipæ¨¡å— / ä¸å˜å­—ç¬¦ä¸²å’Œå¯å˜å­—ç¬¦ä¸² / StringIOçš„ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å…¥é—¨ - æ­£åˆ™è¡¨è¾¾å¼çš„ä½œç”¨ / å…ƒå­—ç¬¦ / è½¬ä¹‰ / é‡è¯ / åˆ†ç»„ / é›¶å®½æ–­è¨€ /è´ªå©ªåŒ¹é…ä¸æƒ°æ€§åŒ¹é…æ‡’æƒ° / ä½¿ç”¨reæ¨¡å—å®ç°æ­£åˆ™è¡¨è¾¾å¼æ“ä½œï¼ˆåŒ¹é…ã€æœç´¢ã€æ›¿æ¢ã€æ•è·ï¼‰ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ - reæ¨¡å— / compileå‡½æ•° / groupå’Œgroupsæ–¹æ³• / matchæ–¹æ³• / searchæ–¹æ³• / findallå’Œfinditeræ–¹æ³• / subå’Œsubnæ–¹æ³• / splitæ–¹æ³•åº”ç”¨æ¡ˆä¾‹ - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼éªŒè¯è¾“å…¥çš„å­—ç¬¦ä¸²Day13 - è¿›ç¨‹å’Œçº¿ç¨‹è¿›ç¨‹å’Œçº¿ç¨‹çš„æ¦‚å¿µ - ä»€ä¹ˆæ˜¯è¿›ç¨‹ / ä»€ä¹ˆæ˜¯çº¿ç¨‹ / å¤šçº¿ç¨‹çš„åº”ç”¨åœºæ™¯ä½¿ç”¨è¿›ç¨‹ - forkå‡½æ•° / multiprocessingæ¨¡å— / è¿›ç¨‹æ±  / è¿›ç¨‹é—´é€šä¿¡ä½¿ç”¨çº¿ç¨‹ -  threadingæ¨¡å— / Threadç±» / RLockç±» / Conditionç±» / çº¿ç¨‹æ± Day14 - ç½‘ç»œç¼–ç¨‹å…¥é—¨å’Œç½‘ç»œåº”ç”¨å¼€å‘è®¡ç®—æœºç½‘ç»œåŸºç¡€ - è®¡ç®—æœºç½‘ç»œå‘å±•å² / â€œTCP-IPâ€æ¨¡å‹ / IPåœ°å€ / ç«¯å£ / åè®® / å…¶ä»–ç›¸å…³æ¦‚å¿µç½‘ç»œåº”ç”¨æ¨¡å¼ - â€œå®¢æˆ·ç«¯-æœåŠ¡å™¨â€æ¨¡å¼ / â€œæµè§ˆå™¨-æœåŠ¡å™¨â€æ¨¡å¼åŸºäºHTTPåè®®è®¿é—®ç½‘ç»œèµ„æº - ç½‘ç»œAPIæ¦‚è¿° / è®¿é—®URL / requestsä¸‰æ–¹åº“ / è§£æJSONæ ¼å¼æ•°æ®Pythonç½‘ç»œç¼–ç¨‹ - å¥—æ¥å­—çš„æ¦‚å¿µ / socketæ¨¡å— /  socketå‡½æ•° / åˆ›å»ºTCPæœåŠ¡å™¨ / åˆ›å»ºTCPå®¢æˆ·ç«¯ / åˆ›å»ºUDPæœåŠ¡å™¨ / åˆ›å»ºUDPå®¢æˆ·ç«¯ç”µå­é‚®ä»¶ - SMTPåè®® / POP3åè®® / IMAPåè®® / smtplibæ¨¡å— / poplibæ¨¡å— / imaplibæ¨¡å—çŸ­ä¿¡æœåŠ¡ - è°ƒç”¨çŸ­ä¿¡æœåŠ¡ç½‘å…³Day15 - å›¾åƒå’Œæ–‡æ¡£å¤„ç†ç”¨Pillowå¤„ç†å›¾ç‰‡ - å›¾ç‰‡è¯»å†™ / å›¾ç‰‡åˆæˆ / å‡ ä½•å˜æ¢ / è‰²å½©è½¬æ¢ / æ»¤é•œæ•ˆæœè¯»å†™Wordæ–‡æ¡£ - æ–‡æœ¬å†…å®¹çš„å¤„ç† / æ®µè½ / é¡µçœ‰å’Œé¡µè„š / æ ·å¼çš„å¤„ç†è¯»å†™Excelæ–‡ä»¶ - xlrd / xlwt / openpyxlDay16~Day20 - Pythonè¯­è¨€è¿›é˜¶ å¸¸ç”¨æ•°æ®ç»“æ„å‡½æ•°çš„é«˜çº§ç”¨æ³• - â€œä¸€ç­‰å…¬æ°‘â€ / é«˜é˜¶å‡½æ•° / Lambdaå‡½æ•° / ä½œç”¨åŸŸå’Œé—­åŒ… / è£…é¥°å™¨é¢å‘å¯¹è±¡é«˜çº§çŸ¥è¯† - â€œä¸‰å¤§æ”¯æŸ±â€ / ç±»ä¸ç±»ä¹‹é—´çš„å…³ç³» / åƒåœ¾å›æ”¶ / é­”æœ¯å±æ€§å’Œæ–¹æ³• / æ··å…¥ / å…ƒç±» / é¢å‘å¯¹è±¡è®¾è®¡åŸåˆ™ / GoFè®¾è®¡æ¨¡å¼è¿­ä»£å™¨å’Œç”Ÿæˆå™¨ - ç›¸å…³é­”æœ¯æ–¹æ³• / åˆ›å»ºç”Ÿæˆå™¨çš„ä¸¤ç§æ–¹å¼ /å¹¶å‘å’Œå¼‚æ­¥ç¼–ç¨‹ - å¤šçº¿ç¨‹ / å¤šè¿›ç¨‹ / å¼‚æ­¥IO / asyncå’ŒawaitDay21~30 - Webå‰ç«¯å…¥é—¨ç”¨HTMLæ ‡ç­¾æ‰¿è½½é¡µé¢å†…å®¹ç”¨CSSæ¸²æŸ“é¡µé¢ç”¨JavaScriptå¤„ç†äº¤äº’å¼è¡Œä¸ºjQueryå…¥é—¨å’Œæé«˜Vue.jså…¥é—¨Elementçš„ä½¿ç”¨Bootstrapçš„ä½¿ç”¨Day31~35 - ç©è½¬Linuxæ“ä½œç³»ç»Ÿæ“ä½œç³»ç»Ÿå‘å±•å²å’ŒLinuxæ¦‚è¿°LinuxåŸºç¡€å‘½ä»¤Linuxä¸­çš„å®ç”¨ç¨‹åºLinuxçš„æ–‡ä»¶ç³»ç»ŸVimç¼–è¾‘å™¨çš„åº”ç”¨ç¯å¢ƒå˜é‡å’ŒShellç¼–ç¨‹è½¯ä»¶çš„å®‰è£…å’ŒæœåŠ¡çš„é…ç½®ç½‘ç»œè®¿é—®å’Œç®¡ç†å…¶ä»–ç›¸å…³å†…å®¹Day36~40 - æ•°æ®åº“åŸºç¡€å’Œè¿›é˜¶å…³ç³»å‹æ•°æ®åº“æ¦‚è¿°MySQLçš„å®‰è£…å’Œä½¿ç”¨SQLçš„ä½¿ç”¨DDL - æ•°æ®å®šä¹‰è¯­è¨€ - create / drop / alterDML - æ•°æ®æ“ä½œè¯­è¨€ - insert / delete / updateDQL - æ•°æ®æŸ¥è¯¢è¯­è¨€ - selectDCL - æ•°æ®æ§åˆ¶è¯­è¨€ - grant / revokeMySQLæ–°ç‰¹æ€§çª—å£å‡½æ•°çš„åº”ç”¨JSONæ•°æ®ç±»å‹ç›¸å…³çŸ¥è¯†æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§è§†å›¾ã€å‡½æ•°ã€è¿‡ç¨‹ã€è§¦å‘å™¨äº‹åŠ¡å’Œé”æ‰§è¡Œè®¡åˆ’å’Œç´¢å¼•èŒƒå¼ç†è®ºå’ŒåèŒƒå¼è®¾è®¡åœ¨Pythonä¸­æ“ä½œMySQLDay41~55 - å®æˆ˜DjangoDay41 - Djangoå¿«é€Ÿä¸Šæ‰‹Webåº”ç”¨å·¥ä½œæœºåˆ¶HTTPè¯·æ±‚å’Œå“åº”Djangoæ¡†æ¶æ¦‚è¿°5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹Day42 - æ·±å…¥æ¨¡å‹å…³ç³»å‹æ•°æ®åº“é…ç½®ä½¿ç”¨ORMå®Œæˆå¯¹æ¨¡å‹çš„CRUDæ“ä½œç®¡ç†åå°çš„ä½¿ç”¨Djangoæ¨¡å‹æœ€ä½³å®è·µæ¨¡å‹å®šä¹‰å‚è€ƒDay43 - é™æ€èµ„æºå’ŒAjaxè¯·æ±‚åŠ è½½é™æ€èµ„æºAjaxæ¦‚è¿°ç”¨Ajaxå®ç°æŠ•ç¥¨åŠŸèƒ½Day44 - Cookieå’ŒSessionå®ç°ç”¨æˆ·è·Ÿè¸ªcookieå’Œsessionçš„å…³ç³»Djangoæ¡†æ¶å¯¹sessionçš„æ”¯æŒè§†å›¾å‡½æ•°ä¸­çš„cookieè¯»å†™æ“ä½œDay45 - æŠ¥è¡¨å’Œæ—¥å¿—é€šè¿‡HttpResponseä¿®æ”¹å“åº”å¤´ä½¿ç”¨StreamingHttpResponseå¤„ç†å¤§æ–‡ä»¶ä½¿ç”¨xlwtç”ŸæˆExcelæŠ¥è¡¨ä½¿ç”¨reportlabç”ŸæˆPDFæŠ¥è¡¨ä½¿ç”¨EChartsç”Ÿæˆå‰ç«¯å›¾è¡¨Day46 - æ—¥å¿—å’Œè°ƒè¯•å·¥å…·æ é…ç½®æ—¥å¿—é…ç½®Django-Debug-Toolbarä¼˜åŒ–ORMä»£ç Day47 - ä¸­é—´ä»¶çš„åº”ç”¨ä»€ä¹ˆæ˜¯ä¸­é—´ä»¶Djangoæ¡†æ¶å†…ç½®çš„ä¸­é—´ä»¶è‡ªå®šä¹‰ä¸­é—´ä»¶åŠå…¶åº”ç”¨åœºæ™¯Day48 - å‰åç«¯åˆ†ç¦»å¼€å‘å…¥é—¨è¿”å›JSONæ ¼å¼çš„æ•°æ®ç”¨Vue.jsæ¸²æŸ“é¡µé¢Day49 - RESTfulæ¶æ„å’ŒDRFå…¥é—¨Day50 - RESTfulæ¶æ„å’ŒDRFè¿›é˜¶Day51 - ä½¿ç”¨ç¼“å­˜ç½‘ç«™ä¼˜åŒ–ç¬¬ä¸€å®šå¾‹åœ¨Djangoé¡¹ç›®ä¸­ä½¿ç”¨Redisæä¾›ç¼“å­˜æœåŠ¡åœ¨è§†å›¾å‡½æ•°ä¸­è¯»å†™ç¼“å­˜ä½¿ç”¨è£…é¥°å™¨å®ç°é¡µé¢ç¼“å­˜ä¸ºæ•°æ®æ¥å£æä¾›ç¼“å­˜æœåŠ¡Day52 - æ¥å…¥ä¸‰æ–¹å¹³å°æ–‡ä»¶ä¸Šä¼ è¡¨å•æ§ä»¶å’Œå›¾ç‰‡æ–‡ä»¶é¢„è§ˆæœåŠ¡å™¨ç«¯å¦‚ä½•å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶Day53 - å¼‚æ­¥ä»»åŠ¡å’Œå®šæ—¶ä»»åŠ¡ç½‘ç«™ä¼˜åŒ–ç¬¬äºŒå®šå¾‹é…ç½®æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡åœ¨é¡¹ç›®ä¸­ä½¿ç”¨Celeryå®ç°ä»»åŠ¡å¼‚æ­¥åŒ–åœ¨é¡¹ç›®ä¸­ä½¿ç”¨Celeryå®ç°å®šæ—¶ä»»åŠ¡Day54 - å•å…ƒæµ‹è¯•Day55 - é¡¹ç›®ä¸Šçº¿Pythonä¸­çš„å•å…ƒæµ‹è¯•Djangoæ¡†æ¶å¯¹å•å…ƒæµ‹è¯•çš„æ”¯æŒä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿé…ç½®å’Œä½¿ç”¨uWSGIåŠ¨é™åˆ†ç¦»å’ŒNginxé…ç½®é…ç½®HTTPSé…ç½®åŸŸåè§£æDay56~60 - ç”¨FastAPIå¼€å‘æ•°æ®æ¥å£FastAPIäº”åˆ†é’Ÿä¸Šæ‰‹è¯·æ±‚å’Œå“åº”æ¥å…¥å…³ç³»å‹æ•°æ®åº“ä¾èµ–æ³¨å…¥ä¸­é—´ä»¶å¼‚æ­¥åŒ–è™šæ‹ŸåŒ–éƒ¨ç½²ï¼ˆDockerï¼‰é¡¹ç›®å®æˆ˜ï¼šè½¦è¾†è¿ç« æŸ¥è¯¢é¡¹ç›®Day61~65 - çˆ¬è™«å¼€å‘Day61 - ç½‘ç»œæ•°æ®é‡‡é›†æ¦‚è¿°ç½‘ç»œçˆ¬è™«çš„æ¦‚å¿µåŠå…¶åº”ç”¨é¢†åŸŸç½‘ç»œçˆ¬è™«çš„åˆæ³•æ€§æ¢è®¨å¼€å‘ç½‘ç»œçˆ¬è™«çš„ç›¸å…³å·¥å…·ä¸€ä¸ªçˆ¬è™«ç¨‹åºçš„æ„æˆDay62 - æ•°æ®æŠ“å–å’Œè§£æä½¿ç”¨requestsä¸‰æ–¹åº“å®ç°æ•°æ®æŠ“å–é¡µé¢è§£æçš„ä¸‰ç§æ–¹å¼æ­£åˆ™è¡¨è¾¾å¼è§£æXPathè§£æCSSé€‰æ‹©å™¨è§£æDay63 - Pythonä¸­çš„å¹¶å‘ç¼–ç¨‹å¤šçº¿ç¨‹å¤šè¿›ç¨‹å¼‚æ­¥I/ODay64 - ä½¿ç”¨SeleniumæŠ“å–ç½‘é¡µåŠ¨æ€å†…å®¹Day65 - çˆ¬è™«æ¡†æ¶Scrapyç®€ä»‹Day66~80 - æ•°æ®åˆ†æDay66 - æ•°æ®åˆ†ææ¦‚è¿°Day67 - ç¯å¢ƒå‡†å¤‡Day68 - NumPyçš„åº”ç”¨-1Day69 - NumPyçš„åº”ç”¨-2Day70 - Pandasçš„åº”ç”¨-1Day71 - Pandasçš„åº”ç”¨-2Day72 - Pandasçš„åº”ç”¨-3Day73 - Pandasçš„åº”ç”¨-4Day74 - Pandasçš„åº”ç”¨-5Day75 - æ•°æ®å¯è§†åŒ–-1Day76 - æ•°æ®å¯è§†åŒ–-2Day77 - æ¦‚ç‡ç»Ÿè®¡åŸºç¡€Day78 - æ–¹å·®åˆ†æå’Œå‚æ•°ä¼°è®¡Day79 - ç›¸å…³å’Œå›å½’Day80 - æ•°æ®åˆ†ææ–¹æ³•è®ºDay81~90 - æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ Day81 - æœºå™¨å­¦ä¹ åŸºç¡€Day82 - kæœ€è¿‘é‚»åˆ†ç±»Day83 - å†³ç­–æ ‘Day84 - è´å¶æ–¯åˆ†ç±»Day85 - æ”¯æŒå‘é‡æœºDay86 - K-å‡å€¼èšç±»Day87 - å›å½’åˆ†æDay88 - æ·±åº¦å­¦ä¹ å…¥é—¨Day89 - PyTorchæ¦‚è¿°Day90 - PyTorchå®æˆ˜Day91~100 - å›¢é˜Ÿé¡¹ç›®å¼€å‘ç¬¬91å¤©ï¼šå›¢é˜Ÿé¡¹ç›®å¼€å‘çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆè½¯ä»¶è¿‡ç¨‹æ¨¡å‹ç»å…¸è¿‡ç¨‹æ¨¡å‹ï¼ˆç€‘å¸ƒæ¨¡å‹ï¼‰å¯è¡Œæ€§åˆ†æï¼ˆç ”ç©¶åšè¿˜æ˜¯ä¸åšï¼‰ï¼Œè¾“å‡ºã€Šå¯è¡Œæ€§åˆ†ææŠ¥å‘Šã€‹ã€‚éœ€æ±‚åˆ†æï¼ˆç ”ç©¶åšä»€ä¹ˆï¼‰ï¼Œè¾“å‡ºã€Šéœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦ã€‹å’Œäº§å“ç•Œé¢åŸå‹å›¾ã€‚æ¦‚è¦è®¾è®¡å’Œè¯¦ç»†è®¾è®¡ï¼Œè¾“å‡ºæ¦‚å¿µæ¨¡å‹å›¾ï¼ˆERå›¾ï¼‰ã€ç‰©ç†æ¨¡å‹å›¾ã€ç±»å›¾ã€æ—¶åºå›¾ç­‰ã€‚ç¼–ç  / æµ‹è¯•ã€‚ä¸Šçº¿ / ç»´æŠ¤ã€‚ç€‘å¸ƒæ¨¡å‹æœ€å¤§çš„ç¼ºç‚¹æ˜¯æ— æ³•æ‹¥æŠ±éœ€æ±‚å˜åŒ–ï¼Œæ•´å¥—æµç¨‹ç»“æŸåæ‰èƒ½çœ‹åˆ°äº§å“ï¼Œå›¢é˜Ÿå£«æ°”ä½è½ã€‚æ•æ·å¼€å‘ï¼ˆScrumï¼‰- äº§å“æ‰€æœ‰è€…ã€Scrum Masterã€ç ”å‘äººå‘˜ - Sprintäº§å“çš„Backlogï¼ˆç”¨æˆ·æ•…äº‹ã€äº§å“åŸå‹ï¼‰ã€‚è®¡åˆ’ä¼šè®®ï¼ˆè¯„ä¼°å’Œé¢„ç®—ï¼‰ã€‚æ—¥å¸¸å¼€å‘ï¼ˆç«™ç«‹ä¼šè®®ã€ç•ªèŒ„å·¥ä½œæ³•ã€ç»“å¯¹ç¼–ç¨‹ã€æµ‹è¯•å…ˆè¡Œã€ä»£ç é‡æ„â€¦â€¦ï¼‰ã€‚ä¿®å¤bugï¼ˆé—®é¢˜æè¿°ã€é‡ç°æ­¥éª¤ã€æµ‹è¯•äººå‘˜ã€è¢«æŒ‡æ´¾äººï¼‰ã€‚å‘å¸ƒç‰ˆæœ¬ã€‚è¯„å®¡ä¼šè®®ï¼ˆShowcaseï¼Œç”¨æˆ·éœ€è¦å‚ä¸ï¼‰ã€‚å›é¡¾ä¼šè®®ï¼ˆå¯¹å½“å‰è¿­ä»£å‘¨æœŸåšä¸€ä¸ªæ€»ç»“ï¼‰ã€‚è¡¥å……ï¼šæ•æ·è½¯ä»¶å¼€å‘å®£è¨€ä¸ªä½“å’Œäº’åŠ¨ é«˜äº æµç¨‹å’Œå·¥å…·å·¥ä½œçš„è½¯ä»¶ é«˜äº è¯¦å°½çš„æ–‡æ¡£å®¢æˆ·åˆä½œ é«˜äº åˆåŒè°ˆåˆ¤å“åº”å˜åŒ– é«˜äº éµå¾ªè®¡åˆ’è§’è‰²ï¼šäº§å“æ‰€æœ‰è€…ï¼ˆå†³å®šåšä»€ä¹ˆï¼Œèƒ½å¯¹éœ€æ±‚æ‹æ¿çš„äººï¼‰ã€å›¢é˜Ÿè´Ÿè´£äººï¼ˆè§£å†³å„ç§é—®é¢˜ï¼Œä¸“æ³¨å¦‚ä½•æ›´å¥½çš„å·¥ä½œï¼Œå±è”½å¤–éƒ¨å¯¹å¼€å‘å›¢é˜Ÿçš„å½±å“ï¼‰ã€å¼€å‘å›¢é˜Ÿï¼ˆé¡¹ç›®æ‰§è¡Œäººå‘˜ï¼Œå…·ä½“æŒ‡å¼€å‘äººå‘˜å’Œæµ‹è¯•äººå‘˜ï¼‰ã€‚å‡†å¤‡å·¥ä½œï¼šå•†ä¸šæ¡ˆä¾‹å’Œèµ„é‡‘ã€åˆåŒã€æ†§æ†¬ã€åˆå§‹äº§å“éœ€æ±‚ã€åˆå§‹å‘å¸ƒè®¡åˆ’ã€å…¥è‚¡ã€ç»„å»ºå›¢é˜Ÿã€‚æ•æ·å›¢é˜Ÿé€šå¸¸äººæ•°ä¸º8-10äººã€‚å·¥ä½œé‡ä¼°ç®—ï¼šå°†å¼€å‘ä»»åŠ¡é‡åŒ–ï¼ŒåŒ…æ‹¬åŸå‹ã€Logoè®¾è®¡ã€UIè®¾è®¡ã€å‰ç«¯å¼€å‘ç­‰ï¼Œå°½é‡æŠŠæ¯ä¸ªå·¥ä½œåˆ†è§£åˆ°æœ€å°ä»»åŠ¡é‡ï¼Œæœ€å°ä»»åŠ¡é‡æ ‡å‡†ä¸ºå·¥ä½œæ—¶é—´ä¸èƒ½è¶…è¿‡ä¸¤å¤©ï¼Œç„¶åä¼°ç®—æ€»ä½“é¡¹ç›®æ—¶é—´ã€‚æŠŠæ¯ä¸ªä»»åŠ¡éƒ½è´´åœ¨çœ‹æ¿ä¸Šé¢ï¼Œçœ‹æ¿ä¸Šåˆ†ä¸‰éƒ¨åˆ†ï¼što doï¼ˆå¾…å®Œæˆï¼‰ã€in progressï¼ˆè¿›è¡Œä¸­ï¼‰å’Œdoneï¼ˆå·²å®Œæˆï¼‰ã€‚é¡¹ç›®å›¢é˜Ÿç»„å»ºå›¢é˜Ÿçš„æ„æˆå’Œè§’è‰²è¯´æ˜ï¼šè°¢è°¢ä»˜ç¥¥è‹±å¥³å£«å¸®åŠ©æˆ‘ç»˜åˆ¶äº†ä¸‹é¢è¿™å¼ ç²¾ç¾çš„å…¬å¸ç»„ç»‡æ¶æ„å›¾ã€‚ç¼–ç¨‹è§„èŒƒå’Œä»£ç å®¡æŸ¥ï¼ˆflake8ã€pylintï¼‰Pythonä¸­çš„ä¸€äº›â€œæƒ¯ä¾‹â€ï¼ˆè¯·å‚è€ƒã€ŠPythonæƒ¯ä¾‹-å¦‚ä½•ç¼–å†™Pythonicçš„ä»£ç ã€‹ï¼‰å½±å“ä»£ç å¯è¯»æ€§çš„åŸå› ï¼šä»£ç æ³¨é‡Šå¤ªå°‘æˆ–è€…æ²¡æœ‰æ³¨é‡Šä»£ç ç ´åäº†è¯­è¨€çš„æœ€ä½³å®è·µåæ¨¡å¼ç¼–ç¨‹ï¼ˆæ„å¤§åˆ©é¢ä»£ç ã€å¤åˆ¶-é»è´´ç¼–ç¨‹ã€è‡ªè´Ÿç¼–ç¨‹ã€â€¦â€¦ï¼‰å›¢é˜Ÿå¼€å‘å·¥å…·ä»‹ç»ç‰ˆæœ¬æ§åˆ¶ï¼šGitã€Mercuryç¼ºé™·ç®¡ç†ï¼šGitlabã€Redmineæ•æ·é—­ç¯å·¥å…·ï¼šç¦…é“ã€JIRAæŒç»­é›†æˆï¼šJenkinsã€Travis-CIè¯·å‚è€ƒã€Šå›¢é˜Ÿé¡¹ç›®å¼€å‘çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆã€‹ã€‚é¡¹ç›®é€‰é¢˜å’Œç†è§£ä¸šåŠ¡é€‰é¢˜èŒƒå›´è®¾å®šCMSï¼ˆç”¨æˆ·ç«¯ï¼‰ï¼šæ–°é—»èšåˆç½‘ç«™ã€é—®ç­”/åˆ†äº«ç¤¾åŒºã€å½±è¯„/ä¹¦è¯„ç½‘ç«™ç­‰ã€‚MISï¼ˆç”¨æˆ·ç«¯+ç®¡ç†ç«¯ï¼‰ï¼šKMSã€KPIè€ƒæ ¸ç³»ç»Ÿã€HRSã€CRMç³»ç»Ÿã€ä¾›åº”é“¾ç³»ç»Ÿã€ä»“å‚¨ç®¡ç†ç³»ç»Ÿç­‰ã€‚Appåå°ï¼ˆç®¡ç†ç«¯+æ•°æ®æ¥å£ï¼‰ï¼šäºŒæ‰‹äº¤æ˜“ç±»ã€æŠ¥åˆŠæ‚å¿—ç±»ã€å°ä¼—ç”µå•†ç±»ã€æ–°é—»èµ„è®¯ç±»ã€æ—…æ¸¸ç±»ã€ç¤¾äº¤ç±»ã€é˜…è¯»ç±»ç­‰ã€‚å…¶ä»–ç±»å‹ï¼šè‡ªèº«è¡Œä¸šèƒŒæ™¯å’Œå·¥ä½œç»éªŒã€ä¸šåŠ¡å®¹æ˜“ç†è§£å’ŒæŠŠæ§ã€‚éœ€æ±‚ç†è§£ã€æ¨¡å—åˆ’åˆ†å’Œä»»åŠ¡åˆ†é…éœ€æ±‚ç†è§£ï¼šå¤´è„‘é£æš´å’Œç«å“åˆ†æã€‚æ¨¡å—åˆ’åˆ†ï¼šç”»æ€ç»´å¯¼å›¾ï¼ˆXMindï¼‰ï¼Œæ¯ä¸ªæ¨¡å—æ˜¯ä¸€ä¸ªæèŠ‚ç‚¹ï¼Œæ¯ä¸ªå…·ä½“çš„åŠŸèƒ½æ˜¯ä¸€ä¸ªå¶èŠ‚ç‚¹ï¼ˆç”¨åŠ¨è¯è¡¨è¿°ï¼‰ï¼Œéœ€è¦ç¡®ä¿æ¯ä¸ªå¶èŠ‚ç‚¹æ— æ³•å†ç”Ÿå‡ºæ–°èŠ‚ç‚¹ï¼Œç¡®å®šæ¯ä¸ªå¶å­èŠ‚ç‚¹çš„é‡è¦æ€§ã€ä¼˜å…ˆçº§å’Œå·¥ä½œé‡ã€‚ä»»åŠ¡åˆ†é…ï¼šç”±é¡¹ç›®è´Ÿè´£äººæ ¹æ®ä¸Šé¢çš„æŒ‡æ ‡ä¸ºæ¯ä¸ªå›¢é˜Ÿæˆå‘˜åˆ†é…ä»»åŠ¡ã€‚åˆ¶å®šé¡¹ç›®è¿›åº¦è¡¨ï¼ˆæ¯æ—¥æ›´æ–°ï¼‰æ¨¡å—åŠŸèƒ½äººå‘˜çŠ¶æ€å®Œæˆå·¥æ—¶è®¡åˆ’å¼€å§‹å®é™…å¼€å§‹è®¡åˆ’ç»“æŸå®é™…ç»“æŸå¤‡æ³¨è¯„è®ºæ·»åŠ è¯„è®ºç‹å¤§é”¤æ­£åœ¨è¿›è¡Œ50%42018/8/72018/8/7åˆ é™¤è¯„è®ºç‹å¤§é”¤ç­‰å¾…0%22018/8/72018/8/7æŸ¥çœ‹è¯„è®ºç™½å…ƒèŠ³æ­£åœ¨è¿›è¡Œ20%42018/8/72018/8/7éœ€è¦è¿›è¡Œä»£ç å®¡æŸ¥è¯„è®ºæŠ•ç¥¨ç™½å…ƒèŠ³ç­‰å¾…0%42018/8/82018/8/8OOADå’Œæ•°æ®åº“è®¾è®¡UMLï¼ˆç»Ÿä¸€å»ºæ¨¡è¯­è¨€ï¼‰çš„ç±»å›¾é€šè¿‡æ¨¡å‹åˆ›å»ºè¡¨ï¼ˆæ­£å‘å·¥ç¨‹ï¼‰ï¼Œä¾‹å¦‚åœ¨Djangoé¡¹ç›®ä¸­å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤åˆ›å»ºäºŒç»´è¡¨ã€‚python manage.py makemigrations apppython manage.py migrateä½¿ç”¨PowerDesignerç»˜åˆ¶ç‰©ç†æ¨¡å‹å›¾ã€‚é€šè¿‡æ•°æ®è¡¨åˆ›å»ºæ¨¡å‹ï¼ˆåå‘å·¥ç¨‹ï¼‰ï¼Œä¾‹å¦‚åœ¨Djangoé¡¹ç›®ä¸­å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤ç”Ÿæˆæ¨¡å‹ã€‚python manage.py inspectdb > app/models.pyç¬¬92å¤©ï¼šDockerå®¹å™¨è¯¦è§£Dockerç®€ä»‹å®‰è£…Dockerä½¿ç”¨Dockeråˆ›å»ºå®¹å™¨ï¼ˆNginxã€MySQLã€Redisã€Gitlabã€Jenkinsï¼‰æ„å»ºDockeré•œåƒï¼ˆDockerfileçš„ç¼–å†™å’Œç›¸å…³æŒ‡ä»¤ï¼‰å®¹å™¨ç¼–æ’ï¼ˆDocker-composeï¼‰é›†ç¾¤ç®¡ç†ï¼ˆKubernetesï¼‰ç¬¬93å¤©ï¼šMySQLæ€§èƒ½ä¼˜åŒ–ç¬¬94å¤©ï¼šç½‘ç»œAPIæ¥å£è®¾è®¡ç¬¬95å¤©ï¼š[ä½¿ç”¨Djangoå¼€å‘å•†ä¸šé¡¹ç›®](./Day91-100/95.ä½¿ç”¨Djangoå¼€å‘å•†ä¸šé¡¹\tç›®.md)é¡¹ç›®å¼€å‘ä¸­çš„å…¬å…±é—®é¢˜æ•°æ®åº“çš„é…ç½®ï¼ˆå¤šæ•°æ®åº“ã€ä¸»ä»å¤åˆ¶ã€æ•°æ®åº“è·¯ç”±ï¼‰ç¼“å­˜çš„é…ç½®ï¼ˆåˆ†åŒºç¼“å­˜ã€é”®è®¾ç½®ã€è¶…æ—¶è®¾ç½®ã€ä¸»ä»å¤åˆ¶ã€æ•…éšœæ¢å¤ï¼ˆå“¨å…µï¼‰ï¼‰æ—¥å¿—çš„é…ç½®åˆ†æå’Œè°ƒè¯•ï¼ˆDjango-Debug-ToolBarï¼‰å¥½ç”¨çš„Pythonæ¨¡å—ï¼ˆæ—¥æœŸè®¡ç®—ã€å›¾åƒå¤„ç†ã€æ•°æ®åŠ å¯†ã€ä¸‰æ–¹APIï¼‰REST APIè®¾è®¡RESTfulæ¶æ„ç†è§£RESTfulæ¶æ„RESTful APIè®¾è®¡æŒ‡å—RESTful APIæœ€ä½³å®è·µAPIæ¥å£æ–‡æ¡£çš„æ’°å†™RAP2YAPIdjango-REST-frameworkçš„åº”ç”¨é¡¹ç›®ä¸­çš„é‡ç‚¹éš¾ç‚¹å‰–æä½¿ç”¨ç¼“å­˜ç¼“è§£æ•°æ®åº“å‹åŠ› - Redisä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—åšè§£è€¦åˆå’Œå‰Šå³° - Celery + RabbitMQç¬¬96å¤©ï¼šè½¯ä»¶æµ‹è¯•å’Œè‡ªåŠ¨åŒ–æµ‹è¯•å•å…ƒæµ‹è¯•æµ‹è¯•çš„ç§ç±»ç¼–å†™å•å…ƒæµ‹è¯•ï¼ˆunittestã€pytestã€nose2ã€toxã€ddtã€â€¦â€¦ï¼‰æµ‹è¯•è¦†ç›–ç‡ï¼ˆcoverageï¼‰Djangoé¡¹ç›®éƒ¨ç½²éƒ¨ç½²å‰çš„å‡†å¤‡å·¥ä½œå…³é”®è®¾ç½®ï¼ˆSECRET_KEY / DEBUG / ALLOWED_HOSTS / ç¼“å­˜ / æ•°æ®åº“ï¼‰HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECUREæ—¥å¿—ç›¸å…³é…ç½®Linuxå¸¸ç”¨å‘½ä»¤å›é¡¾Linuxå¸¸ç”¨æœåŠ¡çš„å®‰è£…å’Œé…ç½®uWSGI/Gunicornå’ŒNginxçš„ä½¿ç”¨Gunicornå’ŒuWSGIçš„æ¯”è¾ƒå¯¹äºä¸éœ€è¦å¤§é‡å®šåˆ¶åŒ–çš„ç®€å•åº”ç”¨ç¨‹åºï¼ŒGunicornæ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ï¼ŒuWSGIçš„å­¦ä¹ æ›²çº¿æ¯”Gunicornè¦é™¡å³­å¾—å¤šï¼ŒGunicornçš„é»˜è®¤å‚æ•°å°±å·²ç»èƒ½å¤Ÿé€‚åº”å¤§å¤šæ•°åº”ç”¨ç¨‹åºã€‚uWSGIæ”¯æŒå¼‚æ„éƒ¨ç½²ã€‚ç”±äºNginxæœ¬èº«æ”¯æŒuWSGIï¼Œåœ¨çº¿ä¸Šä¸€èˆ¬éƒ½å°†Nginxå’ŒuWSGIæ†ç»‘åœ¨ä¸€èµ·éƒ¨ç½²ï¼Œè€Œä¸”uWSGIå±äºåŠŸèƒ½é½å…¨ä¸”é«˜åº¦å®šåˆ¶çš„WSGIä¸­é—´ä»¶ã€‚åœ¨æ€§èƒ½ä¸Šï¼ŒGunicornå’ŒuWSGIå…¶å®è¡¨ç°ç›¸å½“ã€‚ä½¿ç”¨è™šæ‹ŸåŒ–æŠ€æœ¯ï¼ˆDockerï¼‰éƒ¨ç½²æµ‹è¯•ç¯å¢ƒå’Œç”Ÿäº§ç¯å¢ƒæ€§èƒ½æµ‹è¯•ABçš„ä½¿ç”¨SQLslapçš„ä½¿ç”¨sysbenchçš„ä½¿ç”¨è‡ªåŠ¨åŒ–æµ‹è¯•ä½¿ç”¨Shellå’ŒPythonè¿›è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•ä½¿ç”¨Seleniumå®ç°è‡ªåŠ¨åŒ–æµ‹è¯•Selenium IDESelenium WebDriverSelenium Remote Controlæµ‹è¯•å·¥å…·Robot Frameworkä»‹ç»ç¬¬97å¤©ï¼šç”µå•†ç½‘ç«™æŠ€æœ¯è¦ç‚¹å‰–æç¬¬98å¤©ï¼šé¡¹ç›®éƒ¨ç½²ä¸Šçº¿å’Œæ€§èƒ½è°ƒä¼˜MySQLæ•°æ®åº“è°ƒä¼˜WebæœåŠ¡å™¨æ€§èƒ½ä¼˜åŒ–Nginxè´Ÿè½½å‡è¡¡é…ç½®Keepalivedå®ç°é«˜å¯ç”¨ä»£ç æ€§èƒ½è°ƒä¼˜å¤šçº¿ç¨‹å¼‚æ­¥åŒ–é™æ€èµ„æºè®¿é—®ä¼˜åŒ–äº‘å­˜å‚¨CDNç¬¬99å¤©ï¼šé¢è¯•ä¸­çš„å…¬å…±é—®é¢˜ç¬¬100å¤©ï¼šPythoné¢è¯•é¢˜å®å½•"
11,google/it-cert-automation-practice,https://github.com/google/it-cert-automation-practice/blob/master/README.md,Python,Google IT Automation with Python Professional Certificate - Practice filesThis repository contains the practice files used throughout the courses that arepart of the Google IT Automation with Python Professional CertificateThere's a separate folder for each course.
12,Significant-Gravitas/Auto-GPT,https://github.com/Significant-Gravitas/Auto-GPT/blob/master/README.md,Python,"Auto-GPT: An Autonomous GPT-4 ExperimentğŸ’¡ Get help - Q&A or Discord ğŸ’¬ğŸ”´ USE stable not master ğŸ”´Download the latest stable release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.The master branch is under heavy development and may often be in a broken state.Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \""thoughts\"", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI. Demo April 16th 2023               AutoGPTDemo_Subs_WithoutFinalScreen.mp4          Demo made by Blake WerlingerğŸš€ FeaturesğŸŒ Internet access for searches and information gatheringğŸ’¾ Long-term and short-term memory managementğŸ§  GPT-4 instances for text generationğŸ”— Access to popular websites and platformsğŸ—ƒï¸ File storage and summarization with GPT-3.5ğŸ”Œ Extensibility with PluginsQuickstartCheck out the wikiGet an OpenAI API KeyDownload the latest releaseFollow the installation instructionsConfigure any additional features you want, or install some pluginsRun the appPlease see the documentation for full setup instructions and configuration options.ğŸ“– Documentationâš™ï¸ SetupğŸ’» UsageğŸ”Œ PluginsConfigurationğŸ” Web SearchğŸ§  MemoryğŸ—£ï¸ Voice (TTS)ğŸ–¼ï¸ Image Generation ğŸ’– Help Fund Auto-GPT's Development ğŸ’–If you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help to push the boundaries of fully autonomous AI!Your support is greatly appreciated. Development of this free, open-source project is made possible by all the contributors and sponsors. If you'd like to sponsor this project and have your avatar or company logo appear below click here.                Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âš ï¸ LimitationsThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:Not a polished application or product, just an experimentMay not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!Quite expensive to run, so set and monitor your API key limits with OpenAI!ğŸ›¡ DisclaimerThis project, Auto-GPT, is an experimental application and is provided \""as-is\"" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.The developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.Please note that the use of the GPT-4 language model can be expensive due to its token usage. By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.As an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.By using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.ğŸ¦ Connect with Us on TwitterStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.Developer: Follow @siggravitas for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!        "
13,keras-team/keras,https://github.com/keras-team/keras/blob/master/README.md,Python,"Keras: Deep Learning for humansThis repository hosts the development of the Keras library.Read the documentation at keras.io.About KerasKeras is a deep learning API written in Python,running on top of the machine learning platform TensorFlow.It was developed with a focus on enabling fast experimentation andproviding a delightful developer experience.The purpose of Keras is to give an unfair advantage to any developer looking to ship ML-powered apps.Keras is:Simple -- but not simplistic. Keras reduces developer cognitive loadto free you to focus on the parts of the problem that really matter.Keras focuses on ease of use, debugging speed, code elegance & conciseness,maintainability, and deployability (via TFServing, TFLite, TF.js).Flexible -- Keras adopts the principle of progressive disclosure ofcomplexity: simple workflows should be quick and easy, while arbitrarilyadvanced workflows should be possible via a clear path that builds uponwhat you've already learned.Powerful -- Keras provides industry-strength performance andscalability: it is used by organizations and companies including NASA,YouTube, and Waymo. That's right -- your YouTube recommendations arepowered by Keras, and so is the world's most advanced driverless vehicle.Keras & TensorFlow 2TensorFlow 2 is an end-to-end, open-source machine learning platform.You can think of it as an infrastructure layer fordifferentiable programming.It combines four key abilities:Efficiently executing low-level tensor operations on CPU, GPU, or TPU.Computing the gradient of arbitrary differentiable expressions.Scaling computation to many devices, such as clusters of hundreds of GPUs.Exporting programs (\""graphs\"") to external runtimes such as servers, browsers, mobile and embedded devices.Keras is the high-level API of TensorFlow 2: an approachable, highly-productive interfacefor solving machine learning problems,with a focus on modern deep learning. It provides essential abstractions and building blocks for developingand shipping machine learning solutions with high iteration velocity.Keras empowers engineers and researchers to take full advantage of the scalabilityand cross-platform capabilities of TensorFlow 2: you can run Keras on TPU or on large clusters of GPUs,and you can export your Keras models to run in the browser or on a mobile device.First contact with KerasThe core data structures of Keras are layers and models.The simplest type of model is the Sequential model, a linear stack of layers.For more complex architectures, you should use the Keras functional API,which allows you to build arbitrary graphs of layers or write models entirely from scratch via subclassing.Here is the Sequential model:from tensorflow.keras.models import Sequentialmodel = Sequential()Stacking layers is as easy as .add():from tensorflow.keras.layers import Densemodel.add(Dense(units=64, activation='relu'))model.add(Dense(units=10, activation='softmax'))Once your model looks good, configure its learning process with .compile():model.compile(loss='categorical_crossentropy',              optimizer='sgd',              metrics=['accuracy'])If you need to, you can further configure your optimizer. The Keras philosophy is to keep simple things simple,while allowing the user to be fully in control when they need to be (the ultimate control being the easy extensibility of the source code via subclassing).model.compile(loss=tf.keras.losses.categorical_crossentropy,              optimizer=tf.keras.optimizers.SGD(                  learning_rate=0.01, momentum=0.9, nesterov=True))You can now iterate on your training data in batches:# x_train and y_train are Numpy arrays.model.fit(x_train, y_train, epochs=5, batch_size=32)Evaluate your test loss and metrics in one line:loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)Or generate predictions on new data:classes = model.predict(x_test, batch_size=128)What you just saw is the most elementary way to use Keras.However, Keras is also a highly-flexible framework suitable to iterate on state-of-the-art research ideas.Keras follows the principle of progressive disclosure of complexity: it makes it easy to get started,yet it makes it possible to handle arbitrarily advanced use cases,only requiring incremental learning at each step.In pretty much the same way that you were able to train & evaluate a simple neural network above in a few lines,you can use Keras to quickly develop new training procedures or exotic model architectures.Here's a low-level training loop example, combining Keras functionality with the TensorFlow GradientTape:import tensorflow as tf# Prepare an optimizer.optimizer = tf.keras.optimizers.Adam()# Prepare a loss function.loss_fn = tf.keras.losses.kl_divergence# Iterate over the batches of a dataset.for inputs, targets in dataset:    # Open a GradientTape.    with tf.GradientTape() as tape:        # Forward pass.        predictions = model(inputs)        # Compute the loss value for this batch.        loss_value = loss_fn(targets, predictions)    # Get gradients of loss wrt the weights.    gradients = tape.gradient(loss_value, model.trainable_weights)    # Update the weights of the model.    optimizer.apply_gradients(zip(gradients, model.trainable_weights))For more in-depth tutorials about Keras, you can check out:Introduction to Keras for engineersIntroduction to Keras for researchersDeveloper guidesOther learning resourcesInstallationKeras comes packaged with TensorFlow 2 as tensorflow.keras.To start using Keras, simply install TensorFlow 2.You can then import Keras as follows:from tensorflow import kerasRelease and compatibilityKeras has nightly releases (keras-nightly on PyPI)and stable releases (keras on PyPI).The nightly Keras releases are usually compatible with the corresponding versionof the tf-nightly releases(e.g. keras-nightly==2.7.0.dev2021100607 should beused with tf-nightly==2.7.0.dev2021100607).We don't maintain backward compatibility for nightly releases.For stable releases, each Kerasversion maps to a specific stable version of TensorFlow.The table below shows the compatibility version mappingbetween TensorFlow versions and Keras versions.All the release branches can be found on GitHub.All the release binaries can be found on Pypi.SupportYou can ask questions and join the development discussion:In the TensorFlow forum.On the Keras mailing list.Opening an issueYou can also post bug reports and feature requests (only)in GitHub issues.Opening a PRWe welcome contributions! Before opening a PR, please readour contributor guide,and the API design guideline."
14,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
15,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.âš ï¸ IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!âš ï¸ IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means youâ€™ve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the projectâ€™s direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a projectâ€™s website for a â€œteamâ€ page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participantsâ€™ behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, â€œHow do Iâ€¦â€œ or â€œWhat do you think aboutâ€¦â€œ instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
16,open-mmlab/mmdetection,https://github.com/open-mmlab/mmdetection/blob/main/README.md,Python,"    Â       OpenMMLab website                  HOT              Â Â Â Â     OpenMMLab platform                  TRY IT OUT              Â ğŸ“˜Documentation |ğŸ› ï¸Installation |ğŸ‘€Model Zoo |ğŸ†•Update News |ğŸš€Ongoing Projects |ğŸ¤”Reporting IssuesEnglish | ç®€ä½“ä¸­æ–‡                                              IntroductionMMDetection is an open source object detection toolbox based on PyTorch. It isa part of the OpenMMLab project.The main branch works with PyTorch 1.8+.Major featuresModular DesignWe decompose the detection framework into different components and one can easily construct a customized object detection framework by combining different modules.Support of multiple tasks out of boxThe toolbox directly supports multiple detection tasks such as object detection, instance segmentation, panoptic segmentation, and semi-supervised object detection.High efficiencyAll basic bbox and mask operations run on GPUs. The training speed is faster than or comparable to other codebases, including Detectron2, maskrcnn-benchmark and SimpleDet.State of the artThe toolbox stems from the codebase developed by the MMDet team, who won COCO Detection Challenge in 2018, and we keep pushing it forward.The newly released RTMDet also obtains new state-of-the-art results on real-time instance segmentation and rotated object detection tasks and the best parameter-accuracy trade-off on object detection.Apart from MMDetection, we also released MMEngine for model training and MMCV for computer vision research, which are heavily depended on by this toolbox.What's NewHighlightWe are excited to announce our latest work on real-time object recognition tasks, RTMDet, a family of fully convolutional single-stage detectors. RTMDet not only achieves the best parameter-accuracy trade-off on object detection from tiny to extra-large model sizes but also obtains new state-of-the-art performance on instance segmentation and rotated object detection tasks. Details can be found in the technical report. Pre-trained models are here.TaskDatasetAPFPS(TRT FP16 BS1 3090)Object DetectionCOCO52.8322Instance SegmentationCOCO44.6188Rotated Object DetectionDOTA78.9(single-scale)/81.3(multi-scale)121v3.1.0 was released in 30/6/2023:Supports tracking algorithms including multi-object tracking (MOT) algorithms SORT, DeepSORT, StrongSORT, OCSORT, ByteTrack, QDTrack, and video instance segmentation (VIS) algorithm MaskTrackRCNN, Mask2Former-VIS.Support ViTDetSupports inference and evaluation of multimodal algorithms GLIP and XDecoder, and also supports datasets such as COCO semantic segmentation, COCO Caption, ADE20k general segmentation, and RefCOCO. GLIP fine-tuning will be supported in the future.Provides a gradio demo for image type tasks of MMDetection, making it easy for users to experience.InstallationPlease refer to Installation for installation instructions.Getting StartedPlease see Overview for the general introduction of MMDetection.For detailed user guides and advanced guides, please refer to our documentation:User GuidesTrain & TestLearn about ConfigsInference with existing modelsDataset PrepareTest existing models on standard datasetsTrain predefined models on standard datasetsTrain with customized datasetsTrain with customized models and standard datasetsFinetuning ModelsTest Results SubmissionWeight initializationUse a single stage detector as RPNSemi-supervised Object DetectionUseful ToolsAdvanced GuidesBasic ConceptsComponent CustomizationHow toWe also provide object detection colab tutorial  and instance segmentation colab tutorial .To migrate from MMDetection 2.x, please refer to migration.Overview of Benchmark and Model ZooResults and models are available in the model zoo.  Architectures                    Object Detection                    Instance Segmentation                    Panoptic Segmentation                    Other                                        Fast R-CNN (ICCV'2015)            Faster R-CNN (NeurIPS'2015)            RPN (NeurIPS'2015)            SSD (ECCV'2016)            RetinaNet (ICCV'2017)            Cascade R-CNN (CVPR'2018)            YOLOv3 (ArXiv'2018)            CornerNet (ECCV'2018)            Grid R-CNN (CVPR'2019)            Guided Anchoring (CVPR'2019)            FSAF (CVPR'2019)            CenterNet (CVPR'2019)            Libra R-CNN (CVPR'2019)            TridentNet (ICCV'2019)            FCOS (ICCV'2019)            RepPoints (ICCV'2019)            FreeAnchor (NeurIPS'2019)            CascadeRPN (NeurIPS'2019)            Foveabox (TIP'2020)            Double-Head R-CNN (CVPR'2020)            ATSS (CVPR'2020)            NAS-FCOS (CVPR'2020)            CentripetalNet (CVPR'2020)            AutoAssign (ArXiv'2020)            Side-Aware Boundary Localization (ECCV'2020)            Dynamic R-CNN (ECCV'2020)            DETR (ECCV'2020)            PAA (ECCV'2020)            VarifocalNet (CVPR'2021)            Sparse R-CNN (CVPR'2021)            YOLOF (CVPR'2021)            YOLOX (CVPR'2021)            Deformable DETR (ICLR'2021)            TOOD (ICCV'2021)            DDOD (ACM MM'2021)            RTMDet (ArXiv'2022)            Conditional DETR (ICCV'2021)            DAB-DETR (ICLR'2022)            DINO (ICLR'2023)            GLIP (CVPR'2022)            DiffusionDet (ArXiv'2023)            EfficientDet (CVPR'2020)            Detic (ECCV'2022)                                    Mask R-CNN (ICCV'2017)          Cascade Mask R-CNN (CVPR'2018)          Mask Scoring R-CNN (CVPR'2019)          Hybrid Task Cascade (CVPR'2019)          YOLACT (ICCV'2019)          InstaBoost (ICCV'2019)          SOLO (ECCV'2020)          PointRend (CVPR'2020)          DetectoRS (ArXiv'2020)          SOLOv2 (NeurIPS'2020)          SCNet (AAAI'2021)          QueryInst (ICCV'2021)          Mask2Former (ArXiv'2021)          CondInst (ECCV'2020)          SparseInst (CVPR'2022)          RTMDet (ArXiv'2022)          BoxInst (CVPR'2021)                                      Panoptic FPN (CVPR'2019)          MaskFormer (NeurIPS'2021)          Mask2Former (ArXiv'2021)                                      Contrastive Learning                          SwAV (NeurIPS'2020)          MoCo (CVPR'2020)          MoCov2 (ArXiv'2020)                                  Distillation                          Localization Distillation (CVPR'2022)          Label Assignment Distillation (WACV'2022)                          Semi-Supervised Object Detection                          Soft Teacher (ICCV'2021)                                        Components                    Backbones                    Necks                    Loss                    Common                                  VGG (ICLR'2015)        ResNet (CVPR'2016)        ResNeXt (CVPR'2017)        MobileNetV2 (CVPR'2018)        HRNet (CVPR'2019)        Generalized Attention (ICCV'2019)        GCNet (ICCVW'2019)        Res2Net (TPAMI'2020)        RegNet (CVPR'2020)        ResNeSt (ArXiv'2020)        PVT (ICCV'2021)        Swin (CVPR'2021)        PVTv2 (ArXiv'2021)        ResNet strikes back (ArXiv'2021)        EfficientNet (ArXiv'2021)        ConvNeXt (CVPR'2022)        ConvNeXtv2 (ArXiv'2023)                                PAFPN (CVPR'2018)        NAS-FPN (CVPR'2019)        CARAFE (ICCV'2019)        FPG (ArXiv'2020)        GRoIE (ICPR'2020)        DyHead (CVPR'2021)                                    GHM (AAAI'2019)          Generalized Focal Loss (NeurIPS'2020)          Seasaw Loss (CVPR'2021)                                      OHEM (CVPR'2016)          Group Normalization (ECCV'2018)          DCN (ICCV'2017)          DCNv2 (CVPR'2019)          Weight Standardization (ArXiv'2019)          Prime Sample Attention (CVPR'2020)          Strong Baselines (CVPR'2021)          Resnet strikes back (ArXiv'2021)                        Some other methods are also supported in projects using MMDetection.FAQPlease refer to FAQ for frequently asked questions.ContributingWe appreciate all contributions to improve MMDetection. Ongoing projects can be found in out GitHub Projects. Welcome community users to participate in these projects. Please refer to CONTRIBUTING.md for the contributing guideline.AcknowledgementMMDetection is an open source project that is contributed by researchers and engineers from various colleges and companies. We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks.We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new detectors.CitationIf you use this toolbox or benchmark in your research, please cite this project.@article{mmdetection,  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},  journal= {arXiv preprint arXiv:1906.07155},  year={2019}}LicenseThis project is released under the Apache 2.0 license.Projects in OpenMMLabMMEngine: OpenMMLab foundational library for training deep learning models.MMCV: OpenMMLab foundational library for computer vision.MMPreTrain: OpenMMLab pre-training toolbox and benchmark.MMagic: OpenMMLab Advanced, Generative and Intelligent Creation toolbox.MMDetection: OpenMMLab detection toolbox and benchmark.MMDetection3D: OpenMMLab's next-generation platform for general 3D object detection.MMRotate: OpenMMLab rotated object detection toolbox and benchmark.MMYOLO: OpenMMLab YOLO series toolbox and benchmark.MMSegmentation: OpenMMLab semantic segmentation toolbox and benchmark.MMOCR: OpenMMLab text detection, recognition, and understanding toolbox.MMPose: OpenMMLab pose estimation toolbox and benchmark.MMHuman3D: OpenMMLab 3D human parametric model toolbox and benchmark.MMSelfSup: OpenMMLab self-supervised learning toolbox and benchmark.MMRazor: OpenMMLab model compression toolbox and benchmark.MMFewShot: OpenMMLab fewshot learning toolbox and benchmark.MMAction2: OpenMMLab's next-generation action understanding toolbox and benchmark.MMTracking: OpenMMLab video perception toolbox and benchmark.MMFlow: OpenMMLab optical flow toolbox and benchmark.MMEditing: OpenMMLab image and video editing toolbox.MMGeneration: OpenMMLab image and video generative models toolbox.MMDeploy: OpenMMLab model deployment framework.MIM: MIM installs OpenMMLab packages.MMEval: A unified evaluation library for multiple machine learning libraries.Playground: A central hub for gathering and showcasing amazing projects built upon OpenMMLab."
17,hankcs/HanLP,https://github.com/hankcs/HanLP/blob/master/README.md,Python,"HanLP: Han Language Processing                                                                                   ä¸­æ–‡ |    æ—¥æœ¬èª |    Docs |    ForumThe multilingual NLP library for researchers and companies, built on PyTorch and TensorFlow 2.x, for advancingstate-of-the-art deep learning techniques in both academia and industry. HanLP was designed from day one to beefficient, user-friendly and extendable.Thanks to open-access corpora like Universal Dependencies and OntoNotes, HanLP 2.1 now offers 10 joint tasks on 130languages: tokenization, lemmatization, part-of-speech tagging, token feature extraction, dependency parsing,constituency parsing, semantic role labeling, semantic dependency parsing, abstract meaning representation (AMR)parsing.For end users, HanLP offers light-weighted RESTful APIs and native Python APIs.RESTful APIsTiny packages in several KBs for agile development and mobile applications. Although anonymous users are welcomed, anauth key is suggestedand a free one can be applied here underthe CC BY-NC-SA 4.0 license.  Click to expand tutorials for RESTful APIsPythonpip install hanlp_restfulCreate a client with our API endpoint and your auth.from hanlp_restful import HanLPClientHanLP = HanLPClient('https://hanlp.hankcs.com/api', auth=None, language='mul') # mul: multilingual, zh: ChineseJavaInsert the following dependency into your pom.xml.<dependency>  <groupId>com.hankcs.hanlp.restful</groupId>  <artifactId>hanlp-restful</artifactId>  <version>0.0.15</version></dependency>Create a client with our API endpoint and your auth.HanLPClient HanLP = new HanLPClient(\""https://hanlp.hankcs.com/api\"", null, \""mul\""); // mul: multilingual, zh: ChineseQuick StartNo matter which language you use, the same interface can be used to parse a document.HanLP.parse(    \""In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments. 2021å¹´ã€HanLPv2.1ã¯æ¬¡ä¸–ä»£ã®æœ€å…ˆç«¯å¤šè¨€èªNLPæŠ€è¡“ã‚’æœ¬ç•ªç’°å¢ƒã«å°å…¥ã—ã¾ã™ã€‚2021å¹´ HanLPv2.1ä¸ºç”Ÿäº§ç¯å¢ƒå¸¦æ¥æ¬¡ä¸–ä»£æœ€å…ˆè¿›çš„å¤šè¯­ç§NLPæŠ€æœ¯ã€‚\"")See docs for visualization, annotation guidelines and more details.Native APIspip install hanlpHanLP requires Python 3.6 or later. GPU/TPU is suggested but not mandatory.Quick Startimport hanlpHanLP = hanlp.load(hanlp.pretrained.mtl.UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_XLMR_BASE)print(HanLP(['In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments.',             '2021å¹´ã€HanLPv2.1ã¯æ¬¡ä¸–ä»£ã®æœ€å…ˆç«¯å¤šè¨€èªNLPæŠ€è¡“ã‚’æœ¬ç•ªç’°å¢ƒã«å°å…¥ã—ã¾ã™ã€‚',             '2021å¹´ HanLPv2.1ä¸ºç”Ÿäº§ç¯å¢ƒå¸¦æ¥æ¬¡ä¸–ä»£æœ€å…ˆè¿›çš„å¤šè¯­ç§NLPæŠ€æœ¯ã€‚']))In particular, the Python HanLPClient can also be used as a callable function following the same semantics.See docs for visualization, annotation guidelines and more details.To process Chinese or Japanese, HanLP provides mono-lingual models in each language which significantly outperform themulti-lingual model. See docs for the list of models.Train Your Own ModelsTo write DL models is not hard, the real hard thing is to write a model able to reproduce the scores in papers. Thesnippet below shows how to surpass the state-of-the-art tokenizer in 6 minutes.tokenizer = TransformerTaggingTokenizer()save_dir = 'data/model/cws/sighan2005_pku_bert_base_96.7'tokenizer.fit(    SIGHAN2005_PKU_TRAIN_ALL,    SIGHAN2005_PKU_TEST,  # Conventionally, no devset is used. See Tian et al. (2020).    save_dir,    'bert-base-chinese',    max_seq_len=300,    char_level=True,    hard_constraint=True,    sampler_builder=SortingSamplerBuilder(batch_size=32),    epochs=3,    adam_epsilon=1e-6,    warmup_steps=0.1,    weight_decay=0.01,    word_dropout=0.1,    seed=1660853059,)tokenizer.evaluate(SIGHAN2005_PKU_TEST, save_dir)The result is guaranteed to be 96.73 as the random seed is fixed. Different from some overclaiming papers andprojects, HanLP promises every single digit in our scores is reproducible. Any issues on reproducibility will be treatedand solved as a top-priority fatal bug.PerformanceThe performance of multi-task learning models is shown in the following table.langcorporamodeltokposnerdepconsrlsdplemfeaamrfinecoarsectbpku863udpkumsraontonotesSemEval16DMPASPSDmulUD2.7OntoNotes5small98.62----93.23--74.4279.1076.8570.63-91.1993.6785.3487.7184.51-base98.97----90.32--80.3278.7471.2373.63-92.6096.0481.1985.0882.13-zhopensmall97.25-96.66-----95.0084.5787.6273.4084.57------base97.50-97.07-----96.0487.1189.8477.7887.11------closesmall96.7095.9396.8797.5695.05-96.2295.7476.7984.4488.1375.8174.28------base97.5296.4496.9997.5995.29-96.4895.7277.7785.2988.5776.5273.76------ernie96.9597.2996.7697.6495.22-97.3196.4777.9585.6789.1778.5174.10------Multi-task learning models often under-perform their single-task learning counterparts according to our latestresearch. Similarly, mono-lingual models often outperform multi-lingual models. Therefore, we strongly recommend theuse of a single-task mono-lingual model if you aretargeting at high accuracy instead of faster speed.A state-of-the-art AMR model has been released.CitingIf you use HanLP in your research, please cite this repository.@inproceedings{he-choi-2021-stem,    title = \""The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders\"",    author = \""He, Han and Choi, Jinho D.\"",    booktitle = \""Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\"",    month = nov,    year = \""2021\"",    address = \""Online and Punta Cana, Dominican Republic\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://aclanthology.org/2021.emnlp-main.451\"",    pages = \""5555--5577\"",    abstract = \""Multi-task learning with transformer encoders (MTL) has emerged as a powerful technique to improve performance on closely-related tasks for both accuracy and efficiency while a question still remains whether or not it would perform as well on tasks that are distinct in nature. We first present MTL results on five NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over single-task learning. We then conduct an extensive pruning analysis to show that a certain set of attention heads get claimed by most tasks during MTL, who interfere with one another to fine-tune those heads for their own objectives. Based on this finding, we propose the Stem Cell Hypothesis to reveal the existence of attention heads naturally talented for many tasks that cannot be jointly trained to create adequate embeddings for all of those tasks. Finally, we design novel parameter-free probes to justify our hypothesis and demonstrate how attention heads are transformed across the five tasks during MTL through label analysis.\"",}LicenseCodesHanLP is licensed under Apache License 2.0. You can use HanLP in your commercial products for free. We wouldappreciate it if you add a link to HanLP on your website.ModelsUnless otherwise specified, all models in HanLP are licensedunder  CC BY-NC-SA 4.0.Referenceshttps://hanlp.hankcs.com/docs/references.html"
18,XX-net/XX-Net,https://github.com/XX-net/XX-Net/blob/master/README.md,Python,"ğŸš€ XX-Net (ç¿»å¢™VPN)è¿™æ˜¯ä¸€ä¸ªå¯é çš„ç¿»å¢™ç³»ç»Ÿï¼Œå·²ç»è¿ç»­è¿è¡Œ 8 å¹´ï¼æˆ‘ä»¬ä¸å»ç ”ç©¶å¢™æœ‰ä»€ä¹ˆç¼ºé™·ï¼Œå› ä¸ºæ‰€æœ‰çš„ç¼ºé™·éƒ½ä¼šè¢«æ…¢æ…¢çš„è¡¥ä¸Šã€‚æˆ‘ä»¬çš„ç­–ç•¥æ˜¯åŒ–èº«ä¸ºæ™®é€šæµé‡ï¼Œå®Œå…¨æ— æ³•åŒºåˆ†ï¼Œæœ€ç»ˆéšèº«åœ¨èŒ«èŒ«çš„ç½‘ç»œè¿æ¥ä¸­ã€‚ã€‚ã€‚ğŸ”Œ åŠŸèƒ½ç‰¹æ€§æ”¯æŒå¤šå¹³å°ï¼š Android/iOS/Windows/Mac/Linuxé‡‡ç”¨ç‹¬ç‰¹çš„æ··æ·†ç®—æ³•ï¼Œè®©æ‚¨çš„æµé‡åœ¨ç½‘ç»œä¸­æ— æ³•è¢«è¯†åˆ«å¼€æºç»¿è‰²è½¯ä»¶ï¼Œæ— éœ€å®‰è£…ï¼Œå¯ä»¥æ”¯æŒå¤šå°è®¾å¤‡åŒæ—¶è¿æ¥æ¨¡æ‹ŸChromeæµè§ˆå™¨è¡Œä¸ºï¼Œå®Œå…¨æ— æ³•è¯†åˆ«ï¼Œç¨³å®šç¿»å¢™å†…ç½® ChatGPTï¼Œæ¯ä¸ªå¥—é¤èµ é€ ChatGPT-3.5 ä¸€ç™¾ä¸‡tokenå®˜ç½‘ä¸‹è½½: https://xx-net.comTelegram: https://t.me/xxnetshareTwitter: https://twitter.com/XXNetDevä¸­æ–‡å¸®åŠ©æ–‡æ¡£ Â  Â  Â English Document Â  Â  Â ÙØ§Ø±Ø³ÛŒ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒæœ€æ–°å…¬å‘Šï¼š2023-08-15æ–°ç‰ˆ 5.5.0, æå‡è¿æ¥æ€§èƒ½5.1.0ï¼Œå†…ç½®ChatGPTåŸæ¥æ˜¯4.x.x è€ç‰ˆæœ¬çš„ï¼Œéœ€è¦é‡æ–°ä¸‹è½½æ–°ç‰ˆå®‰è£…ï¼Œä¸èƒ½åº”ç”¨å†…å‡çº§ã€‚æç¤ºï¼šæœ‰é—®é¢˜è¯·å…ˆçœ‹Wikiæ–‡æ¡£æé—® å‰ï¼Œè¯·å…ˆçœ‹æœ€è¿‘è®¨è®ºä¸»é¢˜ ï¼Œé¿å…é‡å¤å‘é—®ã€‚"
19,floodsung/Deep-Learning-Papers-Reading-Roadmap,https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md,Python,"Deep Learning Papers Reading RoadmapIf you are a newcomer to the Deep Learning area, the first question you may have is \""Which paper should I start reading from?\""Here is a reading roadmap of Deep Learning papers!The roadmap is constructed in accordance with the following four guidelines:From outline to detailFrom old to state-of-the-artfrom generic to specific areasfocus on state-of-the-artYou will find many papers that are quite new but really worth reading.I would continue adding papers to this roadmap.1 Deep Learning History and Basics1.0 Book[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. \""Deep learning.\"" An MIT Press book. (2015). [html] (Deep Learning Bible, you can read this book while reading following papers.) â­â­â­â­â­1.1 Survey[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. \""Deep learning.\"" Nature 521.7553 (2015): 436-444. [pdf] (Three Giants' Survey) â­â­â­â­â­1.2 Deep Belief Network(DBN)(Milestone of Deep Learning Eve)[2] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. \""A fast learning algorithm for deep belief nets.\"" Neural computation 18.7 (2006): 1527-1554. [pdf](Deep Learning Eve) â­â­â­[3] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. \""Reducing the dimensionality of data with neural networks.\"" Science 313.5786 (2006): 504-507. [pdf] (Milestone, Show the promise of deep learning) â­â­â­1.3 ImageNet Evolutionï¼ˆDeep Learning broke out from hereï¼‰[4] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \""Imagenet classification with deep convolutional neural networks.\"" Advances in neural information processing systems. 2012. [pdf] (AlexNet, Deep Learning Breakthrough) â­â­â­â­â­[5] Simonyan, Karen, and Andrew Zisserman. \""Very deep convolutional networks for large-scale image recognition.\"" arXiv preprint arXiv:1409.1556 (2014). [pdf] (VGGNet,Neural Networks become very deep!) â­â­â­[6] Szegedy, Christian, et al. \""Going deeper with convolutions.\"" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [pdf] (GoogLeNet) â­â­â­[7] He, Kaiming, et al. \""Deep residual learning for image recognition.\"" arXiv preprint arXiv:1512.03385 (2015). [pdf] (ResNet,Very very deep networks, CVPR best paper) â­â­â­â­â­1.4 Speech Recognition Evolution[8] Hinton, Geoffrey, et al. \""Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups.\"" IEEE Signal Processing Magazine 29.6 (2012): 82-97. [pdf] (Breakthrough in speech recognition)â­â­â­â­[9] Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. \""Speech recognition with deep recurrent neural networks.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (RNN)â­â­â­[10] Graves, Alex, and Navdeep Jaitly. \""Towards End-To-End Speech Recognition with Recurrent Neural Networks.\"" ICML. Vol. 14. 2014. [pdf]â­â­â­[11] Sak, HaÅŸim, et al. \""Fast and accurate recurrent neural network acoustic models for speech recognition.\"" arXiv preprint arXiv:1507.06947 (2015). [pdf] (Google Speech Recognition System) â­â­â­[12] Amodei, Dario, et al. \""Deep speech 2: End-to-end speech recognition in english and mandarin.\"" arXiv preprint arXiv:1512.02595 (2015). [pdf] (Baidu Speech Recognition System) â­â­â­â­[13] W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig \""Achieving Human Parity in Conversational Speech Recognition.\"" arXiv preprint arXiv:1610.05256 (2016). [pdf] (State-of-the-art in speech recognition, Microsoft) â­â­â­â­After reading above papers, you will have a basic understanding of the Deep Learning history, the basic architectures of Deep Learning model(including CNN, RNN, LSTM) and how deep learning can be applied to image and speech recognition issues. The following papers will take you in-depth understanding of the Deep Learning method, Deep Learning in different areas of application and the frontiers. I suggest that you can choose the following papers based on your interests and research direction.#2 Deep Learning Method2.1 Model[14] Hinton, Geoffrey E., et al. \""Improving neural networks by preventing co-adaptation of feature detectors.\"" arXiv preprint arXiv:1207.0580 (2012). [pdf] (Dropout) â­â­â­[15] Srivastava, Nitish, et al. \""Dropout: a simple way to prevent neural networks from overfitting.\"" Journal of Machine Learning Research 15.1 (2014): 1929-1958. [pdf] â­â­â­[16] Ioffe, Sergey, and Christian Szegedy. \""Batch normalization: Accelerating deep network training by reducing internal covariate shift.\"" arXiv preprint arXiv:1502.03167 (2015). [pdf] (An outstanding Work in 2015) â­â­â­â­[17] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \""Layer normalization.\"" arXiv preprint arXiv:1607.06450 (2016). [pdf] (Update of Batch Normalization) â­â­â­â­[18] Courbariaux, Matthieu, et al. \""Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 orâˆ’1.\"" [pdf] (New Model,Fast)  â­â­â­[19] Jaderberg, Max, et al. \""Decoupled neural interfaces using synthetic gradients.\"" arXiv preprint arXiv:1608.05343 (2016). [pdf] (Innovation of Training Method,Amazing Work) â­â­â­â­â­[20] Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. \""Net2net: Accelerating learning via knowledge transfer.\"" arXiv preprint arXiv:1511.05641 (2015). [pdf] (Modify previously trained network to reduce training epochs) â­â­â­[21] Wei, Tao, et al. \""Network Morphism.\"" arXiv preprint arXiv:1603.01670 (2016). [pdf] (Modify previously trained network to reduce training epochs) â­â­â­2.2 Optimization[22] Sutskever, Ilya, et al. \""On the importance of initialization and momentum in deep learning.\"" ICML (3) 28 (2013): 1139-1147. [pdf] (Momentum optimizer) â­â­[23] Kingma, Diederik, and Jimmy Ba. \""Adam: A method for stochastic optimization.\"" arXiv preprint arXiv:1412.6980 (2014). [pdf] (Maybe used most often currently) â­â­â­[24] Andrychowicz, Marcin, et al. \""Learning to learn by gradient descent by gradient descent.\"" arXiv preprint arXiv:1606.04474 (2016). [pdf] (Neural Optimizer,Amazing Work) â­â­â­â­â­[25] Han, Song, Huizi Mao, and William J. Dally. \""Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding.\"" CoRR, abs/1510.00149 2 (2015). [pdf] (ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup) â­â­â­â­â­[26] Iandola, Forrest N., et al. \""SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size.\"" arXiv preprint arXiv:1602.07360 (2016). [pdf] (Also a new direction to optimize NN,DeePhi Tech Startup) â­â­â­â­[27] Glorat Xavier, Bengio Yoshua, et al. \""Understanding the difficulty of training deep forward neural networks.\"" Proceedings of the thirteenth International Conference on Artificial Intelligence and Statistics, PMLR 9:249-256,2010. [pdf] â­â­â­â­2.3 Unsupervised Learning / Deep Generative Model[28] Le, Quoc V. \""Building high-level features using large scale unsupervised learning.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (Milestone, Andrew Ng, Google Brain Project, Cat) â­â­â­â­[29] Kingma, Diederik P., and Max Welling. \""Auto-encoding variational bayes.\"" arXiv preprint arXiv:1312.6114 (2013). [pdf] (VAE) â­â­â­â­[30] Goodfellow, Ian, et al. \""Generative adversarial nets.\"" Advances in Neural Information Processing Systems. 2014. [pdf] (GAN,super cool idea) â­â­â­â­â­[31] Radford, Alec, Luke Metz, and Soumith Chintala. \""Unsupervised representation learning with deep convolutional generative adversarial networks.\"" arXiv preprint arXiv:1511.06434 (2015). [pdf] (DCGAN) â­â­â­â­[32] Gregor, Karol, et al. \""DRAW: A recurrent neural network for image generation.\"" arXiv preprint arXiv:1502.04623 (2015). [pdf] (VAE with attention, outstanding work) â­â­â­â­â­[33] Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. \""Pixel recurrent neural networks.\"" arXiv preprint arXiv:1601.06759 (2016). [pdf] (PixelRNN) â­â­â­â­[34] Oord, Aaron van den, et al. \""Conditional image generation with PixelCNN decoders.\"" arXiv preprint arXiv:1606.05328 (2016). [pdf] (PixelCNN) â­â­â­â­[34] S. Mehri et al., \""SampleRNN: An Unconditional End-to-End Neural Audio Generation Model.\"" arXiv preprint \tarXiv:1612.07837 (2016). [pdf] â­â­â­â­â­2.4 RNN / Sequence-to-Sequence Model[35] Graves, Alex. \""Generating sequences with recurrent neural networks.\"" arXiv preprint arXiv:1308.0850 (2013). [pdf] (LSTM, very nice generating result, show the power of RNN) â­â­â­â­[36] Cho, Kyunghyun, et al. \""Learning phrase representations using RNN encoder-decoder for statistical machine translation.\"" arXiv preprint arXiv:1406.1078 (2014). [pdf] (First Seq-to-Seq Paper) â­â­â­â­[37] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \""Sequence to sequence learning with neural networks.\"" Advances in neural information processing systems. 2014. [pdf] (Outstanding Work) â­â­â­â­â­[38] Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. \""Neural Machine Translation by Jointly Learning to Align and Translate.\"" arXiv preprint arXiv:1409.0473 (2014). [pdf] â­â­â­â­[39] Vinyals, Oriol, and Quoc Le. \""A neural conversational model.\"" arXiv preprint arXiv:1506.05869 (2015). [pdf] (Seq-to-Seq on Chatbot) â­â­â­2.5 Neural Turing Machine[40] Graves, Alex, Greg Wayne, and Ivo Danihelka. \""Neural turing machines.\"" arXiv preprint arXiv:1410.5401 (2014). [pdf] (Basic Prototype of Future Computer) â­â­â­â­â­[41] Zaremba, Wojciech, and Ilya Sutskever. \""Reinforcement learning neural Turing machines.\"" arXiv preprint arXiv:1505.00521 362 (2015). [pdf] â­â­â­[42] Weston, Jason, Sumit Chopra, and Antoine Bordes. \""Memory networks.\"" arXiv preprint arXiv:1410.3916 (2014). [pdf] â­â­â­[43] Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. \""End-to-end memory networks.\"" Advances in neural information processing systems. 2015. [pdf] â­â­â­â­[44] Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. \""Pointer networks.\"" Advances in Neural Information Processing Systems. 2015. [pdf] â­â­â­â­[45] Graves, Alex, et al. \""Hybrid computing using a neural network with dynamic external memory.\"" Nature (2016). [pdf] (Milestone,combine above papers' ideas) â­â­â­â­â­2.6 Deep Reinforcement Learning[46] Mnih, Volodymyr, et al. \""Playing atari with deep reinforcement learning.\"" arXiv preprint arXiv:1312.5602 (2013). [pdf]) (First Paper named deep reinforcement learning) â­â­â­â­[47] Mnih, Volodymyr, et al. \""Human-level control through deep reinforcement learning.\"" Nature 518.7540 (2015): 529-533. [pdf] (Milestone) â­â­â­â­â­[48] Wang, Ziyu, Nando de Freitas, and Marc Lanctot. \""Dueling network architectures for deep reinforcement learning.\"" arXiv preprint arXiv:1511.06581 (2015). [pdf] (ICLR best paper,great idea)  â­â­â­â­[49] Mnih, Volodymyr, et al. \""Asynchronous methods for deep reinforcement learning.\"" arXiv preprint arXiv:1602.01783 (2016). [pdf] (State-of-the-art method) â­â­â­â­â­[50] Lillicrap, Timothy P., et al. \""Continuous control with deep reinforcement learning.\"" arXiv preprint arXiv:1509.02971 (2015). [pdf] (DDPG) â­â­â­â­[51] Gu, Shixiang, et al. \""Continuous Deep Q-Learning with Model-based Acceleration.\"" arXiv preprint arXiv:1603.00748 (2016). [pdf] (NAF) â­â­â­â­[52] Schulman, John, et al. \""Trust region policy optimization.\"" CoRR, abs/1502.05477 (2015). [pdf] (TRPO) â­â­â­â­[53] Silver, David, et al. \""Mastering the game of Go with deep neural networks and tree search.\"" Nature 529.7587 (2016): 484-489. [pdf] (AlphaGo) â­â­â­â­â­2.7 Deep Transfer Learning / Lifelong Learning / especially for RL[54] Bengio, Yoshua. \""Deep Learning of Representations for Unsupervised and Transfer Learning.\"" ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [pdf] (A Tutorial) â­â­â­[55] Silver, Daniel L., Qiang Yang, and Lianghao Li. \""Lifelong Machine Learning Systems: Beyond Learning Algorithms.\"" AAAI Spring Symposium: Lifelong Machine Learning. 2013. [pdf] (A brief discussion about lifelong learning)  â­â­â­[56] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \""Distilling the knowledge in a neural network.\"" arXiv preprint arXiv:1503.02531 (2015). [pdf] (Godfather's Work) â­â­â­â­[57] Rusu, Andrei A., et al. \""Policy distillation.\"" arXiv preprint arXiv:1511.06295 (2015). [pdf] (RL domain) â­â­â­[58] Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. \""Actor-mimic: Deep multitask and transfer reinforcement learning.\"" arXiv preprint arXiv:1511.06342 (2015). [pdf] (RL domain) â­â­â­[59] Rusu, Andrei A., et al. \""Progressive neural networks.\"" arXiv preprint arXiv:1606.04671 (2016). [pdf] (Outstanding Work, A novel idea) â­â­â­â­â­2.8 One Shot Deep Learning[60] Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. \""Human-level concept learning through probabilistic program induction.\"" Science 350.6266 (2015): 1332-1338. [pdf] (No Deep Learning,but worth reading) â­â­â­â­â­[61] Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. \""Siamese Neural Networks for One-shot Image Recognition.\""(2015) [pdf] â­â­â­[62] Santoro, Adam, et al. \""One-shot Learning with Memory-Augmented Neural Networks.\"" arXiv preprint arXiv:1605.06065 (2016). [pdf] (A basic step to one shot learning) â­â­â­â­[63] Vinyals, Oriol, et al. \""Matching Networks for One Shot Learning.\"" arXiv preprint arXiv:1606.04080 (2016). [pdf] â­â­â­[64] Hariharan, Bharath, and Ross Girshick. \""Low-shot visual object recognition.\"" arXiv preprint arXiv:1606.02819 (2016). [pdf] (A step to large data) â­â­â­â­3 Applications3.1 NLP(Natural Language Processing)[1] Antoine Bordes, et al. \""Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing.\"" AISTATS(2012) [pdf] â­â­â­â­[2] Mikolov, et al. \""Distributed representations of words and phrases and their compositionality.\"" ANIPS(2013): 3111-3119 [pdf] (word2vec) â­â­â­[3] Sutskever, et al. \""â€œSequence to sequence learning with neural networks.\"" ANIPS(2014) [pdf] â­â­â­[4] Ankit Kumar, et al. \""â€œAsk Me Anything: Dynamic Memory Networks for Natural Language Processing.\"" arXiv preprint arXiv:1506.07285(2015) [pdf] â­â­â­â­[5] Yoon Kim, et al. \""Character-Aware Neural Language Models.\"" NIPS(2015) arXiv preprint arXiv:1508.06615(2015) [pdf] â­â­â­â­[6] Jason Weston, et al. \""Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.\"" arXiv preprint arXiv:1502.05698(2015) [pdf] (bAbI tasks) â­â­â­[7] Karl Moritz Hermann, et al. \""Teaching Machines to Read and Comprehend.\"" arXiv preprint arXiv:1506.03340(2015) [pdf] (CNN/DailyMail cloze style questions) â­â­[8] Alexis Conneau, et al. \""Very Deep Convolutional Networks for Natural Language Processing.\"" arXiv preprint arXiv:1606.01781(2016) [pdf] (state-of-the-art in text classification) â­â­â­[9] Armand Joulin, et al. \""Bag of Tricks for Efficient Text Classification.\"" arXiv preprint arXiv:1607.01759(2016) [pdf] (slightly worse than state-of-the-art, but a lot faster) â­â­â­3.2 Object Detection[1] Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. \""Deep neural networks for object detection.\"" Advances in Neural Information Processing Systems. 2013. [pdf] â­â­â­[2] Girshick, Ross, et al. \""Rich feature hierarchies for accurate object detection and semantic segmentation.\"" Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [pdf] (RCNN) â­â­â­â­â­[3] He, Kaiming, et al. \""Spatial pyramid pooling in deep convolutional networks for visual recognition.\"" European Conference on Computer Vision. Springer International Publishing, 2014. [pdf] (SPPNet) â­â­â­â­[4] Girshick, Ross. \""Fast r-cnn.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] â­â­â­â­[5] Ren, Shaoqing, et al. \""Faster R-CNN: Towards real-time object detection with region proposal networks.\"" Advances in neural information processing systems. 2015. [pdf] â­â­â­â­[6] Redmon, Joseph, et al. \""You only look once: Unified, real-time object detection.\"" arXiv preprint arXiv:1506.02640 (2015). [pdf] (YOLO,Oustanding Work, really practical) â­â­â­â­â­[7] Liu, Wei, et al. \""SSD: Single Shot MultiBox Detector.\"" arXiv preprint arXiv:1512.02325 (2015). [pdf] â­â­â­[8] Dai, Jifeng, et al. \""R-FCN: Object Detection viaRegion-based Fully Convolutional Networks.\"" arXiv preprint arXiv:1605.06409 (2016). [pdf] â­â­â­â­[9] He, Gkioxari, et al. \""Mask R-CNN\"" arXiv preprint arXiv:1703.06870 (2017). [pdf] â­â­â­â­[10] Bochkovskiy, Alexey, et al. \""YOLOv4: Optimal Speed and Accuracy of Object Detection.\""  arXiv preprint arXiv:2004.10934 (2020). [pdf] â­â­â­â­[11] Tan, Mingxing, et al. â€œEfficientDet: Scalable and Efficient Object Detection.\"" arXiv preprint arXiv:1911.09070 (2019). [pdf] â­â­â­â­â­3.3 Visual Tracking[1] Wang, Naiyan, and Dit-Yan Yeung. \""Learning a deep compact image representation for visual tracking.\"" Advances in neural information processing systems. 2013. [pdf] (First Paper to do visual tracking using Deep Learning,DLT Tracker) â­â­â­[2] Wang, Naiyan, et al. \""Transferring rich feature hierarchies for robust visual tracking.\"" arXiv preprint arXiv:1501.04587 (2015). [pdf] (SO-DLT) â­â­â­â­[3] Wang, Lijun, et al. \""Visual tracking with fully convolutional networks.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] (FCNT) â­â­â­â­[4] Held, David, Sebastian Thrun, and Silvio Savarese. \""Learning to Track at 100 FPS with Deep Regression Networks.\"" arXiv preprint arXiv:1604.01802 (2016). [pdf] (GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods) â­â­â­â­[5] Bertinetto, Luca, et al. \""Fully-Convolutional Siamese Networks for Object Tracking.\"" arXiv preprint arXiv:1606.09549 (2016). [pdf] (SiameseFC,New state-of-the-art for real-time object tracking) â­â­â­â­[6] Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. \""Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking.\"" ECCV (2016) [pdf] (C-COT) â­â­â­â­[7] Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. \""Modeling and Propagating CNNs in a Tree Structure for Visual Tracking.\"" arXiv preprint arXiv:1608.07242 (2016). [pdf] (VOT2016 Winner,TCNN) â­â­â­â­3.4 Image Caption[1] Farhadi,Ali,etal. \""Every picture tells a story: Generating sentences from images\"". In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. [pdf] â­â­â­[2] Kulkarni, Girish, et al. \""Baby talk: Understanding and generating image descriptions\"". In Proceedings of the 24th CVPR, 2011. [pdf]â­â­â­â­[3] Vinyals, Oriol, et al. \""Show and tell: A neural image caption generator\"". In arXiv preprint arXiv:1411.4555, 2014. [pdf]â­â­â­[4] Donahue, Jeff, et al. \""Long-term recurrent convolutional networks for visual recognition and description\"". In arXiv preprint arXiv:1411.4389 ,2014. [pdf][5] Karpathy, Andrej, and Li Fei-Fei. \""Deep visual-semantic alignments for generating image descriptions\"". In arXiv preprint arXiv:1412.2306, 2014. [pdf]â­â­â­â­â­[6] Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. \""Deep fragment embeddings for bidirectional image sentence mapping\"". In Advances in neural information processing systems, 2014. [pdf]â­â­â­â­[7] Fang, Hao, et al. \""From captions to visual concepts and back\"". In arXiv preprint arXiv:1411.4952, 2014. [pdf]â­â­â­â­â­[8] Chen, Xinlei, and C. Lawrence Zitnick. \""Learning a recurrent visual representation for image caption generation\"". In arXiv preprint arXiv:1411.5654, 2014. [pdf]â­â­â­â­[9] Mao, Junhua, et al. \""Deep captioning with multimodal recurrent neural networks (m-rnn)\"". In arXiv preprint arXiv:1412.6632, 2014. [pdf]â­â­â­[10] Xu, Kelvin, et al. \""Show, attend and tell: Neural image caption generation with visual attention\"". In arXiv preprint arXiv:1502.03044, 2015. [pdf]â­â­â­â­â­3.5 Machine TranslationSome milestone papers are listed in RNN / Seq-to-Seq topic.[1] Luong, Minh-Thang, et al. \""Addressing the rare word problem in neural machine translation.\"" arXiv preprint arXiv:1410.8206 (2014). [pdf] â­â­â­â­[2] Sennrich, et al. \""Neural Machine Translation of Rare Words with Subword Units\"". In arXiv preprint arXiv:1508.07909, 2015. [pdf]â­â­â­[3] Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. \""Effective approaches to attention-based neural machine translation.\"" arXiv preprint arXiv:1508.04025 (2015). [pdf] â­â­â­â­[4] Chung, et al. \""A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation\"". In arXiv preprint arXiv:1603.06147, 2016. [pdf]â­â­[5] Lee, et al. \""Fully Character-Level Neural Machine Translation without Explicit Segmentation\"". In arXiv preprint arXiv:1610.03017, 2016. [pdf]â­â­â­â­â­[6] Wu, Schuster, Chen, Le, et al. \""Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\"". In arXiv preprint arXiv:1609.08144v2, 2016. [pdf] (Milestone) â­â­â­â­3.6 Robotics[1] KoutnÃ­k, Jan, et al. \""Evolving large-scale neural networks for vision-based reinforcement learning.\"" Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [pdf] â­â­â­[2] Levine, Sergey, et al. \""End-to-end training of deep visuomotor policies.\"" Journal of Machine Learning Research 17.39 (2016): 1-40. [pdf] â­â­â­â­â­[3] Pinto, Lerrel, and Abhinav Gupta. \""Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours.\"" arXiv preprint arXiv:1509.06825 (2015). [pdf] â­â­â­[4] Levine, Sergey, et al. \""Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection.\"" arXiv preprint arXiv:1603.02199 (2016). [pdf] â­â­â­â­[5] Zhu, Yuke, et al. \""Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning.\"" arXiv preprint arXiv:1609.05143 (2016). [pdf] â­â­â­â­[6] Yahya, Ali, et al. \""Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search.\"" arXiv preprint arXiv:1610.00673 (2016). [pdf] â­â­â­â­[7] Gu, Shixiang, et al. \""Deep Reinforcement Learning for Robotic Manipulation.\"" arXiv preprint arXiv:1610.00633 (2016). [pdf] â­â­â­â­[8] A Rusu, M Vecerik, Thomas RothÃ¶rl, N Heess, R Pascanu, R Hadsell.\""Sim-to-Real Robot Learning from Pixels with Progressive Nets.\"" arXiv preprint arXiv:1610.04286 (2016). [pdf] â­â­â­â­[9] Mirowski, Piotr, et al. \""Learning to navigate in complex environments.\"" arXiv preprint arXiv:1611.03673 (2016). [pdf] â­â­â­â­3.7 Art[1] Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). \""Inceptionism: Going Deeper into Neural Networks\"". Google Research. [html] (Deep Dream)â­â­â­â­[2] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. \""A neural algorithm of artistic style.\"" arXiv preprint arXiv:1508.06576 (2015). [pdf] (Outstanding Work, most successful method currently) â­â­â­â­â­[3] Zhu, Jun-Yan, et al. \""Generative Visual Manipulation on the Natural Image Manifold.\"" European Conference on Computer Vision. Springer International Publishing, 2016. [pdf] (iGAN) â­â­â­â­[4] Champandard, Alex J. \""Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks.\"" arXiv preprint arXiv:1603.01768 (2016). [pdf] (Neural Doodle) â­â­â­â­[5] Zhang, Richard, Phillip Isola, and Alexei A. Efros. \""Colorful Image Colorization.\"" arXiv preprint arXiv:1603.08511 (2016). [pdf] â­â­â­â­[6] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. \""Perceptual losses for real-time style transfer and super-resolution.\"" arXiv preprint arXiv:1603.08155 (2016). [pdf] â­â­â­â­[7] Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. \""A learned representation for artistic style.\"" arXiv preprint arXiv:1610.07629 (2016). [pdf] â­â­â­â­[8] Gatys, Leon and Ecker, et al.\""Controlling Perceptual Factors in Neural Style Transfer.\"" arXiv preprint arXiv:1611.07865 (2016). [pdf] (control style transfer over spatial location,colour information and across spatial scale)â­â­â­â­[9] Ulyanov, Dmitry and Lebedev, Vadim, et al. \""Texture Networks: Feed-forward Synthesis of Textures and Stylized Images.\"" arXiv preprint arXiv:1603.03417(2016). [pdf] (texture generation and style transfer) â­â­â­â­[10] Yijun Li, Ming-Yu Liu ,Xueting Li, Ming-Hsuan Yang,Jan Kautz (NVIDIA). \""A Closed-form Solution to Photorealistic Image Stylization.\"" arXiv preprint arXiv:1802.06474(2018). [pdf] (Very fast and ultra realistic style transfer) â­â­â­â­3.8 Object Segmentation[1] J. Long, E. Shelhamer, and T. Darrell, â€œFully convolutional networks for semantic segmentation.â€ in CVPR, 2015. [pdf] â­â­â­â­â­[2] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. \""Semantic image segmentation with deep convolutional nets and fully connected crfs.\"" In ICLR, 2015. [pdf] â­â­â­â­â­[3] Pinheiro, P.O., Collobert, R., Dollar, P. \""Learning to segment object candidates.\"" In: NIPS. 2015. [pdf] â­â­â­â­[4] Dai, J., He, K., Sun, J. \""Instance-aware semantic segmentation via multi-task network cascades.\"" in CVPR. 2016 [pdf] â­â­â­[5] Dai, J., He, K., Sun, J. \""Instance-sensitive Fully Convolutional Networks.\"" arXiv preprint arXiv:1603.08678 (2016). [pdf] â­â­â­"
20,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
21,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        ç®€ä½“ä¸­æ–‡ |        ç¹é«”ä¸­æ–‡ |        í•œêµ­ì–´ |        EspaÃ±ol |        æ—¥æœ¬èª |        à¤¹à¤¿à¤¨à¥à¤¦à¥€        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    ğŸ¤— Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:ğŸ“ Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.ğŸ–¼ï¸ Images, for tasks like image classification, object detection, and segmentation.ğŸ—£ï¸ Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.ğŸ¤— Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.ğŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install ğŸ¤— Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, ğŸ¤— Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.ğŸ¤— Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by ğŸ¤— Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: ğŸ¤— Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from Ã‰cole polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz SuÃ¡rez*, Yoann Dupont, Laurent Romary, Ã‰ric Villemonte de la Clergerie, DjamÃ© Seddah and BenoÃ®t Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of GÃ¶ttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo LÃ¼ddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, HervÃ© JÃ©gou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp KrÃ¤henbÃ¼hl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, TimothÃ©e Darcet, ThÃ©o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, HervÃ© Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas OÄŸuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by RenÃ© Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre DÃ©fossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, LoÃ¯c Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, BenoÃ®t CrabbÃ©, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey Ã–hman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo GarcÃ­a del RÃ­o, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, HervÃ© JÃ©gou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by JÃ¶rg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre DÃ©fossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noahâ€™s Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NystrÃ¶mformer (from the University of Wisconsin - Madison) released with the paper NystrÃ¶mformer: A NystrÃ¶m-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier HÃ©naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, JoÃ£o Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, Åukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr DollÃ¡r.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault FÃ©vry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of WÃ¼rzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, PaweÅ‚ Krzysztof Nowak, Thomas MÃ¼ller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÃ¡r, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario LuÄiÄ‡, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper â€‹XLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the ğŸ¤— Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by ğŸ¤— TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by ğŸ¤— Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the ğŸ¤— Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
22,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answersâš ï¸ DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]ğŸ™ PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!ğŸ‰ AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.â“ Need help?Open new issueğŸ”¥ Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accountingâ—needs updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustratorâ—needs updating  7674Adobe-InDesignâ—needs updating  4240Adobe-Lightroomâ—needs updating  2020Adobe-Photoshopâ—needs updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effectsâ—needs updating  2413Agile Methodologiesâ—needs updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCADâ—needs updating  7775@djayorAutodesk Fusion 360â—needs updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambdaâ—needs updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++â—needs updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurityâ—needs updating10196Django7171@PROCW.NET Framework6359@declarckEclipseâ—needs updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSONâ—needs updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excelâ—needs updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Projectâ—needs updating4443Microsoft Wordâ—needs updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooksâ—needs updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revitâ—needs updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePointâ—needs updating5338Sketchup22SOLIDWORKSâ—needs updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnityâ—needs updating4746@uno-sebastianVisual Basic for Applications (VBA)â—needs updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors âœ¨Thanks goes to these wonderful people (emoji key):            EvgeniiğŸ’» ğŸ–‹      Sergei StadnikğŸ’» ğŸ” ğŸ¤” ğŸ“–      SanthoshğŸ’»      Jacob DsağŸ’» ğŸ–‹      Aaron MeeseğŸ’» ğŸ–‹      arqarqğŸ’» ğŸ–‹      Amit YadavğŸ’» ğŸ–‹              Javokhir NazarovğŸ’» ğŸ–‹      saurav kumarğŸ–‹      ChetanğŸ–‹      Amir Hossein ShekariğŸ¨ ğŸ–‹ ğŸ’»      SergDautğŸ¨      Nilotpal PramanikğŸ¨ ğŸ’» ğŸ–‹ ğŸ’¼ ğŸ“– ğŸ”£ ğŸ’¡      Abhishek KumarğŸ¨              Monu GuptağŸ¨      KARTIKEYA GUPTAğŸ’» ğŸ–‹      kenkyushağŸ’» ğŸ–‹      juandavidtowersğŸ’» ğŸ–‹      cyber-neticsğŸ’» ğŸ–‹      jtriswğŸ’» ğŸ–‹      Renato RegaladoğŸ’» ğŸ–‹              MatthewğŸ’» ğŸ–‹      Jan S.ğŸ’» ğŸ–‹      ManoliğŸ’» ğŸ–‹      Faraz tanveerğŸ’» ğŸ–‹      mohnishkarriğŸ’» ğŸ–‹ ğŸ¨      andyzhuğŸ’» ğŸ–‹      Vishal KushwahğŸ’» ğŸ–‹              Yurii YakymenkoğŸ’» ğŸ–‹      Swetabh SumanğŸ’» ğŸ–‹      AJAY DANDGEğŸ’» ğŸ–‹      Mehmet YesinğŸ¨      Lok Chun WaiğŸ¨      Adria de JuanğŸ¨      GL-ManğŸ¨              Jheel PatelğŸ¨      Sameer WaskarğŸ¨      Alexander AndrewsğŸ¨      Alexander MaxwellğŸ¨      SlavağŸ¨      Mayur KhatriğŸ¨      MascantoshğŸ’» ğŸ–‹ ğŸ“¢ ğŸ¤”              Kivanc EnesğŸ¨      Ritika DasğŸ¨      Zer07793ğŸ¨      Andrew CheungğŸ¨      SadhağŸ¨      tainenkoğŸ¨ ğŸ’»      github-star-coderğŸ¨              Danilo OliveirağŸ¨      lordekoğŸ¨      Shubham KumarğŸ¨ ğŸ’»      testtreeğŸ¨      Cheryl MurphyğŸ¨ ğŸ’»      Bipin ThomasğŸ¨      Abdulrahman HishamğŸ¨              Dakshitha DissanayakağŸ¨      BADR KACIMIğŸ¨      Alex WangğŸ¨      MaximğŸ¨      GordonGrantğŸ¨ ğŸ’»      Ephrem DemelashğŸ¨      JonOrcuttğŸ¨              topdev10ğŸ¨      cookwellwebsiteğŸ¨      xren935ğŸ¨      Nemo FrenkelğŸ¨      MD SAIF ALAMğŸ¨      Boris LÃ³pez ArayağŸ¨      Larry ChiemğŸ¨              Muhammad Bilal IlyasğŸ¨      AliMilaniğŸ¨ ğŸ’»      Suraj SahaniğŸ¨      FlyingSquirrelğŸ¨      Erick TijeroğŸ¨      Jaskaran KukrejağŸ¨      MichaelLğŸ¨              MagicLegendğŸ¨      Dereck BearsongğŸ¨      Pappu Kumar PashiğŸ¨      Venkata Kishore TavvağŸ¨      Rafat Touqir RafsunğŸ¨      Snehesh DuttağŸ¨      Timo KÃ¶rnerğŸ¨ ğŸ’»              alexxxanğŸ¨      GGJasonğŸ¨      LeeAnna EwingğŸ¨ ğŸ¤”      kamal JyotwalğŸ¨      Bob-JohnsğŸ¨ ğŸ’» ğŸ–‹      yunussalmanlyitğŸ¨ ğŸ’»      chilcotğŸ¨ ğŸ’»              Jacky LiğŸ’» ğŸ–‹ ğŸ¨      Sarthak TrivediğŸ¨      Ayush AggarwalğŸ¨ ğŸ’»      Nic BallariniğŸ¨      Luigi ZambettiğŸ¨ ğŸ’»      govindhaswinğŸ¨      Addy RoyğŸ’» ğŸ¨              Akshat TamrakarğŸ¨ ğŸ’»      Sai Bhargava RamuğŸ¨      GurkanğŸ’»      Spencer Hayes-LaverdiereğŸ’»      Aniket SoniğŸ’»      tanmay5792ğŸ’»      Dina TaklitğŸ’» ğŸ¨ ğŸ–‹              Dushyant SinghğŸ’»      Ravi Prakash SinghğŸ’»      Nihal JoshiğŸ’»      Guy KlagesğŸ’»      ArvindğŸ¨ ğŸ’»      mujeeb91ğŸ’»      josercağŸ¨ ğŸ’»              Prateek AgrawalğŸ’»      Teoh Tze Chuin(ã‚µãƒ©)ğŸ’» ğŸ¨      Jayant JainğŸ’»      Ayush SahuğŸ’»      Hridya Krishna RğŸ’» ğŸ¨      Rahul BaliğŸ’» ğŸ¨      S.ZHengğŸ¨ ğŸ’» ğŸ’¼              Shriya MadanğŸ¨ ğŸ’»      mahalrupiğŸ¨      Lucas LermagneğŸ¨      Jeff DeutschğŸ¨ ğŸ’»      Betoxx1ğŸ¨      Wingman4l7ğŸ¨      Martin EspericuetağŸ¨              Mh-TahirğŸ¨      Zdravko Å plajtğŸ¨ ğŸ’»      Ms3105ğŸ¨ ğŸ’» ğŸ–‹      Ambika SidheswareğŸ’»      mundogueroğŸ’»      Darkus24ğŸ–‹      Sou-786ğŸ–‹ ğŸ¨              BanurekhağŸ–‹      ShiraStarLğŸ¨      Ilya KomarovğŸ¨      DemigodMsğŸ–‹ ğŸ“–      Mekha HridyağŸ¨ ğŸ”      Andrey SafonovğŸ¨ ğŸ”      TommasoğŸ¨ ğŸ’»              Jessica SalbertğŸ’» ğŸ¨      JAYANTH DOLAIğŸ’» ğŸ¨      silverstroomğŸ’» ğŸ¨ ğŸ’¼      Furkan SayÄ±mğŸ’» ğŸ¨      Sukumar ChandrasekaranğŸ¨      Yejin ParkğŸ¨ ğŸ’»      Ali NooshabadiğŸ¨ ğŸ’»              imitavorğŸ¨ ğŸ’»      Salih KilicliğŸ¨ ğŸ’»      Marcelo MenesesğŸ¨ ğŸ’»      Anton KrekotunğŸ¨ ğŸš§ ğŸ–‹ ğŸ’» ğŸ“– ğŸ’¼      Arnav SarmağŸ’» ğŸ’¡ ğŸ¨      meghatikuğŸ’» ğŸ¨      Anshu TrivediğŸ¨              Taylor DorsettğŸ’» ğŸ–‹ ğŸ¨      Havit RovikğŸ’»      pushpapuneğŸ’» ğŸ¨      Ramtin RadfarğŸ¨ ğŸ¤” ğŸ’¼ ğŸ’µ ğŸ’» ğŸ–‹ ğŸ’¬      Abdulmajeed IsağŸ’» ğŸ¨      vikassaxena02ğŸ¨      RobTablesğŸ¨ ğŸ’» ğŸ’¼              DanielğŸ¨ ğŸ’» ğŸ’¼ ğŸ”      Zahid AliğŸ’» ğŸ¨      Chad ChaiğŸ’» ğŸ¨      Marco BiedermannğŸ’» ğŸ¨ ğŸ’¼ ğŸ¤”      Srinidhi MurthyğŸ¨      Miao CaiğŸ’» ğŸ¨      Dionicio DiazğŸ¨ ğŸ’»              Mir Monoarul AlamğŸ¨      Shawn OhnğŸ’» ğŸ¨      Amanbolat BalabekovğŸ¨ ğŸ’»      black-mamba-codeğŸ’»      Jian-forksğŸ¨ ğŸ’»      shivani patelğŸ¨      Akash ChowrasiağŸ¨              yairg98ğŸ¨      Jay GajjarğŸ¨      coolerboolerğŸ’»      Md Zinnatul Islam MorolğŸ¨      shresthashok550ğŸ¨ ğŸ“–      Alan PallathğŸ“–      Adrian WongğŸ’»              vsDizzyğŸ’» ğŸ¨      Frex CuadillerağŸ¨ ğŸ’»      ashish570ğŸ’» ğŸ¨      ruchpeanutsğŸ’» ğŸ¨      ArtmasqueğŸ¨ ğŸ’»      Amirhossein Mojiri ForoushaniğŸ¨      forğŸ’» ğŸ¨              LukeğŸ¨ ğŸ’»      Hector EspinozağŸ¨      AdriÃ¡n BuenfilğŸ¨ ğŸ’»      Amit KumarğŸ¨      schoppfeğŸ¨ ğŸ’»      Sofiyal CğŸ¨ ğŸ’»      spitliskğŸ’» ğŸ¨              PRAVIN SHARMAğŸ¨      NIDZAAA1ğŸ¨ ğŸ’»      John MaiğŸ¨ ğŸ’»      kimsoyeongğŸ¨      Dona GhoshğŸ’»      Ryan HillğŸ¨ ğŸ’»      j42zğŸ¨ ğŸ’»              Ashish SangaleğŸ¨ ğŸ’»      Derek YangğŸ¨ ğŸ’»      mohsinmsmğŸ¨ ğŸ’»      Gokulkrish2302ğŸ’»      BhaavishekğŸ’» ğŸ¨      Louis LiaoğŸ¨      sengc92ğŸ¨ ğŸ’»              Alex MarvinğŸ¨      Balkrishna BhattğŸ¨ ğŸ’»      Evaldas LavrinoviÄiusğŸ¨ ğŸ’»      Adam ErchegyiğŸ¨ ğŸ’»      Truman HungğŸ¨ ğŸ’»      rzamora11ğŸ¨      gaurav0224ğŸ¨              Lee GyeongJunğŸ¨      MirekğŸ¨ ğŸ’»      surajm245ğŸ¨      ArisLaodeğŸ¨ ğŸ’»      RaviDhoriyağŸ¨ ğŸ’»      sarai-84ğŸ¨ ğŸ’»      VishnuğŸ¨ ğŸ’»              Muhammad MinhajğŸ’»      Chandrika DebğŸ¨ ğŸ’»      Gitgit101-bitğŸ’» ğŸ¨      Hedi SellamiğŸ’» ğŸ¨      saurabhvaish93ğŸ’» ğŸ¨      Nikola BegovicğŸ’» ğŸ¨      WangğŸ’» ğŸ¨              Manuel Eusebio de Paz CarmonağŸ¨      Basim Al-JawaheryğŸ¨ ğŸ’»      RAJA AHMEDğŸ¨ ğŸ’»      Abhik LodhğŸ’»      Md. Pial AhamedğŸ’» ğŸ¨      Hassan ShahzadğŸ’» ğŸ¨      Christian Sosa GagoğŸ’»              Hasnain RasheedğŸ’» ğŸ¨      T-RadfordğŸ’»      dahiyashishğŸ’» ğŸ¨      RahulSharma468ğŸ’» ğŸ¨      Jumpod PlekhongthuğŸ’» ğŸ¨      Thomas Young-AudetğŸ’» ğŸ¨      VinayagamBabuğŸ’» ğŸ¨              Deniz KoÃ§ğŸ’» ğŸ¨      Azhar KhanğŸ’» ğŸ¨ ğŸ–‹ ğŸ“– ğŸ”£ ğŸš§      Jacob ShortğŸ’» ğŸ¨      Uchimura85ğŸ’» ğŸ¨      Leo NugrahağŸ’» ğŸ¨ ğŸ“–      Mujtaba MehdiğŸ“– ğŸ–‹      Jim-dsğŸ’» ğŸ¨              Sreehari KğŸ’» ğŸ¨      Florian MartinezğŸ’» ğŸ¨      AaronğŸ’» ğŸ¨      apoageğŸ¨      Ignacio Guillermo Martinez ğŸ’» ğŸ¨      AirlineDogğŸ¨ ğŸ’»      MekelğŸ¨ ğŸ’»              hmosharrofğŸ¨ ğŸ’»      Ben EmamianğŸ’» ğŸ¨      babesharkğŸ’» ğŸ¨      Leonardo JaquesğŸ’» ğŸ¨      Stefanos ApkarianğŸ’» ğŸ¨      Ayhan AlbayrakğŸ’» ğŸ¨      KidusMTğŸ’» ğŸ¨              hectormarroquin20ğŸ’» ğŸ¨      Edelweiss35ğŸ’» ğŸ¨      MihaiDğŸ’» ğŸ¨      AnveshReddyAnnemğŸ’» ğŸ¨      Hyunjae ParkğŸ’» ğŸ¨      Rajiv AlbinoğŸ’» ğŸ¨      AtishayğŸ’»              Yusuf NaheemğŸ¨      WinduğŸ¨ ğŸ’»      Superv1sorğŸ’» ğŸ¨      Karine (:ğŸ¨ ğŸ’»      Eduard PechğŸ¨ ğŸ’»      jjeshwaniğŸ¨ ğŸ’»      SteveğŸ¨ ğŸ’»              Aleigh OhslundğŸ’»      Abhinav SumanğŸ¨ ğŸ’»      Hamza Ehtesham FarooqğŸ¨ ğŸ’»      IamNotPeterPanğŸ’» ğŸ’µ ğŸ¨      CetgerğŸ¨      pkonopackiğŸ¨      Yang YangğŸ¨ ğŸ’»              Muhammad Shoaib SarwarğŸ’»      Murilo HenriqueğŸ’» ğŸ¨      emilianoalvzğŸ¨ ğŸ’»      Sumana SahağŸ¨ ğŸ’»      Yurii17KğŸ¨ ğŸ’»      Rupesh BhandariğŸ¨ ğŸ’»      salmos3718ğŸ’»              John BakerğŸ¨ ğŸ’»      SanjaySathirajuğŸ¨ ğŸ’»      Donat KabashiğŸ¨      Arul Prasad JğŸ¨ ğŸ’»      Qi ChenğŸ¨ ğŸ’»      Maksym DmyterkoğŸ¨ ğŸ’»      ilovepullrequestsğŸ’»              Samira MalekiğŸ¨ ğŸ’»      NIKITA MAHOVIYAğŸ’»      jesuisdev.NetğŸ¨ ğŸ’»      Ashraf NazarğŸ¨      Naveed AhmadğŸ¨      Ajmain NaqibğŸ¨ ğŸ’»      Avinash TingreğŸ’» ğŸ¨              nicktidsğŸ¨      Keith DinhğŸ’» ğŸ¨      AndrÃ© FerreirağŸ’» ğŸ¨      eliottkespiğŸ’» ğŸ¨      praveenpnoğŸ’» ğŸ¨      vitowidigdoğŸ’» ğŸ¨      Devesh Pratap SinghğŸ’» ğŸ¨              Dario RodriguezğŸ’» ğŸ¨      charmander_didiğŸ’» ğŸ¨      PHBasinğŸ’» ğŸ¨      Ritvik Singh ChauhanğŸ’» ğŸ¨      Riya P MathewğŸ’» ğŸ¨      Stephanie CherubinğŸ’» ğŸ¨      BenitesGuiğŸ’» ğŸ¨              FarikBearğŸ’» ğŸ¨      Dmytro HavrilovğŸ’» ğŸ¨      Parvesh MonuğŸ’» ğŸ¨      Dipen PanchasarağŸ’» ğŸ¨      gudatağŸ¨ ğŸ’»      gawadeditorğŸ’» ğŸ¨      Kirill TaletskiğŸ¨ ğŸ’»              SaajanğŸ¨ ğŸ’»      Kushagra SğŸ¨ ğŸ’»      Oanh LeğŸ¨ ğŸ’»      Frane MedvidoviÄ‡ğŸ¨ ğŸ’»      YormanğŸ¨ ğŸ’»      Bill ChanğŸ¨ ğŸ’»      Pratik LomteğŸ¨ ğŸ’»              LOC LAMğŸ¨ ğŸ’»      TUSAR RANJAN MAHAPATRAğŸ’»      BhargavKanjarlağŸ’»      Karel De SmetğŸ’» ğŸ¨      sidisanğŸ¨      ygnzayarphyoğŸ¨ ğŸ’»      svansteelandtğŸ’»              KebechetğŸ¨      Daniel Selvan DğŸ¨ ğŸ’»      Mahdi RazaviğŸ¨ ğŸ’»      Niklas TiedeğŸ’» ğŸ¨      narutubaderddinğŸ’» ğŸ¨      dylandhoodğŸ’»      Dheeraj GuptağŸ’»              Pieter ClaerhoutğŸ’» ğŸ¨      Shivam AgnihotriğŸ’»      RanjithReddy-NarrağŸ’»      Nikita WadhwaniğŸ¨ ğŸ’»      rsholokhğŸ’» ğŸ¨      Ayaan HossainğŸ’» ğŸ¨      Rajesh SwarnağŸ’»              Deniz EtkarğŸ¨ ğŸ’»      pro335ğŸ’» ğŸ¨      Jakub RadzikğŸ’» ğŸ¨      Hamza KhanzadağŸ’»      ARNONğŸ¨      Vikram SinghğŸ’»      ShoxruxbekğŸ’» ğŸ¨              Amit KhatriğŸ’» ğŸ¨      Wali UllahğŸ¨ ğŸ’»      Amit11794ğŸ’» ğŸ¨      metis-macys-66898ğŸ’» ğŸ¨      Faisal MaqboolğŸ¨ ğŸ’»      Kumar NeerajğŸ’» ğŸ¨      Maurizio MariniğŸ¨ ğŸ’»              Saket KothariğŸ¨ ğŸ’»      Szymon ZborowskiğŸ¨ ğŸ’»      iks3000ğŸ¨ ğŸ’»      Ehsan SeyediğŸ¨ ğŸ’»      vanekbrğŸ¨ ğŸ’»      Princy_MğŸ¨ ğŸ’»      Shijie ZhouğŸ¨ ğŸ’»              lakshyamcs16ğŸ¨ ğŸ’»      Filippo FaccoğŸ¨ ğŸ’»      mendel5ğŸ¨ ğŸ’»      PatrykğŸ¨ ğŸ’»      VishwaSanganiğŸ¨ ğŸ’»      Alvin ZhaoğŸ¨ ğŸ’»      Lazar GugletağŸ¨ ğŸ’»              vmichoğŸ¨ ğŸ’»      Sikandar AliğŸ¨ ğŸ’»      Raja BabuğŸ¨ ğŸ’»      faizajahanzebğŸ’»      Guil_AiTğŸ¨ ğŸ’»      Kushal DasğŸ¨ ğŸ’»      Luis BonillağŸ¨ ğŸ’»              jovan1013ğŸ¨ ğŸ’»      DamianğŸ¨ ğŸ’»      Yash GuptağŸ’»      lolcatnipğŸ¨ ğŸ’»      Ikko AshimineğŸ¨ ğŸ’»      FarukhğŸ¨ ğŸ’»      MoksedulğŸ’» ğŸ¨              Navneet KumarğŸ¨ ğŸ’»      Saqib AlMalikğŸ’»      fahimrahmanğŸ¨ ğŸ’»      vaibhav patilğŸ¨ ğŸ’»      Rahul MadanğŸ¨ ğŸ’»      kartik KaklotarğŸ¨ ğŸ’»      ASAHI OCEANğŸ¨ ğŸ’»              Daniel JungbluthğŸ¨ ğŸ’»      Rajdeep Singh BoranağŸ¨ ğŸ’»      ankitha19ğŸ’»      Linh TranğŸ’»      islamarrğŸ’» ğŸ¨      Mohamed SabithğŸ¨ ğŸ’»      Miguel Angel Cruz AcostağŸ¨ ğŸ’»              Adebayo Ilerioluwa ğŸ¨      MarkusğŸ¨ ğŸ’»      dkonyayevğŸ¨ ğŸ’»      Kevin A MathewğŸ¨ ğŸ’»      David MeloğŸ¨ ğŸ”£      DFW1NğŸ¨ ğŸ’»      Sohaib AyubğŸ¨ ğŸ’»              NavvyğŸ¨ ğŸ’»      bloodiator2ğŸ¨ ğŸ’»      HanjiğŸ¨ ğŸ’»      arthur74ğŸ¨ ğŸ’»      Sri Subathra Devi BğŸ¨ ğŸ’»      Akif AydogmusğŸ¨ ğŸ’»      Umer JavaidğŸ¨ ğŸ’»              Norio UmatağŸ¨ ğŸ’»      Gazi Hasan RahmanğŸ¨ ğŸ’»      Keith NguyenğŸ¨ ğŸ’»      MegalomaniacğŸ¨ ğŸ’»      ShankS3ğŸ¨ ğŸ’»      Farhad AlishovğŸ¨ ğŸ’»      Ronak J VanpariyağŸ¨ ğŸ’»              azrael0learzağŸ¨ ğŸ’»      Pavel RahmanğŸ¨ ğŸ’»      chuabernğŸ¨ ğŸ’»      Rahul TirkeyğŸ¨ ğŸ’»      Ruslan BesğŸ¨ ğŸ’» ğŸ’¡ ğŸš§ ğŸ–‹ ğŸ”£ ğŸš‡      BohdanğŸ¨ ğŸ’»      JuzdzewskiğŸ¨ ğŸ’»              Grigor MinasyanğŸ¨ ğŸ’»      alvintwcğŸ¨ ğŸ’»      Anand NatarajanğŸ¨ ğŸ’»      Kashan AliğŸ¨ ğŸ’»      Thomas MeshailğŸ¨ ğŸ’»      Son PhamğŸ¨      Michael FrenchğŸ’¡              Yash MishrağŸ“–      Miguel RodriguezğŸ¨ ğŸ’»      Philipp BachmannğŸ¨ ğŸ’»      sunnyğŸ¨ ğŸ’»      Siddharth ChatterjeeğŸ¨ ğŸ’»      Michael NaghavipourğŸ¨ ğŸ’»      Sahil GargğŸ¨ ğŸ’»              MicroLionğŸ¨ ğŸ’»      wctwcğŸ¨ ğŸ’»      Rohan SharmağŸ”£      AshishBodlağŸ¨ ğŸ’»      Taras PysarskyiğŸ¨ ğŸ’»      Luqman Bello O.ğŸ¨ ğŸ’»      DyingDownğŸ¨ ğŸ’»              Diego ChapedelaineğŸ¨ ğŸ’»      RichleeğŸ¨ ğŸ’»      Asif HabibğŸ¨ ğŸ’»      Mazharul HossainğŸ¨ ğŸ’»      toniğŸ¨ ğŸ’»      Pragyanshu RaiğŸ¨ ğŸ’»      Matthew EllerğŸ¨ ğŸ’»              AbhiBijuğŸ¨ ğŸ’»      Roman ZhornytskiyğŸ¨ ğŸ’»      Lucas CaminoğŸ¨ ğŸ’»      JoÃ£o Vitor CasarinğŸ¨ ğŸ’»      Evgeniy ShayğŸ¨ ğŸ’»      Ehsan BarkhordarğŸ¨ ğŸ’»      GabrielğŸ¨ ğŸ’»              Shibu MohapatrağŸ¨ ğŸ’»      Pavel KirkovskyğŸ¨ ğŸ’»      Tahir GulğŸ¨ ğŸ’»      imDevSalmanğŸ¨ ğŸ’»      Jordan DonaldsonğŸ¨ ğŸ’»      js-venusğŸ¨ ğŸ’»      Faisal ShaikhğŸ¨ ğŸ’»              ashishbpatilğŸ¨ ğŸ’»      Tri LeğŸ¨ ğŸ’»      tomtreffkeğŸ¨ ğŸ’»      Salah Eddine LalamiğŸ¨ ğŸ’»      Mattias XuğŸ¨ ğŸ’»      Manas GuptağŸ¨ ğŸ’»      wolfsong62ğŸ¨ ğŸ’»              Mehdi MirzaeiğŸ¨ ğŸ’»      Van Ba KhanhğŸ¨ ğŸ’»      Sel EmbeeğŸ¨ ğŸ’»      Suvradip PaulğŸ¨ ğŸ’»      ShariqueğŸ¨      SeabassğŸ¨ ğŸ’»      Penny LiuğŸ¨ ğŸ’»              jatinder bholağŸ¨ ğŸ’»      misterqbitğŸ¨ ğŸ’»      Daniel-VS9ğŸ¨ ğŸ’»      ShruthiğŸ¨ ğŸ’»      beefydogğŸ¨ ğŸ’»      Suraj KumarğŸ¨ ğŸ’»      hrishikeshpsğŸ¨ ğŸ’»              SudarshanğŸ¨ ğŸ’»      DivyanshğŸ’» ğŸ¨      ZyaireğŸ¨ ğŸ’»      Omar BelkadyğŸ¨ ğŸ’»      alexiismuağŸ¨ ğŸ’»      Eduarda AlvesğŸ¨      pycoachğŸ¨ ğŸ’»              RuhulğŸ¨ ğŸ’»      pmoustopoulosğŸ¨ ğŸ’»      Lee Hui TingğŸ’» ğŸ¨      bodi1981ğŸ¨ ğŸ’»      Devaraat JoshiğŸ¨ ğŸ’»      JohnnyğŸ¨ ğŸ’»      rogue-coderğŸ¨ ğŸ’»              viiktrğŸ¨      Lalit MohanğŸ’»      JoÃ£o SousağŸ’»      è¨€è‘‰ä¹‹éˆğŸ’» ğŸ¨      RJLABSğŸ’»      brittney0522ğŸ¨ ğŸ’»      shamğŸ¨ ğŸ’»              Glenn GoossensğŸ’» ğŸ¨      Cyber HawkğŸ¨ ğŸ’» ğŸ–‹ ğŸ’¼      Ankit YadavğŸ¨ ğŸ’»      verbalityğŸ’»      Mohammed SiddiquiğŸ¨ ğŸ’»      AdamKaczor6250ğŸ¨ ğŸ’»      RamÃ³n Martinez NietoğŸ¨ ğŸ’»              Grzegorz DziubakğŸ¨ ğŸ’»      Ayoub BERDEDDOUCHğŸ¨ ğŸ’»      nikola-fadvğŸ¨ ğŸ’»      Akarsh AgrawalğŸ¨ ğŸ’»      Mitra MirshafieeğŸ¨ ğŸ’»      Parker StephensğŸ¨ ğŸ’»      alrenee99ğŸ’»              Karthick VankayalağŸ’»      Iryna ğŸ¨ ğŸ’»      palanugrahğŸ’»      GwinbleindğŸ¨ ğŸ’»      Randy BobandyğŸ¨ ğŸ’»      Bek RozikoffğŸ’»      davnguyeğŸ¨ ğŸ’»              Neel PatelğŸ’»      ehudbeharğŸ¨ ğŸ’»      nicholas-cod3rğŸ¨ ğŸ’»      michaelfrankiğŸ¨      Esther WhiteğŸ¨ ğŸ’»      prathmeshpbğŸ¨ ğŸ’»      Victor LinğŸ¨ ğŸ’»              Christine C. YinğŸ¨ ğŸ’»      GitLearner-beginğŸ¨ ğŸ’»      Mesrop AndreasyanğŸ¨ ğŸ’»      Nathan GarciağŸ¨      commonsw04ğŸ¨ ğŸ’»      Md. Rashad TanjimğŸ¨ ğŸ’»      Ali MalekğŸ’»              PAODLTğŸ¨ ğŸ’»      Nikhil BobadeğŸ¨ ğŸ’»      hyuckjin21ğŸ’»      Itasha ModiğŸ¨ ğŸ’»      Nikitha ReddyğŸ¨ ğŸ’»      Mahshooq ZubairğŸ¨ ğŸ’»      Subham DasğŸ’»              Onkar BirajdarğŸ¨ ğŸ’»      Nick TitomichelakisğŸ¨ ğŸ’»      Christian Leo-PernoldğŸ¨      Matthew MarquiseğŸ¨ ğŸ’»      baronfacğŸ¨ ğŸ’»      Abhishek TilwarğŸ¨ ğŸ’»      DavidsDvmğŸ¨ ğŸ’»              Parth ParikhğŸ¨ ğŸ’»      Hector CastroğŸ¨ ğŸ’»      Rikky ArisendiğŸ¨ ğŸ’»      Ali HamXağŸ¨ ğŸ’»      Frank.wuğŸ¨ ğŸ’»      Jatin KumarğŸ¨ ğŸ’» ğŸ“–      masterHAWK99ğŸ¨ ğŸ’»              Pushp JainğŸ¨ ğŸ’»      Ashutosh RoutğŸ¨ ğŸ’»      Atharva DeshpandeğŸ¨ ğŸ’»      Teodor CiripescuğŸ¨ ğŸ’»      Anmol BansalğŸ¨ ğŸ’»      Nikhil Kumar MacharlağŸ¨ ğŸ’»      DexterğŸ¨ ğŸ’»              AaronğŸ¨ ğŸ’»      Yogita JaswaniğŸ¨ ğŸ’» ğŸ“– ğŸ–‹      StoryDevğŸ¨ ğŸ’»      Mesut DoÄŸansoyğŸ¨ ğŸ’»      Paras DhawanğŸ¨ ğŸ’»      Emanuel ZhupağŸ¨ ğŸ’»      Aaradhyaa717ğŸ¨ ğŸ’»              jaacko-torusğŸ¨ ğŸ’»      mBlackğŸ’»      kalrayashwinğŸ“– ğŸ–‹ ğŸ¨ ğŸ’»      SeraphğŸ’» ğŸ¨      ZhiHong ChuağŸ¨ ğŸ’»      Amsal KhanğŸ¨ ğŸ’» ğŸ“– ğŸ–‹      Raghav RastogiğŸ¨ ğŸ’»              TzilağŸ“–      Shahriar Nasim NafiğŸ“–      AGğŸ¨ ğŸ’»      Mojtaba KamyabiğŸ¨ ğŸ’»      Ahmad AbdulrahmanğŸ¨ ğŸ’»      EclipseğŸ¨ ğŸ’»      Anshu PalğŸ¨ ğŸ’»              DenisğŸ¨ ğŸ’»      mehmet sayinğŸ“–      WebDEVğŸ¨ ğŸ’»      Sam KomesarookğŸ¨ ğŸ’»      Kiran GhimireğŸ¨ ğŸ’»      Joshua DavisğŸ¨ ğŸ’»      Muhammad-Huzaifa-SiddiquiğŸ’»              tobeornottobeadevğŸ¨ ğŸ’»      VAIBHAV SINGHALğŸ¨ ğŸ’»      Keiran PillmanğŸ¨ ğŸ’»      Max DonchenkoğŸ¨ ğŸ’»      sgonsalğŸ¨ ğŸ’»      diksha137ğŸ¨ ğŸ’»      VigneshğŸ¨ ğŸ’»              Gabriel FranÃ§ağŸ¨ ğŸ’»      JosephğŸ¨ ğŸ’»      Bruno RafaelğŸ¨ ğŸ’»      vcamarreğŸ¨ ğŸ’»      thibault kettererğŸ¨ ğŸ’» ğŸš§      VictorGonzalezToledoğŸ¨ ğŸ’»      1911510996ğŸ¨ ğŸ’»              inviduğŸ¨ ğŸ’»      Nurul FurqonğŸ¨ ğŸ’»      David AsbillğŸ¨ ğŸ’»      Niko BirbilisğŸ¨ ğŸ’»      Mugundan KottursureshğŸ¨      agrsachin81ğŸ¨ ğŸ’»      Othmane El AlamiğŸ¨ ğŸ’»              Syed Atif AliğŸ¨ ğŸ’»      lakhanjindamğŸ¨ ğŸ’»      youssef hamdaneğŸ¨ ğŸ’»      starfaerieğŸ¨ ğŸ’»      rodrigo0107ğŸ¨ ğŸ’»      MichaÅ‚ GralakğŸ¨ ğŸ’»      Jewel MahmudğŸ¨ ğŸ’»              cwilson830ğŸ¨ ğŸ’»      buun1030ğŸ¨ ğŸ’»      Reda-ELOUAHABIğŸ¨ ğŸ’»      saad-aksağŸ¨ ğŸ’»      Emdadul HaqueğŸ¨ ğŸ’»      PROCWğŸ¨ ğŸ’»      cccppp1ğŸ¨ ğŸ’»              Joanna BaileğŸ¨ ğŸ’»      Ahmed SaberğŸ¨ ğŸ’»      Masoud KeshavarzğŸ¨ ğŸ’»      mortazavianğŸ¨ ğŸ’»      Aniket PandeyğŸ¨ ğŸ’»      Vijay NirmalğŸ¨ ğŸ’»      Daniel CarvalloğŸ’»              menaechmiğŸ¨ ğŸ’»      azenyxğŸ¨ ğŸ’»      Ahmet Ã–zrahatğŸ¨ ğŸ’»      Abdulrahman AbouzaidğŸ¨ ğŸ’»      jmgnorbecğŸ¨ ğŸ’»      palinko91ğŸ¨ ğŸ’»      Laisson R. SilveirağŸ¨ ğŸ’»              BHARGAVPATEL1244ğŸ¨ ğŸ’»      Candide UğŸ¨ ğŸ’»      Sitansh RajputğŸ¨ ğŸ’»      Houda MouttalibğŸ¨ ğŸ’»      MumuTWğŸ¨ ğŸ’»      Suave BajajğŸ¨ ğŸ’»      Mehdi ParsaeiğŸ¨ ğŸ’»              Dinko OsreckiğŸ¨ ğŸ’»      Dhia DjobbiğŸ¨ ğŸ’»      Mahmoud GalalğŸ¨ ğŸ’»      Anh MinhğŸ¨ ğŸ’»      Suvesh KğŸ¨ ğŸ’»      Petar TodorovğŸ¨ ğŸ’»      Alexander NguyenğŸ¨ ğŸ’»              Morteza JalalvandğŸ¨ ğŸ’»      Claudson MartinsğŸ¨ ğŸ’»      Matt JacobsonğŸ¨ ğŸ’»      Rafael BelokurowsğŸ¨ ğŸ’»       Thomas GamaufğŸ¨ ğŸ’»      Rishabh MahajanğŸ¨ ğŸ’»      rakeshpdgupta23ğŸ¨ ğŸ’»              ShashidharknaikğŸ¨ ğŸ’»      taleleumağŸ¨ ğŸ’»      Florian BÃ¼hlerğŸ¨ ğŸ’»      Raihan Bin WahidğŸ¨ ğŸ’»      MOHAMMED NASSERğŸ¨ ğŸ’»      federicoğŸ¨ ğŸ’»      Andre ViolanteğŸ¨ ğŸ’»              tcunningham98ğŸ¨ ğŸ’»      Jan GrieÃŸerğŸ¨ ğŸ’»      Serkan AlcğŸ¨ ğŸ’» ğŸ–‹      Jez McKeanğŸ¨ ğŸ’»      meisam alifallahiğŸ¨ ğŸ’»      Mehul ThakkarğŸ¨ ğŸ’»      Saksham SoniğŸ¨ ğŸ’»              Pedro PeregrinağŸ¨ ğŸ’»      Mintu ChoudharyğŸ¨ ğŸ’»      lucianmoldovanuğŸ¨ ğŸ’»      John C. ScottğŸ¨ ğŸ’»      Mia D.ğŸ¨ ğŸ’»      EwenBernardğŸ¨ ğŸ’»      M. Reza NasirlooğŸ¨ ğŸ’»              Jay AgrawalğŸ¨ ğŸ’»      DeShayğŸ¨ ğŸ’»      Jay206-ProgrammerğŸ¨ ğŸ’»      ElenderğŸ¨ ğŸ’» ğŸ–‹      Bobby ByrneğŸ¨ ğŸ’»      PirciğŸ¨ ğŸ’»      HasanuzzamanğŸ¨ ğŸ’»              Josh KautzğŸ¨ ğŸ’»      BrofarğŸ¨ ğŸ’»      Mina KaramğŸ¨ ğŸ’»      Duncan O NğŸ¨ ğŸ’»      Sean Tumulak-NguyenğŸ¨ ğŸ’»      Artur TrzeÅ›niewskiğŸ¨ ğŸ’»      JJaammeessMğŸ¨ ğŸ’»              shubham agarwalğŸ¨ ğŸ’»      Michele RighiğŸ¨ ğŸ’»      Panagiotis KontosğŸ¨ ğŸ’»      sumitbathlağŸ¨ ğŸ’»      Deepak MathurğŸ¨ ğŸ’»      Juho NykÃ¤nenğŸ¨ ğŸ’»      Santiago GonzÃ¡lez SiordiağŸ¨ ğŸ’»              SRIJITA MALLICKğŸ¨ ğŸ’»      Samriddhi BğŸ¨ ğŸ’»      Nitzan PapiniğŸ¨ ğŸ’»      Mario SanzğŸ¨ ğŸ’»      Crab^4ğŸ¨ ğŸ’»      PabloğŸ¨ ğŸ’»      Gordon Pham-NguyenğŸ¨ ğŸ’»              KristofferğŸ¨ ğŸ’»      chrisblachğŸ¨ ğŸ’»      GÃ¡borğŸ¨ ğŸ’»      LinağŸ¨ ğŸ’»      Harrison WattsğŸ¨ ğŸ’»      Mario PetriÄkoğŸ¨ ğŸ’»      Ben8120ğŸ¨ ğŸ’»              GiovannağŸ¨ ğŸ’»      Minal AhujağŸ¨ ğŸ’»      mossfarmerğŸ¨ ğŸ’»      ThaC0derDreğŸ¨ ğŸ’»      itwareğŸ¨ ğŸ’»      Michael WalkerğŸ¨ ğŸ’»      Tom Jacob ChirayilğŸ¨ ğŸ’»              Sachin KumarğŸ¨ ğŸ’»      adi-rayğŸ¨ ğŸ’»      Dr-Blank-altğŸ¨ ğŸ’»      Bogdan CazacuğŸ¨ ğŸ’»      Gilson UrbanoğŸ¨ ğŸ’»      NinağŸ¨ ğŸ’»      AnthonyğŸ¨ ğŸ’»              manushimjaniğŸ¨ ğŸ’»      Michael ReyesğŸ¨ ğŸ’»      Rachel KennellyğŸ¨ ğŸ’»      Aakash GargğŸ¨ ğŸ’»      Daniel LivingstonğŸ¨ ğŸ’»      alexrojcoğŸ¨ ğŸ’»      Minh NguyenğŸ¨ ğŸ’»              Mahesh Dattatraya BabarğŸ¨ ğŸ’»      Jin ZihangğŸ¨ ğŸ’»      Bikramjit GangulyğŸ¨ ğŸ’»      QuestionableGuiseğŸ¨ ğŸ’»      liq19chğŸ¨ ğŸ’»      Bruno RochağŸ¨ ğŸ’»      Anand DyavanapalliğŸ’» ğŸ–‹              crucian-afkğŸ¨ ğŸ’»      0xgainzğŸ¨ ğŸ’»      weirdfshğŸ¨ ğŸ’»      Valan Baptist MathuranayagamğŸ¨ ğŸ’»      Paul KaeferğŸ¨ ğŸ’»      Yu-Hsiang WangğŸ¨ ğŸ’»      Javad AdibğŸ¨ ğŸ’»              davidliu0930ğŸ¨ ğŸ’»      Achilleas John YfantisğŸ¨ ğŸ’»      Omkar ShivadekarğŸ¨ ğŸ’» ğŸ–‹ ğŸ›      ToanTranğŸ¨ ğŸ’»      Gautam NaikğŸ¨ ğŸ’»      MarcğŸ¨ ğŸ’»      twix20ğŸ¨ ğŸ’»              Kristian S.ğŸ¨ ğŸ’»      Aleksey KhoroshilovğŸ¨ ğŸ’»      arjunsrsrğŸ¨ ğŸ’»      Ali HaiderğŸ¨ ğŸ’»      Trisha DringğŸ¨ ğŸ’»      Andre MarzuloğŸ¨ ğŸ’»      Krishna ModiğŸ¨ ğŸ’»              Rosemary LiğŸ¨ ğŸ’»      Alex WellerğŸ¨ ğŸ’»      Tam NguyenğŸ¨ ğŸ’»      aquintelaoliveirağŸ¨ ğŸ’»      Norbert BrettğŸ¨ ğŸ’»      rocsogdğŸ¨ ğŸ’»      0nyrğŸ¨ ğŸ’»              rethkevinğŸ¨ ğŸ’»      RickHeadleğŸ¨ ğŸ’»      LeandreğŸ¨ ğŸ’»      Natnael SisayğŸ¨ ğŸ’»      sbbuğŸ¨ ğŸ’»      waelğŸ¨ ğŸ’»      Fabricio Tramontano PiriniğŸ¨ ğŸ’»              Alexander StoyanovğŸ¨ ğŸ’»      Dezx20ğŸ¨ ğŸ’»      southparkkidsğŸ¨ ğŸ’»      bmstarğŸ¨ ğŸ’»      kiagamğŸ¨ ğŸ’»      Juan CastilloğŸ¨ ğŸ’»      FFenneğŸ¨ ğŸ’»              Jose ToledoğŸ¨ ğŸ’»      Pat McGhenğŸ¨ ğŸ’»      Eiko WagenknechtğŸ’» ğŸ–‹ ğŸ”£      Alan ChalmersğŸ¨ ğŸ’»      Jean DidierğŸ¨ ğŸ’»      AndyğŸ¨ ğŸ’»      pestadieuğŸ¨ ğŸ’»              Kanishka ChakrabortyğŸ¨ ğŸ’»      NandhağŸ¨ ğŸ’»      Vahid MafiğŸ¨ ğŸ’» ğŸ”£ ğŸ–‹ ğŸ’¼      Akshay AshokğŸ¨ ğŸ’»      0x08ğŸ¨ ğŸ’»      Sandeep MishrağŸ¨ ğŸ’»      Evann RegnaultğŸ¨ ğŸ’»              Lenny ZeitounğŸ¨ ğŸ’»      Eden BoaronğŸ¨ ğŸ’»      TroyBTCğŸ¨ ğŸ’»      Aby SebastianğŸ¨ ğŸ’»      Matthew DunnğŸ¨ ğŸ’»      ckulloğŸ¨ ğŸ’» ğŸ–‹ ğŸ”£      Mohamed MamdouhğŸ¨ ğŸ’»              Youssef BazinağŸ¨ ğŸ’»      Frederico KÃ¼ckelhausğŸ’»      Nushan KodikarağŸ’»      Zach CooperğŸ’»      RoyğŸ¨ ğŸ’»      Saurav PanchalğŸ¨ ğŸ’»      totallynotdavidğŸ¨ ğŸ’»              goosepirateğŸ¨ ğŸ’» ğŸ’¡ ğŸ’¼      KAUTHğŸ¨ ğŸ’»      Hari Kiran VusirikalağŸ¨ ğŸ’»      Sounak DeyğŸ¨ ğŸ’»      ziağŸ’¼ ğŸ¨ ğŸ’»      Reza DavariğŸ¨ ğŸ’»      AkshayAjaykumarğŸ¨ ğŸ’»              x24870ğŸ¨ ğŸ’»      Ko PhoneğŸ¨ ğŸ’»      Nabstar3ğŸ¨ ğŸ’»      MateuszğŸ¨ ğŸ’»      Yunus Emre EmikğŸ’»      Abhinav SinhağŸ¨ ğŸ’»      Hung NguyenğŸ¨ ğŸ’»              MaselinoğŸ’»      Shuktika MahantyğŸ’»      MikoÅ‚aj GawroÅ„skiğŸ¨ ğŸ’»      Hussein Habibi JuybariğŸ¨ ğŸ’»      Sean-McArthurğŸ¨ ğŸ’»      Osman F BayramğŸ¨ ğŸ’»      Benjamin Thomas BlodgettğŸ¨ ğŸ’»              Chuanlong-ZangğŸ¨ ğŸ’»      julianğŸ¨ ğŸ’»      franciscoğŸ¨ ğŸ’»      aalihhiader9211ğŸ¨ ğŸ’»      Muhammad ZunairğŸ¨ ğŸ’»      LiyağŸ¨ ğŸ’»      BegadTarekğŸ¨ ğŸ’»              etorobotğŸ¨ ğŸ’»      Hussam KhanğŸ¨ ğŸ’»      Saikat ChakrabortyğŸ¨ ğŸ’»      Nicholas QuislerğŸ¨ ğŸ’»      Evang PoulğŸ¨ ğŸ’»      Gregg LindğŸ¨ ğŸ’»      Deepak KumarğŸ¨ ğŸ’»              Callum LeslieğŸ¨ ğŸ’»      Curtis Barnard Jr.ğŸ¨ ğŸ’»      DeepanshukaimğŸ¨ ğŸ’»      Manthan AnkğŸ¨ ğŸ’»      hossein varmazyarğŸ¨ ğŸ’»      Brayan MuÃ±oz V.ğŸ¨ ğŸ’»      Kamil Rasheed SiddiquiğŸ’» ğŸ¨              mutt0-dsğŸ¨ ğŸ’»      egbertjkğŸ¨ ğŸ’»      Majid ZojajiğŸ¨ ğŸ’»      Sean ChenğŸ¨ ğŸ’»      Herbert MilhommeğŸ¨ ğŸ’»      A3ğŸ¨ ğŸ’»      KillianğŸ¨ ğŸ’»              CoakeowğŸ¨ ğŸ’»      à¾…à¼» Ç¬É€Ä§ à¼„à¼†à½‰ğŸ¨ ğŸ’»      Pratik SolankiğŸ¨ ğŸ’»      SunnyğŸ¨ ğŸ’»      ssgeğŸ¨ ğŸ’»      Bernat FrangiğŸ¨ ğŸ’»      Jeevan RupachağŸ¨ ğŸ’»              amirandapğŸ¨ ğŸ’»      Deepakshi MittalğŸ¨ ğŸ’»      Abhijeet ParidağŸ¨ ğŸ’»      Khaled RiyadğŸ¨ ğŸ’»      Pratap paruiğŸ¨ ğŸ’»      Prajit PandayğŸ¨ ğŸ’»      PipeSierrağŸ¨ ğŸ’»              Collins OdenğŸ¨ ğŸ’»      Kshitij DwivediğŸ¨ ğŸ’»      Bernardia Vitri ArumsariğŸ¨ ğŸ’»      Ã–mer Faruk TaÅŸdemirğŸ¨ ğŸ’»      Spencer StithğŸ¨ ğŸ’»      Porsche RodjanasakğŸ¨ ğŸ’»      Shakeel SharifğŸ¨ ğŸ’»              Victoria ChengğŸ¨ ğŸ’»      DenisğŸ¨ ğŸ’»      Anand Prakash TiwariğŸ¨ ğŸ’»      danijeljw-rpcğŸ¨ ğŸ’»      Ahmed H EbrahimğŸ¨ ğŸ’»      Virginia GardnerğŸ¨ ğŸ’»      Jhironsel Diaz A.ğŸ¨ ğŸ’»              Yunus KidemğŸ¨ ğŸ’»      MTğŸ¨ ğŸ’»      Dinesh ZaldekarğŸ¨ ğŸ’»      adiğŸ¨ ğŸ’»      Farhan ShaikhğŸ¨ ğŸ’»      Elvis SalvatierrağŸ¨ ğŸ’»      Kaushik-IyerğŸ¨ ğŸ’»              HocAndresğŸ¨ ğŸ’»      VictorHugoAguilarAguilarğŸ¨ ğŸ’»      Murat Can AbayğŸ¨ ğŸ’»      ChrisğŸ¨ ğŸ’»      Shivam7-1ğŸ¨ ğŸ’»      Paipai13ğŸ¨ ğŸ’»      Shambles-ioğŸ¨ ğŸ’»              Abhishek K MğŸ¨ ğŸ’»      Ezequiel CuevasğŸ¨ ğŸ’»      Plamen IvanovğŸ¨ ğŸ’»      YujiğŸ¨ ğŸ’»      Jean-Philippe LebÅ“ufğŸ¨ ğŸ’» ğŸ”£      NaufanğŸ¨ ğŸ’»      jadnovğŸ¨ ğŸ’»              vaxtangensğŸ¨ ğŸ’»      subashkonar13ğŸ¨ ğŸ’»      Rushi JaviyağŸ¨ ğŸ’»      Mert GÃ¼lğŸ¨ ğŸ’»      LilyğŸ¨ ğŸ’»      KalinoffğŸ¨ ğŸ’»      Joel TonyğŸ¨ ğŸ’»              PeterğŸ¨ ğŸ’»      Roozbeh ZareiğŸ¨ ğŸ’»      ShenğŸ¨ ğŸ’»      Joonsoo.LEEğŸ¨ ğŸ’»      Fede.BregğŸ¨ ğŸ’»      Rui CostağŸ¨ ğŸ’»      JoÃ£o Gustavo BispoğŸ¨ ğŸ’»              Sami-IğŸ¨ ğŸ’»      Tsvetoslav TsvetkovğŸ¨ ğŸ’»      Olabode Olaniyi DavidğŸ¨ ğŸ’»      theRuslanğŸ¨ ğŸ’»      leighbozğŸ¨ ğŸ’»      Frank SossiğŸ¨ ğŸ’»      Tomasz AdamskiğŸ¨ ğŸ’»              Mansoor M. SathirğŸ¨ ğŸ’»      Golamrabbi AzadğŸ¨ ğŸ’»      Nahian AhmedğŸ¨ ğŸ’»      Rafael de Jesus Silva MonteiroğŸ¨ ğŸ’»      Odionyebuchukwu JudeğŸ¨ ğŸ’»      The Nithin BalajiğŸ¨ ğŸ’»      KnackiiğŸ¨ ğŸ’»              vittorio-giattiğŸ¨ ğŸ’»      Guilherme de Carvalho Lima RebouÃ§asğŸ¨ ğŸ’»      aaref shamiğŸ¨ ğŸ’»      Andrey DryupinğŸ¨ ğŸ’»      Muhanned NomanğŸ¨ ğŸ’»      Jan SilvağŸ¨ ğŸ’»      emanuele-emğŸ¨ ğŸ’» ğŸ–‹              Sanjay TMğŸ¨ ğŸ’»      Joe Markberg / code editorğŸ¨ ğŸ’»      Julien QuiaiosğŸ¨ ğŸ’»      Eric Ramirez SantisğŸ¨ ğŸ’»      MğŸ¨ ğŸ’»      MalcatağŸ¨ ğŸ’»      Athul MuralidharanğŸ¨ ğŸ’»              Dariusz OchotağŸ¨ ğŸ’»      CHANDAN CHOUDHURYğŸ¨ ğŸ’»      DeepğŸ¨ ğŸ’»      Ahmet Ä°stemihan Ã–ZTÃœRKğŸ¨ ğŸ’»      TIMğŸ¨ ğŸ’»      jakeg814ğŸ¨ ğŸ’»      LeonidosğŸ¨ ğŸ’»              Abhinandu V NairğŸ¨ ğŸ’»      charafeddine01ğŸ¨ ğŸ’»      JasperğŸ¨ ğŸ’»      Manish GoyalğŸ¨ ğŸ’»      SATYAM_SINGHğŸ¨ ğŸ’»      FourğŸ¨ ğŸ’»      Vaishnavi Amira YadağŸ¨ ğŸ’»              ShriKrushna BhagwatğŸ¨ ğŸ’»      Rohit NandagawaliğŸ¨ ğŸ’»      felipeğŸ¨ ğŸ’» ğŸš§ ğŸ–‹ âœ… ğŸ§‘â€ğŸ«      Saurabh MudgalğŸ¨ ğŸ’»      szenadamğŸ¨ ğŸ’»      Shubhendra SinghğŸ¨ ğŸ’»      Yoosuf SayyidğŸ’» ğŸ¨              GÃ¼ven Ã‡etinerlerğŸ¨ ğŸ’»      Luke JefferiesğŸ¨ ğŸ’»      ChrisğŸ¨ ğŸ’»      LÃºcio AguiarğŸ’»      Enuma029ğŸ’»      yktsang01ğŸ’»      maximumn3rdğŸ¨ ğŸ’»              Jon GalleteroğŸ¨ ğŸ’»      Thaddeus  ThomasğŸ¨ ğŸ’»      Aakash KumarğŸ’» ğŸ¨      Ali MğŸ¨ ğŸ’»      OskyEdzğŸ¨ ğŸ’»      Ravi GuptağŸ¨ ğŸ’»      Rafa RaizerğŸ¨ ğŸ’»              Abdullah Al MuzakiğŸ¨ ğŸ’»      Rahul FaujdarğŸ¨ ğŸ’»      Abhishek VermağŸ¨ ğŸ’»      Ashutosh ShindeğŸ¨ ğŸ’»      Ganesh RaiğŸ¨ ğŸ’»      StefanTrpkovicğŸ¨ ğŸ’»      Erik BlancağŸ¨ ğŸ’»              Vedant MadaneğŸ¨ ğŸ’»      Antra TripathiğŸ¨ ğŸ’»      Ethan KnightsğŸ¨ ğŸ’»      Alexandru BoncutğŸ¨ ğŸ’»      Pablo BandinoplağŸ¨ ğŸ’» ğŸš§ ğŸ–‹      Robz-99ğŸ¨ ğŸ’»      Harpal SinghğŸ¨ ğŸ’»              paulboundy99ğŸ¨ ğŸ’»      Mubashir AhmedğŸ¨ ğŸ’»      Rohan HariğŸ¨ ğŸ’»      Erik Henrique ğŸ¨ ğŸ’»      Leandro MatheusğŸ¨ ğŸ’»      DeepakğŸ¨ ğŸ’»      AlishaSinghğŸ¨ ğŸ’»              Lynn Latt YatiğŸ¨ ğŸ’»      San ShweğŸ¨ ğŸ’»      SKRğŸ¨ ğŸ’»      msbunnyjaguarğŸ¨ ğŸ’»      Mohamad ZabiullağŸ¨ ğŸ’»      Hatim ZahidğŸ¨ ğŸ’»      Rauzan SumarağŸ¨ ğŸ’»              Hosein1358ğŸ¨ ğŸ’»      MohitğŸ¨ ğŸ’»      AliğŸ¨ ğŸ’»      Avinash1765ğŸ¨ ğŸ’»      Sai Teja MadhağŸ¨ ğŸ’»      Monsur Ahmed ShafiqğŸ¨ ğŸ’»      xuxianjin-devğŸ¨ ğŸ’»              chetnağŸ¨ ğŸ’»      Gul ZaibğŸ¨ ğŸ’»      NataliağŸ¨ ğŸ’»      DionÃ­sio BragağŸ¨ ğŸ’»      Pritish RajpurohitğŸ¨ ğŸ’»      incanloveğŸ¨ ğŸ’»      InnocentğŸ¨ ğŸ’»              Devin AlmonorğŸ¨ ğŸ’»      antonyveyreğŸ¨ ğŸ’»      Beltz AnhxtonğŸ¨ ğŸ’»      MehdiğŸ¨ ğŸ’»      Muhammad UsmanğŸ¨ ğŸ’»      Patrick DantasğŸ¨ ğŸ’»      Tak VannakğŸ¨ ğŸ’»              Ramzi RADDAOUIğŸ¨ ğŸ’»      Konstantin-GlukhovğŸ¨ ğŸ’»      ugurobanğŸ¨ ğŸ’»      Humberto AlvesğŸ¨ ğŸ’»      JuangZendratoğŸ¨ ğŸ’»      James OluwaleyeğŸ¨ ğŸ’»      Wasi SadmanğŸ¨ ğŸ’»              Pavle MijatovicğŸ¨ ğŸ’»      Luiz H. S. BispoğŸ¨ ğŸ’»      Ğ¡ÑƒÑ…Ğ°Ñ Ğ”Ñ…Ğ¾Ğ»Ğ·ğŸ¨ ğŸ’»      Alvaro TrujilloğŸ¨ ğŸ’»      Everton ğŸ¨ ğŸ’»      jfrozasğŸ¨ ğŸ’»      Shuaaib BadranğŸ¨ ğŸ’»              Shivam JhağŸ¨ ğŸ’»      Mohamed TayehğŸ¨ ğŸ’»      Makendran GğŸ¨ ğŸ’»      mayank singh tomarğŸ¨ ğŸ’»      hossam sadanyğŸ¨ ğŸ’»      Harshbardhan SinghğŸ’» ğŸ¨      Fawad Jawaid MalikğŸ¨ ğŸ’»              Tina LacatisğŸ¨ ğŸ’»      TeddyCuoreDolceğŸ¨ ğŸ’»      bchooxgğŸ¨ ğŸ’»      Alisha TakkarğŸ¨ ğŸ’»      GianluigiğŸ¨ ğŸ’»      Mehran JavaherianğŸ¨ ğŸ’»      Benjamin Ololade AdedokunğŸ¨ ğŸ’»              Md. Abdul MutalibğŸ¨ ğŸ’»      Aadil Arsh.S.RğŸ¨ ğŸ’»      J. Nathan AllenğŸ¨ ğŸ’»      Kieran KrugğŸ¨ ğŸ’»      Seth AddoğŸ¨ ğŸ’»      Satvik Singh RathoreğŸ¨ ğŸ’»      dangothğŸ¨ ğŸ’»              MaximğŸ¨ ğŸ’»      Phuong-Cat NgoğŸ¨ ğŸ’»      Frenchtoast0ğŸ¨ ğŸ’»      RakshithğŸ¨ ğŸ’»      Vaibhav ArorağŸ¨ ğŸ’»      zghpğŸ¨ ğŸ’»      BedovanğŸ¨ ğŸ’»              chiaramistroğŸ¨ ğŸ’»      him2016ğŸ¨ ğŸ’»      HarshitSachdevağŸ¨ ğŸ’»      Sadaf SaleemğŸ¨ ğŸ’»      Aaroh SrivastavağŸ¨ ğŸ’»      eloygplazağŸ¨ ğŸ’»      Gaurav Kumar VermağŸ¨ ğŸ’»              AndreaCUSğŸ¨ ğŸ’»      SimranğŸ¨ ğŸ’»      Prashant BhapkarğŸ¨ ğŸ’»      mhaendlerğŸ¨ ğŸ’»      Gauri MaheshwariğŸ¨ ğŸ’»      4LajfğŸ¨ ğŸ’»      Tanmoy SenguptağŸ¨ ğŸ’»              Sharad TripathiğŸ¨ ğŸ’»      Niraj ChavanğŸ¨ ğŸ’»      Luisa GualdağŸ¨ ğŸ’»      Monika-Sivakumar-3ğŸ¨ ğŸ’»      harryfensomeğŸ¨ ğŸ’»      Shubham ChoubeyğŸ¨ ğŸ’»      Ashwini PatilğŸ¨ ğŸ’»              cleversonlirağŸ¨ ğŸ’»      NurmukhammedğŸ¨ ğŸ’»      workspace-utkarshğŸ¨ ğŸ’»      Santosh PhadtareğŸ¨ ğŸ’»      Prashant WarghudeğŸ¨ ğŸ’»      Umang DakhğŸ¨ ğŸ’»      Shalini ChavanğŸ¨ ğŸ’»              vinit gurjarğŸ¨ ğŸ’»      Vishal KumarğŸ¨ ğŸ’»      Wonhyeong SeoğŸ¨ ğŸ’»      Achwale Prajwal NamdevraoğŸ¨ ğŸ’»      Ankan BanerjeeğŸ¨ ğŸ’»      bhaumikankanğŸ¨ ğŸ’»      JamesMacroZhangğŸ¨ ğŸ’»              Pedro LopesğŸ¨ ğŸ’»      diağŸ¨ ğŸ’»      tayyabhussain2910ğŸ¨ ğŸ’»      Rajdeep Shrivastava ğŸ¨ ğŸ’»      Mukul KumarğŸ¨ ğŸ’»      Mayank NğŸ¨ ğŸ’»      jdeluccağŸ¨ ğŸ’»              Sneha MittalğŸ¨ ğŸ’»      Sarika KushwahağŸ¨ ğŸ’»      farzad-khbğŸ¨ ğŸ’»      Elijah ShackelfordğŸ¨ ğŸ’»      The-Only-RaminatorğŸ¨ ğŸ’»      Keerthana KasthurilğŸ¨ ğŸ’»      Viachaslau AuchynnikauğŸ¨ ğŸ’»              Mohammad Osman RasooliğŸ¨ ğŸ’»      mvedovatoğŸ¨ ğŸ’»      Sonali RajputğŸ¨ ğŸ’»      Isha DhekğŸ¨ ğŸ’»      Ramshad Cheriyeri PeediyakkalğŸ¨ ğŸ’»      MicahğŸ¨ ğŸ’»      gauravshukla2203ğŸ¨ ğŸ’»              sndmurthyğŸ¨ ğŸ’»      Shivam-SinghğŸ¨ ğŸ’»      M. Ammar KhanğŸ¨ ğŸ’»      chandolakulğŸ¨ ğŸ’»      bhatnagar221ğŸ¨ ğŸ’»      Adrian NieÅ›ciurğŸ¨ ğŸ’»      nezi311ğŸ¨ ğŸ’»              scottajevansğŸ¨ ğŸ’»      Marcelo Antunes Soares FantiniğŸ¨ ğŸ’»      Axel De AcetisğŸ¨ ğŸ’»      Drishti SahğŸ¨ ğŸ’»      VipulDhillonğŸ¨ ğŸ’»      Urmi JanağŸ¨ ğŸ’»      Ayush MokalğŸ¨ ğŸ’»              Damola OlutokeğŸ¨ ğŸ’»      MaxğŸ¨ ğŸ’»      Lakshmi NğŸ¨ ğŸ’»      ArtemRevağŸ¨ ğŸ’»      Ujjwal AggarwalğŸ¨ ğŸ’»      MoğŸ¨ ğŸ’»      BrianğŸ¨ ğŸ’»              chamleyğŸ¨ ğŸ’»      Simone BaptisteğŸ¨ ğŸ’»      Shekhar ThakurğŸ¨ ğŸ’»      SmithğŸ¨ ğŸ’»      codernoob1ğŸ¨ ğŸ’»      lok84ğŸ¨ ğŸ’»      Tobias RiemenschneiderğŸ¨ ğŸ’»              Tharsanan1ğŸ¨ ğŸ’»      ANURAG SINGHğŸ¨ ğŸ’»      Yash SantğŸ¨ ğŸ’»      Krishiv PatelğŸ¨ ğŸ’»      GGGalaxyğŸ¨ ğŸ’»      pardeepdhillon661ğŸ¨ ğŸ’»      anujd64ğŸ¨ ğŸ’»              Pedro PereirağŸ¨ ğŸ’»      Master_SaptakğŸ¨ ğŸ’»      SURANJAN DASğŸ¨ ğŸ’»      Tripura kantğŸ¨ ğŸ’»      shabzkhanğŸ¨ ğŸ’»      Mustafa PoyağŸ¨ ğŸ’»      Roshan JhağŸ¨ ğŸ’»              GuillaumeLarueğŸ¨ ğŸ’»      Tomasz RodakğŸ¨ ğŸ’»      Junil KimğŸ¨ ğŸ’»      Surbhi MayankğŸ¨ ğŸ’»      Nemanja LekicğŸ¨ ğŸ’»      HemantMalokarğŸ¨ ğŸ’»      Felipe M. LÃ³pezğŸ¨ ğŸ’»              bibliofiloğŸ¨ ğŸ’»      GauthamG2ğŸ¨ ğŸ’»      02_tğŸ¨ ğŸ’»      Yusuf Abdul-razaqğŸ¨ ğŸ’»      VladimirğŸ¨ ğŸ’»      Sai Chandra KğŸ¨ ğŸ’»      Soroush BonabğŸ¨ ğŸ’»              Giide0nğŸ¨ ğŸ’»      GGğŸ¨ ğŸ’»      DÃ¡ger ZÃºÃ±igağŸ¨ ğŸ’»      rsk2ğŸ¨ ğŸ’»      Storozhev DJğŸ¨ ğŸ’»      JeevanğŸ¨ ğŸ’»      Andy JohnsonğŸ¨ ğŸ’»              AnÃ­bal PozoğŸ¨ ğŸ’»      Jovane de CastroğŸ¨ ğŸ’»      Muhammad Hamza AmirğŸ¨ ğŸ’»      tharaka-mtsğŸ¨ ğŸ’»      Ali KHYARğŸ¨ ğŸ’»      Caio AraujoğŸ¨ ğŸ’»      Oscar DyremyhrğŸ¨ ğŸ’»              artealityğŸ¨ ğŸ’»      Daniel DrexlmaierğŸ¨ ğŸ’»      Marco MontiğŸ¨ ğŸ’»      mikeycrystalğŸ¨ ğŸ’»      VeljanovskiiğŸ¨ ğŸ’»      Ivan GorbachevğŸ¨ ğŸ’»      Sahil RawatğŸ¨ ğŸ’»              Hasitha SunethğŸ¨ ğŸ’»      Yerko Vera LezamağŸ¨ ğŸ’»      Ivan PenchevğŸ¨ ğŸ’»      Tanver Islam TonmoyğŸ¨ ğŸ’»      Xun CaoğŸ¨ ğŸ’»      Nayan BabariyağŸ¨ ğŸ’»      Priyanshu MauryağŸ¨ ğŸ’»              Dylan TintenfichğŸ¨ ğŸ’»      Ron StraussğŸ¨ ğŸ’»      Mohammed AlBannağŸ¨ ğŸ’»      Mukund MğŸ¨ ğŸ’»      Franklin OhaegbulamğŸ¨ ğŸ’»      Nisarg ShahğŸ¨ ğŸ’»      Unik DahalğŸ¨ ğŸ’»              ReadilyğŸ¨ ğŸ’»      Alexandre PoitevinğŸ¨ ğŸ’»      ScaramirğŸ¨ ğŸ’»      PruthviğŸ¨ ğŸ’»      KalmanqğŸ¨ ğŸ’»      Alfatah NesabğŸ¨ ğŸ’»      arudesaiğŸ¨ ğŸ’»              AdryenneğŸ¨ ğŸ’»      El mehdi oudaoudğŸ¨ ğŸ’»      Jayant GoelğŸ¨ ğŸ’»      TsukiğŸ¨ ğŸ’»      Peter LemanskiğŸ¨ ğŸ’»      Annurag-byteğŸ¨ ğŸ’»      Anthony VuğŸ¨ ğŸ’»              Vitaly NikolaychukğŸ¨ ğŸ’»      NathanğŸ¨ ğŸ’»      Evgenii PetukhovğŸ¨ ğŸ’»      Loris GuerrağŸ¨ ğŸ’»      fakhriaunurğŸ¨ ğŸ’»      Mehdi HYANIğŸ¨ ğŸ’»      Sarvex JatasrağŸ¨ ğŸ’»              santimanuelrğŸ¨ ğŸ’»      Evgeniy RezanovğŸ¨ ğŸ’»      Sonia MğŸ¨ ğŸ’»      Grzegorz KmitağŸ¨ ğŸ’»      Manuel CaritağŸ¨ ğŸ’»      Felipe Cisternas AlvarezğŸ¨ ğŸ’»      Guo CiğŸ¨ ğŸ’»              Marcos SilvağŸ¨ ğŸ’»      KKğŸ¨ ğŸ’»      Shubhanjan MedhiğŸ¨ ğŸ’»      ArthurFerreiraRodriguesğŸ¨ ğŸ’»      PabloHermunğŸ¨ ğŸ’»      disha-baldawağŸ¨ ğŸ’»      StaroMoonğŸ¨ ğŸ’»              Amila T KumarasekarağŸ¨ ğŸ’»      Amoh PrinceğŸ¨ ğŸ’»      AngeloGCğŸ¨ ğŸ’»      Ebube Glory OgbondağŸ¨ ğŸ’»      Prahalad BelavadiğŸ“–      Antoni Sarnowski-TrypkağŸ¨ ğŸ’»      Alberto PasqualettoğŸ¨ ğŸ’»              Amir BabaeiğŸ¨ ğŸ’»      Syed Abdul HannanğŸ¨ ğŸ’»      Srajan RaiğŸ¨ ğŸ’»      Clarence MooreğŸ¨ ğŸ’»      Nguyen Anh TuanğŸ¨ ğŸ’»      dar2dar2ğŸ¨ ğŸ’»      Ameer IbrahimğŸ¨ ğŸ’»              Tiago LugattoğŸ¨ ğŸ’»      raremiroirğŸ¨ ğŸ’»      MoobieğŸ¨ ğŸ’»      AlicanDursunğŸ¨ ğŸ’»      bbalsamğŸ¨ ğŸ’»      LuboÅ¡ HÃ¡jekğŸ¨ ğŸ’»      mrshahzeb7ğŸ¨ ğŸ’»              Wesley SchollğŸ¨ ğŸ’»      Lawrence TurcotteğŸ¨ ğŸ’»      Michael DiPaoloğŸ¨ ğŸ’»      Smart-CodiğŸ¨ ğŸ’»      Vivek KumarğŸ¨ ğŸ’»      Igor MoiseevğŸ¨ ğŸ’»      BÃ¥rd PedersenğŸ¨ ğŸ’»              HOA PHANğŸ¨ ğŸ’»      GaborModrağŸ¨ ğŸ’»      vivek-114ğŸ¨ ğŸ’»      RobinğŸ¨ ğŸ’»      AlexğŸ¨ ğŸ’»      John EhrlingerğŸ¨ ğŸ’»      Roman ZhuravlovğŸ¨ ğŸ’»              Jordan MossğŸ¨ ğŸ’»      RaeShellyğŸ¨ ğŸ’»      gmollardğŸ¨ ğŸ’»      Md Kaif KhanğŸ¨ ğŸ’»      Pablo RomerağŸ¨ ğŸ’»      Erik BustosğŸ¨ ğŸ’»      trogfieldğŸ¨ ğŸ’»              simon-aichhornğŸ¨ ğŸ’»      Tufan GÃœLEÃ‡ğŸ¨ ğŸ’»      UÄŸur Berkecan ÃœnlÃ¼ğŸ¨ ğŸ’»      Revanth NaikğŸ¨ ğŸ’»      Lia PiresğŸ¨ ğŸ’»      Igor MestechkinğŸ¨ ğŸ’»      Anirudh KaranthğŸ¨ ğŸ’»              KBobovskiyğŸ¨ ğŸ’»      zhatiayuağŸ¨ ğŸ’» ğŸ–‹      David CardonağŸ¨ ğŸ’»      Paulo CastilhoğŸ¨ ğŸ’»      Sebastiano PicchiğŸ¨ ğŸ’»      pjotarğŸ¨ ğŸ’»      Rimel CHERIFğŸ’»              Arsal uddinğŸ–‹      Dmitry KasporskyğŸ’»      SoftwareDev1014ğŸ¨ ğŸ’»      @RobvredğŸ¨ ğŸ’»      Kasun ShanakağŸ’»      Ahmad M.ğŸ¨ ğŸ’»      Alex KozinğŸ¨ ğŸ’»              Mandy MeindersmağŸ¨ ğŸ’»      LEGALISE PIRACYğŸ¨ ğŸ’»      Alex LogvinğŸ¨ ğŸ’»      Aria DahlğŸ¨ ğŸ’»      Mustafa ArifogluğŸ¨ ğŸ’»      Yevhen LeshchenkoğŸ¨ ğŸ’»      Anubhav AdhikariğŸ¨ ğŸ’»              Noah TatkoğŸ¨ ğŸ’»      Mohit GadhaviğŸ¨ ğŸ’»      Pedro BasÃ­lioğŸ¨ ğŸ’»      RealSanjeevğŸ¨ ğŸ’»      Akash HazrağŸ¨ ğŸ’»      Christoph DahlenğŸ¨ ğŸ’»      Vincent du PlessisğŸ¨ ğŸ’»              Karen TamrazyanğŸ¨ ğŸ’»      Mirza Younus BaigğŸ¨ ğŸ’»      Ashish KumarğŸ¨ ğŸ’»      Unknown6334ğŸ¨ ğŸ’»      flowazğŸ¨ ğŸ’»      zi-aikrağŸ¨ ğŸ’»      PAYAL PMğŸ¨ ğŸ’»              Lennart LÃ¶scheğŸ¨ ğŸ’»      Yummy-YumsğŸ¨ ğŸ’»      Njuacha Hubert MikulowskiğŸ¨ ğŸ’»      Hussein EsmailğŸ¨ ğŸ’»      Bilgehan BezirğŸ¨ ğŸ’»      Muhammed ShittuğŸ¨ ğŸ’»      ClÃ©ment FERNANDESğŸ¨ ğŸ’»              JaCKoP619ğŸ¨ ğŸ’»      userutf8ğŸ¨ ğŸ’»      Mohamed UbaidğŸ¨ ğŸ’»      Justin YatesğŸ¨ ğŸ’»      mohammad aliğŸ¨ ğŸ’»      Madhav SinghğŸ¨ ğŸ’»      RgbMouse69ğŸ¨ ğŸ’»              Nicholas LeaskğŸ¨ ğŸ’»      parthav0ğŸ¨ ğŸ’»      SigmağŸ¨ ğŸ’»      Evelina BechevağŸ¨ ğŸ’»      Akshit GulyanğŸ¨ ğŸ’»      Arpita JanağŸ¨ ğŸ’»      Praveen KumarğŸ¨ ğŸ’»              Mohammad SamiğŸ¨ ğŸ’»      eddiestefanescuğŸ¨ ğŸ’»      Ramesh YadavğŸ¨ ğŸ’»      Sarthak JoshiğŸ¨ ğŸ’»      Nikhil12300ğŸ¨ ğŸ’»      YevgenğŸ¨ ğŸ’»      LeoğŸ¨ ğŸ’»              laurent bğŸ¨ ğŸ’»      MettchenğŸ¨ ğŸ’»      Ali MahdaviğŸ¨ ğŸ’»      Lucas DondoğŸ¨ ğŸ’»      Siddhesh AgarwalğŸ¨ ğŸ’»      slimerPuncherğŸ¨ ğŸ’»      saritashhğŸ¨ ğŸ’»              Iulian-Valeriu CioatÄƒğŸ¨ ğŸ’»      Szabolcs NagyğŸ¨ ğŸ’»      Jarle KvileğŸ¨ ğŸ’»      åŠ‰è€€å‡ Vic LiuğŸ¨ ğŸ’»      SuryanshğŸ¨ ğŸ’»      Matthew OosthuyseğŸ¨ ğŸ’»      Florin ZamfirğŸ¨ ğŸ’»              MelekğŸ¨ ğŸ’»      moesocioğŸ¨ ğŸ’»      Alan JamesğŸ¨ ğŸ’»      Mai Thanh PhÆ°Æ¡ngğŸ¨ ğŸ’»      Neville DabreğŸ¨ ğŸ’»      MaksymğŸ¨ ğŸ’»      tamanna900ğŸ¨ ğŸ’»              Adithya AwatiğŸ¨ ğŸ’»      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
23,wangzheng0822/algo,https://github.com/wangzheng0822/algo/blob/master/README.md,Python,æ•°æ®ç»“æ„å’Œç®—æ³•å¿…çŸ¥å¿…ä¼šçš„50ä¸ªä»£ç å®ç°å¾®ä¿¡æœç´¢æˆ‘çš„å…¬ä¼—å·â€œå°äº‰å“¥â€ï¼Œæˆ–è€…å¾®ä¿¡æ‰«æä¸‹é¢äºŒç»´ç å…³æ³¨å…³æ³¨å¾®ä¿¡å…¬ä¼—å·ï¼Œå›å¤â€PDFâ€œè·å–ç‹¬å®¶ç®—æ³•èµ„æ–™ã€‚å‰Googleå·¥ç¨‹å¸ˆï¼Œ10ä¸‡äººè·Ÿç€å­¦çš„ã€Šæ•°æ®ç»“æ„å’Œç®—æ³•ä¹‹ç¾ã€‹ã€Šè®¾è®¡æ¨¡å¼ä¹‹ç¾ã€‹ä¸“æ ä½œè€…æ•°ç»„å®ç°ä¸€ä¸ªæ”¯æŒåŠ¨æ€æ‰©å®¹çš„æ•°ç»„å®ç°ä¸€ä¸ªå¤§å°å›ºå®šçš„æœ‰åºæ•°ç»„ï¼Œæ”¯æŒåŠ¨æ€å¢åˆ æ”¹æ“ä½œå®ç°ä¸¤ä¸ªæœ‰åºæ•°ç»„åˆå¹¶ä¸ºä¸€ä¸ªæœ‰åºæ•°ç»„é“¾è¡¨å®ç°å•é“¾è¡¨ã€å¾ªç¯é“¾è¡¨ã€åŒå‘é“¾è¡¨ï¼Œæ”¯æŒå¢åˆ æ“ä½œå®ç°å•é“¾è¡¨åè½¬å®ç°ä¸¤ä¸ªæœ‰åºçš„é“¾è¡¨åˆå¹¶ä¸ºä¸€ä¸ªæœ‰åºé“¾è¡¨å®ç°æ±‚é“¾è¡¨çš„ä¸­é—´ç»“ç‚¹æ ˆç”¨æ•°ç»„å®ç°ä¸€ä¸ªé¡ºåºæ ˆç”¨é“¾è¡¨å®ç°ä¸€ä¸ªé“¾å¼æ ˆç¼–ç¨‹æ¨¡æ‹Ÿå®ç°ä¸€ä¸ªæµè§ˆå™¨çš„å‰è¿›ã€åé€€åŠŸèƒ½é˜Ÿåˆ—ç”¨æ•°ç»„å®ç°ä¸€ä¸ªé¡ºåºé˜Ÿåˆ—ç”¨é“¾è¡¨å®ç°ä¸€ä¸ªé“¾å¼é˜Ÿåˆ—å®ç°ä¸€ä¸ªå¾ªç¯é˜Ÿåˆ—é€’å½’ç¼–ç¨‹å®ç°æ–æ³¢é‚£å¥‘æ•°åˆ—æ±‚å€¼f(n)=f(n-1)+f(n-2)ç¼–ç¨‹å®ç°æ±‚é˜¶ä¹˜n!ç¼–ç¨‹å®ç°ä¸€ç»„æ•°æ®é›†åˆçš„å…¨æ’åˆ—æ’åºå®ç°å½’å¹¶æ’åºã€å¿«é€Ÿæ’åºã€æ’å…¥æ’åºã€å†’æ³¡æ’åºã€é€‰æ‹©æ’åºç¼–ç¨‹å®ç°O(n)æ—¶é—´å¤æ‚åº¦å†…æ‰¾åˆ°ä¸€ç»„æ•°æ®çš„ç¬¬Kå¤§å…ƒç´ äºŒåˆ†æŸ¥æ‰¾å®ç°ä¸€ä¸ªæœ‰åºæ•°ç»„çš„äºŒåˆ†æŸ¥æ‰¾ç®—æ³•å®ç°æ¨¡ç³ŠäºŒåˆ†æŸ¥æ‰¾ç®—æ³•ï¼ˆæ¯”å¦‚å¤§äºç­‰äºç»™å®šå€¼çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰æ•£åˆ—è¡¨å®ç°ä¸€ä¸ªåŸºäºé“¾è¡¨æ³•è§£å†³å†²çªé—®é¢˜çš„æ•£åˆ—è¡¨å®ç°ä¸€ä¸ªLRUç¼“å­˜æ·˜æ±°ç®—æ³•å­—ç¬¦ä¸²å®ç°ä¸€ä¸ªå­—ç¬¦é›†ï¼ŒåªåŒ…å«aï½zè¿™26ä¸ªè‹±æ–‡å­—æ¯çš„Trieæ ‘å®ç°æœ´ç´ çš„å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•äºŒå‰æ ‘å®ç°ä¸€ä¸ªäºŒå‰æŸ¥æ‰¾æ ‘ï¼Œå¹¶ä¸”æ”¯æŒæ’å…¥ã€åˆ é™¤ã€æŸ¥æ‰¾æ“ä½œå®ç°æŸ¥æ‰¾äºŒå‰æŸ¥æ‰¾æ ‘ä¸­æŸä¸ªèŠ‚ç‚¹çš„åç»§ã€å‰é©±èŠ‚ç‚¹å®ç°äºŒå‰æ ‘å‰ã€ä¸­ã€ååºä»¥åŠæŒ‰å±‚éå†å †å®ç°ä¸€ä¸ªå°é¡¶å †ã€å¤§é¡¶å †ã€ä¼˜å…ˆçº§é˜Ÿåˆ—å®ç°å †æ’åºåˆ©ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—åˆå¹¶Kä¸ªæœ‰åºæ•°ç»„æ±‚ä¸€ç»„åŠ¨æ€æ•°æ®é›†åˆçš„æœ€å¤§Top Kå›¾å®ç°æœ‰å‘å›¾ã€æ— å‘å›¾ã€æœ‰æƒå›¾ã€æ— æƒå›¾çš„é‚»æ¥çŸ©é˜µå’Œé‚»æ¥è¡¨è¡¨ç¤ºæ–¹æ³•å®ç°å›¾çš„æ·±åº¦ä¼˜å…ˆæœç´¢ã€å¹¿åº¦ä¼˜å…ˆæœç´¢å®ç°Dijkstraç®—æ³•ã€A*ç®—æ³•å®ç°æ‹“æ‰‘æ’åºçš„Kahnç®—æ³•ã€DFSç®—æ³•å›æº¯åˆ©ç”¨å›æº¯ç®—æ³•æ±‚è§£å…«çš‡åé—®é¢˜åˆ©ç”¨å›æº¯ç®—æ³•æ±‚è§£0-1èƒŒåŒ…é—®é¢˜åˆ†æ²»åˆ©ç”¨åˆ†æ²»ç®—æ³•æ±‚ä¸€ç»„æ•°æ®çš„é€†åºå¯¹ä¸ªæ•°åŠ¨æ€è§„åˆ’0-1èƒŒåŒ…é—®é¢˜æœ€å°è·¯å¾„å’Œç¼–ç¨‹å®ç°è±æ–‡æ–¯å¦æœ€çŸ­ç¼–è¾‘è·ç¦»ç¼–ç¨‹å®ç°æŸ¥æ‰¾ä¸¤ä¸ªå­—ç¬¦ä¸²çš„æœ€é•¿å…¬å…±å­åºåˆ—ç¼–ç¨‹å®ç°ä¸€ä¸ªæ•°æ®åºåˆ—çš„æœ€é•¿é€’å¢å­åºåˆ—
24,encode/django-rest-framework,https://github.com/encode/django-rest-framework/blob/master/README.md,Python,"Django REST frameworkAwesome web-browsable Web APIs.Full documentation for the project is available at https://www.django-rest-framework.org/.FundingREST framework is a collaboratively funded project. If you useREST framework commercially we strongly encourage you to invest in itscontinued development by signing up for a paid plan.The initial aim is to provide a single full-time position on REST framework.Every single sign-up makes a significant impact towards making that possible.Many thanks to all our wonderful sponsors, and in particular to our premium backers, Sentry, Stream, Spacinov, Retool, bit.io, PostHog, CryptAPI, and FEZTO.OverviewDjango REST framework is a powerful and flexible toolkit for building Web APIs.Some reasons you might want to use REST framework:The Web browsable API is a huge usability win for your developers.Authentication policies including optional packages for OAuth1a and OAuth2.Serialization that supports both ORM and non-ORM data sources.Customizable all the way down - just use regular function-based views if you don't need the more powerful features.Extensive documentation, and great community support.There is a live example API for testing purposes, available here.Below: Screenshot from the browsable APIRequirementsPython 3.6+Django 4.2, 4.1, 4.0, 3.2, 3.1, 3.0We highly recommend and only officially support the latest patch release ofeach Python and Django series.InstallationInstall using pip...pip install djangorestframeworkAdd 'rest_framework' to your INSTALLED_APPS setting.INSTALLED_APPS = [    ...    'rest_framework',]ExampleLet's take a look at a quick example of using REST framework to build a simple model-backed API for accessing users and groups.Startup up a new project like so...pip install djangopip install djangorestframeworkdjango-admin startproject example ../manage.py migrate./manage.py createsuperuserNow edit the example/urls.py module in your project:from django.contrib.auth.models import Userfrom django.urls import include, pathfrom rest_framework import routers, serializers, viewsets# Serializers define the API representation.class UserSerializer(serializers.HyperlinkedModelSerializer):    class Meta:        model = User        fields = ['url', 'username', 'email', 'is_staff']# ViewSets define the view behavior.class UserViewSet(viewsets.ModelViewSet):    queryset = User.objects.all()    serializer_class = UserSerializer# Routers provide a way of automatically determining the URL conf.router = routers.DefaultRouter()router.register(r'users', UserViewSet)# Wire up our API using automatic URL routing.# Additionally, we include login URLs for the browsable API.urlpatterns = [    path('', include(router.urls)),    path('api-auth/', include('rest_framework.urls', namespace='rest_framework')),]We'd also like to configure a couple of settings for our API.Add the following to your settings.py module:INSTALLED_APPS = [    ...  # Make sure to include the default installed apps here.    'rest_framework',]REST_FRAMEWORK = {    # Use Django's standard `django.contrib.auth` permissions,    # or allow read-only access for unauthenticated users.    'DEFAULT_PERMISSION_CLASSES': [        'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly',    ]}That's it, we're done!./manage.py runserverYou can now open the API in your browser at http://127.0.0.1:8000/, and view your new 'users' API. If you use the Login control in the top right corner you'll also be able to add, create and delete users from the system.You can also interact with the API using command line tools such as curl. For example, to list the users endpoint:$ curl -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/[    {        \""url\"": \""http://127.0.0.1:8000/users/1/\"",        \""username\"": \""admin\"",        \""email\"": \""admin@example.com\"",        \""is_staff\"": true,    }]Or to create a new user:$ curl -X POST -d username=new -d email=new@example.com -d is_staff=false -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/{    \""url\"": \""http://127.0.0.1:8000/users/2/\"",    \""username\"": \""new\"",    \""email\"": \""new@example.com\"",    \""is_staff\"": false,}Documentation & SupportFull documentation for the project is available at https://www.django-rest-framework.org/.For questions and support, use the REST framework discussion group, or #restframework on libera.chat IRC.You may also want to follow the author on Twitter.SecurityPlease see the security policy."
25,saltstack/salt,https://github.com/saltstack/salt/blob/master/README.rst,Python,"Latest Salt DocumentationOpen an issue (bug report, feature request, etc.)Salt is the world's fastest, most intelligent and scalable automationengine.About SaltBuilt on Python, Salt is an event-driven automation tool and framework todeploy, configure, and manage complex IT systems. Use Salt to automate commoninfrastructure administration tasks and ensure that all the components of yourinfrastructure are operating in a consistent desired state.Salt has many possible uses, including configuration management, which involves:Managing operating system deployment and configuration.Installing and configuring software applications and services.Managing servers, virtual machines, containers, databases, web servers,network devices, and more.Ensuring consistent configuration and preventing configuration drift.Salt is ideal for configuration management because it is pluggable,customizable, and plays well with many existing technologies. Salt enables youto deploy and manage applications that use any tech stack running on nearly anyoperating system,including different types of network devices such as switches and routers from avariety of vendors.In addition to configuration management Salt can also:Automate and orchestrate routine IT processes, such as common required tasksfor scheduled server downtimes or upgrading operating systems or applications.Create self-aware, self-healing systems that can automatically respond tooutages, common administration problems, or other important events.About our sponsorsSalt powers VMware's VMware Aria Automation Config(previously vRealize Automation SaltStack Config / SaltStack Enterprise), and can be foundunder the hood of products from Juniper, Cisco, Cloudflare, Nutanix, SUSE, andTieto, to name a few.The original sponsor of our community, SaltStack, was acquired by VMware in 2020.The Salt Project remains an open source ecosystem that VMware supports andcontributes to. VMware ensures the code integrity and quality of the Saltmodules by acting as the official sponsor and manager of the Salt project. Manyof the core Salt Project contributors are also VMware employees. This teamcarefully reviews and enhances the Salt modules to ensure speed, quality, andsecurity.Download and install SaltSalt is tested and packaged to run on CentOS, Debian, RHEL, Ubuntu, MacOS,Windows, and more. Download Salt and get started now. Seesupported operating systemsfor more information.To download and install Salt, see:* The Salt install guide* Salt Project repositoryTechnical supportReport bugs or problems using Salt by opening an issue: https://github.com/saltstack/salt/issuesTo join our community forum where you can exchange ideas, best practices,discuss technical support questions, and talk to project maintainers, join ourSlack workspace: Salt Project Community SlackSalt Project documentationInstallation instructions, tutorials, in-depth API and module documentation:The Salt install guideThe Salt user guideLatest Salt documentationSalt's contributing guideSecurity advisoriesKeep an eye on the Salt ProjectSecurity Announcementslanding page. Salt Project recommends subscribing to theSalt Project Security RSS feedto receive notification when new information is available regarding securityannouncements.Other channels to receive security announcements include theSalt Community mailing listand the Salt Project Community Slack.Responsibly reporting security vulnerabilitiesWhen reporting security vulnerabilities for Salt or other SaltStack projects,refer to the SECURITY.md file found in this repository.Join our communitySalt is built by the Salt Project community, which includes more than 3,000contributors working in roles just like yours. This well-known and trustedcommunity works together to improve the underlying technology and extend Salt bycreating a variety of execution and state modules to accomplish the most commontasks or solve the most important problems that people in your role are likelyto face.If you want to help extend Salt or solve a problem with Salt, you can join ourcommunity and contribute today.Please be sure to review ourCode of Conduct.Also, check out some of our community resources including:Salt Project Community WikiSalt Project Community SlackSalt Project: IRC on LiberaChatSalt Project YouTube channelSalt Project Twitch channelThere are lots of ways to get involved in our community. Every month, there arearound a dozen opportunities to meet with other contributors and the Salt Coreteam and collaborate in real time. The best way to keep track is by subscribingto the Salt Project Community Events Calendar on the mainhttps://saltproject.io website.If you have additional questions, email us at saltproject@vmware.com or reach outdirectly to the Community Manager, Jimmy Chunga via Slack. We'd be glad tohave you join our community!LicenseSalt is licensed under the Apache 2.0 license. Pleasesee theLICENSE file for thefull text of the Apache license, followed by a full summary of the licensingused by external modules.A complete list of attributions and dependencies can be found here:salt/DEPENDENCIES.md"
26,openai/gpt-2,https://github.com/openai/gpt-2/blob/master/README.md,Python,"Status: Archive (code is provided as-is, no updates expected)gpt-2Code and models from the paper \""Language Models are Unsupervised Multitask Learners\"".You can read about GPT-2 and its staged release in our original blog post, 6 month follow-up post, and final post.We have also released a dataset for researchers to study their behaviors.* Note that our original parameter counts were wrong due to an error (in our previous blog posts and paper).  Thus you may have seen small referred to as 117M and medium referred to as 345M.UsageThis repository is meant to be a starting point for researchers and engineers to experiment with GPT-2.For basic information, see our model card.Some caveatsGPT-2 models' robustness and worst case behaviors are not well-understood.  As with any machine-learned model, carefully evaluate GPT-2 for your use case, especially if used without fine-tuning or in safety-critical applications where reliability is important.The dataset our GPT-2 models were trained on contains many texts with biases and factual inaccuracies, and thus GPT-2 models are likely to be biased and inaccurate as well.To avoid having samples mistaken as human-written, we recommend clearly labeling samples as synthetic before wide dissemination.  Our models are often incoherent or inaccurate in subtle ways, which takes more than a quick read for a human to notice.Work with usPlease let us know if youâ€™re doing interesting research with or working on applications of GPT-2!  Weâ€™re especially interested in hearing from and potentially working with those who are studyingPotential malicious use cases and defenses against them (e.g. the detectability of synthetic text)The extent of problematic content (e.g. bias) being baked into the models and effective mitigationsDevelopmentSee DEVELOPERS.mdContributorsSee CONTRIBUTORS.mdCitationPlease use the following bibtex entry:@article{radford2019language,  title={Language Models are Unsupervised Multitask Learners},  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},  year={2019}}Future workWe may release code for evaluating the models on various benchmarks.We are still considering release of the larger models.LicenseModified MIT"
27,jumpserver/jumpserver,https://github.com/jumpserver/jumpserver/blob/dev/README.md,Python,"  å¹¿å—æ¬¢è¿çš„å¼€æºå ¡å’æœº            JumpServer v3.0 æ­£å¼å‘å¸ƒã€‚        9 å¹´æ—¶é—´ï¼Œå€¾æƒ…æŠ•å…¥ï¼Œç”¨å¿ƒåšå¥½ä¸€æ¬¾å¼€æºå ¡å’æœºã€‚JumpServer æ˜¯å¹¿å—æ¬¢è¿çš„å¼€æºå ¡å’æœºï¼Œæ˜¯ç¬¦åˆ 4A è§„èŒƒçš„ä¸“ä¸šè¿ç»´å®‰å…¨å®¡è®¡ç³»ç»Ÿã€‚JumpServer å ¡å’æœºå¸®åŠ©ä¼ä¸šä»¥æ›´å®‰å…¨çš„æ–¹å¼ç®¡æ§å’Œç™»å½•å„ç§ç±»å‹çš„èµ„äº§ï¼ŒåŒ…æ‹¬ï¼šSSH: Linux / Unix / ç½‘ç»œè®¾å¤‡ ç­‰ï¼›Windows: Web æ–¹å¼è¿æ¥ / åŸç”Ÿ RDP è¿æ¥ï¼›æ•°æ®åº“: MySQL / MariaDB / PostgreSQL / Oracle / SQLServer / ClickHouse ç­‰ï¼›NoSQL: Redis / MongoDB ç­‰ï¼›GPT: ChatGPT ç­‰;äº‘æœåŠ¡: Kubernetes / VMware vSphere ç­‰;Web ç«™ç‚¹: å„ç±»ç³»ç»Ÿçš„ Web ç®¡ç†åå°ï¼›åº”ç”¨: é€šè¿‡ Remote App è¿æ¥å„ç±»åº”ç”¨ã€‚äº§å“ç‰¹è‰²å¼€æº: é›¶é—¨æ§›ï¼Œçº¿ä¸Šå¿«é€Ÿè·å–å’Œå®‰è£…ï¼›æ— æ’ä»¶: ä»…éœ€æµè§ˆå™¨ï¼Œæè‡´çš„ Web Terminal ä½¿ç”¨ä½“éªŒï¼›åˆ†å¸ƒå¼: æ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²å’Œæ¨ªå‘æ‰©å±•ï¼Œè½»æ¾æ”¯æŒå¤§è§„æ¨¡å¹¶å‘è®¿é—®ï¼›å¤šäº‘æ”¯æŒ: ä¸€å¥—ç³»ç»Ÿï¼ŒåŒæ—¶ç®¡ç†ä¸åŒäº‘ä¸Šé¢çš„èµ„äº§ï¼›å¤šç§Ÿæˆ·: ä¸€å¥—ç³»ç»Ÿï¼Œå¤šä¸ªå­å…¬å¸æˆ–éƒ¨é—¨åŒæ—¶ä½¿ç”¨ï¼›äº‘ç«¯å­˜å‚¨: å®¡è®¡å½•åƒäº‘ç«¯å­˜å‚¨ï¼Œæ°¸ä¸ä¸¢å¤±ï¼›UI å±•ç¤ºåœ¨çº¿ä½“éªŒç¯å¢ƒåœ°å€ï¼šhttps://demo.jumpserver.org/âš ï¸ æ³¨æ„è¯¥ç¯å¢ƒä»…ä½œä½“éªŒç›®çš„ä½¿ç”¨ï¼Œæˆ‘ä»¬ä¼šå®šæ—¶æ¸…ç†ã€é‡ç½®æ•°æ®ï¼è¯·å‹¿ä¿®æ”¹ä½“éªŒç¯å¢ƒç”¨æˆ·çš„å¯†ç ï¼è¯·å‹¿åœ¨ç¯å¢ƒä¸­æ·»åŠ ä¸šåŠ¡ç”Ÿäº§ç¯å¢ƒåœ°å€ã€ç”¨æˆ·åå¯†ç ç­‰æ•æ„Ÿä¿¡æ¯ï¼å¿«é€Ÿå¼€å§‹å¿«é€Ÿå…¥é—¨äº§å“æ–‡æ¡£åœ¨çº¿å­¦ä¹ çŸ¥è¯†åº“æ¡ˆä¾‹ç ”ç©¶è…¾è®¯æµ·å¤–æ¸¸æˆï¼šåŸºäºJumpServeræ„å»ºæ¸¸æˆå®‰å…¨è¿è¥èƒ½åŠ›ä¸‡ååŒ–å­¦ï¼šé€šè¿‡JumpServerç®¡ç†å…¨çƒåŒ–åˆ†å¸ƒå¼ITèµ„äº§ï¼Œå¹¶ä¸”å®ç°ä¸äº‘ç®¡å¹³å°çš„è”åŠ¨é›ªèŠ±å•¤é…’ï¼šJumpServerå ¡å’æœºä½¿ç”¨ä½“ä¼šé¡ºä¸°ç§‘æŠ€ï¼šJumpServer å ¡å’æœºæŠ¤èˆªé¡ºä¸°ç§‘æŠ€è¶…å¤§è§„æ¨¡èµ„äº§å®‰å…¨è¿ç»´æ²ç³æ¸¸æˆï¼šé€šè¿‡JumpServerç®¡æ§å¤šé¡¹ç›®åˆ†å¸ƒå¼èµ„äº§æºç¨‹ï¼šJumpServer å ¡å’æœºéƒ¨ç½²ä¸è¿è¥å®æˆ˜å¤§æ™ºæ…§ï¼šJumpServer å ¡å’æœºè®©â€œå¤§æ™ºæ…§â€çš„æ··åˆ IT è¿ç»´æ›´æ™ºæ…§å°çº¢ä¹¦ï¼šJumpServer å ¡å’æœºå¤§è§„æ¨¡èµ„äº§è·¨ç‰ˆæœ¬è¿ç§»ä¹‹è·¯ä¸­æ‰‹æ¸¸ï¼šJumpServerå ¡å’æœºåŠ©åŠ›ä¸­æ‰‹æ¸¸æå‡å¤šäº‘ç¯å¢ƒä¸‹å®‰å…¨è¿ç»´èƒ½åŠ›ä¸­é€šå¿«é€’ï¼šJumpServerä¸»æœºå®‰å…¨è¿ç»´å®è·µä¸œæ–¹æ˜ç ï¼šJumpServeré«˜æ•ˆç®¡æ§å¼‚æ„åŒ–ã€åˆ†å¸ƒå¼äº‘ç«¯èµ„äº§æ±Ÿè‹å†œä¿¡ï¼šJumpServerå ¡å’æœºåŠ©åŠ›è¡Œä¸šäº‘å®‰å…¨è¿ç»´ç¤¾åŒºäº¤æµå¦‚æœæ‚¨åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­æœ‰ä»»ä½•ç–‘é—®æˆ–å¯¹å»ºè®®ï¼Œæ¬¢è¿æäº¤ GitHub Issueã€‚æ‚¨ä¹Ÿå¯ä»¥åˆ°æˆ‘ä»¬çš„ ç¤¾åŒºè®ºå› å½“ä¸­è¿›è¡Œäº¤æµæ²Ÿé€šã€‚å‚ä¸è´¡çŒ®æ¬¢è¿æäº¤ PR å‚ä¸è´¡çŒ®ã€‚ å‚è€ƒ CONTRIBUTING.mdç»„ä»¶é¡¹ç›®é¡¹ç›®çŠ¶æ€æè¿°LinaJumpServer Web UI é¡¹ç›®LunaJumpServer Web Terminal é¡¹ç›®KoKoJumpServer å­—ç¬¦åè®® Connector é¡¹ç›®LionJumpServer å›¾å½¢åè®® Connector é¡¹ç›®ï¼Œä¾èµ– Apache GuacamoleRazorJumpServer RDP ä»£ç† Connector é¡¹ç›®TinkerJumpServer è¿œç¨‹åº”ç”¨ Connector é¡¹ç›®MagnusJumpServer æ•°æ®åº“ä»£ç† Connector é¡¹ç›®ChenJumpServer Web DB é¡¹ç›®ï¼Œæ›¿ä»£åŸæ¥çš„ OmniDBKaelJumpServer è¿æ¥ GPT èµ„äº§çš„ç»„ä»¶é¡¹ç›®WispJumpServer å„ç³»ç»Ÿç»ˆç«¯ç»„ä»¶å’Œ Core Api é€šä¿¡çš„ç»„ä»¶é¡¹ç›®ClientsJumpServer å®¢æˆ·ç«¯ é¡¹ç›®InstallerJumpServer å®‰è£…åŒ… é¡¹ç›®å®‰å…¨è¯´æ˜JumpServeræ˜¯ä¸€æ¬¾å®‰å…¨äº§å“ï¼Œè¯·å‚è€ƒ åŸºæœ¬å®‰å…¨å»ºè®®è¿›è¡Œå®‰è£…éƒ¨ç½²ã€‚å¦‚æœæ‚¨å‘ç°å®‰å…¨ç›¸å…³é—®é¢˜ï¼Œè¯·ç›´æ¥è”ç³»æˆ‘ä»¬ï¼šé‚®ç®±ï¼šsupport@fit2cloud.comç”µè¯ï¼š400-052-0755License & CopyrightCopyright (c) 2014-2023 é£è‡´äº‘ FIT2CLOUD, All rights reserved.Licensed under The GNU General Public License version 3 (GPLv3)  (the \""License\""); you may not use this file except incompliance with the License. You may obtain a copy of the License athttps://www.gnu.org/licenses/gpl-3.0.htmlUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \""AS IS\"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specificlanguage governing permissions and limitations under the License."
28,celery/celery,https://github.com/celery/celery/blob/main/README.rst,Python,"        Version:5.3.1 (emerald-rush)Web:https://docs.celeryq.dev/en/stable/index.htmlDownload:https://pypi.org/project/celery/Source:https://github.com/celery/celery/Keywords:task, queue, job, async, rabbitmq, amqp, redis,python, distributed, actorsDonationsThis project relies on your generous donations.If you are using Celery to create a commercial product, please consider becoming our backer or our sponsor to ensure Celery's future.For enterpriseAvailable as part of the Tidelift Subscription.The maintainers of celery and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more.What's a Task Queue?Task queues are used as a mechanism to distribute work across threads ormachines.A task queue's input is a unit of work, called a task, dedicated workerprocesses then constantly monitor the queue for new work to perform.Celery communicates via messages, usually using a brokerto mediate between clients and workers. To initiate a task a client puts amessage on the queue, the broker then delivers the message to a worker.A Celery system can consist of multiple workers and brokers, giving wayto high availability and horizontal scaling.Celery is written in Python, but the protocol can be implemented in anylanguage. In addition to Python there's node-celery for Node.js,a PHP client, gocelery, gopher-celery for Go, and rusty-celery for Rust.Language interoperability can also be achieved by using webhooksin such a way that the client enqueues an URL to be requested by a worker.What do I need?Celery version 5.3.1 runs on:Python (3.8, 3.9, 3.10, 3.11)PyPy3.8+ (v7.3.11+)This is the version of celery which will support Python 3.8 or newer.If you're running an older version of Python, you need to be runningan older version of Celery:Python 3.7: Celery 5.2 or earlier.Python 3.6: Celery 5.1 or earlier.Python 2.7: Celery 4.x series.Python 2.6: Celery series 3.1 or earlier.Python 2.5: Celery series 3.0 or earlier.Python 2.4: Celery series 2.2 or earlier.Celery is a project with minimal funding,so we don't support Microsoft Windows but it should be working.Please don't open any issues related to that platform.Celery is usually used with a message broker to send and receive messages.The RabbitMQ, Redis transports are feature complete,but there's also experimental support for a myriad of other solutions, includingusing SQLite for local development.Celery can run on a single machine, on multiple machines, or evenacross datacenters.Get StartedIf this is the first time you're trying to use Celery, or you'renew to Celery v5.3.1 coming from previous versions then you should read ourgetting started tutorials:First steps with CeleryTutorial teaching you the bare minimum needed to get started with Celery.Next stepsA more complete overview, showing more features.You can also get started with Celery by using a hosted broker transport CloudAMQP. The largest hosting provider of RabbitMQ is a proud sponsor of Celery.Celery is...SimpleCelery is easy to use and maintain, and does not need configuration files.It has an active, friendly community you can talk to for support,like at our mailing-list, or the IRC channel.Here's one of the simplest applications you can make:from celery import Celeryapp = Celery('hello', broker='amqp://guest@localhost//')@app.taskdef hello():    return 'hello world'Highly AvailableWorkers and clients will automatically retry in the eventof connection loss or failure, and some brokers supportHA in way of Primary/Primary or Primary/Replica replication.FastA single Celery process can process millions of tasks a minute,with sub-millisecond round-trip latency (using RabbitMQ,py-librabbitmq, and optimized settings).FlexibleAlmost every part of Celery can be extended or used on its own,Custom pool implementations, serializers, compression schemes, logging,schedulers, consumers, producers, broker transports, and much more.It supports...Message TransportsRabbitMQ, Redis, Amazon SQSConcurrencyPrefork, Eventlet, gevent, single threaded (solo)Result StoresAMQP, RedismemcachedSQLAlchemy, Django ORMApache Cassandra, IronCache, ElasticsearchSerializationpickle, json, yaml, msgpack.zlib, bzip2 compression.Cryptographic message signing.Framework IntegrationCelery is easy to integrate with web frameworks, some of which even haveintegration packages:Djangonot neededPyramidpyramid_celeryPylonscelery-pylonsFlasknot neededweb2pyweb2py-celeryTornadotornado-celeryThe integration packages aren't strictly necessary, but they can makedevelopment easier, and sometimes they add important hooks like closingdatabase connections at fork.DocumentationThe latest documentation is hosted at Read The Docs, containing user guides,tutorials, and an API reference.æœ€æ–°çš„ä¸­æ–‡æ–‡æ¡£æ‰˜ç®¡åœ¨ https://www.celerycn.io/ ä¸­ï¼ŒåŒ…å«ç”¨æˆ·æŒ‡å—ã€æ•™ç¨‹ã€APIæ¥å£ç­‰ã€‚InstallationYou can install Celery either via the Python Package Index (PyPI)or from source.To install using pip:$ pip install -U CeleryBundlesCelery also defines a group of bundles that can be usedto install Celery and the dependencies for a given feature.You can specify these in your requirements or on the pipcommand-line by using brackets. Multiple bundles can be specified byseparating them by commas.$ pip install \""celery[redis]\""$ pip install \""celery[redis,auth,msgpack]\""The following bundles are available:Serializerscelery[auth]:for using the auth security serializer.celery[msgpack]:for using the msgpack serializer.celery[yaml]:for using the yaml serializer.Concurrencycelery[eventlet]:for using the eventlet pool.celery[gevent]:for using the gevent pool.Transports and Backendscelery[amqp]:for using the RabbitMQ amqp python library.celery[redis]:for using Redis as a message transport or as a result backend.celery[sqs]:for using Amazon SQS as a message transport.celery[tblib]:for using the task_remote_tracebacks feature.celery[memcache]:for using Memcached as a result backend (using pylibmc)celery[pymemcache]:for using Memcached as a result backend (pure-Python implementation).celery[cassandra]:for using Apache Cassandra/Astra DB as a result backend with the DataStax driver.celery[azureblockblob]:for using Azure Storage as a result backend (using azure-storage)celery[s3]:for using S3 Storage as a result backend.celery[couchbase]:for using Couchbase as a result backend.celery[arangodb]:for using ArangoDB as a result backend.celery[elasticsearch]:for using Elasticsearch as a result backend.celery[riak]:for using Riak as a result backend.celery[cosmosdbsql]:for using Azure Cosmos DB as a result backend (using pydocumentdb)celery[zookeeper]:for using Zookeeper as a message transport.celery[sqlalchemy]:for using SQLAlchemy as a result backend (supported).celery[pyro]:for using the Pyro4 message transport (experimental).celery[slmq]:for using the SoftLayer Message Queue transport (experimental).celery[consul]:for using the Consul.io Key/Value store as a message transport or result backend (experimental).celery[django]:specifies the lowest version possible for Django support.You should probably not use this in your requirements, it's herefor informational purposes only.Downloading and installing from sourceDownload the latest version of Celery from PyPI:https://pypi.org/project/celery/You can install it by doing the following:$ tar xvfz celery-0.0.0.tar.gz$ cd celery-0.0.0$ python setup.py build# python setup.py installThe last command must be executed as a privileged user ifyou aren't currently using a virtualenv.Using the development versionWith pipThe Celery development version also requires the developmentversions of kombu, amqp, billiard, and vine.You can install the latest snapshot of these using the followingpip commands:$ pip install https://github.com/celery/celery/zipball/main#egg=celery$ pip install https://github.com/celery/billiard/zipball/main#egg=billiard$ pip install https://github.com/celery/py-amqp/zipball/main#egg=amqp$ pip install https://github.com/celery/kombu/zipball/main#egg=kombu$ pip install https://github.com/celery/vine/zipball/main#egg=vineWith gitPlease see the Contributing section.Getting HelpMailing listFor discussions about the usage, development, and future of Celery,please join the celery-users mailing list.IRCCome chat with us on IRC. The #celery channel is located at theLibera Chat network.Bug trackerIf you have any suggestions, bug reports, or annoyances please report themto our issue tracker at https://github.com/celery/celery/issues/Wikihttps://github.com/celery/celery/wikiCreditsContributorsThis project exists thanks to all the people who contribute. Development ofcelery happens at GitHub: https://github.com/celery/celeryYou're highly encouraged to participate in the developmentof celery. If you don't like GitHub (for some reason) you're welcometo send regular patches.Be sure to also read the Contributing to Celery section in thedocumentation.BackersThank you to all our backers! ğŸ™ [Become a backer]SponsorsSupport this project by becoming a sponsor. Your logo will show up here with alink to your website. [Become a sponsor]LicenseThis software is licensed under the New BSD License. See the LICENSEfile in the top distribution directory for the full license text."
29,donnemartin/system-design-primer,https://github.com/donnemartin/system-design-primer/blob/master/README-ja.md,Python,"English âˆ™ æ—¥æœ¬èª âˆ™ ç®€ä½“ä¸­æ–‡ âˆ™ ç¹é«”ä¸­æ–‡ | Ø§Ù„Ø¹ÙØ±ÙØ¨ÙÙŠÙÙ‘Ø©â€ âˆ™ à¦¬à¦¾à¦‚à¦²à¦¾ âˆ™ PortuguÃªs do Brasil âˆ™ Deutsch âˆ™ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ âˆ™ ×¢×‘×¨×™×ª âˆ™ Italiano âˆ™ í•œêµ­ì–´ âˆ™ ÙØ§Ø±Ø³ÛŒ âˆ™ Polski âˆ™ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº âˆ™ EspaÃ±ol âˆ™ à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ âˆ™ TÃ¼rkÃ§e âˆ™ tiáº¿ng Viá»‡t âˆ™ FranÃ§ais | Add Translationã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå…¥é–€    å‹•æ©Ÿãƒ»ç›®çš„å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’å­¦ã¶ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«å‚™ãˆã‚‹å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆã‚’å­¦ã¶ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’å­¦ã¶ã“ã¨ã¯ã€ã‚ˆã‚Šè‰¯ã„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ãªã‚‹ã“ã¨ã«è³‡ã™ã‚‹ã§ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã¯ã¨ã¦ã‚‚åºƒç¯„ãªãƒˆãƒ”ãƒƒã‚¯ã‚’å«ã¿ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆåŸç†ã«ã¤ã„ã¦ã¯ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã«ã¯è†¨å¤§ãªé‡ã®æ–‡çŒ®ãŒæ•£ã‚‰ã°ã£ã¦ã„ã¾ã™ã€‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã«å¿…è¦ãªçŸ¥è­˜ã‚’å­¦ã¶ã“ã¨ãŒã§ãã‚‹ æ–‡çŒ®ãƒªã‚¹ãƒˆã‚’ä½“ç³»çš„ã«ã¾ã¨ã‚ãŸã‚‚ã® ã§ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰å­¦ã¶ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ã“ã‚Œã‹ã‚‰ã‚‚ãšã£ã¨æ›´æ–°ã•ã‚Œã¦ã„ãã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸæ®µéšã«ã™ãã¾ã›ã‚“ã€‚Contributions ã¯å¤§æ­“è¿ã§ã™ï¼ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«å‚™ãˆã‚‹ã‚³ãƒ¼ãƒ‰æŠ€è¡“é¢æ¥ã«åŠ ãˆã¦ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«é–¢ã™ã‚‹çŸ¥è­˜ã¯ã€å¤šãã®ãƒ†ãƒƒã‚¯ä¼æ¥­ã«ãŠã‘ã‚‹ æŠ€è¡“æ¡ç”¨é¢æ¥ãƒ—ãƒ­ã‚»ã‚¹ ã§ å¿…è¦ä¸å¯æ¬ ãªè¦ç´  ã§ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§ã®é »å‡ºè³ªå•ã«å‚™ãˆã€è‡ªåˆ†ã®è§£ç­”ã¨æ¨¡ç¯„è§£ç­”:ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã€ã‚³ãƒ¼ãƒ‰ãã—ã¦å›³è¡¨ãªã©ã‚’æ¯”è¼ƒã—ã¦å­¦ã³ã¾ã—ã‚‡ã†ã€‚é¢æ¥æº–å‚™ã«å½¹ç«‹ã¤ãã®ä»–ã®ãƒˆãƒ”ãƒƒã‚¯:å­¦ç¿’æŒ‡é‡ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«ã©ã®ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ ã¨ãã®è§£ç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆèª²é¡Œä¾‹ã€ ã¨ãã®è§£ç­”ãã®ä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œä¾‹æš—è¨˜ã‚«ãƒ¼ãƒ‰    ã“ã®Ankiç”¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒƒã‚­ ã¯ã€é–“éš”åå¾©ã‚’æ´»ç”¨ã—ã¦ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ã‚­ãƒ¼ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®å­¦ç¿’ã‚’æ”¯æ´ã—ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒ‡ãƒƒã‚­ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆç·´ç¿’èª²é¡Œãƒ‡ãƒƒã‚­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ç·´ç¿’èª²é¡Œãƒ‡ãƒƒã‚­å¤–å‡ºå…ˆã‚„ç§»å‹•ä¸­ã®å‹‰å¼·ã«å½¹ç«‹ã¤ã§ã—ã‚‡ã†ã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŠ€è¡“èª²é¡Œç”¨ã®å•é¡Œ: ç·´ç¿’ç”¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰æŠ€è¡“é¢æ¥ç”¨ã®å•é¡Œã‚’æ¢ã—ã¦ã„ã‚‹å ´åˆã¯ã“ã¡ã‚‰    å§‰å¦¹ãƒªãƒã‚¸ãƒˆãƒªã® Interactive Coding Challengesã‚‚è¦‹ã¦ã¿ã¦ãã ã•ã„ã€‚è¿½åŠ ã®æš—è¨˜ãƒ‡ãƒƒã‚­ã‚«ãƒ¼ãƒ‰ã‚‚å…¥ã£ã¦ã„ã¾ã™ã€‚Coding deckã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰å­¦ã¶ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆç­‰ã®è²¢çŒ®ã¯ç©æ¥µçš„ã«ãŠé¡˜ã„ã—ã¾ã™:ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹æ”¹å–„æ–°è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ ç¿»è¨³ã™ã‚‹ç¾åœ¨ã€å†…å®¹ã®æ”¹å–„ãŒå¿…è¦ãªä½œæ¥­ä¸­ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã“ã¡ã‚‰ã§ã™ã€‚ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã®å‰ã«Contributing Guidelinesã‚’èª­ã¿ã¾ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆç›®æ¬¡è³›å¦ã‚‚å«ã‚ãŸæ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®å„ãƒˆãƒ”ãƒƒã‚¯ã®æ¦‚è¦ã€‚ å…¨ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚Šã¾ã™ã€‚ãã‚Œãã‚Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ˆã‚Šå­¦ã³ã‚’æ·±ã‚ã‚‹ã‚ˆã†ãªä»–ã®æ–‡çŒ®ã¸ã®ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚    ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯: ã¾ãšã¯ã“ã“ã‹ã‚‰Step 1: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹å‹•ç”»ã‚’è¦‹ã‚‹Step 2: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹è¨˜äº‹ã‚’èª­ã‚€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¯ç”¨æ€§ vs ä¸€è²«æ€§CAPç†è«–CP - ä¸€è²«æ€§(consistency)ã¨åˆ†å‰²æ€§(partition)è€æ€§AP - å¯ç”¨æ€§(availability)ã¨åˆ†å‰²æ€§(partition)è€æ€§ä¸€è²«æ€§ ãƒ‘ã‚¿ãƒ¼ãƒ³å¼±ã„ä¸€è²«æ€§çµæœæ•´åˆæ€§å¼·ã„ä¸€è²«æ€§å¯ç”¨æ€§ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ (DNS)ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CDN)ãƒ—ãƒƒã‚·ãƒ¥CDNãƒ—ãƒ«CDNãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ–/ãƒ‘ãƒƒã‚·ãƒ–æ§‹æˆã‚¢ã‚¯ãƒ†ã‚£ãƒ–/ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ§‹æˆLayer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· (WEBã‚µãƒ¼ãƒãƒ¼)ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ vs ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (RDBMS)ãƒã‚¹ã‚¿ãƒ¼/ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼/ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ãƒãƒ¼ãƒãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³SQL ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°NoSQLã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã‚°ãƒ©ãƒ• ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹SQL or NoSQLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°CDNã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°Webã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã™ã‚‹ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã®ã‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ (ãƒ©ã‚¤ãƒˆãƒãƒƒã‚¯)ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰éåŒæœŸå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼é€šä¿¡ä¼é€åˆ¶å¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ« (TCP)ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« (UDP)é éš”æ‰‹ç¶šå‘¼å‡º (RPC)Representational state transfer (REST)ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è£œéº2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ä¾‹é¡Œå®Ÿä¸–ç•Œã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å„ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°ä½œæ¥­ä¸­ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆé€£çµ¡æƒ…å ±ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å­¦ç¿’æŒ‡é‡å­¦ç¿’ã‚¹ãƒ‘ãƒ³ã«å¿œã˜ã¦ã¿ã‚‹ã¹ããƒˆãƒ”ãƒƒã‚¯ã‚¹ (short, medium, long)Q: é¢æ¥ã®ãŸã‚ã«ã¯ã€ã“ã“ã«ã‚ã‚‹ã‚‚ã®ã™ã¹ã¦ã‚’ã‚„ã‚‰ãªã„ã¨ã„ã‘ãªã„ã®ã§ã—ã‚‡ã†ã‹ï¼ŸA: ã„ãˆã€ã“ã“ã«ã‚ã‚‹ã™ã¹ã¦ã‚’ã‚„ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚é¢æ¥ã§ä½•ã‚’èã‹ã‚Œã‚‹ã‹ã¯ä»¥ä¸‹ã®æ¡ä»¶ã«ã‚ˆã£ã¦å¤‰ã‚ã£ã¦ãã¾ã™:ã©ã‚Œã ã‘ã®æŠ€è¡“çµŒé¨“ãŒã‚ã‚‹ã‹ã‚ãªãŸã®æŠ€è¡“èƒŒæ™¯ãŒä½•ã§ã‚ã‚‹ã‹ã©ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ãŸã‚ã«é¢æ¥ã‚’å—ã‘ã¦ã„ã‚‹ã‹ã©ã®ä¼æ¥­ã®é¢æ¥ã‚’å—ã‘ã¦ã„ã‚‹ã‹é‹ã‚ˆã‚ŠçµŒé¨“ã®ã‚ã‚‹å€™è£œè€…ã¯ä¸€èˆ¬çš„ã«ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«ã¤ã„ã¦ã‚ˆã‚Šæ·±ã„çŸ¥è­˜ã‚’æœ‰ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¦æ±‚ã•ã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã‚„ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ã¯å„ãƒ¡ãƒ³ãƒãƒ¼ã®æŒã¤ã‚ˆã†ãªçŸ¥è­˜ã‚ˆã‚Šã¯æ·±ã„è¦‹è­˜ã‚’æŒã£ã¦ã„ã‚‹ã¹ãã§ã—ã‚‡ã†ã€‚ä¸€æµãƒ†ãƒƒã‚¯ä¼æ¥­ã§ã¯è¤‡æ•°å›ã®è¨­è¨ˆé¢æ¥ã‚’èª²ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ã¾ãšã¯åºƒãå§‹ã‚ã¦ã€ãã“ã‹ã‚‰ã„ãã¤ã‹ã®åˆ†é‡ã«çµã£ã¦æ·±ã‚ã¦ã„ãã®ãŒã„ã„ã§ã—ã‚‡ã†ã€‚æ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦å°‘ã—ãšã¤çŸ¥ã£ã¦ãŠãã“ã¨ã¯ã„ã„ã“ã¨ã§ã™ã€‚ä»¥ä¸‹ã®å­¦ç¿’ã‚¬ã‚¤ãƒ‰ã‚’è‡ªåˆ†ã®å­¦ç¿’ã«å½“ã¦ã‚‰ã‚Œã‚‹æ™‚é–“ã€æŠ€è¡“çµŒé¨“ã€ã©ã®è·ä½ã€ã©ã®ä¼šç¤¾ã«å¿œå‹Ÿã—ã¦ã„ã‚‹ã‹ãªã©ã‚’åŠ å‘³ã—ã¦è‡ªåˆ†ç”¨ã«èª¿æ•´ã—ã¦ä½¿ã†ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚çŸ­æœŸé–“ - å¹…åºƒã ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚ã„ãã¤ã‹ã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚ä¸­æœŸé–“ - å¹…åºƒã ãã—ã¦ ãã‚Œãªã‚Šã«æ·±ãã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚å¤šãã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚é•·æœŸé–“ - å¹…åºƒã ãã—ã¦ ã‚‚ã£ã¨æ·±ãã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚ã»ã¼å…¨ã¦ã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚çŸ­æœŸé–“ä¸­æœŸé–“é•·æœŸé–“ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ ã‚’èª­ã¿ã€ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œæ©Ÿåºã«ã¤ã„ã¦åºƒãçŸ¥ã‚‹ğŸ‘ğŸ‘ğŸ‘æ¬¡ã®ãƒªãƒ³ã‚¯å…ˆã®ã„ãã¤ã‹ã®ãƒšãƒ¼ã‚¸ã‚’èª­ã‚“ã§ å„ä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ–ãƒ­ã‚° å¿œå‹Ÿã™ã‚‹ä¼šç¤¾ã«ã¤ã„ã¦çŸ¥ã‚‹ğŸ‘ğŸ‘ğŸ‘æ¬¡ã®ãƒªãƒ³ã‚¯å…ˆã®ã„ãã¤ã‹ã®ãƒšãƒ¼ã‚¸ã‚’èª­ã‚€ å®Ÿä¸–ç•Œã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ğŸ‘ğŸ‘ğŸ‘å¾©ç¿’ã™ã‚‹ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«ã©ã®ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã‹ğŸ‘ğŸ‘ğŸ‘ã¨ã‚Šã‚ãˆãšä¸€å‘¨ã™ã‚‹ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹SomeManyMostã¨ã‚Šã‚ãˆãšä¸€å‘¨ã™ã‚‹ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆå•é¡Œã¨è§£ç­”SomeManyMostå¾©ç¿’ã™ã‚‹ ãã®ä»–ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§ã®è³ªå•ä¾‹SomeManyMostã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã«ã©ã®ã‚ˆã†ã«ã—ã¦è‡¨ã‚ã°ã„ã„ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥è©¦é¨“å•é¡Œã«ã©ã®ã‚ˆã†ã«å–ã‚Šçµ„ã‚€ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã¯ open-ended conversation(Yes/Noã§ã¯ç­”ãˆã‚‰ã‚Œãªã„å£é ­è³ªå•)ã§ã™ã€‚ è‡ªåˆ†ã§ä¼šè©±ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã«å¾“ã£ã¦è­°è«–ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã“ã¨ãŒã§ãã‚‹ã§ã—ã‚‡ã†ã€‚ã“ã®éç¨‹ã‚’ç¢ºã‹ãªã‚‚ã®ã«ã™ã‚‹ãŸã‚ã«ã€æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ã¨ãã®è§£ç­” ã‚’ä»¥ä¸‹ã®æŒ‡é‡ã«å¾“ã£ã¦èª­ã¿è¾¼ã‚€ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚ã‚¹ãƒ†ãƒƒãƒ— 1: ãã®ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ä¾‹ã®æ¦‚è¦ã€åˆ¶ç´„ã€æ¨è¨ˆå€¤ç­‰ã‚’èãå‡ºã—ã€ã¾ã¨ã‚ã‚‹ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜ã®è¦æ±‚äº‹é …ã‚’èãå‡ºã—ã€å•é¡Œç®‡æ‰€ã‚’ç‰¹å®šã—ã¾ã—ã‚‡ã†ã€‚ä½¿ç”¨ä¾‹ã¨åˆ¶ç´„ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã®è³ªå•ã‚’æŠ•ã’ã‹ã‘ã¾ã—ã‚‡ã†ã€‚è¦æ±‚ã™ã‚‹æ¨è¨ˆå€¤ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚èª°ãŒãã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã†ã®ã‹ï¼Ÿã©ã®ã‚ˆã†ã«ä½¿ã†ã®ã‹ï¼Ÿä½•äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã„ã‚‹ã®ã‹ï¼Ÿã‚·ã‚¹ãƒ†ãƒ ã¯ã©ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’æœãŸã™ã®ã‹ï¼Ÿã‚·ã‚¹ãƒ†ãƒ ã¸ã®å…¥åŠ›ã¨å‡ºåŠ›ã¯ï¼Ÿã©ã‚Œã ã‘ã®å®¹é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒãå¿…è¦ãŒã‚ã‚‹ã®ã‹ï¼Ÿä¸€ç§’é–“ã«ä½•ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é€ä¿¡ãŒæƒ³å®šã•ã‚Œã‚‹ã‹ï¼Ÿèª­ã¿æ›¸ãæ¯”ç‡ã®æ¨å®šå€¤ã¯ã„ãã‚‰ç¨‹åº¦ã‹ï¼Ÿã‚¹ãƒ†ãƒƒãƒ— 2: ã‚ˆã‚Šé«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’çµ„ã¿ç«‹ã¦ã‚‹é‡è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å…¨ã¦è€ƒæ…®ã—ãŸé«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ¦‚è¦ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¨æ¥ç¶šã‚’ã‚¹ã‚±ãƒƒãƒã—ã¦æ›¸ãå‡ºã™è€ƒãˆã®è£ä»˜ã‘ã‚’ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ— 3: æ ¸ã¨ãªã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è¨­è¨ˆã™ã‚‹ãã‚Œãã‚Œã®ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦ã®è©³ç´°ã‚’å­¦ã¶ã€‚ä¾‹ãˆã°ã€urlçŸ­ç¸®ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆã‚’å•ã‚ã‚ŒãŸéš›ã«ã¯æ¬¡ã®ã‚ˆã†ã«ã™ã‚‹ã¨ã„ã„ã§ã—ã‚‡ã†:å…ƒã®URLã®ãƒãƒƒã‚·ãƒ¥åŒ–ã—ãŸã‚‚ã®ã‚’ä½œã‚Šã€ãã‚Œã‚’ä¿å­˜ã™ã‚‹MD5 ã¨ Base62ãƒãƒƒã‚·ãƒ¥è¡çªSQL ã‚‚ã—ãã¯ NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚ŒãŸURLã‚’å…ƒã®URLã«å†ç¿»è¨³ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‚ç…§API & ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã®è¨­è¨ˆã‚¹ãƒ†ãƒƒãƒ— 4: ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ã‚¹ã‚±ãƒ¼ãƒ«ä¸ãˆã‚‰ã‚ŒãŸåˆ¶ç´„æ¡ä»¶ã‹ã‚‰ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚Šãã†ãªã¨ã“ã‚ã‚’å‰²ã‚Šå‡ºã—ã€æ˜ç¢ºåŒ–ã™ã‚‹ã€‚  ä¾‹ãˆã°ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®å•é¡Œè§£æ±ºã®ãŸã‚ã«ä»¥ä¸‹ã®è¦ç´ ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å–ã‚Šã†ã‚‹è§£æ±ºç­–ã¨ãã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦è­°è«–ã‚’ã—ã‚ˆã†ã€‚å…¨ã¦ã®ã“ã¨ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ã€‚ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ã¤ã„ã¦ã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®åŸç†ã‚’èª­ã‚€ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚ã¡ã‚‡ã£ã¨ã—ãŸæš—ç®—å•é¡Œã¡ã‚‡ã£ã¨ã—ãŸæ¨è¨ˆå€¤ã‚’æ‰‹è¨ˆç®—ã§ã™ã‚‹ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚è£œéºã®ä»¥ä¸‹ã®é …ç›®ãŒå½¹ã«ç«‹ã¤ã§ã—ã‚‡ã†:ãƒãƒ©è£è¨ˆç®—ã§ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã™ã‚‹2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã£ã¦ãŠãã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®å‚è€ƒå€¤æ–‡çŒ®ã¨ãã®ä»–ã®å‚è€ƒè³‡æ–™ä»¥ä¸‹ã®ãƒªãƒ³ã‚¯å…ˆãƒšãƒ¼ã‚¸ã‚’è¦‹ã¦ã©ã®ã‚ˆã†ãªè³ªå•ã‚’æŠ•ã’ã‹ã‘ã‚‰ã‚Œã‚‹ã‹æ¦‚è¦ã‚’é ­ã«å…¥ã‚Œã¦ãŠãã¾ã—ã‚‡ã†:ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§æˆåŠŸã™ã‚‹ã«ã¯ï¼Ÿã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã¸ã®å°å…¥ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ã¨ãã®è§£ç­”é »å‡ºã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨å‚è€ƒè§£ç­”ã€ã‚³ãƒ¼ãƒ‰åŠã³ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è§£ç­”ã¯ solutions/ ãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã‚‹å•é¡ŒPastebin.com (ã‚‚ã—ãã¯ Bit.ly) ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Twitterã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ (ã‚‚ã—ãã¯Facebookãƒ•ã‚£ãƒ¼ãƒ‰)ã‚’è¨­è¨ˆã™ã‚‹Twitteræ¤œç´¢(ã‚‚ã—ãã¯Facebookæ¤œç´¢)æ©Ÿèƒ½ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”ã‚¦ã‚§ãƒ–ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Mint.comã‚’è¨­è¨ˆã™ã‚‹è§£ç­”SNSã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Amazonã®ã‚«ãƒ†ã‚´ãƒªæ¯ã®å£²ã‚Šä¸Šã’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”AWSä¸Šã§100ä¸‡äººè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå•é¡Œã‚’è¿½åŠ ã™ã‚‹ContributePastebin.com (ã‚‚ã—ãã¯ Bit.ly) ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Twitterã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³&æ¤œç´¢ (ã‚‚ã—ãã¯Facebookãƒ•ã‚£ãƒ¼ãƒ‰&æ¤œç´¢)ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹ã‚¦ã‚§ãƒ–ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®è¨­è¨ˆå•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Mint.comã®è¨­è¨ˆå•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹SNSã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Amazonã®ã‚«ãƒ†ã‚´ãƒªæ¯ã®å£²ã‚Šä¸Šã’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹AWSä¸Šã§100ä¸‡äººè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆå•é¡Œã¨è§£ç­”é »å‡ºã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨å‚è€ƒè§£ç­”ã€ã‚³ãƒ¼ãƒ‰åŠã³ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è§£ç­”ã¯ solutions/ ãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã‚‹å‚™è€ƒ: ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ä½œæ¥­ä¸­ã§ã™å•é¡Œãƒãƒƒã‚·ãƒ¥ãƒãƒƒãƒ—ã®è¨­è¨ˆè§£ç­”LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¨­è¨ˆè§£ç­”ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼ã®è¨­è¨ˆè§£ç­”ã‚«ãƒ¼ãƒ‰ã®ãƒ‡ãƒƒã‚­ã®è¨­è¨ˆè§£ç­”é§è»Šå ´ã®è¨­è¨ˆè§£ç­”ãƒãƒ£ãƒƒãƒˆã‚µãƒ¼ãƒãƒ¼ã®è¨­è¨ˆè§£ç­”å††å½¢é…åˆ—ã®è¨­è¨ˆContributeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå•é¡Œã‚’è¿½åŠ ã™ã‚‹Contributeã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚¹: ã¾ãšã¯ã“ã“ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®å‹‰å¼·ã¯åˆã‚ã¦ï¼Ÿã¾ãšåˆã‚ã«ã€ã‚ˆãä½¿ã‚ã‚Œã‚‹è¨­è¨ˆåŸç†ã«ã¤ã„ã¦ã€ãã‚Œã‚‰ãŒä½•ã§ã‚ã‚‹ã‹ã€ã©ã®ã‚ˆã†ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã‹ã€é•·æ‰€çŸ­æ‰€ã«ã¤ã„ã¦åŸºæœ¬çš„ãªçŸ¥è­˜ã‚’å¾—ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‚¹ãƒ†ãƒƒãƒ— 1: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹å‹•ç”»ã‚’è¦³ã¦å¾©ç¿’ã™ã‚‹Harvardã§ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®è¬›ç¾©ã“ã“ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚¹:å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒƒãƒ— 2: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹è³‡æ–™ã‚’èª­ã‚“ã§å¾©ç¿’ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã“ã“ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚¹:ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥éåŒæœŸæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—æ¬¡ã«ã€ãƒã‚¤ãƒ¬ãƒ™ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦ã¿ã¦ã„ã:ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¯ç”¨æ€§ vs ä¸€è²«æ€§å…¨ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ã¨ã„ã†ã®ã‚’è‚ã«å‘½ã˜ã¦ãŠãã¾ã—ã‚‡ã†ã€‚ãã‚Œã‹ã‚‰ã€ã‚ˆã‚Šæ·±ã„å†…å®¹ã€DNSã‚„CDNãã—ã¦ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãªã©ã«ã¤ã„ã¦å­¦ç¿’ã‚’é€²ã‚ã¦ã„ãã¾ã—ã‚‡ã†ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒªã‚½ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚Œã‚‹ã®ã«ã¤ã‚Œã¦ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãŒå‘ä¸Šã™ã‚‹å ´åˆãã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ« ã§ã‚ã‚‹ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚ä¸€èˆ¬çš„ã«ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã¨ã„ã†ã®ã¯ã™ãªã‚ã¡è¨ˆç®—å‡¦ç†ã‚’å¢—ã‚„ã™ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¢—ãˆãŸæ™‚ãªã©ã‚ˆã‚Šå¤§ããªå‡¦ç†ã‚’æŒã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚1ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹vsã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’ã¨ã‚‰ãˆã‚‹ä»–ã®è€ƒãˆæ–¹:ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ã§ã®å•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹æ™‚ã€ã‚ãªãŸã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä¸€äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦é…ã„ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ ã§ã®å•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹ã¨ãã€ä¸€äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã¯é€Ÿã„ã§ã™ãŒã€å¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚ã‚‹æ™‚ã«ã¯é…ããªã£ã¦ã—ã¾ã†ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«ã¤ã„ã¦ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€å¯ç”¨æ€§ã€å®‰å®šæ€§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ã¨ã¯ãªã«ãŒã—ã‹ã®å‹•ä½œã‚’è¡Œã†ã€ã‚‚ã—ãã¯çµæœã‚’ç®—å‡ºã™ã‚‹ã®ã«è¦ã™ã‚‹æ™‚é–“ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ ã¨ã¯ãã®ã‚ˆã†ãªå‹•ä½œã‚„çµæœç®—å‡ºãŒå˜ä½æ™‚é–“ã«è¡Œã‚ã‚Œã‚‹å›æ•°ä¸€èˆ¬çš„ã«ã€ æœ€å¤§é™ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ ã‚’ è¨±å®¹ç¯„å›²å†…ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ã§å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã®ãŒæ™®é€šã ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç†è§£ã™ã‚‹å¯ç”¨æ€§ vs ä¸€è²«æ€§CAP ç†è«–      Source: CAP theorem revisitedåˆ†æ•£å‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã¯ä¸‹ã®ä¸‰ã¤ã®ã†ã¡äºŒã¤ã¾ã§ã—ã‹åŒæ™‚ã«ä¿è¨¼ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€‚:ä¸€è²«æ€§ - å…¨ã¦ã®èª­ã¿è¾¼ã¿ã¯æœ€æ–°ã®æ›¸ãè¾¼ã¿ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã‚’å—ã‘å–ã‚‹å¯ç”¨æ€§ - å—ã‘å–ã‚‹æƒ…å ±ãŒæœ€æ–°ã®ã‚‚ã®ã ã¨ã„ã†ä¿è¨¼ã¯ãªã„ãŒã€å…¨ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¿…ãšå—ã‘å–ã‚‹åˆ†æ–­è€æ€§ - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œã«ã‚ˆã£ã¦é †ä¸åŒã®åˆ†æ–­ãŒèµ·ãã¦ã‚‚ã‚·ã‚¹ãƒ†ãƒ ãŒå‹•ä½œã‚’ç¶šã‘ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ä¿¡é ¼ã§ããªã„ã®ã§ã€åˆ†æ–­è€æ€§ã¯å¿…ãšä¿è¨¼ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ã¤ã¾ã‚Šã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã¯ã€ä¸€è²«æ€§ã‚’å–ã‚‹ã‹ã€å¯ç”¨æ€§ã‚’å–ã‚‹ã‹ã‚’è€ƒãˆãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚CP - ä¸€è²«æ€§ã¨åˆ†æ–­è€æ€§(consistency and partition tolerance)åˆ†æ–­ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¾…ã¡ç¶šã‘ã¦ã„ã‚‹ã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã«é™¥ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚CPã¯ã‚ãªãŸã®ã‚µãƒ¼ãƒ“ã‚¹ãŒã‚¢ãƒˆãƒŸãƒƒã‚¯ãªèª­ã¿æ›¸ãï¼ˆä¸å¯åˆ†æ“ä½œï¼‰ã‚’å¿…è¦ã¨ã™ã‚‹éš›ã«ã¯ã„ã„é¸æŠè‚¢ã§ã—ã‚‡ã†ã€‚AP - å¯ç”¨æ€§ã¨åˆ†æ–­è€æ€§(availability and partition tolerance)ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ãƒãƒ¼ãƒ‰ä¸Šã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã§æœ€æ–°ã®ã‚‚ã®ã‚’è¿”ã—ã¾ã™ã€‚ã¤ã¾ã‚Šã€æœ€æ–°ç‰ˆã®ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚åˆ†æ–­ãŒè§£æ¶ˆã•ã‚ŒãŸå¾Œã‚‚ã€æ›¸ãè¾¼ã¿ãŒåæ˜ ã•ã‚Œã‚‹ã®ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚çµæœæ•´åˆæ€§ã€€ã‚’æ±‚ã‚ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®éš›ã«ã¯APã‚’æ¡ç”¨ã™ã‚‹ã®ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã‚‚ã—ãã¯ã€å¤–éƒ¨ã‚¨ãƒ©ãƒ¼ã«é–¢ã‚ã‚‰ãšã‚·ã‚¹ãƒ†ãƒ ãŒç¨¼åƒã™ã‚‹å¿…è¦ãŒã‚ã‚‹éš›ã«ã‚‚åŒæ§˜ã§ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸CAP ç†è«–ã‚’æŒ¯ã‚Šè¿”ã‚‹å¹³æ˜“ãªè‹±èªã§ã®CAP ç†è«–ã®ã‚¤ãƒ³ãƒˆãƒ­CAP FAQä¸€è²«æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³åŒã˜ãƒ‡ãƒ¼ã‚¿ã®è¤‡è£½ãŒè¤‡æ•°ã‚ã‚‹çŠ¶æ…‹ã§ã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒä¸€è²«ã—ãŸãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚’å—ã‘å–ã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ã«ãã‚Œã‚‰ã‚’åŒæœŸã™ã‚Œã°ã„ã„ã®ã‹ã¨ã„ã†èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ CAP ç†è«– ã«ãŠã‘ã‚‹ä¸€è²«æ€§ã®å®šç¾©ã‚’æ€ã„å‡ºã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚å…¨ã¦ã®èª­ã¿å–ã‚Šã¯æœ€æ–°ã®æ›¸ãè¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã‚’å—ã‘å–ã‚‹ã¯ãšã§ã™ã€‚å¼±ã„ä¸€è²«æ€§æ›¸ãè¾¼ã¿å¾Œã®èª­ã¿å–ã‚Šã§ã¯ã€ãã®æœ€æ–°ã®æ›¸ãè¾¼ã¿ã‚’èª­ã‚ãŸã‚Šèª­ã‚ãªã‹ã£ãŸã‚Šã™ã‚‹ã€‚ãƒ™ã‚¹ãƒˆã‚¨ãƒ•ã‚©ãƒ¼ãƒˆå‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«åŸºã¥ãã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯memcachedãªã©ã®ã‚·ã‚¹ãƒ†ãƒ ã«è¦‹ã‚‰ã‚Œã¾ã™ã€‚å¼±ã„ä¸€è²«æ€§ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒå¿…è¦ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã€ä¾‹ãˆã°VoIPã€ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ«ãƒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚²ãƒ¼ãƒ ãªã©ã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ä¾‹ãˆã°ã€é›»è©±ã«å‡ºã¦ã„ã‚‹ã¨ãã«æ•°ç§’é–“éŸ³å£°ãŒå—ã‘å–ã‚Œãªããªã£ãŸã¨ã—ãŸã‚‰ã€ãã®å¾Œã«æ¥ç¶šãŒå›å¾©ã—ã¦ã‚‚ãã®æ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¦ã„ãŸé–“ã«è©±ã•ã‚Œã¦ã„ãŸã“ã¨ã¯èãå–ã‚Œãªã„ã¨ã„ã†ã‚ˆã†ãªæ„Ÿã˜ã§ã™ã€‚çµæœæ•´åˆæ€§æ›¸ãè¾¼ã¿ã®å¾Œã€èª­ã¿å–ã‚Šã¯æœ€çµ‚çš„ã«ã¯ãã®çµæœã‚’èª­ã¿å–ã‚‹ã“ã¨ãŒã§ãã‚‹(ãƒŸãƒªç§’ã»ã©é…ã‚Œã¦ã¨ã„ã†ã®ãŒä¸€èˆ¬çš„ã§ã™)ã€‚ãƒ‡ãƒ¼ã‚¿ã¯éåŒæœŸçš„ã«è¤‡è£½ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯DNSã‚„ãƒ¡ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãªã©ã«æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚çµæœæ•´åˆæ€§ã¯å¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚å¼·ã„ä¸€è²«æ€§æ›¸ãè¾¼ã¿ã®å¾Œã€èª­ã¿å–ã‚Šã¯ãã‚Œã‚’å¿…ãšèª­ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯åŒæœŸçš„ã«è¤‡è£½ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚„RDBMSãªã©ã§æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ‰±ã†ã‚µãƒ¼ãƒ“ã‚¹ã§ã¯å¼·ã„ä¸€è²«æ€§ãŒå¿…è¦ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼é–“ã§ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¯ç”¨æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³é«˜ã„å¯ç”¨æ€§ã‚’æ‹…ä¿ã™ã‚‹ã«ã¯ä¸»ã«æ¬¡ã®äºŒã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã™: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ ã¨ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã§ã™ã€‚ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã«ãŠã„ã¦ã¯ã€å‘¨æœŸä¿¡å·ã¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚‚ã—ãã¯ã‚¹ã‚¿ãƒ³ãƒã‚¤ä¸­ã®ãƒ‘ãƒƒã‚·ãƒ–ãªã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œã¾ã™ã€‚å‘¨æœŸä¿¡å·ãŒä¸­æ–­ã•ã‚ŒãŸæ™‚ã«ã¯ã€ãƒ‘ãƒƒã‚·ãƒ–ã ã£ãŸã‚µãƒ¼ãƒãƒ¼ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒ¼ãƒãƒ¼ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å¼•ãç¶™ã„ã§ã‚µãƒ¼ãƒ“ã‚¹ã‚’å†é–‹ã—ã¾ã™ã€‚èµ·å‹•ã¾ã§ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã¯ãƒ‘ãƒƒã‚·ãƒ–ã‚µãƒ¼ãƒãƒ¼ãŒã€Œãƒ›ãƒƒãƒˆã€ãªã‚¹ã‚¿ãƒ³ãƒã‚¤çŠ¶æ…‹ã«ã‚ã‚‹ã‹ã€ã€Œã‚³ãƒ¼ãƒ«ãƒ‰ã€ãªã‚¹ã‚¿ãƒ³ãƒã‚¤çŠ¶æ…‹ã«ã‚ã‚‹ã‹ã§å¤‰ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚µãƒ¼ãƒãƒ¼ã®ã¿ãŒãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ§‹æˆã§ã¯ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã“ã¨ã§è² è·ã‚’åˆ†æ•£ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒ‘ãƒ–ãƒªãƒƒã‚¯ãªã‚‚ã®ã®å ´åˆã€DNSã¯ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ã®ãƒ‘ãƒ–ãƒªãƒƒã‚¯IPã‚’çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚‚ã—ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªã‚‚ã®ãªå ´åˆã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ãŒä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã«ã¤ã„ã¦çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚çŸ­æ‰€: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã§ã¯ã‚ˆã‚Šå¤šãã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’è¦ã—ã€è¤‡é›‘ã•ãŒå¢—ã—ã¾ã™ã€‚æœ€æ–°ã®æ›¸ãè¾¼ã¿ãŒãƒ‘ãƒƒã‚·ãƒ–ã‚µãƒ¼ãƒãƒ¼ã«è¤‡è£½ã•ã‚Œã‚‹å‰ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãŒè½ã¡ã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿æ¬ æãŒèµ·ãã‚‹æ½œåœ¨å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–ã€€ã¨ã€€ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã¯ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã‚ˆã‚Šè©³ç´°ã«è§£èª¬ã•ã‚Œã¦ã„ã¾ã™:ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ       Source: DNS security presentationãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (DNS) ã¯ www.example.com ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚’IPã‚¢ãƒ‰ãƒ¬ã‚¹ã¸ã¨ç¿»è¨³ã—ã¾ã™ã€‚DNSã¯å°‘æ•°ã®ã‚ªãƒ¼ã‚½ãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ãŒä¸Šä½ã«ä½ç½®ã™ã‚‹éšå±¤çš„æ§‹é€ ã§ã™ã€‚ã‚ãªãŸã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚‚ã—ãã¯ISPã¯æ¤œç´¢ã‚’ã™ã‚‹éš›ã«ã©ã®DNSã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã‹ã¨ã„ã†æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚ä½ã„éšå±¤ã®DNSã‚µãƒ¼ãƒãƒ¼ã¯ãã®çµŒè·¯ãƒãƒƒãƒ—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚ãŸã ã€ã“ã®æƒ…å ±ã¯ä¼æ¬é…å»¶ã«ã‚ˆã£ã¦é™³è…åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚DNSã®çµæœã¯ã‚ãªãŸã®ãƒ–ãƒ©ã‚¦ã‚¶ã‚‚ã—ãã¯OSã«ä¸€å®šæœŸé–“ï¼ˆtime to live (TTL)ã«è¨­å®šã•ã‚ŒãŸæœŸé–“ï¼‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ã€‚NS record (name server) - ã‚ãªãŸã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®DNSã‚µãƒ¼ãƒãƒ¼ã‚’ç‰¹å®šã—ã¾ã™ã€‚MX record (mail exchange) - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚µãƒ¼ãƒãƒ¼ã‚’ç‰¹å®šã—ã¾ã™ã€‚A record (address) - IPã‚¢ãƒ‰ãƒ¬ã‚¹ã«åå‰ã‚’ã¤ã‘ã¾ã™ã€‚CNAME (canonical) - ä»–ã®åå‰ã‚‚ã—ãã¯ã€€CNAME (example.com ã‚’ www.example.com) ã‚‚ã—ãã¯ A recordã¸ã¨åå‰ã‚’æŒ‡ã—ç¤ºã™ã€‚CloudFlare ã‚„ Route 53 ãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒãƒãƒ¼ã‚¸ãƒ‰DNSã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã„ãã¤ã‹ã®DNSã‚µãƒ¼ãƒ“ã‚¹ã§ã¯æ§˜ã€…ãªæ‰‹æ³•ã‚’ä½¿ã£ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã“ã¨ãŒã§ãã¾ã™:åŠ é‡ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã®ã‚µãƒ¼ãƒãƒ¼ã«è¡Œãã®ã‚’é˜²ãã¾ã™æ§˜ã€…ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´ã—ã¾ã™A/B ãƒ†ã‚¹ãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãƒ™ãƒ¼ã‚¹åœ°ç†ãƒ™ãƒ¼ã‚¹æ¬ ç‚¹: DNSä¸Šè¨˜ã§ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã«ã‚ˆã£ã¦ç·©å’Œã•ã‚Œã¦ã„ã‚‹ã¨ã¯ã„ãˆã€DNSã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã«ã¯å°‘ã—é…å»¶ãŒç”Ÿã˜ã‚‹ã€‚DNSã‚µãƒ¼ãƒãƒ¼ã¯ã€æ”¿åºœã€ISPä¼æ¥­,ãã—ã¦å¤§ä¼æ¥­ã«ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãŒã€ãã‚Œã‚‰ã®ç®¡ç†ã¯è¤‡é›‘ã§ã‚ã‚‹ã€‚DNSã‚µãƒ¼ãƒ“ã‚¹ã¯DDoS attackã®ä¾‹ã§ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ãªã—ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒTwitterãªã©ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªããªã£ãŸã‚ˆã†ã«ã€æ”»æ’ƒã‚’å—ã‘ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸DNS ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£WikipediaDNS è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(Content delivery network)      Source: Why use a CDNã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CDN)ã¯ä¸–ç•Œä¸­ã«é…ç½®ã•ã‚ŒãŸãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¸€ç•ªåœ°ç†çš„ã«è¿‘ã„ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é…ä¿¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®ã“ã¨ã§ã™ã€‚Amazonã®CloudFrontãªã©ã¯ä¾‹å¤–çš„ã«ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚é…ä¿¡ã—ã¾ã™ãŒã€ä¸€èˆ¬çš„ã«ã€HTML/CSS/JSã€å†™çœŸã€ãã—ã¦å‹•ç”»ãªã©ã®é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãŒCDNã‚’é€šã˜ã¦é…ä¿¡ã•ã‚Œã¾ã™ã€‚ãã®ã‚µã‚¤ãƒˆã®DNSãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã©ã®ã‚µãƒ¼ãƒãƒ¼ã¨äº¤ä¿¡ã™ã‚‹ã‹ã¨ã„ã†æƒ…å ±ã‚’ä¼ãˆã¾ã™ã€‚CDNã‚’ç”¨ã„ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é…ä¿¡ã™ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®äºŒã¤ã®ç†ç”±ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒåŠ‡çš„ã«å‘ä¸Šã—ã¾ã™:ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è¿‘ãã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰å—ä¿¡ã§ãã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã¯CDNãŒå‡¦ç†ã—ã¦ãã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«é–¢ã—ã¦ã¯å‡¦ç†ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ãƒ—ãƒƒã‚·ãƒ¥CDNãƒ—ãƒƒã‚·ãƒ¥CDNã§ã¯ã‚µãƒ¼ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ã«æ›´æ–°ãŒã‚ã£ãŸæ™‚ã«ã¯å¿…ãšã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å—ã‘å–ã‚‹æ–¹å¼ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”¨æ„ã—ã€CDNã«ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€URLã‚’CDNã‚’æŒ‡ã™ã‚ˆã†ã«æŒ‡å®šã™ã‚‹ã¨ã“ã‚ã¾ã§ã€å…¨ã¦è‡ªåˆ†ã§è²¬ä»»ã‚’è² ã†å½¢ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã„ã¤æœŸé™åˆ‡ã‚Œã«ãªã‚‹ã®ã‹æ›´æ–°ã•ã‚Œã‚‹ã®ã‹ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ–°è¦ä½œæˆæ™‚ã€æ›´æ–°æ™‚ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã“ã¨ã§ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã¯æœ€å°åŒ–ã•ã‚Œã‚‹ä¸€æ–¹ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¯æœ€å¤§é™æ¶ˆè²»ã•ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å°‘ãªã„ã€ã‚‚ã—ãã¯é »ç¹ã«ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ›´æ–°ã•ã‚Œãªã„ã‚µã‚¤ãƒˆã®å ´åˆã«ã¯ãƒ—ãƒƒã‚·ãƒ¥CDNã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å®šæœŸçš„ã«å†ã³ãƒ—ãƒ«ã•ã‚Œã‚‹ã®ã§ã¯ãªãã€CDNã«ä¸€åº¦ã®ã¿é…ç½®ã•ã‚Œã¾ã™ã€‚ãƒ—ãƒ«CDNãƒ—ãƒ«CDNã§ã¯ä¸€äººç›®ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãŸæ™‚ã«ã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å–å¾—ã—ã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯è‡ªåˆ†ã®ã‚µãƒ¼ãƒãƒ¼ã«ä¿å­˜ã—ã¦ã€CDNã‚’æŒ‡ã™URLã‚’æ›¸ãæ›ãˆã¾ã™ã€‚çµæœã¨ã—ã¦ã€CDNã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã¾ã§ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ãŒé…ããªã‚Šã¾ã™ã€‚time-to-live (TTL) ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã©ã‚Œã ã‘ã®æœŸé–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã‹ã‚’è¦å®šã—ã¾ã™ã€‚ãƒ—ãƒ«CDNã¯CDN ä¸Šã§ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¹ãƒšãƒ¼ã‚¹ã‚’æœ€å°åŒ–ã—ã¾ã™ãŒã€æœ‰åŠ¹æœŸé™ãŒåˆ‡ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›´æ–°å‰ã«ãƒ—ãƒ«ã•ã‚Œã¦ã—ã¾ã†ã“ã¨ã§å†—é•·ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«ç¹‹ãŒã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å¤§è¦æ¨¡ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ã‚ã‚‹ã‚µã‚¤ãƒˆã§ã¯ãƒ—ãƒ«CDNãŒç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã¨ã„ã†ã®ã‚‚ã€ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å¤§éƒ¨åˆ†ã¯æœ€è¿‘ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚Œã€CDNã«æ®‹ã£ã¦ã„ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã‹ã‚‰ã§ã™ã€‚æ¬ ç‚¹: CDNCDNã®ã‚³ã‚¹ãƒˆã¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯é‡ã«ã‚ˆã£ã¦å¤‰ã‚ã‚Šã¾ã™ã€‚ã‚‚ã¡ã‚ã‚“ã€CDNã‚’ä½¿ã‚ãªã„å ´åˆã®ã‚³ã‚¹ãƒˆã¨æ¯”è¼ƒã™ã‚‹ã¹ãã§ã—ã‚‡ã†ã€‚TTLãŒåˆ‡ã‚Œã‚‹å‰ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ›´æ–°ã•ã‚Œã‚‹ã¨é™³è…åŒ–ã™ã‚‹æã‚ŒãŒã‚ã‚Šã¾ã™ã€‚CDNã§ã¯é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒCDNã‚’æŒ‡ã™ã‚ˆã†ã«URLã‚’æ›´æ–°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«åˆ†æ•£ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ—ãƒƒã‚·ãƒ¥CDNã¨ãƒ—ãƒ«CDNã®é•ã„Wikipediaãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼      Source: Scalable system design patternsãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯å…¥åŠ›ã•ã‚Œã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã¨åˆ†æ•£ã•ã›ã‚‹ã€‚ã©ã®ã‚±ãƒ¼ã‚¹ã§ã‚‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ã‚µãƒ¼ãƒãƒ¼ç­‰è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é©åˆ‡ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è¿”ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ä»¥ä¸‹ã®ã“ã¨ã«åŠ¹æœçš„ã§ã™:ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒçŠ¶æ…‹ã®è‰¯ããªã„ã‚µãƒ¼ãƒãƒ¼ã«è¡Œãã®ã‚’é˜²ããƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’éå‰°ã«é€ã‚‹ã®ã‚’é˜²ãç‰¹å®šç®‡æ‰€ã®æ¬ é™¥ã§ã‚µãƒ¼ãƒ“ã‚¹ãŒè½ã¡ã‚‹ã“ã¨ã‚’é˜²ããƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ (è²»ç”¨ã®é«˜ã„) ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚‚ã—ãã¯HAProxyãªã©ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã§å®Ÿç¾ã§ãã‚‹ã€‚ä»–ã®åˆ©ç‚¹ã¨ã—ã¦ã¯:SSL termination - å…¥åŠ›ã•ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£èª­ã™ã‚‹ã€ã¾ãŸã€ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æš—å·åŒ–ã™ã‚‹ã“ã¨ã§ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã‚µãƒ¼ãƒãƒ¼ãŒã“ã®ã‚³ã‚¹ãƒˆãŒé«˜ãã¤ããŒã¡ãªå‡¦ç†ã‚’è«‹ã‘è² ã‚ãªãã¦ã„ã„ã‚ˆã†ã«è‚©ä»£ã‚ã‚Šã—ã¾ã™ã€‚X.509 certificates ã‚’ãã‚Œãã‚Œã®ã‚µãƒ¼ãƒãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ã‚’ãªãã—ã¾ã™ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† - ã‚¯ãƒƒã‚­ãƒ¼ã‚’å–ã‚Šæ‰±ã†ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªãŒã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ãªã„æ™‚ãªã©ã«ã€ç‰¹å®šã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åŒã˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¸ã¨æµã—ã¾ã™ã€‚éšœå®³ã«å¯¾å¿œã™ã‚‹ãŸã‚ã«ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ– ã‚‚ã—ãã¯ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ– ãƒ¢ãƒ¼ãƒ‰ã®ã©ã¡ã‚‰ã«ãŠã„ã¦ã‚‚ã€è¤‡æ•°ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’é…ç½®ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªç¨®ã€…ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç”¨ã„ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™:ãƒ©ãƒ³ãƒ€ãƒ Least loadedã‚»ãƒƒã‚·ãƒ§ãƒ³/ã‚¯ãƒƒã‚­ãƒ¼ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ã‚‚ã—ãã¯åŠ é‡ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³Layer 4Layer 7Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ ã‚’å‚ç…§ã—ã¦ã©ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é…åˆ†ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ã—ã¦ã¯ã€ã‚½ãƒ¼ã‚¹ã€é€ä¿¡å…ˆIPã‚¢ãƒ‰ãƒ¬ã‚¹ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã«è¨˜è¿°ã•ã‚ŒãŸãƒãƒ¼ãƒˆç•ªå·ãŒå«ã¾ã‚Œã¾ã™ãŒã€ãƒ‘ã‚±ãƒƒãƒˆã®ä¸­èº«ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å«ã¿ã¾ã›ã‚“ã€‚ Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‘ã‚±ãƒƒãƒˆã‚’ä¸Šæµã‚µãƒ¼ãƒãƒ¼ã¸å±Šã‘ã€ä¸Šæµã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰é…ä¿¡ã™ã‚‹ã“ã¨ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ‰ãƒ¬ã‚¹å¤‰æ› Network Address Translation (NAT) ã‚’å®Ÿç¾ã—ã¾ã™ã€‚Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ ã‚’å‚ç…§ã—ã¦ã©ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é…åˆ†ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ã‚¯ãƒƒã‚­ãƒ¼ãªã©ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã“ã¨ã§ã™ã€‚Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®çµ‚ç«¯ã‚’å—ã‘æŒã¡ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã®åˆ¤æ–­ã‚’ã—ã€é¸æŠã—ãŸã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šã‚’ç¹‹ãã¾ã™ã€‚ä¾‹ãˆã° layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯å‹•ç”»ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ç›´æ¥ã€ãã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ›ã‚¹ãƒˆã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒãƒ¼ã«ã¤ãªãã¨åŒæ™‚ã«ã€æ±ºæ¸ˆå‡¦ç†ãªã©ã®ã‚ˆã‚Šç¹Šç´°ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ã«æµã™ã¨ã„ã†ã“ã¨ã‚‚ã§ãã‚‹ã€‚æŸ”è»Ÿæ€§ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãªã‚Šã¾ã™ãŒã€ layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ã¯Layer 7ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚ˆã‚Šã‚‚æ‰€è¦æ™‚é–“ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å°‘ãªãæ¸ˆã¾ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãŸã ã—ã€æ˜¨ä»Šã®æ±ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯æœ€å°é™ã®ã¿ã—ã‹ç™ºæ®ã§ããªã„ã§ã—ã‚‡ã†ã€‚æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ã¯æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å¯ç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ‰‹é ƒãªæ±ç”¨ãƒã‚·ãƒ³ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã•ã›ã‚‹æ–¹ãŒã€ä¸€ã¤ã®ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚ˆã‚Šé«˜ä¾¡ãªãƒã‚·ãƒ³ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ï¼ˆå‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã‚ˆã‚Šè²»ç”¨å¯¾åŠ¹æœã‚‚é«˜ããªã‚Šã€çµæœçš„ã«å¯ç”¨æ€§ã‚‚é«˜ããªã‚Šã¾ã™ã€‚ã¾ãŸã€æ±ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ‰±ãˆã‚‹äººæã‚’é›‡ã†æ–¹ãŒã€ç‰¹åŒ–å‹ã®å•†ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ‰±ãˆã‚‹äººæã‚’é›‡ã†ã‚ˆã‚Šã‚‚ç°¡å˜ã§ã—ã‚‡ã†ã€‚æ¬ ç‚¹: æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ°´å¹³çš„ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã„ãã¨ã€è¤‡é›‘ã•ãŒå¢—ã™ä¸Šã«ã€ã‚µãƒ¼ãƒãƒ¼ã®ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã«ãªã‚‹ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢é€£ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚„ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å†™çœŸãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã¯ã„ã‘ãªã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ä¸€å…ƒçš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (SQLã€ NoSQL)ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã«ã‚¹ãƒˆã‚¢ã•ã‚Œã‚‹ã‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ (Redisã€ Memcached)ã«æ®‹ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®ä¸‹æµã‚µãƒ¼ãƒãƒ¼ã¯ä¸Šæµã‚µãƒ¼ãƒãƒ¼ãŒã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã™ã‚‹ã«ã¤ã‚Œã¦ã‚ˆã‚Šå¤šãã®åŒæ™‚æ¥ç¶šã‚’ä¿ãŸãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚æ¬ ç‚¹: ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒªã‚½ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ãŸã‚Šã€è¨­å®šãŒé©åˆ‡ã§ãªã„å ´åˆã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å˜ä¸€éšœå®³ç‚¹ã‚’é™¤ã“ã†ã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’å°å…¥ã—ãŸçµæœã€è¤‡é›‘ã•ãŒå¢—ã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãŒä¸€ã¤ã ã‘ã ã¨ãã“ãŒå˜ä¸€éšœå®³ç‚¹ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚ä¸€æ–¹ã§ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’è¤‡æ•°ã«ã™ã‚‹ã¨ã€ã•ã‚‰ã«è¤‡é›‘ã•ãŒå¢—ã—ã¦ã—ã¾ã„ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸NGINX ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HAProxy ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¬ã‚¤ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£WikipediaLayer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ELB listener configãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·(webã‚µãƒ¼ãƒãƒ¼)      Source: Wikipedia  ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã¯å†…éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã¾ã¨ã‚ã¦å¤–éƒ¨ã«çµ±ä¸€ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãã‚Œã«å¯¾å¿œã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œã¦ã€ãã®å¾Œãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è¿”ã—ã¾ã™ã€‚ä»–ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªåˆ©ç‚¹ãŒã‚ã‚Šã¾ã™:ã‚ˆã‚Šå …ç‰¢ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã‚’éš ã—ãŸã‚Šã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆåŒ–ã—ãŸã‚Šã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã”ã¨ã®æ¥ç¶šæ•°ã‚’åˆ¶é™ã—ãŸã‚Šã§ãã¾ã™ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚„æŸ”è»Ÿæ€§ãŒå¢—ã—ã¾ã™ - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã®IPã—ã‹è¦‹ãªã„ã®ã§ã€è£ã§ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã—ãŸã‚Šã€è¨­å®šã‚’å¤‰ãˆã‚„ã™ããªã‚Šã¾ã™ã€‚SSL termination - å…¥åŠ›ã•ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£èª­ã—ã€ã‚µãƒ¼ãƒãƒ¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æš—å·åŒ–ã™ã‚‹ã“ã¨ã§ã‚µãƒ¼ãƒãƒ¼ãŒã“ã®ã‚³ã‚¹ãƒˆã®ã‹ã‹ã‚Šã†ã‚‹å‡¦ç†ã‚’ã—ãªãã¦æ¸ˆã‚€ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚X.509 è¨¼æ˜æ›¸ ã‚’å„ã‚µãƒ¼ãƒãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚åœ§ç¸® - ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åœ§ç¸®ã§ãã¾ã™ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚° - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã—ã¾ã™é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ - é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥é€ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚HTML/CSS/JSå†™çœŸå‹•ç”»ãªã©ãªã©ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ vs ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·è¤‡æ•°ã®ã‚µãƒ¼ãƒãƒ¼ãŒã‚ã‚‹æ™‚ã«ã¯ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨å½¹ã«ç«‹ã¤ã§ã—ã‚‡ã†ã€‚ ã—ã°ã—ã°ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯åŒã˜æ©Ÿèƒ½ã‚’æœãŸã™ã‚µãƒ¼ãƒãƒ¼ç¾¤ã¸ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã¾ã™ã€‚ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã§ã¯ã€ä¸Šè¨˜ã«è¿°ã¹ãŸã‚ˆã†ãªåˆ©ç‚¹ã‚’ã€å˜ä¸€ã®ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã‚„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å¯¾ã—ã¦ã‚‚ç¤ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚NGINX ã‚„ HAProxy ãªã©ã®æŠ€è¡“ã¯layer 7 ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚æ¬ ç‚¹: ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’å°å…¥ã™ã‚‹ã¨ã‚·ã‚¹ãƒ†ãƒ ã®è¤‡é›‘æ€§ãŒå¢—ã—ã¾ã™ã€‚å˜ä¸€ã®ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã¯å˜ä¸€éšœå®³ç‚¹ã«ãªã‚Šãˆã¾ã™ã€‚ä¸€æ–¹ã§ã€è¤‡æ•°ã®ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’å°å…¥ã™ã‚‹ã¨(ä¾‹: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼) è¤‡é›‘æ€§ã¯ã‚ˆã‚Šå¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· vs ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼NGINX ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HAProxy ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ã‚¬ã‚¤ãƒ‰Wikipediaã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤      Source: Intro to architecting systems for scaleã‚¦ã‚§ãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ (ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å±¤ã¨ã‚‚è¨€ã‚ã‚Œã‚‹) ã¨åˆ†é›¢ã™ã‚‹ã“ã¨ã§ãã‚Œãã‚Œã®å±¤ã‚’ç‹¬ç«‹ã«ã‚¹ã‚±ãƒ¼ãƒ«ã€è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚æ–°ã—ã„APIã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã«è¿½åŠ ã™ã‚‹éš›ã«ã€ä¸å¿…è¦ã«ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚å˜ä¸€è²¬ä»»ã®åŸå‰‡ ã§ã¯ã€å°ã•ã„è‡ªå¾‹çš„ãªã‚µãƒ¼ãƒ“ã‚¹ãŒå”èª¿ã—ã¦å‹•ãã‚ˆã†ã«æå”±ã—ã¦ã„ã¾ã™ã€‚å°ã•ã„ã‚µãƒ¼ãƒ“ã‚¹ã®å°ã•ã„ãƒãƒ¼ãƒ ãŒæ€¥æˆé•·ã®ãŸã‚ã«ã‚ˆã‚Šç©æ¥µçš„ãªè¨ˆç”»ã‚’ç«‹ã¦ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã¯éåŒæœŸå‡¦ç†ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ç‹¬ç«‹ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹ã€å°è¦æ¨¡ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§˜å¼ã§ã‚ã‚‹ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚‚ã“ã®è­°è«–ã«é–¢ä¿‚ã—ã¦ãã‚‹æŠ€è¡“ã§ã—ã‚‡ã†ã€‚ãã‚Œãã‚Œã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ç‹¬è‡ªã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å‡¦ç†ã—ã€æ˜ç¢ºã§è»½é‡ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§é€šä¿¡ã—ã¦ã€ãã®ç›®çš„ã¨ã™ã‚‹æ©Ÿèƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚1ä¾‹ãˆã°Pinterestã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã€ãƒ•ã‚£ãƒ¼ãƒ‰ã€æ¤œç´¢ã€å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãªã©ã§ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼Consulã€ Etcdã€ Zookeeper ãªã©ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®åå‰ã€ã‚¢ãƒ‰ãƒ¬ã‚¹ã€ãƒãƒ¼ãƒˆã®æƒ…å ±ã‚’ç›£è¦–ã™ã‚‹ã“ã¨ã§ã€ã‚µãƒ¼ãƒ“ã‚¹åŒå£«ãŒäº’ã„ã‚’è¦‹ã¤ã‘ã‚„ã™ãã—ã¦ã„ã¾ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ã®å®Œå…¨æ€§ã®ç¢ºèªã«ã¯ Health checks ãŒä¾¿åˆ©ã§ã€ã“ã‚Œã«ã¯ HTTP ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚ Consul ã¨ Etcd ã®ã„ãšã‚Œã‚‚çµ„ã¿è¾¼ã¿ã® key-value store ã‚’æŒã£ã¦ãŠã‚Šã€è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚„å…±æœ‰ãƒ‡ãƒ¼ã‚¿ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¦ãŠãã“ã¨ã«ä½¿ã‚ã‚Œã¾ã™ã€‚æ¬ ç‚¹: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€é‹ç”¨ã€ãã—ã¦ãƒ—ãƒ­ã‚»ã‚¹ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ç·©ãçµã³ä»˜ã‘ã‚‰ã‚ŒãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‚’è¿½åŠ ã™ã‚‹ã«ã¯ã€ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒ‡ãƒ—ãƒ­ã‚¤ã¨é‹ç”¨ã®ç‚¹ã‹ã‚‰è¦‹ã‚‹ã¨è¤‡é›‘æ€§ãŒå¢—ã™ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒˆãƒ­ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’ç´è§£ãã‚µãƒ¼ãƒ“ã‚¹æŒ‡å‘ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Zookeeperã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½œã‚‹ãŸã‚ã«çŸ¥ã£ã¦ãŠããŸã„ã“ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹      Source: Scaling up to your first 10 million usersãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (RDBMS)SQLãªã©ã®ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ•´ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®é›†åˆã§ã‚ã‚‹ã€‚ACID ã¯ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãŠã‘ã‚‹ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®é›†åˆã§ã‚ã‚‹ä¸å¯åˆ†æ€§ - ãã‚Œãã‚Œã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ã‚‹ã‹ãªã„ã‹ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹ä¸€è²«æ€§ - ã©ã‚“ãªãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚ã‚‹ç¢ºã‹ãªçŠ¶æ…‹ã‹ã‚‰æ¬¡ã®çŠ¶æ…‹ã«é·ç§»ã•ã›ã‚‹ã€‚ç‹¬ç«‹æ€§ - åŒæ™‚ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ã¯ã€é€£ç¶šçš„ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã®ã¨åŒã˜çµæœã‚’ã‚‚ãŸã‚‰ã™ã€‚æ°¸ç¶šæ€§ - ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãŒå‡¦ç†ã•ã‚ŒãŸã‚‰ã€ãã®ã‚ˆã†ã«ä¿å­˜ã•ã‚Œã‚‹ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ãŸã‚ã«ã¯ãŸãã•ã‚“ã®æŠ€è¡“ãŒã‚ã‚‹: ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ federationã€ ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ éæ­£è¦åŒ–ã€ ãã—ã¦ SQL ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒèª­ã¿å–ã‚Šã¨æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã—ã€æ›¸ãè¾¼ã¿ã‚’ä¸€ã¤ä»¥ä¸Šã®ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¤‡è£½ã—ã¾ã™ã€‚ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯èª­ã¿å–ã‚Šã®ã¿ã‚’å‡¦ç†ã—ã¾ã™ã€‚ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æœ¨æ§‹é€ ã®ã‚ˆã†ã«è¿½åŠ ã®ã‚¹ãƒ¬ãƒ¼ãƒ–ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã«ãªã£ãŸå ´åˆã«ã¯ã€ã„ãšã‚Œã‹ã®ã‚¹ãƒ¬ãƒ¼ãƒ–ãŒãƒã‚¹ã‚¿ãƒ¼ã«æ˜‡æ ¼ã™ã‚‹ã‹ã€æ–°ã—ã„ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚Œã‚‹ã¾ã§ã¯èª­ã¿å–ã‚Šå°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ã§ç¨¼åƒã—ã¾ã™ã€‚      Source: Scalability, availability, stability, patternsæ¬ ç‚¹: ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ãƒ¬ãƒ¼ãƒ–ã‚’ãƒã‚¹ã‚¿ãƒ¼ã«æ˜‡æ ¼ã•ã›ã‚‹ã«ã¯è¿½åŠ ã®ãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…è¦ã«ãªã‚‹ã€‚ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® ä¸¡æ–¹ ã®æ¬ ç‚¹ã¯æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã„ãšã‚Œã®ãƒã‚¹ã‚¿ãƒ¼ã‚‚èª­ã¿å–ã‚Šæ›¸ãè¾¼ã¿ã®ä¸¡æ–¹ã«å¯¾å¿œã™ã‚‹ã€‚æ›¸ãè¾¼ã¿ã«é–¢ã—ã¦ã¯ãã‚Œãã‚Œå”èª¿ã™ã‚‹ã€‚ã„ãšã‚Œã‹ã®ãƒã‚¹ã‚¿ãƒ¼ãŒè½ã¡ã¦ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¨ã—ã¦ã¯èª­ã¿æ›¸ãä¸¡æ–¹ã«å¯¾å¿œã—ãŸã¾ã¾é‹ç”¨ã§ãã‚‹ã€‚      Source: Scalability, availability, stability, patternsæ¬ ç‚¹: ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’å°å…¥ã™ã‚‹ã‹ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã©ã“ã«æ›¸ãè¾¼ã‚€ã‹ã‚’æŒ‡å®šã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚å¤§ä½“ã®ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä¸€è²«æ€§ãŒç·©ã„ï¼ˆACIDåŸç†ã‚’å®ˆã£ã¦ã„ãªã„ï¼‰ã‚‚ã—ãã¯ã€åŒæœŸã™ã‚‹æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã«æ›¸ãè¾¼ã¿ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã€‚æ›¸ãè¾¼ã¿ãƒãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚Œã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œæ›¸ãè¾¼ã¿ã®è¡çªã®å¯èƒ½æ€§ãŒå¢—ãˆã‚‹ã€‚ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® ä¸¡æ–¹ ã®æ¬ ç‚¹ã¯æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã‚’å‚ç…§æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚’è¤‡è£½ã™ã‚‹å‰ã«ãƒã‚¹ã‚¿ãƒ¼ãŒè½ã¡ãŸå ´åˆã«ã¯ãã®ãƒ‡ãƒ¼ã‚¿ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æ›¸ãè¾¼ã¿ã¯èª­ã¿å–ã‚Šãƒ¬ãƒ—ãƒªã‚«ã«ãŠã„ã¦ãƒªãƒ—ãƒ¬ã‚¤ã•ã‚Œã‚‹ã€‚æ›¸ãè¾¼ã¿ãŒå¤šã„å ´åˆã€è¤‡è£½ãƒãƒ¼ãƒ‰ãŒæ›¸ãè¾¼ã¿ã®å‡¦ç†ã®ã¿ã§è¡Œãè©°ã¾ã£ã¦ã€èª­ã¿å–ã‚Šã®å‡¦ç†ã‚’æº€è¶³ã«è¡Œãˆãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚èª­ã¿å–ã‚Šã‚¹ãƒ¬ãƒ¼ãƒ–ãƒãƒ¼ãƒ‰ã®æ•°ãŒå¤šã‘ã‚Œã°å¤šã„ã»ã©ã€è¤‡è£½ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„æ•°ã‚‚å¢—ãˆã€è¤‡è£½æ™‚é–“ãŒä¼¸ã³ã¦ã—ã¾ã„ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã£ã¦ã¯ã€ãƒã‚¹ã‚¿ãƒ¼ã¸ã®æ›¸ãè¾¼ã¿ã¯ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§ä¸¦åˆ—å‡¦ç†ã§ãã‚‹ä¸€æ–¹ã€ã‚¹ãƒ¬ãƒ¼ãƒ–ã¸ã®è¤‡è£½ã¯å˜ä¸€ã‚¹ãƒ¬ãƒƒãƒ‰ã§é€£ç¶šçš„ã«å‡¦ç†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€ å¯ç”¨æ€§ã€ ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒ«ãƒãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³Federation      Source: Scaling up to your first 10 million usersãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (ã‚‚ã—ãã¯æ©Ÿèƒ½åˆ†å‰²åŒ–ã¨ã‚‚è¨€ã†) ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ©Ÿèƒ½ã”ã¨ã«åˆ†å‰²ã™ã‚‹ã€‚ä¾‹ãˆã°ã€ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªå˜ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä»£ã‚ã‚Šã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã€ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ ã®ã‚ˆã†ã«ä¸‰ã¤ã«ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸€ã¤ã‚ãŸã‚Šã®æ›¸ãè¾¼ã¿ãƒ»èª­ã¿å–ã‚Šã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒæ¸›ã‚Šã€ãã®çµæœãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ©ã‚°ã‚‚çŸ­ããªã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå°ã•ããªã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã«åã¾ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒå¢—ãˆã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å±€æ‰€æ€§ãŒé«˜ã¾ã‚‹ãŸã‚ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã‚‚ä¸ŠãŒã‚Šã¾ã™ã€‚å˜ä¸€ã®ä¸­å¤®ãƒã‚¹ã‚¿ãƒ¼ã§æ›¸ãè¾¼ã¿ã‚’ç›´åˆ—åŒ–ã—ãŸã‚Šã—ãªã„ãŸã‚ã€ä¸¦åˆ—ã§æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚æ¬ ç‚¹: federationå¤§è¦æ¨¡ãªå‡¦ç†ã‚„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¦ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒã®å ´åˆã€ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯åŠ¹æœçš„ã¨ã¯è¨€ãˆãªã„ã§ã—ã‚‡ã†ã€‚ã©ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«èª­ã¿æ›¸ãã‚’ã™ã‚‹ã®ã‹ã‚’æŒ‡å®šã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ›´æ–°ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚server linkã§äºŒã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€£çµã™ã‚‹ã®ã¯ã‚ˆã‚Šè¤‡é›‘ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: federationScaling up to your first 10 million usersã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°      Source: Scalability, availability, stability, patternsã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãã‚Œãã‚ŒãŒãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ–ã‚»ãƒƒãƒˆæ–­ç‰‡ã®ã¿ã‚’æŒã¤ã‚ˆã†ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¾‹ã«ã¨ã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«ã¯ã‚ˆã‚Šå¤šãã®æ–­ç‰‡ãŒåŠ ãˆã‚‰ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚federationã®åˆ©ç‚¹ã«ä¼¼ã¦ã„ã¦ã€ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯èª­ã¿æ›¸ãã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æ¸›ã‚‰ã—ã€ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¸›ã‚‰ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã‚’å¢—ã‚„ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚‚æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™ã¨ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã‚¯ã‚¨ãƒªé€Ÿåº¦ãŒé€Ÿããªã‚Šã¾ã™ã€‚ãªã«ãŒã—ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡è£½ã™ã‚‹æ©Ÿèƒ½ãŒãªã‘ã‚Œã°ãƒ‡ãƒ¼ã‚¿ãƒ­ã‚¹ã«ã¤ãªãŒã‚Šã¾ã™ãŒã€ã‚‚ã—ã€ä¸€ã¤ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒè½ã¡ã¦ã‚‚ã€ä»–ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒå‹•ã„ã¦ã„ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜ãã€å˜ä¸€ã®ä¸­å¤®ãƒã‚¹ã‚¿ãƒ¼ãŒæ›¸ãè¾¼ã¿ã®å‡¦ç†ã‚’ã—ãªãã¦ã‚‚ã€ä¸¦åˆ—ã§æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ä¸€èˆ¬çš„ãªæ–¹æ³•ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ©ã‚¹ãƒˆãƒãƒ¼ãƒ ã‚¤ãƒ‹ã‚·ãƒ£ãƒ«ã§ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åœ°ç†çš„é…ç½®ã§ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ãªã©ã§ã™ã€‚æ¬ ç‚¹: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒ£ãƒ¼ãƒ‰ã«å¯¾å¿œã™ã‚‹ã‚ˆã†ã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚çµæœã¨ã—ã¦SQLã‚¯ã‚¨ãƒªãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ‰ã§ã¯ãƒ‡ãƒ¼ã‚¿é…åˆ†ãŒã„ã³ã¤ã«ãªã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€æ¨™æº–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é›†åˆã‚’æŒã¤ã‚·ãƒ£ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã€ãã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒä»–ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚ˆã‚Šã‚‚é‡ã„è² è·ã‚’è² ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒªãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã‚’ã™ã‚‹ã¨è¤‡é›‘æ€§ãŒã‚ˆã‚Šå¢—ã—ã¾ã™ã€‚consistent hashing ã«åŸºã¥ã„ãŸã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ã€é€šä¿¡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚è¤‡æ•°ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€£çµã™ã‚‹ã®ã¯ã‚ˆã‚Šè¤‡é›‘ã§ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒ£ãƒ¼ãƒ‰ã®ç™»å ´ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Consistent hashingéæ­£è¦åŒ–éæ­£è¦åŒ–ã§ã¯ã€æ›¸ãè¾¼ã¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã„ãã‚‰ã‹çŠ ç‰²ã«ã—ã¦èª­ã¿è¾¼ã¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚ˆã†ã¨ã—ã¾ã™ã€‚è¨ˆç®—çš„ã«é‡ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµåˆãªã©ã‚’ã›ãšã«ã€è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«å†—é•·ãªãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ãŒæ›¸ãè¾¼ã¾ã‚Œã‚‹ã®ã‚’è¨±å®¹ã—ã¾ã™ã€‚ã„ãã¤ã‹ã®RDBMSä¾‹ãˆã°ã€PostgreSQL ã‚„Oracleã¯ã“ã®å†—é•·ãªæƒ…å ±ã‚’å–ã‚Šæ‰±ã„ã€ä¸€è²«æ€§ã‚’ä¿ã¤ãŸã‚ã®materialized views ã¨ã„ã†æ©Ÿèƒ½ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ã‚„ ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã«ã‚ˆã£ã¦ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã«åˆ†é…ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’åˆä¸€ã•ã›ã‚‹ã“ã¨ã¯ã¨ã¦ã‚‚è¤‡é›‘ãªä½œæ¥­ã§ã™ã€‚éæ­£è¦åŒ–ã«ã‚ˆã£ã¦ãã®ã‚ˆã†ãªè¤‡é›‘ãªå‡¦ç†ã‚’ã—ãªãã¦æ¸ˆã‚€ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚å¤šãã®ã‚·ã‚¹ãƒ†ãƒ ã§ã€100å¯¾1ã‚ã‚‹ã„ã¯1000å¯¾1ãã‚‰ã„ã«ãªã‚‹ãã‚‰ã„èª­ã¿å–ã‚Šã®æ–¹ãŒã€æ›¸ãè¾¼ã¿ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚ˆã‚Šã‚‚å¤šã„ã“ã¨ã§ã—ã‚‡ã†ã€‚èª­ã¿è¾¼ã¿ã‚’è¡Œã†ãŸã‚ã«ã€è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¸ãƒ§ã‚¤ãƒ³å‡¦ç†ãŒå«ã¾ã‚Œã‚‹ã‚‚ã®ã¯è¨ˆç®—çš„ã«é«˜ä¾¡ã«ã¤ãã¾ã™ã—ã€ãƒ‡ã‚£ã‚¹ã‚¯ã®å‡¦ç†æ™‚é–“ã§è†¨å¤§ãªæ™‚é–“ã‚’è²»æ¶ˆã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ¬ ç‚¹: éæ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ãŒè¤‡è£½ã•ã‚Œã‚‹ã€‚å†—é•·ãªãƒ‡ãƒ¼ã‚¿ã®è¤‡è£½ãŒåŒæœŸã•ã‚Œã‚‹ã‚ˆã†ã«åˆ¶ç´„ãŒå­˜åœ¨ã—ã€ãã®ã“ã¨ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®è¨­è¨ˆãŒè¤‡é›‘åŒ–ã™ã‚‹ã€‚éæ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯éå¤§ãªæ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å ´åˆã€æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ãã‚Œã‚ˆã‚Šã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ãŠã„ã¦åŠ£ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: éæ­£è¦åŒ–DenormalizationSQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯åºƒç¯„ãªçŸ¥è­˜ã‚’å¿…è¦ã¨ã™ã‚‹åˆ†é‡ã§å¤šãã® æœ¬ ãŒæ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’æ˜ã‚‰ã‹ã«ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ä¸Šã§ã€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ã‚’å®šã‚ã€ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« ã™ã‚‹ã“ã¨ã¯ã¨ã¦ã‚‚é‡è¦ã§ã™ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - abãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€é«˜è² è·ã®çŠ¶æ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« - slow query log ãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çŠ¶æ³ã®ç¢ºèªã‚’ã—ã¾ã—ã‚‡ã†ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¨ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®ã‚ˆã†ãªåŠ¹ç‡åŒ–ã®é¸æŠè‚¢ã‚’ã¨ã‚‹ã“ã¨ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¹ã‚­ãƒ¼ãƒã‚’çµã‚‹MySQLã¯ã‚¢ã‚¯ã‚»ã‚¹é€Ÿåº¦å‘ä¸Šã®ãŸã‚ã€ãƒ‡ã‚£ã‚¹ã‚¯ä¸Šã®é€£ç¶šã—ãŸãƒ–ãƒ­ãƒƒã‚¯ã¸ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã—ã¦ã„ã¾ã™ã€‚é•·ã•ã®æ±ºã¾ã£ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å¯¾ã—ã¦ã¯ VARCHAR ã‚ˆã‚Šã‚‚ CHAR ã‚’ä½¿ã†ã‚ˆã†ã«ã—ã¾ã—ã‚‡ã†ã€‚CHAR ã®æ–¹ãŒåŠ¹ç‡çš„ã«é€Ÿããƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ ä¸€æ–¹ã€ VARCHAR ã§ã¯æ¬¡ã®ãƒ‡ãƒ¼ã‚¿ã«ç§»ã‚‹å‰ã«ãƒ‡ãƒ¼ã‚¿ã®æœ«å°¾ã‚’æ¤œçŸ¥ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ãŸã‚ã«é€Ÿåº¦ãŒçŠ ç‰²ã«ãªã‚Šã¾ã™ã€‚ãƒ–ãƒ­ã‚°ã®æŠ•ç¨¿ãªã©ã€å¤§ããªãƒ†ã‚­ã‚¹ãƒˆã«ã¯ TEXT ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚ TEXT ã§ã¯ãƒ–ãƒ¼ãƒªã‚¢ãƒ³å‹ã®æ¤œç´¢ã‚‚å¯èƒ½ã§ã™ã€‚ TEXT ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ã€ãƒ‡ã‚£ã‚¹ã‚¯ä¸Šã®å ´æ‰€ã¸ã®ãƒã‚¤ãƒ³ã‚¿ãƒ¼ãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚2ã®32ä¹—ã‚„40å„„ä»¥ä¸‹ã‚’è¶…ãˆãªã„ç¨‹åº¦ã®å¤§ããªæ•°ã«ã¯ INT ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚é€šè²¨ã«é–¢ã—ã¦ã¯å°æ•°ç‚¹è¡¨ç¤ºä¸Šã®ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã« DECIMAL ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚å¤§ããª BLOBS ã‚’ä¿å­˜ã™ã‚‹ã®ã¯é¿ã‘ã¾ã—ã‚‡ã†ã€‚ã©ã“ã‹ã‚‰ãã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–ã£ã¦ãã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã®æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚VARCHAR(255) ã¯8ãƒ“ãƒƒãƒˆã§æ•°ãˆã‚‰ã‚Œã‚‹æœ€å¤§ã®æ–‡å­—æ•°ã§ã™ã€‚ä¸€éƒ¨ã®DBMSã§ã¯ã€1ãƒã‚¤ãƒˆã®åˆ©ç”¨åŠ¹ç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«ã“ã®æ–‡å­—æ•°ãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚æ¤œç´¢æ€§èƒ½å‘ä¸Šã®ãŸã‚ ã€å¯èƒ½ã§ã‚ã‚Œã° NOT NULL åˆ¶ç´„ã‚’è¨­å®šã—ã¾ã—ã‚‡ã†ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åŠ¹æœçš„ã«ç”¨ã„ã‚‹ã‚¯ã‚¨ãƒª(SELECTã€ GROUP BYã€ ORDER BYã€ JOIN) ã®å¯¾è±¡ã¨ãªã‚‹åˆ—ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã†ã“ã¨ã§é€Ÿåº¦ã‚’å‘ä¸Šã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯é€šå¸¸ã€å¹³è¡¡æ¢ç´¢æœ¨ã§ã‚ã‚‹Bæœ¨ã®å½¢ã§è¡¨ã•ã‚Œã¾ã™ã€‚Bæœ¨ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ã¯å¸¸ã«ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸçŠ¶æ…‹ã«ãªã‚Šã¾ã™ã€‚ã¾ãŸæ¤œç´¢ã€é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ã€æŒ¿å…¥ã€å‰Šé™¤ã‚’å¯¾æ•°æ™‚é–“ã§è¡Œãˆã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é…ç½®ã™ã‚‹ã“ã¨ã¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªãƒ¼ã«æ®‹ã™ã“ã¨ã«ã¤ãªãŒã‚Šã‚ˆã‚Šå®¹é‡ã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°ã‚‚å¿…è¦ã«ãªã‚‹ãŸã‚æ›¸ãè¾¼ã¿ã‚‚é…ããªã‚Šã¾ã™ã€‚å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹éš›ã«ã¯ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ‡ã£ã¦ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å†ã³ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ“ãƒ«ãƒ‰ã—ãŸæ–¹ãŒé€Ÿã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚é«˜è² è·ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’é¿ã‘ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šå¿…è¦ãªã¨ã“ã‚ã«ã¯éæ­£è¦åŒ–ã‚’é©ç”¨ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆ†å‰²ã—ã€ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆã‚’ç‹¬ç«‹ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã«åˆ†é›¢ã—ã¦ãƒ¡ãƒ¢ãƒªãƒ¼ã«ä¹—ã›ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª¿æ•´ã™ã‚‹å ´åˆã«ã‚ˆã£ã¦ã¯ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°MySQLã‚¯ã‚¨ãƒªã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®TipsVARCHAR(255)ã‚’ã‚„ãŸã‚‰ã‚ˆãè¦‹ã‹ã‘ã‚‹ã®ã¯ãªã‚“ã§ï¼Ÿnullå€¤ã¯ã©ã®ã‚ˆã†ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã™ã‚‹ã®ã‹ï¼ŸSlow query logNoSQLNoSQL ã¯ key-value storeã€ document-storeã€ wide column storeã€ ã‚‚ã—ãã¯ graph databaseã«ã‚ˆã£ã¦è¡¨ç¾ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¤ãƒ†ãƒ ã®é›†åˆã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ä¸€èˆ¬çš„ã«æ­£è¦åŒ–ã•ã‚Œã¦ãŠã‚‰ãšã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã§ã‚¸ãƒ§ã‚¤ãƒ³ãŒè¡Œã‚ã‚Œã¾ã™ã€‚å¤§éƒ¨åˆ†ã®NoSQLã¯çœŸã®ACIDãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŒãŸãšã€ çµæœæ•´åˆæ€§ çš„ãªæŒ¯ã‚‹èˆã„ã®æ–¹ã‚’å¥½ã¿ã¾ã™ã€‚BASE ã¯ã—ã°ã—ã°NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚CAP Theorem ã¨å¯¾ç…§çš„ã«ã€BASEã¯ä¸€è²«æ€§ã‚ˆã‚Šã‚‚å¯ç”¨æ€§ã‚’å„ªå…ˆã—ã¾ã™ã€‚Basically available - ã‚·ã‚¹ãƒ†ãƒ ã¯å¯ç”¨æ€§ã‚’ä¿è¨¼ã—ã¾ã™ã€‚Soft state - ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã¯å…¥åŠ›ãŒãªãã¦ã‚‚æ™‚é–“çµŒéã¨ã¨ã‚‚ã«å¤‰åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚çµæœæ•´åˆæ€§ - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¯æ™‚é–“çµŒéã¨ã¨ã‚‚ã«ãã®é–“ã«å…¥åŠ›ãŒãªã„ã¨ã„ã†å‰æã®ã‚‚ã¨ã€ä¸€è²«æ€§ãŒé”æˆã•ã‚Œã¾ã™ã€‚SQLã‹ï¼ŸNoSQLã‹ï¼Ÿ ã‚’é¸æŠã™ã‚‹ã®ã«åŠ ãˆã¦ã€ã©ã®ã‚¿ã‚¤ãƒ—ã®NoSQLãŒã©ã®ä½¿ç”¨ä¾‹ã«æœ€ã‚‚é©ã™ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ã®ã¯ã¨ã¦ã‚‚æœ‰ç›Šã§ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã€ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã€ ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã€ ã¨ ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã«ã¤ã„ã¦è§¦ã‚Œã¦ã„ãã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢æ¦‚è¦: ãƒãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ä¸€èˆ¬çš„ã«O(1)ã®èª­ã¿æ›¸ããŒã§ãã€ãã‚Œã‚‰ã¯ãƒ¡ãƒ¢ãƒªãªã„ã—SSDã§è£ä»˜ã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¯ã‚­ãƒ¼ã‚’ è¾æ›¸çš„é †åº ã§ä¿æŒã™ã‚‹ã“ã¨ã§ã‚­ãƒ¼ã®åŠ¹ç‡çš„ãªå–å¾—ã‚’å¯èƒ½ã«ã—ã¦ã„ã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å€¤ã¨ã¨ã‚‚ã«ä¿æŒã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã¯ãƒã‚¤ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãªæŒ™å‹•ãŒå¯èƒ½ã§ã€å˜ç´”ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ãªã©ã®ãƒ‡ãƒ¼ã‚¿ãŒæ€¥é€Ÿã«å¤‰ã‚ã‚‹å ´åˆãªã©ã«ä½¿ã‚ã‚Œã¾ã™ã€‚å˜ç´”ãªå‡¦ç†ã®ã¿ã«æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€è¿½åŠ ã®å‡¦ç†æ©Ÿèƒ½ãŒå¿…è¦ãªå ´åˆã«ã¯ãã®è¤‡é›‘æ€§ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã«è¼‰ã›ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã¯ã‚‚ã£ã¨è¤‡é›‘ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã‚„ã€ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®åŸºæœ¬ã§ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã®æ¬ ç‚¹Redisã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢æ¦‚è¦: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãƒãƒªãƒ¥ãƒ¼ã¨ã—ã¦ä¿å­˜ã•ã‚ŒãŸã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«é–¢ã™ã‚‹å…¨ã¦ã®æƒ…å ±ã‚’æŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ(XMLã€ JSONã€ binaryãªã©)ã‚’ä¸­å¿ƒã«æ®ãˆãŸã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã§ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªèº«ã®å†…éƒ¨æ§‹é€ ã«åŸºã¥ã„ãŸã€APIã‚‚ã—ãã¯ã‚¯ã‚¨ãƒªè¨€èªã‚’æä¾›ã—ã¾ã™ã€‚ ãƒ¡ãƒ¢ï¼šå¤šãã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ã€å€¤ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†æ©Ÿèƒ½ã‚’å«ã‚“ã§ã„ã¾ã™ãŒã€ãã®ã“ã¨ã«ã‚ˆã£ã¦äºŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¨ã®å¢ƒç•Œç·šãŒæ›–æ˜§ã«ãªã£ã¦ã—ã¾ã£ã¦ã„ã¾ã™ã€‚ä»¥ä¸Šã®ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã€ã‚¿ã‚°ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã©ã¨ã—ã¦æ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒå£«ã¯ã¾ã¨ã‚ã¦ã‚°ãƒ«ãƒ¼ãƒ—ã«ã§ãã‚‹ã‚‚ã®ã®ã€ãã‚Œãã‚Œã§å…¨ãç•°ãªã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚MongoDB ã‚„ CouchDB ãªã©ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã‚‚ã€è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã®SQLã®ã‚ˆã†ãªè¨€èªã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚DynamoDB ã¯ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¯é«˜ã„æŸ”è»Ÿæ€§ã‚’æ‹…ä¿ã™ã‚‹ã®ã§ã€é »ç¹ã«å¤‰åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†æ™‚ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹MongoDB ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£CouchDB ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Elasticsearch ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢      Source: SQL & NoSQL, a brief historyæ¦‚è¦: ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒãƒƒãƒ— ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼<è¡Œã‚­ãƒ¼ã€ ã‚«ãƒ©ãƒ <ColKeyã€ Valueã€ Timestamp>>ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬å˜ä½ã¯ã‚«ãƒ©ãƒ ï¼ˆãƒãƒ¼ãƒ ãƒ»ãƒãƒªãƒ¥ãƒ¼ã®ãƒšã‚¢ï¼‰ã§ã™ã€‚ãã‚Œãã‚Œã®ã‚«ãƒ©ãƒ ã¯ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¨ã—ã¦ï¼ˆSQLãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚ˆã†ã«ï¼‰ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¯ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®é›†åˆã§ã™ã€‚ãã‚Œãã‚Œã®ã‚«ãƒ©ãƒ ã«ã¯è¡Œã‚­ãƒ¼ã§ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚åŒã˜è¡Œã‚­ãƒ¼ã‚’æŒã¤ã‚«ãƒ©ãƒ ã¯åŒã˜è¡Œã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã™ã€‚ãã‚Œãã‚Œã®å€¤ã¯ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãŒèµ·ããŸæ™‚ã®ãŸã‚ã«ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å«ã¿ã¾ã™ã€‚Googleã¯Bigtableã‚’åˆã®ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã¨ã—ã¦ç™ºè¡¨ã—ã¾ã—ãŸã€‚ãã‚ŒãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§Hadoopãªã©ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹HBase ã‚„Facebookã«ã‚ˆã‚‹Cassandra ãªã©ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å½±éŸ¿ã‚’ä¸ãˆã¾ã—ãŸã€‚BigTableã€HBaseã‚„Cassandraãªã©ã®ã‚¹ãƒˆã‚¢ã¯ã‚­ãƒ¼ã‚’è¾æ›¸å½¢å¼ã§ä¿æŒã™ã‚‹ã“ã¨ã§é¸æŠã—ãŸã‚­ãƒ¼ãƒ¬ãƒ³ã‚¸ã§ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’åŠ¹ç‡çš„ã«ã—ã¾ã™ã€‚ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã¯é«˜ã„å¯ç”¨æ€§ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’æ‹…ä¿ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã¨ã¦ã‚‚å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‰±ã†ã“ã¨ã«ã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢SQL & NoSQLç°¡å˜ã«æ­´å²ã‚’ã•ã‚‰ã†Bigtable ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HBase ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Cassandra ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹      Source: Graph databaseæ¦‚è¦: ã‚°ãƒ©ãƒ•ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã¯ã€ãã‚Œãã‚Œã®ãƒãƒ¼ãƒ‰ãŒãƒ¬ã‚³ãƒ¼ãƒ‰ã§ã€ãã‚Œãã‚Œã®ã‚¢ãƒ¼ã‚¯ã¯äºŒã¤ã®ãƒãƒ¼ãƒ‰ã‚’ç¹‹ãé–¢ä¿‚æ€§ã¨ã—ã¦å®šç¾©ã•ã‚Œã¾ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯å¤šæ•°ã®å¤–éƒ¨ã‚­ãƒ¼ã‚„å¤šå¯¾å¤šãªã©ã®è¤‡é›‘ãªé–¢ä¿‚æ€§ã‚’è¡¨ã™ã®ã«æœ€é©ã§ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯SNSãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹ã®è¤‡é›‘ãªé–¢ä¿‚æ€§ãƒ¢ãƒ‡ãƒ«ãªã©ã«ã¤ã„ã¦é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚æ¯”è¼ƒçš„æ–°ã—ãã€ã¾ã ä¸€èˆ¬çš„ã«ã¯ç”¨ã„ã‚‰ã‚Œã¦ã„ãªã„ã®ã§ã€é–‹ç™ºãƒ„ãƒ¼ãƒ«ã‚„ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¢ã™ã®ãŒä»–ã®æ–¹æ³•ã«æ¯”ã¹ã¦é›£ã—ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å¤šãã®ã‚°ãƒ©ãƒ•ã¯REST APIsã‚’é€šã˜ã¦ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ã‚°ãƒ©ãƒ•Graphãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹Neo4jFlockDBãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  NoSQLåŸºæœ¬ç”¨èªã®èª¬æ˜NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¤ã„ã¦èª¿æŸ»ã¨é¸æŠã‚¬ã‚¤ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£NoSQLã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³NoSQLãƒ‘ã‚¿ãƒ¼ãƒ³SQLã‹ï¼ŸNoSQLã‹ï¼Ÿ      Source: Transitioning from RDBMS to NoSQLSQL ã‚’é¸ã¶ç†ç”±:æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å³æ ¼ãªã‚¹ã‚­ãƒ¼ãƒãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿è¤‡é›‘ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’ã™ã‚‹å¿…è¦æ€§ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹éš›ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ˜ç¢ºãªã¨ãé–‹ç™ºè€…ã®æ•°ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã€ã‚³ãƒ¼ãƒ‰ç­‰ãŒã‚ˆã‚Šå……å®Ÿã—ã¦ã„ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã¯ã¨ã¦ã‚‚é€Ÿã„NoSQL ã‚’é¸ã¶ç†ç”±:æº–æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã„ã—ã€ãƒ•ãƒ¬ã‚­ã‚·ãƒ–ãƒ«ãªã‚¹ã‚­ãƒ¼ãƒãƒãƒ³ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãªãƒ‡ãƒ¼ã‚¿è¤‡é›‘ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’ã™ã‚‹å¿…è¦ãŒãªã„ãƒ‡ãƒ¼ã‚¿ã®å¤šãã®TB (ã‚‚ã—ãã¯ PB) ã‚’ä¿å­˜ã™ã‚‹é›†ä¸­çš„ã€å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿è² è·ã«è€ãˆã‚‰ã‚Œã‚‹IOPSã«ã¤ã„ã¦ã¯æ¥µã‚ã¦é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¤ºã™NoSQLã«é©ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:æ€¥æ¿€ãªã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚„ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã®åé›†ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã‚„ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚«ãƒ¼ãƒˆãªã©ã®ä¸€æ™‚çš„æƒ…å ±é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ ('ãƒ›ãƒƒãƒˆãª') ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ã€€SQLã‚‚ã—ãã¯NoSQLæœ€åˆã®1000ä¸‡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«SQLã¨NoSQLã®é•ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥      Source: Scalable system design patternsã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿æ™‚é–“ã‚’å‰Šæ¸›ã—ã€ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®è² è·ã‚’ä½æ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€å®Ÿéš›ã®å‡¦ç†ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«ã€ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒãƒ£ãƒ¼ãŒã¾ãšä»¥å‰ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒé€ä¿¡ã•ã‚ŒãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã€ç›´å‰ã®çµæœã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ãã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«æ¸¡ã£ã¦çµ±åˆã•ã‚ŒãŸèª­ã¿å–ã‚Šæ›¸ãè¾¼ã¿ã®åˆ†é…ã‚’è¦æ±‚ã—ã¾ã™ãŒã€äººæ°—ã‚¢ã‚¤ãƒ†ãƒ ã¯ãã®åˆ†é…ã‚’æ­ªã‚ã¦ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã£ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å·®ã—è¾¼ã‚€ã“ã¨ã§ã“ã®ã‚ˆã†ã«ã€å‡ä¸€ã§ãªã„è² è·ã‚„ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®æ€¥æ¿€ãªå¢—åŠ ã‚’å¸åã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯OSã‚„ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ãªã©ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã€ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ ã‚‚ã—ãã¯ç‹¬ç«‹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«è¨­ç½®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚CDNã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°CDN ã‚‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¸€ã¤ã¨ã—ã¦è€ƒãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Webã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· ã‚„ Varnish ãªã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯é™çš„ãã—ã¦å‹•çš„ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥é…ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ webã‚µãƒ¼ãƒãƒ¼ã‚‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã“ã¨ãªã—ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æ™®é€šã€ä¸€èˆ¬çš„ãªä½¿ç”¨çŠ¶æ³ã«é©ã™ã‚‹ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã®è¨­å®šã‚’åˆæœŸçŠ¶æ…‹ã§æŒã£ã¦ã„ã¾ã™ã€‚ã“ã®è¨­å®šã‚’ç‰¹å®šã®ä»•æ§˜ã«åˆã‚ã›ã¦èª¿æ•´ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã©ã®In-memoryã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„Redisã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®é–“ã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯RAMã§ä¿æŒã•ã‚Œã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ã‚£ã‚¹ã‚¯ã§ä¿å­˜ã•ã‚Œã‚‹ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚ˆã‚Šã‚‚ã ã„ã¶é€Ÿã„ã§ã™ã€‚RAMå®¹é‡ã¯ãƒ‡ã‚£ã‚¹ã‚¯ã‚ˆã‚Šã‚‚é™ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã€least recently used (LRU)ãªã©ã®cache invalidation ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒ 'ã‚³ãƒ¼ãƒ«ãƒ‰' ãªã‚¨ãƒ³ãƒˆãƒªã‚’å¼¾ãã€'ãƒ›ãƒƒãƒˆ' ãªãƒ‡ãƒ¼ã‚¿ã‚’RAMã«ä¿å­˜ã—ã¾ã™ã€‚Redisã¯ã•ã‚‰ã«ä»¥ä¸‹ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’å‚™ãˆã¦ã„ã¾ã™:ãƒ‘ãƒ¼ã‚¸ã‚¹ãƒ†ãƒ³ã‚¹è¨­å®šã‚½ãƒ¼ãƒˆæ¸ˆã¿ã‚»ãƒƒãƒˆã€ãƒªã‚¹ãƒˆãªã©ã®çµ„ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã¯æ§˜ã€…ãªãƒ¬ãƒ™ãƒ«ã®ã‚‚ã®ãŒã‚ã‚Šã¾ã™ãŒã€ã„ãšã‚Œã‚‚å¤§ããäºŒã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ã„ãšã‚Œã‹ã«åˆ†é¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª ã¨ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ ã§ã™:è¡Œãƒ¬ãƒ™ãƒ«ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«Fully-formed serializable objectsFully-rendered HTMLä¸€èˆ¬çš„ã«ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã¯ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’ä½œã‚Šå‡ºã—ã¦ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’é›£ã—ãã—ã¦ã—ã¾ã†ã®ã§é¿ã‘ã‚‹ã¹ãã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹éš›ã«ã¯å¿…ãšã‚¯ã‚¨ãƒªã‚’ã‚­ãƒ¼ã¨ã—ã¦ãƒãƒƒã‚·ãƒ¥ã—ã¦çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚ã“ã®æ‰‹æ³•ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœŸé™åˆ‡ã‚Œå•é¡Œã«æ‚©ã‚€ã“ã¨ã«ãªã‚Šã¾ã™:è¤‡é›‘ãªã‚¯ã‚¨ãƒªã«ã‚ˆã‚Šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçµæœã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ãŒå›°é›£ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ãƒ«ãªã©ã®ãƒ‡ãƒ¼ã‚¿æ–­ç‰‡ãŒå¤‰åŒ–ã—ãŸæ™‚ã«ã€ãã®å¤‰åŒ–ã—ãŸã‚»ãƒ«ã‚’å«ã‚€ã‹ã‚‚ã—ã‚Œãªã„å…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’å‰Šé™¤ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã†ã™ã‚‹ã‚ˆã†ã«ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰ãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨ã—ã¦çµ„ã¿ç«‹ã¦ã•ã›ã¾ã™ã€‚:ãã®ãƒ‡ãƒ¼ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‰Šé™¤ã™ã‚‹ã“ã¨éåŒæœŸå‡¦ç†ã‚’è¨±å®¹ã—ã¾ã™: ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸­ã§æœ€æ–°ã®ã‚‚ã®ã‚’é›†ã‚ã¦ãã¾ã™ä½•ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã‹:ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œå…¨ã«ãƒ¬ãƒ³ãƒ€ãƒ¼ã•ã‚ŒãŸã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‚¢ã‚¯ãƒ†ãƒ“ãƒ†ã‚£ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã§ãã‚‹å®¹é‡ã¯é™ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€è‡ªåˆ†ã®ã‚±ãƒ¼ã‚¹ã§ã¯ã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‰‹æ³•ãŒä¸€ç•ªã„ã„ã‹ã¯æ¤œè¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰      Source: From cache to in-memory data gridã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¸ã®èª­ã¿æ›¸ãã®å‡¦ç†ã‚’ã—ã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ã¯ç›´æ¥ã‚„ã‚Šã¨ã‚Šã‚’ã—ã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ã“ã¨ã‚’ã—ã¾ã™:ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¸­ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å‚ç…§ã—ã¾ã™ãŒã€çµæœã¨ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã«ãªã‚Šã¾ã™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—ã—ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ ã—ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã—ã¾ã™def get_user(self, user_id):    user = cache.get(\""user.{0}\"", user_id)    if user is None:        user = db.query(\""SELECT * FROM users WHERE user_id = {0}\"", user_id)        if user is not None:            key = \""user.{0}\"".format(user_id)            cache.set(key, json.dumps(user))    return userMemcached ã¯é€šå¸¸ã“ã®ã‚ˆã†ã«ä½¿ã‚ã‚Œã‚‹ã€‚ãã®å¾Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¯é€Ÿã„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã¯ãƒ¬ãƒ¼ã‚¸ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚ã‚‹ã¨ã‚‚è¨€ã‚ã‚Œã¾ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã¿ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæº¢ã‚Œã‚‹ã®ã‚’é˜²æ­¢ã—ã¾ã™ã€‚æ¬ ç‚¹: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰å„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã¯ä¸‰ã¤ã®ãƒˆãƒªãƒƒãƒ—ã‚’å‘¼ã³å‡ºã™ã“ã¨ã«ãªã‚Šã€ä½“æ„Ÿã§ãã‚‹ã»ã©ã®é…å»¶ãŒèµ·ãã¦ã—ã¾ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ãŒæ›´æ–°ã•ã‚Œã‚‹ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã¯å¤ã„ã‚‚ã®ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚time-to-live (TTL)ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã®æ›´æ–°ã‚’å¼·åˆ¶çš„ã«è¡Œã†ã€ã‚‚ã—ãã¯ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã¯ç·©å’Œã§ãã¾ã™ã€‚ãƒãƒ¼ãƒ‰ãŒè½ã¡ã‚‹ã¨ã€æ–°è¦ã®ç©ºã®ãƒãƒ¼ãƒ‰ã§ä»£æ›¿ã•ã‚Œã‚‹ã“ã¨ã§ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼      Source: Scalability, availability, stability, patternsã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¨ã—ã¦ä½¿ã„ã€ãã“ã«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿æ›¸ãã‚’è¡Œã„ã¾ã™ã€‚ä¸€æ–¹ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®èª­ã¿æ›¸ãã‚’æ‹…å½“ã—ã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚‹ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã™ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯åŒæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã«æ›¸ãè¾¼ã¿ã‚’è¡Œã„ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã—ã¾ã™ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰:set_user(12345, {\""foo\"":\""bar\""})ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚³ãƒ¼ãƒ‰:def set_user(user_id, values):    user = db.query(\""UPDATE Users WHERE id = {0}\"", user_id, values)    cache.set(user_id, user)ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã¯æ›¸ãè¾¼ã¿å‡¦ç†ã®ã›ã„ã§å…¨ä½“ã¨ã—ã¦ã¯é…ã„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ãŒã€æ›¸ãè¾¼ã¾ã‚ŒãŸã°ã‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹èª­ã¿è¾¼ã¿ã¯é€Ÿã„ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã¯ä¸€èˆ¬çš„ã«ãƒ‡ãƒ¼ã‚¿æ›´æ–°æ™‚ã®æ–¹ãŒèª­ã¿è¾¼ã¿æ™‚ã‚ˆã‚Šã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã«è¨±å®¹çš„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã¯æœ€æ–°ç‰ˆã§ä¿ãŸã‚Œã¾ã™ã€‚æ¬ ç‚¹: ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ãƒãƒ¼ãƒ‰ãŒè½ã¡ãŸã“ã¨ã€ã‚‚ã—ãã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦æ–°ã—ã„ãƒãƒ¼ãƒ‰ãŒä½œæˆã•ã‚ŒãŸæ™‚ã«ã€æ–°ã—ã„ãƒãƒ¼ãƒ‰ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒæ›´æ–°ã•ã‚Œã‚‹ã¾ã§ã¯ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã›ã‚“ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã¨ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚’ä½µç”¨ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã‚’ç·©å’Œã§ãã¾ã™ã€‚æ›¸ãè¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã¯ä¸€åº¦ã‚‚èª­ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯TTLã«ã‚ˆã£ã¦åœ§ç¸®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ (ãƒ©ã‚¤ãƒˆãƒãƒƒã‚¯)      Source: Scalability, availability, stability, patternsãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ã§ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ã“ã¨ã‚’ã—ã¾ã™:ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã™ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¸ã®æ›¸ãè¾¼ã¿ã‚’éåŒæœŸçš„ã«è¡Œã†ã“ã¨ã§ã€æ›¸ãè¾¼ã¿ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚æ¬ ç‚¹: ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢å†…ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ãƒ’ãƒƒãƒˆã™ã‚‹å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè½ã¡ã‚‹ã¨ãƒ‡ãƒ¼ã‚¿æ¬ æãŒèµ·ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã‚„ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚ˆã‚Šã‚‚å®Ÿè£…ãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰      Source: From cache to in-memory data gridæœŸé™åˆ‡ã‚Œã‚ˆã‚Šã‚‚å‰ã«ã€ç›´è¿‘ã§ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸå…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’è‡ªå‹•çš„ã«æ›´æ–°ã™ã‚‹ã‚ˆã†ã«è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚‚ã—ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå°†æ¥å¿…è¦ã«ãªã‚‹ã®ã‹ã‚’æ­£ç¢ºã«äºˆæ¸¬ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ãªã‚‰ã°ã€ãƒªãƒ¼ãƒ‰ã‚¹ãƒ«ãƒ¼ã‚ˆã‚Šã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬ ç‚¹: ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå¿…è¦ã«ãªã‚‹ã‹ã®äºˆæ¸¬ãŒæ­£ç¢ºã§ãªã„å ´åˆã«ã¯ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰ãŒãªã„æ–¹ãŒãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¯è‰¯ã„ã¨ã„ã†çµæœã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚æ¬ ç‚¹: ã‚­ãƒ£ãƒƒã‚·ãƒ¥cache invalidationãªã©ã‚’ç”¨ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®çœŸã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®é–“ã®ä¸€è²«æ€§ã‚’ä¿ã¤å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Redisã‚„memcachedã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹æˆã‚’å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Cache invalidationã‚‚é›£ã—ã„ã§ã™ãŒãã‚Œã«åŠ ãˆã¦ã€ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã‹ã¨ã„ã†è¤‡é›‘ãªå•é¡Œã«ã‚‚æ‚©ã¾ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸From cache to in-memory data gridã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€å¯ç”¨æ€§ã€å®‰å®šæ€§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£AWS ElastiCacheã®ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼WikipediaéåŒæœŸå‡¦ç†      Source: Intro to architecting systems for scaleéåŒæœŸã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ã‚‚ã—ã€é€£ç¶šçš„ã«è¡Œã‚ã‚Œã‚‹ã¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚é–“ã‚’åœ§è¿«ã—ã¦ã—ã¾ã†ã‚ˆã†ãªé‡ã„å‡¦ç†ã‚’åˆ¥ã§å‡¦ç†ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã¾ãŸã€å®šæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†åˆã•ã›ã‚‹ãªã©ã®æ™‚é–“ãŒã‹ã‹ã‚‹ã‚ˆã†ãªå‡¦ç†ã‚’å‰ã‚‚ã£ã¦å‡¦ç†ã—ã¦ãŠãã“ã¨ã«ã‚‚å½¹ç«‹ã¡ã¾ã™ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã€ä¿å­˜ã—ã€é…ä¿¡ã—ã¾ã™ã€‚ã‚‚ã—ã€å‡¦ç†ãŒã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã§è¡Œã†ã«ã¯é…ã™ãã‚‹å ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚’ç”¨ã„ã‚‹ã¨ã„ã„ã§ã—ã‚‡ã†:ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¸ãƒ§ãƒ–ã‚’ã‚­ãƒ¥ãƒ¼ã«é…ä¿¡ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ä¼ãˆã¾ã™ã€‚ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å—ã‘å–ã£ã¦ã€å‡¦ç†ã‚’è¡Œã„ã€çµ‚äº†ã—ãŸã‚‰ãã®ã‚·ã‚°ãƒŠãƒ«ã‚’è¿”ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‡¦ç†ãŒæ­¢ã¾ã‚‹ã“ã¨ã¯ãªãã€ã‚¸ãƒ§ãƒ–ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å‡¦ç†ã•ã‚Œã¾ã™ã€‚ã“ã®é–“ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã€ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ãŸã‹ã®ã‚ˆã†ã«è¦‹ã›ã‚‹ãŸã‚ã«å°è¦æ¨¡ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æŠ•ç¨¿ã™ã‚‹ã¨ãã«ã€ãƒ„ã‚¤ãƒ¼ãƒˆã¯ã™ãã«ã‚ãªãŸã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«åæ˜ ã•ã‚ŒãŸã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€ãã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒå®Ÿéš›ã«å…¨ã¦ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã«é…ä¿¡ã•ã‚Œã‚‹ã¾ã§ã«ã¯ã‚‚ã†å°‘ã—æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã‚‹ã§ã—ã‚‡ã†ã€‚Redis ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä»²ä»‹ã¨ã—ã¦ã¯ã„ã„ã§ã™ãŒã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚RabbitMQ ã¯ã‚ˆãä½¿ã‚ã‚Œã¦ã„ã¾ã™ãŒã€'AMQP'ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¯¾å¿œã—ã¦ã€è‡ªå‰ã®ãƒãƒ¼ãƒ‰ã‚’ç«‹ã¦ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Amazon SQS ã¨ã„ã†é¸æŠè‚¢ã‚‚ã‚ã‚Šã¾ã™ãŒã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒé«˜ãã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé‡è¤‡ã—ã¦é…ä¿¡ã•ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã¯ã‚¿ã‚¹ã‚¯ã¨ãã®é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€å‡¦ç†ã—ãŸä¸Šã§ãã®çµæœã‚’è¿”ã—ã¾ã™ã€‚ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã‚’ã§ãã‚‹ã»ã‹ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã¨ã¦ã‚‚é‡ã„ã‚¸ãƒ§ãƒ–ã‚’ã“ãªã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚Celery ã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨pythonã®ã‚µãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚‚ã—ã€ã‚­ãƒ¥ãƒ¼ãŒæ‹¡å¤§ã—ã™ãã‚‹ã¨ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã‚ˆã‚Šã‚‚ã‚­ãƒ¥ãƒ¼ã®æ–¹ãŒå¤§ãããªã‚Šã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ãŒèµ·ã“ã‚Šã€ãƒ‡ã‚£ã‚¹ã‚¯èª­ã¿å‡ºã—ã«ã¤ãªãŒã‚Šã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã«ã¤ãªãŒã‚Šã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã¯ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§å›é¿ã™ã‚‹ã“ã¨ãŒã§ãã€é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¢ºä¿ã—ã‚­ãƒ¥ãƒ¼ã«ã™ã§ã«ã‚ã‚‹ã‚¸ãƒ§ãƒ–ã«ã¤ã„ã¦ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’çŸ­ç¸®ã§ãã¾ã™ã€‚ã‚­ãƒ¥ãƒ¼ãŒã„ã£ã±ã„ã«ãªã‚‹ã¨ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã‚µãƒ¼ãƒãƒ¼ãƒ“ã‚¸ãƒ¼ã‚‚ã—ãã¯HTTP 503ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦å—ã‘å–ã‚Šã¾ãŸå¾Œã§æ™‚é–“ã‚’ãŠã„ã¦ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚ˆã†ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯exponential backoffãªã©ã«ã‚ˆã£ã¦å¾Œã»ã©å†åº¦æ™‚é–“ã‚’ç½®ã„ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬ ç‚¹: éåŒæœŸå‡¦ç†ã‚­ãƒ¥ãƒ¼ã‚’ç”¨ã„ã‚‹ã“ã¨ã§é…å»¶ãŒèµ·ã“ã‚Šã€è¤‡é›‘ã•ã‚‚å¢—ã™ãŸã‚ã€ã‚ã¾ã‚Šé‡ããªã„è¨ˆç®—å‡¦ç†ã‚„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ãŠã„ã¦ã¯åŒæœŸå‡¦ç†ã®æ–¹ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸It's all a numbers gameã‚ªãƒ¼ãƒãƒ¼ãƒ­ãƒ¼ãƒ‰ã—ãŸæ™‚ã«ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚’é©ç”¨ã™ã‚‹Little's lawãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¨ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã®é•ã„ã¨ã¯ï¼Ÿé€šä¿¡      Source: OSI 7 layer modelHypertext transfer protocol (HTTP)HTTP ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦è»¢é€ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã§ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«é–¢ã‚ã‚‹ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚µãƒ¼ãƒãƒ¼ã«æŠ•ã’ã€ã‚µãƒ¼ãƒãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã«é–¢ä¿‚ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨å®Œäº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚HTTPã¯è‡ªå·±å®Œçµã™ã‚‹ã®ã§ã€é–“ã«ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ³ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã€åœ§ç¸®ãªã©ã®ã©ã‚“ãªä¸­é–“ãƒ«ãƒ¼ã‚¿ãƒ¼ãŒå…¥ã£ã¦ã‚‚å‹•ãã‚ˆã†ã«ã§ãã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯HTTPå‹•è©(ãƒ¡ã‚½ãƒƒãƒ‰)ã¨ãƒªã‚½ãƒ¼ã‚¹(ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ)ã§æˆã‚Šç«‹ã£ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ãŒã‚ˆãã‚ã‚‹HTTPå‹•è©ã§ã™ã€‚:å‹•è©è©³ç´°å†ªç­‰æ€§*ã‚»ãƒ¼ãƒ•ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§ãã‚‹ã‹GETãƒªã‚½ãƒ¼ã‚¹ã‚’èª­ã¿å–ã‚‹YesYesYesPOSTãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹ã‚‚ã—ãã¯ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ãƒˆãƒªã‚¬ãƒ¼NoNoYes ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚€å ´åˆPUTãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã‚‚ã—ãã¯å…¥ã‚Œæ›¿ãˆã‚‹YesNoNoPATCHãƒªã‚½ãƒ¼ã‚¹ã‚’éƒ¨åˆ†çš„ã«æ›´æ–°ã™ã‚‹NoNoYes ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚€å ´åˆDELETEãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ã™ã‚‹YesNoNoä½•åº¦å‘¼ã‚“ã§ã‚‚åŒã˜çµæœãŒè¿”ã£ã¦ãã‚‹ã“ã¨HTTPã¯TCP ã‚„ UDP ãªã©ã®ä½ç´šãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: HTTPHTTPã£ã¦ãªã«?HTTP ã¨ TCPã®é•ã„PUT ã¨ PATCHã®é•ã„ä¼é€åˆ¶å¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ« (TCP)      Source: How to make a multiplayer gameTCPã¯IP networkã®ä¸Šã§æˆã‚Šç«‹ã¤æ¥ç¶šãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚æ¥ç¶šã¯handshakeã«ã‚ˆã£ã¦é–‹å§‹ã€è§£é™¤ã•ã‚Œã¾ã™ã€‚å…¨ã¦ã®é€ä¿¡ã•ã‚ŒãŸãƒ‘ã‚±ãƒƒãƒˆã¯æ¬ æãªã—ã§é€ä¿¡å…ˆã«é€ä¿¡ã•ã‚ŒãŸé †ç•ªã§åˆ°é”ã™ã‚‹ã‚ˆã†ã«ä»¥ä¸‹ã®æ–¹æ³•ã§ä¿è¨¼ã•ã‚Œã¦ã„ã¾ã™:ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã¨checksum fieldsãŒå…¨ã¦ã®ãƒ‘ã‚±ãƒƒãƒˆã«ç”¨æ„ã•ã‚Œã¦ã„ã‚‹Acknowledgementãƒ‘ã‚±ãƒƒãƒˆã¨è‡ªå‹•å†é€ä¿¡ã‚‚ã—é€ä¿¡è€…ãŒæ­£ã—ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ã‘å–ã‚‰ãªã‹ã£ãŸã¨ãã€ãƒ‘ã‚±ãƒƒãƒˆã‚’å†é€ä¿¡ã—ã¾ã™ã€‚è¤‡æ•°ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒã‚ã£ãŸã¨ãã€æ¥ç¶šã¯è§£é™¤ã•ã‚Œã¾ã™ã€‚TCP ã¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ ã¨ è¼»è¼³åˆ¶å¾¡ã‚‚å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã«ã‚ˆã£ã¦é€Ÿåº¦ã¯ä½ä¸‹ã—ã€ä¸€èˆ¬çš„ã«UDPã‚ˆã‚Šã‚‚éåŠ¹ç‡ãªè»¢é€æ‰‹æ®µã«ãªã£ã¦ã„ã¾ã™ã€‚ãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã¯ã‹ãªã‚Šå¤§ããªæ•°ã®TCPæ¥ç¶šã‚’é–‹ã„ã¦ãŠãã“ã¨ãŒã‚ã‚Šã€ãã®ã“ã¨ã§ãƒ¡ãƒ¢ãƒªãƒ¼ä½¿ç”¨ãŒåœ§è¿«ã•ã‚Œã¾ã™ã€‚ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã¨ä¾‹ãˆã°memcached ã‚µãƒ¼ãƒãƒ¼ã®é–“ã§å¤šæ•°ã®ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿ã£ã¦ãŠãã“ã¨ã¯é«˜ãã¤ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å¯èƒ½ãªã¨ã“ã‚ã§ã¯UDPã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã ã‘ã§ãªãã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãªã©ã‚‚å½¹ç«‹ã¤ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚TCPã¯é«˜ã„ä¾å­˜æ€§ã‚’è¦ã—ã€æ™‚é–“åˆ¶ç´„ãŒå³ã—ããªã„ã‚‚ã®ã«é©ã—ã¦ã„ã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã€SMTPã€FTPã‚„SSHãªã©ã®ä¾‹ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®æ™‚ã«UDPã‚ˆã‚Šã‚‚TCPã‚’ä½¿ã†ã¨ã„ã„ã§ã—ã‚‡ã†:å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒæ¬ æã™ã‚‹ã“ã¨ãªã—ã«å±Šã„ã¦ã»ã—ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®æœ€é©ãªè‡ªå‹•æ¨æ¸¬ã‚’ã—ã¦ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« (UDP)      Source: How to make a multiplayer gameUDPã¯ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ã‚¹ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ï¼ˆãƒ‘ã‚±ãƒƒãƒˆã®ã‚ˆã†ãªã‚‚ã®ï¼‰ã¯ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ¬ãƒ™ãƒ«ã§ã®ä¿è¨¼ã—ã‹ã•ã‚Œã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ã¯é †ä¸åŒã§å—ã‘å–ã‚Šå…ˆã«åˆ°ç€ã—ãŸã‚Šãã‚‚ãã‚‚ç€ã‹ãªã‹ã£ãŸã‚Šã—ã¾ã™ã€‚UDPã¯è¼»è¼³åˆ¶å¾¡ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã›ã‚“ã€‚TCPã«ãŠã„ã¦ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã“ã‚Œã‚‰ã®ä¿è¨¼ãŒãªã„ãŸã‚ã€UDPã¯ä¸€èˆ¬çš„ã«ã€TCPã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã™ã€‚UDPã¯ã‚µãƒ–ãƒãƒƒãƒˆä¸Šã®ã™ã¹ã¦ã®æ©Ÿå™¨ã«ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ã‚’é€ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã¯DHCP ã«ãŠã„ã¦å½¹ã«ç«‹ã¡ã¾ã™ã€‚ã¨ã„ã†ã®ã‚‚ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã¾ã IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—ã—ã¦ã„ãªã„ã®ã§ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å¿…è¦ã¨ã™ã‚‹TCPã«ã‚ˆã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒã§ããªã„ã‹ã‚‰ã§ã™ã€‚UDPã¯ä¿¡é ¼æ€§ã®é¢ã§ã¯åŠ£ã‚Šã¾ã™ãŒã€VoIPã€ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚„åŒæ™‚é€šä¿¡ãƒãƒ«ãƒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚²ãƒ¼ãƒ ãªã©ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒé‡è¦–ã•ã‚Œã‚‹æ™‚ã«ã¯ã¨ã¦ã‚‚åŠ¹æœçš„ã§ã™ã€‚TCPã‚ˆã‚Šã‚‚UDPã‚’ä½¿ã†ã®ã¯:ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’æœ€ä½é™ã«æŠ‘ãˆãŸã„æ™‚ãƒ‡ãƒ¼ã‚¿æ¬ æã‚ˆã‚Šã‚‚ã€ãƒ‡ãƒ¼ã‚¿é…å»¶ã‚’é‡è¦–ã™ã‚‹ã¨ãã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚’è‡ªå‰ã§å®Ÿè£…ã—ãŸã„ã¨ããã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: TCP ã¨ UDPã‚²ãƒ¼ãƒ ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ãŸã‚ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯TCP ã¨ UDP ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ä¸»ãªé•ã„TCP ã¨ UDPã®é•ã„Transmission control protocolUser datagram protocolFacebookã®ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°é éš”æ‰‹ç¶šå‘¼å‡º (RPC)      Source: Crack the system design interviewRPCã§ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒªãƒ¢ãƒ¼ãƒˆã‚µãƒ¼ãƒãƒ¼ãªã©ã®ç•°ãªã‚‹ã‚¢ãƒ‰ãƒ¬ã‚¹ç©ºé–“ã§ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ãŒå‡¦ç†ã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ã‚³ãƒ¼ãƒ«ã®ã‚ˆã†ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã«ã©ã®ã‚ˆã†ã«é€šä¿¡ã™ã‚‹ã‹ã¨ã„ã†è©³ç´°ã‚’çœã„ãŸçŠ¶æ…‹ã§ã‚³ãƒ¼ãƒ‰ãŒæ›¸ã‹ã‚Œã¾ã™ã€‚ãƒªãƒ¢ãƒ¼ãƒˆã®ã‚³ãƒ¼ãƒ«ã¯æ™®é€šã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ã‚³ãƒ¼ãƒ«ã‚ˆã‚Šã‚‚é…ãã€ä¿¡é ¼æ€§ã«æ¬ ã‘ã‚‹ãŸã‚ã€RPCã‚³ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‚³ãƒ¼ãƒ«ã¨åŒºåˆ¥ã•ã›ã¦ãŠãã“ã¨ãŒå¥½ã¾ã—ã„ã§ã—ã‚‡ã†ã€‚äººæ°—ã®RPCãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ä»¥ä¸‹ã§ã™ã€‚Protobufã€ Thriftã€AvroRPC ã¯ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒˆã‚³ãƒ«:ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ  - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚³ãƒ¼ãƒ«ã®ã‚ˆã†ã«ã‚¹ã‚¿ãƒƒã‚¯ã¸ã¨ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ãã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ - ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£IDã¨ã‚¢ãƒ¼ã‚®ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ‘ãƒƒã‚¯ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã—ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé€šä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - OSãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã¸ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚Šã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼é€šä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - OSãŒå—ã‘å–ã£ãŸãƒ‘ã‚±ãƒƒãƒˆã‚’ã‚µãƒ¼ãƒãƒ¼ã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã«å—ã‘æ¸¡ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ -  çµæœã‚’å±•é–‹ã—ã€ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼IDã«ãƒãƒƒãƒã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’è¿”ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ä¸Šè¨˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é€†é †ã§ç¹°ã‚Šè¿”ã—ã¾ã™ã€‚Sample RPC calls:GET /someoperation?data=anIdPOST /anotheroperation{  \""data\"":\""anId\"";  \""anotherdata\"": \""another value\""}RPCã¯æŒ¯ã‚‹èˆã„ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚RPCã¯å†…éƒ¨é€šä¿¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç†ç”±ã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ã¨ã„ã†ã®ã‚‚ã€ä½¿ç”¨ã™ã‚‹çŠ¶æ³ã«åˆã‚ã›ã¦ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚³ãƒ¼ãƒ«ã‚’è‡ªä½œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã‚‰ã§ã™ã€‚ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼ (aka SDK) ã‚’å‘¼ã¶ã®ã¯ä»¥ä¸‹ã®æ™‚:ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’çŸ¥ã£ã¦ã„ã‚‹æ™‚ãƒ­ã‚¸ãƒƒã‚¯ãŒã©ã®ã‚ˆã†ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ã®ã‹ã‚’ç®¡ç†ã—ãŸã„ã¨ããƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼å¤–ã§ã‚¨ãƒ©ãƒ¼ãŒã©ã®ã‚ˆã†ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã•ã‚Œã‚‹ã‹ã‚’ç®¡ç†ã—ãŸã„æ™‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ãŒæœ€å„ªå…ˆã®æ™‚REST ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¾“ã†HTTP APIã¯ãƒ‘ãƒ–ãƒªãƒƒã‚¯APIã«ãŠã„ã¦ã‚ˆãç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚æ¬ ç‚¹: RPCRPCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã¯ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…ã«ã‚ˆã‚Šå³å¯†ã«å·¦å³ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ–°ã—ã„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ä½¿ç”¨ä¾‹ãŒã‚ã‚‹ãŸã³ã«æ–°ã—ãAPIãŒå®šç¾©ã•ã‚Œãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚RPCã‚’ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ã®ã¯é›£ã—ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ—¢å­˜ã®ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚’ãã®ã¾ã¾ä½¿ã£ã¦ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€Squidãªã©ã®ã‚µãƒ¼ãƒãƒ¼ã«RPCã‚³ãƒ¼ãƒ«ãŒæ­£ã—ãã‚­ãƒ£ãƒƒã‚·ãƒ¥ ã•ã‚Œã‚‹ã‚ˆã†ã«è¿½åŠ ã§éª¨ã‚’æŠ˜ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚Representational state transfer (REST)RESTã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒã‚µãƒ¼ãƒãƒ¼ã«ã‚ˆã£ã¦ãƒãƒãƒ¼ã‚¸ã•ã‚Œã‚‹ãƒªã‚½ãƒ¼ã‚¹ã«å¯¾ã—ã¦å‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ»ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’æ”¯æŒã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚­ãƒãƒ£ã‚¹ã‚¿ã‚¤ãƒ«ã§ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯æ“ä½œã§ãã‚‹ã‚‚ã—ãã¯æ–°ã—ã„ãƒªã‚½ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ãªãƒªã‚½ãƒ¼ã‚¹ã‚„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ¬ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚ã™ã¹ã¦ã®é€šä¿¡ã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯èƒ½ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚RESTful ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«ã¯æ¬¡ã®å››ã¤ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™:ç‰¹å¾´çš„ãªãƒªã‚½ãƒ¼ã‚¹ (URI in HTTP) - ã©ã®ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚ã£ã¦ã‚‚åŒã˜URIã‚’ä½¿ã†ã€‚HTTPå‹•è©ã«ã‚ˆã£ã¦å¤‰ã‚ã‚‹ (Verbs in HTTP) - å‹•è©ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒœãƒ‡ã‚£ã‚’ä½¿ã†è‡ªå·±èª¬æ˜çš„ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (status response in HTTP) - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã„ã€æ–°ã—ãä½œã£ãŸã‚Šã—ãªã„ã“ã¨ã€‚HATEOAS (HTML interface for HTTP) - è‡ªåˆ†ã®webã‚µãƒ¼ãƒ“ã‚¹ãŒãƒ–ãƒ©ã‚¦ã‚¶ã§å®Œå…¨ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã“ã¨ã€‚ã‚µãƒ³ãƒ—ãƒ« REST ã‚³ãƒ¼ãƒ«:GET /someresources/anIdPUT /someresources/anId{\""anotherdata\"": \""another value\""}RESTã¯ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼ã®ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ã‚’æœ€å°é™ã«ã™ã‚‹ã‚‚ã®ã§ã€ãƒ‘ãƒ–ãƒªãƒƒã‚¯APIãªã©ã«ã‚ˆãç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚RESTã¯URIã€ representation through headersã€ãã—ã¦ã€GETã€POSTã€PUTã€ DELETEã€PATCHãªã©ã®HTTPå‹•è©ç­‰ã®ã‚ˆã‚Šã‚¸ã‚§ãƒãƒªãƒƒã‚¯ã§çµ±ä¸€ã•ã‚ŒãŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¾ã™ã€‚ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹ã®ã§RESTã¯æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã«æœ€é©ã§ã™ã€‚æ¬ ç‚¹: RESTRESTã¯ãƒ‡ãƒ¼ã‚¿å…¬é–‹ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã®ã§ã€ãƒªã‚½ãƒ¼ã‚¹ãŒè‡ªç„¶ã«æ•´ç†ã•ã‚Œã¦ã„ãªã‹ã£ãŸã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ã§è¡¨ã›ã‚‰ã‚Œãªã„æ™‚ã«ã¯ã‚ˆã„é¸æŠè‚¢ã¨ã¯è¨€ãˆãªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€ã¨ã‚ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã«ãƒãƒƒãƒã™ã‚‹ã™ã¹ã¦ã®æ›´æ–°æƒ…å ±ã‚’è¿”ã™ã¨è¨€ã£ãŸå‡¦ç†ã¯ç°¡å˜ã«ã¯ãƒ‘ã‚¹ã§è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚RESTã§ã¯ã€URIãƒ‘ã‚¹ã€ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãã—ã¦å ´åˆã«ã‚ˆã£ã¦ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ãªã©ã«ã‚ˆã£ã¦å®Ÿè£…ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã€‚RESTã¯å°‘æ•°ã®å‹•è©ã«ä¾å­˜ã—ã¦ã„ã¾ã™(GETã€POSTã€PUTã€DELETEã€ãã—ã¦ PATCH) ãŒæ™‚ã«ã¯ä½¿ã„ãŸã„äº‹ä¾‹ã«åˆã‚ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€æœŸé™ã®åˆ‡ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ç§»ã—ãŸã„å ´åˆãªã©ã¯ã“ã‚Œã‚‰ã®å‹•è©ã®ä¸­ã«ã¯ç¶ºéº—ã«ã¯ãƒ•ã‚£ãƒƒãƒˆã—ã¾ã›ã‚“ã€‚ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ã®ä¸­ã«ã‚ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚’ã¨ã£ã¦ãã‚‹ã®ã¯ã‚·ãƒ³ã‚°ãƒ«ãƒ“ãƒ¥ãƒ¼ã‚’æç”»ã™ã‚‹ã®ã«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã§æ•°å›ã‚„ã‚Šã¨ã‚Šã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ä¾‹ã¨ã—ã¦ã€ãƒ–ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ãã‚Œã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤ºã™ã‚‹å ´åˆãªã©ã§ã™ã€‚æ§˜ã€…ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒã§å‹•ä½œã™ã‚‹å¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã‚‹ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã¯ã“ã®ã‚ˆã†ãªè¤‡æ•°ã®ã‚„ã‚Šå–ã‚Šã¯å¥½ã¾ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚æ™‚ãŒçµŒã¤ã«ã¤ã‚Œã¦ã€APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚ˆã‚Šå¤šãã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸ãˆã‚‰ã‚Œã¦ã€å¤ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã™ã§ã«ã„ã‚‰ãªã„ã‚‚ã®ã‚‚å«ã‚ã¦ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å—ã‘å–ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ã“ã¨ã§ã€ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãŒå¤§ãããªã‚Šã™ãã¦ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚‚æ‹¡å¤§ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚RPCã¨RESTæ¯”è¼ƒOperationRPCRESTã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—POST /signupPOST /personsãƒªã‚¶ã‚¤ãƒ³POST /resign{\""personid\"": \""1234\""}DELETE /persons/1234Personèª­ã¿è¾¼ã¿GET /readPerson?personid=1234GET /persons/1234Personã®ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿GET /readUsersItemsList?personid=1234GET /persons/1234/itemsPersonã®ã‚¢ã‚¤ãƒ†ãƒ ã¸ã®ã‚¢ã‚¤ãƒ†ãƒ è¿½åŠ POST /addItemToUsersItemsList{\""personid\"": \""1234\"";\""itemid\"": \""456\""}POST /persons/1234/items{\""itemid\"": \""456\""}ã‚¢ã‚¤ãƒ†ãƒ æ›´æ–°POST /modifyItem{\""itemid\"": \""456\"";\""key\"": \""value\""}PUT /items/456{\""key\"": \""value\""}ã‚¢ã‚¤ãƒ†ãƒ å‰Šé™¤POST /removeItem{\""itemid\"": \""456\""}DELETE /items/456  Source: Do you really know why you prefer REST over RPCãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: REST ã¨ RPCDo you really know why you prefer REST over RPCWhen are RPC-ish approaches more appropriate than REST?REST vs JSON-RPCDebunking the myths of RPC and RESTWhat are the drawbacks of using RESTCrack the system design interviewThriftWhy REST for internal use and not RPCã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯æ›´æ–°ãŒå¿…è¦ã§ã™ã€‚contributingã—ã¦ãã ã•ã„ï¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¯å¹…åºƒã„ãƒˆãƒ”ãƒƒã‚¯ã§ã™ã€‚ååˆ†ãªçµŒé¨“ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†é‡ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãŒãªãã¦ã‚‚ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®çŸ¥è­˜ã‚’è¦ã™ã‚‹è·ã«å¿œå‹Ÿã™ã‚‹ã®ã§ãªã„é™ã‚Šã€åŸºæœ¬ä»¥ä¸Šã®ã“ã¨ã‚’çŸ¥ã‚‹å¿…è¦ã¯ãªã„ã§ã—ã‚‡ã†ã€‚æƒ…å ±ä¼é”ã€ä¿å­˜ã«ãŠã‘ã‚‹æš—å·åŒ–XSS ã‚„ SQL injectionã‚’é˜²ããŸã‚ã«ã€å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚‚ã—ãã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«éœ²å‡ºã•ã‚Œã‚‹å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã™ã‚‹SQL injectionã‚’é˜²ããŸã‚ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’ç”¨ã„ã‚‹ã€‚least privilegeã®åŸç†ã‚’ç”¨ã„ã‚‹ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:é–‹ç™ºè€…ã®ãŸã‚ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¬ã‚¤ãƒ‰OWASP top tenè£œéºæš—ç®—ã§ã€æ¨è¨ˆå€¤ã‚’æ±‚ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚‚æ™‚ã«ã¯ã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰100æšã‚¤ãƒ¡ãƒ¼ã‚¸åˆ†ã®ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ä½œã‚‹æ™‚é–“ã‚’æ±‚ã‚ãŸã‚Šã€ãã®æ™‚ã«ã©ã‚Œã ã‘ãƒ‡ã‚£ã‚¹ã‚¯ãƒ¡ãƒ¢ãƒªãƒ¼ãŒæ¶ˆè²»ã•ã‚Œã‚‹ã‹ãªã©ã®å€¤ã§ã™ã€‚2ã®ä¹—æ•°è¡¨ ã¨ å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ ã¯è‰¯ã„å‚è€ƒã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚2ã®ä¹—æ•°è¡¨ä¹—æ•°           å³å¯†ãªå€¤         ç´„        Bytes---------------------------------------------------------------7                             1288                             25610                           1024   1 thousand           1 KB16                         65,536                       64 KB20                      1,048,576   1 million            1 MB30                  1,073,741,824   1 billion            1 GB32                  4,294,967,296                        4 GB40              1,099,511,627,776   1 trillion           1 TBãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤Latency Comparison Numbers--------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy            10,000   ns       10 usSend 1 KB bytes over 1 Gbps network     10,000   ns       10 usRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSDRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSDSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 msNotes-----1 ns = 10^-9 seconds1 us = 10^-6 seconds = 1,000 ns1 ms = 10^-3 seconds = 1,000 us = 1,000,000 nsä¸Šè¨˜è¡¨ã«åŸºã¥ã„ãŸå½¹ã«ç«‹ã¤æ•°å€¤:ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 30 MB/s1 Gbps Ethernetã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ã€€100 MB/sSSDã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 1 GB/smain memoryã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 4 GB/s1ç§’ã§åœ°çƒ6-7å‘¨ã§ãã‚‹1ç§’ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã¨2000å‘¨ã‚„ã‚Šã¨ã‚Šã§ãã‚‹ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã®è¦–è¦šçš„è¡¨ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ - 1å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ - 2Designs, lessons, and advice from building large distributed systemsSoftware Engineering Advice from Building Large-Scale Distributed Systemsä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ä¾‹é¡Œé »å‡ºã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨ãã®è§£ç­”ã¸ã®ãƒªãƒ³ã‚¯è³ªå•è§£ç­”Dropboxã®ã‚ˆã†ãªãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹youtube.comGoogleã®ã‚ˆã†ãªæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­è¨ˆqueue.acm.orgstackexchange.comardendertat.comstanford.eduGoogleã®ã‚ˆã†ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªwebã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®è¨­è¨ˆquora.comGoogle docsã®è¨­è¨ˆcode.google.comneil.fraser.nameRedisã®ã‚ˆã†ãªã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã®è¨­è¨ˆslideshare.netMemcachedã®ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆslideshare.netAmazonã®ã‚ˆã†ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆhulu.comijcai13.orgBitlyã®ã‚ˆã†ãªURLçŸ­ç¸®ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆn00tc0d3r.blogspot.comWhatsAppã®ã‚ˆã†ãªãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã®è¨­è¨ˆhighscalability.comInstagramã®ã‚ˆã†ãªå†™çœŸå…±æœ‰ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆhighscalability.comhighscalability.comFacebookãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚£ãƒ¼ãƒ‰ã®è¨­è¨ˆquora.comquora.comslideshare.netFacebookã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®è¨­è¨ˆfacebook.comhighscalability.comFacebookãƒãƒ£ãƒƒãƒˆã®è¨­è¨ˆerlang-factory.comfacebook.comFacebookã®ã‚ˆã†ãªgraphæ¤œç´¢ã®è¨­è¨ˆfacebook.comfacebook.comfacebook.comCloudFlareã®ã‚ˆã†ãªCDNã®è¨­è¨ˆcmu.eduTwitterã®ãƒˆãƒ¬ãƒ³ãƒ‰æ©Ÿèƒ½ã®è¨­è¨ˆmichael-noll.comsnikolov .wordpress.comãƒ©ãƒ³ãƒ€ãƒ IDç™ºè¡Œã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆblog.twitter.comgithub.comä¸€å®šã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«æ™‚é–“ã§ã®ä¸Šä½kä»¶ã‚’è¿”ã™ucsb.eduwpi.eduè¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’é…ä¿¡ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆhighscalability.comã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®è¤‡æ•°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã®è¨­è¨ˆindieflashblog.combuildnewgames.comã‚¬ãƒ¼ãƒ™ãƒƒã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆstuffwithstuff.comwashington.eduã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆä¾‹é¡Œã‚’è¿½åŠ ã™ã‚‹Contributeå®Ÿä¸–ç•Œã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸–ã®ä¸­ã®ã‚·ã‚¹ãƒ†ãƒ ãŒã©ã®ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã®è¨˜äº‹      Source: Twitter timelines at scaleä»¥ä¸‹ã®è¨˜äº‹ã®é‡ç®±ã®éš…ã‚’ã¤ã¤ãã‚ˆã†ãªç´°ã‹ã„è©³ç´°ã«ã“ã ã‚ã‚‰ãªã„ã“ã¨ã€‚ã‚€ã—ã‚å…±é€šã®åŸç†ã€æŠ€è¡“ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã‚‹ã“ã¨ãã‚Œãã‚Œã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã©ã‚“ãªå•é¡ŒãŒè§£æ±ºã•ã‚Œã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¯ã©ã“ã§ã†ã¾ãä½¿ãˆã‚‚ã—ãã¯ä½¿ãˆãªã„ã‹ã‚’çŸ¥ã‚‹ã“ã¨å­¦ã‚“ã ã“ã¨ã‚’å¾©ç¿’ã™ã‚‹ã“ã¨ç¨®é¡ã‚·ã‚¹ãƒ†ãƒ å‚è€ƒãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿å‡¦ç†MapReduce - Googleã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ research.google.comãƒ‡ãƒ¼ã‚¿å‡¦ç†Spark - Databricksã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿å‡¦ç†Storm - Twitterã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Bigtable - Googleã®ã‚«ãƒ©ãƒ æŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹harvard.eduãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢HBase - Bigtableã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Cassandra - Facebookã®ã‚«ãƒ©ãƒ æŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢DynamoDB - Amazonã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹harvard.eduãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢MongoDB - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Spanner - Googleã®ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹research.google.comãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Memcached - åˆ†æ•£ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Redis - æ°¸ç¶šæ€§ã¨ãƒãƒªãƒ¥ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’å…¼ã­å‚™ãˆãŸåˆ†æ•£ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ Google File System (GFS) - åˆ†æ•£ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ research.google.comãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ Hadoop File System (HDFS) - GFSã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…apache.orgMiscChubby - ç–çµåˆã®åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ­ãƒƒã‚¯ã™ã‚‹Googleã®ã‚µãƒ¼ãƒ“ã‚¹research.google.comMiscDapper - åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’è¿½è·¡ã™ã‚‹ã‚¤ãƒ³ãƒ•ãƒ©research.google.comMiscKafka - LinkedInã«ã‚ˆã‚‹Pub/subãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼slideshare.netMiscZookeeper - åŒæœŸã‚’å¯èƒ½ã«ã™ã‚‹ä¸­å¤®é›†æ¨©ã‚¤ãƒ³ãƒ•ãƒ©ã¨ã‚µãƒ¼ãƒ“ã‚¹slideshare.netã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¿½åŠ ã™ã‚‹Contributeå„ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¼æ¥­å‚è€ƒãƒšãƒ¼ã‚¸AmazonAmazon architectureCinchcastProducing 1,500 hours of audio every dayDataSiftRealtime datamining At 120,000 tweets per secondDropBoxHow we've scaled DropboxESPNOperating At 100,000 duh nuh nuhs per secondGoogleGoogle architectureInstagram14 million users, terabytes of photosWhat powers InstagramJustin.tvJustin.Tv's live video broadcasting architectureFacebookScaling memcached at FacebookTAO: Facebookâ€™s distributed data store for the social graphFacebookâ€™s photo storageFlickrFlickr architectureMailboxFrom 0 to one million users in 6 weeksPinterestFrom 0 To 10s of billions of page views a month18 million visitors, 10x growth, 12 employeesPlayfish50 million monthly users and growingPlentyOfFishPlentyOfFish architectureSalesforceHow they handle 1.3 billion transactions a dayStack OverflowStack Overflow architectureTripAdvisor40M visitors, 200M dynamic page views, 30TB dataTumblr15 billion page views a monthTwitterMaking Twitter 10000 percent fasterStoring 250 million tweets a day using MySQL150M active users, 300K QPS, a 22 MB/S firehoseTimelines at scaleBig and small data at TwitterOperations at Twitter: scaling beyond 100 million usersUberHow Uber scales their real-time market platformWhatsAppThe WhatsApp architecture Facebook bought for $19 billionYouTubeYouTube scalabilityYouTube architectureä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°é¢æ¥ã‚’å—ã‘ã‚‹ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æŠ•ã’ã‚‰ã‚Œã‚‹è³ªå•ã¯åŒã˜åˆ†é‡ã‹ã‚‰æ¥ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã§ã—ã‚‡ã†Airbnb EngineeringAtlassian DevelopersAutodesk EngineeringAWS BlogBitly Engineering BlogBox BlogsCloudera Developer BlogDropbox Tech BlogEngineering at QuoraEbay Tech BlogEvernote Tech BlogEtsy Code as CraftFacebook EngineeringFlickr CodeFoursquare Engineering BlogGitHub Engineering BlogGoogle Research BlogGroupon Engineering BlogHeroku Engineering BlogHubspot Engineering BlogHigh ScalabilityInstagram EngineeringIntel Software BlogJane Street Tech BlogLinkedIn EngineeringMicrosoft EngineeringMicrosoft Python EngineeringNetflix Tech BlogPaypal Developer BlogPinterest Engineering BlogQuora EngineeringReddit BlogSalesforce Engineering BlogSlack Engineering BlogSpotify LabsTwilio Engineering BlogTwitter EngineeringUber Engineering BlogYahoo Engineering BlogYelp Engineering BlogZynga Engineering Blogãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:kilimchoi/engineering-blogsã“ã“ã«ã‚ã‚‹ãƒªã‚¹ãƒˆã¯æ¯”è¼ƒçš„å°è¦æ¨¡ãªã‚‚ã®ã«ã¨ã©ã‚ã€kilimchoi/engineering-blogsã«ã‚ˆã‚Šè©³ç´°ã«è¨˜ã™ã“ã¨ã§é‡è¤‡ã—ãªã„ã‚ˆã†ã«ã—ã¦ãŠãã“ã¨ã«ã™ã‚‹ã€‚ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°ã¸ã®ãƒªãƒ³ã‚¯ã‚’è¿½åŠ ã™ã‚‹å ´åˆã¯ã“ã“ã§ã¯ãªãã€engineering-blogsãƒ¬ãƒœã‚¸ãƒˆãƒªã«è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚é€²è¡Œä¸­ã®ä½œæ¥­ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¿½åŠ ã‚„ã€é€²è¡Œä¸­ã®ä½œæ¥­ã‚’æ‰‹ä¼ã£ã¦ã„ãŸã ã‘ã‚‹å ´åˆã¯ã“ã¡ã‚‰!MapReduceã«ã‚ˆã‚‹åˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°Consistent hashingScatter gatherContributeã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¯ãƒ¬ã‚¸ãƒƒãƒˆåŠã³ã€å‚ç…§ãƒšãƒ¼ã‚¸ã¯é©æ™‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªå†…ã«è¨˜è¼‰ã—ã¦ã‚ã‚Šã¾ã™Special thanks to:Hired in techCracking the coding interviewHigh scalabilitycheckcheckzz/system-design-interviewshashank88/system_designmmcgrana/services-engineeringSystem design cheat sheetA distributed systems reading listCracking the system design interviewContact infoFeel free to contact me to discuss any issues, questions, or comments.My contact info can be found on my GitHub page.LicenseI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2017 Donne MartinCreative Commons Attribution 4.0 International License (CC BY 4.0)http://creativecommons.org/licenses/by/4.0/"
30,AUTOMATIC1111/stable-diffusion-webui,https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/README.md,Python,"Stable Diffusion web UIA browser interface based on Gradio library for Stable Diffusion.FeaturesDetailed feature showcase with images:Original txt2img and img2img modesOne click install and run script (but you still must install python and git)OutpaintingInpaintingColor SketchPrompt MatrixStable Diffusion UpscaleAttention, specify parts of text that the model should pay more attention toa man in a ((tuxedo)) - will pay more attention to tuxedoa man in a (tuxedo:1.21) - alternative syntaxselect text and press Ctrl+Up or Ctrl+Down (or Command+Up or Command+Down if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)Loopback, run img2img processing multiple timesX/Y/Z plot, a way to draw a 3 dimensional plot of images with different parametersTextual Inversionhave as many embeddings as you want and use any names you like for themuse multiple embeddings with different numbers of vectors per tokenworks with half precision floating point numberstrain embeddings on 8GB (also reports of 6GB working)Extras tab with:GFPGAN, neural network that fixes facesCodeFormer, face restoration tool as an alternative to GFPGANRealESRGAN, neural network upscalerESRGAN, neural network upscaler with a lot of third party modelsSwinIR and Swin2SR (see here), neural network upscalersLDSR, Latent diffusion super resolution upscalingResizing aspect ratio optionsSampling method selectionAdjust sampler eta values (noise multiplier)More advanced noise setting optionsInterrupt processing at any time4GB video card support (also reports of 2GB working)Correct seeds for batchesLive prompt token length validationGeneration parametersparameters you used to generate images are saved with that imagein PNG chunks for PNG, in EXIF for JPEGcan drag the image to PNG info tab to restore generation parameters and automatically copy them into UIcan be disabled in settingsdrag and drop an image/text-parameters to promptboxRead Generation Parameters Button, loads parameters in promptbox to UISettings pageRunning arbitrary python code from UI (must run with --allow-code to enable)Mouseover hints for most UI elementsPossible to change defaults/mix/max/step values for UI elements via text configTiling support, a checkbox to create images that can be tiled like texturesProgress bar and live image generation previewCan use a separate neural network to produce previews with almost none VRAM or compute requirementNegative prompt, an extra text field that allows you to list what you don't want to see in generated imageStyles, a way to save part of prompt and easily apply them via dropdown laterVariations, a way to generate same image but with tiny differencesSeed resizing, a way to generate same image but at slightly different resolutionCLIP interrogator, a button that tries to guess prompt from an imagePrompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midwayBatch Processing, process a group of files using img2imgImg2img Alternative, reverse Euler method of cross attention controlHighres Fix, a convenience option to produce high resolution pictures in one click without usual distortionsReloading checkpoints on the flyCheckpoint Merger, a tab that allows you to merge up to 3 checkpoints into oneCustom scripts with many extensions from communityComposable-Diffusion, a way to use multiple prompts at onceseparate prompts using uppercase ANDalso supports weights for prompts: a cat :1.2 AND a dog AND a penguin :2.2No token limit for prompts (original stable diffusion lets you use up to 75 tokens)DeepDanbooru integration, creates danbooru style tags for anime promptsxformers, major speed increase for select cards: (add --xformers to commandline args)via extension: History tab: view, direct and delete images conveniently within the UIGenerate forever optionTraining tabhypernetworks and embeddings optionsPreprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)Clip skipHypernetworksLoras (same as Hypernetworks but more pretty)A sparate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your promptCan select to load a different VAE from settings screenEstimated completion time in progress barAPISupport for dedicated inpainting model by RunwayMLvia extension: Aesthetic Gradients, a way to generate images with a specific aesthetic by using clip images embeds (implementation of https://github.com/vicgalle/stable-diffusion-aesthetic-gradients)Stable Diffusion 2.0 support - see wiki for instructionsAlt-Diffusion support - see wiki for instructionsNow without any bad letters!Load checkpoints in safetensors formatEased resolution restriction: generated image's domension must be a multiple of 8 rather than 64Now with a license!Reorder elements in the UI from settings screenInstallation and RunningMake sure the required dependencies are met and follow the instructions available for both NVidia (recommended) and AMD GPUs.Alternatively, use online services (like Google Colab):List of Online ServicesInstallation on Windows 10/11 with NVidia-GPUs using release packageDownload sd.webui.zip from v1.0.0-pre and extract it's contents.Run update.bat.Run run.bat.For more details see Install-and-Run-on-NVidia-GPUsAutomatic Installation on WindowsInstall Python 3.10.6 (Newer version of Python does not support torch), checking \""Add Python to PATH\"".Install git.Download the stable-diffusion-webui repository, for example by running git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git.Run webui-user.bat from Windows Explorer as normal, non-administrator, user.Automatic Installation on LinuxInstall the dependencies:# Debian-based:sudo apt install wget git python3 python3-venv# Red Hat-based:sudo dnf install wget git python3# Arch-based:sudo pacman -S wget git python3Navigate to the directory you would like the webui to be installed and execute the following command:bash <(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)Run webui.sh.Check webui-user.sh for options.Installation on Apple SiliconFind the instructions here.ContributingHere's how to add code to this repo: ContributingDocumentationThe documentation was moved from this README over to the project's wiki.For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) crawlable wiki.CreditsLicenses for borrowed code can be found in Settings -> Licenses screen, and also in html/licenses.html file.Stable Diffusion - https://github.com/CompVis/stable-diffusion, https://github.com/CompVis/taming-transformersk-diffusion - https://github.com/crowsonkb/k-diffusion.gitGFPGAN - https://github.com/TencentARC/GFPGAN.gitCodeFormer - https://github.com/sczhou/CodeFormerESRGAN - https://github.com/xinntao/ESRGANSwinIR - https://github.com/JingyunLiang/SwinIRSwin2SR - https://github.com/mv-lab/swin2srLDSR - https://github.com/Hafiidz/latent-diffusionMiDaS - https://github.com/isl-org/MiDaSIdeas for optimizations - https://github.com/basujindal/stable-diffusionCross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)Sub-quadratic Cross Attention layer optimization - Alex Birch (Birch-san/diffusers#1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we're not using his code, but we are using his ideas).Idea for SD upscale - https://github.com/jquesnelle/txt2imghdNoise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-botCLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogatorIdea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorchxformers - https://github.com/facebookresearch/xformersDeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooruSampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pixSecurity advice - RyotaKUniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPCTAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesdLyCORIS - KohakuBlueleafInitial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.(You)"
31,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
32,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.âš ï¸ IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!âš ï¸ IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means youâ€™ve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the projectâ€™s direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a projectâ€™s website for a â€œteamâ€ page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participantsâ€™ behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, â€œHow do Iâ€¦â€œ or â€œWhat do you think aboutâ€¦â€œ instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
33,geekcomputers/Python,https://github.com/geekcomputers/Python/blob/master/README.md,Python,"My Python Eggs ğŸ ğŸ˜„I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in Notepad++ ğŸ—’ï¸Feel free to explore the scripts and use them for your learning and automation needs!List of Scripts:batch_file_rename.py - Batch rename a group of files in a specified directory, changing their extensions.create_dir_if_not_there.py - Check if a directory exists in the user's home directory. Create it if it doesn't exist.Fast Youtube Downloader - Download YouTube videos quickly with parallel threads using aria2c.Google Image Downloader - Query a given term and retrieve images from the Google Image database.dir_test.py - Test if the directory testdir exists. If not, create it.env_check.py - Check if all the required environment variables are set.blackjack.py - Casino Blackjack-21 game in Python.fileinfo.py - Show file information for a given file.folder_size.py - Scan the current directory and all subdirectories and display their sizes.logs.py - Search for all *.log files in a directory, zip them using the specified program, and date stamp them.move_files_over_x_days.py - Move all files over a specified age (in days) from the source directory to the destination directory.nslookup_check.py - Open the file server_list.txt and perform nslookup for each server to check the DNS entry.osinfo.py - Display information about the operating system on which the script is running.ping_servers.py - Ping the servers associated with the specified application group.ping_subnet.py - Scan the final range of a given IP subnet for available addresses.powerdown_startup.py - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.puttylogs.py - Zip all the logs in the given directory.script_count.py - Scan the scripts directory and count the different types of scripts.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.script_listing.py - List all files in a given directory and its subdirectories.testlines.py - Open a file and print out 100 lines of the set line variable.tweeter.py - Tweet text or a picture from the terminal.serial_scanner.py - List available serial ports in use on Linux and Windows systems.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.CountMillionCharacter.py and CountMillionCharacter2.0 - Get character count of a text file.xkcd_downloader.py - Download the latest XKCD comic and place them in a new folder called \""comics\"".timymodule.py - An alternative to Python's 'timeit' module and easier to use.calculator.py - Implement a calculator using Python's eval() function.Google_News.py - Use BeautifulSoup to provide latest news headlines along with news links.cricket_live_score - Use BeautifulSoup to provide live cricket scores.youtube.py - Take a song name as input and fetch the YouTube URL of the best matching song and play it.site_health.py - Check the health of a remote server.SimpleStopWatch.py - Simple stop watch implementation using Python's time module.Changemac.py - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).whatsapp-monitor.py - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.whatsapp-chat-analyzer.py - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.JARVIS.py - Control Windows programs with your voice.Images Downloader - Download images from webpages on Unix-based systems.space_invader.py.py - Classical 2D space invader game to recall your childhood memories.Test Case Generator - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.Note: The content in this repository belongs to the respective authors and creators. I'm just providing a formatted README.md for better presentation."
34,floodsung/Deep-Learning-Papers-Reading-Roadmap,https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md,Python,"Deep Learning Papers Reading RoadmapIf you are a newcomer to the Deep Learning area, the first question you may have is \""Which paper should I start reading from?\""Here is a reading roadmap of Deep Learning papers!The roadmap is constructed in accordance with the following four guidelines:From outline to detailFrom old to state-of-the-artfrom generic to specific areasfocus on state-of-the-artYou will find many papers that are quite new but really worth reading.I would continue adding papers to this roadmap.1 Deep Learning History and Basics1.0 Book[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. \""Deep learning.\"" An MIT Press book. (2015). [html] (Deep Learning Bible, you can read this book while reading following papers.) â­â­â­â­â­1.1 Survey[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. \""Deep learning.\"" Nature 521.7553 (2015): 436-444. [pdf] (Three Giants' Survey) â­â­â­â­â­1.2 Deep Belief Network(DBN)(Milestone of Deep Learning Eve)[2] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. \""A fast learning algorithm for deep belief nets.\"" Neural computation 18.7 (2006): 1527-1554. [pdf](Deep Learning Eve) â­â­â­[3] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. \""Reducing the dimensionality of data with neural networks.\"" Science 313.5786 (2006): 504-507. [pdf] (Milestone, Show the promise of deep learning) â­â­â­1.3 ImageNet Evolutionï¼ˆDeep Learning broke out from hereï¼‰[4] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \""Imagenet classification with deep convolutional neural networks.\"" Advances in neural information processing systems. 2012. [pdf] (AlexNet, Deep Learning Breakthrough) â­â­â­â­â­[5] Simonyan, Karen, and Andrew Zisserman. \""Very deep convolutional networks for large-scale image recognition.\"" arXiv preprint arXiv:1409.1556 (2014). [pdf] (VGGNet,Neural Networks become very deep!) â­â­â­[6] Szegedy, Christian, et al. \""Going deeper with convolutions.\"" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [pdf] (GoogLeNet) â­â­â­[7] He, Kaiming, et al. \""Deep residual learning for image recognition.\"" arXiv preprint arXiv:1512.03385 (2015). [pdf] (ResNet,Very very deep networks, CVPR best paper) â­â­â­â­â­1.4 Speech Recognition Evolution[8] Hinton, Geoffrey, et al. \""Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups.\"" IEEE Signal Processing Magazine 29.6 (2012): 82-97. [pdf] (Breakthrough in speech recognition)â­â­â­â­[9] Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. \""Speech recognition with deep recurrent neural networks.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (RNN)â­â­â­[10] Graves, Alex, and Navdeep Jaitly. \""Towards End-To-End Speech Recognition with Recurrent Neural Networks.\"" ICML. Vol. 14. 2014. [pdf]â­â­â­[11] Sak, HaÅŸim, et al. \""Fast and accurate recurrent neural network acoustic models for speech recognition.\"" arXiv preprint arXiv:1507.06947 (2015). [pdf] (Google Speech Recognition System) â­â­â­[12] Amodei, Dario, et al. \""Deep speech 2: End-to-end speech recognition in english and mandarin.\"" arXiv preprint arXiv:1512.02595 (2015). [pdf] (Baidu Speech Recognition System) â­â­â­â­[13] W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig \""Achieving Human Parity in Conversational Speech Recognition.\"" arXiv preprint arXiv:1610.05256 (2016). [pdf] (State-of-the-art in speech recognition, Microsoft) â­â­â­â­After reading above papers, you will have a basic understanding of the Deep Learning history, the basic architectures of Deep Learning model(including CNN, RNN, LSTM) and how deep learning can be applied to image and speech recognition issues. The following papers will take you in-depth understanding of the Deep Learning method, Deep Learning in different areas of application and the frontiers. I suggest that you can choose the following papers based on your interests and research direction.#2 Deep Learning Method2.1 Model[14] Hinton, Geoffrey E., et al. \""Improving neural networks by preventing co-adaptation of feature detectors.\"" arXiv preprint arXiv:1207.0580 (2012). [pdf] (Dropout) â­â­â­[15] Srivastava, Nitish, et al. \""Dropout: a simple way to prevent neural networks from overfitting.\"" Journal of Machine Learning Research 15.1 (2014): 1929-1958. [pdf] â­â­â­[16] Ioffe, Sergey, and Christian Szegedy. \""Batch normalization: Accelerating deep network training by reducing internal covariate shift.\"" arXiv preprint arXiv:1502.03167 (2015). [pdf] (An outstanding Work in 2015) â­â­â­â­[17] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \""Layer normalization.\"" arXiv preprint arXiv:1607.06450 (2016). [pdf] (Update of Batch Normalization) â­â­â­â­[18] Courbariaux, Matthieu, et al. \""Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 orâˆ’1.\"" [pdf] (New Model,Fast)  â­â­â­[19] Jaderberg, Max, et al. \""Decoupled neural interfaces using synthetic gradients.\"" arXiv preprint arXiv:1608.05343 (2016). [pdf] (Innovation of Training Method,Amazing Work) â­â­â­â­â­[20] Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. \""Net2net: Accelerating learning via knowledge transfer.\"" arXiv preprint arXiv:1511.05641 (2015). [pdf] (Modify previously trained network to reduce training epochs) â­â­â­[21] Wei, Tao, et al. \""Network Morphism.\"" arXiv preprint arXiv:1603.01670 (2016). [pdf] (Modify previously trained network to reduce training epochs) â­â­â­2.2 Optimization[22] Sutskever, Ilya, et al. \""On the importance of initialization and momentum in deep learning.\"" ICML (3) 28 (2013): 1139-1147. [pdf] (Momentum optimizer) â­â­[23] Kingma, Diederik, and Jimmy Ba. \""Adam: A method for stochastic optimization.\"" arXiv preprint arXiv:1412.6980 (2014). [pdf] (Maybe used most often currently) â­â­â­[24] Andrychowicz, Marcin, et al. \""Learning to learn by gradient descent by gradient descent.\"" arXiv preprint arXiv:1606.04474 (2016). [pdf] (Neural Optimizer,Amazing Work) â­â­â­â­â­[25] Han, Song, Huizi Mao, and William J. Dally. \""Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding.\"" CoRR, abs/1510.00149 2 (2015). [pdf] (ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup) â­â­â­â­â­[26] Iandola, Forrest N., et al. \""SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size.\"" arXiv preprint arXiv:1602.07360 (2016). [pdf] (Also a new direction to optimize NN,DeePhi Tech Startup) â­â­â­â­[27] Glorat Xavier, Bengio Yoshua, et al. \""Understanding the difficulty of training deep forward neural networks.\"" Proceedings of the thirteenth International Conference on Artificial Intelligence and Statistics, PMLR 9:249-256,2010. [pdf] â­â­â­â­2.3 Unsupervised Learning / Deep Generative Model[28] Le, Quoc V. \""Building high-level features using large scale unsupervised learning.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (Milestone, Andrew Ng, Google Brain Project, Cat) â­â­â­â­[29] Kingma, Diederik P., and Max Welling. \""Auto-encoding variational bayes.\"" arXiv preprint arXiv:1312.6114 (2013). [pdf] (VAE) â­â­â­â­[30] Goodfellow, Ian, et al. \""Generative adversarial nets.\"" Advances in Neural Information Processing Systems. 2014. [pdf] (GAN,super cool idea) â­â­â­â­â­[31] Radford, Alec, Luke Metz, and Soumith Chintala. \""Unsupervised representation learning with deep convolutional generative adversarial networks.\"" arXiv preprint arXiv:1511.06434 (2015). [pdf] (DCGAN) â­â­â­â­[32] Gregor, Karol, et al. \""DRAW: A recurrent neural network for image generation.\"" arXiv preprint arXiv:1502.04623 (2015). [pdf] (VAE with attention, outstanding work) â­â­â­â­â­[33] Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. \""Pixel recurrent neural networks.\"" arXiv preprint arXiv:1601.06759 (2016). [pdf] (PixelRNN) â­â­â­â­[34] Oord, Aaron van den, et al. \""Conditional image generation with PixelCNN decoders.\"" arXiv preprint arXiv:1606.05328 (2016). [pdf] (PixelCNN) â­â­â­â­[34] S. Mehri et al., \""SampleRNN: An Unconditional End-to-End Neural Audio Generation Model.\"" arXiv preprint \tarXiv:1612.07837 (2016). [pdf] â­â­â­â­â­2.4 RNN / Sequence-to-Sequence Model[35] Graves, Alex. \""Generating sequences with recurrent neural networks.\"" arXiv preprint arXiv:1308.0850 (2013). [pdf] (LSTM, very nice generating result, show the power of RNN) â­â­â­â­[36] Cho, Kyunghyun, et al. \""Learning phrase representations using RNN encoder-decoder for statistical machine translation.\"" arXiv preprint arXiv:1406.1078 (2014). [pdf] (First Seq-to-Seq Paper) â­â­â­â­[37] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \""Sequence to sequence learning with neural networks.\"" Advances in neural information processing systems. 2014. [pdf] (Outstanding Work) â­â­â­â­â­[38] Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. \""Neural Machine Translation by Jointly Learning to Align and Translate.\"" arXiv preprint arXiv:1409.0473 (2014). [pdf] â­â­â­â­[39] Vinyals, Oriol, and Quoc Le. \""A neural conversational model.\"" arXiv preprint arXiv:1506.05869 (2015). [pdf] (Seq-to-Seq on Chatbot) â­â­â­2.5 Neural Turing Machine[40] Graves, Alex, Greg Wayne, and Ivo Danihelka. \""Neural turing machines.\"" arXiv preprint arXiv:1410.5401 (2014). [pdf] (Basic Prototype of Future Computer) â­â­â­â­â­[41] Zaremba, Wojciech, and Ilya Sutskever. \""Reinforcement learning neural Turing machines.\"" arXiv preprint arXiv:1505.00521 362 (2015). [pdf] â­â­â­[42] Weston, Jason, Sumit Chopra, and Antoine Bordes. \""Memory networks.\"" arXiv preprint arXiv:1410.3916 (2014). [pdf] â­â­â­[43] Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. \""End-to-end memory networks.\"" Advances in neural information processing systems. 2015. [pdf] â­â­â­â­[44] Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. \""Pointer networks.\"" Advances in Neural Information Processing Systems. 2015. [pdf] â­â­â­â­[45] Graves, Alex, et al. \""Hybrid computing using a neural network with dynamic external memory.\"" Nature (2016). [pdf] (Milestone,combine above papers' ideas) â­â­â­â­â­2.6 Deep Reinforcement Learning[46] Mnih, Volodymyr, et al. \""Playing atari with deep reinforcement learning.\"" arXiv preprint arXiv:1312.5602 (2013). [pdf]) (First Paper named deep reinforcement learning) â­â­â­â­[47] Mnih, Volodymyr, et al. \""Human-level control through deep reinforcement learning.\"" Nature 518.7540 (2015): 529-533. [pdf] (Milestone) â­â­â­â­â­[48] Wang, Ziyu, Nando de Freitas, and Marc Lanctot. \""Dueling network architectures for deep reinforcement learning.\"" arXiv preprint arXiv:1511.06581 (2015). [pdf] (ICLR best paper,great idea)  â­â­â­â­[49] Mnih, Volodymyr, et al. \""Asynchronous methods for deep reinforcement learning.\"" arXiv preprint arXiv:1602.01783 (2016). [pdf] (State-of-the-art method) â­â­â­â­â­[50] Lillicrap, Timothy P., et al. \""Continuous control with deep reinforcement learning.\"" arXiv preprint arXiv:1509.02971 (2015). [pdf] (DDPG) â­â­â­â­[51] Gu, Shixiang, et al. \""Continuous Deep Q-Learning with Model-based Acceleration.\"" arXiv preprint arXiv:1603.00748 (2016). [pdf] (NAF) â­â­â­â­[52] Schulman, John, et al. \""Trust region policy optimization.\"" CoRR, abs/1502.05477 (2015). [pdf] (TRPO) â­â­â­â­[53] Silver, David, et al. \""Mastering the game of Go with deep neural networks and tree search.\"" Nature 529.7587 (2016): 484-489. [pdf] (AlphaGo) â­â­â­â­â­2.7 Deep Transfer Learning / Lifelong Learning / especially for RL[54] Bengio, Yoshua. \""Deep Learning of Representations for Unsupervised and Transfer Learning.\"" ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [pdf] (A Tutorial) â­â­â­[55] Silver, Daniel L., Qiang Yang, and Lianghao Li. \""Lifelong Machine Learning Systems: Beyond Learning Algorithms.\"" AAAI Spring Symposium: Lifelong Machine Learning. 2013. [pdf] (A brief discussion about lifelong learning)  â­â­â­[56] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \""Distilling the knowledge in a neural network.\"" arXiv preprint arXiv:1503.02531 (2015). [pdf] (Godfather's Work) â­â­â­â­[57] Rusu, Andrei A., et al. \""Policy distillation.\"" arXiv preprint arXiv:1511.06295 (2015). [pdf] (RL domain) â­â­â­[58] Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. \""Actor-mimic: Deep multitask and transfer reinforcement learning.\"" arXiv preprint arXiv:1511.06342 (2015). [pdf] (RL domain) â­â­â­[59] Rusu, Andrei A., et al. \""Progressive neural networks.\"" arXiv preprint arXiv:1606.04671 (2016). [pdf] (Outstanding Work, A novel idea) â­â­â­â­â­2.8 One Shot Deep Learning[60] Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. \""Human-level concept learning through probabilistic program induction.\"" Science 350.6266 (2015): 1332-1338. [pdf] (No Deep Learning,but worth reading) â­â­â­â­â­[61] Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. \""Siamese Neural Networks for One-shot Image Recognition.\""(2015) [pdf] â­â­â­[62] Santoro, Adam, et al. \""One-shot Learning with Memory-Augmented Neural Networks.\"" arXiv preprint arXiv:1605.06065 (2016). [pdf] (A basic step to one shot learning) â­â­â­â­[63] Vinyals, Oriol, et al. \""Matching Networks for One Shot Learning.\"" arXiv preprint arXiv:1606.04080 (2016). [pdf] â­â­â­[64] Hariharan, Bharath, and Ross Girshick. \""Low-shot visual object recognition.\"" arXiv preprint arXiv:1606.02819 (2016). [pdf] (A step to large data) â­â­â­â­3 Applications3.1 NLP(Natural Language Processing)[1] Antoine Bordes, et al. \""Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing.\"" AISTATS(2012) [pdf] â­â­â­â­[2] Mikolov, et al. \""Distributed representations of words and phrases and their compositionality.\"" ANIPS(2013): 3111-3119 [pdf] (word2vec) â­â­â­[3] Sutskever, et al. \""â€œSequence to sequence learning with neural networks.\"" ANIPS(2014) [pdf] â­â­â­[4] Ankit Kumar, et al. \""â€œAsk Me Anything: Dynamic Memory Networks for Natural Language Processing.\"" arXiv preprint arXiv:1506.07285(2015) [pdf] â­â­â­â­[5] Yoon Kim, et al. \""Character-Aware Neural Language Models.\"" NIPS(2015) arXiv preprint arXiv:1508.06615(2015) [pdf] â­â­â­â­[6] Jason Weston, et al. \""Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.\"" arXiv preprint arXiv:1502.05698(2015) [pdf] (bAbI tasks) â­â­â­[7] Karl Moritz Hermann, et al. \""Teaching Machines to Read and Comprehend.\"" arXiv preprint arXiv:1506.03340(2015) [pdf] (CNN/DailyMail cloze style questions) â­â­[8] Alexis Conneau, et al. \""Very Deep Convolutional Networks for Natural Language Processing.\"" arXiv preprint arXiv:1606.01781(2016) [pdf] (state-of-the-art in text classification) â­â­â­[9] Armand Joulin, et al. \""Bag of Tricks for Efficient Text Classification.\"" arXiv preprint arXiv:1607.01759(2016) [pdf] (slightly worse than state-of-the-art, but a lot faster) â­â­â­3.2 Object Detection[1] Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. \""Deep neural networks for object detection.\"" Advances in Neural Information Processing Systems. 2013. [pdf] â­â­â­[2] Girshick, Ross, et al. \""Rich feature hierarchies for accurate object detection and semantic segmentation.\"" Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [pdf] (RCNN) â­â­â­â­â­[3] He, Kaiming, et al. \""Spatial pyramid pooling in deep convolutional networks for visual recognition.\"" European Conference on Computer Vision. Springer International Publishing, 2014. [pdf] (SPPNet) â­â­â­â­[4] Girshick, Ross. \""Fast r-cnn.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] â­â­â­â­[5] Ren, Shaoqing, et al. \""Faster R-CNN: Towards real-time object detection with region proposal networks.\"" Advances in neural information processing systems. 2015. [pdf] â­â­â­â­[6] Redmon, Joseph, et al. \""You only look once: Unified, real-time object detection.\"" arXiv preprint arXiv:1506.02640 (2015). [pdf] (YOLO,Oustanding Work, really practical) â­â­â­â­â­[7] Liu, Wei, et al. \""SSD: Single Shot MultiBox Detector.\"" arXiv preprint arXiv:1512.02325 (2015). [pdf] â­â­â­[8] Dai, Jifeng, et al. \""R-FCN: Object Detection viaRegion-based Fully Convolutional Networks.\"" arXiv preprint arXiv:1605.06409 (2016). [pdf] â­â­â­â­[9] He, Gkioxari, et al. \""Mask R-CNN\"" arXiv preprint arXiv:1703.06870 (2017). [pdf] â­â­â­â­[10] Bochkovskiy, Alexey, et al. \""YOLOv4: Optimal Speed and Accuracy of Object Detection.\""  arXiv preprint arXiv:2004.10934 (2020). [pdf] â­â­â­â­[11] Tan, Mingxing, et al. â€œEfficientDet: Scalable and Efficient Object Detection.\"" arXiv preprint arXiv:1911.09070 (2019). [pdf] â­â­â­â­â­3.3 Visual Tracking[1] Wang, Naiyan, and Dit-Yan Yeung. \""Learning a deep compact image representation for visual tracking.\"" Advances in neural information processing systems. 2013. [pdf] (First Paper to do visual tracking using Deep Learning,DLT Tracker) â­â­â­[2] Wang, Naiyan, et al. \""Transferring rich feature hierarchies for robust visual tracking.\"" arXiv preprint arXiv:1501.04587 (2015). [pdf] (SO-DLT) â­â­â­â­[3] Wang, Lijun, et al. \""Visual tracking with fully convolutional networks.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] (FCNT) â­â­â­â­[4] Held, David, Sebastian Thrun, and Silvio Savarese. \""Learning to Track at 100 FPS with Deep Regression Networks.\"" arXiv preprint arXiv:1604.01802 (2016). [pdf] (GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods) â­â­â­â­[5] Bertinetto, Luca, et al. \""Fully-Convolutional Siamese Networks for Object Tracking.\"" arXiv preprint arXiv:1606.09549 (2016). [pdf] (SiameseFC,New state-of-the-art for real-time object tracking) â­â­â­â­[6] Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. \""Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking.\"" ECCV (2016) [pdf] (C-COT) â­â­â­â­[7] Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. \""Modeling and Propagating CNNs in a Tree Structure for Visual Tracking.\"" arXiv preprint arXiv:1608.07242 (2016). [pdf] (VOT2016 Winner,TCNN) â­â­â­â­3.4 Image Caption[1] Farhadi,Ali,etal. \""Every picture tells a story: Generating sentences from images\"". In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. [pdf] â­â­â­[2] Kulkarni, Girish, et al. \""Baby talk: Understanding and generating image descriptions\"". In Proceedings of the 24th CVPR, 2011. [pdf]â­â­â­â­[3] Vinyals, Oriol, et al. \""Show and tell: A neural image caption generator\"". In arXiv preprint arXiv:1411.4555, 2014. [pdf]â­â­â­[4] Donahue, Jeff, et al. \""Long-term recurrent convolutional networks for visual recognition and description\"". In arXiv preprint arXiv:1411.4389 ,2014. [pdf][5] Karpathy, Andrej, and Li Fei-Fei. \""Deep visual-semantic alignments for generating image descriptions\"". In arXiv preprint arXiv:1412.2306, 2014. [pdf]â­â­â­â­â­[6] Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. \""Deep fragment embeddings for bidirectional image sentence mapping\"". In Advances in neural information processing systems, 2014. [pdf]â­â­â­â­[7] Fang, Hao, et al. \""From captions to visual concepts and back\"". In arXiv preprint arXiv:1411.4952, 2014. [pdf]â­â­â­â­â­[8] Chen, Xinlei, and C. Lawrence Zitnick. \""Learning a recurrent visual representation for image caption generation\"". In arXiv preprint arXiv:1411.5654, 2014. [pdf]â­â­â­â­[9] Mao, Junhua, et al. \""Deep captioning with multimodal recurrent neural networks (m-rnn)\"". In arXiv preprint arXiv:1412.6632, 2014. [pdf]â­â­â­[10] Xu, Kelvin, et al. \""Show, attend and tell: Neural image caption generation with visual attention\"". In arXiv preprint arXiv:1502.03044, 2015. [pdf]â­â­â­â­â­3.5 Machine TranslationSome milestone papers are listed in RNN / Seq-to-Seq topic.[1] Luong, Minh-Thang, et al. \""Addressing the rare word problem in neural machine translation.\"" arXiv preprint arXiv:1410.8206 (2014). [pdf] â­â­â­â­[2] Sennrich, et al. \""Neural Machine Translation of Rare Words with Subword Units\"". In arXiv preprint arXiv:1508.07909, 2015. [pdf]â­â­â­[3] Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. \""Effective approaches to attention-based neural machine translation.\"" arXiv preprint arXiv:1508.04025 (2015). [pdf] â­â­â­â­[4] Chung, et al. \""A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation\"". In arXiv preprint arXiv:1603.06147, 2016. [pdf]â­â­[5] Lee, et al. \""Fully Character-Level Neural Machine Translation without Explicit Segmentation\"". In arXiv preprint arXiv:1610.03017, 2016. [pdf]â­â­â­â­â­[6] Wu, Schuster, Chen, Le, et al. \""Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\"". In arXiv preprint arXiv:1609.08144v2, 2016. [pdf] (Milestone) â­â­â­â­3.6 Robotics[1] KoutnÃ­k, Jan, et al. \""Evolving large-scale neural networks for vision-based reinforcement learning.\"" Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [pdf] â­â­â­[2] Levine, Sergey, et al. \""End-to-end training of deep visuomotor policies.\"" Journal of Machine Learning Research 17.39 (2016): 1-40. [pdf] â­â­â­â­â­[3] Pinto, Lerrel, and Abhinav Gupta. \""Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours.\"" arXiv preprint arXiv:1509.06825 (2015). [pdf] â­â­â­[4] Levine, Sergey, et al. \""Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection.\"" arXiv preprint arXiv:1603.02199 (2016). [pdf] â­â­â­â­[5] Zhu, Yuke, et al. \""Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning.\"" arXiv preprint arXiv:1609.05143 (2016). [pdf] â­â­â­â­[6] Yahya, Ali, et al. \""Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search.\"" arXiv preprint arXiv:1610.00673 (2016). [pdf] â­â­â­â­[7] Gu, Shixiang, et al. \""Deep Reinforcement Learning for Robotic Manipulation.\"" arXiv preprint arXiv:1610.00633 (2016). [pdf] â­â­â­â­[8] A Rusu, M Vecerik, Thomas RothÃ¶rl, N Heess, R Pascanu, R Hadsell.\""Sim-to-Real Robot Learning from Pixels with Progressive Nets.\"" arXiv preprint arXiv:1610.04286 (2016). [pdf] â­â­â­â­[9] Mirowski, Piotr, et al. \""Learning to navigate in complex environments.\"" arXiv preprint arXiv:1611.03673 (2016). [pdf] â­â­â­â­3.7 Art[1] Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). \""Inceptionism: Going Deeper into Neural Networks\"". Google Research. [html] (Deep Dream)â­â­â­â­[2] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. \""A neural algorithm of artistic style.\"" arXiv preprint arXiv:1508.06576 (2015). [pdf] (Outstanding Work, most successful method currently) â­â­â­â­â­[3] Zhu, Jun-Yan, et al. \""Generative Visual Manipulation on the Natural Image Manifold.\"" European Conference on Computer Vision. Springer International Publishing, 2016. [pdf] (iGAN) â­â­â­â­[4] Champandard, Alex J. \""Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks.\"" arXiv preprint arXiv:1603.01768 (2016). [pdf] (Neural Doodle) â­â­â­â­[5] Zhang, Richard, Phillip Isola, and Alexei A. Efros. \""Colorful Image Colorization.\"" arXiv preprint arXiv:1603.08511 (2016). [pdf] â­â­â­â­[6] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. \""Perceptual losses for real-time style transfer and super-resolution.\"" arXiv preprint arXiv:1603.08155 (2016). [pdf] â­â­â­â­[7] Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. \""A learned representation for artistic style.\"" arXiv preprint arXiv:1610.07629 (2016). [pdf] â­â­â­â­[8] Gatys, Leon and Ecker, et al.\""Controlling Perceptual Factors in Neural Style Transfer.\"" arXiv preprint arXiv:1611.07865 (2016). [pdf] (control style transfer over spatial location,colour information and across spatial scale)â­â­â­â­[9] Ulyanov, Dmitry and Lebedev, Vadim, et al. \""Texture Networks: Feed-forward Synthesis of Textures and Stylized Images.\"" arXiv preprint arXiv:1603.03417(2016). [pdf] (texture generation and style transfer) â­â­â­â­[10] Yijun Li, Ming-Yu Liu ,Xueting Li, Ming-Hsuan Yang,Jan Kautz (NVIDIA). \""A Closed-form Solution to Photorealistic Image Stylization.\"" arXiv preprint arXiv:1802.06474(2018). [pdf] (Very fast and ultra realistic style transfer) â­â­â­â­3.8 Object Segmentation[1] J. Long, E. Shelhamer, and T. Darrell, â€œFully convolutional networks for semantic segmentation.â€ in CVPR, 2015. [pdf] â­â­â­â­â­[2] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. \""Semantic image segmentation with deep convolutional nets and fully connected crfs.\"" In ICLR, 2015. [pdf] â­â­â­â­â­[3] Pinheiro, P.O., Collobert, R., Dollar, P. \""Learning to segment object candidates.\"" In: NIPS. 2015. [pdf] â­â­â­â­[4] Dai, J., He, K., Sun, J. \""Instance-aware semantic segmentation via multi-task network cascades.\"" in CVPR. 2016 [pdf] â­â­â­[5] Dai, J., He, K., Sun, J. \""Instance-sensitive Fully Convolutional Networks.\"" arXiv preprint arXiv:1603.08678 (2016). [pdf] â­â­â­"
35,AntonOsika/gpt-engineer,https://github.com/AntonOsika/gpt-engineer/blob/main/README.md,Python,"GPT EngineerSpecify what you want it to build, the AI asks for clarification, and then builds it.GPT Engineer is made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt.DemoProject philosophySimple to get valueFlexible and easy to add new own \""AI steps\"". See steps.py.Incrementally build towards a user experience of:high level promptinggiving feedback to the AI that it will remember over timeFast handovers back and forth between AI and humanSimplicity, all computation is \""resumable\"" and persisted to the filesystemUsageChoose either stable or development.For stable release:python -m pip install gpt-engineerFor development:git clone https://github.com/AntonOsika/gpt-engineer.gitcd gpt-engineerpython -m pip install -e .(or: make install && source venv/bin/activate for a venv)API KeyEither just:export OPENAI_API_KEY=[your api key]Or:Create a copy of .env.template named .envAdd your OPENAI_API_KEY in .envCheck the Windows README for windows usage.RunningCreate an empty folder. If inside the repo, you can run:cp -r projects/example/ projects/my-new-projectFill in the prompt file in your new foldergpt-engineer projects/my-new-project(Note, gpt-engineer --help lets you see all available options. For example --steps use_feedback lets you improve/fix code in a project)By running gpt-engineer you agree to our terms.ResultsCheck the generated files in projects/my-new-project/workspaceAlternativesYou can check Docker instructions to use Docker, or simplydo everything in your browser:FeaturesYou can specify the \""identity\"" of the AI agent by editing the files in the preprompts folder.Editing the preprompts, and evolving how you write the project prompt, is how you make the agent remember things between projects.Each step in steps.py will have its communication history with GPT4 stored in the logs folder, and can be rerun with scripts/rerun_edited_message_logs.py.VisionThe gpt-engineer community is building the open platform for devs to tinker with and build their personal code-generation toolbox.If you are interested in contributing to this, we would be interested in having you.If you want to see our broader ambitions, check out the roadmap, and joindiscordto get input on how you can contribute to it.We are currently looking for more maintainers and community organizers. Email anton.osika@gmail.com if you are interested in an official role.Example              Demo.mov          "
36,fxsjy/jieba,https://github.com/fxsjy/jieba/blob/master/README.md,Python,"jiebaâ€œç»“å·´â€ä¸­æ–‡åˆ†è¯ï¼šåšæœ€å¥½çš„ Python ä¸­æ–‡åˆ†è¯ç»„ä»¶\""Jieba\"" (Chinese for \""to stutter\"") Chinese text segmentation: built to be the best Python Chinese word segmentation module.Scroll down for English documentation.ç‰¹ç‚¹æ”¯æŒå››ç§åˆ†è¯æ¨¡å¼ï¼šç²¾ç¡®æ¨¡å¼ï¼Œè¯•å›¾å°†å¥å­æœ€ç²¾ç¡®åœ°åˆ‡å¼€ï¼Œé€‚åˆæ–‡æœ¬åˆ†æï¼›å…¨æ¨¡å¼ï¼ŒæŠŠå¥å­ä¸­æ‰€æœ‰çš„å¯ä»¥æˆè¯çš„è¯è¯­éƒ½æ‰«æå‡ºæ¥, é€Ÿåº¦éå¸¸å¿«ï¼Œä½†æ˜¯ä¸èƒ½è§£å†³æ­§ä¹‰ï¼›æœç´¢å¼•æ“æ¨¡å¼ï¼Œåœ¨ç²¾ç¡®æ¨¡å¼çš„åŸºç¡€ä¸Šï¼Œå¯¹é•¿è¯å†æ¬¡åˆ‡åˆ†ï¼Œæé«˜å¬å›ç‡ï¼Œé€‚åˆç”¨äºæœç´¢å¼•æ“åˆ†è¯ã€‚paddleæ¨¡å¼ï¼Œåˆ©ç”¨PaddlePaddleæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè®­ç»ƒåºåˆ—æ ‡æ³¨ï¼ˆåŒå‘GRUï¼‰ç½‘ç»œæ¨¡å‹å®ç°åˆ†è¯ã€‚åŒæ—¶æ”¯æŒè¯æ€§æ ‡æ³¨ã€‚paddleæ¨¡å¼ä½¿ç”¨éœ€å®‰è£…paddlepaddle-tinyï¼Œpip install paddlepaddle-tiny==1.6.1ã€‚ç›®å‰paddleæ¨¡å¼æ”¯æŒjieba v0.40åŠä»¥ä¸Šç‰ˆæœ¬ã€‚jieba v0.40ä»¥ä¸‹ç‰ˆæœ¬ï¼Œè¯·å‡çº§jiebaï¼Œpip install jieba --upgrade ã€‚PaddlePaddleå®˜ç½‘æ”¯æŒç¹ä½“åˆ†è¯æ”¯æŒè‡ªå®šä¹‰è¯å…¸MIT æˆæƒåè®®å®‰è£…è¯´æ˜ä»£ç å¯¹ Python 2/3 å‡å…¼å®¹å…¨è‡ªåŠ¨å®‰è£…ï¼šeasy_install jieba æˆ–è€… pip install jieba / pip3 install jiebaåŠè‡ªåŠ¨å®‰è£…ï¼šå…ˆä¸‹è½½ http://pypi.python.org/pypi/jieba/ ï¼Œè§£å‹åè¿è¡Œ python setup.py installæ‰‹åŠ¨å®‰è£…ï¼šå°† jieba ç›®å½•æ”¾ç½®äºå½“å‰ç›®å½•æˆ–è€… site-packages ç›®å½•é€šè¿‡ import jieba æ¥å¼•ç”¨å¦‚æœéœ€è¦ä½¿ç”¨paddleæ¨¡å¼ä¸‹çš„åˆ†è¯å’Œè¯æ€§æ ‡æ³¨åŠŸèƒ½ï¼Œè¯·å…ˆå®‰è£…paddlepaddle-tinyï¼Œpip install paddlepaddle-tiny==1.6.1ã€‚ç®—æ³•åŸºäºå‰ç¼€è¯å…¸å®ç°é«˜æ•ˆçš„è¯å›¾æ‰«æï¼Œç”Ÿæˆå¥å­ä¸­æ±‰å­—æ‰€æœ‰å¯èƒ½æˆè¯æƒ…å†µæ‰€æ„æˆçš„æœ‰å‘æ— ç¯å›¾ (DAG)é‡‡ç”¨äº†åŠ¨æ€è§„åˆ’æŸ¥æ‰¾æœ€å¤§æ¦‚ç‡è·¯å¾„, æ‰¾å‡ºåŸºäºè¯é¢‘çš„æœ€å¤§åˆ‡åˆ†ç»„åˆå¯¹äºæœªç™»å½•è¯ï¼Œé‡‡ç”¨äº†åŸºäºæ±‰å­—æˆè¯èƒ½åŠ›çš„ HMM æ¨¡å‹ï¼Œä½¿ç”¨äº† Viterbi ç®—æ³•ä¸»è¦åŠŸèƒ½åˆ†è¯jieba.cut æ–¹æ³•æ¥å—å››ä¸ªè¾“å…¥å‚æ•°: éœ€è¦åˆ†è¯çš„å­—ç¬¦ä¸²ï¼›cut_all å‚æ•°ç”¨æ¥æ§åˆ¶æ˜¯å¦é‡‡ç”¨å…¨æ¨¡å¼ï¼›HMM å‚æ•°ç”¨æ¥æ§åˆ¶æ˜¯å¦ä½¿ç”¨ HMM æ¨¡å‹ï¼›use_paddle å‚æ•°ç”¨æ¥æ§åˆ¶æ˜¯å¦ä½¿ç”¨paddleæ¨¡å¼ä¸‹çš„åˆ†è¯æ¨¡å¼ï¼Œpaddleæ¨¡å¼é‡‡ç”¨å»¶è¿ŸåŠ è½½æ–¹å¼ï¼Œé€šè¿‡enable_paddleæ¥å£å®‰è£…paddlepaddle-tinyï¼Œå¹¶ä¸”importç›¸å…³ä»£ç ï¼›jieba.cut_for_search æ–¹æ³•æ¥å—ä¸¤ä¸ªå‚æ•°ï¼šéœ€è¦åˆ†è¯çš„å­—ç¬¦ä¸²ï¼›æ˜¯å¦ä½¿ç”¨ HMM æ¨¡å‹ã€‚è¯¥æ–¹æ³•é€‚åˆç”¨äºæœç´¢å¼•æ“æ„å»ºå€’æ’ç´¢å¼•çš„åˆ†è¯ï¼Œç²’åº¦æ¯”è¾ƒç»†å¾…åˆ†è¯çš„å­—ç¬¦ä¸²å¯ä»¥æ˜¯ unicode æˆ– UTF-8 å­—ç¬¦ä¸²ã€GBK å­—ç¬¦ä¸²ã€‚æ³¨æ„ï¼šä¸å»ºè®®ç›´æ¥è¾“å…¥ GBK å­—ç¬¦ä¸²ï¼Œå¯èƒ½æ— æ³•é¢„æ–™åœ°é”™è¯¯è§£ç æˆ UTF-8jieba.cut ä»¥åŠ jieba.cut_for_search è¿”å›çš„ç»“æ„éƒ½æ˜¯ä¸€ä¸ªå¯è¿­ä»£çš„ generatorï¼Œå¯ä»¥ä½¿ç”¨ for å¾ªç¯æ¥è·å¾—åˆ†è¯åå¾—åˆ°çš„æ¯ä¸€ä¸ªè¯è¯­(unicode)ï¼Œæˆ–è€…ç”¨jieba.lcut ä»¥åŠ jieba.lcut_for_search ç›´æ¥è¿”å› listjieba.Tokenizer(dictionary=DEFAULT_DICT) æ–°å»ºè‡ªå®šä¹‰åˆ†è¯å™¨ï¼Œå¯ç”¨äºåŒæ—¶ä½¿ç”¨ä¸åŒè¯å…¸ã€‚jieba.dt ä¸ºé»˜è®¤åˆ†è¯å™¨ï¼Œæ‰€æœ‰å…¨å±€åˆ†è¯ç›¸å…³å‡½æ•°éƒ½æ˜¯è¯¥åˆ†è¯å™¨çš„æ˜ å°„ã€‚ä»£ç ç¤ºä¾‹# encoding=utf-8import jiebajieba.enable_paddle()# å¯åŠ¨paddleæ¨¡å¼ã€‚ 0.40ç‰ˆä¹‹åå¼€å§‹æ”¯æŒï¼Œæ—©æœŸç‰ˆæœ¬ä¸æ”¯æŒstrs=[\""æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦\"",\""ä¹’ä¹“çƒæ‹å–å®Œäº†\"",\""ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦\""]for str in strs:    seg_list = jieba.cut(str,use_paddle=True) # ä½¿ç”¨paddleæ¨¡å¼    print(\""Paddle Mode: \"" + '/'.join(list(seg_list)))seg_list = jieba.cut(\""æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦\"", cut_all=True)print(\""Full Mode: \"" + \""/ \"".join(seg_list))  # å…¨æ¨¡å¼seg_list = jieba.cut(\""æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦\"", cut_all=False)print(\""Default Mode: \"" + \""/ \"".join(seg_list))  # ç²¾ç¡®æ¨¡å¼seg_list = jieba.cut(\""ä»–æ¥åˆ°äº†ç½‘æ˜“æ­ç ”å¤§å¦\"")  # é»˜è®¤æ˜¯ç²¾ç¡®æ¨¡å¼print(\"", \"".join(seg_list))seg_list = jieba.cut_for_search(\""å°æ˜ç¡•å£«æ¯•ä¸šäºä¸­å›½ç§‘å­¦é™¢è®¡ç®—æ‰€ï¼Œååœ¨æ—¥æœ¬äº¬éƒ½å¤§å­¦æ·±é€ \"")  # æœç´¢å¼•æ“æ¨¡å¼print(\"", \"".join(seg_list))è¾“å‡º:ã€å…¨æ¨¡å¼ã€‘: æˆ‘/ æ¥åˆ°/ åŒ—äº¬/ æ¸…å/ æ¸…åå¤§å­¦/ åå¤§/ å¤§å­¦ã€ç²¾ç¡®æ¨¡å¼ã€‘: æˆ‘/ æ¥åˆ°/ åŒ—äº¬/ æ¸…åå¤§å­¦ã€æ–°è¯è¯†åˆ«ã€‘ï¼šä»–, æ¥åˆ°, äº†, ç½‘æ˜“, æ­ç ”, å¤§å¦    (æ­¤å¤„ï¼Œâ€œæ­ç ”â€å¹¶æ²¡æœ‰åœ¨è¯å…¸ä¸­ï¼Œä½†æ˜¯ä¹Ÿè¢«Viterbiç®—æ³•è¯†åˆ«å‡ºæ¥äº†)ã€æœç´¢å¼•æ“æ¨¡å¼ã€‘ï¼š å°æ˜, ç¡•å£«, æ¯•ä¸š, äº, ä¸­å›½, ç§‘å­¦, å­¦é™¢, ç§‘å­¦é™¢, ä¸­å›½ç§‘å­¦é™¢, è®¡ç®—, è®¡ç®—æ‰€, å, åœ¨, æ—¥æœ¬, äº¬éƒ½, å¤§å­¦, æ—¥æœ¬äº¬éƒ½å¤§å­¦, æ·±é€ æ·»åŠ è‡ªå®šä¹‰è¯å…¸è½½å…¥è¯å…¸å¼€å‘è€…å¯ä»¥æŒ‡å®šè‡ªå·±è‡ªå®šä¹‰çš„è¯å…¸ï¼Œä»¥ä¾¿åŒ…å« jieba è¯åº“é‡Œæ²¡æœ‰çš„è¯ã€‚è™½ç„¶ jieba æœ‰æ–°è¯è¯†åˆ«èƒ½åŠ›ï¼Œä½†æ˜¯è‡ªè¡Œæ·»åŠ æ–°è¯å¯ä»¥ä¿è¯æ›´é«˜çš„æ­£ç¡®ç‡ç”¨æ³•ï¼š jieba.load_userdict(file_name) # file_name ä¸ºæ–‡ä»¶ç±»å¯¹è±¡æˆ–è‡ªå®šä¹‰è¯å…¸çš„è·¯å¾„è¯å…¸æ ¼å¼å’Œ dict.txt ä¸€æ ·ï¼Œä¸€ä¸ªè¯å ä¸€è¡Œï¼›æ¯ä¸€è¡Œåˆ†ä¸‰éƒ¨åˆ†ï¼šè¯è¯­ã€è¯é¢‘ï¼ˆå¯çœç•¥ï¼‰ã€è¯æ€§ï¼ˆå¯çœç•¥ï¼‰ï¼Œç”¨ç©ºæ ¼éš”å¼€ï¼Œé¡ºåºä¸å¯é¢ å€’ã€‚file_name è‹¥ä¸ºè·¯å¾„æˆ–äºŒè¿›åˆ¶æ–¹å¼æ‰“å¼€çš„æ–‡ä»¶ï¼Œåˆ™æ–‡ä»¶å¿…é¡»ä¸º UTF-8 ç¼–ç ã€‚è¯é¢‘çœç•¥æ—¶ä½¿ç”¨è‡ªåŠ¨è®¡ç®—çš„èƒ½ä¿è¯åˆ†å‡ºè¯¥è¯çš„è¯é¢‘ã€‚ä¾‹å¦‚ï¼šåˆ›æ–°åŠ 3 iäº‘è®¡ç®— 5å‡±ç‰¹ç³ nzå°ä¸­æ›´æ”¹åˆ†è¯å™¨ï¼ˆé»˜è®¤ä¸º jieba.dtï¼‰çš„ tmp_dir å’Œ cache_file å±æ€§ï¼Œå¯åˆ†åˆ«æŒ‡å®šç¼“å­˜æ–‡ä»¶æ‰€åœ¨çš„æ–‡ä»¶å¤¹åŠå…¶æ–‡ä»¶åï¼Œç”¨äºå—é™çš„æ–‡ä»¶ç³»ç»Ÿã€‚èŒƒä¾‹ï¼šè‡ªå®šä¹‰è¯å…¸ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/userdict.txtç”¨æ³•ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/test_userdict.pyä¹‹å‰ï¼š æå°ç¦ / æ˜¯ / åˆ›æ–° / åŠ / ä¸»ä»» / ä¹Ÿ / æ˜¯ / äº‘ / è®¡ç®— / æ–¹é¢ / çš„ / ä¸“å®¶ /åŠ è½½è‡ªå®šä¹‰è¯åº“åï¼šã€€æå°ç¦ / æ˜¯ / åˆ›æ–°åŠ / ä¸»ä»» / ä¹Ÿ / æ˜¯ / äº‘è®¡ç®— / æ–¹é¢ / çš„ / ä¸“å®¶ /è°ƒæ•´è¯å…¸ä½¿ç”¨ add_word(word, freq=None, tag=None) å’Œ del_word(word) å¯åœ¨ç¨‹åºä¸­åŠ¨æ€ä¿®æ”¹è¯å…¸ã€‚ä½¿ç”¨ suggest_freq(segment, tune=True) å¯è°ƒèŠ‚å•ä¸ªè¯è¯­çš„è¯é¢‘ï¼Œä½¿å…¶èƒ½ï¼ˆæˆ–ä¸èƒ½ï¼‰è¢«åˆ†å‡ºæ¥ã€‚æ³¨æ„ï¼šè‡ªåŠ¨è®¡ç®—çš„è¯é¢‘åœ¨ä½¿ç”¨ HMM æ–°è¯å‘ç°åŠŸèƒ½æ—¶å¯èƒ½æ— æ•ˆã€‚ä»£ç ç¤ºä¾‹ï¼š>>> print('/'.join(jieba.cut('å¦‚æœæ”¾åˆ°postä¸­å°†å‡ºé”™ã€‚', HMM=False)))å¦‚æœ/æ”¾åˆ°/post/ä¸­å°†/å‡ºé”™/ã€‚>>> jieba.suggest_freq(('ä¸­', 'å°†'), True)494>>> print('/'.join(jieba.cut('å¦‚æœæ”¾åˆ°postä¸­å°†å‡ºé”™ã€‚', HMM=False)))å¦‚æœ/æ”¾åˆ°/post/ä¸­/å°†/å‡ºé”™/ã€‚>>> print('/'.join(jieba.cut('ã€Œå°ä¸­ã€æ­£ç¡®åº”è¯¥ä¸ä¼šè¢«åˆ‡å¼€', HMM=False)))ã€Œ/å°/ä¸­/ã€/æ­£ç¡®/åº”è¯¥/ä¸ä¼š/è¢«/åˆ‡å¼€>>> jieba.suggest_freq('å°ä¸­', True)69>>> print('/'.join(jieba.cut('ã€Œå°ä¸­ã€æ­£ç¡®åº”è¯¥ä¸ä¼šè¢«åˆ‡å¼€', HMM=False)))ã€Œ/å°ä¸­/ã€/æ­£ç¡®/åº”è¯¥/ä¸ä¼š/è¢«/åˆ‡å¼€\""é€šè¿‡ç”¨æˆ·è‡ªå®šä¹‰è¯å…¸æ¥å¢å¼ºæ­§ä¹‰çº é”™èƒ½åŠ›\"" --- #14å…³é”®è¯æå–åŸºäº TF-IDF ç®—æ³•çš„å…³é”®è¯æŠ½å–import jieba.analysejieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())sentence ä¸ºå¾…æå–çš„æ–‡æœ¬topK ä¸ºè¿”å›å‡ ä¸ª TF/IDF æƒé‡æœ€å¤§çš„å…³é”®è¯ï¼Œé»˜è®¤å€¼ä¸º 20withWeight ä¸ºæ˜¯å¦ä¸€å¹¶è¿”å›å…³é”®è¯æƒé‡å€¼ï¼Œé»˜è®¤å€¼ä¸º FalseallowPOS ä»…åŒ…æ‹¬æŒ‡å®šè¯æ€§çš„è¯ï¼Œé»˜è®¤å€¼ä¸ºç©ºï¼Œå³ä¸ç­›é€‰jieba.analyse.TFIDF(idf_path=None) æ–°å»º TFIDF å®ä¾‹ï¼Œidf_path ä¸º IDF é¢‘ç‡æ–‡ä»¶ä»£ç ç¤ºä¾‹ ï¼ˆå…³é”®è¯æå–ï¼‰https://github.com/fxsjy/jieba/blob/master/test/extract_tags.pyå…³é”®è¯æå–æ‰€ä½¿ç”¨é€†å‘æ–‡ä»¶é¢‘ç‡ï¼ˆIDFï¼‰æ–‡æœ¬è¯­æ–™åº“å¯ä»¥åˆ‡æ¢æˆè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„ç”¨æ³•ï¼š jieba.analyse.set_idf_path(file_name) # file_nameä¸ºè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„è‡ªå®šä¹‰è¯­æ–™åº“ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.bigç”¨æ³•ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.pyå…³é”®è¯æå–æ‰€ä½¿ç”¨åœæ­¢è¯ï¼ˆStop Wordsï¼‰æ–‡æœ¬è¯­æ–™åº“å¯ä»¥åˆ‡æ¢æˆè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„ç”¨æ³•ï¼š jieba.analyse.set_stop_words(file_name) # file_nameä¸ºè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„è‡ªå®šä¹‰è¯­æ–™åº“ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txtç”¨æ³•ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.pyå…³é”®è¯ä¸€å¹¶è¿”å›å…³é”®è¯æƒé‡å€¼ç¤ºä¾‹ç”¨æ³•ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.pyåŸºäº TextRank ç®—æ³•çš„å…³é”®è¯æŠ½å–jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) ç›´æ¥ä½¿ç”¨ï¼Œæ¥å£ç›¸åŒï¼Œæ³¨æ„é»˜è®¤è¿‡æ»¤è¯æ€§ã€‚jieba.analyse.TextRank() æ–°å»ºè‡ªå®šä¹‰ TextRank å®ä¾‹ç®—æ³•è®ºæ–‡ï¼š TextRank: Bringing Order into TextsåŸºæœ¬æ€æƒ³:å°†å¾…æŠ½å–å…³é”®è¯çš„æ–‡æœ¬è¿›è¡Œåˆ†è¯ä»¥å›ºå®šçª—å£å¤§å°(é»˜è®¤ä¸º5ï¼Œé€šè¿‡spanå±æ€§è°ƒæ•´)ï¼Œè¯ä¹‹é—´çš„å…±ç°å…³ç³»ï¼Œæ„å»ºå›¾è®¡ç®—å›¾ä¸­èŠ‚ç‚¹çš„PageRankï¼Œæ³¨æ„æ˜¯æ— å‘å¸¦æƒå›¾ä½¿ç”¨ç¤ºä¾‹:è§ test/demo.pyè¯æ€§æ ‡æ³¨jieba.posseg.POSTokenizer(tokenizer=None) æ–°å»ºè‡ªå®šä¹‰åˆ†è¯å™¨ï¼Œtokenizer å‚æ•°å¯æŒ‡å®šå†…éƒ¨ä½¿ç”¨çš„ jieba.Tokenizer åˆ†è¯å™¨ã€‚jieba.posseg.dt ä¸ºé»˜è®¤è¯æ€§æ ‡æ³¨åˆ†è¯å™¨ã€‚æ ‡æ³¨å¥å­åˆ†è¯åæ¯ä¸ªè¯çš„è¯æ€§ï¼Œé‡‡ç”¨å’Œ ictclas å…¼å®¹çš„æ ‡è®°æ³•ã€‚é™¤äº†jiebaé»˜è®¤åˆ†è¯æ¨¡å¼ï¼Œæä¾›paddleæ¨¡å¼ä¸‹çš„è¯æ€§æ ‡æ³¨åŠŸèƒ½ã€‚paddleæ¨¡å¼é‡‡ç”¨å»¶è¿ŸåŠ è½½æ–¹å¼ï¼Œé€šè¿‡enable_paddle()å®‰è£…paddlepaddle-tinyï¼Œå¹¶ä¸”importç›¸å…³ä»£ç ï¼›ç”¨æ³•ç¤ºä¾‹>>> import jieba>>> import jieba.posseg as pseg>>> words = pseg.cut(\""æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨\"") #jiebaé»˜è®¤æ¨¡å¼>>> jieba.enable_paddle() #å¯åŠ¨paddleæ¨¡å¼ã€‚ 0.40ç‰ˆä¹‹åå¼€å§‹æ”¯æŒï¼Œæ—©æœŸç‰ˆæœ¬ä¸æ”¯æŒ>>> words = pseg.cut(\""æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨\"",use_paddle=True) #paddleæ¨¡å¼>>> for word, flag in words:...    print('%s %s' % (word, flag))...æˆ‘ rçˆ± våŒ—äº¬ nså¤©å®‰é—¨ nspaddleæ¨¡å¼è¯æ€§æ ‡æ³¨å¯¹åº”è¡¨å¦‚ä¸‹ï¼špaddleæ¨¡å¼è¯æ€§å’Œä¸“åç±»åˆ«æ ‡ç­¾é›†åˆå¦‚ä¸‹è¡¨ï¼Œå…¶ä¸­è¯æ€§æ ‡ç­¾ 24 ä¸ªï¼ˆå°å†™å­—æ¯ï¼‰ï¼Œä¸“åç±»åˆ«æ ‡ç­¾ 4 ä¸ªï¼ˆå¤§å†™å­—æ¯ï¼‰ã€‚æ ‡ç­¾å«ä¹‰æ ‡ç­¾å«ä¹‰æ ‡ç­¾å«ä¹‰æ ‡ç­¾å«ä¹‰næ™®é€šåè¯fæ–¹ä½åè¯så¤„æ‰€åè¯tæ—¶é—´nräººånsåœ°åntæœºæ„ånwä½œå“ånzå…¶ä»–ä¸“åvæ™®é€šåŠ¨è¯vdåŠ¨å‰¯è¯vnååŠ¨è¯aå½¢å®¹è¯adå‰¯å½¢è¯anåå½¢è¯då‰¯è¯mæ•°é‡è¯qé‡è¯rä»£è¯pä»‹è¯cè¿è¯uåŠ©è¯xcå…¶ä»–è™šè¯wæ ‡ç‚¹ç¬¦å·PERäººåLOCåœ°åORGæœºæ„åTIMEæ—¶é—´å¹¶è¡Œåˆ†è¯åŸç†ï¼šå°†ç›®æ ‡æ–‡æœ¬æŒ‰è¡Œåˆ†éš”åï¼ŒæŠŠå„è¡Œæ–‡æœ¬åˆ†é…åˆ°å¤šä¸ª Python è¿›ç¨‹å¹¶è¡Œåˆ†è¯ï¼Œç„¶åå½’å¹¶ç»“æœï¼Œä»è€Œè·å¾—åˆ†è¯é€Ÿåº¦çš„å¯è§‚æå‡åŸºäº python è‡ªå¸¦çš„ multiprocessing æ¨¡å—ï¼Œç›®å‰æš‚ä¸æ”¯æŒ Windowsç”¨æ³•ï¼šjieba.enable_parallel(4) # å¼€å¯å¹¶è¡Œåˆ†è¯æ¨¡å¼ï¼Œå‚æ•°ä¸ºå¹¶è¡Œè¿›ç¨‹æ•°jieba.disable_parallel() # å…³é—­å¹¶è¡Œåˆ†è¯æ¨¡å¼ä¾‹å­ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.pyå®éªŒç»“æœï¼šåœ¨ 4 æ ¸ 3.4GHz Linux æœºå™¨ä¸Šï¼Œå¯¹é‡‘åº¸å…¨é›†è¿›è¡Œç²¾ç¡®åˆ†è¯ï¼Œè·å¾—äº† 1MB/s çš„é€Ÿåº¦ï¼Œæ˜¯å•è¿›ç¨‹ç‰ˆçš„ 3.3 å€ã€‚æ³¨æ„ï¼šå¹¶è¡Œåˆ†è¯ä»…æ”¯æŒé»˜è®¤åˆ†è¯å™¨ jieba.dt å’Œ jieba.posseg.dtã€‚Tokenizeï¼šè¿”å›è¯è¯­åœ¨åŸæ–‡çš„èµ·æ­¢ä½ç½®æ³¨æ„ï¼Œè¾“å…¥å‚æ•°åªæ¥å— unicodeé»˜è®¤æ¨¡å¼result = jieba.tokenize(u'æ°¸å’Œæœè£…é¥°å“æœ‰é™å…¬å¸')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word æ°¸å’Œ                start: 0                end:2word æœè£…                start: 2                end:4word é¥°å“                start: 4                end:6word æœ‰é™å…¬å¸            start: 6                end:10æœç´¢æ¨¡å¼result = jieba.tokenize(u'æ°¸å’Œæœè£…é¥°å“æœ‰é™å…¬å¸', mode='search')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word æ°¸å’Œ                start: 0                end:2word æœè£…                start: 2                end:4word é¥°å“                start: 4                end:6word æœ‰é™                start: 6                end:8word å…¬å¸                start: 8                end:10word æœ‰é™å…¬å¸            start: 6                end:10ChineseAnalyzer for Whoosh æœç´¢å¼•æ“å¼•ç”¨ï¼š from jieba.analyse import ChineseAnalyzerç”¨æ³•ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/test_whoosh.pyå‘½ä»¤è¡Œåˆ†è¯ä½¿ç”¨ç¤ºä¾‹ï¼špython -m jieba news.txt > cut_result.txtå‘½ä»¤è¡Œé€‰é¡¹ï¼ˆç¿»è¯‘ï¼‰ï¼šä½¿ç”¨: python -m jieba [options] filenameç»“å·´å‘½ä»¤è¡Œç•Œé¢ã€‚å›ºå®šå‚æ•°:  filename              è¾“å…¥æ–‡ä»¶å¯é€‰å‚æ•°:  -h, --help            æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º  -d [DELIM], --delimiter [DELIM]                        ä½¿ç”¨ DELIM åˆ†éš”è¯è¯­ï¼Œè€Œä¸æ˜¯ç”¨é»˜è®¤çš„' / 'ã€‚                        è‹¥ä¸æŒ‡å®š DELIMï¼Œåˆ™ä½¿ç”¨ä¸€ä¸ªç©ºæ ¼åˆ†éš”ã€‚  -p [DELIM], --pos [DELIM]                        å¯ç”¨è¯æ€§æ ‡æ³¨ï¼›å¦‚æœæŒ‡å®š DELIMï¼Œè¯è¯­å’Œè¯æ€§ä¹‹é—´                        ç”¨å®ƒåˆ†éš”ï¼Œå¦åˆ™ç”¨ _ åˆ†éš”  -D DICT, --dict DICT  ä½¿ç”¨ DICT ä»£æ›¿é»˜è®¤è¯å…¸  -u USER_DICT, --user-dict USER_DICT                        ä½¿ç”¨ USER_DICT ä½œä¸ºé™„åŠ è¯å…¸ï¼Œä¸é»˜è®¤è¯å…¸æˆ–è‡ªå®šä¹‰è¯å…¸é…åˆä½¿ç”¨  -a, --cut-all         å…¨æ¨¡å¼åˆ†è¯ï¼ˆä¸æ”¯æŒè¯æ€§æ ‡æ³¨ï¼‰  -n, --no-hmm          ä¸ä½¿ç”¨éšå«é©¬å°”å¯å¤«æ¨¡å‹  -q, --quiet           ä¸è¾“å‡ºè½½å…¥ä¿¡æ¯åˆ° STDERR  -V, --version         æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯å¹¶é€€å‡ºå¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶åï¼Œåˆ™ä½¿ç”¨æ ‡å‡†è¾“å…¥ã€‚--help é€‰é¡¹è¾“å‡ºï¼š$> python -m jieba --helpJieba command line interface.positional arguments:  filename              input fileoptional arguments:  -h, --help            show this help message and exit  -d [DELIM], --delimiter [DELIM]                        use DELIM instead of ' / ' for word delimiter; or a                        space if it is used without DELIM  -p [DELIM], --pos [DELIM]                        enable POS tagging; if DELIM is specified, use DELIM                        instead of '_' for POS delimiter  -D DICT, --dict DICT  use DICT as dictionary  -u USER_DICT, --user-dict USER_DICT                        use USER_DICT together with the default dictionary or                        DICT (if specified)  -a, --cut-all         full pattern cutting (ignored with POS tagging)  -n, --no-hmm          don't use the Hidden Markov Model  -q, --quiet           don't print loading messages to stderr  -V, --version         show program's version number and exitIf no filename specified, use STDIN instead.å»¶è¿ŸåŠ è½½æœºåˆ¶jieba é‡‡ç”¨å»¶è¿ŸåŠ è½½ï¼Œimport jieba å’Œ jieba.Tokenizer() ä¸ä¼šç«‹å³è§¦å‘è¯å…¸çš„åŠ è½½ï¼Œä¸€æ—¦æœ‰å¿…è¦æ‰å¼€å§‹åŠ è½½è¯å…¸æ„å»ºå‰ç¼€å­—å…¸ã€‚å¦‚æœä½ æƒ³æ‰‹å·¥åˆå§‹ jiebaï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨åˆå§‹åŒ–ã€‚import jiebajieba.initialize()  # æ‰‹åŠ¨åˆå§‹åŒ–ï¼ˆå¯é€‰ï¼‰åœ¨ 0.28 ä¹‹å‰çš„ç‰ˆæœ¬æ˜¯ä¸èƒ½æŒ‡å®šä¸»è¯å…¸çš„è·¯å¾„çš„ï¼Œæœ‰äº†å»¶è¿ŸåŠ è½½æœºåˆ¶åï¼Œä½ å¯ä»¥æ”¹å˜ä¸»è¯å…¸çš„è·¯å¾„:jieba.set_dictionary('data/dict.txt.big')ä¾‹å­ï¼š https://github.com/fxsjy/jieba/blob/master/test/test_change_dictpath.pyå…¶ä»–è¯å…¸å ç”¨å†…å­˜è¾ƒå°çš„è¯å…¸æ–‡ä»¶https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.smallæ”¯æŒç¹ä½“åˆ†è¯æ›´å¥½çš„è¯å…¸æ–‡ä»¶https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.bigä¸‹è½½ä½ æ‰€éœ€è¦çš„è¯å…¸ï¼Œç„¶åè¦†ç›– jieba/dict.txt å³å¯ï¼›æˆ–è€…ç”¨ jieba.set_dictionary('data/dict.txt.big')å…¶ä»–è¯­è¨€å®ç°ç»“å·´åˆ†è¯ Java ç‰ˆæœ¬ä½œè€…ï¼špiaolingxueåœ°å€ï¼šhttps://github.com/huaban/jieba-analysisç»“å·´åˆ†è¯ C++ ç‰ˆæœ¬ä½œè€…ï¼šyanyiwuåœ°å€ï¼šhttps://github.com/yanyiwu/cppjiebaç»“å·´åˆ†è¯ Rust ç‰ˆæœ¬ä½œè€…ï¼šmessense, MnO2åœ°å€ï¼šhttps://github.com/messense/jieba-rsç»“å·´åˆ†è¯ Node.js ç‰ˆæœ¬ä½œè€…ï¼šyanyiwuåœ°å€ï¼šhttps://github.com/yanyiwu/nodejiebaç»“å·´åˆ†è¯ Erlang ç‰ˆæœ¬ä½œè€…ï¼šfaloodåœ°å€ï¼šhttps://github.com/falood/exjiebaç»“å·´åˆ†è¯ R ç‰ˆæœ¬ä½œè€…ï¼šqinwfåœ°å€ï¼šhttps://github.com/qinwf/jiebaRç»“å·´åˆ†è¯ iOS ç‰ˆæœ¬ä½œè€…ï¼šyanyiwuåœ°å€ï¼šhttps://github.com/yanyiwu/iosjiebaç»“å·´åˆ†è¯ PHP ç‰ˆæœ¬ä½œè€…ï¼šfukuballåœ°å€ï¼šhttps://github.com/fukuball/jieba-phpç»“å·´åˆ†è¯ .NET(C#) ç‰ˆæœ¬ä½œè€…ï¼šanderscuiåœ°å€ï¼šhttps://github.com/anderscui/jieba.NET/ç»“å·´åˆ†è¯ Go ç‰ˆæœ¬ä½œè€…: wangbin åœ°å€: https://github.com/wangbin/jiebagoä½œè€…: yanyiwu åœ°å€: https://github.com/yanyiwu/gojiebaç»“å·´åˆ†è¯Androidç‰ˆæœ¬ä½œè€…   Dongliang.W  åœ°å€ï¼šhttps://github.com/452896915/jieba-androidå‹æƒ…é“¾æ¥https://github.com/baidu/lac   ç™¾åº¦ä¸­æ–‡è¯æ³•åˆ†æï¼ˆåˆ†è¯+è¯æ€§+ä¸“åï¼‰ç³»ç»Ÿhttps://github.com/baidu/AnyQ  ç™¾åº¦FAQè‡ªåŠ¨é—®ç­”ç³»ç»Ÿhttps://github.com/baidu/Senta ç™¾åº¦æƒ…æ„Ÿè¯†åˆ«ç³»ç»Ÿç³»ç»Ÿé›†æˆSolr: https://github.com/sing1ee/jieba-solråˆ†è¯é€Ÿåº¦1.5 MB / Second in Full Mode400 KB / Second in Default Modeæµ‹è¯•ç¯å¢ƒ: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHzï¼›ã€Šå›´åŸã€‹.txtå¸¸è§é—®é¢˜1. æ¨¡å‹çš„æ•°æ®æ˜¯å¦‚ä½•ç”Ÿæˆçš„ï¼Ÿè¯¦è§ï¼š #72. â€œå°ä¸­â€æ€»æ˜¯è¢«åˆ‡æˆâ€œå° ä¸­â€ï¼Ÿï¼ˆä»¥åŠç±»ä¼¼æƒ…å†µï¼‰P(å°ä¸­) ï¼œ P(å°)Ã—P(ä¸­)ï¼Œâ€œå°ä¸­â€è¯é¢‘ä¸å¤Ÿå¯¼è‡´å…¶æˆè¯æ¦‚ç‡è¾ƒä½è§£å†³æ–¹æ³•ï¼šå¼ºåˆ¶è°ƒé«˜è¯é¢‘jieba.add_word('å°ä¸­') æˆ–è€… jieba.suggest_freq('å°ä¸­', True)3. â€œä»Šå¤©å¤©æ°” ä¸é”™â€åº”è¯¥è¢«åˆ‡æˆâ€œä»Šå¤© å¤©æ°” ä¸é”™â€ï¼Ÿï¼ˆä»¥åŠç±»ä¼¼æƒ…å†µï¼‰è§£å†³æ–¹æ³•ï¼šå¼ºåˆ¶è°ƒä½è¯é¢‘jieba.suggest_freq(('ä»Šå¤©', 'å¤©æ°”'), True)æˆ–è€…ç›´æ¥åˆ é™¤è¯¥è¯ jieba.del_word('ä»Šå¤©å¤©æ°”')4. åˆ‡å‡ºäº†è¯å…¸ä¸­æ²¡æœ‰çš„è¯è¯­ï¼Œæ•ˆæœä¸ç†æƒ³ï¼Ÿè§£å†³æ–¹æ³•ï¼šå…³é—­æ–°è¯å‘ç°jieba.cut('ä¸°ç”°å¤ªçœäº†', HMM=False)jieba.cut('æˆ‘ä»¬ä¸­å‡ºäº†ä¸€ä¸ªå›å¾’', HMM=False)æ›´å¤šé—®é¢˜è¯·ç‚¹å‡»ï¼šhttps://github.com/fxsjy/jieba/issues?sort=updated&state=closedä¿®è®¢å†å²https://github.com/fxsjy/jieba/blob/master/Changelogjieba\""Jieba\"" (Chinese for \""to stutter\"") Chinese text segmentation: built to be the best Python Chinese word segmentation module.FeaturesSupport three types of segmentation mode:Accurate Mode attempts to cut the sentence into the most accurate segmentations, which is suitable for text analysis.Full Mode gets all the possible words from the sentence. Fast but not accurate.Search Engine Mode, based on the Accurate Mode, attempts to cut long words into several short words, which can raise the recall rate. Suitable for search engines.Supports Traditional ChineseSupports customized dictionariesMIT LicenseOnline demohttp://jiebademo.ap01.aws.af.cm/(Powered by Appfog)UsageFully automatic installation: easy_install jieba or pip install jiebaSemi-automatic installation: Download http://pypi.python.org/pypi/jieba/ , run python setup.py install after extracting.Manual installation: place the jieba directory in the current directory or python site-packages directory.import jieba.AlgorithmBased on a prefix dictionary structure to achieve efficient word graph scanning. Build a directed acyclic graph (DAG) for all possible word combinations.Use dynamic programming to find the most probable combination based on the word frequency.For unknown words, a HMM-based model is used with the Viterbi algorithm.Main FunctionsCutThe jieba.cut function accepts three input parameters: the first parameter is the string to be cut; the second parameter is cut_all, controlling the cut mode; the third parameter is to control whether to use the Hidden Markov Model.jieba.cut_for_search accepts two parameter: the string to be cut; whether to use the Hidden Markov Model. This will cut the sentence into short words suitable for search engines.The input string can be an unicode/str object, or a str/bytes object which is encoded in UTF-8 or GBK. Note that using GBK encoding is not recommended because it may be unexpectly decoded as UTF-8.jieba.cut and jieba.cut_for_search returns an generator, from which you can use a for loop to get the segmentation result (in unicode).jieba.lcut and jieba.lcut_for_search returns a list.jieba.Tokenizer(dictionary=DEFAULT_DICT) creates a new customized Tokenizer, which enables you to use different dictionaries at the same time. jieba.dt is the default Tokenizer, to which almost all global functions are mapped.Code example: segmentation#encoding=utf-8import jiebaseg_list = jieba.cut(\""æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦\"", cut_all=True)print(\""Full Mode: \"" + \""/ \"".join(seg_list))  # å…¨æ¨¡å¼seg_list = jieba.cut(\""æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦\"", cut_all=False)print(\""Default Mode: \"" + \""/ \"".join(seg_list))  # é»˜è®¤æ¨¡å¼seg_list = jieba.cut(\""ä»–æ¥åˆ°äº†ç½‘æ˜“æ­ç ”å¤§å¦\"")print(\"", \"".join(seg_list))seg_list = jieba.cut_for_search(\""å°æ˜ç¡•å£«æ¯•ä¸šäºä¸­å›½ç§‘å­¦é™¢è®¡ç®—æ‰€ï¼Œååœ¨æ—¥æœ¬äº¬éƒ½å¤§å­¦æ·±é€ \"")  # æœç´¢å¼•æ“æ¨¡å¼print(\"", \"".join(seg_list))Output:[Full Mode]: æˆ‘/ æ¥åˆ°/ åŒ—äº¬/ æ¸…å/ æ¸…åå¤§å­¦/ åå¤§/ å¤§å­¦[Accurate Mode]: æˆ‘/ æ¥åˆ°/ åŒ—äº¬/ æ¸…åå¤§å­¦[Unknown Words Recognize] ä»–, æ¥åˆ°, äº†, ç½‘æ˜“, æ­ç ”, å¤§å¦    (In this case, \""æ­ç ”\"" is not in the dictionary, but is identified by the Viterbi algorithm)[Search Engine Mode]ï¼š å°æ˜, ç¡•å£«, æ¯•ä¸š, äº, ä¸­å›½, ç§‘å­¦, å­¦é™¢, ç§‘å­¦é™¢, ä¸­å›½ç§‘å­¦é™¢, è®¡ç®—, è®¡ç®—æ‰€, å, åœ¨, æ—¥æœ¬, äº¬éƒ½, å¤§å­¦, æ—¥æœ¬äº¬éƒ½å¤§å­¦, æ·±é€ Add a custom dictionaryLoad dictionaryDevelopers can specify their own custom dictionary to be included in the jieba default dictionary. Jieba is able to identify new words, but you can add your own new words can ensure a higher accuracy.Usageï¼š jieba.load_userdict(file_name) # file_name is a file-like object or the path of the custom dictionaryThe dictionary format is the same as that of dict.txt: one word per line; each line is divided into three parts separated by a space: word, word frequency, POS tag. If file_name is a path or a file opened in binary mode, the dictionary must be UTF-8 encoded.The word frequency and POS tag can be omitted respectively. The word frequency will be filled with a suitable value if omitted.For example:åˆ›æ–°åŠ 3 iäº‘è®¡ç®— 5å‡±ç‰¹ç³ nzå°ä¸­Change a Tokenizer's tmp_dir and cache_file to specify the path of the cache file, for using on a restricted file system.Example:  äº‘è®¡ç®— 5  æå°ç¦ 2  åˆ›æ–°åŠ 3  [Before]ï¼š æå°ç¦ / æ˜¯ / åˆ›æ–° / åŠ / ä¸»ä»» / ä¹Ÿ / æ˜¯ / äº‘ / è®¡ç®— / æ–¹é¢ / çš„ / ä¸“å®¶ /  [After]ï¼šã€€æå°ç¦ / æ˜¯ / åˆ›æ–°åŠ / ä¸»ä»» / ä¹Ÿ / æ˜¯ / äº‘è®¡ç®— / æ–¹é¢ / çš„ / ä¸“å®¶ /Modify dictionaryUse add_word(word, freq=None, tag=None) and del_word(word) to modify the dictionary dynamically in programs.Use suggest_freq(segment, tune=True) to adjust the frequency of a single word so that it can (or cannot) be segmented.Note that HMM may affect the final result.Example:>>> print('/'.join(jieba.cut('å¦‚æœæ”¾åˆ°postä¸­å°†å‡ºé”™ã€‚', HMM=False)))å¦‚æœ/æ”¾åˆ°/post/ä¸­å°†/å‡ºé”™/ã€‚>>> jieba.suggest_freq(('ä¸­', 'å°†'), True)494>>> print('/'.join(jieba.cut('å¦‚æœæ”¾åˆ°postä¸­å°†å‡ºé”™ã€‚', HMM=False)))å¦‚æœ/æ”¾åˆ°/post/ä¸­/å°†/å‡ºé”™/ã€‚>>> print('/'.join(jieba.cut('ã€Œå°ä¸­ã€æ­£ç¡®åº”è¯¥ä¸ä¼šè¢«åˆ‡å¼€', HMM=False)))ã€Œ/å°/ä¸­/ã€/æ­£ç¡®/åº”è¯¥/ä¸ä¼š/è¢«/åˆ‡å¼€>>> jieba.suggest_freq('å°ä¸­', True)69>>> print('/'.join(jieba.cut('ã€Œå°ä¸­ã€æ­£ç¡®åº”è¯¥ä¸ä¼šè¢«åˆ‡å¼€', HMM=False)))ã€Œ/å°ä¸­/ã€/æ­£ç¡®/åº”è¯¥/ä¸ä¼š/è¢«/åˆ‡å¼€Keyword Extractionimport jieba.analysejieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())sentence: the text to be extractedtopK: return how many keywords with the highest TF/IDF weights. The default value is 20withWeight: whether return TF/IDF weights with the keywords. The default value is FalseallowPOS: filter words with which POSs are included. Empty for no filtering.jieba.analyse.TFIDF(idf_path=None) creates a new TFIDF instance, idf_path specifies IDF file path.Example (keyword extraction)https://github.com/fxsjy/jieba/blob/master/test/extract_tags.pyDevelopers can specify their own custom IDF corpus in jieba keyword extractionUsageï¼š jieba.analyse.set_idf_path(file_name) # file_name is the path for the custom corpusCustom Corpus Sampleï¼šhttps://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.bigSample Codeï¼šhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.pyDevelopers can specify their own custom stop words corpus in jieba keyword extractionUsageï¼š jieba.analyse.set_stop_words(file_name) # file_name is the path for the custom corpusCustom Corpus Sampleï¼šhttps://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txtSample Codeï¼šhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.pyThere's also a TextRank implementation available.Use: jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))Note that it filters POS by default.jieba.analyse.TextRank() creates a new TextRank instance.Part of Speech Taggingjieba.posseg.POSTokenizer(tokenizer=None) creates a new customized Tokenizer. tokenizer specifies the jieba.Tokenizer to internally use. jieba.posseg.dt is the default POSTokenizer.Tags the POS of each word after segmentation, using labels compatible with ictclas.Example:>>> import jieba.posseg as pseg>>> words = pseg.cut(\""æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨\"")>>> for w in words:...    print('%s %s' % (w.word, w.flag))...æˆ‘ rçˆ± våŒ—äº¬ nså¤©å®‰é—¨ nsParallel ProcessingPrinciple: Split target text by line, assign the lines into multiple Python processes, and then merge the results, which is considerably faster.Based on the multiprocessing module of Python.Usage:jieba.enable_parallel(4) # Enable parallel processing. The parameter is the number of processes.jieba.disable_parallel() # Disable parallel processing.Example:https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.pyResult: On a four-core 3.4GHz Linux machine, do accurate word segmentation on Complete Works of Jin Yong, and the speed reaches 1MB/s, which is 3.3 times faster than the single-process version.Note that parallel processing supports only default tokenizers, jieba.dt and jieba.posseg.dt.Tokenize: return words with positionThe input must be unicodeDefault moderesult = jieba.tokenize(u'æ°¸å’Œæœè£…é¥°å“æœ‰é™å…¬å¸')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word æ°¸å’Œ                start: 0                end:2word æœè£…                start: 2                end:4word é¥°å“                start: 4                end:6word æœ‰é™å…¬å¸            start: 6                end:10Search moderesult = jieba.tokenize(u'æ°¸å’Œæœè£…é¥°å“æœ‰é™å…¬å¸',mode='search')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word æ°¸å’Œ                start: 0                end:2word æœè£…                start: 2                end:4word é¥°å“                start: 4                end:6word æœ‰é™                start: 6                end:8word å…¬å¸                start: 8                end:10word æœ‰é™å…¬å¸            start: 6                end:10ChineseAnalyzer for Whooshfrom jieba.analyse import ChineseAnalyzerExample: https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.pyCommand Line Interface$> python -m jieba --helpJieba command line interface.positional arguments:  filename              input fileoptional arguments:  -h, --help            show this help message and exit  -d [DELIM], --delimiter [DELIM]                        use DELIM instead of ' / ' for word delimiter; or a                        space if it is used without DELIM  -p [DELIM], --pos [DELIM]                        enable POS tagging; if DELIM is specified, use DELIM                        instead of '_' for POS delimiter  -D DICT, --dict DICT  use DICT as dictionary  -u USER_DICT, --user-dict USER_DICT                        use USER_DICT together with the default dictionary or                        DICT (if specified)  -a, --cut-all         full pattern cutting (ignored with POS tagging)  -n, --no-hmm          don't use the Hidden Markov Model  -q, --quiet           don't print loading messages to stderr  -V, --version         show program's version number and exitIf no filename specified, use STDIN instead.InitializationBy default, Jieba don't build the prefix dictionary unless it's necessary. This takes 1-3 seconds, after which it is not initialized again. If you want to initialize Jieba manually, you can call:import jiebajieba.initialize()  # (optional)You can also specify the dictionary (not supported before version 0.28) :jieba.set_dictionary('data/dict.txt.big')Using Other DictionariesIt is possible to use your own dictionary with Jieba, and there are also two dictionaries ready for download:A smaller dictionary for a smaller memory footprint:https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.smallThere is also a bigger dictionary that has better support for traditional Chinese (ç¹é«”):https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.bigBy default, an in-between dictionary is used, called dict.txt and included in the distribution.In either case, download the file you want, and then call jieba.set_dictionary('data/dict.txt.big') or just replace the existing dict.txt.Segmentation speed1.5 MB / Second in Full Mode400 KB / Second in Default ModeTest Env: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHzï¼›ã€Šå›´åŸã€‹.txt"
37,PaddlePaddle/PaddleOCR,https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/README.md,Python,"English | ç®€ä½“ä¸­æ–‡ | à¤¹à¤¿à¤¨à¥à¤¦à¥€ | æ—¥æœ¬èª | í•œêµ­ì¸ | PÑƒÌÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹ÌĞº                             ç®€ä»‹PaddleOCRæ—¨åœ¨æ‰“é€ ä¸€å¥—ä¸°å¯Œã€é¢†å…ˆã€ä¸”å®ç”¨çš„OCRå·¥å…·åº“ï¼ŒåŠ©åŠ›å¼€å‘è€…è®­ç»ƒå‡ºæ›´å¥½çš„æ¨¡å‹ï¼Œå¹¶åº”ç”¨è½åœ°ã€‚        ğŸ“£ è¿‘æœŸæ›´æ–°ğŸ”¥2023.8.7 å‘å¸ƒ PaddleOCR release/2.7å‘å¸ƒPP-OCRv4ï¼Œæä¾›mobileå’Œserverä¸¤ç§æ¨¡å‹PP-OCRv4-mobileï¼šé€Ÿåº¦å¯æ¯”æƒ…å†µä¸‹ï¼Œä¸­æ–‡åœºæ™¯æ•ˆæœç›¸æ¯”äºPP-OCRv3å†æå‡4.5%ï¼Œè‹±æ–‡åœºæ™¯æå‡10%ï¼Œ80è¯­ç§å¤šè¯­è¨€æ¨¡å‹å¹³å‡è¯†åˆ«å‡†ç¡®ç‡æå‡8%ä»¥ä¸ŠPP-OCRv4-serverï¼šå‘å¸ƒäº†ç›®å‰ç²¾åº¦æœ€é«˜çš„OCRæ¨¡å‹ï¼Œä¸­è‹±æ–‡åœºæ™¯ä¸Šæ£€æµ‹æ¨¡å‹ç²¾åº¦æå‡4.9%ï¼Œ è¯†åˆ«æ¨¡å‹ç²¾åº¦æå‡2%å¯å‚è€ƒå¿«é€Ÿå¼€å§‹ ä¸€è¡Œå‘½ä»¤å¿«é€Ÿä½¿ç”¨ï¼ŒåŒæ—¶ä¹Ÿå¯åœ¨é£æ¡¨AIå¥—ä»¶(PaddleX)ä¸­çš„é€šç”¨OCRäº§ä¸šæ–¹æ¡ˆä¸­ä½ä»£ç å®Œæˆæ¨¡å‹è®­ç»ƒã€æ¨ç†ã€é«˜æ€§èƒ½éƒ¨ç½²å…¨æµç¨‹å‘å¸ƒPP-ChatOCR ,ä½¿ç”¨èåˆPP-OCRæ¨¡å‹å’Œæ–‡å¿ƒå¤§æ¨¡å‹çš„é€šç”¨åœºæ™¯å…³é”®ä¿¡æ¯æŠ½å–å…¨æ–°æ–¹æ¡ˆğŸ”¨2022.11 æ–°å¢å®ç°4ç§å‰æ²¿ç®—æ³•ï¼šæ–‡æœ¬æ£€æµ‹ DRRG,  æ–‡æœ¬è¯†åˆ« RFL, æ–‡æœ¬è¶…åˆ†Text Telescopeï¼Œå…¬å¼è¯†åˆ«CAN2022.10 ä¼˜åŒ–JSç‰ˆPP-OCRv3æ¨¡å‹ï¼šæ¨¡å‹å¤§å°ä»…4.3Mï¼Œé¢„æµ‹é€Ÿåº¦æå‡8å€ï¼Œé…å¥—web demoå¼€ç®±å³ç”¨ğŸ’¥ ç›´æ’­å›æ”¾ï¼šPaddleOCRç ”å‘å›¢é˜Ÿè¯¦è§£PP-StructureV2ä¼˜åŒ–ç­–ç•¥ã€‚å¾®ä¿¡æ‰«æä¸‹æ–¹äºŒç»´ç ï¼Œå…³æ³¨å…¬ä¼—å·å¹¶å¡«å†™é—®å·åè¿›å…¥å®˜æ–¹äº¤æµç¾¤ï¼Œè·å–ç›´æ’­å›æ”¾é“¾æ¥ä¸20Gé‡ç£…OCRå­¦ä¹ å¤§ç¤¼åŒ…ï¼ˆå†…å«PDFè½¬Wordåº”ç”¨ç¨‹åºã€10ç§å‚ç±»æ¨¡å‹ã€ã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ç­‰ï¼‰ğŸ”¥2022.8.24 å‘å¸ƒ PaddleOCR release/2.6å‘å¸ƒPP-StructureV2ï¼Œç³»ç»ŸåŠŸèƒ½æ€§èƒ½å…¨é¢å‡çº§ï¼Œé€‚é…ä¸­æ–‡åœºæ™¯ï¼Œæ–°å¢æ”¯æŒç‰ˆé¢å¤åŸï¼Œæ”¯æŒä¸€è¡Œå‘½ä»¤å®ŒæˆPDFè½¬Wordï¼›ç‰ˆé¢åˆ†ææ¨¡å‹ä¼˜åŒ–ï¼šæ¨¡å‹å­˜å‚¨å‡å°‘95%ï¼Œé€Ÿåº¦æå‡11å€ï¼Œå¹³å‡CPUè€—æ—¶ä»…éœ€41msï¼›è¡¨æ ¼è¯†åˆ«æ¨¡å‹ä¼˜åŒ–ï¼šè®¾è®¡3å¤§ä¼˜åŒ–ç­–ç•¥ï¼Œé¢„æµ‹è€—æ—¶ä¸å˜æƒ…å†µä¸‹ï¼Œæ¨¡å‹ç²¾åº¦æå‡6%ï¼›å…³é”®ä¿¡æ¯æŠ½å–æ¨¡å‹ä¼˜åŒ–ï¼šè®¾è®¡è§†è§‰æ— å…³æ¨¡å‹ç»“æ„ï¼Œè¯­ä¹‰å®ä½“è¯†åˆ«ç²¾åº¦æå‡2.8%ï¼Œå…³ç³»æŠ½å–ç²¾åº¦æå‡9.1%ã€‚ğŸ”¥2022.8 å‘å¸ƒ OCRåœºæ™¯åº”ç”¨é›†åˆï¼šåŒ…å«æ•°ç ç®¡ã€æ¶²æ™¶å±ã€è½¦ç‰Œã€é«˜ç²¾åº¦SVTRæ¨¡å‹ã€æ‰‹å†™ä½“è¯†åˆ«ç­‰9ä¸ªå‚ç±»æ¨¡å‹ï¼Œè¦†ç›–é€šç”¨ï¼Œåˆ¶é€ ã€é‡‘èã€äº¤é€šè¡Œä¸šçš„ä¸»è¦OCRå‚ç±»åº”ç”¨ã€‚æ›´å¤šğŸŒŸ ç‰¹æ€§æ”¯æŒå¤šç§OCRç›¸å…³å‰æ²¿ç®—æ³•ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šæ‰“é€ äº§ä¸šçº§ç‰¹è‰²æ¨¡å‹PP-OCRã€PP-Structureå’ŒPP-ChatOCRï¼Œå¹¶æ‰“é€šæ•°æ®ç”Ÿäº§ã€æ¨¡å‹è®­ç»ƒã€å‹ç¼©ã€é¢„æµ‹éƒ¨ç½²å…¨æµç¨‹ã€‚    ä¸Šè¿°å†…å®¹çš„ä½¿ç”¨æ–¹æ³•å»ºè®®ä»æ–‡æ¡£æ•™ç¨‹ä¸­çš„å¿«é€Ÿå¼€å§‹ä½“éªŒâš¡ å¿«é€Ÿå¼€å§‹åœ¨çº¿ç½‘ç«™ä½“éªŒï¼šPP-OCRv4 åœ¨çº¿ä½“éªŒåœ°å€ï¼šhttps://aistudio.baidu.com/aistudio/projectdetail/6611435PP-ChatOCR åœ¨çº¿ä½“éªŒåœ°å€ï¼šhttps://aistudio.baidu.com/aistudio/projectdetail/6488689ä¸€è¡Œå‘½ä»¤å¿«é€Ÿä½¿ç”¨ï¼šå¿«é€Ÿå¼€å§‹ï¼ˆä¸­è‹±æ–‡/å¤šè¯­è¨€/æ–‡æ¡£åˆ†æï¼‰é£æ¡¨AIå¥—ä»¶ï¼ˆPaddleXï¼‰ä¸­è®­ç»ƒã€æ¨ç†ã€é«˜æ€§èƒ½éƒ¨ç½²å…¨æµç¨‹ä½“éªŒï¼šPP-OCRv4ï¼šhttps://aistudio.baidu.com/aistudio/modelsdetail?modelId=286PP-ChatOCRï¼šhttps://aistudio.baidu.com/aistudio/modelsdetail?modelId=332ç§»åŠ¨ç«¯demoä½“éªŒï¼šå®‰è£…åŒ…DEMOä¸‹è½½åœ°å€(åŸºäºEasyEdgeå’ŒPaddle-Lite, æ”¯æŒiOSå’ŒAndroidç³»ç»Ÿ)ğŸ“– æŠ€æœ¯äº¤æµåˆä½œé£æ¡¨AIå¥—ä»¶(PaddleX)æä¾›äº†é£æ¡¨æ¨¡å‹è®­å‹æ¨ä¸€ç«™å¼å…¨æµç¨‹é«˜æ•ˆç‡å¼€å‘å¹³å°ï¼Œå…¶ä½¿å‘½æ˜¯åŠ©åŠ›AIæŠ€æœ¯å¿«é€Ÿè½åœ°ï¼Œæ„¿æ™¯æ˜¯ä½¿äººäººæˆä¸ºAI Developerï¼PaddleX ç›®å‰è¦†ç›–å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²ã€3Dã€OCRå’Œæ—¶åºé¢„æµ‹ç­‰é¢†åŸŸæ–¹å‘ï¼Œå·²å†…ç½®äº†36ç§åŸºç¡€å•æ¨¡å‹ï¼Œä¾‹å¦‚RT-DETRã€PP-YOLOEã€PP-HGNetã€PP-LCNetã€PP-LiteSegç­‰ï¼›é›†æˆäº†12ç§å®ç”¨çš„äº§ä¸šæ–¹æ¡ˆï¼Œä¾‹å¦‚PP-OCRv4ã€PP-ChatOCRã€PP-ShiTuã€PP-TSã€è½¦è½½è·¯é¢åƒåœ¾æ£€æµ‹ã€é‡ç”ŸåŠ¨ç‰©è¿ç¦åˆ¶å“è¯†åˆ«ç­‰ã€‚PaddleX æä¾›äº†â€œå·¥å…·ç®±â€å’Œâ€œå¼€å‘è€…â€ä¸¤ç§AIå¼€å‘æ¨¡å¼ã€‚å·¥å…·ç®±æ¨¡å¼å¯ä»¥æ— ä»£ç è°ƒä¼˜å…³é”®è¶…å‚ï¼Œå¼€å‘è€…æ¨¡å¼å¯ä»¥ä½ä»£ç è¿›è¡Œå•æ¨¡å‹è®­å‹æ¨å’Œå¤šæ¨¡å‹ä¸²è”æ¨ç†ï¼ŒåŒæ—¶æ”¯æŒäº‘ç«¯å’Œæœ¬åœ°ç«¯ã€‚PaddleX è¿˜æ”¯æŒè”åˆ›å¼€å‘ï¼Œåˆ©æ¶¦åˆ†æˆï¼ç›®å‰ PaddleX æ­£åœ¨å¿«é€Ÿè¿­ä»£ï¼Œæ¬¢è¿å¹¿å¤§çš„ä¸ªäººå¼€å‘è€…å’Œä¼ä¸šå¼€å‘è€…å‚ä¸è¿›æ¥ï¼Œå…±åˆ›ç¹è£çš„ AI æŠ€æœ¯ç”Ÿæ€ï¼å¾®ä¿¡æ‰«æä¸‹é¢äºŒç»´ç æ·»åŠ è¿è¥åŒå­¦ï¼Œå¹¶å›å¤ã€paddlexã€‘ï¼Œè¿è¥åŒå­¦ä¼šé‚€è¯·æ‚¨åŠ å…¥å®˜æ–¹äº¤æµç¾¤ï¼Œè·å¾—æ›´é«˜æ•ˆçš„é—®é¢˜ç­”ç–‘ã€‚é£æ¡¨AIå¥—ä»¶ã€PaddleXã€‘æŠ€æœ¯äº¤æµç¾¤äºŒç»´ç ğŸ“šã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ğŸš€ å¼€æºå…±å»ºğŸ‘« åŠ å…¥ç¤¾åŒºï¼šæ„Ÿè°¢å¤§å®¶é•¿ä¹…ä»¥æ¥å¯¹ PaddleOCR çš„æ”¯æŒå’Œå…³æ³¨ï¼Œä¸å¹¿å¤§å¼€å‘è€…å…±åŒæ„å»ºä¸€ä¸ªä¸“ä¸šã€å’Œè°ã€ç›¸äº’å¸®åŠ©çš„å¼€æºç¤¾åŒºæ˜¯ PaddleOCR çš„ç›®æ ‡ã€‚æˆ‘ä»¬éå¸¸æ¬¢è¿å„ä½å¼€å‘è€…å‚ä¸åˆ°é£æ¡¨ç¤¾åŒºçš„å¼€æºå»ºè®¾ä¸­ï¼ŒåŠ å…¥å¼€æºã€å…±å»ºé£æ¡¨ã€‚ä¸ºæ„Ÿè°¢ç¤¾åŒºå¼€å‘è€…åœ¨ PaddleOCR release2.7 ä¸­åšå‡ºçš„ä»£ç è´¡çŒ®ï¼Œæˆ‘ä»¬å°†ä¸ºè´¡çŒ®è€…åˆ¶ä½œä¸é‚®å¯„å¼€æºè´¡çŒ®è¯ä¹¦ï¼Œçƒ¦è¯·å¡«å†™é—®å·æä¾›å¿…è¦çš„é‚®å¯„ä¿¡æ¯ã€‚ğŸ¤© ç¤¾åŒºæ´»åŠ¨ï¼šé£æ¡¨å¼€æºç¤¾åŒºé•¿æœŸè¿è¥ä¸å‘å¸ƒå„ç±»ä¸°å¯Œçš„æ´»åŠ¨ä¸å¼€å‘ä»»åŠ¡ï¼Œåœ¨ PaddleOCR ç¤¾åŒºï¼Œä½ å¯ä»¥å…³æ³¨ä»¥ä¸‹ç¤¾åŒºæ´»åŠ¨ï¼Œå¹¶é€‰æ‹©è‡ªå·±æ„Ÿå…´è¶£çš„å†…å®¹å‚ä¸å¼€æºå…±å»ºï¼šğŸ é£æ¡¨å¥—ä»¶å¿«ä¹å¼€æºå¸¸è§„èµ› | ä¼ é€é—¨ï¼šOCR ç¤¾åŒºå¸¸è§„èµ›å‡çº§ç‰ˆï¼Œä»¥å»ºè®¾æ›´å¥½ç”¨çš„ OCR å¥—ä»¶ä¸ºç›®æ ‡ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºå­¦æœ¯å‰æ²¿æ¨¡å‹è®­ç»ƒä¸æ¨ç†ã€æ‰“ç£¨ä¼˜åŒ– OCR å·¥å…·ä¸åº”ç”¨é¡¹ç›®å¼€å‘ç­‰ï¼Œä»»ä½•æœ‰åˆ©äºç¤¾åŒºæ„è§æµåŠ¨å’Œé—®é¢˜è§£å†³çš„è¡Œä¸ºéƒ½çƒ­åˆ‡å¸Œæœ›å¤§å®¶çš„å‚ä¸ã€‚è®©æˆ‘ä»¬å…±åŒæˆé•¿ä¸ºé£æ¡¨å¥—ä»¶çš„é‡è¦ Contributor ğŸ‰ğŸ‰ğŸ‰ã€‚ğŸ’¡ æ–°éœ€æ±‚å¾é›† | ä¼ é€é—¨ï¼šä½ åœ¨æ—¥å¸¸ç ”ç©¶å’Œå®è·µæ·±åº¦å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œæœ‰å“ªäº›ä½ æœŸæœ›çš„ feature äºŸå¾…å®ç°ï¼Ÿè¯·æŒ‰ç…§æ ¼å¼æè¿°ä½ æƒ³å®ç°çš„ feature å’Œä½ æå‡ºçš„åˆæ­¥å®ç°æ€è·¯ï¼Œæˆ‘ä»¬ä¼šå®šæœŸæ²Ÿé€šä¸è®¨è®ºè¿™äº›éœ€æ±‚ï¼Œå¹¶å°†å…¶çº³å…¥æœªæ¥çš„ç‰ˆæœ¬è§„åˆ’ä¸­ã€‚ğŸ’¬ PP-SIG æŠ€æœ¯ç ”è®¨ä¼š | ä¼ é€é—¨ï¼šPP-SIG æ˜¯é£æ¡¨ç¤¾åŒºå¼€å‘è€…ç”±äºç›¸åŒçš„å…´è¶£æ±‡èšåœ¨ä¸€èµ·å½¢æˆçš„è™šæ‹Ÿç»„ç»‡ï¼Œé€šè¿‡å®šæœŸå¬å¼€æŠ€æœ¯ç ”è®¨ä¼šçš„æ–¹å¼ï¼Œåˆ†äº«è¡Œä¸šå‰æ²¿åŠ¨æ€ã€æ¢è®¨ç¤¾åŒºéœ€æ±‚ä¸æŠ€æœ¯å¼€å‘ç»†èŠ‚ã€å‘èµ·ç¤¾åŒºè”åˆè´¡çŒ®ä»»åŠ¡ã€‚PaddleOCR å¸Œæœ›å¯ä»¥é€šè¿‡ AI çš„åŠ›é‡åŠ©åŠ›ä»»ä½•ä¸€ä½æœ‰æ¢¦æƒ³çš„å¼€å‘è€…å®ç°è‡ªå·±çš„æƒ³æ³•ï¼Œäº«å—åˆ›é€ ä»·å€¼å¸¦æ¥çš„æ„‰æ‚¦ã€‚ğŸ“‘ é¡¹ç›®åˆä½œï¼šå¦‚æœä½ æœ‰ä¼ä¸šä¸­æ˜ç¡®çš„ OCR å‚ç±»åº”ç”¨éœ€æ±‚ï¼Œæˆ‘ä»¬æ¨èä½ ä½¿ç”¨è®­å‹æ¨ä¸€ç«™å¼å…¨æµç¨‹é«˜æ•ˆç‡å¼€å‘å¹³å° PaddleXï¼ŒåŠ©åŠ› AI æŠ€æœ¯å¿«é€Ÿè½åœ°ã€‚PaddleX è¿˜æ”¯æŒè”åˆ›å¼€å‘ï¼Œåˆ©æ¶¦åˆ†æˆï¼æ¬¢è¿å¹¿å¤§çš„ä¸ªäººå¼€å‘è€…å’Œä¼ä¸šå¼€å‘è€…å‚ä¸è¿›æ¥ï¼Œå…±åˆ›ç¹è£çš„ AI æŠ€æœ¯ç”Ÿæ€ï¼ğŸ› ï¸ PP-OCRç³»åˆ—æ¨¡å‹åˆ—è¡¨ï¼ˆæ›´æ–°ä¸­ï¼‰æ¨¡å‹ç®€ä»‹æ¨¡å‹åç§°æ¨èåœºæ™¯æ£€æµ‹æ¨¡å‹æ–¹å‘åˆ†ç±»å™¨è¯†åˆ«æ¨¡å‹ä¸­è‹±æ–‡è¶…è½»é‡PP-OCRv4æ¨¡å‹ï¼ˆ15.8Mï¼‰ch_PP-OCRv4_xxç§»åŠ¨ç«¯&æœåŠ¡å™¨ç«¯æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹ä¸­è‹±æ–‡è¶…è½»é‡PP-OCRv3æ¨¡å‹ï¼ˆ16.2Mï¼‰ch_PP-OCRv3_xxç§»åŠ¨ç«¯&æœåŠ¡å™¨ç«¯æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹è‹±æ–‡è¶…è½»é‡PP-OCRv3æ¨¡å‹ï¼ˆ13.4Mï¼‰en_PP-OCRv3_xxç§»åŠ¨ç«¯&æœåŠ¡å™¨ç«¯æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹è¶…è½»é‡OCRç³»åˆ—æ›´å¤šæ¨¡å‹ä¸‹è½½ï¼ˆåŒ…æ‹¬å¤šè¯­è¨€ï¼‰ï¼Œå¯ä»¥å‚è€ƒPP-OCRç³»åˆ—æ¨¡å‹ä¸‹è½½ï¼Œæ–‡æ¡£åˆ†æç›¸å…³æ¨¡å‹å‚è€ƒPP-Structureç³»åˆ—æ¨¡å‹ä¸‹è½½PaddleOCRåœºæ™¯åº”ç”¨æ¨¡å‹è¡Œä¸šç±»åˆ«äº®ç‚¹æ–‡æ¡£è¯´æ˜æ¨¡å‹ä¸‹è½½åˆ¶é€ æ•°ç ç®¡è¯†åˆ«æ•°ç ç®¡æ•°æ®åˆæˆã€æ¼è¯†åˆ«è°ƒä¼˜å…‰åŠŸç‡è®¡æ•°ç ç®¡å­—ç¬¦è¯†åˆ«ä¸‹è½½é“¾æ¥é‡‘èé€šç”¨è¡¨å•è¯†åˆ«å¤šæ¨¡æ€é€šç”¨è¡¨å•ç»“æ„åŒ–æå–å¤šæ¨¡æ€è¡¨å•è¯†åˆ«ä¸‹è½½é“¾æ¥äº¤é€šè½¦ç‰Œè¯†åˆ«å¤šè§’åº¦å›¾åƒå¤„ç†ã€è½»é‡æ¨¡å‹ã€ç«¯ä¾§éƒ¨ç½²è½»é‡çº§è½¦ç‰Œè¯†åˆ«ä¸‹è½½é“¾æ¥æ›´å¤šåˆ¶é€ ã€é‡‘èã€äº¤é€šè¡Œä¸šçš„ä¸»è¦OCRå‚ç±»åº”ç”¨æ¨¡å‹ï¼ˆå¦‚ç”µè¡¨ã€æ¶²æ™¶å±ã€é«˜ç²¾åº¦SVTRæ¨¡å‹ç­‰ï¼‰ï¼Œå¯å‚è€ƒåœºæ™¯åº”ç”¨æ¨¡å‹ä¸‹è½½ğŸ“– æ–‡æ¡£æ•™ç¨‹è¿è¡Œç¯å¢ƒå‡†å¤‡PP-OCRæ–‡æœ¬æ£€æµ‹è¯†åˆ«ğŸ”¥å¿«é€Ÿå¼€å§‹æ¨¡å‹åº“æ¨¡å‹è®­ç»ƒæ–‡æœ¬æ£€æµ‹æ–‡æœ¬è¯†åˆ«æ–‡æœ¬æ–¹å‘åˆ†ç±»å™¨æ¨¡å‹å‹ç¼©æ¨¡å‹é‡åŒ–æ¨¡å‹è£å‰ªçŸ¥è¯†è’¸é¦æ¨ç†éƒ¨ç½²åŸºäºPythoné¢„æµ‹å¼•æ“æ¨ç†åŸºäºC++é¢„æµ‹å¼•æ“æ¨ç†æœåŠ¡åŒ–éƒ¨ç½²ç«¯ä¾§éƒ¨ç½²Paddle2ONNXæ¨¡å‹è½¬åŒ–ä¸é¢„æµ‹äº‘ä¸Šé£æ¡¨éƒ¨ç½²å·¥å…·BenchmarkPP-Structureæ–‡æ¡£åˆ†æğŸ”¥å¿«é€Ÿå¼€å§‹æ¨¡å‹åº“æ¨¡å‹è®­ç»ƒç‰ˆé¢åˆ†æè¡¨æ ¼è¯†åˆ«å…³é”®ä¿¡æ¯æå–æ¨ç†éƒ¨ç½²åŸºäºPythoné¢„æµ‹å¼•æ“æ¨ç†åŸºäºC++é¢„æµ‹å¼•æ“æ¨ç†æœåŠ¡åŒ–éƒ¨ç½²å‰æ²¿ç®—æ³•ä¸æ¨¡å‹ğŸš€æ–‡æœ¬æ£€æµ‹ç®—æ³•æ–‡æœ¬è¯†åˆ«ç®—æ³•ç«¯åˆ°ç«¯OCRç®—æ³•è¡¨æ ¼è¯†åˆ«ç®—æ³•å…³é”®ä¿¡æ¯æŠ½å–ç®—æ³•ä½¿ç”¨PaddleOCRæ¶æ„æ·»åŠ æ–°ç®—æ³•åœºæ™¯åº”ç”¨æ•°æ®æ ‡æ³¨ä¸åˆæˆåŠè‡ªåŠ¨æ ‡æ³¨å·¥å…·PPOCRLabelæ•°æ®åˆæˆå·¥å…·Style-Textå…¶å®ƒæ•°æ®æ ‡æ³¨å·¥å…·å…¶å®ƒæ•°æ®åˆæˆå·¥å…·æ•°æ®é›†é€šç”¨ä¸­è‹±æ–‡OCRæ•°æ®é›†æ‰‹å†™ä¸­æ–‡OCRæ•°æ®é›†å‚ç±»å¤šè¯­è¨€OCRæ•°æ®é›†ç‰ˆé¢åˆ†ææ•°æ®é›†è¡¨æ ¼è¯†åˆ«æ•°æ®é›†å…³é”®ä¿¡æ¯æå–æ•°æ®é›†ä»£ç ç»„ç»‡ç»“æ„æ•ˆæœå±•ç¤ºã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ğŸ“šå¼€æºç¤¾åŒºFAQé€šç”¨é—®é¢˜PaddleOCRå®æˆ˜é—®é¢˜å‚è€ƒæ–‡çŒ®è®¸å¯è¯ä¹¦ğŸ‘€ æ•ˆæœå±•ç¤º morePP-OCRv3 ä¸­æ–‡æ¨¡å‹            PP-OCRv3 è‹±æ–‡æ¨¡å‹        PP-OCRv3 å¤šè¯­è¨€æ¨¡å‹        PP-Structure æ–‡æ¡£åˆ†æç‰ˆé¢åˆ†æ+è¡¨æ ¼è¯†åˆ«    SERï¼ˆè¯­ä¹‰å®ä½“è¯†åˆ«ï¼‰            REï¼ˆå…³ç³»æå–ï¼‰            è®¸å¯è¯ä¹¦æœ¬é¡¹ç›®çš„å‘å¸ƒå—Apache 2.0 licenseè®¸å¯è®¤è¯ã€‚"
38,lazyprogrammer/machine_learning_examples,https://github.com/lazyprogrammer/machine_learning_examples/blob/master/README.md,Python,"machine_learning_examplesA collection of machine learning examples and tutorials.Find associated tutorials at https://lazyprogrammer.meFind associated courses at https://deeplearningcourses.comPlease note that not all code from all courses will be found in this repository. Some newer code examples (e.g. most of Tensorflow 2.0) were done in Google Colab. Therefore, you should check the instructions given in the lectures for the course you are taking.How to I find the code for a particular course?The code for each course is separated by folder. You can determine which folder corresponds with which course by watching the \""Where to get the code\"" lecture inside the course (usually Lecture 2 or 3).Remember: one folder = one course.Why you should not fork this repoI've noticed that many people have out-of-date forks. Thus, I recommend not forking this repository if you take one of my courses. I am constantly updating my courses, and your fork will soon become out-of-date. You should clone the repository instead to make it easy to get updates (i.e. just \""git pull\"" randomly and frequently).Where is the code for your latest courses?Beginning with Tensorflow 2, I started to use Google Colab. For those courses, unless otherwise noted, the code will be on Google Colab. Links to the notebooks are provided in the course. See the lecture \""Where to get the code\"" for further details.VIP Course LinksData Science: Transformers for Natural Language Processinghttps://deeplearningcourses.com/c/data-science-transformers-nlpMachine Learning: Natural Language Processing in Python (V2)https://deeplearningcourses.com/c/natural-language-processing-in-pythonTime Series Analysis, Forecasting, and Machine Learninghttps://deeplearningcourses.com/c/time-series-analysisFinancial Engineering and Artificial Intelligence in Pythonhttps://deeplearningcourses.com/c/ai-financePyTorch: Deep Learning and Artificial Intelligencehttps://deeplearningcourses.com/c/pytorch-deep-learningTensorflow 2.0: Deep Learning and Artificial Intelligence (VIP Version)https://deeplearningcourses.com/c/deep-learning-tensorflow-2Deep Learning Courses ExclusivesData Science: Bayesian Linear Regression in Pythonhttps://deeplearningcourses.com/c/bayesian-linear-regression-in-pythonData Science: Bayesian Classification in Pythonhttps://deeplearningcourses.com/c/bayesian-classification-in-pythonClassical Statistical Inference and A/B Testing in Pythonhttps://deeplearningcourses.com/c/statistical-inference-in-pythonLinear Programming for Linear Regression in Pythonhttps://deeplearningcourses.com/c/linear-programming-pythonMATLAB for Students, Engineers, and Professionals in STEMhttps://deeplearningcourses.com/c/matlabOther Course LinksFinancial Analysis: Build a ChatGPT Pairs Trading Bothttps://deeplearningcourses.com/c/chatgpt-pairs-tradingMath 0-1: Calculus for Data Science & Machine Learninghttps://deeplearningcourses.com/c/calculus-data-scienceData Science & Machine Learning: Naive Bayes in Pythonhttps://deeplearningcourses.com/c/data-science-machine-learning-naive-bayes-in-pythonCutting-Edge AI: Deep Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/cutting-edge-artificial-intelligenceRecommender Systems and Deep Learning in Pythonhttps://deeplearningcourses.com/c/recommender-systemsMachine Learning and AI: Support Vector Machines in Pythonhttps://deeplearningcourses.com/c/support-vector-machines-in-pythonDeep Learning: Advanced Computer Visionhttps://deeplearningcourses.com/c/advanced-computer-visionDeep Learning: Advanced NLP and RNNshttps://deeplearningcourses.com/c/deep-learning-advanced-nlpDeep Learning: GANs and Variational Autoencodershttps://deeplearningcourses.com/c/deep-learning-gans-and-variational-autoencodersAdvanced AI: Deep Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/deep-reinforcement-learning-in-pythonArtificial Intelligence: Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-pythonNatural Language Processing with Deep Learning in Pythonhttps://deeplearningcourses.com/c/natural-language-processing-with-deep-learning-in-pythonDeep Learning: Recurrent Neural Networks in Pythonhttps://deeplearningcourses.com/c/deep-learning-recurrent-neural-networks-in-pythonUnsupervised Machine Learning: Hidden Markov Models in Pythonhttps://deeplearningcourses.com/c/unsupervised-machine-learning-hidden-markov-models-in-pythonDeep Learning Prerequisites: The Numpy Stack in Pythonhttps://deeplearningcourses.com/c/deep-learning-prerequisites-the-numpy-stack-in-pythonDeep Learning Prerequisites: Linear Regression in Pythonhttps://deeplearningcourses.com/c/data-science-linear-regression-in-pythonDeep Learning Prerequisites: Logistic Regression in Pythonhttps://deeplearningcourses.com/c/data-science-logistic-regression-in-pythonData Science: Deep Learning and Neural Networks in Pythonhttps://deeplearningcourses.com/c/data-science-deep-learning-in-pythonCluster Analysis and Unsupervised Machine Learning in Pythonhttps://deeplearningcourses.com/c/cluster-analysis-unsupervised-machine-learning-pythonData Science: Supervised Machine Learning in Pythonhttps://deeplearningcourses.com/c/data-science-supervised-machine-learning-in-pythonBayesian Machine Learning in Python: A/B Testinghttps://deeplearningcourses.com/c/bayesian-machine-learning-in-python-ab-testingData Science: Natural Language Processing in Pythonhttps://deeplearningcourses.com/c/data-science-natural-language-processing-in-pythonModern Deep Learning in Pythonhttps://deeplearningcourses.com/c/data-science-deep-learning-in-theano-tensorflowEnsemble Machine Learning in Python: Random Forest and AdaBoosthttps://deeplearningcourses.com/c/machine-learning-in-python-random-forest-adaboostDeep Learning: Convolutional Neural Networks in Pythonhttps://deeplearningcourses.com/c/deep-learning-convolutional-neural-networks-theano-tensorflowUnsupervised Deep Learning in Pythonhttps://deeplearningcourses.com/c/unsupervised-deep-learning-in-python"
39,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
40,donnemartin/system-design-primer,https://github.com/donnemartin/system-design-primer/blob/master/README-ja.md,Python,"English âˆ™ æ—¥æœ¬èª âˆ™ ç®€ä½“ä¸­æ–‡ âˆ™ ç¹é«”ä¸­æ–‡ | Ø§Ù„Ø¹ÙØ±ÙØ¨ÙÙŠÙÙ‘Ø©â€ âˆ™ à¦¬à¦¾à¦‚à¦²à¦¾ âˆ™ PortuguÃªs do Brasil âˆ™ Deutsch âˆ™ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ âˆ™ ×¢×‘×¨×™×ª âˆ™ Italiano âˆ™ í•œêµ­ì–´ âˆ™ ÙØ§Ø±Ø³ÛŒ âˆ™ Polski âˆ™ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº âˆ™ EspaÃ±ol âˆ™ à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ âˆ™ TÃ¼rkÃ§e âˆ™ tiáº¿ng Viá»‡t âˆ™ FranÃ§ais | Add Translationã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå…¥é–€    å‹•æ©Ÿãƒ»ç›®çš„å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’å­¦ã¶ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«å‚™ãˆã‚‹å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆã‚’å­¦ã¶ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’å­¦ã¶ã“ã¨ã¯ã€ã‚ˆã‚Šè‰¯ã„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ãªã‚‹ã“ã¨ã«è³‡ã™ã‚‹ã§ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã¯ã¨ã¦ã‚‚åºƒç¯„ãªãƒˆãƒ”ãƒƒã‚¯ã‚’å«ã¿ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆåŸç†ã«ã¤ã„ã¦ã¯ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã«ã¯è†¨å¤§ãªé‡ã®æ–‡çŒ®ãŒæ•£ã‚‰ã°ã£ã¦ã„ã¾ã™ã€‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã«å¿…è¦ãªçŸ¥è­˜ã‚’å­¦ã¶ã“ã¨ãŒã§ãã‚‹ æ–‡çŒ®ãƒªã‚¹ãƒˆã‚’ä½“ç³»çš„ã«ã¾ã¨ã‚ãŸã‚‚ã® ã§ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰å­¦ã¶ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ã“ã‚Œã‹ã‚‰ã‚‚ãšã£ã¨æ›´æ–°ã•ã‚Œã¦ã„ãã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸæ®µéšã«ã™ãã¾ã›ã‚“ã€‚Contributions ã¯å¤§æ­“è¿ã§ã™ï¼ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«å‚™ãˆã‚‹ã‚³ãƒ¼ãƒ‰æŠ€è¡“é¢æ¥ã«åŠ ãˆã¦ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«é–¢ã™ã‚‹çŸ¥è­˜ã¯ã€å¤šãã®ãƒ†ãƒƒã‚¯ä¼æ¥­ã«ãŠã‘ã‚‹ æŠ€è¡“æ¡ç”¨é¢æ¥ãƒ—ãƒ­ã‚»ã‚¹ ã§ å¿…è¦ä¸å¯æ¬ ãªè¦ç´  ã§ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§ã®é »å‡ºè³ªå•ã«å‚™ãˆã€è‡ªåˆ†ã®è§£ç­”ã¨æ¨¡ç¯„è§£ç­”:ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã€ã‚³ãƒ¼ãƒ‰ãã—ã¦å›³è¡¨ãªã©ã‚’æ¯”è¼ƒã—ã¦å­¦ã³ã¾ã—ã‚‡ã†ã€‚é¢æ¥æº–å‚™ã«å½¹ç«‹ã¤ãã®ä»–ã®ãƒˆãƒ”ãƒƒã‚¯:å­¦ç¿’æŒ‡é‡ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«ã©ã®ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ ã¨ãã®è§£ç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆèª²é¡Œä¾‹ã€ ã¨ãã®è§£ç­”ãã®ä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œä¾‹æš—è¨˜ã‚«ãƒ¼ãƒ‰    ã“ã®Ankiç”¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒƒã‚­ ã¯ã€é–“éš”åå¾©ã‚’æ´»ç”¨ã—ã¦ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ã‚­ãƒ¼ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®å­¦ç¿’ã‚’æ”¯æ´ã—ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒ‡ãƒƒã‚­ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆç·´ç¿’èª²é¡Œãƒ‡ãƒƒã‚­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ç·´ç¿’èª²é¡Œãƒ‡ãƒƒã‚­å¤–å‡ºå…ˆã‚„ç§»å‹•ä¸­ã®å‹‰å¼·ã«å½¹ç«‹ã¤ã§ã—ã‚‡ã†ã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŠ€è¡“èª²é¡Œç”¨ã®å•é¡Œ: ç·´ç¿’ç”¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰æŠ€è¡“é¢æ¥ç”¨ã®å•é¡Œã‚’æ¢ã—ã¦ã„ã‚‹å ´åˆã¯ã“ã¡ã‚‰    å§‰å¦¹ãƒªãƒã‚¸ãƒˆãƒªã® Interactive Coding Challengesã‚‚è¦‹ã¦ã¿ã¦ãã ã•ã„ã€‚è¿½åŠ ã®æš—è¨˜ãƒ‡ãƒƒã‚­ã‚«ãƒ¼ãƒ‰ã‚‚å…¥ã£ã¦ã„ã¾ã™ã€‚Coding deckã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰å­¦ã¶ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆç­‰ã®è²¢çŒ®ã¯ç©æ¥µçš„ã«ãŠé¡˜ã„ã—ã¾ã™:ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹æ”¹å–„æ–°è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ ç¿»è¨³ã™ã‚‹ç¾åœ¨ã€å†…å®¹ã®æ”¹å–„ãŒå¿…è¦ãªä½œæ¥­ä¸­ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã“ã¡ã‚‰ã§ã™ã€‚ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã®å‰ã«Contributing Guidelinesã‚’èª­ã¿ã¾ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆç›®æ¬¡è³›å¦ã‚‚å«ã‚ãŸæ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®å„ãƒˆãƒ”ãƒƒã‚¯ã®æ¦‚è¦ã€‚ å…¨ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚Šã¾ã™ã€‚ãã‚Œãã‚Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ˆã‚Šå­¦ã³ã‚’æ·±ã‚ã‚‹ã‚ˆã†ãªä»–ã®æ–‡çŒ®ã¸ã®ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚    ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯: ã¾ãšã¯ã“ã“ã‹ã‚‰Step 1: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹å‹•ç”»ã‚’è¦‹ã‚‹Step 2: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹è¨˜äº‹ã‚’èª­ã‚€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¯ç”¨æ€§ vs ä¸€è²«æ€§CAPç†è«–CP - ä¸€è²«æ€§(consistency)ã¨åˆ†å‰²æ€§(partition)è€æ€§AP - å¯ç”¨æ€§(availability)ã¨åˆ†å‰²æ€§(partition)è€æ€§ä¸€è²«æ€§ ãƒ‘ã‚¿ãƒ¼ãƒ³å¼±ã„ä¸€è²«æ€§çµæœæ•´åˆæ€§å¼·ã„ä¸€è²«æ€§å¯ç”¨æ€§ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ (DNS)ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CDN)ãƒ—ãƒƒã‚·ãƒ¥CDNãƒ—ãƒ«CDNãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ–/ãƒ‘ãƒƒã‚·ãƒ–æ§‹æˆã‚¢ã‚¯ãƒ†ã‚£ãƒ–/ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ§‹æˆLayer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· (WEBã‚µãƒ¼ãƒãƒ¼)ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ vs ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (RDBMS)ãƒã‚¹ã‚¿ãƒ¼/ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼/ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ãƒãƒ¼ãƒãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³SQL ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°NoSQLã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã‚°ãƒ©ãƒ• ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹SQL or NoSQLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°CDNã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°Webã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã™ã‚‹ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã®ã‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ (ãƒ©ã‚¤ãƒˆãƒãƒƒã‚¯)ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰éåŒæœŸå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼é€šä¿¡ä¼é€åˆ¶å¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ« (TCP)ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« (UDP)é éš”æ‰‹ç¶šå‘¼å‡º (RPC)Representational state transfer (REST)ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è£œéº2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ä¾‹é¡Œå®Ÿä¸–ç•Œã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å„ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°ä½œæ¥­ä¸­ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆé€£çµ¡æƒ…å ±ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å­¦ç¿’æŒ‡é‡å­¦ç¿’ã‚¹ãƒ‘ãƒ³ã«å¿œã˜ã¦ã¿ã‚‹ã¹ããƒˆãƒ”ãƒƒã‚¯ã‚¹ (short, medium, long)Q: é¢æ¥ã®ãŸã‚ã«ã¯ã€ã“ã“ã«ã‚ã‚‹ã‚‚ã®ã™ã¹ã¦ã‚’ã‚„ã‚‰ãªã„ã¨ã„ã‘ãªã„ã®ã§ã—ã‚‡ã†ã‹ï¼ŸA: ã„ãˆã€ã“ã“ã«ã‚ã‚‹ã™ã¹ã¦ã‚’ã‚„ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚é¢æ¥ã§ä½•ã‚’èã‹ã‚Œã‚‹ã‹ã¯ä»¥ä¸‹ã®æ¡ä»¶ã«ã‚ˆã£ã¦å¤‰ã‚ã£ã¦ãã¾ã™:ã©ã‚Œã ã‘ã®æŠ€è¡“çµŒé¨“ãŒã‚ã‚‹ã‹ã‚ãªãŸã®æŠ€è¡“èƒŒæ™¯ãŒä½•ã§ã‚ã‚‹ã‹ã©ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ãŸã‚ã«é¢æ¥ã‚’å—ã‘ã¦ã„ã‚‹ã‹ã©ã®ä¼æ¥­ã®é¢æ¥ã‚’å—ã‘ã¦ã„ã‚‹ã‹é‹ã‚ˆã‚ŠçµŒé¨“ã®ã‚ã‚‹å€™è£œè€…ã¯ä¸€èˆ¬çš„ã«ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«ã¤ã„ã¦ã‚ˆã‚Šæ·±ã„çŸ¥è­˜ã‚’æœ‰ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¦æ±‚ã•ã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã‚„ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ã¯å„ãƒ¡ãƒ³ãƒãƒ¼ã®æŒã¤ã‚ˆã†ãªçŸ¥è­˜ã‚ˆã‚Šã¯æ·±ã„è¦‹è­˜ã‚’æŒã£ã¦ã„ã‚‹ã¹ãã§ã—ã‚‡ã†ã€‚ä¸€æµãƒ†ãƒƒã‚¯ä¼æ¥­ã§ã¯è¤‡æ•°å›ã®è¨­è¨ˆé¢æ¥ã‚’èª²ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ã¾ãšã¯åºƒãå§‹ã‚ã¦ã€ãã“ã‹ã‚‰ã„ãã¤ã‹ã®åˆ†é‡ã«çµã£ã¦æ·±ã‚ã¦ã„ãã®ãŒã„ã„ã§ã—ã‚‡ã†ã€‚æ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦å°‘ã—ãšã¤çŸ¥ã£ã¦ãŠãã“ã¨ã¯ã„ã„ã“ã¨ã§ã™ã€‚ä»¥ä¸‹ã®å­¦ç¿’ã‚¬ã‚¤ãƒ‰ã‚’è‡ªåˆ†ã®å­¦ç¿’ã«å½“ã¦ã‚‰ã‚Œã‚‹æ™‚é–“ã€æŠ€è¡“çµŒé¨“ã€ã©ã®è·ä½ã€ã©ã®ä¼šç¤¾ã«å¿œå‹Ÿã—ã¦ã„ã‚‹ã‹ãªã©ã‚’åŠ å‘³ã—ã¦è‡ªåˆ†ç”¨ã«èª¿æ•´ã—ã¦ä½¿ã†ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚çŸ­æœŸé–“ - å¹…åºƒã ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚ã„ãã¤ã‹ã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚ä¸­æœŸé–“ - å¹…åºƒã ãã—ã¦ ãã‚Œãªã‚Šã«æ·±ãã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚å¤šãã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚é•·æœŸé–“ - å¹…åºƒã ãã—ã¦ ã‚‚ã£ã¨æ·±ãã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚ã»ã¼å…¨ã¦ã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚çŸ­æœŸé–“ä¸­æœŸé–“é•·æœŸé–“ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ ã‚’èª­ã¿ã€ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œæ©Ÿåºã«ã¤ã„ã¦åºƒãçŸ¥ã‚‹ğŸ‘ğŸ‘ğŸ‘æ¬¡ã®ãƒªãƒ³ã‚¯å…ˆã®ã„ãã¤ã‹ã®ãƒšãƒ¼ã‚¸ã‚’èª­ã‚“ã§ å„ä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ–ãƒ­ã‚° å¿œå‹Ÿã™ã‚‹ä¼šç¤¾ã«ã¤ã„ã¦çŸ¥ã‚‹ğŸ‘ğŸ‘ğŸ‘æ¬¡ã®ãƒªãƒ³ã‚¯å…ˆã®ã„ãã¤ã‹ã®ãƒšãƒ¼ã‚¸ã‚’èª­ã‚€ å®Ÿä¸–ç•Œã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ğŸ‘ğŸ‘ğŸ‘å¾©ç¿’ã™ã‚‹ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«ã©ã®ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã‹ğŸ‘ğŸ‘ğŸ‘ã¨ã‚Šã‚ãˆãšä¸€å‘¨ã™ã‚‹ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹SomeManyMostã¨ã‚Šã‚ãˆãšä¸€å‘¨ã™ã‚‹ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆå•é¡Œã¨è§£ç­”SomeManyMostå¾©ç¿’ã™ã‚‹ ãã®ä»–ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§ã®è³ªå•ä¾‹SomeManyMostã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã«ã©ã®ã‚ˆã†ã«ã—ã¦è‡¨ã‚ã°ã„ã„ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥è©¦é¨“å•é¡Œã«ã©ã®ã‚ˆã†ã«å–ã‚Šçµ„ã‚€ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã¯ open-ended conversation(Yes/Noã§ã¯ç­”ãˆã‚‰ã‚Œãªã„å£é ­è³ªå•)ã§ã™ã€‚ è‡ªåˆ†ã§ä¼šè©±ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã«å¾“ã£ã¦è­°è«–ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã“ã¨ãŒã§ãã‚‹ã§ã—ã‚‡ã†ã€‚ã“ã®éç¨‹ã‚’ç¢ºã‹ãªã‚‚ã®ã«ã™ã‚‹ãŸã‚ã«ã€æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ã¨ãã®è§£ç­” ã‚’ä»¥ä¸‹ã®æŒ‡é‡ã«å¾“ã£ã¦èª­ã¿è¾¼ã‚€ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚ã‚¹ãƒ†ãƒƒãƒ— 1: ãã®ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ä¾‹ã®æ¦‚è¦ã€åˆ¶ç´„ã€æ¨è¨ˆå€¤ç­‰ã‚’èãå‡ºã—ã€ã¾ã¨ã‚ã‚‹ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜ã®è¦æ±‚äº‹é …ã‚’èãå‡ºã—ã€å•é¡Œç®‡æ‰€ã‚’ç‰¹å®šã—ã¾ã—ã‚‡ã†ã€‚ä½¿ç”¨ä¾‹ã¨åˆ¶ç´„ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã®è³ªå•ã‚’æŠ•ã’ã‹ã‘ã¾ã—ã‚‡ã†ã€‚è¦æ±‚ã™ã‚‹æ¨è¨ˆå€¤ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚èª°ãŒãã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã†ã®ã‹ï¼Ÿã©ã®ã‚ˆã†ã«ä½¿ã†ã®ã‹ï¼Ÿä½•äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã„ã‚‹ã®ã‹ï¼Ÿã‚·ã‚¹ãƒ†ãƒ ã¯ã©ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’æœãŸã™ã®ã‹ï¼Ÿã‚·ã‚¹ãƒ†ãƒ ã¸ã®å…¥åŠ›ã¨å‡ºåŠ›ã¯ï¼Ÿã©ã‚Œã ã‘ã®å®¹é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒãå¿…è¦ãŒã‚ã‚‹ã®ã‹ï¼Ÿä¸€ç§’é–“ã«ä½•ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é€ä¿¡ãŒæƒ³å®šã•ã‚Œã‚‹ã‹ï¼Ÿèª­ã¿æ›¸ãæ¯”ç‡ã®æ¨å®šå€¤ã¯ã„ãã‚‰ç¨‹åº¦ã‹ï¼Ÿã‚¹ãƒ†ãƒƒãƒ— 2: ã‚ˆã‚Šé«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’çµ„ã¿ç«‹ã¦ã‚‹é‡è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å…¨ã¦è€ƒæ…®ã—ãŸé«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ¦‚è¦ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¨æ¥ç¶šã‚’ã‚¹ã‚±ãƒƒãƒã—ã¦æ›¸ãå‡ºã™è€ƒãˆã®è£ä»˜ã‘ã‚’ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ— 3: æ ¸ã¨ãªã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è¨­è¨ˆã™ã‚‹ãã‚Œãã‚Œã®ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦ã®è©³ç´°ã‚’å­¦ã¶ã€‚ä¾‹ãˆã°ã€urlçŸ­ç¸®ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆã‚’å•ã‚ã‚ŒãŸéš›ã«ã¯æ¬¡ã®ã‚ˆã†ã«ã™ã‚‹ã¨ã„ã„ã§ã—ã‚‡ã†:å…ƒã®URLã®ãƒãƒƒã‚·ãƒ¥åŒ–ã—ãŸã‚‚ã®ã‚’ä½œã‚Šã€ãã‚Œã‚’ä¿å­˜ã™ã‚‹MD5 ã¨ Base62ãƒãƒƒã‚·ãƒ¥è¡çªSQL ã‚‚ã—ãã¯ NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚ŒãŸURLã‚’å…ƒã®URLã«å†ç¿»è¨³ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‚ç…§API & ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã®è¨­è¨ˆã‚¹ãƒ†ãƒƒãƒ— 4: ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ã‚¹ã‚±ãƒ¼ãƒ«ä¸ãˆã‚‰ã‚ŒãŸåˆ¶ç´„æ¡ä»¶ã‹ã‚‰ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚Šãã†ãªã¨ã“ã‚ã‚’å‰²ã‚Šå‡ºã—ã€æ˜ç¢ºåŒ–ã™ã‚‹ã€‚  ä¾‹ãˆã°ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®å•é¡Œè§£æ±ºã®ãŸã‚ã«ä»¥ä¸‹ã®è¦ç´ ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å–ã‚Šã†ã‚‹è§£æ±ºç­–ã¨ãã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦è­°è«–ã‚’ã—ã‚ˆã†ã€‚å…¨ã¦ã®ã“ã¨ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ã€‚ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ã¤ã„ã¦ã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®åŸç†ã‚’èª­ã‚€ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚ã¡ã‚‡ã£ã¨ã—ãŸæš—ç®—å•é¡Œã¡ã‚‡ã£ã¨ã—ãŸæ¨è¨ˆå€¤ã‚’æ‰‹è¨ˆç®—ã§ã™ã‚‹ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚è£œéºã®ä»¥ä¸‹ã®é …ç›®ãŒå½¹ã«ç«‹ã¤ã§ã—ã‚‡ã†:ãƒãƒ©è£è¨ˆç®—ã§ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã™ã‚‹2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã£ã¦ãŠãã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®å‚è€ƒå€¤æ–‡çŒ®ã¨ãã®ä»–ã®å‚è€ƒè³‡æ–™ä»¥ä¸‹ã®ãƒªãƒ³ã‚¯å…ˆãƒšãƒ¼ã‚¸ã‚’è¦‹ã¦ã©ã®ã‚ˆã†ãªè³ªå•ã‚’æŠ•ã’ã‹ã‘ã‚‰ã‚Œã‚‹ã‹æ¦‚è¦ã‚’é ­ã«å…¥ã‚Œã¦ãŠãã¾ã—ã‚‡ã†:ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§æˆåŠŸã™ã‚‹ã«ã¯ï¼Ÿã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã¸ã®å°å…¥ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ã¨ãã®è§£ç­”é »å‡ºã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨å‚è€ƒè§£ç­”ã€ã‚³ãƒ¼ãƒ‰åŠã³ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è§£ç­”ã¯ solutions/ ãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã‚‹å•é¡ŒPastebin.com (ã‚‚ã—ãã¯ Bit.ly) ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Twitterã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ (ã‚‚ã—ãã¯Facebookãƒ•ã‚£ãƒ¼ãƒ‰)ã‚’è¨­è¨ˆã™ã‚‹Twitteræ¤œç´¢(ã‚‚ã—ãã¯Facebookæ¤œç´¢)æ©Ÿèƒ½ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”ã‚¦ã‚§ãƒ–ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Mint.comã‚’è¨­è¨ˆã™ã‚‹è§£ç­”SNSã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Amazonã®ã‚«ãƒ†ã‚´ãƒªæ¯ã®å£²ã‚Šä¸Šã’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”AWSä¸Šã§100ä¸‡äººè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå•é¡Œã‚’è¿½åŠ ã™ã‚‹ContributePastebin.com (ã‚‚ã—ãã¯ Bit.ly) ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Twitterã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³&æ¤œç´¢ (ã‚‚ã—ãã¯Facebookãƒ•ã‚£ãƒ¼ãƒ‰&æ¤œç´¢)ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹ã‚¦ã‚§ãƒ–ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®è¨­è¨ˆå•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Mint.comã®è¨­è¨ˆå•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹SNSã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Amazonã®ã‚«ãƒ†ã‚´ãƒªæ¯ã®å£²ã‚Šä¸Šã’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹AWSä¸Šã§100ä¸‡äººè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆå•é¡Œã¨è§£ç­”é »å‡ºã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨å‚è€ƒè§£ç­”ã€ã‚³ãƒ¼ãƒ‰åŠã³ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è§£ç­”ã¯ solutions/ ãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã‚‹å‚™è€ƒ: ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ä½œæ¥­ä¸­ã§ã™å•é¡Œãƒãƒƒã‚·ãƒ¥ãƒãƒƒãƒ—ã®è¨­è¨ˆè§£ç­”LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¨­è¨ˆè§£ç­”ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼ã®è¨­è¨ˆè§£ç­”ã‚«ãƒ¼ãƒ‰ã®ãƒ‡ãƒƒã‚­ã®è¨­è¨ˆè§£ç­”é§è»Šå ´ã®è¨­è¨ˆè§£ç­”ãƒãƒ£ãƒƒãƒˆã‚µãƒ¼ãƒãƒ¼ã®è¨­è¨ˆè§£ç­”å††å½¢é…åˆ—ã®è¨­è¨ˆContributeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå•é¡Œã‚’è¿½åŠ ã™ã‚‹Contributeã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚¹: ã¾ãšã¯ã“ã“ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®å‹‰å¼·ã¯åˆã‚ã¦ï¼Ÿã¾ãšåˆã‚ã«ã€ã‚ˆãä½¿ã‚ã‚Œã‚‹è¨­è¨ˆåŸç†ã«ã¤ã„ã¦ã€ãã‚Œã‚‰ãŒä½•ã§ã‚ã‚‹ã‹ã€ã©ã®ã‚ˆã†ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã‹ã€é•·æ‰€çŸ­æ‰€ã«ã¤ã„ã¦åŸºæœ¬çš„ãªçŸ¥è­˜ã‚’å¾—ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‚¹ãƒ†ãƒƒãƒ— 1: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹å‹•ç”»ã‚’è¦³ã¦å¾©ç¿’ã™ã‚‹Harvardã§ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®è¬›ç¾©ã“ã“ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚¹:å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒƒãƒ— 2: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹è³‡æ–™ã‚’èª­ã‚“ã§å¾©ç¿’ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã“ã“ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚¹:ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥éåŒæœŸæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—æ¬¡ã«ã€ãƒã‚¤ãƒ¬ãƒ™ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦ã¿ã¦ã„ã:ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¯ç”¨æ€§ vs ä¸€è²«æ€§å…¨ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ã¨ã„ã†ã®ã‚’è‚ã«å‘½ã˜ã¦ãŠãã¾ã—ã‚‡ã†ã€‚ãã‚Œã‹ã‚‰ã€ã‚ˆã‚Šæ·±ã„å†…å®¹ã€DNSã‚„CDNãã—ã¦ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãªã©ã«ã¤ã„ã¦å­¦ç¿’ã‚’é€²ã‚ã¦ã„ãã¾ã—ã‚‡ã†ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒªã‚½ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚Œã‚‹ã®ã«ã¤ã‚Œã¦ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãŒå‘ä¸Šã™ã‚‹å ´åˆãã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ« ã§ã‚ã‚‹ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚ä¸€èˆ¬çš„ã«ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã¨ã„ã†ã®ã¯ã™ãªã‚ã¡è¨ˆç®—å‡¦ç†ã‚’å¢—ã‚„ã™ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¢—ãˆãŸæ™‚ãªã©ã‚ˆã‚Šå¤§ããªå‡¦ç†ã‚’æŒã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚1ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹vsã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’ã¨ã‚‰ãˆã‚‹ä»–ã®è€ƒãˆæ–¹:ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ã§ã®å•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹æ™‚ã€ã‚ãªãŸã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä¸€äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦é…ã„ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ ã§ã®å•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹ã¨ãã€ä¸€äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã¯é€Ÿã„ã§ã™ãŒã€å¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚ã‚‹æ™‚ã«ã¯é…ããªã£ã¦ã—ã¾ã†ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«ã¤ã„ã¦ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€å¯ç”¨æ€§ã€å®‰å®šæ€§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ã¨ã¯ãªã«ãŒã—ã‹ã®å‹•ä½œã‚’è¡Œã†ã€ã‚‚ã—ãã¯çµæœã‚’ç®—å‡ºã™ã‚‹ã®ã«è¦ã™ã‚‹æ™‚é–“ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ ã¨ã¯ãã®ã‚ˆã†ãªå‹•ä½œã‚„çµæœç®—å‡ºãŒå˜ä½æ™‚é–“ã«è¡Œã‚ã‚Œã‚‹å›æ•°ä¸€èˆ¬çš„ã«ã€ æœ€å¤§é™ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ ã‚’ è¨±å®¹ç¯„å›²å†…ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ã§å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã®ãŒæ™®é€šã ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç†è§£ã™ã‚‹å¯ç”¨æ€§ vs ä¸€è²«æ€§CAP ç†è«–      Source: CAP theorem revisitedåˆ†æ•£å‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã¯ä¸‹ã®ä¸‰ã¤ã®ã†ã¡äºŒã¤ã¾ã§ã—ã‹åŒæ™‚ã«ä¿è¨¼ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€‚:ä¸€è²«æ€§ - å…¨ã¦ã®èª­ã¿è¾¼ã¿ã¯æœ€æ–°ã®æ›¸ãè¾¼ã¿ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã‚’å—ã‘å–ã‚‹å¯ç”¨æ€§ - å—ã‘å–ã‚‹æƒ…å ±ãŒæœ€æ–°ã®ã‚‚ã®ã ã¨ã„ã†ä¿è¨¼ã¯ãªã„ãŒã€å…¨ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¿…ãšå—ã‘å–ã‚‹åˆ†æ–­è€æ€§ - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œã«ã‚ˆã£ã¦é †ä¸åŒã®åˆ†æ–­ãŒèµ·ãã¦ã‚‚ã‚·ã‚¹ãƒ†ãƒ ãŒå‹•ä½œã‚’ç¶šã‘ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ä¿¡é ¼ã§ããªã„ã®ã§ã€åˆ†æ–­è€æ€§ã¯å¿…ãšä¿è¨¼ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ã¤ã¾ã‚Šã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã¯ã€ä¸€è²«æ€§ã‚’å–ã‚‹ã‹ã€å¯ç”¨æ€§ã‚’å–ã‚‹ã‹ã‚’è€ƒãˆãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚CP - ä¸€è²«æ€§ã¨åˆ†æ–­è€æ€§(consistency and partition tolerance)åˆ†æ–­ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¾…ã¡ç¶šã‘ã¦ã„ã‚‹ã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã«é™¥ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚CPã¯ã‚ãªãŸã®ã‚µãƒ¼ãƒ“ã‚¹ãŒã‚¢ãƒˆãƒŸãƒƒã‚¯ãªèª­ã¿æ›¸ãï¼ˆä¸å¯åˆ†æ“ä½œï¼‰ã‚’å¿…è¦ã¨ã™ã‚‹éš›ã«ã¯ã„ã„é¸æŠè‚¢ã§ã—ã‚‡ã†ã€‚AP - å¯ç”¨æ€§ã¨åˆ†æ–­è€æ€§(availability and partition tolerance)ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ãƒãƒ¼ãƒ‰ä¸Šã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã§æœ€æ–°ã®ã‚‚ã®ã‚’è¿”ã—ã¾ã™ã€‚ã¤ã¾ã‚Šã€æœ€æ–°ç‰ˆã®ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚åˆ†æ–­ãŒè§£æ¶ˆã•ã‚ŒãŸå¾Œã‚‚ã€æ›¸ãè¾¼ã¿ãŒåæ˜ ã•ã‚Œã‚‹ã®ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚çµæœæ•´åˆæ€§ã€€ã‚’æ±‚ã‚ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®éš›ã«ã¯APã‚’æ¡ç”¨ã™ã‚‹ã®ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã‚‚ã—ãã¯ã€å¤–éƒ¨ã‚¨ãƒ©ãƒ¼ã«é–¢ã‚ã‚‰ãšã‚·ã‚¹ãƒ†ãƒ ãŒç¨¼åƒã™ã‚‹å¿…è¦ãŒã‚ã‚‹éš›ã«ã‚‚åŒæ§˜ã§ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸CAP ç†è«–ã‚’æŒ¯ã‚Šè¿”ã‚‹å¹³æ˜“ãªè‹±èªã§ã®CAP ç†è«–ã®ã‚¤ãƒ³ãƒˆãƒ­CAP FAQä¸€è²«æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³åŒã˜ãƒ‡ãƒ¼ã‚¿ã®è¤‡è£½ãŒè¤‡æ•°ã‚ã‚‹çŠ¶æ…‹ã§ã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒä¸€è²«ã—ãŸãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚’å—ã‘å–ã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ã«ãã‚Œã‚‰ã‚’åŒæœŸã™ã‚Œã°ã„ã„ã®ã‹ã¨ã„ã†èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ CAP ç†è«– ã«ãŠã‘ã‚‹ä¸€è²«æ€§ã®å®šç¾©ã‚’æ€ã„å‡ºã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚å…¨ã¦ã®èª­ã¿å–ã‚Šã¯æœ€æ–°ã®æ›¸ãè¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã‚’å—ã‘å–ã‚‹ã¯ãšã§ã™ã€‚å¼±ã„ä¸€è²«æ€§æ›¸ãè¾¼ã¿å¾Œã®èª­ã¿å–ã‚Šã§ã¯ã€ãã®æœ€æ–°ã®æ›¸ãè¾¼ã¿ã‚’èª­ã‚ãŸã‚Šèª­ã‚ãªã‹ã£ãŸã‚Šã™ã‚‹ã€‚ãƒ™ã‚¹ãƒˆã‚¨ãƒ•ã‚©ãƒ¼ãƒˆå‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«åŸºã¥ãã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯memcachedãªã©ã®ã‚·ã‚¹ãƒ†ãƒ ã«è¦‹ã‚‰ã‚Œã¾ã™ã€‚å¼±ã„ä¸€è²«æ€§ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒå¿…è¦ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã€ä¾‹ãˆã°VoIPã€ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ«ãƒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚²ãƒ¼ãƒ ãªã©ã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ä¾‹ãˆã°ã€é›»è©±ã«å‡ºã¦ã„ã‚‹ã¨ãã«æ•°ç§’é–“éŸ³å£°ãŒå—ã‘å–ã‚Œãªããªã£ãŸã¨ã—ãŸã‚‰ã€ãã®å¾Œã«æ¥ç¶šãŒå›å¾©ã—ã¦ã‚‚ãã®æ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¦ã„ãŸé–“ã«è©±ã•ã‚Œã¦ã„ãŸã“ã¨ã¯èãå–ã‚Œãªã„ã¨ã„ã†ã‚ˆã†ãªæ„Ÿã˜ã§ã™ã€‚çµæœæ•´åˆæ€§æ›¸ãè¾¼ã¿ã®å¾Œã€èª­ã¿å–ã‚Šã¯æœ€çµ‚çš„ã«ã¯ãã®çµæœã‚’èª­ã¿å–ã‚‹ã“ã¨ãŒã§ãã‚‹(ãƒŸãƒªç§’ã»ã©é…ã‚Œã¦ã¨ã„ã†ã®ãŒä¸€èˆ¬çš„ã§ã™)ã€‚ãƒ‡ãƒ¼ã‚¿ã¯éåŒæœŸçš„ã«è¤‡è£½ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯DNSã‚„ãƒ¡ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãªã©ã«æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚çµæœæ•´åˆæ€§ã¯å¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚å¼·ã„ä¸€è²«æ€§æ›¸ãè¾¼ã¿ã®å¾Œã€èª­ã¿å–ã‚Šã¯ãã‚Œã‚’å¿…ãšèª­ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯åŒæœŸçš„ã«è¤‡è£½ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚„RDBMSãªã©ã§æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ‰±ã†ã‚µãƒ¼ãƒ“ã‚¹ã§ã¯å¼·ã„ä¸€è²«æ€§ãŒå¿…è¦ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼é–“ã§ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¯ç”¨æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³é«˜ã„å¯ç”¨æ€§ã‚’æ‹…ä¿ã™ã‚‹ã«ã¯ä¸»ã«æ¬¡ã®äºŒã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã™: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ ã¨ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã§ã™ã€‚ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã«ãŠã„ã¦ã¯ã€å‘¨æœŸä¿¡å·ã¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚‚ã—ãã¯ã‚¹ã‚¿ãƒ³ãƒã‚¤ä¸­ã®ãƒ‘ãƒƒã‚·ãƒ–ãªã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œã¾ã™ã€‚å‘¨æœŸä¿¡å·ãŒä¸­æ–­ã•ã‚ŒãŸæ™‚ã«ã¯ã€ãƒ‘ãƒƒã‚·ãƒ–ã ã£ãŸã‚µãƒ¼ãƒãƒ¼ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒ¼ãƒãƒ¼ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å¼•ãç¶™ã„ã§ã‚µãƒ¼ãƒ“ã‚¹ã‚’å†é–‹ã—ã¾ã™ã€‚èµ·å‹•ã¾ã§ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã¯ãƒ‘ãƒƒã‚·ãƒ–ã‚µãƒ¼ãƒãƒ¼ãŒã€Œãƒ›ãƒƒãƒˆã€ãªã‚¹ã‚¿ãƒ³ãƒã‚¤çŠ¶æ…‹ã«ã‚ã‚‹ã‹ã€ã€Œã‚³ãƒ¼ãƒ«ãƒ‰ã€ãªã‚¹ã‚¿ãƒ³ãƒã‚¤çŠ¶æ…‹ã«ã‚ã‚‹ã‹ã§å¤‰ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚µãƒ¼ãƒãƒ¼ã®ã¿ãŒãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ§‹æˆã§ã¯ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã“ã¨ã§è² è·ã‚’åˆ†æ•£ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒ‘ãƒ–ãƒªãƒƒã‚¯ãªã‚‚ã®ã®å ´åˆã€DNSã¯ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ã®ãƒ‘ãƒ–ãƒªãƒƒã‚¯IPã‚’çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚‚ã—ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªã‚‚ã®ãªå ´åˆã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ãŒä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã«ã¤ã„ã¦çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚çŸ­æ‰€: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã§ã¯ã‚ˆã‚Šå¤šãã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’è¦ã—ã€è¤‡é›‘ã•ãŒå¢—ã—ã¾ã™ã€‚æœ€æ–°ã®æ›¸ãè¾¼ã¿ãŒãƒ‘ãƒƒã‚·ãƒ–ã‚µãƒ¼ãƒãƒ¼ã«è¤‡è£½ã•ã‚Œã‚‹å‰ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãŒè½ã¡ã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿æ¬ æãŒèµ·ãã‚‹æ½œåœ¨å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–ã€€ã¨ã€€ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã¯ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã‚ˆã‚Šè©³ç´°ã«è§£èª¬ã•ã‚Œã¦ã„ã¾ã™:ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ       Source: DNS security presentationãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (DNS) ã¯ www.example.com ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚’IPã‚¢ãƒ‰ãƒ¬ã‚¹ã¸ã¨ç¿»è¨³ã—ã¾ã™ã€‚DNSã¯å°‘æ•°ã®ã‚ªãƒ¼ã‚½ãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ãŒä¸Šä½ã«ä½ç½®ã™ã‚‹éšå±¤çš„æ§‹é€ ã§ã™ã€‚ã‚ãªãŸã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚‚ã—ãã¯ISPã¯æ¤œç´¢ã‚’ã™ã‚‹éš›ã«ã©ã®DNSã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã‹ã¨ã„ã†æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚ä½ã„éšå±¤ã®DNSã‚µãƒ¼ãƒãƒ¼ã¯ãã®çµŒè·¯ãƒãƒƒãƒ—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚ãŸã ã€ã“ã®æƒ…å ±ã¯ä¼æ¬é…å»¶ã«ã‚ˆã£ã¦é™³è…åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚DNSã®çµæœã¯ã‚ãªãŸã®ãƒ–ãƒ©ã‚¦ã‚¶ã‚‚ã—ãã¯OSã«ä¸€å®šæœŸé–“ï¼ˆtime to live (TTL)ã«è¨­å®šã•ã‚ŒãŸæœŸé–“ï¼‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ã€‚NS record (name server) - ã‚ãªãŸã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®DNSã‚µãƒ¼ãƒãƒ¼ã‚’ç‰¹å®šã—ã¾ã™ã€‚MX record (mail exchange) - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚µãƒ¼ãƒãƒ¼ã‚’ç‰¹å®šã—ã¾ã™ã€‚A record (address) - IPã‚¢ãƒ‰ãƒ¬ã‚¹ã«åå‰ã‚’ã¤ã‘ã¾ã™ã€‚CNAME (canonical) - ä»–ã®åå‰ã‚‚ã—ãã¯ã€€CNAME (example.com ã‚’ www.example.com) ã‚‚ã—ãã¯ A recordã¸ã¨åå‰ã‚’æŒ‡ã—ç¤ºã™ã€‚CloudFlare ã‚„ Route 53 ãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒãƒãƒ¼ã‚¸ãƒ‰DNSã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã„ãã¤ã‹ã®DNSã‚µãƒ¼ãƒ“ã‚¹ã§ã¯æ§˜ã€…ãªæ‰‹æ³•ã‚’ä½¿ã£ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã“ã¨ãŒã§ãã¾ã™:åŠ é‡ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã®ã‚µãƒ¼ãƒãƒ¼ã«è¡Œãã®ã‚’é˜²ãã¾ã™æ§˜ã€…ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´ã—ã¾ã™A/B ãƒ†ã‚¹ãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãƒ™ãƒ¼ã‚¹åœ°ç†ãƒ™ãƒ¼ã‚¹æ¬ ç‚¹: DNSä¸Šè¨˜ã§ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã«ã‚ˆã£ã¦ç·©å’Œã•ã‚Œã¦ã„ã‚‹ã¨ã¯ã„ãˆã€DNSã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã«ã¯å°‘ã—é…å»¶ãŒç”Ÿã˜ã‚‹ã€‚DNSã‚µãƒ¼ãƒãƒ¼ã¯ã€æ”¿åºœã€ISPä¼æ¥­,ãã—ã¦å¤§ä¼æ¥­ã«ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãŒã€ãã‚Œã‚‰ã®ç®¡ç†ã¯è¤‡é›‘ã§ã‚ã‚‹ã€‚DNSã‚µãƒ¼ãƒ“ã‚¹ã¯DDoS attackã®ä¾‹ã§ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ãªã—ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒTwitterãªã©ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªããªã£ãŸã‚ˆã†ã«ã€æ”»æ’ƒã‚’å—ã‘ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸DNS ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£WikipediaDNS è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(Content delivery network)      Source: Why use a CDNã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CDN)ã¯ä¸–ç•Œä¸­ã«é…ç½®ã•ã‚ŒãŸãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¸€ç•ªåœ°ç†çš„ã«è¿‘ã„ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é…ä¿¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®ã“ã¨ã§ã™ã€‚Amazonã®CloudFrontãªã©ã¯ä¾‹å¤–çš„ã«ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚é…ä¿¡ã—ã¾ã™ãŒã€ä¸€èˆ¬çš„ã«ã€HTML/CSS/JSã€å†™çœŸã€ãã—ã¦å‹•ç”»ãªã©ã®é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãŒCDNã‚’é€šã˜ã¦é…ä¿¡ã•ã‚Œã¾ã™ã€‚ãã®ã‚µã‚¤ãƒˆã®DNSãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã©ã®ã‚µãƒ¼ãƒãƒ¼ã¨äº¤ä¿¡ã™ã‚‹ã‹ã¨ã„ã†æƒ…å ±ã‚’ä¼ãˆã¾ã™ã€‚CDNã‚’ç”¨ã„ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é…ä¿¡ã™ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®äºŒã¤ã®ç†ç”±ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒåŠ‡çš„ã«å‘ä¸Šã—ã¾ã™:ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è¿‘ãã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰å—ä¿¡ã§ãã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã¯CDNãŒå‡¦ç†ã—ã¦ãã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«é–¢ã—ã¦ã¯å‡¦ç†ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ãƒ—ãƒƒã‚·ãƒ¥CDNãƒ—ãƒƒã‚·ãƒ¥CDNã§ã¯ã‚µãƒ¼ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ã«æ›´æ–°ãŒã‚ã£ãŸæ™‚ã«ã¯å¿…ãšã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å—ã‘å–ã‚‹æ–¹å¼ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”¨æ„ã—ã€CDNã«ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€URLã‚’CDNã‚’æŒ‡ã™ã‚ˆã†ã«æŒ‡å®šã™ã‚‹ã¨ã“ã‚ã¾ã§ã€å…¨ã¦è‡ªåˆ†ã§è²¬ä»»ã‚’è² ã†å½¢ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã„ã¤æœŸé™åˆ‡ã‚Œã«ãªã‚‹ã®ã‹æ›´æ–°ã•ã‚Œã‚‹ã®ã‹ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ–°è¦ä½œæˆæ™‚ã€æ›´æ–°æ™‚ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã“ã¨ã§ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã¯æœ€å°åŒ–ã•ã‚Œã‚‹ä¸€æ–¹ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¯æœ€å¤§é™æ¶ˆè²»ã•ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å°‘ãªã„ã€ã‚‚ã—ãã¯é »ç¹ã«ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ›´æ–°ã•ã‚Œãªã„ã‚µã‚¤ãƒˆã®å ´åˆã«ã¯ãƒ—ãƒƒã‚·ãƒ¥CDNã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å®šæœŸçš„ã«å†ã³ãƒ—ãƒ«ã•ã‚Œã‚‹ã®ã§ã¯ãªãã€CDNã«ä¸€åº¦ã®ã¿é…ç½®ã•ã‚Œã¾ã™ã€‚ãƒ—ãƒ«CDNãƒ—ãƒ«CDNã§ã¯ä¸€äººç›®ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãŸæ™‚ã«ã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å–å¾—ã—ã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯è‡ªåˆ†ã®ã‚µãƒ¼ãƒãƒ¼ã«ä¿å­˜ã—ã¦ã€CDNã‚’æŒ‡ã™URLã‚’æ›¸ãæ›ãˆã¾ã™ã€‚çµæœã¨ã—ã¦ã€CDNã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã¾ã§ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ãŒé…ããªã‚Šã¾ã™ã€‚time-to-live (TTL) ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã©ã‚Œã ã‘ã®æœŸé–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã‹ã‚’è¦å®šã—ã¾ã™ã€‚ãƒ—ãƒ«CDNã¯CDN ä¸Šã§ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¹ãƒšãƒ¼ã‚¹ã‚’æœ€å°åŒ–ã—ã¾ã™ãŒã€æœ‰åŠ¹æœŸé™ãŒåˆ‡ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›´æ–°å‰ã«ãƒ—ãƒ«ã•ã‚Œã¦ã—ã¾ã†ã“ã¨ã§å†—é•·ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«ç¹‹ãŒã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å¤§è¦æ¨¡ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ã‚ã‚‹ã‚µã‚¤ãƒˆã§ã¯ãƒ—ãƒ«CDNãŒç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã¨ã„ã†ã®ã‚‚ã€ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å¤§éƒ¨åˆ†ã¯æœ€è¿‘ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚Œã€CDNã«æ®‹ã£ã¦ã„ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã‹ã‚‰ã§ã™ã€‚æ¬ ç‚¹: CDNCDNã®ã‚³ã‚¹ãƒˆã¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯é‡ã«ã‚ˆã£ã¦å¤‰ã‚ã‚Šã¾ã™ã€‚ã‚‚ã¡ã‚ã‚“ã€CDNã‚’ä½¿ã‚ãªã„å ´åˆã®ã‚³ã‚¹ãƒˆã¨æ¯”è¼ƒã™ã‚‹ã¹ãã§ã—ã‚‡ã†ã€‚TTLãŒåˆ‡ã‚Œã‚‹å‰ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ›´æ–°ã•ã‚Œã‚‹ã¨é™³è…åŒ–ã™ã‚‹æã‚ŒãŒã‚ã‚Šã¾ã™ã€‚CDNã§ã¯é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒCDNã‚’æŒ‡ã™ã‚ˆã†ã«URLã‚’æ›´æ–°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«åˆ†æ•£ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ—ãƒƒã‚·ãƒ¥CDNã¨ãƒ—ãƒ«CDNã®é•ã„Wikipediaãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼      Source: Scalable system design patternsãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯å…¥åŠ›ã•ã‚Œã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã¨åˆ†æ•£ã•ã›ã‚‹ã€‚ã©ã®ã‚±ãƒ¼ã‚¹ã§ã‚‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ã‚µãƒ¼ãƒãƒ¼ç­‰è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é©åˆ‡ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è¿”ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ä»¥ä¸‹ã®ã“ã¨ã«åŠ¹æœçš„ã§ã™:ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒçŠ¶æ…‹ã®è‰¯ããªã„ã‚µãƒ¼ãƒãƒ¼ã«è¡Œãã®ã‚’é˜²ããƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’éå‰°ã«é€ã‚‹ã®ã‚’é˜²ãç‰¹å®šç®‡æ‰€ã®æ¬ é™¥ã§ã‚µãƒ¼ãƒ“ã‚¹ãŒè½ã¡ã‚‹ã“ã¨ã‚’é˜²ããƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ (è²»ç”¨ã®é«˜ã„) ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚‚ã—ãã¯HAProxyãªã©ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã§å®Ÿç¾ã§ãã‚‹ã€‚ä»–ã®åˆ©ç‚¹ã¨ã—ã¦ã¯:SSL termination - å…¥åŠ›ã•ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£èª­ã™ã‚‹ã€ã¾ãŸã€ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æš—å·åŒ–ã™ã‚‹ã“ã¨ã§ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã‚µãƒ¼ãƒãƒ¼ãŒã“ã®ã‚³ã‚¹ãƒˆãŒé«˜ãã¤ããŒã¡ãªå‡¦ç†ã‚’è«‹ã‘è² ã‚ãªãã¦ã„ã„ã‚ˆã†ã«è‚©ä»£ã‚ã‚Šã—ã¾ã™ã€‚X.509 certificates ã‚’ãã‚Œãã‚Œã®ã‚µãƒ¼ãƒãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ã‚’ãªãã—ã¾ã™ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† - ã‚¯ãƒƒã‚­ãƒ¼ã‚’å–ã‚Šæ‰±ã†ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªãŒã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ãªã„æ™‚ãªã©ã«ã€ç‰¹å®šã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åŒã˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¸ã¨æµã—ã¾ã™ã€‚éšœå®³ã«å¯¾å¿œã™ã‚‹ãŸã‚ã«ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ– ã‚‚ã—ãã¯ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ– ãƒ¢ãƒ¼ãƒ‰ã®ã©ã¡ã‚‰ã«ãŠã„ã¦ã‚‚ã€è¤‡æ•°ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’é…ç½®ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªç¨®ã€…ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç”¨ã„ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™:ãƒ©ãƒ³ãƒ€ãƒ Least loadedã‚»ãƒƒã‚·ãƒ§ãƒ³/ã‚¯ãƒƒã‚­ãƒ¼ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ã‚‚ã—ãã¯åŠ é‡ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³Layer 4Layer 7Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ ã‚’å‚ç…§ã—ã¦ã©ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é…åˆ†ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ã—ã¦ã¯ã€ã‚½ãƒ¼ã‚¹ã€é€ä¿¡å…ˆIPã‚¢ãƒ‰ãƒ¬ã‚¹ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã«è¨˜è¿°ã•ã‚ŒãŸãƒãƒ¼ãƒˆç•ªå·ãŒå«ã¾ã‚Œã¾ã™ãŒã€ãƒ‘ã‚±ãƒƒãƒˆã®ä¸­èº«ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å«ã¿ã¾ã›ã‚“ã€‚ Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‘ã‚±ãƒƒãƒˆã‚’ä¸Šæµã‚µãƒ¼ãƒãƒ¼ã¸å±Šã‘ã€ä¸Šæµã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰é…ä¿¡ã™ã‚‹ã“ã¨ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ‰ãƒ¬ã‚¹å¤‰æ› Network Address Translation (NAT) ã‚’å®Ÿç¾ã—ã¾ã™ã€‚Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ ã‚’å‚ç…§ã—ã¦ã©ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é…åˆ†ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ã‚¯ãƒƒã‚­ãƒ¼ãªã©ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã“ã¨ã§ã™ã€‚Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®çµ‚ç«¯ã‚’å—ã‘æŒã¡ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã®åˆ¤æ–­ã‚’ã—ã€é¸æŠã—ãŸã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šã‚’ç¹‹ãã¾ã™ã€‚ä¾‹ãˆã° layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯å‹•ç”»ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ç›´æ¥ã€ãã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ›ã‚¹ãƒˆã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒãƒ¼ã«ã¤ãªãã¨åŒæ™‚ã«ã€æ±ºæ¸ˆå‡¦ç†ãªã©ã®ã‚ˆã‚Šç¹Šç´°ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ã«æµã™ã¨ã„ã†ã“ã¨ã‚‚ã§ãã‚‹ã€‚æŸ”è»Ÿæ€§ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãªã‚Šã¾ã™ãŒã€ layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ã¯Layer 7ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚ˆã‚Šã‚‚æ‰€è¦æ™‚é–“ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å°‘ãªãæ¸ˆã¾ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãŸã ã—ã€æ˜¨ä»Šã®æ±ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯æœ€å°é™ã®ã¿ã—ã‹ç™ºæ®ã§ããªã„ã§ã—ã‚‡ã†ã€‚æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ã¯æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å¯ç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ‰‹é ƒãªæ±ç”¨ãƒã‚·ãƒ³ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã•ã›ã‚‹æ–¹ãŒã€ä¸€ã¤ã®ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚ˆã‚Šé«˜ä¾¡ãªãƒã‚·ãƒ³ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ï¼ˆå‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã‚ˆã‚Šè²»ç”¨å¯¾åŠ¹æœã‚‚é«˜ããªã‚Šã€çµæœçš„ã«å¯ç”¨æ€§ã‚‚é«˜ããªã‚Šã¾ã™ã€‚ã¾ãŸã€æ±ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ‰±ãˆã‚‹äººæã‚’é›‡ã†æ–¹ãŒã€ç‰¹åŒ–å‹ã®å•†ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ‰±ãˆã‚‹äººæã‚’é›‡ã†ã‚ˆã‚Šã‚‚ç°¡å˜ã§ã—ã‚‡ã†ã€‚æ¬ ç‚¹: æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ°´å¹³çš„ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã„ãã¨ã€è¤‡é›‘ã•ãŒå¢—ã™ä¸Šã«ã€ã‚µãƒ¼ãƒãƒ¼ã®ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã«ãªã‚‹ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢é€£ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚„ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å†™çœŸãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã¯ã„ã‘ãªã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ä¸€å…ƒçš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (SQLã€ NoSQL)ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã«ã‚¹ãƒˆã‚¢ã•ã‚Œã‚‹ã‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ (Redisã€ Memcached)ã«æ®‹ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®ä¸‹æµã‚µãƒ¼ãƒãƒ¼ã¯ä¸Šæµã‚µãƒ¼ãƒãƒ¼ãŒã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã™ã‚‹ã«ã¤ã‚Œã¦ã‚ˆã‚Šå¤šãã®åŒæ™‚æ¥ç¶šã‚’ä¿ãŸãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚æ¬ ç‚¹: ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒªã‚½ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ãŸã‚Šã€è¨­å®šãŒé©åˆ‡ã§ãªã„å ´åˆã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å˜ä¸€éšœå®³ç‚¹ã‚’é™¤ã“ã†ã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’å°å…¥ã—ãŸçµæœã€è¤‡é›‘ã•ãŒå¢—ã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãŒä¸€ã¤ã ã‘ã ã¨ãã“ãŒå˜ä¸€éšœå®³ç‚¹ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚ä¸€æ–¹ã§ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’è¤‡æ•°ã«ã™ã‚‹ã¨ã€ã•ã‚‰ã«è¤‡é›‘ã•ãŒå¢—ã—ã¦ã—ã¾ã„ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸NGINX ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HAProxy ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¬ã‚¤ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£WikipediaLayer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ELB listener configãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·(webã‚µãƒ¼ãƒãƒ¼)      Source: Wikipedia  ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã¯å†…éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã¾ã¨ã‚ã¦å¤–éƒ¨ã«çµ±ä¸€ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãã‚Œã«å¯¾å¿œã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œã¦ã€ãã®å¾Œãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è¿”ã—ã¾ã™ã€‚ä»–ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªåˆ©ç‚¹ãŒã‚ã‚Šã¾ã™:ã‚ˆã‚Šå …ç‰¢ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã‚’éš ã—ãŸã‚Šã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆåŒ–ã—ãŸã‚Šã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã”ã¨ã®æ¥ç¶šæ•°ã‚’åˆ¶é™ã—ãŸã‚Šã§ãã¾ã™ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚„æŸ”è»Ÿæ€§ãŒå¢—ã—ã¾ã™ - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã®IPã—ã‹è¦‹ãªã„ã®ã§ã€è£ã§ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã—ãŸã‚Šã€è¨­å®šã‚’å¤‰ãˆã‚„ã™ããªã‚Šã¾ã™ã€‚SSL termination - å…¥åŠ›ã•ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£èª­ã—ã€ã‚µãƒ¼ãƒãƒ¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æš—å·åŒ–ã™ã‚‹ã“ã¨ã§ã‚µãƒ¼ãƒãƒ¼ãŒã“ã®ã‚³ã‚¹ãƒˆã®ã‹ã‹ã‚Šã†ã‚‹å‡¦ç†ã‚’ã—ãªãã¦æ¸ˆã‚€ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚X.509 è¨¼æ˜æ›¸ ã‚’å„ã‚µãƒ¼ãƒãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚åœ§ç¸® - ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åœ§ç¸®ã§ãã¾ã™ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚° - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã—ã¾ã™é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ - é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥é€ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚HTML/CSS/JSå†™çœŸå‹•ç”»ãªã©ãªã©ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ vs ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·è¤‡æ•°ã®ã‚µãƒ¼ãƒãƒ¼ãŒã‚ã‚‹æ™‚ã«ã¯ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨å½¹ã«ç«‹ã¤ã§ã—ã‚‡ã†ã€‚ ã—ã°ã—ã°ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯åŒã˜æ©Ÿèƒ½ã‚’æœãŸã™ã‚µãƒ¼ãƒãƒ¼ç¾¤ã¸ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã¾ã™ã€‚ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã§ã¯ã€ä¸Šè¨˜ã«è¿°ã¹ãŸã‚ˆã†ãªåˆ©ç‚¹ã‚’ã€å˜ä¸€ã®ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã‚„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å¯¾ã—ã¦ã‚‚ç¤ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚NGINX ã‚„ HAProxy ãªã©ã®æŠ€è¡“ã¯layer 7 ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚æ¬ ç‚¹: ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’å°å…¥ã™ã‚‹ã¨ã‚·ã‚¹ãƒ†ãƒ ã®è¤‡é›‘æ€§ãŒå¢—ã—ã¾ã™ã€‚å˜ä¸€ã®ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã¯å˜ä¸€éšœå®³ç‚¹ã«ãªã‚Šãˆã¾ã™ã€‚ä¸€æ–¹ã§ã€è¤‡æ•°ã®ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’å°å…¥ã™ã‚‹ã¨(ä¾‹: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼) è¤‡é›‘æ€§ã¯ã‚ˆã‚Šå¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· vs ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼NGINX ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HAProxy ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ã‚¬ã‚¤ãƒ‰Wikipediaã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤      Source: Intro to architecting systems for scaleã‚¦ã‚§ãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ (ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å±¤ã¨ã‚‚è¨€ã‚ã‚Œã‚‹) ã¨åˆ†é›¢ã™ã‚‹ã“ã¨ã§ãã‚Œãã‚Œã®å±¤ã‚’ç‹¬ç«‹ã«ã‚¹ã‚±ãƒ¼ãƒ«ã€è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚æ–°ã—ã„APIã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã«è¿½åŠ ã™ã‚‹éš›ã«ã€ä¸å¿…è¦ã«ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚å˜ä¸€è²¬ä»»ã®åŸå‰‡ ã§ã¯ã€å°ã•ã„è‡ªå¾‹çš„ãªã‚µãƒ¼ãƒ“ã‚¹ãŒå”èª¿ã—ã¦å‹•ãã‚ˆã†ã«æå”±ã—ã¦ã„ã¾ã™ã€‚å°ã•ã„ã‚µãƒ¼ãƒ“ã‚¹ã®å°ã•ã„ãƒãƒ¼ãƒ ãŒæ€¥æˆé•·ã®ãŸã‚ã«ã‚ˆã‚Šç©æ¥µçš„ãªè¨ˆç”»ã‚’ç«‹ã¦ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã¯éåŒæœŸå‡¦ç†ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ç‹¬ç«‹ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹ã€å°è¦æ¨¡ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§˜å¼ã§ã‚ã‚‹ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚‚ã“ã®è­°è«–ã«é–¢ä¿‚ã—ã¦ãã‚‹æŠ€è¡“ã§ã—ã‚‡ã†ã€‚ãã‚Œãã‚Œã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ç‹¬è‡ªã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å‡¦ç†ã—ã€æ˜ç¢ºã§è»½é‡ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§é€šä¿¡ã—ã¦ã€ãã®ç›®çš„ã¨ã™ã‚‹æ©Ÿèƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚1ä¾‹ãˆã°Pinterestã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã€ãƒ•ã‚£ãƒ¼ãƒ‰ã€æ¤œç´¢ã€å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãªã©ã§ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼Consulã€ Etcdã€ Zookeeper ãªã©ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®åå‰ã€ã‚¢ãƒ‰ãƒ¬ã‚¹ã€ãƒãƒ¼ãƒˆã®æƒ…å ±ã‚’ç›£è¦–ã™ã‚‹ã“ã¨ã§ã€ã‚µãƒ¼ãƒ“ã‚¹åŒå£«ãŒäº’ã„ã‚’è¦‹ã¤ã‘ã‚„ã™ãã—ã¦ã„ã¾ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ã®å®Œå…¨æ€§ã®ç¢ºèªã«ã¯ Health checks ãŒä¾¿åˆ©ã§ã€ã“ã‚Œã«ã¯ HTTP ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚ Consul ã¨ Etcd ã®ã„ãšã‚Œã‚‚çµ„ã¿è¾¼ã¿ã® key-value store ã‚’æŒã£ã¦ãŠã‚Šã€è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚„å…±æœ‰ãƒ‡ãƒ¼ã‚¿ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¦ãŠãã“ã¨ã«ä½¿ã‚ã‚Œã¾ã™ã€‚æ¬ ç‚¹: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€é‹ç”¨ã€ãã—ã¦ãƒ—ãƒ­ã‚»ã‚¹ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ç·©ãçµã³ä»˜ã‘ã‚‰ã‚ŒãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‚’è¿½åŠ ã™ã‚‹ã«ã¯ã€ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒ‡ãƒ—ãƒ­ã‚¤ã¨é‹ç”¨ã®ç‚¹ã‹ã‚‰è¦‹ã‚‹ã¨è¤‡é›‘æ€§ãŒå¢—ã™ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒˆãƒ­ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’ç´è§£ãã‚µãƒ¼ãƒ“ã‚¹æŒ‡å‘ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Zookeeperã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½œã‚‹ãŸã‚ã«çŸ¥ã£ã¦ãŠããŸã„ã“ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹      Source: Scaling up to your first 10 million usersãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (RDBMS)SQLãªã©ã®ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ•´ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®é›†åˆã§ã‚ã‚‹ã€‚ACID ã¯ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãŠã‘ã‚‹ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®é›†åˆã§ã‚ã‚‹ä¸å¯åˆ†æ€§ - ãã‚Œãã‚Œã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ã‚‹ã‹ãªã„ã‹ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹ä¸€è²«æ€§ - ã©ã‚“ãªãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚ã‚‹ç¢ºã‹ãªçŠ¶æ…‹ã‹ã‚‰æ¬¡ã®çŠ¶æ…‹ã«é·ç§»ã•ã›ã‚‹ã€‚ç‹¬ç«‹æ€§ - åŒæ™‚ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ã¯ã€é€£ç¶šçš„ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã®ã¨åŒã˜çµæœã‚’ã‚‚ãŸã‚‰ã™ã€‚æ°¸ç¶šæ€§ - ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãŒå‡¦ç†ã•ã‚ŒãŸã‚‰ã€ãã®ã‚ˆã†ã«ä¿å­˜ã•ã‚Œã‚‹ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ãŸã‚ã«ã¯ãŸãã•ã‚“ã®æŠ€è¡“ãŒã‚ã‚‹: ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ federationã€ ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ éæ­£è¦åŒ–ã€ ãã—ã¦ SQL ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒèª­ã¿å–ã‚Šã¨æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã—ã€æ›¸ãè¾¼ã¿ã‚’ä¸€ã¤ä»¥ä¸Šã®ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¤‡è£½ã—ã¾ã™ã€‚ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯èª­ã¿å–ã‚Šã®ã¿ã‚’å‡¦ç†ã—ã¾ã™ã€‚ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æœ¨æ§‹é€ ã®ã‚ˆã†ã«è¿½åŠ ã®ã‚¹ãƒ¬ãƒ¼ãƒ–ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã«ãªã£ãŸå ´åˆã«ã¯ã€ã„ãšã‚Œã‹ã®ã‚¹ãƒ¬ãƒ¼ãƒ–ãŒãƒã‚¹ã‚¿ãƒ¼ã«æ˜‡æ ¼ã™ã‚‹ã‹ã€æ–°ã—ã„ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚Œã‚‹ã¾ã§ã¯èª­ã¿å–ã‚Šå°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ã§ç¨¼åƒã—ã¾ã™ã€‚      Source: Scalability, availability, stability, patternsæ¬ ç‚¹: ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ãƒ¬ãƒ¼ãƒ–ã‚’ãƒã‚¹ã‚¿ãƒ¼ã«æ˜‡æ ¼ã•ã›ã‚‹ã«ã¯è¿½åŠ ã®ãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…è¦ã«ãªã‚‹ã€‚ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® ä¸¡æ–¹ ã®æ¬ ç‚¹ã¯æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã„ãšã‚Œã®ãƒã‚¹ã‚¿ãƒ¼ã‚‚èª­ã¿å–ã‚Šæ›¸ãè¾¼ã¿ã®ä¸¡æ–¹ã«å¯¾å¿œã™ã‚‹ã€‚æ›¸ãè¾¼ã¿ã«é–¢ã—ã¦ã¯ãã‚Œãã‚Œå”èª¿ã™ã‚‹ã€‚ã„ãšã‚Œã‹ã®ãƒã‚¹ã‚¿ãƒ¼ãŒè½ã¡ã¦ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¨ã—ã¦ã¯èª­ã¿æ›¸ãä¸¡æ–¹ã«å¯¾å¿œã—ãŸã¾ã¾é‹ç”¨ã§ãã‚‹ã€‚      Source: Scalability, availability, stability, patternsæ¬ ç‚¹: ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’å°å…¥ã™ã‚‹ã‹ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã©ã“ã«æ›¸ãè¾¼ã‚€ã‹ã‚’æŒ‡å®šã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚å¤§ä½“ã®ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä¸€è²«æ€§ãŒç·©ã„ï¼ˆACIDåŸç†ã‚’å®ˆã£ã¦ã„ãªã„ï¼‰ã‚‚ã—ãã¯ã€åŒæœŸã™ã‚‹æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã«æ›¸ãè¾¼ã¿ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã€‚æ›¸ãè¾¼ã¿ãƒãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚Œã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œæ›¸ãè¾¼ã¿ã®è¡çªã®å¯èƒ½æ€§ãŒå¢—ãˆã‚‹ã€‚ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® ä¸¡æ–¹ ã®æ¬ ç‚¹ã¯æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã‚’å‚ç…§æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚’è¤‡è£½ã™ã‚‹å‰ã«ãƒã‚¹ã‚¿ãƒ¼ãŒè½ã¡ãŸå ´åˆã«ã¯ãã®ãƒ‡ãƒ¼ã‚¿ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æ›¸ãè¾¼ã¿ã¯èª­ã¿å–ã‚Šãƒ¬ãƒ—ãƒªã‚«ã«ãŠã„ã¦ãƒªãƒ—ãƒ¬ã‚¤ã•ã‚Œã‚‹ã€‚æ›¸ãè¾¼ã¿ãŒå¤šã„å ´åˆã€è¤‡è£½ãƒãƒ¼ãƒ‰ãŒæ›¸ãè¾¼ã¿ã®å‡¦ç†ã®ã¿ã§è¡Œãè©°ã¾ã£ã¦ã€èª­ã¿å–ã‚Šã®å‡¦ç†ã‚’æº€è¶³ã«è¡Œãˆãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚èª­ã¿å–ã‚Šã‚¹ãƒ¬ãƒ¼ãƒ–ãƒãƒ¼ãƒ‰ã®æ•°ãŒå¤šã‘ã‚Œã°å¤šã„ã»ã©ã€è¤‡è£½ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„æ•°ã‚‚å¢—ãˆã€è¤‡è£½æ™‚é–“ãŒä¼¸ã³ã¦ã—ã¾ã„ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã£ã¦ã¯ã€ãƒã‚¹ã‚¿ãƒ¼ã¸ã®æ›¸ãè¾¼ã¿ã¯ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§ä¸¦åˆ—å‡¦ç†ã§ãã‚‹ä¸€æ–¹ã€ã‚¹ãƒ¬ãƒ¼ãƒ–ã¸ã®è¤‡è£½ã¯å˜ä¸€ã‚¹ãƒ¬ãƒƒãƒ‰ã§é€£ç¶šçš„ã«å‡¦ç†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€ å¯ç”¨æ€§ã€ ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒ«ãƒãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³Federation      Source: Scaling up to your first 10 million usersãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (ã‚‚ã—ãã¯æ©Ÿèƒ½åˆ†å‰²åŒ–ã¨ã‚‚è¨€ã†) ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ©Ÿèƒ½ã”ã¨ã«åˆ†å‰²ã™ã‚‹ã€‚ä¾‹ãˆã°ã€ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªå˜ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä»£ã‚ã‚Šã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã€ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ ã®ã‚ˆã†ã«ä¸‰ã¤ã«ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸€ã¤ã‚ãŸã‚Šã®æ›¸ãè¾¼ã¿ãƒ»èª­ã¿å–ã‚Šã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒæ¸›ã‚Šã€ãã®çµæœãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ©ã‚°ã‚‚çŸ­ããªã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå°ã•ããªã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã«åã¾ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒå¢—ãˆã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å±€æ‰€æ€§ãŒé«˜ã¾ã‚‹ãŸã‚ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã‚‚ä¸ŠãŒã‚Šã¾ã™ã€‚å˜ä¸€ã®ä¸­å¤®ãƒã‚¹ã‚¿ãƒ¼ã§æ›¸ãè¾¼ã¿ã‚’ç›´åˆ—åŒ–ã—ãŸã‚Šã—ãªã„ãŸã‚ã€ä¸¦åˆ—ã§æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚æ¬ ç‚¹: federationå¤§è¦æ¨¡ãªå‡¦ç†ã‚„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¦ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒã®å ´åˆã€ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯åŠ¹æœçš„ã¨ã¯è¨€ãˆãªã„ã§ã—ã‚‡ã†ã€‚ã©ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«èª­ã¿æ›¸ãã‚’ã™ã‚‹ã®ã‹ã‚’æŒ‡å®šã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ›´æ–°ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚server linkã§äºŒã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€£çµã™ã‚‹ã®ã¯ã‚ˆã‚Šè¤‡é›‘ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: federationScaling up to your first 10 million usersã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°      Source: Scalability, availability, stability, patternsã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãã‚Œãã‚ŒãŒãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ–ã‚»ãƒƒãƒˆæ–­ç‰‡ã®ã¿ã‚’æŒã¤ã‚ˆã†ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¾‹ã«ã¨ã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«ã¯ã‚ˆã‚Šå¤šãã®æ–­ç‰‡ãŒåŠ ãˆã‚‰ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚federationã®åˆ©ç‚¹ã«ä¼¼ã¦ã„ã¦ã€ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯èª­ã¿æ›¸ãã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æ¸›ã‚‰ã—ã€ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¸›ã‚‰ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã‚’å¢—ã‚„ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚‚æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™ã¨ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã‚¯ã‚¨ãƒªé€Ÿåº¦ãŒé€Ÿããªã‚Šã¾ã™ã€‚ãªã«ãŒã—ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡è£½ã™ã‚‹æ©Ÿèƒ½ãŒãªã‘ã‚Œã°ãƒ‡ãƒ¼ã‚¿ãƒ­ã‚¹ã«ã¤ãªãŒã‚Šã¾ã™ãŒã€ã‚‚ã—ã€ä¸€ã¤ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒè½ã¡ã¦ã‚‚ã€ä»–ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒå‹•ã„ã¦ã„ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜ãã€å˜ä¸€ã®ä¸­å¤®ãƒã‚¹ã‚¿ãƒ¼ãŒæ›¸ãè¾¼ã¿ã®å‡¦ç†ã‚’ã—ãªãã¦ã‚‚ã€ä¸¦åˆ—ã§æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ä¸€èˆ¬çš„ãªæ–¹æ³•ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ©ã‚¹ãƒˆãƒãƒ¼ãƒ ã‚¤ãƒ‹ã‚·ãƒ£ãƒ«ã§ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åœ°ç†çš„é…ç½®ã§ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ãªã©ã§ã™ã€‚æ¬ ç‚¹: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒ£ãƒ¼ãƒ‰ã«å¯¾å¿œã™ã‚‹ã‚ˆã†ã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚çµæœã¨ã—ã¦SQLã‚¯ã‚¨ãƒªãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ‰ã§ã¯ãƒ‡ãƒ¼ã‚¿é…åˆ†ãŒã„ã³ã¤ã«ãªã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€æ¨™æº–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é›†åˆã‚’æŒã¤ã‚·ãƒ£ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã€ãã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒä»–ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚ˆã‚Šã‚‚é‡ã„è² è·ã‚’è² ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒªãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã‚’ã™ã‚‹ã¨è¤‡é›‘æ€§ãŒã‚ˆã‚Šå¢—ã—ã¾ã™ã€‚consistent hashing ã«åŸºã¥ã„ãŸã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ã€é€šä¿¡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚è¤‡æ•°ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€£çµã™ã‚‹ã®ã¯ã‚ˆã‚Šè¤‡é›‘ã§ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒ£ãƒ¼ãƒ‰ã®ç™»å ´ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Consistent hashingéæ­£è¦åŒ–éæ­£è¦åŒ–ã§ã¯ã€æ›¸ãè¾¼ã¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã„ãã‚‰ã‹çŠ ç‰²ã«ã—ã¦èª­ã¿è¾¼ã¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚ˆã†ã¨ã—ã¾ã™ã€‚è¨ˆç®—çš„ã«é‡ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµåˆãªã©ã‚’ã›ãšã«ã€è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«å†—é•·ãªãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ãŒæ›¸ãè¾¼ã¾ã‚Œã‚‹ã®ã‚’è¨±å®¹ã—ã¾ã™ã€‚ã„ãã¤ã‹ã®RDBMSä¾‹ãˆã°ã€PostgreSQL ã‚„Oracleã¯ã“ã®å†—é•·ãªæƒ…å ±ã‚’å–ã‚Šæ‰±ã„ã€ä¸€è²«æ€§ã‚’ä¿ã¤ãŸã‚ã®materialized views ã¨ã„ã†æ©Ÿèƒ½ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ã‚„ ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã«ã‚ˆã£ã¦ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã«åˆ†é…ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’åˆä¸€ã•ã›ã‚‹ã“ã¨ã¯ã¨ã¦ã‚‚è¤‡é›‘ãªä½œæ¥­ã§ã™ã€‚éæ­£è¦åŒ–ã«ã‚ˆã£ã¦ãã®ã‚ˆã†ãªè¤‡é›‘ãªå‡¦ç†ã‚’ã—ãªãã¦æ¸ˆã‚€ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚å¤šãã®ã‚·ã‚¹ãƒ†ãƒ ã§ã€100å¯¾1ã‚ã‚‹ã„ã¯1000å¯¾1ãã‚‰ã„ã«ãªã‚‹ãã‚‰ã„èª­ã¿å–ã‚Šã®æ–¹ãŒã€æ›¸ãè¾¼ã¿ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚ˆã‚Šã‚‚å¤šã„ã“ã¨ã§ã—ã‚‡ã†ã€‚èª­ã¿è¾¼ã¿ã‚’è¡Œã†ãŸã‚ã«ã€è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¸ãƒ§ã‚¤ãƒ³å‡¦ç†ãŒå«ã¾ã‚Œã‚‹ã‚‚ã®ã¯è¨ˆç®—çš„ã«é«˜ä¾¡ã«ã¤ãã¾ã™ã—ã€ãƒ‡ã‚£ã‚¹ã‚¯ã®å‡¦ç†æ™‚é–“ã§è†¨å¤§ãªæ™‚é–“ã‚’è²»æ¶ˆã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ¬ ç‚¹: éæ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ãŒè¤‡è£½ã•ã‚Œã‚‹ã€‚å†—é•·ãªãƒ‡ãƒ¼ã‚¿ã®è¤‡è£½ãŒåŒæœŸã•ã‚Œã‚‹ã‚ˆã†ã«åˆ¶ç´„ãŒå­˜åœ¨ã—ã€ãã®ã“ã¨ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®è¨­è¨ˆãŒè¤‡é›‘åŒ–ã™ã‚‹ã€‚éæ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯éå¤§ãªæ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å ´åˆã€æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ãã‚Œã‚ˆã‚Šã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ãŠã„ã¦åŠ£ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: éæ­£è¦åŒ–DenormalizationSQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯åºƒç¯„ãªçŸ¥è­˜ã‚’å¿…è¦ã¨ã™ã‚‹åˆ†é‡ã§å¤šãã® æœ¬ ãŒæ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’æ˜ã‚‰ã‹ã«ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ä¸Šã§ã€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ã‚’å®šã‚ã€ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« ã™ã‚‹ã“ã¨ã¯ã¨ã¦ã‚‚é‡è¦ã§ã™ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - abãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€é«˜è² è·ã®çŠ¶æ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« - slow query log ãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çŠ¶æ³ã®ç¢ºèªã‚’ã—ã¾ã—ã‚‡ã†ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¨ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®ã‚ˆã†ãªåŠ¹ç‡åŒ–ã®é¸æŠè‚¢ã‚’ã¨ã‚‹ã“ã¨ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¹ã‚­ãƒ¼ãƒã‚’çµã‚‹MySQLã¯ã‚¢ã‚¯ã‚»ã‚¹é€Ÿåº¦å‘ä¸Šã®ãŸã‚ã€ãƒ‡ã‚£ã‚¹ã‚¯ä¸Šã®é€£ç¶šã—ãŸãƒ–ãƒ­ãƒƒã‚¯ã¸ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã—ã¦ã„ã¾ã™ã€‚é•·ã•ã®æ±ºã¾ã£ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å¯¾ã—ã¦ã¯ VARCHAR ã‚ˆã‚Šã‚‚ CHAR ã‚’ä½¿ã†ã‚ˆã†ã«ã—ã¾ã—ã‚‡ã†ã€‚CHAR ã®æ–¹ãŒåŠ¹ç‡çš„ã«é€Ÿããƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ ä¸€æ–¹ã€ VARCHAR ã§ã¯æ¬¡ã®ãƒ‡ãƒ¼ã‚¿ã«ç§»ã‚‹å‰ã«ãƒ‡ãƒ¼ã‚¿ã®æœ«å°¾ã‚’æ¤œçŸ¥ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ãŸã‚ã«é€Ÿåº¦ãŒçŠ ç‰²ã«ãªã‚Šã¾ã™ã€‚ãƒ–ãƒ­ã‚°ã®æŠ•ç¨¿ãªã©ã€å¤§ããªãƒ†ã‚­ã‚¹ãƒˆã«ã¯ TEXT ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚ TEXT ã§ã¯ãƒ–ãƒ¼ãƒªã‚¢ãƒ³å‹ã®æ¤œç´¢ã‚‚å¯èƒ½ã§ã™ã€‚ TEXT ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ã€ãƒ‡ã‚£ã‚¹ã‚¯ä¸Šã®å ´æ‰€ã¸ã®ãƒã‚¤ãƒ³ã‚¿ãƒ¼ãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚2ã®32ä¹—ã‚„40å„„ä»¥ä¸‹ã‚’è¶…ãˆãªã„ç¨‹åº¦ã®å¤§ããªæ•°ã«ã¯ INT ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚é€šè²¨ã«é–¢ã—ã¦ã¯å°æ•°ç‚¹è¡¨ç¤ºä¸Šã®ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã« DECIMAL ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚å¤§ããª BLOBS ã‚’ä¿å­˜ã™ã‚‹ã®ã¯é¿ã‘ã¾ã—ã‚‡ã†ã€‚ã©ã“ã‹ã‚‰ãã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–ã£ã¦ãã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã®æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚VARCHAR(255) ã¯8ãƒ“ãƒƒãƒˆã§æ•°ãˆã‚‰ã‚Œã‚‹æœ€å¤§ã®æ–‡å­—æ•°ã§ã™ã€‚ä¸€éƒ¨ã®DBMSã§ã¯ã€1ãƒã‚¤ãƒˆã®åˆ©ç”¨åŠ¹ç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«ã“ã®æ–‡å­—æ•°ãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚æ¤œç´¢æ€§èƒ½å‘ä¸Šã®ãŸã‚ ã€å¯èƒ½ã§ã‚ã‚Œã° NOT NULL åˆ¶ç´„ã‚’è¨­å®šã—ã¾ã—ã‚‡ã†ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åŠ¹æœçš„ã«ç”¨ã„ã‚‹ã‚¯ã‚¨ãƒª(SELECTã€ GROUP BYã€ ORDER BYã€ JOIN) ã®å¯¾è±¡ã¨ãªã‚‹åˆ—ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã†ã“ã¨ã§é€Ÿåº¦ã‚’å‘ä¸Šã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯é€šå¸¸ã€å¹³è¡¡æ¢ç´¢æœ¨ã§ã‚ã‚‹Bæœ¨ã®å½¢ã§è¡¨ã•ã‚Œã¾ã™ã€‚Bæœ¨ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ã¯å¸¸ã«ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸçŠ¶æ…‹ã«ãªã‚Šã¾ã™ã€‚ã¾ãŸæ¤œç´¢ã€é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ã€æŒ¿å…¥ã€å‰Šé™¤ã‚’å¯¾æ•°æ™‚é–“ã§è¡Œãˆã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é…ç½®ã™ã‚‹ã“ã¨ã¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªãƒ¼ã«æ®‹ã™ã“ã¨ã«ã¤ãªãŒã‚Šã‚ˆã‚Šå®¹é‡ã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°ã‚‚å¿…è¦ã«ãªã‚‹ãŸã‚æ›¸ãè¾¼ã¿ã‚‚é…ããªã‚Šã¾ã™ã€‚å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹éš›ã«ã¯ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ‡ã£ã¦ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å†ã³ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ“ãƒ«ãƒ‰ã—ãŸæ–¹ãŒé€Ÿã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚é«˜è² è·ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’é¿ã‘ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šå¿…è¦ãªã¨ã“ã‚ã«ã¯éæ­£è¦åŒ–ã‚’é©ç”¨ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆ†å‰²ã—ã€ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆã‚’ç‹¬ç«‹ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã«åˆ†é›¢ã—ã¦ãƒ¡ãƒ¢ãƒªãƒ¼ã«ä¹—ã›ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª¿æ•´ã™ã‚‹å ´åˆã«ã‚ˆã£ã¦ã¯ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°MySQLã‚¯ã‚¨ãƒªã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®TipsVARCHAR(255)ã‚’ã‚„ãŸã‚‰ã‚ˆãè¦‹ã‹ã‘ã‚‹ã®ã¯ãªã‚“ã§ï¼Ÿnullå€¤ã¯ã©ã®ã‚ˆã†ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã™ã‚‹ã®ã‹ï¼ŸSlow query logNoSQLNoSQL ã¯ key-value storeã€ document-storeã€ wide column storeã€ ã‚‚ã—ãã¯ graph databaseã«ã‚ˆã£ã¦è¡¨ç¾ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¤ãƒ†ãƒ ã®é›†åˆã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ä¸€èˆ¬çš„ã«æ­£è¦åŒ–ã•ã‚Œã¦ãŠã‚‰ãšã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã§ã‚¸ãƒ§ã‚¤ãƒ³ãŒè¡Œã‚ã‚Œã¾ã™ã€‚å¤§éƒ¨åˆ†ã®NoSQLã¯çœŸã®ACIDãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŒãŸãšã€ çµæœæ•´åˆæ€§ çš„ãªæŒ¯ã‚‹èˆã„ã®æ–¹ã‚’å¥½ã¿ã¾ã™ã€‚BASE ã¯ã—ã°ã—ã°NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚CAP Theorem ã¨å¯¾ç…§çš„ã«ã€BASEã¯ä¸€è²«æ€§ã‚ˆã‚Šã‚‚å¯ç”¨æ€§ã‚’å„ªå…ˆã—ã¾ã™ã€‚Basically available - ã‚·ã‚¹ãƒ†ãƒ ã¯å¯ç”¨æ€§ã‚’ä¿è¨¼ã—ã¾ã™ã€‚Soft state - ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã¯å…¥åŠ›ãŒãªãã¦ã‚‚æ™‚é–“çµŒéã¨ã¨ã‚‚ã«å¤‰åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚çµæœæ•´åˆæ€§ - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¯æ™‚é–“çµŒéã¨ã¨ã‚‚ã«ãã®é–“ã«å…¥åŠ›ãŒãªã„ã¨ã„ã†å‰æã®ã‚‚ã¨ã€ä¸€è²«æ€§ãŒé”æˆã•ã‚Œã¾ã™ã€‚SQLã‹ï¼ŸNoSQLã‹ï¼Ÿ ã‚’é¸æŠã™ã‚‹ã®ã«åŠ ãˆã¦ã€ã©ã®ã‚¿ã‚¤ãƒ—ã®NoSQLãŒã©ã®ä½¿ç”¨ä¾‹ã«æœ€ã‚‚é©ã™ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ã®ã¯ã¨ã¦ã‚‚æœ‰ç›Šã§ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã€ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã€ ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã€ ã¨ ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã«ã¤ã„ã¦è§¦ã‚Œã¦ã„ãã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢æ¦‚è¦: ãƒãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ä¸€èˆ¬çš„ã«O(1)ã®èª­ã¿æ›¸ããŒã§ãã€ãã‚Œã‚‰ã¯ãƒ¡ãƒ¢ãƒªãªã„ã—SSDã§è£ä»˜ã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¯ã‚­ãƒ¼ã‚’ è¾æ›¸çš„é †åº ã§ä¿æŒã™ã‚‹ã“ã¨ã§ã‚­ãƒ¼ã®åŠ¹ç‡çš„ãªå–å¾—ã‚’å¯èƒ½ã«ã—ã¦ã„ã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å€¤ã¨ã¨ã‚‚ã«ä¿æŒã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã¯ãƒã‚¤ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãªæŒ™å‹•ãŒå¯èƒ½ã§ã€å˜ç´”ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ãªã©ã®ãƒ‡ãƒ¼ã‚¿ãŒæ€¥é€Ÿã«å¤‰ã‚ã‚‹å ´åˆãªã©ã«ä½¿ã‚ã‚Œã¾ã™ã€‚å˜ç´”ãªå‡¦ç†ã®ã¿ã«æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€è¿½åŠ ã®å‡¦ç†æ©Ÿèƒ½ãŒå¿…è¦ãªå ´åˆã«ã¯ãã®è¤‡é›‘æ€§ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã«è¼‰ã›ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã¯ã‚‚ã£ã¨è¤‡é›‘ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã‚„ã€ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®åŸºæœ¬ã§ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã®æ¬ ç‚¹Redisã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢æ¦‚è¦: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãƒãƒªãƒ¥ãƒ¼ã¨ã—ã¦ä¿å­˜ã•ã‚ŒãŸã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«é–¢ã™ã‚‹å…¨ã¦ã®æƒ…å ±ã‚’æŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ(XMLã€ JSONã€ binaryãªã©)ã‚’ä¸­å¿ƒã«æ®ãˆãŸã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã§ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªèº«ã®å†…éƒ¨æ§‹é€ ã«åŸºã¥ã„ãŸã€APIã‚‚ã—ãã¯ã‚¯ã‚¨ãƒªè¨€èªã‚’æä¾›ã—ã¾ã™ã€‚ ãƒ¡ãƒ¢ï¼šå¤šãã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ã€å€¤ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†æ©Ÿèƒ½ã‚’å«ã‚“ã§ã„ã¾ã™ãŒã€ãã®ã“ã¨ã«ã‚ˆã£ã¦äºŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¨ã®å¢ƒç•Œç·šãŒæ›–æ˜§ã«ãªã£ã¦ã—ã¾ã£ã¦ã„ã¾ã™ã€‚ä»¥ä¸Šã®ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã€ã‚¿ã‚°ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã©ã¨ã—ã¦æ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒå£«ã¯ã¾ã¨ã‚ã¦ã‚°ãƒ«ãƒ¼ãƒ—ã«ã§ãã‚‹ã‚‚ã®ã®ã€ãã‚Œãã‚Œã§å…¨ãç•°ãªã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚MongoDB ã‚„ CouchDB ãªã©ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã‚‚ã€è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã®SQLã®ã‚ˆã†ãªè¨€èªã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚DynamoDB ã¯ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¯é«˜ã„æŸ”è»Ÿæ€§ã‚’æ‹…ä¿ã™ã‚‹ã®ã§ã€é »ç¹ã«å¤‰åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†æ™‚ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹MongoDB ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£CouchDB ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Elasticsearch ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢      Source: SQL & NoSQL, a brief historyæ¦‚è¦: ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒãƒƒãƒ— ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼<è¡Œã‚­ãƒ¼ã€ ã‚«ãƒ©ãƒ <ColKeyã€ Valueã€ Timestamp>>ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬å˜ä½ã¯ã‚«ãƒ©ãƒ ï¼ˆãƒãƒ¼ãƒ ãƒ»ãƒãƒªãƒ¥ãƒ¼ã®ãƒšã‚¢ï¼‰ã§ã™ã€‚ãã‚Œãã‚Œã®ã‚«ãƒ©ãƒ ã¯ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¨ã—ã¦ï¼ˆSQLãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚ˆã†ã«ï¼‰ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¯ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®é›†åˆã§ã™ã€‚ãã‚Œãã‚Œã®ã‚«ãƒ©ãƒ ã«ã¯è¡Œã‚­ãƒ¼ã§ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚åŒã˜è¡Œã‚­ãƒ¼ã‚’æŒã¤ã‚«ãƒ©ãƒ ã¯åŒã˜è¡Œã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã™ã€‚ãã‚Œãã‚Œã®å€¤ã¯ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãŒèµ·ããŸæ™‚ã®ãŸã‚ã«ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å«ã¿ã¾ã™ã€‚Googleã¯Bigtableã‚’åˆã®ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã¨ã—ã¦ç™ºè¡¨ã—ã¾ã—ãŸã€‚ãã‚ŒãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§Hadoopãªã©ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹HBase ã‚„Facebookã«ã‚ˆã‚‹Cassandra ãªã©ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å½±éŸ¿ã‚’ä¸ãˆã¾ã—ãŸã€‚BigTableã€HBaseã‚„Cassandraãªã©ã®ã‚¹ãƒˆã‚¢ã¯ã‚­ãƒ¼ã‚’è¾æ›¸å½¢å¼ã§ä¿æŒã™ã‚‹ã“ã¨ã§é¸æŠã—ãŸã‚­ãƒ¼ãƒ¬ãƒ³ã‚¸ã§ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’åŠ¹ç‡çš„ã«ã—ã¾ã™ã€‚ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã¯é«˜ã„å¯ç”¨æ€§ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’æ‹…ä¿ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã¨ã¦ã‚‚å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‰±ã†ã“ã¨ã«ã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢SQL & NoSQLç°¡å˜ã«æ­´å²ã‚’ã•ã‚‰ã†Bigtable ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HBase ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Cassandra ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹      Source: Graph databaseæ¦‚è¦: ã‚°ãƒ©ãƒ•ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã¯ã€ãã‚Œãã‚Œã®ãƒãƒ¼ãƒ‰ãŒãƒ¬ã‚³ãƒ¼ãƒ‰ã§ã€ãã‚Œãã‚Œã®ã‚¢ãƒ¼ã‚¯ã¯äºŒã¤ã®ãƒãƒ¼ãƒ‰ã‚’ç¹‹ãé–¢ä¿‚æ€§ã¨ã—ã¦å®šç¾©ã•ã‚Œã¾ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯å¤šæ•°ã®å¤–éƒ¨ã‚­ãƒ¼ã‚„å¤šå¯¾å¤šãªã©ã®è¤‡é›‘ãªé–¢ä¿‚æ€§ã‚’è¡¨ã™ã®ã«æœ€é©ã§ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯SNSãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹ã®è¤‡é›‘ãªé–¢ä¿‚æ€§ãƒ¢ãƒ‡ãƒ«ãªã©ã«ã¤ã„ã¦é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚æ¯”è¼ƒçš„æ–°ã—ãã€ã¾ã ä¸€èˆ¬çš„ã«ã¯ç”¨ã„ã‚‰ã‚Œã¦ã„ãªã„ã®ã§ã€é–‹ç™ºãƒ„ãƒ¼ãƒ«ã‚„ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¢ã™ã®ãŒä»–ã®æ–¹æ³•ã«æ¯”ã¹ã¦é›£ã—ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å¤šãã®ã‚°ãƒ©ãƒ•ã¯REST APIsã‚’é€šã˜ã¦ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ã‚°ãƒ©ãƒ•Graphãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹Neo4jFlockDBãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  NoSQLåŸºæœ¬ç”¨èªã®èª¬æ˜NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¤ã„ã¦èª¿æŸ»ã¨é¸æŠã‚¬ã‚¤ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£NoSQLã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³NoSQLãƒ‘ã‚¿ãƒ¼ãƒ³SQLã‹ï¼ŸNoSQLã‹ï¼Ÿ      Source: Transitioning from RDBMS to NoSQLSQL ã‚’é¸ã¶ç†ç”±:æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å³æ ¼ãªã‚¹ã‚­ãƒ¼ãƒãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿è¤‡é›‘ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’ã™ã‚‹å¿…è¦æ€§ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹éš›ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ˜ç¢ºãªã¨ãé–‹ç™ºè€…ã®æ•°ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã€ã‚³ãƒ¼ãƒ‰ç­‰ãŒã‚ˆã‚Šå……å®Ÿã—ã¦ã„ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã¯ã¨ã¦ã‚‚é€Ÿã„NoSQL ã‚’é¸ã¶ç†ç”±:æº–æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã„ã—ã€ãƒ•ãƒ¬ã‚­ã‚·ãƒ–ãƒ«ãªã‚¹ã‚­ãƒ¼ãƒãƒãƒ³ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãªãƒ‡ãƒ¼ã‚¿è¤‡é›‘ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’ã™ã‚‹å¿…è¦ãŒãªã„ãƒ‡ãƒ¼ã‚¿ã®å¤šãã®TB (ã‚‚ã—ãã¯ PB) ã‚’ä¿å­˜ã™ã‚‹é›†ä¸­çš„ã€å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿è² è·ã«è€ãˆã‚‰ã‚Œã‚‹IOPSã«ã¤ã„ã¦ã¯æ¥µã‚ã¦é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¤ºã™NoSQLã«é©ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:æ€¥æ¿€ãªã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚„ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã®åé›†ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã‚„ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚«ãƒ¼ãƒˆãªã©ã®ä¸€æ™‚çš„æƒ…å ±é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ ('ãƒ›ãƒƒãƒˆãª') ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ã€€SQLã‚‚ã—ãã¯NoSQLæœ€åˆã®1000ä¸‡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«SQLã¨NoSQLã®é•ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥      Source: Scalable system design patternsã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿æ™‚é–“ã‚’å‰Šæ¸›ã—ã€ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®è² è·ã‚’ä½æ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€å®Ÿéš›ã®å‡¦ç†ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«ã€ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒãƒ£ãƒ¼ãŒã¾ãšä»¥å‰ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒé€ä¿¡ã•ã‚ŒãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã€ç›´å‰ã®çµæœã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ãã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«æ¸¡ã£ã¦çµ±åˆã•ã‚ŒãŸèª­ã¿å–ã‚Šæ›¸ãè¾¼ã¿ã®åˆ†é…ã‚’è¦æ±‚ã—ã¾ã™ãŒã€äººæ°—ã‚¢ã‚¤ãƒ†ãƒ ã¯ãã®åˆ†é…ã‚’æ­ªã‚ã¦ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã£ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å·®ã—è¾¼ã‚€ã“ã¨ã§ã“ã®ã‚ˆã†ã«ã€å‡ä¸€ã§ãªã„è² è·ã‚„ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®æ€¥æ¿€ãªå¢—åŠ ã‚’å¸åã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯OSã‚„ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ãªã©ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã€ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ ã‚‚ã—ãã¯ç‹¬ç«‹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«è¨­ç½®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚CDNã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°CDN ã‚‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¸€ã¤ã¨ã—ã¦è€ƒãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Webã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· ã‚„ Varnish ãªã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯é™çš„ãã—ã¦å‹•çš„ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥é…ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ webã‚µãƒ¼ãƒãƒ¼ã‚‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã“ã¨ãªã—ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æ™®é€šã€ä¸€èˆ¬çš„ãªä½¿ç”¨çŠ¶æ³ã«é©ã™ã‚‹ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã®è¨­å®šã‚’åˆæœŸçŠ¶æ…‹ã§æŒã£ã¦ã„ã¾ã™ã€‚ã“ã®è¨­å®šã‚’ç‰¹å®šã®ä»•æ§˜ã«åˆã‚ã›ã¦èª¿æ•´ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã©ã®In-memoryã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„Redisã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®é–“ã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯RAMã§ä¿æŒã•ã‚Œã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ã‚£ã‚¹ã‚¯ã§ä¿å­˜ã•ã‚Œã‚‹ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚ˆã‚Šã‚‚ã ã„ã¶é€Ÿã„ã§ã™ã€‚RAMå®¹é‡ã¯ãƒ‡ã‚£ã‚¹ã‚¯ã‚ˆã‚Šã‚‚é™ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã€least recently used (LRU)ãªã©ã®cache invalidation ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒ 'ã‚³ãƒ¼ãƒ«ãƒ‰' ãªã‚¨ãƒ³ãƒˆãƒªã‚’å¼¾ãã€'ãƒ›ãƒƒãƒˆ' ãªãƒ‡ãƒ¼ã‚¿ã‚’RAMã«ä¿å­˜ã—ã¾ã™ã€‚Redisã¯ã•ã‚‰ã«ä»¥ä¸‹ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’å‚™ãˆã¦ã„ã¾ã™:ãƒ‘ãƒ¼ã‚¸ã‚¹ãƒ†ãƒ³ã‚¹è¨­å®šã‚½ãƒ¼ãƒˆæ¸ˆã¿ã‚»ãƒƒãƒˆã€ãƒªã‚¹ãƒˆãªã©ã®çµ„ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã¯æ§˜ã€…ãªãƒ¬ãƒ™ãƒ«ã®ã‚‚ã®ãŒã‚ã‚Šã¾ã™ãŒã€ã„ãšã‚Œã‚‚å¤§ããäºŒã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ã„ãšã‚Œã‹ã«åˆ†é¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª ã¨ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ ã§ã™:è¡Œãƒ¬ãƒ™ãƒ«ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«Fully-formed serializable objectsFully-rendered HTMLä¸€èˆ¬çš„ã«ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã¯ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’ä½œã‚Šå‡ºã—ã¦ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’é›£ã—ãã—ã¦ã—ã¾ã†ã®ã§é¿ã‘ã‚‹ã¹ãã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹éš›ã«ã¯å¿…ãšã‚¯ã‚¨ãƒªã‚’ã‚­ãƒ¼ã¨ã—ã¦ãƒãƒƒã‚·ãƒ¥ã—ã¦çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚ã“ã®æ‰‹æ³•ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœŸé™åˆ‡ã‚Œå•é¡Œã«æ‚©ã‚€ã“ã¨ã«ãªã‚Šã¾ã™:è¤‡é›‘ãªã‚¯ã‚¨ãƒªã«ã‚ˆã‚Šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçµæœã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ãŒå›°é›£ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ãƒ«ãªã©ã®ãƒ‡ãƒ¼ã‚¿æ–­ç‰‡ãŒå¤‰åŒ–ã—ãŸæ™‚ã«ã€ãã®å¤‰åŒ–ã—ãŸã‚»ãƒ«ã‚’å«ã‚€ã‹ã‚‚ã—ã‚Œãªã„å…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’å‰Šé™¤ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã†ã™ã‚‹ã‚ˆã†ã«ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰ãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨ã—ã¦çµ„ã¿ç«‹ã¦ã•ã›ã¾ã™ã€‚:ãã®ãƒ‡ãƒ¼ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‰Šé™¤ã™ã‚‹ã“ã¨éåŒæœŸå‡¦ç†ã‚’è¨±å®¹ã—ã¾ã™: ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸­ã§æœ€æ–°ã®ã‚‚ã®ã‚’é›†ã‚ã¦ãã¾ã™ä½•ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã‹:ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œå…¨ã«ãƒ¬ãƒ³ãƒ€ãƒ¼ã•ã‚ŒãŸã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‚¢ã‚¯ãƒ†ãƒ“ãƒ†ã‚£ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã§ãã‚‹å®¹é‡ã¯é™ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€è‡ªåˆ†ã®ã‚±ãƒ¼ã‚¹ã§ã¯ã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‰‹æ³•ãŒä¸€ç•ªã„ã„ã‹ã¯æ¤œè¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰      Source: From cache to in-memory data gridã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¸ã®èª­ã¿æ›¸ãã®å‡¦ç†ã‚’ã—ã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ã¯ç›´æ¥ã‚„ã‚Šã¨ã‚Šã‚’ã—ã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ã“ã¨ã‚’ã—ã¾ã™:ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¸­ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å‚ç…§ã—ã¾ã™ãŒã€çµæœã¨ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã«ãªã‚Šã¾ã™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—ã—ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ ã—ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã—ã¾ã™def get_user(self, user_id):    user = cache.get(\""user.{0}\"", user_id)    if user is None:        user = db.query(\""SELECT * FROM users WHERE user_id = {0}\"", user_id)        if user is not None:            key = \""user.{0}\"".format(user_id)            cache.set(key, json.dumps(user))    return userMemcached ã¯é€šå¸¸ã“ã®ã‚ˆã†ã«ä½¿ã‚ã‚Œã‚‹ã€‚ãã®å¾Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¯é€Ÿã„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã¯ãƒ¬ãƒ¼ã‚¸ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚ã‚‹ã¨ã‚‚è¨€ã‚ã‚Œã¾ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã¿ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæº¢ã‚Œã‚‹ã®ã‚’é˜²æ­¢ã—ã¾ã™ã€‚æ¬ ç‚¹: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰å„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã¯ä¸‰ã¤ã®ãƒˆãƒªãƒƒãƒ—ã‚’å‘¼ã³å‡ºã™ã“ã¨ã«ãªã‚Šã€ä½“æ„Ÿã§ãã‚‹ã»ã©ã®é…å»¶ãŒèµ·ãã¦ã—ã¾ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ãŒæ›´æ–°ã•ã‚Œã‚‹ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã¯å¤ã„ã‚‚ã®ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚time-to-live (TTL)ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã®æ›´æ–°ã‚’å¼·åˆ¶çš„ã«è¡Œã†ã€ã‚‚ã—ãã¯ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã¯ç·©å’Œã§ãã¾ã™ã€‚ãƒãƒ¼ãƒ‰ãŒè½ã¡ã‚‹ã¨ã€æ–°è¦ã®ç©ºã®ãƒãƒ¼ãƒ‰ã§ä»£æ›¿ã•ã‚Œã‚‹ã“ã¨ã§ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼      Source: Scalability, availability, stability, patternsã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¨ã—ã¦ä½¿ã„ã€ãã“ã«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿æ›¸ãã‚’è¡Œã„ã¾ã™ã€‚ä¸€æ–¹ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®èª­ã¿æ›¸ãã‚’æ‹…å½“ã—ã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚‹ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã™ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯åŒæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã«æ›¸ãè¾¼ã¿ã‚’è¡Œã„ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã—ã¾ã™ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰:set_user(12345, {\""foo\"":\""bar\""})ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚³ãƒ¼ãƒ‰:def set_user(user_id, values):    user = db.query(\""UPDATE Users WHERE id = {0}\"", user_id, values)    cache.set(user_id, user)ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã¯æ›¸ãè¾¼ã¿å‡¦ç†ã®ã›ã„ã§å…¨ä½“ã¨ã—ã¦ã¯é…ã„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ãŒã€æ›¸ãè¾¼ã¾ã‚ŒãŸã°ã‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹èª­ã¿è¾¼ã¿ã¯é€Ÿã„ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã¯ä¸€èˆ¬çš„ã«ãƒ‡ãƒ¼ã‚¿æ›´æ–°æ™‚ã®æ–¹ãŒèª­ã¿è¾¼ã¿æ™‚ã‚ˆã‚Šã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã«è¨±å®¹çš„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã¯æœ€æ–°ç‰ˆã§ä¿ãŸã‚Œã¾ã™ã€‚æ¬ ç‚¹: ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ãƒãƒ¼ãƒ‰ãŒè½ã¡ãŸã“ã¨ã€ã‚‚ã—ãã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦æ–°ã—ã„ãƒãƒ¼ãƒ‰ãŒä½œæˆã•ã‚ŒãŸæ™‚ã«ã€æ–°ã—ã„ãƒãƒ¼ãƒ‰ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒæ›´æ–°ã•ã‚Œã‚‹ã¾ã§ã¯ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã›ã‚“ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã¨ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚’ä½µç”¨ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã‚’ç·©å’Œã§ãã¾ã™ã€‚æ›¸ãè¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã¯ä¸€åº¦ã‚‚èª­ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯TTLã«ã‚ˆã£ã¦åœ§ç¸®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ (ãƒ©ã‚¤ãƒˆãƒãƒƒã‚¯)      Source: Scalability, availability, stability, patternsãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ã§ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ã“ã¨ã‚’ã—ã¾ã™:ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã™ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¸ã®æ›¸ãè¾¼ã¿ã‚’éåŒæœŸçš„ã«è¡Œã†ã“ã¨ã§ã€æ›¸ãè¾¼ã¿ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚æ¬ ç‚¹: ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢å†…ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ãƒ’ãƒƒãƒˆã™ã‚‹å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè½ã¡ã‚‹ã¨ãƒ‡ãƒ¼ã‚¿æ¬ æãŒèµ·ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã‚„ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚ˆã‚Šã‚‚å®Ÿè£…ãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰      Source: From cache to in-memory data gridæœŸé™åˆ‡ã‚Œã‚ˆã‚Šã‚‚å‰ã«ã€ç›´è¿‘ã§ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸå…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’è‡ªå‹•çš„ã«æ›´æ–°ã™ã‚‹ã‚ˆã†ã«è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚‚ã—ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå°†æ¥å¿…è¦ã«ãªã‚‹ã®ã‹ã‚’æ­£ç¢ºã«äºˆæ¸¬ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ãªã‚‰ã°ã€ãƒªãƒ¼ãƒ‰ã‚¹ãƒ«ãƒ¼ã‚ˆã‚Šã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬ ç‚¹: ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå¿…è¦ã«ãªã‚‹ã‹ã®äºˆæ¸¬ãŒæ­£ç¢ºã§ãªã„å ´åˆã«ã¯ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰ãŒãªã„æ–¹ãŒãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¯è‰¯ã„ã¨ã„ã†çµæœã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚æ¬ ç‚¹: ã‚­ãƒ£ãƒƒã‚·ãƒ¥cache invalidationãªã©ã‚’ç”¨ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®çœŸã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®é–“ã®ä¸€è²«æ€§ã‚’ä¿ã¤å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Redisã‚„memcachedã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹æˆã‚’å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Cache invalidationã‚‚é›£ã—ã„ã§ã™ãŒãã‚Œã«åŠ ãˆã¦ã€ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã‹ã¨ã„ã†è¤‡é›‘ãªå•é¡Œã«ã‚‚æ‚©ã¾ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸From cache to in-memory data gridã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€å¯ç”¨æ€§ã€å®‰å®šæ€§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£AWS ElastiCacheã®ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼WikipediaéåŒæœŸå‡¦ç†      Source: Intro to architecting systems for scaleéåŒæœŸã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ã‚‚ã—ã€é€£ç¶šçš„ã«è¡Œã‚ã‚Œã‚‹ã¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚é–“ã‚’åœ§è¿«ã—ã¦ã—ã¾ã†ã‚ˆã†ãªé‡ã„å‡¦ç†ã‚’åˆ¥ã§å‡¦ç†ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã¾ãŸã€å®šæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†åˆã•ã›ã‚‹ãªã©ã®æ™‚é–“ãŒã‹ã‹ã‚‹ã‚ˆã†ãªå‡¦ç†ã‚’å‰ã‚‚ã£ã¦å‡¦ç†ã—ã¦ãŠãã“ã¨ã«ã‚‚å½¹ç«‹ã¡ã¾ã™ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã€ä¿å­˜ã—ã€é…ä¿¡ã—ã¾ã™ã€‚ã‚‚ã—ã€å‡¦ç†ãŒã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã§è¡Œã†ã«ã¯é…ã™ãã‚‹å ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚’ç”¨ã„ã‚‹ã¨ã„ã„ã§ã—ã‚‡ã†:ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¸ãƒ§ãƒ–ã‚’ã‚­ãƒ¥ãƒ¼ã«é…ä¿¡ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ä¼ãˆã¾ã™ã€‚ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å—ã‘å–ã£ã¦ã€å‡¦ç†ã‚’è¡Œã„ã€çµ‚äº†ã—ãŸã‚‰ãã®ã‚·ã‚°ãƒŠãƒ«ã‚’è¿”ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‡¦ç†ãŒæ­¢ã¾ã‚‹ã“ã¨ã¯ãªãã€ã‚¸ãƒ§ãƒ–ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å‡¦ç†ã•ã‚Œã¾ã™ã€‚ã“ã®é–“ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã€ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ãŸã‹ã®ã‚ˆã†ã«è¦‹ã›ã‚‹ãŸã‚ã«å°è¦æ¨¡ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æŠ•ç¨¿ã™ã‚‹ã¨ãã«ã€ãƒ„ã‚¤ãƒ¼ãƒˆã¯ã™ãã«ã‚ãªãŸã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«åæ˜ ã•ã‚ŒãŸã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€ãã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒå®Ÿéš›ã«å…¨ã¦ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã«é…ä¿¡ã•ã‚Œã‚‹ã¾ã§ã«ã¯ã‚‚ã†å°‘ã—æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã‚‹ã§ã—ã‚‡ã†ã€‚Redis ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä»²ä»‹ã¨ã—ã¦ã¯ã„ã„ã§ã™ãŒã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚RabbitMQ ã¯ã‚ˆãä½¿ã‚ã‚Œã¦ã„ã¾ã™ãŒã€'AMQP'ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¯¾å¿œã—ã¦ã€è‡ªå‰ã®ãƒãƒ¼ãƒ‰ã‚’ç«‹ã¦ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Amazon SQS ã¨ã„ã†é¸æŠè‚¢ã‚‚ã‚ã‚Šã¾ã™ãŒã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒé«˜ãã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé‡è¤‡ã—ã¦é…ä¿¡ã•ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã¯ã‚¿ã‚¹ã‚¯ã¨ãã®é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€å‡¦ç†ã—ãŸä¸Šã§ãã®çµæœã‚’è¿”ã—ã¾ã™ã€‚ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã‚’ã§ãã‚‹ã»ã‹ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã¨ã¦ã‚‚é‡ã„ã‚¸ãƒ§ãƒ–ã‚’ã“ãªã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚Celery ã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨pythonã®ã‚µãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚‚ã—ã€ã‚­ãƒ¥ãƒ¼ãŒæ‹¡å¤§ã—ã™ãã‚‹ã¨ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã‚ˆã‚Šã‚‚ã‚­ãƒ¥ãƒ¼ã®æ–¹ãŒå¤§ãããªã‚Šã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ãŒèµ·ã“ã‚Šã€ãƒ‡ã‚£ã‚¹ã‚¯èª­ã¿å‡ºã—ã«ã¤ãªãŒã‚Šã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã«ã¤ãªãŒã‚Šã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã¯ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§å›é¿ã™ã‚‹ã“ã¨ãŒã§ãã€é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¢ºä¿ã—ã‚­ãƒ¥ãƒ¼ã«ã™ã§ã«ã‚ã‚‹ã‚¸ãƒ§ãƒ–ã«ã¤ã„ã¦ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’çŸ­ç¸®ã§ãã¾ã™ã€‚ã‚­ãƒ¥ãƒ¼ãŒã„ã£ã±ã„ã«ãªã‚‹ã¨ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã‚µãƒ¼ãƒãƒ¼ãƒ“ã‚¸ãƒ¼ã‚‚ã—ãã¯HTTP 503ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦å—ã‘å–ã‚Šã¾ãŸå¾Œã§æ™‚é–“ã‚’ãŠã„ã¦ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚ˆã†ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯exponential backoffãªã©ã«ã‚ˆã£ã¦å¾Œã»ã©å†åº¦æ™‚é–“ã‚’ç½®ã„ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬ ç‚¹: éåŒæœŸå‡¦ç†ã‚­ãƒ¥ãƒ¼ã‚’ç”¨ã„ã‚‹ã“ã¨ã§é…å»¶ãŒèµ·ã“ã‚Šã€è¤‡é›‘ã•ã‚‚å¢—ã™ãŸã‚ã€ã‚ã¾ã‚Šé‡ããªã„è¨ˆç®—å‡¦ç†ã‚„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ãŠã„ã¦ã¯åŒæœŸå‡¦ç†ã®æ–¹ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸It's all a numbers gameã‚ªãƒ¼ãƒãƒ¼ãƒ­ãƒ¼ãƒ‰ã—ãŸæ™‚ã«ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚’é©ç”¨ã™ã‚‹Little's lawãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¨ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã®é•ã„ã¨ã¯ï¼Ÿé€šä¿¡      Source: OSI 7 layer modelHypertext transfer protocol (HTTP)HTTP ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦è»¢é€ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã§ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«é–¢ã‚ã‚‹ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚µãƒ¼ãƒãƒ¼ã«æŠ•ã’ã€ã‚µãƒ¼ãƒãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã«é–¢ä¿‚ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨å®Œäº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚HTTPã¯è‡ªå·±å®Œçµã™ã‚‹ã®ã§ã€é–“ã«ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ³ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã€åœ§ç¸®ãªã©ã®ã©ã‚“ãªä¸­é–“ãƒ«ãƒ¼ã‚¿ãƒ¼ãŒå…¥ã£ã¦ã‚‚å‹•ãã‚ˆã†ã«ã§ãã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯HTTPå‹•è©(ãƒ¡ã‚½ãƒƒãƒ‰)ã¨ãƒªã‚½ãƒ¼ã‚¹(ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ)ã§æˆã‚Šç«‹ã£ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ãŒã‚ˆãã‚ã‚‹HTTPå‹•è©ã§ã™ã€‚:å‹•è©è©³ç´°å†ªç­‰æ€§*ã‚»ãƒ¼ãƒ•ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§ãã‚‹ã‹GETãƒªã‚½ãƒ¼ã‚¹ã‚’èª­ã¿å–ã‚‹YesYesYesPOSTãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹ã‚‚ã—ãã¯ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ãƒˆãƒªã‚¬ãƒ¼NoNoYes ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚€å ´åˆPUTãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã‚‚ã—ãã¯å…¥ã‚Œæ›¿ãˆã‚‹YesNoNoPATCHãƒªã‚½ãƒ¼ã‚¹ã‚’éƒ¨åˆ†çš„ã«æ›´æ–°ã™ã‚‹NoNoYes ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚€å ´åˆDELETEãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ã™ã‚‹YesNoNoä½•åº¦å‘¼ã‚“ã§ã‚‚åŒã˜çµæœãŒè¿”ã£ã¦ãã‚‹ã“ã¨HTTPã¯TCP ã‚„ UDP ãªã©ã®ä½ç´šãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: HTTPHTTPã£ã¦ãªã«?HTTP ã¨ TCPã®é•ã„PUT ã¨ PATCHã®é•ã„ä¼é€åˆ¶å¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ« (TCP)      Source: How to make a multiplayer gameTCPã¯IP networkã®ä¸Šã§æˆã‚Šç«‹ã¤æ¥ç¶šãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚æ¥ç¶šã¯handshakeã«ã‚ˆã£ã¦é–‹å§‹ã€è§£é™¤ã•ã‚Œã¾ã™ã€‚å…¨ã¦ã®é€ä¿¡ã•ã‚ŒãŸãƒ‘ã‚±ãƒƒãƒˆã¯æ¬ æãªã—ã§é€ä¿¡å…ˆã«é€ä¿¡ã•ã‚ŒãŸé †ç•ªã§åˆ°é”ã™ã‚‹ã‚ˆã†ã«ä»¥ä¸‹ã®æ–¹æ³•ã§ä¿è¨¼ã•ã‚Œã¦ã„ã¾ã™:ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã¨checksum fieldsãŒå…¨ã¦ã®ãƒ‘ã‚±ãƒƒãƒˆã«ç”¨æ„ã•ã‚Œã¦ã„ã‚‹Acknowledgementãƒ‘ã‚±ãƒƒãƒˆã¨è‡ªå‹•å†é€ä¿¡ã‚‚ã—é€ä¿¡è€…ãŒæ­£ã—ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ã‘å–ã‚‰ãªã‹ã£ãŸã¨ãã€ãƒ‘ã‚±ãƒƒãƒˆã‚’å†é€ä¿¡ã—ã¾ã™ã€‚è¤‡æ•°ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒã‚ã£ãŸã¨ãã€æ¥ç¶šã¯è§£é™¤ã•ã‚Œã¾ã™ã€‚TCP ã¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ ã¨ è¼»è¼³åˆ¶å¾¡ã‚‚å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã«ã‚ˆã£ã¦é€Ÿåº¦ã¯ä½ä¸‹ã—ã€ä¸€èˆ¬çš„ã«UDPã‚ˆã‚Šã‚‚éåŠ¹ç‡ãªè»¢é€æ‰‹æ®µã«ãªã£ã¦ã„ã¾ã™ã€‚ãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã¯ã‹ãªã‚Šå¤§ããªæ•°ã®TCPæ¥ç¶šã‚’é–‹ã„ã¦ãŠãã“ã¨ãŒã‚ã‚Šã€ãã®ã“ã¨ã§ãƒ¡ãƒ¢ãƒªãƒ¼ä½¿ç”¨ãŒåœ§è¿«ã•ã‚Œã¾ã™ã€‚ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã¨ä¾‹ãˆã°memcached ã‚µãƒ¼ãƒãƒ¼ã®é–“ã§å¤šæ•°ã®ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿ã£ã¦ãŠãã“ã¨ã¯é«˜ãã¤ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å¯èƒ½ãªã¨ã“ã‚ã§ã¯UDPã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã ã‘ã§ãªãã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãªã©ã‚‚å½¹ç«‹ã¤ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚TCPã¯é«˜ã„ä¾å­˜æ€§ã‚’è¦ã—ã€æ™‚é–“åˆ¶ç´„ãŒå³ã—ããªã„ã‚‚ã®ã«é©ã—ã¦ã„ã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã€SMTPã€FTPã‚„SSHãªã©ã®ä¾‹ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®æ™‚ã«UDPã‚ˆã‚Šã‚‚TCPã‚’ä½¿ã†ã¨ã„ã„ã§ã—ã‚‡ã†:å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒæ¬ æã™ã‚‹ã“ã¨ãªã—ã«å±Šã„ã¦ã»ã—ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®æœ€é©ãªè‡ªå‹•æ¨æ¸¬ã‚’ã—ã¦ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« (UDP)      Source: How to make a multiplayer gameUDPã¯ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ã‚¹ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ï¼ˆãƒ‘ã‚±ãƒƒãƒˆã®ã‚ˆã†ãªã‚‚ã®ï¼‰ã¯ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ¬ãƒ™ãƒ«ã§ã®ä¿è¨¼ã—ã‹ã•ã‚Œã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ã¯é †ä¸åŒã§å—ã‘å–ã‚Šå…ˆã«åˆ°ç€ã—ãŸã‚Šãã‚‚ãã‚‚ç€ã‹ãªã‹ã£ãŸã‚Šã—ã¾ã™ã€‚UDPã¯è¼»è¼³åˆ¶å¾¡ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã›ã‚“ã€‚TCPã«ãŠã„ã¦ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã“ã‚Œã‚‰ã®ä¿è¨¼ãŒãªã„ãŸã‚ã€UDPã¯ä¸€èˆ¬çš„ã«ã€TCPã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã™ã€‚UDPã¯ã‚µãƒ–ãƒãƒƒãƒˆä¸Šã®ã™ã¹ã¦ã®æ©Ÿå™¨ã«ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ã‚’é€ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã¯DHCP ã«ãŠã„ã¦å½¹ã«ç«‹ã¡ã¾ã™ã€‚ã¨ã„ã†ã®ã‚‚ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã¾ã IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—ã—ã¦ã„ãªã„ã®ã§ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å¿…è¦ã¨ã™ã‚‹TCPã«ã‚ˆã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒã§ããªã„ã‹ã‚‰ã§ã™ã€‚UDPã¯ä¿¡é ¼æ€§ã®é¢ã§ã¯åŠ£ã‚Šã¾ã™ãŒã€VoIPã€ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚„åŒæ™‚é€šä¿¡ãƒãƒ«ãƒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚²ãƒ¼ãƒ ãªã©ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒé‡è¦–ã•ã‚Œã‚‹æ™‚ã«ã¯ã¨ã¦ã‚‚åŠ¹æœçš„ã§ã™ã€‚TCPã‚ˆã‚Šã‚‚UDPã‚’ä½¿ã†ã®ã¯:ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’æœ€ä½é™ã«æŠ‘ãˆãŸã„æ™‚ãƒ‡ãƒ¼ã‚¿æ¬ æã‚ˆã‚Šã‚‚ã€ãƒ‡ãƒ¼ã‚¿é…å»¶ã‚’é‡è¦–ã™ã‚‹ã¨ãã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚’è‡ªå‰ã§å®Ÿè£…ã—ãŸã„ã¨ããã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: TCP ã¨ UDPã‚²ãƒ¼ãƒ ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ãŸã‚ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯TCP ã¨ UDP ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ä¸»ãªé•ã„TCP ã¨ UDPã®é•ã„Transmission control protocolUser datagram protocolFacebookã®ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°é éš”æ‰‹ç¶šå‘¼å‡º (RPC)      Source: Crack the system design interviewRPCã§ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒªãƒ¢ãƒ¼ãƒˆã‚µãƒ¼ãƒãƒ¼ãªã©ã®ç•°ãªã‚‹ã‚¢ãƒ‰ãƒ¬ã‚¹ç©ºé–“ã§ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ãŒå‡¦ç†ã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ã‚³ãƒ¼ãƒ«ã®ã‚ˆã†ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã«ã©ã®ã‚ˆã†ã«é€šä¿¡ã™ã‚‹ã‹ã¨ã„ã†è©³ç´°ã‚’çœã„ãŸçŠ¶æ…‹ã§ã‚³ãƒ¼ãƒ‰ãŒæ›¸ã‹ã‚Œã¾ã™ã€‚ãƒªãƒ¢ãƒ¼ãƒˆã®ã‚³ãƒ¼ãƒ«ã¯æ™®é€šã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ã‚³ãƒ¼ãƒ«ã‚ˆã‚Šã‚‚é…ãã€ä¿¡é ¼æ€§ã«æ¬ ã‘ã‚‹ãŸã‚ã€RPCã‚³ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‚³ãƒ¼ãƒ«ã¨åŒºåˆ¥ã•ã›ã¦ãŠãã“ã¨ãŒå¥½ã¾ã—ã„ã§ã—ã‚‡ã†ã€‚äººæ°—ã®RPCãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ä»¥ä¸‹ã§ã™ã€‚Protobufã€ Thriftã€AvroRPC ã¯ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒˆã‚³ãƒ«:ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ  - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚³ãƒ¼ãƒ«ã®ã‚ˆã†ã«ã‚¹ã‚¿ãƒƒã‚¯ã¸ã¨ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ãã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ - ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£IDã¨ã‚¢ãƒ¼ã‚®ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ‘ãƒƒã‚¯ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã—ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé€šä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - OSãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã¸ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚Šã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼é€šä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - OSãŒå—ã‘å–ã£ãŸãƒ‘ã‚±ãƒƒãƒˆã‚’ã‚µãƒ¼ãƒãƒ¼ã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã«å—ã‘æ¸¡ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ -  çµæœã‚’å±•é–‹ã—ã€ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼IDã«ãƒãƒƒãƒã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’è¿”ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ä¸Šè¨˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é€†é †ã§ç¹°ã‚Šè¿”ã—ã¾ã™ã€‚Sample RPC calls:GET /someoperation?data=anIdPOST /anotheroperation{  \""data\"":\""anId\"";  \""anotherdata\"": \""another value\""}RPCã¯æŒ¯ã‚‹èˆã„ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚RPCã¯å†…éƒ¨é€šä¿¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç†ç”±ã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ã¨ã„ã†ã®ã‚‚ã€ä½¿ç”¨ã™ã‚‹çŠ¶æ³ã«åˆã‚ã›ã¦ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚³ãƒ¼ãƒ«ã‚’è‡ªä½œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã‚‰ã§ã™ã€‚ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼ (aka SDK) ã‚’å‘¼ã¶ã®ã¯ä»¥ä¸‹ã®æ™‚:ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’çŸ¥ã£ã¦ã„ã‚‹æ™‚ãƒ­ã‚¸ãƒƒã‚¯ãŒã©ã®ã‚ˆã†ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ã®ã‹ã‚’ç®¡ç†ã—ãŸã„ã¨ããƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼å¤–ã§ã‚¨ãƒ©ãƒ¼ãŒã©ã®ã‚ˆã†ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã•ã‚Œã‚‹ã‹ã‚’ç®¡ç†ã—ãŸã„æ™‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ãŒæœ€å„ªå…ˆã®æ™‚REST ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¾“ã†HTTP APIã¯ãƒ‘ãƒ–ãƒªãƒƒã‚¯APIã«ãŠã„ã¦ã‚ˆãç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚æ¬ ç‚¹: RPCRPCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã¯ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…ã«ã‚ˆã‚Šå³å¯†ã«å·¦å³ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ–°ã—ã„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ä½¿ç”¨ä¾‹ãŒã‚ã‚‹ãŸã³ã«æ–°ã—ãAPIãŒå®šç¾©ã•ã‚Œãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚RPCã‚’ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ã®ã¯é›£ã—ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ—¢å­˜ã®ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚’ãã®ã¾ã¾ä½¿ã£ã¦ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€Squidãªã©ã®ã‚µãƒ¼ãƒãƒ¼ã«RPCã‚³ãƒ¼ãƒ«ãŒæ­£ã—ãã‚­ãƒ£ãƒƒã‚·ãƒ¥ ã•ã‚Œã‚‹ã‚ˆã†ã«è¿½åŠ ã§éª¨ã‚’æŠ˜ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚Representational state transfer (REST)RESTã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒã‚µãƒ¼ãƒãƒ¼ã«ã‚ˆã£ã¦ãƒãƒãƒ¼ã‚¸ã•ã‚Œã‚‹ãƒªã‚½ãƒ¼ã‚¹ã«å¯¾ã—ã¦å‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ»ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’æ”¯æŒã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚­ãƒãƒ£ã‚¹ã‚¿ã‚¤ãƒ«ã§ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯æ“ä½œã§ãã‚‹ã‚‚ã—ãã¯æ–°ã—ã„ãƒªã‚½ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ãªãƒªã‚½ãƒ¼ã‚¹ã‚„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ¬ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚ã™ã¹ã¦ã®é€šä¿¡ã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯èƒ½ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚RESTful ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«ã¯æ¬¡ã®å››ã¤ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™:ç‰¹å¾´çš„ãªãƒªã‚½ãƒ¼ã‚¹ (URI in HTTP) - ã©ã®ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚ã£ã¦ã‚‚åŒã˜URIã‚’ä½¿ã†ã€‚HTTPå‹•è©ã«ã‚ˆã£ã¦å¤‰ã‚ã‚‹ (Verbs in HTTP) - å‹•è©ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒœãƒ‡ã‚£ã‚’ä½¿ã†è‡ªå·±èª¬æ˜çš„ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (status response in HTTP) - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã„ã€æ–°ã—ãä½œã£ãŸã‚Šã—ãªã„ã“ã¨ã€‚HATEOAS (HTML interface for HTTP) - è‡ªåˆ†ã®webã‚µãƒ¼ãƒ“ã‚¹ãŒãƒ–ãƒ©ã‚¦ã‚¶ã§å®Œå…¨ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã“ã¨ã€‚ã‚µãƒ³ãƒ—ãƒ« REST ã‚³ãƒ¼ãƒ«:GET /someresources/anIdPUT /someresources/anId{\""anotherdata\"": \""another value\""}RESTã¯ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼ã®ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ã‚’æœ€å°é™ã«ã™ã‚‹ã‚‚ã®ã§ã€ãƒ‘ãƒ–ãƒªãƒƒã‚¯APIãªã©ã«ã‚ˆãç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚RESTã¯URIã€ representation through headersã€ãã—ã¦ã€GETã€POSTã€PUTã€ DELETEã€PATCHãªã©ã®HTTPå‹•è©ç­‰ã®ã‚ˆã‚Šã‚¸ã‚§ãƒãƒªãƒƒã‚¯ã§çµ±ä¸€ã•ã‚ŒãŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¾ã™ã€‚ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹ã®ã§RESTã¯æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã«æœ€é©ã§ã™ã€‚æ¬ ç‚¹: RESTRESTã¯ãƒ‡ãƒ¼ã‚¿å…¬é–‹ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã®ã§ã€ãƒªã‚½ãƒ¼ã‚¹ãŒè‡ªç„¶ã«æ•´ç†ã•ã‚Œã¦ã„ãªã‹ã£ãŸã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ã§è¡¨ã›ã‚‰ã‚Œãªã„æ™‚ã«ã¯ã‚ˆã„é¸æŠè‚¢ã¨ã¯è¨€ãˆãªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€ã¨ã‚ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã«ãƒãƒƒãƒã™ã‚‹ã™ã¹ã¦ã®æ›´æ–°æƒ…å ±ã‚’è¿”ã™ã¨è¨€ã£ãŸå‡¦ç†ã¯ç°¡å˜ã«ã¯ãƒ‘ã‚¹ã§è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚RESTã§ã¯ã€URIãƒ‘ã‚¹ã€ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãã—ã¦å ´åˆã«ã‚ˆã£ã¦ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ãªã©ã«ã‚ˆã£ã¦å®Ÿè£…ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã€‚RESTã¯å°‘æ•°ã®å‹•è©ã«ä¾å­˜ã—ã¦ã„ã¾ã™(GETã€POSTã€PUTã€DELETEã€ãã—ã¦ PATCH) ãŒæ™‚ã«ã¯ä½¿ã„ãŸã„äº‹ä¾‹ã«åˆã‚ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€æœŸé™ã®åˆ‡ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ç§»ã—ãŸã„å ´åˆãªã©ã¯ã“ã‚Œã‚‰ã®å‹•è©ã®ä¸­ã«ã¯ç¶ºéº—ã«ã¯ãƒ•ã‚£ãƒƒãƒˆã—ã¾ã›ã‚“ã€‚ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ã®ä¸­ã«ã‚ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚’ã¨ã£ã¦ãã‚‹ã®ã¯ã‚·ãƒ³ã‚°ãƒ«ãƒ“ãƒ¥ãƒ¼ã‚’æç”»ã™ã‚‹ã®ã«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã§æ•°å›ã‚„ã‚Šã¨ã‚Šã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ä¾‹ã¨ã—ã¦ã€ãƒ–ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ãã‚Œã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤ºã™ã‚‹å ´åˆãªã©ã§ã™ã€‚æ§˜ã€…ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒã§å‹•ä½œã™ã‚‹å¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã‚‹ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã¯ã“ã®ã‚ˆã†ãªè¤‡æ•°ã®ã‚„ã‚Šå–ã‚Šã¯å¥½ã¾ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚æ™‚ãŒçµŒã¤ã«ã¤ã‚Œã¦ã€APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚ˆã‚Šå¤šãã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸ãˆã‚‰ã‚Œã¦ã€å¤ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã™ã§ã«ã„ã‚‰ãªã„ã‚‚ã®ã‚‚å«ã‚ã¦ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å—ã‘å–ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ã“ã¨ã§ã€ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãŒå¤§ãããªã‚Šã™ãã¦ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚‚æ‹¡å¤§ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚RPCã¨RESTæ¯”è¼ƒOperationRPCRESTã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—POST /signupPOST /personsãƒªã‚¶ã‚¤ãƒ³POST /resign{\""personid\"": \""1234\""}DELETE /persons/1234Personèª­ã¿è¾¼ã¿GET /readPerson?personid=1234GET /persons/1234Personã®ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿GET /readUsersItemsList?personid=1234GET /persons/1234/itemsPersonã®ã‚¢ã‚¤ãƒ†ãƒ ã¸ã®ã‚¢ã‚¤ãƒ†ãƒ è¿½åŠ POST /addItemToUsersItemsList{\""personid\"": \""1234\"";\""itemid\"": \""456\""}POST /persons/1234/items{\""itemid\"": \""456\""}ã‚¢ã‚¤ãƒ†ãƒ æ›´æ–°POST /modifyItem{\""itemid\"": \""456\"";\""key\"": \""value\""}PUT /items/456{\""key\"": \""value\""}ã‚¢ã‚¤ãƒ†ãƒ å‰Šé™¤POST /removeItem{\""itemid\"": \""456\""}DELETE /items/456  Source: Do you really know why you prefer REST over RPCãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: REST ã¨ RPCDo you really know why you prefer REST over RPCWhen are RPC-ish approaches more appropriate than REST?REST vs JSON-RPCDebunking the myths of RPC and RESTWhat are the drawbacks of using RESTCrack the system design interviewThriftWhy REST for internal use and not RPCã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯æ›´æ–°ãŒå¿…è¦ã§ã™ã€‚contributingã—ã¦ãã ã•ã„ï¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¯å¹…åºƒã„ãƒˆãƒ”ãƒƒã‚¯ã§ã™ã€‚ååˆ†ãªçµŒé¨“ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†é‡ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãŒãªãã¦ã‚‚ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®çŸ¥è­˜ã‚’è¦ã™ã‚‹è·ã«å¿œå‹Ÿã™ã‚‹ã®ã§ãªã„é™ã‚Šã€åŸºæœ¬ä»¥ä¸Šã®ã“ã¨ã‚’çŸ¥ã‚‹å¿…è¦ã¯ãªã„ã§ã—ã‚‡ã†ã€‚æƒ…å ±ä¼é”ã€ä¿å­˜ã«ãŠã‘ã‚‹æš—å·åŒ–XSS ã‚„ SQL injectionã‚’é˜²ããŸã‚ã«ã€å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚‚ã—ãã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«éœ²å‡ºã•ã‚Œã‚‹å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã™ã‚‹SQL injectionã‚’é˜²ããŸã‚ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’ç”¨ã„ã‚‹ã€‚least privilegeã®åŸç†ã‚’ç”¨ã„ã‚‹ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:é–‹ç™ºè€…ã®ãŸã‚ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¬ã‚¤ãƒ‰OWASP top tenè£œéºæš—ç®—ã§ã€æ¨è¨ˆå€¤ã‚’æ±‚ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚‚æ™‚ã«ã¯ã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰100æšã‚¤ãƒ¡ãƒ¼ã‚¸åˆ†ã®ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ä½œã‚‹æ™‚é–“ã‚’æ±‚ã‚ãŸã‚Šã€ãã®æ™‚ã«ã©ã‚Œã ã‘ãƒ‡ã‚£ã‚¹ã‚¯ãƒ¡ãƒ¢ãƒªãƒ¼ãŒæ¶ˆè²»ã•ã‚Œã‚‹ã‹ãªã©ã®å€¤ã§ã™ã€‚2ã®ä¹—æ•°è¡¨ ã¨ å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ ã¯è‰¯ã„å‚è€ƒã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚2ã®ä¹—æ•°è¡¨ä¹—æ•°           å³å¯†ãªå€¤         ç´„        Bytes---------------------------------------------------------------7                             1288                             25610                           1024   1 thousand           1 KB16                         65,536                       64 KB20                      1,048,576   1 million            1 MB30                  1,073,741,824   1 billion            1 GB32                  4,294,967,296                        4 GB40              1,099,511,627,776   1 trillion           1 TBãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤Latency Comparison Numbers--------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy            10,000   ns       10 usSend 1 KB bytes over 1 Gbps network     10,000   ns       10 usRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSDRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSDSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 msNotes-----1 ns = 10^-9 seconds1 us = 10^-6 seconds = 1,000 ns1 ms = 10^-3 seconds = 1,000 us = 1,000,000 nsä¸Šè¨˜è¡¨ã«åŸºã¥ã„ãŸå½¹ã«ç«‹ã¤æ•°å€¤:ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 30 MB/s1 Gbps Ethernetã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ã€€100 MB/sSSDã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 1 GB/smain memoryã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 4 GB/s1ç§’ã§åœ°çƒ6-7å‘¨ã§ãã‚‹1ç§’ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã¨2000å‘¨ã‚„ã‚Šã¨ã‚Šã§ãã‚‹ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã®è¦–è¦šçš„è¡¨ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ - 1å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ - 2Designs, lessons, and advice from building large distributed systemsSoftware Engineering Advice from Building Large-Scale Distributed Systemsä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ä¾‹é¡Œé »å‡ºã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨ãã®è§£ç­”ã¸ã®ãƒªãƒ³ã‚¯è³ªå•è§£ç­”Dropboxã®ã‚ˆã†ãªãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹youtube.comGoogleã®ã‚ˆã†ãªæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­è¨ˆqueue.acm.orgstackexchange.comardendertat.comstanford.eduGoogleã®ã‚ˆã†ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªwebã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®è¨­è¨ˆquora.comGoogle docsã®è¨­è¨ˆcode.google.comneil.fraser.nameRedisã®ã‚ˆã†ãªã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã®è¨­è¨ˆslideshare.netMemcachedã®ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆslideshare.netAmazonã®ã‚ˆã†ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆhulu.comijcai13.orgBitlyã®ã‚ˆã†ãªURLçŸ­ç¸®ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆn00tc0d3r.blogspot.comWhatsAppã®ã‚ˆã†ãªãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã®è¨­è¨ˆhighscalability.comInstagramã®ã‚ˆã†ãªå†™çœŸå…±æœ‰ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆhighscalability.comhighscalability.comFacebookãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚£ãƒ¼ãƒ‰ã®è¨­è¨ˆquora.comquora.comslideshare.netFacebookã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®è¨­è¨ˆfacebook.comhighscalability.comFacebookãƒãƒ£ãƒƒãƒˆã®è¨­è¨ˆerlang-factory.comfacebook.comFacebookã®ã‚ˆã†ãªgraphæ¤œç´¢ã®è¨­è¨ˆfacebook.comfacebook.comfacebook.comCloudFlareã®ã‚ˆã†ãªCDNã®è¨­è¨ˆcmu.eduTwitterã®ãƒˆãƒ¬ãƒ³ãƒ‰æ©Ÿèƒ½ã®è¨­è¨ˆmichael-noll.comsnikolov .wordpress.comãƒ©ãƒ³ãƒ€ãƒ IDç™ºè¡Œã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆblog.twitter.comgithub.comä¸€å®šã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«æ™‚é–“ã§ã®ä¸Šä½kä»¶ã‚’è¿”ã™ucsb.eduwpi.eduè¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’é…ä¿¡ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆhighscalability.comã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®è¤‡æ•°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã®è¨­è¨ˆindieflashblog.combuildnewgames.comã‚¬ãƒ¼ãƒ™ãƒƒã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆstuffwithstuff.comwashington.eduã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆä¾‹é¡Œã‚’è¿½åŠ ã™ã‚‹Contributeå®Ÿä¸–ç•Œã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸–ã®ä¸­ã®ã‚·ã‚¹ãƒ†ãƒ ãŒã©ã®ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã®è¨˜äº‹      Source: Twitter timelines at scaleä»¥ä¸‹ã®è¨˜äº‹ã®é‡ç®±ã®éš…ã‚’ã¤ã¤ãã‚ˆã†ãªç´°ã‹ã„è©³ç´°ã«ã“ã ã‚ã‚‰ãªã„ã“ã¨ã€‚ã‚€ã—ã‚å…±é€šã®åŸç†ã€æŠ€è¡“ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã‚‹ã“ã¨ãã‚Œãã‚Œã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã©ã‚“ãªå•é¡ŒãŒè§£æ±ºã•ã‚Œã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¯ã©ã“ã§ã†ã¾ãä½¿ãˆã‚‚ã—ãã¯ä½¿ãˆãªã„ã‹ã‚’çŸ¥ã‚‹ã“ã¨å­¦ã‚“ã ã“ã¨ã‚’å¾©ç¿’ã™ã‚‹ã“ã¨ç¨®é¡ã‚·ã‚¹ãƒ†ãƒ å‚è€ƒãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿å‡¦ç†MapReduce - Googleã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ research.google.comãƒ‡ãƒ¼ã‚¿å‡¦ç†Spark - Databricksã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿å‡¦ç†Storm - Twitterã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Bigtable - Googleã®ã‚«ãƒ©ãƒ æŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹harvard.eduãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢HBase - Bigtableã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Cassandra - Facebookã®ã‚«ãƒ©ãƒ æŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢DynamoDB - Amazonã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹harvard.eduãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢MongoDB - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Spanner - Googleã®ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹research.google.comãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Memcached - åˆ†æ•£ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Redis - æ°¸ç¶šæ€§ã¨ãƒãƒªãƒ¥ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’å…¼ã­å‚™ãˆãŸåˆ†æ•£ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ Google File System (GFS) - åˆ†æ•£ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ research.google.comãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ Hadoop File System (HDFS) - GFSã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…apache.orgMiscChubby - ç–çµåˆã®åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ­ãƒƒã‚¯ã™ã‚‹Googleã®ã‚µãƒ¼ãƒ“ã‚¹research.google.comMiscDapper - åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’è¿½è·¡ã™ã‚‹ã‚¤ãƒ³ãƒ•ãƒ©research.google.comMiscKafka - LinkedInã«ã‚ˆã‚‹Pub/subãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼slideshare.netMiscZookeeper - åŒæœŸã‚’å¯èƒ½ã«ã™ã‚‹ä¸­å¤®é›†æ¨©ã‚¤ãƒ³ãƒ•ãƒ©ã¨ã‚µãƒ¼ãƒ“ã‚¹slideshare.netã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¿½åŠ ã™ã‚‹Contributeå„ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¼æ¥­å‚è€ƒãƒšãƒ¼ã‚¸AmazonAmazon architectureCinchcastProducing 1,500 hours of audio every dayDataSiftRealtime datamining At 120,000 tweets per secondDropBoxHow we've scaled DropboxESPNOperating At 100,000 duh nuh nuhs per secondGoogleGoogle architectureInstagram14 million users, terabytes of photosWhat powers InstagramJustin.tvJustin.Tv's live video broadcasting architectureFacebookScaling memcached at FacebookTAO: Facebookâ€™s distributed data store for the social graphFacebookâ€™s photo storageFlickrFlickr architectureMailboxFrom 0 to one million users in 6 weeksPinterestFrom 0 To 10s of billions of page views a month18 million visitors, 10x growth, 12 employeesPlayfish50 million monthly users and growingPlentyOfFishPlentyOfFish architectureSalesforceHow they handle 1.3 billion transactions a dayStack OverflowStack Overflow architectureTripAdvisor40M visitors, 200M dynamic page views, 30TB dataTumblr15 billion page views a monthTwitterMaking Twitter 10000 percent fasterStoring 250 million tweets a day using MySQL150M active users, 300K QPS, a 22 MB/S firehoseTimelines at scaleBig and small data at TwitterOperations at Twitter: scaling beyond 100 million usersUberHow Uber scales their real-time market platformWhatsAppThe WhatsApp architecture Facebook bought for $19 billionYouTubeYouTube scalabilityYouTube architectureä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°é¢æ¥ã‚’å—ã‘ã‚‹ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æŠ•ã’ã‚‰ã‚Œã‚‹è³ªå•ã¯åŒã˜åˆ†é‡ã‹ã‚‰æ¥ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã§ã—ã‚‡ã†Airbnb EngineeringAtlassian DevelopersAutodesk EngineeringAWS BlogBitly Engineering BlogBox BlogsCloudera Developer BlogDropbox Tech BlogEngineering at QuoraEbay Tech BlogEvernote Tech BlogEtsy Code as CraftFacebook EngineeringFlickr CodeFoursquare Engineering BlogGitHub Engineering BlogGoogle Research BlogGroupon Engineering BlogHeroku Engineering BlogHubspot Engineering BlogHigh ScalabilityInstagram EngineeringIntel Software BlogJane Street Tech BlogLinkedIn EngineeringMicrosoft EngineeringMicrosoft Python EngineeringNetflix Tech BlogPaypal Developer BlogPinterest Engineering BlogQuora EngineeringReddit BlogSalesforce Engineering BlogSlack Engineering BlogSpotify LabsTwilio Engineering BlogTwitter EngineeringUber Engineering BlogYahoo Engineering BlogYelp Engineering BlogZynga Engineering Blogãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:kilimchoi/engineering-blogsã“ã“ã«ã‚ã‚‹ãƒªã‚¹ãƒˆã¯æ¯”è¼ƒçš„å°è¦æ¨¡ãªã‚‚ã®ã«ã¨ã©ã‚ã€kilimchoi/engineering-blogsã«ã‚ˆã‚Šè©³ç´°ã«è¨˜ã™ã“ã¨ã§é‡è¤‡ã—ãªã„ã‚ˆã†ã«ã—ã¦ãŠãã“ã¨ã«ã™ã‚‹ã€‚ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°ã¸ã®ãƒªãƒ³ã‚¯ã‚’è¿½åŠ ã™ã‚‹å ´åˆã¯ã“ã“ã§ã¯ãªãã€engineering-blogsãƒ¬ãƒœã‚¸ãƒˆãƒªã«è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚é€²è¡Œä¸­ã®ä½œæ¥­ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¿½åŠ ã‚„ã€é€²è¡Œä¸­ã®ä½œæ¥­ã‚’æ‰‹ä¼ã£ã¦ã„ãŸã ã‘ã‚‹å ´åˆã¯ã“ã¡ã‚‰!MapReduceã«ã‚ˆã‚‹åˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°Consistent hashingScatter gatherContributeã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¯ãƒ¬ã‚¸ãƒƒãƒˆåŠã³ã€å‚ç…§ãƒšãƒ¼ã‚¸ã¯é©æ™‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªå†…ã«è¨˜è¼‰ã—ã¦ã‚ã‚Šã¾ã™Special thanks to:Hired in techCracking the coding interviewHigh scalabilitycheckcheckzz/system-design-interviewshashank88/system_designmmcgrana/services-engineeringSystem design cheat sheetA distributed systems reading listCracking the system design interviewContact infoFeel free to contact me to discuss any issues, questions, or comments.My contact info can be found on my GitHub page.LicenseI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2017 Donne MartinCreative Commons Attribution 4.0 International License (CC BY 4.0)http://creativecommons.org/licenses/by/4.0/"
41,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        ç®€ä½“ä¸­æ–‡ |        ç¹é«”ä¸­æ–‡ |        í•œêµ­ì–´ |        EspaÃ±ol |        æ—¥æœ¬èª |        à¤¹à¤¿à¤¨à¥à¤¦à¥€        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    ğŸ¤— Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:ğŸ“ Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.ğŸ–¼ï¸ Images, for tasks like image classification, object detection, and segmentation.ğŸ—£ï¸ Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.ğŸ¤— Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.ğŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install ğŸ¤— Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, ğŸ¤— Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.ğŸ¤— Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by ğŸ¤— Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: ğŸ¤— Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from Ã‰cole polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz SuÃ¡rez*, Yoann Dupont, Laurent Romary, Ã‰ric Villemonte de la Clergerie, DjamÃ© Seddah and BenoÃ®t Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of GÃ¶ttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo LÃ¼ddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, HervÃ© JÃ©gou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp KrÃ¤henbÃ¼hl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, TimothÃ©e Darcet, ThÃ©o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, HervÃ© Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas OÄŸuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by RenÃ© Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre DÃ©fossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, LoÃ¯c Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, BenoÃ®t CrabbÃ©, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey Ã–hman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo GarcÃ­a del RÃ­o, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, HervÃ© JÃ©gou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by JÃ¶rg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre DÃ©fossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noahâ€™s Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NystrÃ¶mformer (from the University of Wisconsin - Madison) released with the paper NystrÃ¶mformer: A NystrÃ¶m-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier HÃ©naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, JoÃ£o Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, Åukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr DollÃ¡r.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault FÃ©vry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of WÃ¼rzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, PaweÅ‚ Krzysztof Nowak, Thomas MÃ¼ller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÃ¡r, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario LuÄiÄ‡, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper â€‹XLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the ğŸ¤— Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by ğŸ¤— TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by ğŸ¤— Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the ğŸ¤— Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
42,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answersâš ï¸ DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]ğŸ™ PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!ğŸ‰ AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.â“ Need help?Open new issueğŸ”¥ Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accountingâ—needs updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustratorâ—needs updating  7674Adobe-InDesignâ—needs updating  4240Adobe-Lightroomâ—needs updating  2020Adobe-Photoshopâ—needs updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effectsâ—needs updating  2413Agile Methodologiesâ—needs updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCADâ—needs updating  7775@djayorAutodesk Fusion 360â—needs updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambdaâ—needs updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++â—needs updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurityâ—needs updating10196Django7171@PROCW.NET Framework6359@declarckEclipseâ—needs updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSONâ—needs updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excelâ—needs updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Projectâ—needs updating4443Microsoft Wordâ—needs updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooksâ—needs updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revitâ—needs updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePointâ—needs updating5338Sketchup22SOLIDWORKSâ—needs updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnityâ—needs updating4746@uno-sebastianVisual Basic for Applications (VBA)â—needs updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors âœ¨Thanks goes to these wonderful people (emoji key):            EvgeniiğŸ’» ğŸ–‹      Sergei StadnikğŸ’» ğŸ” ğŸ¤” ğŸ“–      SanthoshğŸ’»      Jacob DsağŸ’» ğŸ–‹      Aaron MeeseğŸ’» ğŸ–‹      arqarqğŸ’» ğŸ–‹      Amit YadavğŸ’» ğŸ–‹              Javokhir NazarovğŸ’» ğŸ–‹      saurav kumarğŸ–‹      ChetanğŸ–‹      Amir Hossein ShekariğŸ¨ ğŸ–‹ ğŸ’»      SergDautğŸ¨      Nilotpal PramanikğŸ¨ ğŸ’» ğŸ–‹ ğŸ’¼ ğŸ“– ğŸ”£ ğŸ’¡      Abhishek KumarğŸ¨              Monu GuptağŸ¨      KARTIKEYA GUPTAğŸ’» ğŸ–‹      kenkyushağŸ’» ğŸ–‹      juandavidtowersğŸ’» ğŸ–‹      cyber-neticsğŸ’» ğŸ–‹      jtriswğŸ’» ğŸ–‹      Renato RegaladoğŸ’» ğŸ–‹              MatthewğŸ’» ğŸ–‹      Jan S.ğŸ’» ğŸ–‹      ManoliğŸ’» ğŸ–‹      Faraz tanveerğŸ’» ğŸ–‹      mohnishkarriğŸ’» ğŸ–‹ ğŸ¨      andyzhuğŸ’» ğŸ–‹      Vishal KushwahğŸ’» ğŸ–‹              Yurii YakymenkoğŸ’» ğŸ–‹      Swetabh SumanğŸ’» ğŸ–‹      AJAY DANDGEğŸ’» ğŸ–‹      Mehmet YesinğŸ¨      Lok Chun WaiğŸ¨      Adria de JuanğŸ¨      GL-ManğŸ¨              Jheel PatelğŸ¨      Sameer WaskarğŸ¨      Alexander AndrewsğŸ¨      Alexander MaxwellğŸ¨      SlavağŸ¨      Mayur KhatriğŸ¨      MascantoshğŸ’» ğŸ–‹ ğŸ“¢ ğŸ¤”              Kivanc EnesğŸ¨      Ritika DasğŸ¨      Zer07793ğŸ¨      Andrew CheungğŸ¨      SadhağŸ¨      tainenkoğŸ¨ ğŸ’»      github-star-coderğŸ¨              Danilo OliveirağŸ¨      lordekoğŸ¨      Shubham KumarğŸ¨ ğŸ’»      testtreeğŸ¨      Cheryl MurphyğŸ¨ ğŸ’»      Bipin ThomasğŸ¨      Abdulrahman HishamğŸ¨              Dakshitha DissanayakağŸ¨      BADR KACIMIğŸ¨      Alex WangğŸ¨      MaximğŸ¨      GordonGrantğŸ¨ ğŸ’»      Ephrem DemelashğŸ¨      JonOrcuttğŸ¨              topdev10ğŸ¨      cookwellwebsiteğŸ¨      xren935ğŸ¨      Nemo FrenkelğŸ¨      MD SAIF ALAMğŸ¨      Boris LÃ³pez ArayağŸ¨      Larry ChiemğŸ¨              Muhammad Bilal IlyasğŸ¨      AliMilaniğŸ¨ ğŸ’»      Suraj SahaniğŸ¨      FlyingSquirrelğŸ¨      Erick TijeroğŸ¨      Jaskaran KukrejağŸ¨      MichaelLğŸ¨              MagicLegendğŸ¨      Dereck BearsongğŸ¨      Pappu Kumar PashiğŸ¨      Venkata Kishore TavvağŸ¨      Rafat Touqir RafsunğŸ¨      Snehesh DuttağŸ¨      Timo KÃ¶rnerğŸ¨ ğŸ’»              alexxxanğŸ¨      GGJasonğŸ¨      LeeAnna EwingğŸ¨ ğŸ¤”      kamal JyotwalğŸ¨      Bob-JohnsğŸ¨ ğŸ’» ğŸ–‹      yunussalmanlyitğŸ¨ ğŸ’»      chilcotğŸ¨ ğŸ’»              Jacky LiğŸ’» ğŸ–‹ ğŸ¨      Sarthak TrivediğŸ¨      Ayush AggarwalğŸ¨ ğŸ’»      Nic BallariniğŸ¨      Luigi ZambettiğŸ¨ ğŸ’»      govindhaswinğŸ¨      Addy RoyğŸ’» ğŸ¨              Akshat TamrakarğŸ¨ ğŸ’»      Sai Bhargava RamuğŸ¨      GurkanğŸ’»      Spencer Hayes-LaverdiereğŸ’»      Aniket SoniğŸ’»      tanmay5792ğŸ’»      Dina TaklitğŸ’» ğŸ¨ ğŸ–‹              Dushyant SinghğŸ’»      Ravi Prakash SinghğŸ’»      Nihal JoshiğŸ’»      Guy KlagesğŸ’»      ArvindğŸ¨ ğŸ’»      mujeeb91ğŸ’»      josercağŸ¨ ğŸ’»              Prateek AgrawalğŸ’»      Teoh Tze Chuin(ã‚µãƒ©)ğŸ’» ğŸ¨      Jayant JainğŸ’»      Ayush SahuğŸ’»      Hridya Krishna RğŸ’» ğŸ¨      Rahul BaliğŸ’» ğŸ¨      S.ZHengğŸ¨ ğŸ’» ğŸ’¼              Shriya MadanğŸ¨ ğŸ’»      mahalrupiğŸ¨      Lucas LermagneğŸ¨      Jeff DeutschğŸ¨ ğŸ’»      Betoxx1ğŸ¨      Wingman4l7ğŸ¨      Martin EspericuetağŸ¨              Mh-TahirğŸ¨      Zdravko Å plajtğŸ¨ ğŸ’»      Ms3105ğŸ¨ ğŸ’» ğŸ–‹      Ambika SidheswareğŸ’»      mundogueroğŸ’»      Darkus24ğŸ–‹      Sou-786ğŸ–‹ ğŸ¨              BanurekhağŸ–‹      ShiraStarLğŸ¨      Ilya KomarovğŸ¨      DemigodMsğŸ–‹ ğŸ“–      Mekha HridyağŸ¨ ğŸ”      Andrey SafonovğŸ¨ ğŸ”      TommasoğŸ¨ ğŸ’»              Jessica SalbertğŸ’» ğŸ¨      JAYANTH DOLAIğŸ’» ğŸ¨      silverstroomğŸ’» ğŸ¨ ğŸ’¼      Furkan SayÄ±mğŸ’» ğŸ¨      Sukumar ChandrasekaranğŸ¨      Yejin ParkğŸ¨ ğŸ’»      Ali NooshabadiğŸ¨ ğŸ’»              imitavorğŸ¨ ğŸ’»      Salih KilicliğŸ¨ ğŸ’»      Marcelo MenesesğŸ¨ ğŸ’»      Anton KrekotunğŸ¨ ğŸš§ ğŸ–‹ ğŸ’» ğŸ“– ğŸ’¼      Arnav SarmağŸ’» ğŸ’¡ ğŸ¨      meghatikuğŸ’» ğŸ¨      Anshu TrivediğŸ¨              Taylor DorsettğŸ’» ğŸ–‹ ğŸ¨      Havit RovikğŸ’»      pushpapuneğŸ’» ğŸ¨      Ramtin RadfarğŸ¨ ğŸ¤” ğŸ’¼ ğŸ’µ ğŸ’» ğŸ–‹ ğŸ’¬      Abdulmajeed IsağŸ’» ğŸ¨      vikassaxena02ğŸ¨      RobTablesğŸ¨ ğŸ’» ğŸ’¼              DanielğŸ¨ ğŸ’» ğŸ’¼ ğŸ”      Zahid AliğŸ’» ğŸ¨      Chad ChaiğŸ’» ğŸ¨      Marco BiedermannğŸ’» ğŸ¨ ğŸ’¼ ğŸ¤”      Srinidhi MurthyğŸ¨      Miao CaiğŸ’» ğŸ¨      Dionicio DiazğŸ¨ ğŸ’»              Mir Monoarul AlamğŸ¨      Shawn OhnğŸ’» ğŸ¨      Amanbolat BalabekovğŸ¨ ğŸ’»      black-mamba-codeğŸ’»      Jian-forksğŸ¨ ğŸ’»      shivani patelğŸ¨      Akash ChowrasiağŸ¨              yairg98ğŸ¨      Jay GajjarğŸ¨      coolerboolerğŸ’»      Md Zinnatul Islam MorolğŸ¨      shresthashok550ğŸ¨ ğŸ“–      Alan PallathğŸ“–      Adrian WongğŸ’»              vsDizzyğŸ’» ğŸ¨      Frex CuadillerağŸ¨ ğŸ’»      ashish570ğŸ’» ğŸ¨      ruchpeanutsğŸ’» ğŸ¨      ArtmasqueğŸ¨ ğŸ’»      Amirhossein Mojiri ForoushaniğŸ¨      forğŸ’» ğŸ¨              LukeğŸ¨ ğŸ’»      Hector EspinozağŸ¨      AdriÃ¡n BuenfilğŸ¨ ğŸ’»      Amit KumarğŸ¨      schoppfeğŸ¨ ğŸ’»      Sofiyal CğŸ¨ ğŸ’»      spitliskğŸ’» ğŸ¨              PRAVIN SHARMAğŸ¨      NIDZAAA1ğŸ¨ ğŸ’»      John MaiğŸ¨ ğŸ’»      kimsoyeongğŸ¨      Dona GhoshğŸ’»      Ryan HillğŸ¨ ğŸ’»      j42zğŸ¨ ğŸ’»              Ashish SangaleğŸ¨ ğŸ’»      Derek YangğŸ¨ ğŸ’»      mohsinmsmğŸ¨ ğŸ’»      Gokulkrish2302ğŸ’»      BhaavishekğŸ’» ğŸ¨      Louis LiaoğŸ¨      sengc92ğŸ¨ ğŸ’»              Alex MarvinğŸ¨      Balkrishna BhattğŸ¨ ğŸ’»      Evaldas LavrinoviÄiusğŸ¨ ğŸ’»      Adam ErchegyiğŸ¨ ğŸ’»      Truman HungğŸ¨ ğŸ’»      rzamora11ğŸ¨      gaurav0224ğŸ¨              Lee GyeongJunğŸ¨      MirekğŸ¨ ğŸ’»      surajm245ğŸ¨      ArisLaodeğŸ¨ ğŸ’»      RaviDhoriyağŸ¨ ğŸ’»      sarai-84ğŸ¨ ğŸ’»      VishnuğŸ¨ ğŸ’»              Muhammad MinhajğŸ’»      Chandrika DebğŸ¨ ğŸ’»      Gitgit101-bitğŸ’» ğŸ¨      Hedi SellamiğŸ’» ğŸ¨      saurabhvaish93ğŸ’» ğŸ¨      Nikola BegovicğŸ’» ğŸ¨      WangğŸ’» ğŸ¨              Manuel Eusebio de Paz CarmonağŸ¨      Basim Al-JawaheryğŸ¨ ğŸ’»      RAJA AHMEDğŸ¨ ğŸ’»      Abhik LodhğŸ’»      Md. Pial AhamedğŸ’» ğŸ¨      Hassan ShahzadğŸ’» ğŸ¨      Christian Sosa GagoğŸ’»              Hasnain RasheedğŸ’» ğŸ¨      T-RadfordğŸ’»      dahiyashishğŸ’» ğŸ¨      RahulSharma468ğŸ’» ğŸ¨      Jumpod PlekhongthuğŸ’» ğŸ¨      Thomas Young-AudetğŸ’» ğŸ¨      VinayagamBabuğŸ’» ğŸ¨              Deniz KoÃ§ğŸ’» ğŸ¨      Azhar KhanğŸ’» ğŸ¨ ğŸ–‹ ğŸ“– ğŸ”£ ğŸš§      Jacob ShortğŸ’» ğŸ¨      Uchimura85ğŸ’» ğŸ¨      Leo NugrahağŸ’» ğŸ¨ ğŸ“–      Mujtaba MehdiğŸ“– ğŸ–‹      Jim-dsğŸ’» ğŸ¨              Sreehari KğŸ’» ğŸ¨      Florian MartinezğŸ’» ğŸ¨      AaronğŸ’» ğŸ¨      apoageğŸ¨      Ignacio Guillermo Martinez ğŸ’» ğŸ¨      AirlineDogğŸ¨ ğŸ’»      MekelğŸ¨ ğŸ’»              hmosharrofğŸ¨ ğŸ’»      Ben EmamianğŸ’» ğŸ¨      babesharkğŸ’» ğŸ¨      Leonardo JaquesğŸ’» ğŸ¨      Stefanos ApkarianğŸ’» ğŸ¨      Ayhan AlbayrakğŸ’» ğŸ¨      KidusMTğŸ’» ğŸ¨              hectormarroquin20ğŸ’» ğŸ¨      Edelweiss35ğŸ’» ğŸ¨      MihaiDğŸ’» ğŸ¨      AnveshReddyAnnemğŸ’» ğŸ¨      Hyunjae ParkğŸ’» ğŸ¨      Rajiv AlbinoğŸ’» ğŸ¨      AtishayğŸ’»              Yusuf NaheemğŸ¨      WinduğŸ¨ ğŸ’»      Superv1sorğŸ’» ğŸ¨      Karine (:ğŸ¨ ğŸ’»      Eduard PechğŸ¨ ğŸ’»      jjeshwaniğŸ¨ ğŸ’»      SteveğŸ¨ ğŸ’»              Aleigh OhslundğŸ’»      Abhinav SumanğŸ¨ ğŸ’»      Hamza Ehtesham FarooqğŸ¨ ğŸ’»      IamNotPeterPanğŸ’» ğŸ’µ ğŸ¨      CetgerğŸ¨      pkonopackiğŸ¨      Yang YangğŸ¨ ğŸ’»              Muhammad Shoaib SarwarğŸ’»      Murilo HenriqueğŸ’» ğŸ¨      emilianoalvzğŸ¨ ğŸ’»      Sumana SahağŸ¨ ğŸ’»      Yurii17KğŸ¨ ğŸ’»      Rupesh BhandariğŸ¨ ğŸ’»      salmos3718ğŸ’»              John BakerğŸ¨ ğŸ’»      SanjaySathirajuğŸ¨ ğŸ’»      Donat KabashiğŸ¨      Arul Prasad JğŸ¨ ğŸ’»      Qi ChenğŸ¨ ğŸ’»      Maksym DmyterkoğŸ¨ ğŸ’»      ilovepullrequestsğŸ’»              Samira MalekiğŸ¨ ğŸ’»      NIKITA MAHOVIYAğŸ’»      jesuisdev.NetğŸ¨ ğŸ’»      Ashraf NazarğŸ¨      Naveed AhmadğŸ¨      Ajmain NaqibğŸ¨ ğŸ’»      Avinash TingreğŸ’» ğŸ¨              nicktidsğŸ¨      Keith DinhğŸ’» ğŸ¨      AndrÃ© FerreirağŸ’» ğŸ¨      eliottkespiğŸ’» ğŸ¨      praveenpnoğŸ’» ğŸ¨      vitowidigdoğŸ’» ğŸ¨      Devesh Pratap SinghğŸ’» ğŸ¨              Dario RodriguezğŸ’» ğŸ¨      charmander_didiğŸ’» ğŸ¨      PHBasinğŸ’» ğŸ¨      Ritvik Singh ChauhanğŸ’» ğŸ¨      Riya P MathewğŸ’» ğŸ¨      Stephanie CherubinğŸ’» ğŸ¨      BenitesGuiğŸ’» ğŸ¨              FarikBearğŸ’» ğŸ¨      Dmytro HavrilovğŸ’» ğŸ¨      Parvesh MonuğŸ’» ğŸ¨      Dipen PanchasarağŸ’» ğŸ¨      gudatağŸ¨ ğŸ’»      gawadeditorğŸ’» ğŸ¨      Kirill TaletskiğŸ¨ ğŸ’»              SaajanğŸ¨ ğŸ’»      Kushagra SğŸ¨ ğŸ’»      Oanh LeğŸ¨ ğŸ’»      Frane MedvidoviÄ‡ğŸ¨ ğŸ’»      YormanğŸ¨ ğŸ’»      Bill ChanğŸ¨ ğŸ’»      Pratik LomteğŸ¨ ğŸ’»              LOC LAMğŸ¨ ğŸ’»      TUSAR RANJAN MAHAPATRAğŸ’»      BhargavKanjarlağŸ’»      Karel De SmetğŸ’» ğŸ¨      sidisanğŸ¨      ygnzayarphyoğŸ¨ ğŸ’»      svansteelandtğŸ’»              KebechetğŸ¨      Daniel Selvan DğŸ¨ ğŸ’»      Mahdi RazaviğŸ¨ ğŸ’»      Niklas TiedeğŸ’» ğŸ¨      narutubaderddinğŸ’» ğŸ¨      dylandhoodğŸ’»      Dheeraj GuptağŸ’»              Pieter ClaerhoutğŸ’» ğŸ¨      Shivam AgnihotriğŸ’»      RanjithReddy-NarrağŸ’»      Nikita WadhwaniğŸ¨ ğŸ’»      rsholokhğŸ’» ğŸ¨      Ayaan HossainğŸ’» ğŸ¨      Rajesh SwarnağŸ’»              Deniz EtkarğŸ¨ ğŸ’»      pro335ğŸ’» ğŸ¨      Jakub RadzikğŸ’» ğŸ¨      Hamza KhanzadağŸ’»      ARNONğŸ¨      Vikram SinghğŸ’»      ShoxruxbekğŸ’» ğŸ¨              Amit KhatriğŸ’» ğŸ¨      Wali UllahğŸ¨ ğŸ’»      Amit11794ğŸ’» ğŸ¨      metis-macys-66898ğŸ’» ğŸ¨      Faisal MaqboolğŸ¨ ğŸ’»      Kumar NeerajğŸ’» ğŸ¨      Maurizio MariniğŸ¨ ğŸ’»              Saket KothariğŸ¨ ğŸ’»      Szymon ZborowskiğŸ¨ ğŸ’»      iks3000ğŸ¨ ğŸ’»      Ehsan SeyediğŸ¨ ğŸ’»      vanekbrğŸ¨ ğŸ’»      Princy_MğŸ¨ ğŸ’»      Shijie ZhouğŸ¨ ğŸ’»              lakshyamcs16ğŸ¨ ğŸ’»      Filippo FaccoğŸ¨ ğŸ’»      mendel5ğŸ¨ ğŸ’»      PatrykğŸ¨ ğŸ’»      VishwaSanganiğŸ¨ ğŸ’»      Alvin ZhaoğŸ¨ ğŸ’»      Lazar GugletağŸ¨ ğŸ’»              vmichoğŸ¨ ğŸ’»      Sikandar AliğŸ¨ ğŸ’»      Raja BabuğŸ¨ ğŸ’»      faizajahanzebğŸ’»      Guil_AiTğŸ¨ ğŸ’»      Kushal DasğŸ¨ ğŸ’»      Luis BonillağŸ¨ ğŸ’»              jovan1013ğŸ¨ ğŸ’»      DamianğŸ¨ ğŸ’»      Yash GuptağŸ’»      lolcatnipğŸ¨ ğŸ’»      Ikko AshimineğŸ¨ ğŸ’»      FarukhğŸ¨ ğŸ’»      MoksedulğŸ’» ğŸ¨              Navneet KumarğŸ¨ ğŸ’»      Saqib AlMalikğŸ’»      fahimrahmanğŸ¨ ğŸ’»      vaibhav patilğŸ¨ ğŸ’»      Rahul MadanğŸ¨ ğŸ’»      kartik KaklotarğŸ¨ ğŸ’»      ASAHI OCEANğŸ¨ ğŸ’»              Daniel JungbluthğŸ¨ ğŸ’»      Rajdeep Singh BoranağŸ¨ ğŸ’»      ankitha19ğŸ’»      Linh TranğŸ’»      islamarrğŸ’» ğŸ¨      Mohamed SabithğŸ¨ ğŸ’»      Miguel Angel Cruz AcostağŸ¨ ğŸ’»              Adebayo Ilerioluwa ğŸ¨      MarkusğŸ¨ ğŸ’»      dkonyayevğŸ¨ ğŸ’»      Kevin A MathewğŸ¨ ğŸ’»      David MeloğŸ¨ ğŸ”£      DFW1NğŸ¨ ğŸ’»      Sohaib AyubğŸ¨ ğŸ’»              NavvyğŸ¨ ğŸ’»      bloodiator2ğŸ¨ ğŸ’»      HanjiğŸ¨ ğŸ’»      arthur74ğŸ¨ ğŸ’»      Sri Subathra Devi BğŸ¨ ğŸ’»      Akif AydogmusğŸ¨ ğŸ’»      Umer JavaidğŸ¨ ğŸ’»              Norio UmatağŸ¨ ğŸ’»      Gazi Hasan RahmanğŸ¨ ğŸ’»      Keith NguyenğŸ¨ ğŸ’»      MegalomaniacğŸ¨ ğŸ’»      ShankS3ğŸ¨ ğŸ’»      Farhad AlishovğŸ¨ ğŸ’»      Ronak J VanpariyağŸ¨ ğŸ’»              azrael0learzağŸ¨ ğŸ’»      Pavel RahmanğŸ¨ ğŸ’»      chuabernğŸ¨ ğŸ’»      Rahul TirkeyğŸ¨ ğŸ’»      Ruslan BesğŸ¨ ğŸ’» ğŸ’¡ ğŸš§ ğŸ–‹ ğŸ”£ ğŸš‡      BohdanğŸ¨ ğŸ’»      JuzdzewskiğŸ¨ ğŸ’»              Grigor MinasyanğŸ¨ ğŸ’»      alvintwcğŸ¨ ğŸ’»      Anand NatarajanğŸ¨ ğŸ’»      Kashan AliğŸ¨ ğŸ’»      Thomas MeshailğŸ¨ ğŸ’»      Son PhamğŸ¨      Michael FrenchğŸ’¡              Yash MishrağŸ“–      Miguel RodriguezğŸ¨ ğŸ’»      Philipp BachmannğŸ¨ ğŸ’»      sunnyğŸ¨ ğŸ’»      Siddharth ChatterjeeğŸ¨ ğŸ’»      Michael NaghavipourğŸ¨ ğŸ’»      Sahil GargğŸ¨ ğŸ’»              MicroLionğŸ¨ ğŸ’»      wctwcğŸ¨ ğŸ’»      Rohan SharmağŸ”£      AshishBodlağŸ¨ ğŸ’»      Taras PysarskyiğŸ¨ ğŸ’»      Luqman Bello O.ğŸ¨ ğŸ’»      DyingDownğŸ¨ ğŸ’»              Diego ChapedelaineğŸ¨ ğŸ’»      RichleeğŸ¨ ğŸ’»      Asif HabibğŸ¨ ğŸ’»      Mazharul HossainğŸ¨ ğŸ’»      toniğŸ¨ ğŸ’»      Pragyanshu RaiğŸ¨ ğŸ’»      Matthew EllerğŸ¨ ğŸ’»              AbhiBijuğŸ¨ ğŸ’»      Roman ZhornytskiyğŸ¨ ğŸ’»      Lucas CaminoğŸ¨ ğŸ’»      JoÃ£o Vitor CasarinğŸ¨ ğŸ’»      Evgeniy ShayğŸ¨ ğŸ’»      Ehsan BarkhordarğŸ¨ ğŸ’»      GabrielğŸ¨ ğŸ’»              Shibu MohapatrağŸ¨ ğŸ’»      Pavel KirkovskyğŸ¨ ğŸ’»      Tahir GulğŸ¨ ğŸ’»      imDevSalmanğŸ¨ ğŸ’»      Jordan DonaldsonğŸ¨ ğŸ’»      js-venusğŸ¨ ğŸ’»      Faisal ShaikhğŸ¨ ğŸ’»              ashishbpatilğŸ¨ ğŸ’»      Tri LeğŸ¨ ğŸ’»      tomtreffkeğŸ¨ ğŸ’»      Salah Eddine LalamiğŸ¨ ğŸ’»      Mattias XuğŸ¨ ğŸ’»      Manas GuptağŸ¨ ğŸ’»      wolfsong62ğŸ¨ ğŸ’»              Mehdi MirzaeiğŸ¨ ğŸ’»      Van Ba KhanhğŸ¨ ğŸ’»      Sel EmbeeğŸ¨ ğŸ’»      Suvradip PaulğŸ¨ ğŸ’»      ShariqueğŸ¨      SeabassğŸ¨ ğŸ’»      Penny LiuğŸ¨ ğŸ’»              jatinder bholağŸ¨ ğŸ’»      misterqbitğŸ¨ ğŸ’»      Daniel-VS9ğŸ¨ ğŸ’»      ShruthiğŸ¨ ğŸ’»      beefydogğŸ¨ ğŸ’»      Suraj KumarğŸ¨ ğŸ’»      hrishikeshpsğŸ¨ ğŸ’»              SudarshanğŸ¨ ğŸ’»      DivyanshğŸ’» ğŸ¨      ZyaireğŸ¨ ğŸ’»      Omar BelkadyğŸ¨ ğŸ’»      alexiismuağŸ¨ ğŸ’»      Eduarda AlvesğŸ¨      pycoachğŸ¨ ğŸ’»              RuhulğŸ¨ ğŸ’»      pmoustopoulosğŸ¨ ğŸ’»      Lee Hui TingğŸ’» ğŸ¨      bodi1981ğŸ¨ ğŸ’»      Devaraat JoshiğŸ¨ ğŸ’»      JohnnyğŸ¨ ğŸ’»      rogue-coderğŸ¨ ğŸ’»              viiktrğŸ¨      Lalit MohanğŸ’»      JoÃ£o SousağŸ’»      è¨€è‘‰ä¹‹éˆğŸ’» ğŸ¨      RJLABSğŸ’»      brittney0522ğŸ¨ ğŸ’»      shamğŸ¨ ğŸ’»              Glenn GoossensğŸ’» ğŸ¨      Cyber HawkğŸ¨ ğŸ’» ğŸ–‹ ğŸ’¼      Ankit YadavğŸ¨ ğŸ’»      verbalityğŸ’»      Mohammed SiddiquiğŸ¨ ğŸ’»      AdamKaczor6250ğŸ¨ ğŸ’»      RamÃ³n Martinez NietoğŸ¨ ğŸ’»              Grzegorz DziubakğŸ¨ ğŸ’»      Ayoub BERDEDDOUCHğŸ¨ ğŸ’»      nikola-fadvğŸ¨ ğŸ’»      Akarsh AgrawalğŸ¨ ğŸ’»      Mitra MirshafieeğŸ¨ ğŸ’»      Parker StephensğŸ¨ ğŸ’»      alrenee99ğŸ’»              Karthick VankayalağŸ’»      Iryna ğŸ¨ ğŸ’»      palanugrahğŸ’»      GwinbleindğŸ¨ ğŸ’»      Randy BobandyğŸ¨ ğŸ’»      Bek RozikoffğŸ’»      davnguyeğŸ¨ ğŸ’»              Neel PatelğŸ’»      ehudbeharğŸ¨ ğŸ’»      nicholas-cod3rğŸ¨ ğŸ’»      michaelfrankiğŸ¨      Esther WhiteğŸ¨ ğŸ’»      prathmeshpbğŸ¨ ğŸ’»      Victor LinğŸ¨ ğŸ’»              Christine C. YinğŸ¨ ğŸ’»      GitLearner-beginğŸ¨ ğŸ’»      Mesrop AndreasyanğŸ¨ ğŸ’»      Nathan GarciağŸ¨      commonsw04ğŸ¨ ğŸ’»      Md. Rashad TanjimğŸ¨ ğŸ’»      Ali MalekğŸ’»              PAODLTğŸ¨ ğŸ’»      Nikhil BobadeğŸ¨ ğŸ’»      hyuckjin21ğŸ’»      Itasha ModiğŸ¨ ğŸ’»      Nikitha ReddyğŸ¨ ğŸ’»      Mahshooq ZubairğŸ¨ ğŸ’»      Subham DasğŸ’»              Onkar BirajdarğŸ¨ ğŸ’»      Nick TitomichelakisğŸ¨ ğŸ’»      Christian Leo-PernoldğŸ¨      Matthew MarquiseğŸ¨ ğŸ’»      baronfacğŸ¨ ğŸ’»      Abhishek TilwarğŸ¨ ğŸ’»      DavidsDvmğŸ¨ ğŸ’»              Parth ParikhğŸ¨ ğŸ’»      Hector CastroğŸ¨ ğŸ’»      Rikky ArisendiğŸ¨ ğŸ’»      Ali HamXağŸ¨ ğŸ’»      Frank.wuğŸ¨ ğŸ’»      Jatin KumarğŸ¨ ğŸ’» ğŸ“–      masterHAWK99ğŸ¨ ğŸ’»              Pushp JainğŸ¨ ğŸ’»      Ashutosh RoutğŸ¨ ğŸ’»      Atharva DeshpandeğŸ¨ ğŸ’»      Teodor CiripescuğŸ¨ ğŸ’»      Anmol BansalğŸ¨ ğŸ’»      Nikhil Kumar MacharlağŸ¨ ğŸ’»      DexterğŸ¨ ğŸ’»              AaronğŸ¨ ğŸ’»      Yogita JaswaniğŸ¨ ğŸ’» ğŸ“– ğŸ–‹      StoryDevğŸ¨ ğŸ’»      Mesut DoÄŸansoyğŸ¨ ğŸ’»      Paras DhawanğŸ¨ ğŸ’»      Emanuel ZhupağŸ¨ ğŸ’»      Aaradhyaa717ğŸ¨ ğŸ’»              jaacko-torusğŸ¨ ğŸ’»      mBlackğŸ’»      kalrayashwinğŸ“– ğŸ–‹ ğŸ¨ ğŸ’»      SeraphğŸ’» ğŸ¨      ZhiHong ChuağŸ¨ ğŸ’»      Amsal KhanğŸ¨ ğŸ’» ğŸ“– ğŸ–‹      Raghav RastogiğŸ¨ ğŸ’»              TzilağŸ“–      Shahriar Nasim NafiğŸ“–      AGğŸ¨ ğŸ’»      Mojtaba KamyabiğŸ¨ ğŸ’»      Ahmad AbdulrahmanğŸ¨ ğŸ’»      EclipseğŸ¨ ğŸ’»      Anshu PalğŸ¨ ğŸ’»              DenisğŸ¨ ğŸ’»      mehmet sayinğŸ“–      WebDEVğŸ¨ ğŸ’»      Sam KomesarookğŸ¨ ğŸ’»      Kiran GhimireğŸ¨ ğŸ’»      Joshua DavisğŸ¨ ğŸ’»      Muhammad-Huzaifa-SiddiquiğŸ’»              tobeornottobeadevğŸ¨ ğŸ’»      VAIBHAV SINGHALğŸ¨ ğŸ’»      Keiran PillmanğŸ¨ ğŸ’»      Max DonchenkoğŸ¨ ğŸ’»      sgonsalğŸ¨ ğŸ’»      diksha137ğŸ¨ ğŸ’»      VigneshğŸ¨ ğŸ’»              Gabriel FranÃ§ağŸ¨ ğŸ’»      JosephğŸ¨ ğŸ’»      Bruno RafaelğŸ¨ ğŸ’»      vcamarreğŸ¨ ğŸ’»      thibault kettererğŸ¨ ğŸ’» ğŸš§      VictorGonzalezToledoğŸ¨ ğŸ’»      1911510996ğŸ¨ ğŸ’»              inviduğŸ¨ ğŸ’»      Nurul FurqonğŸ¨ ğŸ’»      David AsbillğŸ¨ ğŸ’»      Niko BirbilisğŸ¨ ğŸ’»      Mugundan KottursureshğŸ¨      agrsachin81ğŸ¨ ğŸ’»      Othmane El AlamiğŸ¨ ğŸ’»              Syed Atif AliğŸ¨ ğŸ’»      lakhanjindamğŸ¨ ğŸ’»      youssef hamdaneğŸ¨ ğŸ’»      starfaerieğŸ¨ ğŸ’»      rodrigo0107ğŸ¨ ğŸ’»      MichaÅ‚ GralakğŸ¨ ğŸ’»      Jewel MahmudğŸ¨ ğŸ’»              cwilson830ğŸ¨ ğŸ’»      buun1030ğŸ¨ ğŸ’»      Reda-ELOUAHABIğŸ¨ ğŸ’»      saad-aksağŸ¨ ğŸ’»      Emdadul HaqueğŸ¨ ğŸ’»      PROCWğŸ¨ ğŸ’»      cccppp1ğŸ¨ ğŸ’»              Joanna BaileğŸ¨ ğŸ’»      Ahmed SaberğŸ¨ ğŸ’»      Masoud KeshavarzğŸ¨ ğŸ’»      mortazavianğŸ¨ ğŸ’»      Aniket PandeyğŸ¨ ğŸ’»      Vijay NirmalğŸ¨ ğŸ’»      Daniel CarvalloğŸ’»              menaechmiğŸ¨ ğŸ’»      azenyxğŸ¨ ğŸ’»      Ahmet Ã–zrahatğŸ¨ ğŸ’»      Abdulrahman AbouzaidğŸ¨ ğŸ’»      jmgnorbecğŸ¨ ğŸ’»      palinko91ğŸ¨ ğŸ’»      Laisson R. SilveirağŸ¨ ğŸ’»              BHARGAVPATEL1244ğŸ¨ ğŸ’»      Candide UğŸ¨ ğŸ’»      Sitansh RajputğŸ¨ ğŸ’»      Houda MouttalibğŸ¨ ğŸ’»      MumuTWğŸ¨ ğŸ’»      Suave BajajğŸ¨ ğŸ’»      Mehdi ParsaeiğŸ¨ ğŸ’»              Dinko OsreckiğŸ¨ ğŸ’»      Dhia DjobbiğŸ¨ ğŸ’»      Mahmoud GalalğŸ¨ ğŸ’»      Anh MinhğŸ¨ ğŸ’»      Suvesh KğŸ¨ ğŸ’»      Petar TodorovğŸ¨ ğŸ’»      Alexander NguyenğŸ¨ ğŸ’»              Morteza JalalvandğŸ¨ ğŸ’»      Claudson MartinsğŸ¨ ğŸ’»      Matt JacobsonğŸ¨ ğŸ’»      Rafael BelokurowsğŸ¨ ğŸ’»       Thomas GamaufğŸ¨ ğŸ’»      Rishabh MahajanğŸ¨ ğŸ’»      rakeshpdgupta23ğŸ¨ ğŸ’»              ShashidharknaikğŸ¨ ğŸ’»      taleleumağŸ¨ ğŸ’»      Florian BÃ¼hlerğŸ¨ ğŸ’»      Raihan Bin WahidğŸ¨ ğŸ’»      MOHAMMED NASSERğŸ¨ ğŸ’»      federicoğŸ¨ ğŸ’»      Andre ViolanteğŸ¨ ğŸ’»              tcunningham98ğŸ¨ ğŸ’»      Jan GrieÃŸerğŸ¨ ğŸ’»      Serkan AlcğŸ¨ ğŸ’» ğŸ–‹      Jez McKeanğŸ¨ ğŸ’»      meisam alifallahiğŸ¨ ğŸ’»      Mehul ThakkarğŸ¨ ğŸ’»      Saksham SoniğŸ¨ ğŸ’»              Pedro PeregrinağŸ¨ ğŸ’»      Mintu ChoudharyğŸ¨ ğŸ’»      lucianmoldovanuğŸ¨ ğŸ’»      John C. ScottğŸ¨ ğŸ’»      Mia D.ğŸ¨ ğŸ’»      EwenBernardğŸ¨ ğŸ’»      M. Reza NasirlooğŸ¨ ğŸ’»              Jay AgrawalğŸ¨ ğŸ’»      DeShayğŸ¨ ğŸ’»      Jay206-ProgrammerğŸ¨ ğŸ’»      ElenderğŸ¨ ğŸ’» ğŸ–‹      Bobby ByrneğŸ¨ ğŸ’»      PirciğŸ¨ ğŸ’»      HasanuzzamanğŸ¨ ğŸ’»              Josh KautzğŸ¨ ğŸ’»      BrofarğŸ¨ ğŸ’»      Mina KaramğŸ¨ ğŸ’»      Duncan O NğŸ¨ ğŸ’»      Sean Tumulak-NguyenğŸ¨ ğŸ’»      Artur TrzeÅ›niewskiğŸ¨ ğŸ’»      JJaammeessMğŸ¨ ğŸ’»              shubham agarwalğŸ¨ ğŸ’»      Michele RighiğŸ¨ ğŸ’»      Panagiotis KontosğŸ¨ ğŸ’»      sumitbathlağŸ¨ ğŸ’»      Deepak MathurğŸ¨ ğŸ’»      Juho NykÃ¤nenğŸ¨ ğŸ’»      Santiago GonzÃ¡lez SiordiağŸ¨ ğŸ’»              SRIJITA MALLICKğŸ¨ ğŸ’»      Samriddhi BğŸ¨ ğŸ’»      Nitzan PapiniğŸ¨ ğŸ’»      Mario SanzğŸ¨ ğŸ’»      Crab^4ğŸ¨ ğŸ’»      PabloğŸ¨ ğŸ’»      Gordon Pham-NguyenğŸ¨ ğŸ’»              KristofferğŸ¨ ğŸ’»      chrisblachğŸ¨ ğŸ’»      GÃ¡borğŸ¨ ğŸ’»      LinağŸ¨ ğŸ’»      Harrison WattsğŸ¨ ğŸ’»      Mario PetriÄkoğŸ¨ ğŸ’»      Ben8120ğŸ¨ ğŸ’»              GiovannağŸ¨ ğŸ’»      Minal AhujağŸ¨ ğŸ’»      mossfarmerğŸ¨ ğŸ’»      ThaC0derDreğŸ¨ ğŸ’»      itwareğŸ¨ ğŸ’»      Michael WalkerğŸ¨ ğŸ’»      Tom Jacob ChirayilğŸ¨ ğŸ’»              Sachin KumarğŸ¨ ğŸ’»      adi-rayğŸ¨ ğŸ’»      Dr-Blank-altğŸ¨ ğŸ’»      Bogdan CazacuğŸ¨ ğŸ’»      Gilson UrbanoğŸ¨ ğŸ’»      NinağŸ¨ ğŸ’»      AnthonyğŸ¨ ğŸ’»              manushimjaniğŸ¨ ğŸ’»      Michael ReyesğŸ¨ ğŸ’»      Rachel KennellyğŸ¨ ğŸ’»      Aakash GargğŸ¨ ğŸ’»      Daniel LivingstonğŸ¨ ğŸ’»      alexrojcoğŸ¨ ğŸ’»      Minh NguyenğŸ¨ ğŸ’»              Mahesh Dattatraya BabarğŸ¨ ğŸ’»      Jin ZihangğŸ¨ ğŸ’»      Bikramjit GangulyğŸ¨ ğŸ’»      QuestionableGuiseğŸ¨ ğŸ’»      liq19chğŸ¨ ğŸ’»      Bruno RochağŸ¨ ğŸ’»      Anand DyavanapalliğŸ’» ğŸ–‹              crucian-afkğŸ¨ ğŸ’»      0xgainzğŸ¨ ğŸ’»      weirdfshğŸ¨ ğŸ’»      Valan Baptist MathuranayagamğŸ¨ ğŸ’»      Paul KaeferğŸ¨ ğŸ’»      Yu-Hsiang WangğŸ¨ ğŸ’»      Javad AdibğŸ¨ ğŸ’»              davidliu0930ğŸ¨ ğŸ’»      Achilleas John YfantisğŸ¨ ğŸ’»      Omkar ShivadekarğŸ¨ ğŸ’» ğŸ–‹ ğŸ›      ToanTranğŸ¨ ğŸ’»      Gautam NaikğŸ¨ ğŸ’»      MarcğŸ¨ ğŸ’»      twix20ğŸ¨ ğŸ’»              Kristian S.ğŸ¨ ğŸ’»      Aleksey KhoroshilovğŸ¨ ğŸ’»      arjunsrsrğŸ¨ ğŸ’»      Ali HaiderğŸ¨ ğŸ’»      Trisha DringğŸ¨ ğŸ’»      Andre MarzuloğŸ¨ ğŸ’»      Krishna ModiğŸ¨ ğŸ’»              Rosemary LiğŸ¨ ğŸ’»      Alex WellerğŸ¨ ğŸ’»      Tam NguyenğŸ¨ ğŸ’»      aquintelaoliveirağŸ¨ ğŸ’»      Norbert BrettğŸ¨ ğŸ’»      rocsogdğŸ¨ ğŸ’»      0nyrğŸ¨ ğŸ’»              rethkevinğŸ¨ ğŸ’»      RickHeadleğŸ¨ ğŸ’»      LeandreğŸ¨ ğŸ’»      Natnael SisayğŸ¨ ğŸ’»      sbbuğŸ¨ ğŸ’»      waelğŸ¨ ğŸ’»      Fabricio Tramontano PiriniğŸ¨ ğŸ’»              Alexander StoyanovğŸ¨ ğŸ’»      Dezx20ğŸ¨ ğŸ’»      southparkkidsğŸ¨ ğŸ’»      bmstarğŸ¨ ğŸ’»      kiagamğŸ¨ ğŸ’»      Juan CastilloğŸ¨ ğŸ’»      FFenneğŸ¨ ğŸ’»              Jose ToledoğŸ¨ ğŸ’»      Pat McGhenğŸ¨ ğŸ’»      Eiko WagenknechtğŸ’» ğŸ–‹ ğŸ”£      Alan ChalmersğŸ¨ ğŸ’»      Jean DidierğŸ¨ ğŸ’»      AndyğŸ¨ ğŸ’»      pestadieuğŸ¨ ğŸ’»              Kanishka ChakrabortyğŸ¨ ğŸ’»      NandhağŸ¨ ğŸ’»      Vahid MafiğŸ¨ ğŸ’» ğŸ”£ ğŸ–‹ ğŸ’¼      Akshay AshokğŸ¨ ğŸ’»      0x08ğŸ¨ ğŸ’»      Sandeep MishrağŸ¨ ğŸ’»      Evann RegnaultğŸ¨ ğŸ’»              Lenny ZeitounğŸ¨ ğŸ’»      Eden BoaronğŸ¨ ğŸ’»      TroyBTCğŸ¨ ğŸ’»      Aby SebastianğŸ¨ ğŸ’»      Matthew DunnğŸ¨ ğŸ’»      ckulloğŸ¨ ğŸ’» ğŸ–‹ ğŸ”£      Mohamed MamdouhğŸ¨ ğŸ’»              Youssef BazinağŸ¨ ğŸ’»      Frederico KÃ¼ckelhausğŸ’»      Nushan KodikarağŸ’»      Zach CooperğŸ’»      RoyğŸ¨ ğŸ’»      Saurav PanchalğŸ¨ ğŸ’»      totallynotdavidğŸ¨ ğŸ’»              goosepirateğŸ¨ ğŸ’» ğŸ’¡ ğŸ’¼      KAUTHğŸ¨ ğŸ’»      Hari Kiran VusirikalağŸ¨ ğŸ’»      Sounak DeyğŸ¨ ğŸ’»      ziağŸ’¼ ğŸ¨ ğŸ’»      Reza DavariğŸ¨ ğŸ’»      AkshayAjaykumarğŸ¨ ğŸ’»              x24870ğŸ¨ ğŸ’»      Ko PhoneğŸ¨ ğŸ’»      Nabstar3ğŸ¨ ğŸ’»      MateuszğŸ¨ ğŸ’»      Yunus Emre EmikğŸ’»      Abhinav SinhağŸ¨ ğŸ’»      Hung NguyenğŸ¨ ğŸ’»              MaselinoğŸ’»      Shuktika MahantyğŸ’»      MikoÅ‚aj GawroÅ„skiğŸ¨ ğŸ’»      Hussein Habibi JuybariğŸ¨ ğŸ’»      Sean-McArthurğŸ¨ ğŸ’»      Osman F BayramğŸ¨ ğŸ’»      Benjamin Thomas BlodgettğŸ¨ ğŸ’»              Chuanlong-ZangğŸ¨ ğŸ’»      julianğŸ¨ ğŸ’»      franciscoğŸ¨ ğŸ’»      aalihhiader9211ğŸ¨ ğŸ’»      Muhammad ZunairğŸ¨ ğŸ’»      LiyağŸ¨ ğŸ’»      BegadTarekğŸ¨ ğŸ’»              etorobotğŸ¨ ğŸ’»      Hussam KhanğŸ¨ ğŸ’»      Saikat ChakrabortyğŸ¨ ğŸ’»      Nicholas QuislerğŸ¨ ğŸ’»      Evang PoulğŸ¨ ğŸ’»      Gregg LindğŸ¨ ğŸ’»      Deepak KumarğŸ¨ ğŸ’»              Callum LeslieğŸ¨ ğŸ’»      Curtis Barnard Jr.ğŸ¨ ğŸ’»      DeepanshukaimğŸ¨ ğŸ’»      Manthan AnkğŸ¨ ğŸ’»      hossein varmazyarğŸ¨ ğŸ’»      Brayan MuÃ±oz V.ğŸ¨ ğŸ’»      Kamil Rasheed SiddiquiğŸ’» ğŸ¨              mutt0-dsğŸ¨ ğŸ’»      egbertjkğŸ¨ ğŸ’»      Majid ZojajiğŸ¨ ğŸ’»      Sean ChenğŸ¨ ğŸ’»      Herbert MilhommeğŸ¨ ğŸ’»      A3ğŸ¨ ğŸ’»      KillianğŸ¨ ğŸ’»              CoakeowğŸ¨ ğŸ’»      à¾…à¼» Ç¬É€Ä§ à¼„à¼†à½‰ğŸ¨ ğŸ’»      Pratik SolankiğŸ¨ ğŸ’»      SunnyğŸ¨ ğŸ’»      ssgeğŸ¨ ğŸ’»      Bernat FrangiğŸ¨ ğŸ’»      Jeevan RupachağŸ¨ ğŸ’»              amirandapğŸ¨ ğŸ’»      Deepakshi MittalğŸ¨ ğŸ’»      Abhijeet ParidağŸ¨ ğŸ’»      Khaled RiyadğŸ¨ ğŸ’»      Pratap paruiğŸ¨ ğŸ’»      Prajit PandayğŸ¨ ğŸ’»      PipeSierrağŸ¨ ğŸ’»              Collins OdenğŸ¨ ğŸ’»      Kshitij DwivediğŸ¨ ğŸ’»      Bernardia Vitri ArumsariğŸ¨ ğŸ’»      Ã–mer Faruk TaÅŸdemirğŸ¨ ğŸ’»      Spencer StithğŸ¨ ğŸ’»      Porsche RodjanasakğŸ¨ ğŸ’»      Shakeel SharifğŸ¨ ğŸ’»              Victoria ChengğŸ¨ ğŸ’»      DenisğŸ¨ ğŸ’»      Anand Prakash TiwariğŸ¨ ğŸ’»      danijeljw-rpcğŸ¨ ğŸ’»      Ahmed H EbrahimğŸ¨ ğŸ’»      Virginia GardnerğŸ¨ ğŸ’»      Jhironsel Diaz A.ğŸ¨ ğŸ’»              Yunus KidemğŸ¨ ğŸ’»      MTğŸ¨ ğŸ’»      Dinesh ZaldekarğŸ¨ ğŸ’»      adiğŸ¨ ğŸ’»      Farhan ShaikhğŸ¨ ğŸ’»      Elvis SalvatierrağŸ¨ ğŸ’»      Kaushik-IyerğŸ¨ ğŸ’»              HocAndresğŸ¨ ğŸ’»      VictorHugoAguilarAguilarğŸ¨ ğŸ’»      Murat Can AbayğŸ¨ ğŸ’»      ChrisğŸ¨ ğŸ’»      Shivam7-1ğŸ¨ ğŸ’»      Paipai13ğŸ¨ ğŸ’»      Shambles-ioğŸ¨ ğŸ’»              Abhishek K MğŸ¨ ğŸ’»      Ezequiel CuevasğŸ¨ ğŸ’»      Plamen IvanovğŸ¨ ğŸ’»      YujiğŸ¨ ğŸ’»      Jean-Philippe LebÅ“ufğŸ¨ ğŸ’» ğŸ”£      NaufanğŸ¨ ğŸ’»      jadnovğŸ¨ ğŸ’»              vaxtangensğŸ¨ ğŸ’»      subashkonar13ğŸ¨ ğŸ’»      Rushi JaviyağŸ¨ ğŸ’»      Mert GÃ¼lğŸ¨ ğŸ’»      LilyğŸ¨ ğŸ’»      KalinoffğŸ¨ ğŸ’»      Joel TonyğŸ¨ ğŸ’»              PeterğŸ¨ ğŸ’»      Roozbeh ZareiğŸ¨ ğŸ’»      ShenğŸ¨ ğŸ’»      Joonsoo.LEEğŸ¨ ğŸ’»      Fede.BregğŸ¨ ğŸ’»      Rui CostağŸ¨ ğŸ’»      JoÃ£o Gustavo BispoğŸ¨ ğŸ’»              Sami-IğŸ¨ ğŸ’»      Tsvetoslav TsvetkovğŸ¨ ğŸ’»      Olabode Olaniyi DavidğŸ¨ ğŸ’»      theRuslanğŸ¨ ğŸ’»      leighbozğŸ¨ ğŸ’»      Frank SossiğŸ¨ ğŸ’»      Tomasz AdamskiğŸ¨ ğŸ’»              Mansoor M. SathirğŸ¨ ğŸ’»      Golamrabbi AzadğŸ¨ ğŸ’»      Nahian AhmedğŸ¨ ğŸ’»      Rafael de Jesus Silva MonteiroğŸ¨ ğŸ’»      Odionyebuchukwu JudeğŸ¨ ğŸ’»      The Nithin BalajiğŸ¨ ğŸ’»      KnackiiğŸ¨ ğŸ’»              vittorio-giattiğŸ¨ ğŸ’»      Guilherme de Carvalho Lima RebouÃ§asğŸ¨ ğŸ’»      aaref shamiğŸ¨ ğŸ’»      Andrey DryupinğŸ¨ ğŸ’»      Muhanned NomanğŸ¨ ğŸ’»      Jan SilvağŸ¨ ğŸ’»      emanuele-emğŸ¨ ğŸ’» ğŸ–‹              Sanjay TMğŸ¨ ğŸ’»      Joe Markberg / code editorğŸ¨ ğŸ’»      Julien QuiaiosğŸ¨ ğŸ’»      Eric Ramirez SantisğŸ¨ ğŸ’»      MğŸ¨ ğŸ’»      MalcatağŸ¨ ğŸ’»      Athul MuralidharanğŸ¨ ğŸ’»              Dariusz OchotağŸ¨ ğŸ’»      CHANDAN CHOUDHURYğŸ¨ ğŸ’»      DeepğŸ¨ ğŸ’»      Ahmet Ä°stemihan Ã–ZTÃœRKğŸ¨ ğŸ’»      TIMğŸ¨ ğŸ’»      jakeg814ğŸ¨ ğŸ’»      LeonidosğŸ¨ ğŸ’»              Abhinandu V NairğŸ¨ ğŸ’»      charafeddine01ğŸ¨ ğŸ’»      JasperğŸ¨ ğŸ’»      Manish GoyalğŸ¨ ğŸ’»      SATYAM_SINGHğŸ¨ ğŸ’»      FourğŸ¨ ğŸ’»      Vaishnavi Amira YadağŸ¨ ğŸ’»              ShriKrushna BhagwatğŸ¨ ğŸ’»      Rohit NandagawaliğŸ¨ ğŸ’»      felipeğŸ¨ ğŸ’» ğŸš§ ğŸ–‹ âœ… ğŸ§‘â€ğŸ«      Saurabh MudgalğŸ¨ ğŸ’»      szenadamğŸ¨ ğŸ’»      Shubhendra SinghğŸ¨ ğŸ’»      Yoosuf SayyidğŸ’» ğŸ¨              GÃ¼ven Ã‡etinerlerğŸ¨ ğŸ’»      Luke JefferiesğŸ¨ ğŸ’»      ChrisğŸ¨ ğŸ’»      LÃºcio AguiarğŸ’»      Enuma029ğŸ’»      yktsang01ğŸ’»      maximumn3rdğŸ¨ ğŸ’»              Jon GalleteroğŸ¨ ğŸ’»      Thaddeus  ThomasğŸ¨ ğŸ’»      Aakash KumarğŸ’» ğŸ¨      Ali MğŸ¨ ğŸ’»      OskyEdzğŸ¨ ğŸ’»      Ravi GuptağŸ¨ ğŸ’»      Rafa RaizerğŸ¨ ğŸ’»              Abdullah Al MuzakiğŸ¨ ğŸ’»      Rahul FaujdarğŸ¨ ğŸ’»      Abhishek VermağŸ¨ ğŸ’»      Ashutosh ShindeğŸ¨ ğŸ’»      Ganesh RaiğŸ¨ ğŸ’»      StefanTrpkovicğŸ¨ ğŸ’»      Erik BlancağŸ¨ ğŸ’»              Vedant MadaneğŸ¨ ğŸ’»      Antra TripathiğŸ¨ ğŸ’»      Ethan KnightsğŸ¨ ğŸ’»      Alexandru BoncutğŸ¨ ğŸ’»      Pablo BandinoplağŸ¨ ğŸ’» ğŸš§ ğŸ–‹      Robz-99ğŸ¨ ğŸ’»      Harpal SinghğŸ¨ ğŸ’»              paulboundy99ğŸ¨ ğŸ’»      Mubashir AhmedğŸ¨ ğŸ’»      Rohan HariğŸ¨ ğŸ’»      Erik Henrique ğŸ¨ ğŸ’»      Leandro MatheusğŸ¨ ğŸ’»      DeepakğŸ¨ ğŸ’»      AlishaSinghğŸ¨ ğŸ’»              Lynn Latt YatiğŸ¨ ğŸ’»      San ShweğŸ¨ ğŸ’»      SKRğŸ¨ ğŸ’»      msbunnyjaguarğŸ¨ ğŸ’»      Mohamad ZabiullağŸ¨ ğŸ’»      Hatim ZahidğŸ¨ ğŸ’»      Rauzan SumarağŸ¨ ğŸ’»              Hosein1358ğŸ¨ ğŸ’»      MohitğŸ¨ ğŸ’»      AliğŸ¨ ğŸ’»      Avinash1765ğŸ¨ ğŸ’»      Sai Teja MadhağŸ¨ ğŸ’»      Monsur Ahmed ShafiqğŸ¨ ğŸ’»      xuxianjin-devğŸ¨ ğŸ’»              chetnağŸ¨ ğŸ’»      Gul ZaibğŸ¨ ğŸ’»      NataliağŸ¨ ğŸ’»      DionÃ­sio BragağŸ¨ ğŸ’»      Pritish RajpurohitğŸ¨ ğŸ’»      incanloveğŸ¨ ğŸ’»      InnocentğŸ¨ ğŸ’»              Devin AlmonorğŸ¨ ğŸ’»      antonyveyreğŸ¨ ğŸ’»      Beltz AnhxtonğŸ¨ ğŸ’»      MehdiğŸ¨ ğŸ’»      Muhammad UsmanğŸ¨ ğŸ’»      Patrick DantasğŸ¨ ğŸ’»      Tak VannakğŸ¨ ğŸ’»              Ramzi RADDAOUIğŸ¨ ğŸ’»      Konstantin-GlukhovğŸ¨ ğŸ’»      ugurobanğŸ¨ ğŸ’»      Humberto AlvesğŸ¨ ğŸ’»      JuangZendratoğŸ¨ ğŸ’»      James OluwaleyeğŸ¨ ğŸ’»      Wasi SadmanğŸ¨ ğŸ’»              Pavle MijatovicğŸ¨ ğŸ’»      Luiz H. S. BispoğŸ¨ ğŸ’»      Ğ¡ÑƒÑ…Ğ°Ñ Ğ”Ñ…Ğ¾Ğ»Ğ·ğŸ¨ ğŸ’»      Alvaro TrujilloğŸ¨ ğŸ’»      Everton ğŸ¨ ğŸ’»      jfrozasğŸ¨ ğŸ’»      Shuaaib BadranğŸ¨ ğŸ’»              Shivam JhağŸ¨ ğŸ’»      Mohamed TayehğŸ¨ ğŸ’»      Makendran GğŸ¨ ğŸ’»      mayank singh tomarğŸ¨ ğŸ’»      hossam sadanyğŸ¨ ğŸ’»      Harshbardhan SinghğŸ’» ğŸ¨      Fawad Jawaid MalikğŸ¨ ğŸ’»              Tina LacatisğŸ¨ ğŸ’»      TeddyCuoreDolceğŸ¨ ğŸ’»      bchooxgğŸ¨ ğŸ’»      Alisha TakkarğŸ¨ ğŸ’»      GianluigiğŸ¨ ğŸ’»      Mehran JavaherianğŸ¨ ğŸ’»      Benjamin Ololade AdedokunğŸ¨ ğŸ’»              Md. Abdul MutalibğŸ¨ ğŸ’»      Aadil Arsh.S.RğŸ¨ ğŸ’»      J. Nathan AllenğŸ¨ ğŸ’»      Kieran KrugğŸ¨ ğŸ’»      Seth AddoğŸ¨ ğŸ’»      Satvik Singh RathoreğŸ¨ ğŸ’»      dangothğŸ¨ ğŸ’»              MaximğŸ¨ ğŸ’»      Phuong-Cat NgoğŸ¨ ğŸ’»      Frenchtoast0ğŸ¨ ğŸ’»      RakshithğŸ¨ ğŸ’»      Vaibhav ArorağŸ¨ ğŸ’»      zghpğŸ¨ ğŸ’»      BedovanğŸ¨ ğŸ’»              chiaramistroğŸ¨ ğŸ’»      him2016ğŸ¨ ğŸ’»      HarshitSachdevağŸ¨ ğŸ’»      Sadaf SaleemğŸ¨ ğŸ’»      Aaroh SrivastavağŸ¨ ğŸ’»      eloygplazağŸ¨ ğŸ’»      Gaurav Kumar VermağŸ¨ ğŸ’»              AndreaCUSğŸ¨ ğŸ’»      SimranğŸ¨ ğŸ’»      Prashant BhapkarğŸ¨ ğŸ’»      mhaendlerğŸ¨ ğŸ’»      Gauri MaheshwariğŸ¨ ğŸ’»      4LajfğŸ¨ ğŸ’»      Tanmoy SenguptağŸ¨ ğŸ’»              Sharad TripathiğŸ¨ ğŸ’»      Niraj ChavanğŸ¨ ğŸ’»      Luisa GualdağŸ¨ ğŸ’»      Monika-Sivakumar-3ğŸ¨ ğŸ’»      harryfensomeğŸ¨ ğŸ’»      Shubham ChoubeyğŸ¨ ğŸ’»      Ashwini PatilğŸ¨ ğŸ’»              cleversonlirağŸ¨ ğŸ’»      NurmukhammedğŸ¨ ğŸ’»      workspace-utkarshğŸ¨ ğŸ’»      Santosh PhadtareğŸ¨ ğŸ’»      Prashant WarghudeğŸ¨ ğŸ’»      Umang DakhğŸ¨ ğŸ’»      Shalini ChavanğŸ¨ ğŸ’»              vinit gurjarğŸ¨ ğŸ’»      Vishal KumarğŸ¨ ğŸ’»      Wonhyeong SeoğŸ¨ ğŸ’»      Achwale Prajwal NamdevraoğŸ¨ ğŸ’»      Ankan BanerjeeğŸ¨ ğŸ’»      bhaumikankanğŸ¨ ğŸ’»      JamesMacroZhangğŸ¨ ğŸ’»              Pedro LopesğŸ¨ ğŸ’»      diağŸ¨ ğŸ’»      tayyabhussain2910ğŸ¨ ğŸ’»      Rajdeep Shrivastava ğŸ¨ ğŸ’»      Mukul KumarğŸ¨ ğŸ’»      Mayank NğŸ¨ ğŸ’»      jdeluccağŸ¨ ğŸ’»              Sneha MittalğŸ¨ ğŸ’»      Sarika KushwahağŸ¨ ğŸ’»      farzad-khbğŸ¨ ğŸ’»      Elijah ShackelfordğŸ¨ ğŸ’»      The-Only-RaminatorğŸ¨ ğŸ’»      Keerthana KasthurilğŸ¨ ğŸ’»      Viachaslau AuchynnikauğŸ¨ ğŸ’»              Mohammad Osman RasooliğŸ¨ ğŸ’»      mvedovatoğŸ¨ ğŸ’»      Sonali RajputğŸ¨ ğŸ’»      Isha DhekğŸ¨ ğŸ’»      Ramshad Cheriyeri PeediyakkalğŸ¨ ğŸ’»      MicahğŸ¨ ğŸ’»      gauravshukla2203ğŸ¨ ğŸ’»              sndmurthyğŸ¨ ğŸ’»      Shivam-SinghğŸ¨ ğŸ’»      M. Ammar KhanğŸ¨ ğŸ’»      chandolakulğŸ¨ ğŸ’»      bhatnagar221ğŸ¨ ğŸ’»      Adrian NieÅ›ciurğŸ¨ ğŸ’»      nezi311ğŸ¨ ğŸ’»              scottajevansğŸ¨ ğŸ’»      Marcelo Antunes Soares FantiniğŸ¨ ğŸ’»      Axel De AcetisğŸ¨ ğŸ’»      Drishti SahğŸ¨ ğŸ’»      VipulDhillonğŸ¨ ğŸ’»      Urmi JanağŸ¨ ğŸ’»      Ayush MokalğŸ¨ ğŸ’»              Damola OlutokeğŸ¨ ğŸ’»      MaxğŸ¨ ğŸ’»      Lakshmi NğŸ¨ ğŸ’»      ArtemRevağŸ¨ ğŸ’»      Ujjwal AggarwalğŸ¨ ğŸ’»      MoğŸ¨ ğŸ’»      BrianğŸ¨ ğŸ’»              chamleyğŸ¨ ğŸ’»      Simone BaptisteğŸ¨ ğŸ’»      Shekhar ThakurğŸ¨ ğŸ’»      SmithğŸ¨ ğŸ’»      codernoob1ğŸ¨ ğŸ’»      lok84ğŸ¨ ğŸ’»      Tobias RiemenschneiderğŸ¨ ğŸ’»              Tharsanan1ğŸ¨ ğŸ’»      ANURAG SINGHğŸ¨ ğŸ’»      Yash SantğŸ¨ ğŸ’»      Krishiv PatelğŸ¨ ğŸ’»      GGGalaxyğŸ¨ ğŸ’»      pardeepdhillon661ğŸ¨ ğŸ’»      anujd64ğŸ¨ ğŸ’»              Pedro PereirağŸ¨ ğŸ’»      Master_SaptakğŸ¨ ğŸ’»      SURANJAN DASğŸ¨ ğŸ’»      Tripura kantğŸ¨ ğŸ’»      shabzkhanğŸ¨ ğŸ’»      Mustafa PoyağŸ¨ ğŸ’»      Roshan JhağŸ¨ ğŸ’»              GuillaumeLarueğŸ¨ ğŸ’»      Tomasz RodakğŸ¨ ğŸ’»      Junil KimğŸ¨ ğŸ’»      Surbhi MayankğŸ¨ ğŸ’»      Nemanja LekicğŸ¨ ğŸ’»      HemantMalokarğŸ¨ ğŸ’»      Felipe M. LÃ³pezğŸ¨ ğŸ’»              bibliofiloğŸ¨ ğŸ’»      GauthamG2ğŸ¨ ğŸ’»      02_tğŸ¨ ğŸ’»      Yusuf Abdul-razaqğŸ¨ ğŸ’»      VladimirğŸ¨ ğŸ’»      Sai Chandra KğŸ¨ ğŸ’»      Soroush BonabğŸ¨ ğŸ’»              Giide0nğŸ¨ ğŸ’»      GGğŸ¨ ğŸ’»      DÃ¡ger ZÃºÃ±igağŸ¨ ğŸ’»      rsk2ğŸ¨ ğŸ’»      Storozhev DJğŸ¨ ğŸ’»      JeevanğŸ¨ ğŸ’»      Andy JohnsonğŸ¨ ğŸ’»              AnÃ­bal PozoğŸ¨ ğŸ’»      Jovane de CastroğŸ¨ ğŸ’»      Muhammad Hamza AmirğŸ¨ ğŸ’»      tharaka-mtsğŸ¨ ğŸ’»      Ali KHYARğŸ¨ ğŸ’»      Caio AraujoğŸ¨ ğŸ’»      Oscar DyremyhrğŸ¨ ğŸ’»              artealityğŸ¨ ğŸ’»      Daniel DrexlmaierğŸ¨ ğŸ’»      Marco MontiğŸ¨ ğŸ’»      mikeycrystalğŸ¨ ğŸ’»      VeljanovskiiğŸ¨ ğŸ’»      Ivan GorbachevğŸ¨ ğŸ’»      Sahil RawatğŸ¨ ğŸ’»              Hasitha SunethğŸ¨ ğŸ’»      Yerko Vera LezamağŸ¨ ğŸ’»      Ivan PenchevğŸ¨ ğŸ’»      Tanver Islam TonmoyğŸ¨ ğŸ’»      Xun CaoğŸ¨ ğŸ’»      Nayan BabariyağŸ¨ ğŸ’»      Priyanshu MauryağŸ¨ ğŸ’»              Dylan TintenfichğŸ¨ ğŸ’»      Ron StraussğŸ¨ ğŸ’»      Mohammed AlBannağŸ¨ ğŸ’»      Mukund MğŸ¨ ğŸ’»      Franklin OhaegbulamğŸ¨ ğŸ’»      Nisarg ShahğŸ¨ ğŸ’»      Unik DahalğŸ¨ ğŸ’»              ReadilyğŸ¨ ğŸ’»      Alexandre PoitevinğŸ¨ ğŸ’»      ScaramirğŸ¨ ğŸ’»      PruthviğŸ¨ ğŸ’»      KalmanqğŸ¨ ğŸ’»      Alfatah NesabğŸ¨ ğŸ’»      arudesaiğŸ¨ ğŸ’»              AdryenneğŸ¨ ğŸ’»      El mehdi oudaoudğŸ¨ ğŸ’»      Jayant GoelğŸ¨ ğŸ’»      TsukiğŸ¨ ğŸ’»      Peter LemanskiğŸ¨ ğŸ’»      Annurag-byteğŸ¨ ğŸ’»      Anthony VuğŸ¨ ğŸ’»              Vitaly NikolaychukğŸ¨ ğŸ’»      NathanğŸ¨ ğŸ’»      Evgenii PetukhovğŸ¨ ğŸ’»      Loris GuerrağŸ¨ ğŸ’»      fakhriaunurğŸ¨ ğŸ’»      Mehdi HYANIğŸ¨ ğŸ’»      Sarvex JatasrağŸ¨ ğŸ’»              santimanuelrğŸ¨ ğŸ’»      Evgeniy RezanovğŸ¨ ğŸ’»      Sonia MğŸ¨ ğŸ’»      Grzegorz KmitağŸ¨ ğŸ’»      Manuel CaritağŸ¨ ğŸ’»      Felipe Cisternas AlvarezğŸ¨ ğŸ’»      Guo CiğŸ¨ ğŸ’»              Marcos SilvağŸ¨ ğŸ’»      KKğŸ¨ ğŸ’»      Shubhanjan MedhiğŸ¨ ğŸ’»      ArthurFerreiraRodriguesğŸ¨ ğŸ’»      PabloHermunğŸ¨ ğŸ’»      disha-baldawağŸ¨ ğŸ’»      StaroMoonğŸ¨ ğŸ’»              Amila T KumarasekarağŸ¨ ğŸ’»      Amoh PrinceğŸ¨ ğŸ’»      AngeloGCğŸ¨ ğŸ’»      Ebube Glory OgbondağŸ¨ ğŸ’»      Prahalad BelavadiğŸ“–      Antoni Sarnowski-TrypkağŸ¨ ğŸ’»      Alberto PasqualettoğŸ¨ ğŸ’»              Amir BabaeiğŸ¨ ğŸ’»      Syed Abdul HannanğŸ¨ ğŸ’»      Srajan RaiğŸ¨ ğŸ’»      Clarence MooreğŸ¨ ğŸ’»      Nguyen Anh TuanğŸ¨ ğŸ’»      dar2dar2ğŸ¨ ğŸ’»      Ameer IbrahimğŸ¨ ğŸ’»              Tiago LugattoğŸ¨ ğŸ’»      raremiroirğŸ¨ ğŸ’»      MoobieğŸ¨ ğŸ’»      AlicanDursunğŸ¨ ğŸ’»      bbalsamğŸ¨ ğŸ’»      LuboÅ¡ HÃ¡jekğŸ¨ ğŸ’»      mrshahzeb7ğŸ¨ ğŸ’»              Wesley SchollğŸ¨ ğŸ’»      Lawrence TurcotteğŸ¨ ğŸ’»      Michael DiPaoloğŸ¨ ğŸ’»      Smart-CodiğŸ¨ ğŸ’»      Vivek KumarğŸ¨ ğŸ’»      Igor MoiseevğŸ¨ ğŸ’»      BÃ¥rd PedersenğŸ¨ ğŸ’»              HOA PHANğŸ¨ ğŸ’»      GaborModrağŸ¨ ğŸ’»      vivek-114ğŸ¨ ğŸ’»      RobinğŸ¨ ğŸ’»      AlexğŸ¨ ğŸ’»      John EhrlingerğŸ¨ ğŸ’»      Roman ZhuravlovğŸ¨ ğŸ’»              Jordan MossğŸ¨ ğŸ’»      RaeShellyğŸ¨ ğŸ’»      gmollardğŸ¨ ğŸ’»      Md Kaif KhanğŸ¨ ğŸ’»      Pablo RomerağŸ¨ ğŸ’»      Erik BustosğŸ¨ ğŸ’»      trogfieldğŸ¨ ğŸ’»              simon-aichhornğŸ¨ ğŸ’»      Tufan GÃœLEÃ‡ğŸ¨ ğŸ’»      UÄŸur Berkecan ÃœnlÃ¼ğŸ¨ ğŸ’»      Revanth NaikğŸ¨ ğŸ’»      Lia PiresğŸ¨ ğŸ’»      Igor MestechkinğŸ¨ ğŸ’»      Anirudh KaranthğŸ¨ ğŸ’»              KBobovskiyğŸ¨ ğŸ’»      zhatiayuağŸ¨ ğŸ’» ğŸ–‹      David CardonağŸ¨ ğŸ’»      Paulo CastilhoğŸ¨ ğŸ’»      Sebastiano PicchiğŸ¨ ğŸ’»      pjotarğŸ¨ ğŸ’»      Rimel CHERIFğŸ’»              Arsal uddinğŸ–‹      Dmitry KasporskyğŸ’»      SoftwareDev1014ğŸ¨ ğŸ’»      @RobvredğŸ¨ ğŸ’»      Kasun ShanakağŸ’»      Ahmad M.ğŸ¨ ğŸ’»      Alex KozinğŸ¨ ğŸ’»              Mandy MeindersmağŸ¨ ğŸ’»      LEGALISE PIRACYğŸ¨ ğŸ’»      Alex LogvinğŸ¨ ğŸ’»      Aria DahlğŸ¨ ğŸ’»      Mustafa ArifogluğŸ¨ ğŸ’»      Yevhen LeshchenkoğŸ¨ ğŸ’»      Anubhav AdhikariğŸ¨ ğŸ’»              Noah TatkoğŸ¨ ğŸ’»      Mohit GadhaviğŸ¨ ğŸ’»      Pedro BasÃ­lioğŸ¨ ğŸ’»      RealSanjeevğŸ¨ ğŸ’»      Akash HazrağŸ¨ ğŸ’»      Christoph DahlenğŸ¨ ğŸ’»      Vincent du PlessisğŸ¨ ğŸ’»              Karen TamrazyanğŸ¨ ğŸ’»      Mirza Younus BaigğŸ¨ ğŸ’»      Ashish KumarğŸ¨ ğŸ’»      Unknown6334ğŸ¨ ğŸ’»      flowazğŸ¨ ğŸ’»      zi-aikrağŸ¨ ğŸ’»      PAYAL PMğŸ¨ ğŸ’»              Lennart LÃ¶scheğŸ¨ ğŸ’»      Yummy-YumsğŸ¨ ğŸ’»      Njuacha Hubert MikulowskiğŸ¨ ğŸ’»      Hussein EsmailğŸ¨ ğŸ’»      Bilgehan BezirğŸ¨ ğŸ’»      Muhammed ShittuğŸ¨ ğŸ’»      ClÃ©ment FERNANDESğŸ¨ ğŸ’»              JaCKoP619ğŸ¨ ğŸ’»      userutf8ğŸ¨ ğŸ’»      Mohamed UbaidğŸ¨ ğŸ’»      Justin YatesğŸ¨ ğŸ’»      mohammad aliğŸ¨ ğŸ’»      Madhav SinghğŸ¨ ğŸ’»      RgbMouse69ğŸ¨ ğŸ’»              Nicholas LeaskğŸ¨ ğŸ’»      parthav0ğŸ¨ ğŸ’»      SigmağŸ¨ ğŸ’»      Evelina BechevağŸ¨ ğŸ’»      Akshit GulyanğŸ¨ ğŸ’»      Arpita JanağŸ¨ ğŸ’»      Praveen KumarğŸ¨ ğŸ’»              Mohammad SamiğŸ¨ ğŸ’»      eddiestefanescuğŸ¨ ğŸ’»      Ramesh YadavğŸ¨ ğŸ’»      Sarthak JoshiğŸ¨ ğŸ’»      Nikhil12300ğŸ¨ ğŸ’»      YevgenğŸ¨ ğŸ’»      LeoğŸ¨ ğŸ’»              laurent bğŸ¨ ğŸ’»      MettchenğŸ¨ ğŸ’»      Ali MahdaviğŸ¨ ğŸ’»      Lucas DondoğŸ¨ ğŸ’»      Siddhesh AgarwalğŸ¨ ğŸ’»      slimerPuncherğŸ¨ ğŸ’»      saritashhğŸ¨ ğŸ’»              Iulian-Valeriu CioatÄƒğŸ¨ ğŸ’»      Szabolcs NagyğŸ¨ ğŸ’»      Jarle KvileğŸ¨ ğŸ’»      åŠ‰è€€å‡ Vic LiuğŸ¨ ğŸ’»      SuryanshğŸ¨ ğŸ’»      Matthew OosthuyseğŸ¨ ğŸ’»      Florin ZamfirğŸ¨ ğŸ’»              MelekğŸ¨ ğŸ’»      moesocioğŸ¨ ğŸ’»      Alan JamesğŸ¨ ğŸ’»      Mai Thanh PhÆ°Æ¡ngğŸ¨ ğŸ’»      Neville DabreğŸ¨ ğŸ’»      MaksymğŸ¨ ğŸ’»      tamanna900ğŸ¨ ğŸ’»              Adithya AwatiğŸ¨ ğŸ’»      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
43,geekcomputers/Python,https://github.com/geekcomputers/Python/blob/master/README.md,Python,"My Python Eggs ğŸ ğŸ˜„I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in Notepad++ ğŸ—’ï¸Feel free to explore the scripts and use them for your learning and automation needs!List of Scripts:batch_file_rename.py - Batch rename a group of files in a specified directory, changing their extensions.create_dir_if_not_there.py - Check if a directory exists in the user's home directory. Create it if it doesn't exist.Fast Youtube Downloader - Download YouTube videos quickly with parallel threads using aria2c.Google Image Downloader - Query a given term and retrieve images from the Google Image database.dir_test.py - Test if the directory testdir exists. If not, create it.env_check.py - Check if all the required environment variables are set.blackjack.py - Casino Blackjack-21 game in Python.fileinfo.py - Show file information for a given file.folder_size.py - Scan the current directory and all subdirectories and display their sizes.logs.py - Search for all *.log files in a directory, zip them using the specified program, and date stamp them.move_files_over_x_days.py - Move all files over a specified age (in days) from the source directory to the destination directory.nslookup_check.py - Open the file server_list.txt and perform nslookup for each server to check the DNS entry.osinfo.py - Display information about the operating system on which the script is running.ping_servers.py - Ping the servers associated with the specified application group.ping_subnet.py - Scan the final range of a given IP subnet for available addresses.powerdown_startup.py - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.puttylogs.py - Zip all the logs in the given directory.script_count.py - Scan the scripts directory and count the different types of scripts.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.script_listing.py - List all files in a given directory and its subdirectories.testlines.py - Open a file and print out 100 lines of the set line variable.tweeter.py - Tweet text or a picture from the terminal.serial_scanner.py - List available serial ports in use on Linux and Windows systems.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.CountMillionCharacter.py and CountMillionCharacter2.0 - Get character count of a text file.xkcd_downloader.py - Download the latest XKCD comic and place them in a new folder called \""comics\"".timymodule.py - An alternative to Python's 'timeit' module and easier to use.calculator.py - Implement a calculator using Python's eval() function.Google_News.py - Use BeautifulSoup to provide latest news headlines along with news links.cricket_live_score - Use BeautifulSoup to provide live cricket scores.youtube.py - Take a song name as input and fetch the YouTube URL of the best matching song and play it.site_health.py - Check the health of a remote server.SimpleStopWatch.py - Simple stop watch implementation using Python's time module.Changemac.py - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).whatsapp-monitor.py - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.whatsapp-chat-analyzer.py - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.JARVIS.py - Control Windows programs with your voice.Images Downloader - Download images from webpages on Unix-based systems.space_invader.py.py - Classical 2D space invader game to recall your childhood memories.Test Case Generator - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.Note: The content in this repository belongs to the respective authors and creators. I'm just providing a formatted README.md for better presentation."
44,wangzheng0822/algo,https://github.com/wangzheng0822/algo/blob/master/README.md,Python,æ•°æ®ç»“æ„å’Œç®—æ³•å¿…çŸ¥å¿…ä¼šçš„50ä¸ªä»£ç å®ç°å¾®ä¿¡æœç´¢æˆ‘çš„å…¬ä¼—å·â€œå°äº‰å“¥â€ï¼Œæˆ–è€…å¾®ä¿¡æ‰«æä¸‹é¢äºŒç»´ç å…³æ³¨å…³æ³¨å¾®ä¿¡å…¬ä¼—å·ï¼Œå›å¤â€PDFâ€œè·å–ç‹¬å®¶ç®—æ³•èµ„æ–™ã€‚å‰Googleå·¥ç¨‹å¸ˆï¼Œ10ä¸‡äººè·Ÿç€å­¦çš„ã€Šæ•°æ®ç»“æ„å’Œç®—æ³•ä¹‹ç¾ã€‹ã€Šè®¾è®¡æ¨¡å¼ä¹‹ç¾ã€‹ä¸“æ ä½œè€…æ•°ç»„å®ç°ä¸€ä¸ªæ”¯æŒåŠ¨æ€æ‰©å®¹çš„æ•°ç»„å®ç°ä¸€ä¸ªå¤§å°å›ºå®šçš„æœ‰åºæ•°ç»„ï¼Œæ”¯æŒåŠ¨æ€å¢åˆ æ”¹æ“ä½œå®ç°ä¸¤ä¸ªæœ‰åºæ•°ç»„åˆå¹¶ä¸ºä¸€ä¸ªæœ‰åºæ•°ç»„é“¾è¡¨å®ç°å•é“¾è¡¨ã€å¾ªç¯é“¾è¡¨ã€åŒå‘é“¾è¡¨ï¼Œæ”¯æŒå¢åˆ æ“ä½œå®ç°å•é“¾è¡¨åè½¬å®ç°ä¸¤ä¸ªæœ‰åºçš„é“¾è¡¨åˆå¹¶ä¸ºä¸€ä¸ªæœ‰åºé“¾è¡¨å®ç°æ±‚é“¾è¡¨çš„ä¸­é—´ç»“ç‚¹æ ˆç”¨æ•°ç»„å®ç°ä¸€ä¸ªé¡ºåºæ ˆç”¨é“¾è¡¨å®ç°ä¸€ä¸ªé“¾å¼æ ˆç¼–ç¨‹æ¨¡æ‹Ÿå®ç°ä¸€ä¸ªæµè§ˆå™¨çš„å‰è¿›ã€åé€€åŠŸèƒ½é˜Ÿåˆ—ç”¨æ•°ç»„å®ç°ä¸€ä¸ªé¡ºåºé˜Ÿåˆ—ç”¨é“¾è¡¨å®ç°ä¸€ä¸ªé“¾å¼é˜Ÿåˆ—å®ç°ä¸€ä¸ªå¾ªç¯é˜Ÿåˆ—é€’å½’ç¼–ç¨‹å®ç°æ–æ³¢é‚£å¥‘æ•°åˆ—æ±‚å€¼f(n)=f(n-1)+f(n-2)ç¼–ç¨‹å®ç°æ±‚é˜¶ä¹˜n!ç¼–ç¨‹å®ç°ä¸€ç»„æ•°æ®é›†åˆçš„å…¨æ’åˆ—æ’åºå®ç°å½’å¹¶æ’åºã€å¿«é€Ÿæ’åºã€æ’å…¥æ’åºã€å†’æ³¡æ’åºã€é€‰æ‹©æ’åºç¼–ç¨‹å®ç°O(n)æ—¶é—´å¤æ‚åº¦å†…æ‰¾åˆ°ä¸€ç»„æ•°æ®çš„ç¬¬Kå¤§å…ƒç´ äºŒåˆ†æŸ¥æ‰¾å®ç°ä¸€ä¸ªæœ‰åºæ•°ç»„çš„äºŒåˆ†æŸ¥æ‰¾ç®—æ³•å®ç°æ¨¡ç³ŠäºŒåˆ†æŸ¥æ‰¾ç®—æ³•ï¼ˆæ¯”å¦‚å¤§äºç­‰äºç»™å®šå€¼çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰æ•£åˆ—è¡¨å®ç°ä¸€ä¸ªåŸºäºé“¾è¡¨æ³•è§£å†³å†²çªé—®é¢˜çš„æ•£åˆ—è¡¨å®ç°ä¸€ä¸ªLRUç¼“å­˜æ·˜æ±°ç®—æ³•å­—ç¬¦ä¸²å®ç°ä¸€ä¸ªå­—ç¬¦é›†ï¼ŒåªåŒ…å«aï½zè¿™26ä¸ªè‹±æ–‡å­—æ¯çš„Trieæ ‘å®ç°æœ´ç´ çš„å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•äºŒå‰æ ‘å®ç°ä¸€ä¸ªäºŒå‰æŸ¥æ‰¾æ ‘ï¼Œå¹¶ä¸”æ”¯æŒæ’å…¥ã€åˆ é™¤ã€æŸ¥æ‰¾æ“ä½œå®ç°æŸ¥æ‰¾äºŒå‰æŸ¥æ‰¾æ ‘ä¸­æŸä¸ªèŠ‚ç‚¹çš„åç»§ã€å‰é©±èŠ‚ç‚¹å®ç°äºŒå‰æ ‘å‰ã€ä¸­ã€ååºä»¥åŠæŒ‰å±‚éå†å †å®ç°ä¸€ä¸ªå°é¡¶å †ã€å¤§é¡¶å †ã€ä¼˜å…ˆçº§é˜Ÿåˆ—å®ç°å †æ’åºåˆ©ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—åˆå¹¶Kä¸ªæœ‰åºæ•°ç»„æ±‚ä¸€ç»„åŠ¨æ€æ•°æ®é›†åˆçš„æœ€å¤§Top Kå›¾å®ç°æœ‰å‘å›¾ã€æ— å‘å›¾ã€æœ‰æƒå›¾ã€æ— æƒå›¾çš„é‚»æ¥çŸ©é˜µå’Œé‚»æ¥è¡¨è¡¨ç¤ºæ–¹æ³•å®ç°å›¾çš„æ·±åº¦ä¼˜å…ˆæœç´¢ã€å¹¿åº¦ä¼˜å…ˆæœç´¢å®ç°Dijkstraç®—æ³•ã€A*ç®—æ³•å®ç°æ‹“æ‰‘æ’åºçš„Kahnç®—æ³•ã€DFSç®—æ³•å›æº¯åˆ©ç”¨å›æº¯ç®—æ³•æ±‚è§£å…«çš‡åé—®é¢˜åˆ©ç”¨å›æº¯ç®—æ³•æ±‚è§£0-1èƒŒåŒ…é—®é¢˜åˆ†æ²»åˆ©ç”¨åˆ†æ²»ç®—æ³•æ±‚ä¸€ç»„æ•°æ®çš„é€†åºå¯¹ä¸ªæ•°åŠ¨æ€è§„åˆ’0-1èƒŒåŒ…é—®é¢˜æœ€å°è·¯å¾„å’Œç¼–ç¨‹å®ç°è±æ–‡æ–¯å¦æœ€çŸ­ç¼–è¾‘è·ç¦»ç¼–ç¨‹å®ç°æŸ¥æ‰¾ä¸¤ä¸ªå­—ç¬¦ä¸²çš„æœ€é•¿å…¬å…±å­åºåˆ—ç¼–ç¨‹å®ç°ä¸€ä¸ªæ•°æ®åºåˆ—çš„æœ€é•¿é€’å¢å­åºåˆ—
45,encode/django-rest-framework,https://github.com/encode/django-rest-framework/blob/master/README.md,Python,"Django REST frameworkAwesome web-browsable Web APIs.Full documentation for the project is available at https://www.django-rest-framework.org/.FundingREST framework is a collaboratively funded project. If you useREST framework commercially we strongly encourage you to invest in itscontinued development by signing up for a paid plan.The initial aim is to provide a single full-time position on REST framework.Every single sign-up makes a significant impact towards making that possible.Many thanks to all our wonderful sponsors, and in particular to our premium backers, Sentry, Stream, Spacinov, Retool, bit.io, PostHog, CryptAPI, and FEZTO.OverviewDjango REST framework is a powerful and flexible toolkit for building Web APIs.Some reasons you might want to use REST framework:The Web browsable API is a huge usability win for your developers.Authentication policies including optional packages for OAuth1a and OAuth2.Serialization that supports both ORM and non-ORM data sources.Customizable all the way down - just use regular function-based views if you don't need the more powerful features.Extensive documentation, and great community support.There is a live example API for testing purposes, available here.Below: Screenshot from the browsable APIRequirementsPython 3.6+Django 4.2, 4.1, 4.0, 3.2, 3.1, 3.0We highly recommend and only officially support the latest patch release ofeach Python and Django series.InstallationInstall using pip...pip install djangorestframeworkAdd 'rest_framework' to your INSTALLED_APPS setting.INSTALLED_APPS = [    ...    'rest_framework',]ExampleLet's take a look at a quick example of using REST framework to build a simple model-backed API for accessing users and groups.Startup up a new project like so...pip install djangopip install djangorestframeworkdjango-admin startproject example ../manage.py migrate./manage.py createsuperuserNow edit the example/urls.py module in your project:from django.contrib.auth.models import Userfrom django.urls import include, pathfrom rest_framework import routers, serializers, viewsets# Serializers define the API representation.class UserSerializer(serializers.HyperlinkedModelSerializer):    class Meta:        model = User        fields = ['url', 'username', 'email', 'is_staff']# ViewSets define the view behavior.class UserViewSet(viewsets.ModelViewSet):    queryset = User.objects.all()    serializer_class = UserSerializer# Routers provide a way of automatically determining the URL conf.router = routers.DefaultRouter()router.register(r'users', UserViewSet)# Wire up our API using automatic URL routing.# Additionally, we include login URLs for the browsable API.urlpatterns = [    path('', include(router.urls)),    path('api-auth/', include('rest_framework.urls', namespace='rest_framework')),]We'd also like to configure a couple of settings for our API.Add the following to your settings.py module:INSTALLED_APPS = [    ...  # Make sure to include the default installed apps here.    'rest_framework',]REST_FRAMEWORK = {    # Use Django's standard `django.contrib.auth` permissions,    # or allow read-only access for unauthenticated users.    'DEFAULT_PERMISSION_CLASSES': [        'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly',    ]}That's it, we're done!./manage.py runserverYou can now open the API in your browser at http://127.0.0.1:8000/, and view your new 'users' API. If you use the Login control in the top right corner you'll also be able to add, create and delete users from the system.You can also interact with the API using command line tools such as curl. For example, to list the users endpoint:$ curl -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/[    {        \""url\"": \""http://127.0.0.1:8000/users/1/\"",        \""username\"": \""admin\"",        \""email\"": \""admin@example.com\"",        \""is_staff\"": true,    }]Or to create a new user:$ curl -X POST -d username=new -d email=new@example.com -d is_staff=false -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/{    \""url\"": \""http://127.0.0.1:8000/users/2/\"",    \""username\"": \""new\"",    \""email\"": \""new@example.com\"",    \""is_staff\"": false,}Documentation & SupportFull documentation for the project is available at https://www.django-rest-framework.org/.For questions and support, use the REST framework discussion group, or #restframework on libera.chat IRC.You may also want to follow the author on Twitter.SecurityPlease see the security policy."
46,facebookresearch/Detectron,https://github.com/facebookresearch/Detectron/blob/main/README.md,Python,"Detectron is deprecated. Please see detectron2, a ground-up rewrite of Detectron in PyTorch.DetectronDetectron is Facebook AI Research's software system that implements state-of-the-art object detection algorithms, including Mask R-CNN. It is written in Python and powered by the Caffe2 deep learning framework.At FAIR, Detectron has enabled numerous research projects, including: Feature Pyramid Networks for Object Detection, Mask R-CNN, Detecting and Recognizing Human-Object Interactions, Focal Loss for Dense Object Detection, Non-local Neural Networks, Learning to Segment Every Thing, Data Distillation: Towards Omni-Supervised Learning, DensePose: Dense Human Pose Estimation In The Wild, and Group Normalization.    Example Mask R-CNN output.IntroductionThe goal of Detectron is to provide a high-quality, high-performancecodebase for object detection research. It is designed to be flexible in orderto support rapid implementation and evaluation of novel research. Detectronincludes implementations of the following object detection algorithms:Mask R-CNN -- Marr Prize at ICCV 2017RetinaNet -- Best Student Paper Award at ICCV 2017Faster R-CNNRPNFast R-CNNR-FCNusing the following backbone network architectures:ResNeXt{50,101,152}ResNet{50,101,152}Feature Pyramid Networks (with ResNet/ResNeXt)VGG16Additional backbone architectures may be easily implemented. For more details about these models, please see References below.Update4/2018: Support Group Normalization - see GN/README.mdLicenseDetectron is released under the Apache 2.0 license. See the NOTICE file for additional details.Citing DetectronIf you use Detectron in your research or wish to refer to the baseline results published in the Model Zoo, please use the following BibTeX entry.@misc{Detectron2018,  author =       {Ross Girshick and Ilija Radosavovic and Georgia Gkioxari and                  Piotr Doll\\'{a}r and Kaiming He},  title =        {Detectron},  howpublished = {\\url{https://github.com/facebookresearch/detectron}},  year =         {2018}}Model Zoo and BaselinesWe provide a large set of baseline results and trained models available for download in the Detectron Model Zoo.InstallationPlease find installation instructions for Caffe2 and Detectron in INSTALL.md.Quick Start: Using DetectronAfter installation, please see GETTING_STARTED.md for brief tutorials covering inference and training with Detectron.Getting HelpTo start, please check the troubleshooting section of our installation instructions as well as our FAQ. If you couldn't find help there, try searching our GitHub issues. We intend the issues page to be a forum in which the community collectively troubleshoots problems.If bugs are found, we appreciate pull requests (including adding Q&A's to FAQ.md and improving our installation instructions and troubleshooting documents). Please see CONTRIBUTING.md for more information about contributing to Detectron.ReferencesData Distillation: Towards Omni-Supervised Learning.Ilija Radosavovic, Piotr DollÃ¡r, Ross Girshick, Georgia Gkioxari, and Kaiming He.Tech report, arXiv, Dec. 2017.Learning to Segment Every Thing.Ronghang Hu, Piotr DollÃ¡r, Kaiming He, Trevor Darrell, and Ross Girshick.Tech report, arXiv, Nov. 2017.Non-Local Neural Networks.Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.Tech report, arXiv, Nov. 2017.Mask R-CNN.Kaiming He, Georgia Gkioxari, Piotr DollÃ¡r, and Ross Girshick.IEEE International Conference on Computer Vision (ICCV), 2017.Focal Loss for Dense Object Detection.Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr DollÃ¡r.IEEE International Conference on Computer Vision (ICCV), 2017.Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour.Priya Goyal, Piotr DollÃ¡r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.Tech report, arXiv, June 2017.Detecting and Recognizing Human-Object Interactions.Georgia Gkioxari, Ross Girshick, Piotr DollÃ¡r, and Kaiming He.Tech report, arXiv, Apr. 2017.Feature Pyramid Networks for Object Detection.Tsung-Yi Lin, Piotr DollÃ¡r, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.Aggregated Residual Transformations for Deep Neural Networks.Saining Xie, Ross Girshick, Piotr DollÃ¡r, Zhuowen Tu, and Kaiming He.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.R-FCN: Object Detection via Region-based Fully Convolutional Networks.Jifeng Dai, Yi Li, Kaiming He, and Jian Sun.Conference on Neural Information Processing Systems (NIPS), 2016.Deep Residual Learning for Image Recognition.Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.Faster R-CNN: Towards Real-Time Object Detection with Region Proposal NetworksShaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.Conference on Neural Information Processing Systems (NIPS), 2015.Fast R-CNN.Ross Girshick.IEEE International Conference on Computer Vision (ICCV), 2015."
47,saltstack/salt,https://github.com/saltstack/salt/blob/master/README.rst,Python,"Latest Salt DocumentationOpen an issue (bug report, feature request, etc.)Salt is the world's fastest, most intelligent and scalable automationengine.About SaltBuilt on Python, Salt is an event-driven automation tool and framework todeploy, configure, and manage complex IT systems. Use Salt to automate commoninfrastructure administration tasks and ensure that all the components of yourinfrastructure are operating in a consistent desired state.Salt has many possible uses, including configuration management, which involves:Managing operating system deployment and configuration.Installing and configuring software applications and services.Managing servers, virtual machines, containers, databases, web servers,network devices, and more.Ensuring consistent configuration and preventing configuration drift.Salt is ideal for configuration management because it is pluggable,customizable, and plays well with many existing technologies. Salt enables youto deploy and manage applications that use any tech stack running on nearly anyoperating system,including different types of network devices such as switches and routers from avariety of vendors.In addition to configuration management Salt can also:Automate and orchestrate routine IT processes, such as common required tasksfor scheduled server downtimes or upgrading operating systems or applications.Create self-aware, self-healing systems that can automatically respond tooutages, common administration problems, or other important events.About our sponsorsSalt powers VMware's VMware Aria Automation Config(previously vRealize Automation SaltStack Config / SaltStack Enterprise), and can be foundunder the hood of products from Juniper, Cisco, Cloudflare, Nutanix, SUSE, andTieto, to name a few.The original sponsor of our community, SaltStack, was acquired by VMware in 2020.The Salt Project remains an open source ecosystem that VMware supports andcontributes to. VMware ensures the code integrity and quality of the Saltmodules by acting as the official sponsor and manager of the Salt project. Manyof the core Salt Project contributors are also VMware employees. This teamcarefully reviews and enhances the Salt modules to ensure speed, quality, andsecurity.Download and install SaltSalt is tested and packaged to run on CentOS, Debian, RHEL, Ubuntu, MacOS,Windows, and more. Download Salt and get started now. Seesupported operating systemsfor more information.To download and install Salt, see:* The Salt install guide* Salt Project repositoryTechnical supportReport bugs or problems using Salt by opening an issue: https://github.com/saltstack/salt/issuesTo join our community forum where you can exchange ideas, best practices,discuss technical support questions, and talk to project maintainers, join ourSlack workspace: Salt Project Community SlackSalt Project documentationInstallation instructions, tutorials, in-depth API and module documentation:The Salt install guideThe Salt user guideLatest Salt documentationSalt's contributing guideSecurity advisoriesKeep an eye on the Salt ProjectSecurity Announcementslanding page. Salt Project recommends subscribing to theSalt Project Security RSS feedto receive notification when new information is available regarding securityannouncements.Other channels to receive security announcements include theSalt Community mailing listand the Salt Project Community Slack.Responsibly reporting security vulnerabilitiesWhen reporting security vulnerabilities for Salt or other SaltStack projects,refer to the SECURITY.md file found in this repository.Join our communitySalt is built by the Salt Project community, which includes more than 3,000contributors working in roles just like yours. This well-known and trustedcommunity works together to improve the underlying technology and extend Salt bycreating a variety of execution and state modules to accomplish the most commontasks or solve the most important problems that people in your role are likelyto face.If you want to help extend Salt or solve a problem with Salt, you can join ourcommunity and contribute today.Please be sure to review ourCode of Conduct.Also, check out some of our community resources including:Salt Project Community WikiSalt Project Community SlackSalt Project: IRC on LiberaChatSalt Project YouTube channelSalt Project Twitch channelThere are lots of ways to get involved in our community. Every month, there arearound a dozen opportunities to meet with other contributors and the Salt Coreteam and collaborate in real time. The best way to keep track is by subscribingto the Salt Project Community Events Calendar on the mainhttps://saltproject.io website.If you have additional questions, email us at saltproject@vmware.com or reach outdirectly to the Community Manager, Jimmy Chunga via Slack. We'd be glad tohave you join our community!LicenseSalt is licensed under the Apache 2.0 license. Pleasesee theLICENSE file for thefull text of the Apache license, followed by a full summary of the licensingused by external modules.A complete list of attributions and dependencies can be found here:salt/DEPENDENCIES.md"
48,donnemartin/system-design-primer,https://github.com/donnemartin/system-design-primer/blob/master/README-ja.md,Python,"English âˆ™ æ—¥æœ¬èª âˆ™ ç®€ä½“ä¸­æ–‡ âˆ™ ç¹é«”ä¸­æ–‡ | Ø§Ù„Ø¹ÙØ±ÙØ¨ÙÙŠÙÙ‘Ø©â€ âˆ™ à¦¬à¦¾à¦‚à¦²à¦¾ âˆ™ PortuguÃªs do Brasil âˆ™ Deutsch âˆ™ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ âˆ™ ×¢×‘×¨×™×ª âˆ™ Italiano âˆ™ í•œêµ­ì–´ âˆ™ ÙØ§Ø±Ø³ÛŒ âˆ™ Polski âˆ™ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº âˆ™ EspaÃ±ol âˆ™ à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ âˆ™ TÃ¼rkÃ§e âˆ™ tiáº¿ng Viá»‡t âˆ™ FranÃ§ais | Add Translationã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå…¥é–€    å‹•æ©Ÿãƒ»ç›®çš„å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’å­¦ã¶ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«å‚™ãˆã‚‹å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆã‚’å­¦ã¶ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’å­¦ã¶ã“ã¨ã¯ã€ã‚ˆã‚Šè‰¯ã„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ãªã‚‹ã“ã¨ã«è³‡ã™ã‚‹ã§ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã¯ã¨ã¦ã‚‚åºƒç¯„ãªãƒˆãƒ”ãƒƒã‚¯ã‚’å«ã¿ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆåŸç†ã«ã¤ã„ã¦ã¯ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã«ã¯è†¨å¤§ãªé‡ã®æ–‡çŒ®ãŒæ•£ã‚‰ã°ã£ã¦ã„ã¾ã™ã€‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã«å¿…è¦ãªçŸ¥è­˜ã‚’å­¦ã¶ã“ã¨ãŒã§ãã‚‹ æ–‡çŒ®ãƒªã‚¹ãƒˆã‚’ä½“ç³»çš„ã«ã¾ã¨ã‚ãŸã‚‚ã® ã§ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰å­¦ã¶ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ã“ã‚Œã‹ã‚‰ã‚‚ãšã£ã¨æ›´æ–°ã•ã‚Œã¦ã„ãã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸæ®µéšã«ã™ãã¾ã›ã‚“ã€‚Contributions ã¯å¤§æ­“è¿ã§ã™ï¼ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«å‚™ãˆã‚‹ã‚³ãƒ¼ãƒ‰æŠ€è¡“é¢æ¥ã«åŠ ãˆã¦ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«é–¢ã™ã‚‹çŸ¥è­˜ã¯ã€å¤šãã®ãƒ†ãƒƒã‚¯ä¼æ¥­ã«ãŠã‘ã‚‹ æŠ€è¡“æ¡ç”¨é¢æ¥ãƒ—ãƒ­ã‚»ã‚¹ ã§ å¿…è¦ä¸å¯æ¬ ãªè¦ç´  ã§ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§ã®é »å‡ºè³ªå•ã«å‚™ãˆã€è‡ªåˆ†ã®è§£ç­”ã¨æ¨¡ç¯„è§£ç­”:ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã€ã‚³ãƒ¼ãƒ‰ãã—ã¦å›³è¡¨ãªã©ã‚’æ¯”è¼ƒã—ã¦å­¦ã³ã¾ã—ã‚‡ã†ã€‚é¢æ¥æº–å‚™ã«å½¹ç«‹ã¤ãã®ä»–ã®ãƒˆãƒ”ãƒƒã‚¯:å­¦ç¿’æŒ‡é‡ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«ã©ã®ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ ã¨ãã®è§£ç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆèª²é¡Œä¾‹ã€ ã¨ãã®è§£ç­”ãã®ä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œä¾‹æš—è¨˜ã‚«ãƒ¼ãƒ‰    ã“ã®Ankiç”¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒƒã‚­ ã¯ã€é–“éš”åå¾©ã‚’æ´»ç”¨ã—ã¦ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ã‚­ãƒ¼ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®å­¦ç¿’ã‚’æ”¯æ´ã—ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒ‡ãƒƒã‚­ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆç·´ç¿’èª²é¡Œãƒ‡ãƒƒã‚­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ç·´ç¿’èª²é¡Œãƒ‡ãƒƒã‚­å¤–å‡ºå…ˆã‚„ç§»å‹•ä¸­ã®å‹‰å¼·ã«å½¹ç«‹ã¤ã§ã—ã‚‡ã†ã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŠ€è¡“èª²é¡Œç”¨ã®å•é¡Œ: ç·´ç¿’ç”¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰æŠ€è¡“é¢æ¥ç”¨ã®å•é¡Œã‚’æ¢ã—ã¦ã„ã‚‹å ´åˆã¯ã“ã¡ã‚‰    å§‰å¦¹ãƒªãƒã‚¸ãƒˆãƒªã® Interactive Coding Challengesã‚‚è¦‹ã¦ã¿ã¦ãã ã•ã„ã€‚è¿½åŠ ã®æš—è¨˜ãƒ‡ãƒƒã‚­ã‚«ãƒ¼ãƒ‰ã‚‚å…¥ã£ã¦ã„ã¾ã™ã€‚Coding deckã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰å­¦ã¶ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆç­‰ã®è²¢çŒ®ã¯ç©æ¥µçš„ã«ãŠé¡˜ã„ã—ã¾ã™:ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹æ”¹å–„æ–°è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ ç¿»è¨³ã™ã‚‹ç¾åœ¨ã€å†…å®¹ã®æ”¹å–„ãŒå¿…è¦ãªä½œæ¥­ä¸­ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã“ã¡ã‚‰ã§ã™ã€‚ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã®å‰ã«Contributing Guidelinesã‚’èª­ã¿ã¾ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆç›®æ¬¡è³›å¦ã‚‚å«ã‚ãŸæ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®å„ãƒˆãƒ”ãƒƒã‚¯ã®æ¦‚è¦ã€‚ å…¨ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚Šã¾ã™ã€‚ãã‚Œãã‚Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ˆã‚Šå­¦ã³ã‚’æ·±ã‚ã‚‹ã‚ˆã†ãªä»–ã®æ–‡çŒ®ã¸ã®ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚    ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯: ã¾ãšã¯ã“ã“ã‹ã‚‰Step 1: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹å‹•ç”»ã‚’è¦‹ã‚‹Step 2: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹è¨˜äº‹ã‚’èª­ã‚€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¯ç”¨æ€§ vs ä¸€è²«æ€§CAPç†è«–CP - ä¸€è²«æ€§(consistency)ã¨åˆ†å‰²æ€§(partition)è€æ€§AP - å¯ç”¨æ€§(availability)ã¨åˆ†å‰²æ€§(partition)è€æ€§ä¸€è²«æ€§ ãƒ‘ã‚¿ãƒ¼ãƒ³å¼±ã„ä¸€è²«æ€§çµæœæ•´åˆæ€§å¼·ã„ä¸€è²«æ€§å¯ç”¨æ€§ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ (DNS)ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CDN)ãƒ—ãƒƒã‚·ãƒ¥CDNãƒ—ãƒ«CDNãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ–/ãƒ‘ãƒƒã‚·ãƒ–æ§‹æˆã‚¢ã‚¯ãƒ†ã‚£ãƒ–/ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ§‹æˆLayer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· (WEBã‚µãƒ¼ãƒãƒ¼)ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ vs ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (RDBMS)ãƒã‚¹ã‚¿ãƒ¼/ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼/ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ãƒãƒ¼ãƒãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³SQL ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°NoSQLã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã‚°ãƒ©ãƒ• ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹SQL or NoSQLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°CDNã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°Webã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã™ã‚‹ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã®ã‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ (ãƒ©ã‚¤ãƒˆãƒãƒƒã‚¯)ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰éåŒæœŸå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼é€šä¿¡ä¼é€åˆ¶å¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ« (TCP)ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« (UDP)é éš”æ‰‹ç¶šå‘¼å‡º (RPC)Representational state transfer (REST)ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è£œéº2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ä¾‹é¡Œå®Ÿä¸–ç•Œã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å„ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°ä½œæ¥­ä¸­ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆé€£çµ¡æƒ…å ±ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å­¦ç¿’æŒ‡é‡å­¦ç¿’ã‚¹ãƒ‘ãƒ³ã«å¿œã˜ã¦ã¿ã‚‹ã¹ããƒˆãƒ”ãƒƒã‚¯ã‚¹ (short, medium, long)Q: é¢æ¥ã®ãŸã‚ã«ã¯ã€ã“ã“ã«ã‚ã‚‹ã‚‚ã®ã™ã¹ã¦ã‚’ã‚„ã‚‰ãªã„ã¨ã„ã‘ãªã„ã®ã§ã—ã‚‡ã†ã‹ï¼ŸA: ã„ãˆã€ã“ã“ã«ã‚ã‚‹ã™ã¹ã¦ã‚’ã‚„ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚é¢æ¥ã§ä½•ã‚’èã‹ã‚Œã‚‹ã‹ã¯ä»¥ä¸‹ã®æ¡ä»¶ã«ã‚ˆã£ã¦å¤‰ã‚ã£ã¦ãã¾ã™:ã©ã‚Œã ã‘ã®æŠ€è¡“çµŒé¨“ãŒã‚ã‚‹ã‹ã‚ãªãŸã®æŠ€è¡“èƒŒæ™¯ãŒä½•ã§ã‚ã‚‹ã‹ã©ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ãŸã‚ã«é¢æ¥ã‚’å—ã‘ã¦ã„ã‚‹ã‹ã©ã®ä¼æ¥­ã®é¢æ¥ã‚’å—ã‘ã¦ã„ã‚‹ã‹é‹ã‚ˆã‚ŠçµŒé¨“ã®ã‚ã‚‹å€™è£œè€…ã¯ä¸€èˆ¬çš„ã«ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«ã¤ã„ã¦ã‚ˆã‚Šæ·±ã„çŸ¥è­˜ã‚’æœ‰ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¦æ±‚ã•ã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã‚„ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ã¯å„ãƒ¡ãƒ³ãƒãƒ¼ã®æŒã¤ã‚ˆã†ãªçŸ¥è­˜ã‚ˆã‚Šã¯æ·±ã„è¦‹è­˜ã‚’æŒã£ã¦ã„ã‚‹ã¹ãã§ã—ã‚‡ã†ã€‚ä¸€æµãƒ†ãƒƒã‚¯ä¼æ¥­ã§ã¯è¤‡æ•°å›ã®è¨­è¨ˆé¢æ¥ã‚’èª²ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ã¾ãšã¯åºƒãå§‹ã‚ã¦ã€ãã“ã‹ã‚‰ã„ãã¤ã‹ã®åˆ†é‡ã«çµã£ã¦æ·±ã‚ã¦ã„ãã®ãŒã„ã„ã§ã—ã‚‡ã†ã€‚æ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦å°‘ã—ãšã¤çŸ¥ã£ã¦ãŠãã“ã¨ã¯ã„ã„ã“ã¨ã§ã™ã€‚ä»¥ä¸‹ã®å­¦ç¿’ã‚¬ã‚¤ãƒ‰ã‚’è‡ªåˆ†ã®å­¦ç¿’ã«å½“ã¦ã‚‰ã‚Œã‚‹æ™‚é–“ã€æŠ€è¡“çµŒé¨“ã€ã©ã®è·ä½ã€ã©ã®ä¼šç¤¾ã«å¿œå‹Ÿã—ã¦ã„ã‚‹ã‹ãªã©ã‚’åŠ å‘³ã—ã¦è‡ªåˆ†ç”¨ã«èª¿æ•´ã—ã¦ä½¿ã†ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚çŸ­æœŸé–“ - å¹…åºƒã ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚ã„ãã¤ã‹ã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚ä¸­æœŸé–“ - å¹…åºƒã ãã—ã¦ ãã‚Œãªã‚Šã«æ·±ãã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚å¤šãã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚é•·æœŸé–“ - å¹…åºƒã ãã—ã¦ ã‚‚ã£ã¨æ·±ãã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚ã»ã¼å…¨ã¦ã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚çŸ­æœŸé–“ä¸­æœŸé–“é•·æœŸé–“ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ ã‚’èª­ã¿ã€ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œæ©Ÿåºã«ã¤ã„ã¦åºƒãçŸ¥ã‚‹ğŸ‘ğŸ‘ğŸ‘æ¬¡ã®ãƒªãƒ³ã‚¯å…ˆã®ã„ãã¤ã‹ã®ãƒšãƒ¼ã‚¸ã‚’èª­ã‚“ã§ å„ä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ–ãƒ­ã‚° å¿œå‹Ÿã™ã‚‹ä¼šç¤¾ã«ã¤ã„ã¦çŸ¥ã‚‹ğŸ‘ğŸ‘ğŸ‘æ¬¡ã®ãƒªãƒ³ã‚¯å…ˆã®ã„ãã¤ã‹ã®ãƒšãƒ¼ã‚¸ã‚’èª­ã‚€ å®Ÿä¸–ç•Œã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ğŸ‘ğŸ‘ğŸ‘å¾©ç¿’ã™ã‚‹ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«ã©ã®ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã‹ğŸ‘ğŸ‘ğŸ‘ã¨ã‚Šã‚ãˆãšä¸€å‘¨ã™ã‚‹ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹SomeManyMostã¨ã‚Šã‚ãˆãšä¸€å‘¨ã™ã‚‹ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆå•é¡Œã¨è§£ç­”SomeManyMostå¾©ç¿’ã™ã‚‹ ãã®ä»–ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§ã®è³ªå•ä¾‹SomeManyMostã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã«ã©ã®ã‚ˆã†ã«ã—ã¦è‡¨ã‚ã°ã„ã„ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥è©¦é¨“å•é¡Œã«ã©ã®ã‚ˆã†ã«å–ã‚Šçµ„ã‚€ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã¯ open-ended conversation(Yes/Noã§ã¯ç­”ãˆã‚‰ã‚Œãªã„å£é ­è³ªå•)ã§ã™ã€‚ è‡ªåˆ†ã§ä¼šè©±ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã«å¾“ã£ã¦è­°è«–ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã“ã¨ãŒã§ãã‚‹ã§ã—ã‚‡ã†ã€‚ã“ã®éç¨‹ã‚’ç¢ºã‹ãªã‚‚ã®ã«ã™ã‚‹ãŸã‚ã«ã€æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ã¨ãã®è§£ç­” ã‚’ä»¥ä¸‹ã®æŒ‡é‡ã«å¾“ã£ã¦èª­ã¿è¾¼ã‚€ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚ã‚¹ãƒ†ãƒƒãƒ— 1: ãã®ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ä¾‹ã®æ¦‚è¦ã€åˆ¶ç´„ã€æ¨è¨ˆå€¤ç­‰ã‚’èãå‡ºã—ã€ã¾ã¨ã‚ã‚‹ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜ã®è¦æ±‚äº‹é …ã‚’èãå‡ºã—ã€å•é¡Œç®‡æ‰€ã‚’ç‰¹å®šã—ã¾ã—ã‚‡ã†ã€‚ä½¿ç”¨ä¾‹ã¨åˆ¶ç´„ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã®è³ªå•ã‚’æŠ•ã’ã‹ã‘ã¾ã—ã‚‡ã†ã€‚è¦æ±‚ã™ã‚‹æ¨è¨ˆå€¤ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚èª°ãŒãã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã†ã®ã‹ï¼Ÿã©ã®ã‚ˆã†ã«ä½¿ã†ã®ã‹ï¼Ÿä½•äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã„ã‚‹ã®ã‹ï¼Ÿã‚·ã‚¹ãƒ†ãƒ ã¯ã©ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’æœãŸã™ã®ã‹ï¼Ÿã‚·ã‚¹ãƒ†ãƒ ã¸ã®å…¥åŠ›ã¨å‡ºåŠ›ã¯ï¼Ÿã©ã‚Œã ã‘ã®å®¹é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒãå¿…è¦ãŒã‚ã‚‹ã®ã‹ï¼Ÿä¸€ç§’é–“ã«ä½•ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é€ä¿¡ãŒæƒ³å®šã•ã‚Œã‚‹ã‹ï¼Ÿèª­ã¿æ›¸ãæ¯”ç‡ã®æ¨å®šå€¤ã¯ã„ãã‚‰ç¨‹åº¦ã‹ï¼Ÿã‚¹ãƒ†ãƒƒãƒ— 2: ã‚ˆã‚Šé«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’çµ„ã¿ç«‹ã¦ã‚‹é‡è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å…¨ã¦è€ƒæ…®ã—ãŸé«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ¦‚è¦ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¨æ¥ç¶šã‚’ã‚¹ã‚±ãƒƒãƒã—ã¦æ›¸ãå‡ºã™è€ƒãˆã®è£ä»˜ã‘ã‚’ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ— 3: æ ¸ã¨ãªã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è¨­è¨ˆã™ã‚‹ãã‚Œãã‚Œã®ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦ã®è©³ç´°ã‚’å­¦ã¶ã€‚ä¾‹ãˆã°ã€urlçŸ­ç¸®ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆã‚’å•ã‚ã‚ŒãŸéš›ã«ã¯æ¬¡ã®ã‚ˆã†ã«ã™ã‚‹ã¨ã„ã„ã§ã—ã‚‡ã†:å…ƒã®URLã®ãƒãƒƒã‚·ãƒ¥åŒ–ã—ãŸã‚‚ã®ã‚’ä½œã‚Šã€ãã‚Œã‚’ä¿å­˜ã™ã‚‹MD5 ã¨ Base62ãƒãƒƒã‚·ãƒ¥è¡çªSQL ã‚‚ã—ãã¯ NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚ŒãŸURLã‚’å…ƒã®URLã«å†ç¿»è¨³ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‚ç…§API & ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã®è¨­è¨ˆã‚¹ãƒ†ãƒƒãƒ— 4: ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ã‚¹ã‚±ãƒ¼ãƒ«ä¸ãˆã‚‰ã‚ŒãŸåˆ¶ç´„æ¡ä»¶ã‹ã‚‰ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚Šãã†ãªã¨ã“ã‚ã‚’å‰²ã‚Šå‡ºã—ã€æ˜ç¢ºåŒ–ã™ã‚‹ã€‚  ä¾‹ãˆã°ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®å•é¡Œè§£æ±ºã®ãŸã‚ã«ä»¥ä¸‹ã®è¦ç´ ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å–ã‚Šã†ã‚‹è§£æ±ºç­–ã¨ãã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦è­°è«–ã‚’ã—ã‚ˆã†ã€‚å…¨ã¦ã®ã“ã¨ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ã€‚ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ã¤ã„ã¦ã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®åŸç†ã‚’èª­ã‚€ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚ã¡ã‚‡ã£ã¨ã—ãŸæš—ç®—å•é¡Œã¡ã‚‡ã£ã¨ã—ãŸæ¨è¨ˆå€¤ã‚’æ‰‹è¨ˆç®—ã§ã™ã‚‹ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚è£œéºã®ä»¥ä¸‹ã®é …ç›®ãŒå½¹ã«ç«‹ã¤ã§ã—ã‚‡ã†:ãƒãƒ©è£è¨ˆç®—ã§ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã™ã‚‹2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã£ã¦ãŠãã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®å‚è€ƒå€¤æ–‡çŒ®ã¨ãã®ä»–ã®å‚è€ƒè³‡æ–™ä»¥ä¸‹ã®ãƒªãƒ³ã‚¯å…ˆãƒšãƒ¼ã‚¸ã‚’è¦‹ã¦ã©ã®ã‚ˆã†ãªè³ªå•ã‚’æŠ•ã’ã‹ã‘ã‚‰ã‚Œã‚‹ã‹æ¦‚è¦ã‚’é ­ã«å…¥ã‚Œã¦ãŠãã¾ã—ã‚‡ã†:ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§æˆåŠŸã™ã‚‹ã«ã¯ï¼Ÿã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã¸ã®å°å…¥ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ã¨ãã®è§£ç­”é »å‡ºã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨å‚è€ƒè§£ç­”ã€ã‚³ãƒ¼ãƒ‰åŠã³ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è§£ç­”ã¯ solutions/ ãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã‚‹å•é¡ŒPastebin.com (ã‚‚ã—ãã¯ Bit.ly) ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Twitterã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ (ã‚‚ã—ãã¯Facebookãƒ•ã‚£ãƒ¼ãƒ‰)ã‚’è¨­è¨ˆã™ã‚‹Twitteræ¤œç´¢(ã‚‚ã—ãã¯Facebookæ¤œç´¢)æ©Ÿèƒ½ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”ã‚¦ã‚§ãƒ–ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Mint.comã‚’è¨­è¨ˆã™ã‚‹è§£ç­”SNSã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Amazonã®ã‚«ãƒ†ã‚´ãƒªæ¯ã®å£²ã‚Šä¸Šã’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”AWSä¸Šã§100ä¸‡äººè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå•é¡Œã‚’è¿½åŠ ã™ã‚‹ContributePastebin.com (ã‚‚ã—ãã¯ Bit.ly) ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Twitterã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³&æ¤œç´¢ (ã‚‚ã—ãã¯Facebookãƒ•ã‚£ãƒ¼ãƒ‰&æ¤œç´¢)ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹ã‚¦ã‚§ãƒ–ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®è¨­è¨ˆå•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Mint.comã®è¨­è¨ˆå•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹SNSã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Amazonã®ã‚«ãƒ†ã‚´ãƒªæ¯ã®å£²ã‚Šä¸Šã’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹AWSä¸Šã§100ä¸‡äººè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆå•é¡Œã¨è§£ç­”é »å‡ºã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨å‚è€ƒè§£ç­”ã€ã‚³ãƒ¼ãƒ‰åŠã³ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è§£ç­”ã¯ solutions/ ãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã‚‹å‚™è€ƒ: ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ä½œæ¥­ä¸­ã§ã™å•é¡Œãƒãƒƒã‚·ãƒ¥ãƒãƒƒãƒ—ã®è¨­è¨ˆè§£ç­”LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¨­è¨ˆè§£ç­”ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼ã®è¨­è¨ˆè§£ç­”ã‚«ãƒ¼ãƒ‰ã®ãƒ‡ãƒƒã‚­ã®è¨­è¨ˆè§£ç­”é§è»Šå ´ã®è¨­è¨ˆè§£ç­”ãƒãƒ£ãƒƒãƒˆã‚µãƒ¼ãƒãƒ¼ã®è¨­è¨ˆè§£ç­”å††å½¢é…åˆ—ã®è¨­è¨ˆContributeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå•é¡Œã‚’è¿½åŠ ã™ã‚‹Contributeã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚¹: ã¾ãšã¯ã“ã“ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®å‹‰å¼·ã¯åˆã‚ã¦ï¼Ÿã¾ãšåˆã‚ã«ã€ã‚ˆãä½¿ã‚ã‚Œã‚‹è¨­è¨ˆåŸç†ã«ã¤ã„ã¦ã€ãã‚Œã‚‰ãŒä½•ã§ã‚ã‚‹ã‹ã€ã©ã®ã‚ˆã†ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã‹ã€é•·æ‰€çŸ­æ‰€ã«ã¤ã„ã¦åŸºæœ¬çš„ãªçŸ¥è­˜ã‚’å¾—ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‚¹ãƒ†ãƒƒãƒ— 1: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹å‹•ç”»ã‚’è¦³ã¦å¾©ç¿’ã™ã‚‹Harvardã§ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®è¬›ç¾©ã“ã“ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚¹:å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒƒãƒ— 2: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹è³‡æ–™ã‚’èª­ã‚“ã§å¾©ç¿’ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã“ã“ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚¹:ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥éåŒæœŸæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—æ¬¡ã«ã€ãƒã‚¤ãƒ¬ãƒ™ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦ã¿ã¦ã„ã:ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¯ç”¨æ€§ vs ä¸€è²«æ€§å…¨ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ã¨ã„ã†ã®ã‚’è‚ã«å‘½ã˜ã¦ãŠãã¾ã—ã‚‡ã†ã€‚ãã‚Œã‹ã‚‰ã€ã‚ˆã‚Šæ·±ã„å†…å®¹ã€DNSã‚„CDNãã—ã¦ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãªã©ã«ã¤ã„ã¦å­¦ç¿’ã‚’é€²ã‚ã¦ã„ãã¾ã—ã‚‡ã†ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒªã‚½ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚Œã‚‹ã®ã«ã¤ã‚Œã¦ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãŒå‘ä¸Šã™ã‚‹å ´åˆãã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ« ã§ã‚ã‚‹ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚ä¸€èˆ¬çš„ã«ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã¨ã„ã†ã®ã¯ã™ãªã‚ã¡è¨ˆç®—å‡¦ç†ã‚’å¢—ã‚„ã™ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¢—ãˆãŸæ™‚ãªã©ã‚ˆã‚Šå¤§ããªå‡¦ç†ã‚’æŒã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚1ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹vsã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’ã¨ã‚‰ãˆã‚‹ä»–ã®è€ƒãˆæ–¹:ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ã§ã®å•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹æ™‚ã€ã‚ãªãŸã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä¸€äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦é…ã„ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ ã§ã®å•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹ã¨ãã€ä¸€äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã¯é€Ÿã„ã§ã™ãŒã€å¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚ã‚‹æ™‚ã«ã¯é…ããªã£ã¦ã—ã¾ã†ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«ã¤ã„ã¦ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€å¯ç”¨æ€§ã€å®‰å®šæ€§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ã¨ã¯ãªã«ãŒã—ã‹ã®å‹•ä½œã‚’è¡Œã†ã€ã‚‚ã—ãã¯çµæœã‚’ç®—å‡ºã™ã‚‹ã®ã«è¦ã™ã‚‹æ™‚é–“ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ ã¨ã¯ãã®ã‚ˆã†ãªå‹•ä½œã‚„çµæœç®—å‡ºãŒå˜ä½æ™‚é–“ã«è¡Œã‚ã‚Œã‚‹å›æ•°ä¸€èˆ¬çš„ã«ã€ æœ€å¤§é™ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ ã‚’ è¨±å®¹ç¯„å›²å†…ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ã§å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã®ãŒæ™®é€šã ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç†è§£ã™ã‚‹å¯ç”¨æ€§ vs ä¸€è²«æ€§CAP ç†è«–      Source: CAP theorem revisitedåˆ†æ•£å‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã¯ä¸‹ã®ä¸‰ã¤ã®ã†ã¡äºŒã¤ã¾ã§ã—ã‹åŒæ™‚ã«ä¿è¨¼ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€‚:ä¸€è²«æ€§ - å…¨ã¦ã®èª­ã¿è¾¼ã¿ã¯æœ€æ–°ã®æ›¸ãè¾¼ã¿ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã‚’å—ã‘å–ã‚‹å¯ç”¨æ€§ - å—ã‘å–ã‚‹æƒ…å ±ãŒæœ€æ–°ã®ã‚‚ã®ã ã¨ã„ã†ä¿è¨¼ã¯ãªã„ãŒã€å…¨ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¿…ãšå—ã‘å–ã‚‹åˆ†æ–­è€æ€§ - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œã«ã‚ˆã£ã¦é †ä¸åŒã®åˆ†æ–­ãŒèµ·ãã¦ã‚‚ã‚·ã‚¹ãƒ†ãƒ ãŒå‹•ä½œã‚’ç¶šã‘ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ä¿¡é ¼ã§ããªã„ã®ã§ã€åˆ†æ–­è€æ€§ã¯å¿…ãšä¿è¨¼ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ã¤ã¾ã‚Šã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã¯ã€ä¸€è²«æ€§ã‚’å–ã‚‹ã‹ã€å¯ç”¨æ€§ã‚’å–ã‚‹ã‹ã‚’è€ƒãˆãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚CP - ä¸€è²«æ€§ã¨åˆ†æ–­è€æ€§(consistency and partition tolerance)åˆ†æ–­ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¾…ã¡ç¶šã‘ã¦ã„ã‚‹ã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã«é™¥ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚CPã¯ã‚ãªãŸã®ã‚µãƒ¼ãƒ“ã‚¹ãŒã‚¢ãƒˆãƒŸãƒƒã‚¯ãªèª­ã¿æ›¸ãï¼ˆä¸å¯åˆ†æ“ä½œï¼‰ã‚’å¿…è¦ã¨ã™ã‚‹éš›ã«ã¯ã„ã„é¸æŠè‚¢ã§ã—ã‚‡ã†ã€‚AP - å¯ç”¨æ€§ã¨åˆ†æ–­è€æ€§(availability and partition tolerance)ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ãƒãƒ¼ãƒ‰ä¸Šã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã§æœ€æ–°ã®ã‚‚ã®ã‚’è¿”ã—ã¾ã™ã€‚ã¤ã¾ã‚Šã€æœ€æ–°ç‰ˆã®ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚åˆ†æ–­ãŒè§£æ¶ˆã•ã‚ŒãŸå¾Œã‚‚ã€æ›¸ãè¾¼ã¿ãŒåæ˜ ã•ã‚Œã‚‹ã®ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚çµæœæ•´åˆæ€§ã€€ã‚’æ±‚ã‚ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®éš›ã«ã¯APã‚’æ¡ç”¨ã™ã‚‹ã®ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã‚‚ã—ãã¯ã€å¤–éƒ¨ã‚¨ãƒ©ãƒ¼ã«é–¢ã‚ã‚‰ãšã‚·ã‚¹ãƒ†ãƒ ãŒç¨¼åƒã™ã‚‹å¿…è¦ãŒã‚ã‚‹éš›ã«ã‚‚åŒæ§˜ã§ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸CAP ç†è«–ã‚’æŒ¯ã‚Šè¿”ã‚‹å¹³æ˜“ãªè‹±èªã§ã®CAP ç†è«–ã®ã‚¤ãƒ³ãƒˆãƒ­CAP FAQä¸€è²«æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³åŒã˜ãƒ‡ãƒ¼ã‚¿ã®è¤‡è£½ãŒè¤‡æ•°ã‚ã‚‹çŠ¶æ…‹ã§ã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒä¸€è²«ã—ãŸãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚’å—ã‘å–ã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ã«ãã‚Œã‚‰ã‚’åŒæœŸã™ã‚Œã°ã„ã„ã®ã‹ã¨ã„ã†èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ CAP ç†è«– ã«ãŠã‘ã‚‹ä¸€è²«æ€§ã®å®šç¾©ã‚’æ€ã„å‡ºã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚å…¨ã¦ã®èª­ã¿å–ã‚Šã¯æœ€æ–°ã®æ›¸ãè¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã‚’å—ã‘å–ã‚‹ã¯ãšã§ã™ã€‚å¼±ã„ä¸€è²«æ€§æ›¸ãè¾¼ã¿å¾Œã®èª­ã¿å–ã‚Šã§ã¯ã€ãã®æœ€æ–°ã®æ›¸ãè¾¼ã¿ã‚’èª­ã‚ãŸã‚Šèª­ã‚ãªã‹ã£ãŸã‚Šã™ã‚‹ã€‚ãƒ™ã‚¹ãƒˆã‚¨ãƒ•ã‚©ãƒ¼ãƒˆå‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«åŸºã¥ãã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯memcachedãªã©ã®ã‚·ã‚¹ãƒ†ãƒ ã«è¦‹ã‚‰ã‚Œã¾ã™ã€‚å¼±ã„ä¸€è²«æ€§ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒå¿…è¦ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã€ä¾‹ãˆã°VoIPã€ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ«ãƒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚²ãƒ¼ãƒ ãªã©ã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ä¾‹ãˆã°ã€é›»è©±ã«å‡ºã¦ã„ã‚‹ã¨ãã«æ•°ç§’é–“éŸ³å£°ãŒå—ã‘å–ã‚Œãªããªã£ãŸã¨ã—ãŸã‚‰ã€ãã®å¾Œã«æ¥ç¶šãŒå›å¾©ã—ã¦ã‚‚ãã®æ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¦ã„ãŸé–“ã«è©±ã•ã‚Œã¦ã„ãŸã“ã¨ã¯èãå–ã‚Œãªã„ã¨ã„ã†ã‚ˆã†ãªæ„Ÿã˜ã§ã™ã€‚çµæœæ•´åˆæ€§æ›¸ãè¾¼ã¿ã®å¾Œã€èª­ã¿å–ã‚Šã¯æœ€çµ‚çš„ã«ã¯ãã®çµæœã‚’èª­ã¿å–ã‚‹ã“ã¨ãŒã§ãã‚‹(ãƒŸãƒªç§’ã»ã©é…ã‚Œã¦ã¨ã„ã†ã®ãŒä¸€èˆ¬çš„ã§ã™)ã€‚ãƒ‡ãƒ¼ã‚¿ã¯éåŒæœŸçš„ã«è¤‡è£½ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯DNSã‚„ãƒ¡ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãªã©ã«æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚çµæœæ•´åˆæ€§ã¯å¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚å¼·ã„ä¸€è²«æ€§æ›¸ãè¾¼ã¿ã®å¾Œã€èª­ã¿å–ã‚Šã¯ãã‚Œã‚’å¿…ãšèª­ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯åŒæœŸçš„ã«è¤‡è£½ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚„RDBMSãªã©ã§æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ‰±ã†ã‚µãƒ¼ãƒ“ã‚¹ã§ã¯å¼·ã„ä¸€è²«æ€§ãŒå¿…è¦ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼é–“ã§ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¯ç”¨æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³é«˜ã„å¯ç”¨æ€§ã‚’æ‹…ä¿ã™ã‚‹ã«ã¯ä¸»ã«æ¬¡ã®äºŒã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã™: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ ã¨ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã§ã™ã€‚ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã«ãŠã„ã¦ã¯ã€å‘¨æœŸä¿¡å·ã¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚‚ã—ãã¯ã‚¹ã‚¿ãƒ³ãƒã‚¤ä¸­ã®ãƒ‘ãƒƒã‚·ãƒ–ãªã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œã¾ã™ã€‚å‘¨æœŸä¿¡å·ãŒä¸­æ–­ã•ã‚ŒãŸæ™‚ã«ã¯ã€ãƒ‘ãƒƒã‚·ãƒ–ã ã£ãŸã‚µãƒ¼ãƒãƒ¼ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒ¼ãƒãƒ¼ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å¼•ãç¶™ã„ã§ã‚µãƒ¼ãƒ“ã‚¹ã‚’å†é–‹ã—ã¾ã™ã€‚èµ·å‹•ã¾ã§ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã¯ãƒ‘ãƒƒã‚·ãƒ–ã‚µãƒ¼ãƒãƒ¼ãŒã€Œãƒ›ãƒƒãƒˆã€ãªã‚¹ã‚¿ãƒ³ãƒã‚¤çŠ¶æ…‹ã«ã‚ã‚‹ã‹ã€ã€Œã‚³ãƒ¼ãƒ«ãƒ‰ã€ãªã‚¹ã‚¿ãƒ³ãƒã‚¤çŠ¶æ…‹ã«ã‚ã‚‹ã‹ã§å¤‰ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚µãƒ¼ãƒãƒ¼ã®ã¿ãŒãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ§‹æˆã§ã¯ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã“ã¨ã§è² è·ã‚’åˆ†æ•£ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒ‘ãƒ–ãƒªãƒƒã‚¯ãªã‚‚ã®ã®å ´åˆã€DNSã¯ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ã®ãƒ‘ãƒ–ãƒªãƒƒã‚¯IPã‚’çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚‚ã—ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªã‚‚ã®ãªå ´åˆã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ãŒä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã«ã¤ã„ã¦çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚çŸ­æ‰€: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã§ã¯ã‚ˆã‚Šå¤šãã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’è¦ã—ã€è¤‡é›‘ã•ãŒå¢—ã—ã¾ã™ã€‚æœ€æ–°ã®æ›¸ãè¾¼ã¿ãŒãƒ‘ãƒƒã‚·ãƒ–ã‚µãƒ¼ãƒãƒ¼ã«è¤‡è£½ã•ã‚Œã‚‹å‰ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãŒè½ã¡ã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿æ¬ æãŒèµ·ãã‚‹æ½œåœ¨å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–ã€€ã¨ã€€ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã¯ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã‚ˆã‚Šè©³ç´°ã«è§£èª¬ã•ã‚Œã¦ã„ã¾ã™:ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ       Source: DNS security presentationãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (DNS) ã¯ www.example.com ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚’IPã‚¢ãƒ‰ãƒ¬ã‚¹ã¸ã¨ç¿»è¨³ã—ã¾ã™ã€‚DNSã¯å°‘æ•°ã®ã‚ªãƒ¼ã‚½ãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ãŒä¸Šä½ã«ä½ç½®ã™ã‚‹éšå±¤çš„æ§‹é€ ã§ã™ã€‚ã‚ãªãŸã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚‚ã—ãã¯ISPã¯æ¤œç´¢ã‚’ã™ã‚‹éš›ã«ã©ã®DNSã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã‹ã¨ã„ã†æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚ä½ã„éšå±¤ã®DNSã‚µãƒ¼ãƒãƒ¼ã¯ãã®çµŒè·¯ãƒãƒƒãƒ—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚ãŸã ã€ã“ã®æƒ…å ±ã¯ä¼æ¬é…å»¶ã«ã‚ˆã£ã¦é™³è…åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚DNSã®çµæœã¯ã‚ãªãŸã®ãƒ–ãƒ©ã‚¦ã‚¶ã‚‚ã—ãã¯OSã«ä¸€å®šæœŸé–“ï¼ˆtime to live (TTL)ã«è¨­å®šã•ã‚ŒãŸæœŸé–“ï¼‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ã€‚NS record (name server) - ã‚ãªãŸã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®DNSã‚µãƒ¼ãƒãƒ¼ã‚’ç‰¹å®šã—ã¾ã™ã€‚MX record (mail exchange) - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚µãƒ¼ãƒãƒ¼ã‚’ç‰¹å®šã—ã¾ã™ã€‚A record (address) - IPã‚¢ãƒ‰ãƒ¬ã‚¹ã«åå‰ã‚’ã¤ã‘ã¾ã™ã€‚CNAME (canonical) - ä»–ã®åå‰ã‚‚ã—ãã¯ã€€CNAME (example.com ã‚’ www.example.com) ã‚‚ã—ãã¯ A recordã¸ã¨åå‰ã‚’æŒ‡ã—ç¤ºã™ã€‚CloudFlare ã‚„ Route 53 ãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒãƒãƒ¼ã‚¸ãƒ‰DNSã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã„ãã¤ã‹ã®DNSã‚µãƒ¼ãƒ“ã‚¹ã§ã¯æ§˜ã€…ãªæ‰‹æ³•ã‚’ä½¿ã£ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã“ã¨ãŒã§ãã¾ã™:åŠ é‡ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã®ã‚µãƒ¼ãƒãƒ¼ã«è¡Œãã®ã‚’é˜²ãã¾ã™æ§˜ã€…ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´ã—ã¾ã™A/B ãƒ†ã‚¹ãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãƒ™ãƒ¼ã‚¹åœ°ç†ãƒ™ãƒ¼ã‚¹æ¬ ç‚¹: DNSä¸Šè¨˜ã§ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã«ã‚ˆã£ã¦ç·©å’Œã•ã‚Œã¦ã„ã‚‹ã¨ã¯ã„ãˆã€DNSã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã«ã¯å°‘ã—é…å»¶ãŒç”Ÿã˜ã‚‹ã€‚DNSã‚µãƒ¼ãƒãƒ¼ã¯ã€æ”¿åºœã€ISPä¼æ¥­,ãã—ã¦å¤§ä¼æ¥­ã«ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãŒã€ãã‚Œã‚‰ã®ç®¡ç†ã¯è¤‡é›‘ã§ã‚ã‚‹ã€‚DNSã‚µãƒ¼ãƒ“ã‚¹ã¯DDoS attackã®ä¾‹ã§ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ãªã—ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒTwitterãªã©ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªããªã£ãŸã‚ˆã†ã«ã€æ”»æ’ƒã‚’å—ã‘ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸DNS ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£WikipediaDNS è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(Content delivery network)      Source: Why use a CDNã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CDN)ã¯ä¸–ç•Œä¸­ã«é…ç½®ã•ã‚ŒãŸãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¸€ç•ªåœ°ç†çš„ã«è¿‘ã„ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é…ä¿¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®ã“ã¨ã§ã™ã€‚Amazonã®CloudFrontãªã©ã¯ä¾‹å¤–çš„ã«ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚é…ä¿¡ã—ã¾ã™ãŒã€ä¸€èˆ¬çš„ã«ã€HTML/CSS/JSã€å†™çœŸã€ãã—ã¦å‹•ç”»ãªã©ã®é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãŒCDNã‚’é€šã˜ã¦é…ä¿¡ã•ã‚Œã¾ã™ã€‚ãã®ã‚µã‚¤ãƒˆã®DNSãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã©ã®ã‚µãƒ¼ãƒãƒ¼ã¨äº¤ä¿¡ã™ã‚‹ã‹ã¨ã„ã†æƒ…å ±ã‚’ä¼ãˆã¾ã™ã€‚CDNã‚’ç”¨ã„ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é…ä¿¡ã™ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®äºŒã¤ã®ç†ç”±ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒåŠ‡çš„ã«å‘ä¸Šã—ã¾ã™:ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è¿‘ãã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰å—ä¿¡ã§ãã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã¯CDNãŒå‡¦ç†ã—ã¦ãã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«é–¢ã—ã¦ã¯å‡¦ç†ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ãƒ—ãƒƒã‚·ãƒ¥CDNãƒ—ãƒƒã‚·ãƒ¥CDNã§ã¯ã‚µãƒ¼ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ã«æ›´æ–°ãŒã‚ã£ãŸæ™‚ã«ã¯å¿…ãšã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å—ã‘å–ã‚‹æ–¹å¼ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”¨æ„ã—ã€CDNã«ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€URLã‚’CDNã‚’æŒ‡ã™ã‚ˆã†ã«æŒ‡å®šã™ã‚‹ã¨ã“ã‚ã¾ã§ã€å…¨ã¦è‡ªåˆ†ã§è²¬ä»»ã‚’è² ã†å½¢ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã„ã¤æœŸé™åˆ‡ã‚Œã«ãªã‚‹ã®ã‹æ›´æ–°ã•ã‚Œã‚‹ã®ã‹ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ–°è¦ä½œæˆæ™‚ã€æ›´æ–°æ™‚ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã“ã¨ã§ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã¯æœ€å°åŒ–ã•ã‚Œã‚‹ä¸€æ–¹ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¯æœ€å¤§é™æ¶ˆè²»ã•ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å°‘ãªã„ã€ã‚‚ã—ãã¯é »ç¹ã«ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ›´æ–°ã•ã‚Œãªã„ã‚µã‚¤ãƒˆã®å ´åˆã«ã¯ãƒ—ãƒƒã‚·ãƒ¥CDNã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å®šæœŸçš„ã«å†ã³ãƒ—ãƒ«ã•ã‚Œã‚‹ã®ã§ã¯ãªãã€CDNã«ä¸€åº¦ã®ã¿é…ç½®ã•ã‚Œã¾ã™ã€‚ãƒ—ãƒ«CDNãƒ—ãƒ«CDNã§ã¯ä¸€äººç›®ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãŸæ™‚ã«ã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å–å¾—ã—ã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯è‡ªåˆ†ã®ã‚µãƒ¼ãƒãƒ¼ã«ä¿å­˜ã—ã¦ã€CDNã‚’æŒ‡ã™URLã‚’æ›¸ãæ›ãˆã¾ã™ã€‚çµæœã¨ã—ã¦ã€CDNã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã¾ã§ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ãŒé…ããªã‚Šã¾ã™ã€‚time-to-live (TTL) ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã©ã‚Œã ã‘ã®æœŸé–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã‹ã‚’è¦å®šã—ã¾ã™ã€‚ãƒ—ãƒ«CDNã¯CDN ä¸Šã§ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¹ãƒšãƒ¼ã‚¹ã‚’æœ€å°åŒ–ã—ã¾ã™ãŒã€æœ‰åŠ¹æœŸé™ãŒåˆ‡ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›´æ–°å‰ã«ãƒ—ãƒ«ã•ã‚Œã¦ã—ã¾ã†ã“ã¨ã§å†—é•·ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«ç¹‹ãŒã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å¤§è¦æ¨¡ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ã‚ã‚‹ã‚µã‚¤ãƒˆã§ã¯ãƒ—ãƒ«CDNãŒç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã¨ã„ã†ã®ã‚‚ã€ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å¤§éƒ¨åˆ†ã¯æœ€è¿‘ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚Œã€CDNã«æ®‹ã£ã¦ã„ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã‹ã‚‰ã§ã™ã€‚æ¬ ç‚¹: CDNCDNã®ã‚³ã‚¹ãƒˆã¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯é‡ã«ã‚ˆã£ã¦å¤‰ã‚ã‚Šã¾ã™ã€‚ã‚‚ã¡ã‚ã‚“ã€CDNã‚’ä½¿ã‚ãªã„å ´åˆã®ã‚³ã‚¹ãƒˆã¨æ¯”è¼ƒã™ã‚‹ã¹ãã§ã—ã‚‡ã†ã€‚TTLãŒåˆ‡ã‚Œã‚‹å‰ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ›´æ–°ã•ã‚Œã‚‹ã¨é™³è…åŒ–ã™ã‚‹æã‚ŒãŒã‚ã‚Šã¾ã™ã€‚CDNã§ã¯é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒCDNã‚’æŒ‡ã™ã‚ˆã†ã«URLã‚’æ›´æ–°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«åˆ†æ•£ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ—ãƒƒã‚·ãƒ¥CDNã¨ãƒ—ãƒ«CDNã®é•ã„Wikipediaãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼      Source: Scalable system design patternsãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯å…¥åŠ›ã•ã‚Œã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã¨åˆ†æ•£ã•ã›ã‚‹ã€‚ã©ã®ã‚±ãƒ¼ã‚¹ã§ã‚‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ã‚µãƒ¼ãƒãƒ¼ç­‰è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é©åˆ‡ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è¿”ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ä»¥ä¸‹ã®ã“ã¨ã«åŠ¹æœçš„ã§ã™:ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒçŠ¶æ…‹ã®è‰¯ããªã„ã‚µãƒ¼ãƒãƒ¼ã«è¡Œãã®ã‚’é˜²ããƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’éå‰°ã«é€ã‚‹ã®ã‚’é˜²ãç‰¹å®šç®‡æ‰€ã®æ¬ é™¥ã§ã‚µãƒ¼ãƒ“ã‚¹ãŒè½ã¡ã‚‹ã“ã¨ã‚’é˜²ããƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ (è²»ç”¨ã®é«˜ã„) ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚‚ã—ãã¯HAProxyãªã©ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã§å®Ÿç¾ã§ãã‚‹ã€‚ä»–ã®åˆ©ç‚¹ã¨ã—ã¦ã¯:SSL termination - å…¥åŠ›ã•ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£èª­ã™ã‚‹ã€ã¾ãŸã€ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æš—å·åŒ–ã™ã‚‹ã“ã¨ã§ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã‚µãƒ¼ãƒãƒ¼ãŒã“ã®ã‚³ã‚¹ãƒˆãŒé«˜ãã¤ããŒã¡ãªå‡¦ç†ã‚’è«‹ã‘è² ã‚ãªãã¦ã„ã„ã‚ˆã†ã«è‚©ä»£ã‚ã‚Šã—ã¾ã™ã€‚X.509 certificates ã‚’ãã‚Œãã‚Œã®ã‚µãƒ¼ãƒãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ã‚’ãªãã—ã¾ã™ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† - ã‚¯ãƒƒã‚­ãƒ¼ã‚’å–ã‚Šæ‰±ã†ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªãŒã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ãªã„æ™‚ãªã©ã«ã€ç‰¹å®šã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åŒã˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¸ã¨æµã—ã¾ã™ã€‚éšœå®³ã«å¯¾å¿œã™ã‚‹ãŸã‚ã«ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ– ã‚‚ã—ãã¯ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ– ãƒ¢ãƒ¼ãƒ‰ã®ã©ã¡ã‚‰ã«ãŠã„ã¦ã‚‚ã€è¤‡æ•°ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’é…ç½®ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªç¨®ã€…ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç”¨ã„ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™:ãƒ©ãƒ³ãƒ€ãƒ Least loadedã‚»ãƒƒã‚·ãƒ§ãƒ³/ã‚¯ãƒƒã‚­ãƒ¼ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ã‚‚ã—ãã¯åŠ é‡ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³Layer 4Layer 7Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ ã‚’å‚ç…§ã—ã¦ã©ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é…åˆ†ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ã—ã¦ã¯ã€ã‚½ãƒ¼ã‚¹ã€é€ä¿¡å…ˆIPã‚¢ãƒ‰ãƒ¬ã‚¹ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã«è¨˜è¿°ã•ã‚ŒãŸãƒãƒ¼ãƒˆç•ªå·ãŒå«ã¾ã‚Œã¾ã™ãŒã€ãƒ‘ã‚±ãƒƒãƒˆã®ä¸­èº«ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å«ã¿ã¾ã›ã‚“ã€‚ Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‘ã‚±ãƒƒãƒˆã‚’ä¸Šæµã‚µãƒ¼ãƒãƒ¼ã¸å±Šã‘ã€ä¸Šæµã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰é…ä¿¡ã™ã‚‹ã“ã¨ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ‰ãƒ¬ã‚¹å¤‰æ› Network Address Translation (NAT) ã‚’å®Ÿç¾ã—ã¾ã™ã€‚Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ ã‚’å‚ç…§ã—ã¦ã©ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é…åˆ†ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ã‚¯ãƒƒã‚­ãƒ¼ãªã©ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã“ã¨ã§ã™ã€‚Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®çµ‚ç«¯ã‚’å—ã‘æŒã¡ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã®åˆ¤æ–­ã‚’ã—ã€é¸æŠã—ãŸã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šã‚’ç¹‹ãã¾ã™ã€‚ä¾‹ãˆã° layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯å‹•ç”»ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ç›´æ¥ã€ãã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ›ã‚¹ãƒˆã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒãƒ¼ã«ã¤ãªãã¨åŒæ™‚ã«ã€æ±ºæ¸ˆå‡¦ç†ãªã©ã®ã‚ˆã‚Šç¹Šç´°ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ã«æµã™ã¨ã„ã†ã“ã¨ã‚‚ã§ãã‚‹ã€‚æŸ”è»Ÿæ€§ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãªã‚Šã¾ã™ãŒã€ layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ã¯Layer 7ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚ˆã‚Šã‚‚æ‰€è¦æ™‚é–“ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å°‘ãªãæ¸ˆã¾ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãŸã ã—ã€æ˜¨ä»Šã®æ±ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯æœ€å°é™ã®ã¿ã—ã‹ç™ºæ®ã§ããªã„ã§ã—ã‚‡ã†ã€‚æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ã¯æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å¯ç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ‰‹é ƒãªæ±ç”¨ãƒã‚·ãƒ³ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã•ã›ã‚‹æ–¹ãŒã€ä¸€ã¤ã®ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚ˆã‚Šé«˜ä¾¡ãªãƒã‚·ãƒ³ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ï¼ˆå‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã‚ˆã‚Šè²»ç”¨å¯¾åŠ¹æœã‚‚é«˜ããªã‚Šã€çµæœçš„ã«å¯ç”¨æ€§ã‚‚é«˜ããªã‚Šã¾ã™ã€‚ã¾ãŸã€æ±ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ‰±ãˆã‚‹äººæã‚’é›‡ã†æ–¹ãŒã€ç‰¹åŒ–å‹ã®å•†ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ‰±ãˆã‚‹äººæã‚’é›‡ã†ã‚ˆã‚Šã‚‚ç°¡å˜ã§ã—ã‚‡ã†ã€‚æ¬ ç‚¹: æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ°´å¹³çš„ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã„ãã¨ã€è¤‡é›‘ã•ãŒå¢—ã™ä¸Šã«ã€ã‚µãƒ¼ãƒãƒ¼ã®ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã«ãªã‚‹ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢é€£ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚„ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å†™çœŸãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã¯ã„ã‘ãªã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ä¸€å…ƒçš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (SQLã€ NoSQL)ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã«ã‚¹ãƒˆã‚¢ã•ã‚Œã‚‹ã‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ (Redisã€ Memcached)ã«æ®‹ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®ä¸‹æµã‚µãƒ¼ãƒãƒ¼ã¯ä¸Šæµã‚µãƒ¼ãƒãƒ¼ãŒã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã™ã‚‹ã«ã¤ã‚Œã¦ã‚ˆã‚Šå¤šãã®åŒæ™‚æ¥ç¶šã‚’ä¿ãŸãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚æ¬ ç‚¹: ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒªã‚½ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ãŸã‚Šã€è¨­å®šãŒé©åˆ‡ã§ãªã„å ´åˆã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å˜ä¸€éšœå®³ç‚¹ã‚’é™¤ã“ã†ã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’å°å…¥ã—ãŸçµæœã€è¤‡é›‘ã•ãŒå¢—ã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãŒä¸€ã¤ã ã‘ã ã¨ãã“ãŒå˜ä¸€éšœå®³ç‚¹ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚ä¸€æ–¹ã§ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’è¤‡æ•°ã«ã™ã‚‹ã¨ã€ã•ã‚‰ã«è¤‡é›‘ã•ãŒå¢—ã—ã¦ã—ã¾ã„ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸NGINX ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HAProxy ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¬ã‚¤ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£WikipediaLayer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ELB listener configãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·(webã‚µãƒ¼ãƒãƒ¼)      Source: Wikipedia  ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã¯å†…éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã¾ã¨ã‚ã¦å¤–éƒ¨ã«çµ±ä¸€ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãã‚Œã«å¯¾å¿œã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œã¦ã€ãã®å¾Œãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è¿”ã—ã¾ã™ã€‚ä»–ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªåˆ©ç‚¹ãŒã‚ã‚Šã¾ã™:ã‚ˆã‚Šå …ç‰¢ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã‚’éš ã—ãŸã‚Šã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆåŒ–ã—ãŸã‚Šã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã”ã¨ã®æ¥ç¶šæ•°ã‚’åˆ¶é™ã—ãŸã‚Šã§ãã¾ã™ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚„æŸ”è»Ÿæ€§ãŒå¢—ã—ã¾ã™ - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã®IPã—ã‹è¦‹ãªã„ã®ã§ã€è£ã§ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã—ãŸã‚Šã€è¨­å®šã‚’å¤‰ãˆã‚„ã™ããªã‚Šã¾ã™ã€‚SSL termination - å…¥åŠ›ã•ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£èª­ã—ã€ã‚µãƒ¼ãƒãƒ¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æš—å·åŒ–ã™ã‚‹ã“ã¨ã§ã‚µãƒ¼ãƒãƒ¼ãŒã“ã®ã‚³ã‚¹ãƒˆã®ã‹ã‹ã‚Šã†ã‚‹å‡¦ç†ã‚’ã—ãªãã¦æ¸ˆã‚€ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚X.509 è¨¼æ˜æ›¸ ã‚’å„ã‚µãƒ¼ãƒãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚åœ§ç¸® - ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åœ§ç¸®ã§ãã¾ã™ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚° - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã—ã¾ã™é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ - é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥é€ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚HTML/CSS/JSå†™çœŸå‹•ç”»ãªã©ãªã©ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ vs ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·è¤‡æ•°ã®ã‚µãƒ¼ãƒãƒ¼ãŒã‚ã‚‹æ™‚ã«ã¯ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨å½¹ã«ç«‹ã¤ã§ã—ã‚‡ã†ã€‚ ã—ã°ã—ã°ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯åŒã˜æ©Ÿèƒ½ã‚’æœãŸã™ã‚µãƒ¼ãƒãƒ¼ç¾¤ã¸ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã¾ã™ã€‚ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã§ã¯ã€ä¸Šè¨˜ã«è¿°ã¹ãŸã‚ˆã†ãªåˆ©ç‚¹ã‚’ã€å˜ä¸€ã®ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã‚„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å¯¾ã—ã¦ã‚‚ç¤ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚NGINX ã‚„ HAProxy ãªã©ã®æŠ€è¡“ã¯layer 7 ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚æ¬ ç‚¹: ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’å°å…¥ã™ã‚‹ã¨ã‚·ã‚¹ãƒ†ãƒ ã®è¤‡é›‘æ€§ãŒå¢—ã—ã¾ã™ã€‚å˜ä¸€ã®ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã¯å˜ä¸€éšœå®³ç‚¹ã«ãªã‚Šãˆã¾ã™ã€‚ä¸€æ–¹ã§ã€è¤‡æ•°ã®ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’å°å…¥ã™ã‚‹ã¨(ä¾‹: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼) è¤‡é›‘æ€§ã¯ã‚ˆã‚Šå¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· vs ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼NGINX ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HAProxy ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ã‚¬ã‚¤ãƒ‰Wikipediaã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤      Source: Intro to architecting systems for scaleã‚¦ã‚§ãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ (ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å±¤ã¨ã‚‚è¨€ã‚ã‚Œã‚‹) ã¨åˆ†é›¢ã™ã‚‹ã“ã¨ã§ãã‚Œãã‚Œã®å±¤ã‚’ç‹¬ç«‹ã«ã‚¹ã‚±ãƒ¼ãƒ«ã€è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚æ–°ã—ã„APIã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã«è¿½åŠ ã™ã‚‹éš›ã«ã€ä¸å¿…è¦ã«ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚å˜ä¸€è²¬ä»»ã®åŸå‰‡ ã§ã¯ã€å°ã•ã„è‡ªå¾‹çš„ãªã‚µãƒ¼ãƒ“ã‚¹ãŒå”èª¿ã—ã¦å‹•ãã‚ˆã†ã«æå”±ã—ã¦ã„ã¾ã™ã€‚å°ã•ã„ã‚µãƒ¼ãƒ“ã‚¹ã®å°ã•ã„ãƒãƒ¼ãƒ ãŒæ€¥æˆé•·ã®ãŸã‚ã«ã‚ˆã‚Šç©æ¥µçš„ãªè¨ˆç”»ã‚’ç«‹ã¦ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã¯éåŒæœŸå‡¦ç†ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ç‹¬ç«‹ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹ã€å°è¦æ¨¡ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§˜å¼ã§ã‚ã‚‹ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚‚ã“ã®è­°è«–ã«é–¢ä¿‚ã—ã¦ãã‚‹æŠ€è¡“ã§ã—ã‚‡ã†ã€‚ãã‚Œãã‚Œã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ç‹¬è‡ªã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å‡¦ç†ã—ã€æ˜ç¢ºã§è»½é‡ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§é€šä¿¡ã—ã¦ã€ãã®ç›®çš„ã¨ã™ã‚‹æ©Ÿèƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚1ä¾‹ãˆã°Pinterestã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã€ãƒ•ã‚£ãƒ¼ãƒ‰ã€æ¤œç´¢ã€å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãªã©ã§ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼Consulã€ Etcdã€ Zookeeper ãªã©ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®åå‰ã€ã‚¢ãƒ‰ãƒ¬ã‚¹ã€ãƒãƒ¼ãƒˆã®æƒ…å ±ã‚’ç›£è¦–ã™ã‚‹ã“ã¨ã§ã€ã‚µãƒ¼ãƒ“ã‚¹åŒå£«ãŒäº’ã„ã‚’è¦‹ã¤ã‘ã‚„ã™ãã—ã¦ã„ã¾ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ã®å®Œå…¨æ€§ã®ç¢ºèªã«ã¯ Health checks ãŒä¾¿åˆ©ã§ã€ã“ã‚Œã«ã¯ HTTP ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚ Consul ã¨ Etcd ã®ã„ãšã‚Œã‚‚çµ„ã¿è¾¼ã¿ã® key-value store ã‚’æŒã£ã¦ãŠã‚Šã€è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚„å…±æœ‰ãƒ‡ãƒ¼ã‚¿ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¦ãŠãã“ã¨ã«ä½¿ã‚ã‚Œã¾ã™ã€‚æ¬ ç‚¹: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€é‹ç”¨ã€ãã—ã¦ãƒ—ãƒ­ã‚»ã‚¹ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ç·©ãçµã³ä»˜ã‘ã‚‰ã‚ŒãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‚’è¿½åŠ ã™ã‚‹ã«ã¯ã€ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒ‡ãƒ—ãƒ­ã‚¤ã¨é‹ç”¨ã®ç‚¹ã‹ã‚‰è¦‹ã‚‹ã¨è¤‡é›‘æ€§ãŒå¢—ã™ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒˆãƒ­ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’ç´è§£ãã‚µãƒ¼ãƒ“ã‚¹æŒ‡å‘ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Zookeeperã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½œã‚‹ãŸã‚ã«çŸ¥ã£ã¦ãŠããŸã„ã“ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹      Source: Scaling up to your first 10 million usersãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (RDBMS)SQLãªã©ã®ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ•´ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®é›†åˆã§ã‚ã‚‹ã€‚ACID ã¯ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãŠã‘ã‚‹ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®é›†åˆã§ã‚ã‚‹ä¸å¯åˆ†æ€§ - ãã‚Œãã‚Œã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ã‚‹ã‹ãªã„ã‹ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹ä¸€è²«æ€§ - ã©ã‚“ãªãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚ã‚‹ç¢ºã‹ãªçŠ¶æ…‹ã‹ã‚‰æ¬¡ã®çŠ¶æ…‹ã«é·ç§»ã•ã›ã‚‹ã€‚ç‹¬ç«‹æ€§ - åŒæ™‚ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ã¯ã€é€£ç¶šçš„ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã®ã¨åŒã˜çµæœã‚’ã‚‚ãŸã‚‰ã™ã€‚æ°¸ç¶šæ€§ - ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãŒå‡¦ç†ã•ã‚ŒãŸã‚‰ã€ãã®ã‚ˆã†ã«ä¿å­˜ã•ã‚Œã‚‹ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ãŸã‚ã«ã¯ãŸãã•ã‚“ã®æŠ€è¡“ãŒã‚ã‚‹: ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ federationã€ ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ éæ­£è¦åŒ–ã€ ãã—ã¦ SQL ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒèª­ã¿å–ã‚Šã¨æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã—ã€æ›¸ãè¾¼ã¿ã‚’ä¸€ã¤ä»¥ä¸Šã®ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¤‡è£½ã—ã¾ã™ã€‚ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯èª­ã¿å–ã‚Šã®ã¿ã‚’å‡¦ç†ã—ã¾ã™ã€‚ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æœ¨æ§‹é€ ã®ã‚ˆã†ã«è¿½åŠ ã®ã‚¹ãƒ¬ãƒ¼ãƒ–ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã«ãªã£ãŸå ´åˆã«ã¯ã€ã„ãšã‚Œã‹ã®ã‚¹ãƒ¬ãƒ¼ãƒ–ãŒãƒã‚¹ã‚¿ãƒ¼ã«æ˜‡æ ¼ã™ã‚‹ã‹ã€æ–°ã—ã„ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚Œã‚‹ã¾ã§ã¯èª­ã¿å–ã‚Šå°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ã§ç¨¼åƒã—ã¾ã™ã€‚      Source: Scalability, availability, stability, patternsæ¬ ç‚¹: ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ãƒ¬ãƒ¼ãƒ–ã‚’ãƒã‚¹ã‚¿ãƒ¼ã«æ˜‡æ ¼ã•ã›ã‚‹ã«ã¯è¿½åŠ ã®ãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…è¦ã«ãªã‚‹ã€‚ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® ä¸¡æ–¹ ã®æ¬ ç‚¹ã¯æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã„ãšã‚Œã®ãƒã‚¹ã‚¿ãƒ¼ã‚‚èª­ã¿å–ã‚Šæ›¸ãè¾¼ã¿ã®ä¸¡æ–¹ã«å¯¾å¿œã™ã‚‹ã€‚æ›¸ãè¾¼ã¿ã«é–¢ã—ã¦ã¯ãã‚Œãã‚Œå”èª¿ã™ã‚‹ã€‚ã„ãšã‚Œã‹ã®ãƒã‚¹ã‚¿ãƒ¼ãŒè½ã¡ã¦ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¨ã—ã¦ã¯èª­ã¿æ›¸ãä¸¡æ–¹ã«å¯¾å¿œã—ãŸã¾ã¾é‹ç”¨ã§ãã‚‹ã€‚      Source: Scalability, availability, stability, patternsæ¬ ç‚¹: ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’å°å…¥ã™ã‚‹ã‹ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã©ã“ã«æ›¸ãè¾¼ã‚€ã‹ã‚’æŒ‡å®šã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚å¤§ä½“ã®ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä¸€è²«æ€§ãŒç·©ã„ï¼ˆACIDåŸç†ã‚’å®ˆã£ã¦ã„ãªã„ï¼‰ã‚‚ã—ãã¯ã€åŒæœŸã™ã‚‹æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã«æ›¸ãè¾¼ã¿ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã€‚æ›¸ãè¾¼ã¿ãƒãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚Œã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œæ›¸ãè¾¼ã¿ã®è¡çªã®å¯èƒ½æ€§ãŒå¢—ãˆã‚‹ã€‚ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® ä¸¡æ–¹ ã®æ¬ ç‚¹ã¯æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã‚’å‚ç…§æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚’è¤‡è£½ã™ã‚‹å‰ã«ãƒã‚¹ã‚¿ãƒ¼ãŒè½ã¡ãŸå ´åˆã«ã¯ãã®ãƒ‡ãƒ¼ã‚¿ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æ›¸ãè¾¼ã¿ã¯èª­ã¿å–ã‚Šãƒ¬ãƒ—ãƒªã‚«ã«ãŠã„ã¦ãƒªãƒ—ãƒ¬ã‚¤ã•ã‚Œã‚‹ã€‚æ›¸ãè¾¼ã¿ãŒå¤šã„å ´åˆã€è¤‡è£½ãƒãƒ¼ãƒ‰ãŒæ›¸ãè¾¼ã¿ã®å‡¦ç†ã®ã¿ã§è¡Œãè©°ã¾ã£ã¦ã€èª­ã¿å–ã‚Šã®å‡¦ç†ã‚’æº€è¶³ã«è¡Œãˆãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚èª­ã¿å–ã‚Šã‚¹ãƒ¬ãƒ¼ãƒ–ãƒãƒ¼ãƒ‰ã®æ•°ãŒå¤šã‘ã‚Œã°å¤šã„ã»ã©ã€è¤‡è£½ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„æ•°ã‚‚å¢—ãˆã€è¤‡è£½æ™‚é–“ãŒä¼¸ã³ã¦ã—ã¾ã„ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã£ã¦ã¯ã€ãƒã‚¹ã‚¿ãƒ¼ã¸ã®æ›¸ãè¾¼ã¿ã¯ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§ä¸¦åˆ—å‡¦ç†ã§ãã‚‹ä¸€æ–¹ã€ã‚¹ãƒ¬ãƒ¼ãƒ–ã¸ã®è¤‡è£½ã¯å˜ä¸€ã‚¹ãƒ¬ãƒƒãƒ‰ã§é€£ç¶šçš„ã«å‡¦ç†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€ å¯ç”¨æ€§ã€ ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒ«ãƒãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³Federation      Source: Scaling up to your first 10 million usersãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (ã‚‚ã—ãã¯æ©Ÿèƒ½åˆ†å‰²åŒ–ã¨ã‚‚è¨€ã†) ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ©Ÿèƒ½ã”ã¨ã«åˆ†å‰²ã™ã‚‹ã€‚ä¾‹ãˆã°ã€ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªå˜ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä»£ã‚ã‚Šã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã€ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ ã®ã‚ˆã†ã«ä¸‰ã¤ã«ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸€ã¤ã‚ãŸã‚Šã®æ›¸ãè¾¼ã¿ãƒ»èª­ã¿å–ã‚Šã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒæ¸›ã‚Šã€ãã®çµæœãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ©ã‚°ã‚‚çŸ­ããªã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå°ã•ããªã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã«åã¾ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒå¢—ãˆã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å±€æ‰€æ€§ãŒé«˜ã¾ã‚‹ãŸã‚ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã‚‚ä¸ŠãŒã‚Šã¾ã™ã€‚å˜ä¸€ã®ä¸­å¤®ãƒã‚¹ã‚¿ãƒ¼ã§æ›¸ãè¾¼ã¿ã‚’ç›´åˆ—åŒ–ã—ãŸã‚Šã—ãªã„ãŸã‚ã€ä¸¦åˆ—ã§æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚æ¬ ç‚¹: federationå¤§è¦æ¨¡ãªå‡¦ç†ã‚„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¦ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒã®å ´åˆã€ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯åŠ¹æœçš„ã¨ã¯è¨€ãˆãªã„ã§ã—ã‚‡ã†ã€‚ã©ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«èª­ã¿æ›¸ãã‚’ã™ã‚‹ã®ã‹ã‚’æŒ‡å®šã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ›´æ–°ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚server linkã§äºŒã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€£çµã™ã‚‹ã®ã¯ã‚ˆã‚Šè¤‡é›‘ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: federationScaling up to your first 10 million usersã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°      Source: Scalability, availability, stability, patternsã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãã‚Œãã‚ŒãŒãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ–ã‚»ãƒƒãƒˆæ–­ç‰‡ã®ã¿ã‚’æŒã¤ã‚ˆã†ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¾‹ã«ã¨ã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«ã¯ã‚ˆã‚Šå¤šãã®æ–­ç‰‡ãŒåŠ ãˆã‚‰ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚federationã®åˆ©ç‚¹ã«ä¼¼ã¦ã„ã¦ã€ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯èª­ã¿æ›¸ãã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æ¸›ã‚‰ã—ã€ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¸›ã‚‰ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã‚’å¢—ã‚„ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚‚æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™ã¨ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã‚¯ã‚¨ãƒªé€Ÿåº¦ãŒé€Ÿããªã‚Šã¾ã™ã€‚ãªã«ãŒã—ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡è£½ã™ã‚‹æ©Ÿèƒ½ãŒãªã‘ã‚Œã°ãƒ‡ãƒ¼ã‚¿ãƒ­ã‚¹ã«ã¤ãªãŒã‚Šã¾ã™ãŒã€ã‚‚ã—ã€ä¸€ã¤ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒè½ã¡ã¦ã‚‚ã€ä»–ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒå‹•ã„ã¦ã„ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜ãã€å˜ä¸€ã®ä¸­å¤®ãƒã‚¹ã‚¿ãƒ¼ãŒæ›¸ãè¾¼ã¿ã®å‡¦ç†ã‚’ã—ãªãã¦ã‚‚ã€ä¸¦åˆ—ã§æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ä¸€èˆ¬çš„ãªæ–¹æ³•ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ©ã‚¹ãƒˆãƒãƒ¼ãƒ ã‚¤ãƒ‹ã‚·ãƒ£ãƒ«ã§ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åœ°ç†çš„é…ç½®ã§ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ãªã©ã§ã™ã€‚æ¬ ç‚¹: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒ£ãƒ¼ãƒ‰ã«å¯¾å¿œã™ã‚‹ã‚ˆã†ã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚çµæœã¨ã—ã¦SQLã‚¯ã‚¨ãƒªãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ‰ã§ã¯ãƒ‡ãƒ¼ã‚¿é…åˆ†ãŒã„ã³ã¤ã«ãªã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€æ¨™æº–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é›†åˆã‚’æŒã¤ã‚·ãƒ£ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã€ãã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒä»–ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚ˆã‚Šã‚‚é‡ã„è² è·ã‚’è² ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒªãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã‚’ã™ã‚‹ã¨è¤‡é›‘æ€§ãŒã‚ˆã‚Šå¢—ã—ã¾ã™ã€‚consistent hashing ã«åŸºã¥ã„ãŸã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ã€é€šä¿¡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚è¤‡æ•°ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€£çµã™ã‚‹ã®ã¯ã‚ˆã‚Šè¤‡é›‘ã§ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒ£ãƒ¼ãƒ‰ã®ç™»å ´ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Consistent hashingéæ­£è¦åŒ–éæ­£è¦åŒ–ã§ã¯ã€æ›¸ãè¾¼ã¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã„ãã‚‰ã‹çŠ ç‰²ã«ã—ã¦èª­ã¿è¾¼ã¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚ˆã†ã¨ã—ã¾ã™ã€‚è¨ˆç®—çš„ã«é‡ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµåˆãªã©ã‚’ã›ãšã«ã€è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«å†—é•·ãªãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ãŒæ›¸ãè¾¼ã¾ã‚Œã‚‹ã®ã‚’è¨±å®¹ã—ã¾ã™ã€‚ã„ãã¤ã‹ã®RDBMSä¾‹ãˆã°ã€PostgreSQL ã‚„Oracleã¯ã“ã®å†—é•·ãªæƒ…å ±ã‚’å–ã‚Šæ‰±ã„ã€ä¸€è²«æ€§ã‚’ä¿ã¤ãŸã‚ã®materialized views ã¨ã„ã†æ©Ÿèƒ½ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ã‚„ ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã«ã‚ˆã£ã¦ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã«åˆ†é…ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’åˆä¸€ã•ã›ã‚‹ã“ã¨ã¯ã¨ã¦ã‚‚è¤‡é›‘ãªä½œæ¥­ã§ã™ã€‚éæ­£è¦åŒ–ã«ã‚ˆã£ã¦ãã®ã‚ˆã†ãªè¤‡é›‘ãªå‡¦ç†ã‚’ã—ãªãã¦æ¸ˆã‚€ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚å¤šãã®ã‚·ã‚¹ãƒ†ãƒ ã§ã€100å¯¾1ã‚ã‚‹ã„ã¯1000å¯¾1ãã‚‰ã„ã«ãªã‚‹ãã‚‰ã„èª­ã¿å–ã‚Šã®æ–¹ãŒã€æ›¸ãè¾¼ã¿ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚ˆã‚Šã‚‚å¤šã„ã“ã¨ã§ã—ã‚‡ã†ã€‚èª­ã¿è¾¼ã¿ã‚’è¡Œã†ãŸã‚ã«ã€è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¸ãƒ§ã‚¤ãƒ³å‡¦ç†ãŒå«ã¾ã‚Œã‚‹ã‚‚ã®ã¯è¨ˆç®—çš„ã«é«˜ä¾¡ã«ã¤ãã¾ã™ã—ã€ãƒ‡ã‚£ã‚¹ã‚¯ã®å‡¦ç†æ™‚é–“ã§è†¨å¤§ãªæ™‚é–“ã‚’è²»æ¶ˆã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ¬ ç‚¹: éæ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ãŒè¤‡è£½ã•ã‚Œã‚‹ã€‚å†—é•·ãªãƒ‡ãƒ¼ã‚¿ã®è¤‡è£½ãŒåŒæœŸã•ã‚Œã‚‹ã‚ˆã†ã«åˆ¶ç´„ãŒå­˜åœ¨ã—ã€ãã®ã“ã¨ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®è¨­è¨ˆãŒè¤‡é›‘åŒ–ã™ã‚‹ã€‚éæ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯éå¤§ãªæ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å ´åˆã€æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ãã‚Œã‚ˆã‚Šã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ãŠã„ã¦åŠ£ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: éæ­£è¦åŒ–DenormalizationSQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯åºƒç¯„ãªçŸ¥è­˜ã‚’å¿…è¦ã¨ã™ã‚‹åˆ†é‡ã§å¤šãã® æœ¬ ãŒæ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’æ˜ã‚‰ã‹ã«ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ä¸Šã§ã€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ã‚’å®šã‚ã€ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« ã™ã‚‹ã“ã¨ã¯ã¨ã¦ã‚‚é‡è¦ã§ã™ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - abãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€é«˜è² è·ã®çŠ¶æ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« - slow query log ãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çŠ¶æ³ã®ç¢ºèªã‚’ã—ã¾ã—ã‚‡ã†ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¨ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®ã‚ˆã†ãªåŠ¹ç‡åŒ–ã®é¸æŠè‚¢ã‚’ã¨ã‚‹ã“ã¨ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¹ã‚­ãƒ¼ãƒã‚’çµã‚‹MySQLã¯ã‚¢ã‚¯ã‚»ã‚¹é€Ÿåº¦å‘ä¸Šã®ãŸã‚ã€ãƒ‡ã‚£ã‚¹ã‚¯ä¸Šã®é€£ç¶šã—ãŸãƒ–ãƒ­ãƒƒã‚¯ã¸ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã—ã¦ã„ã¾ã™ã€‚é•·ã•ã®æ±ºã¾ã£ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å¯¾ã—ã¦ã¯ VARCHAR ã‚ˆã‚Šã‚‚ CHAR ã‚’ä½¿ã†ã‚ˆã†ã«ã—ã¾ã—ã‚‡ã†ã€‚CHAR ã®æ–¹ãŒåŠ¹ç‡çš„ã«é€Ÿããƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ ä¸€æ–¹ã€ VARCHAR ã§ã¯æ¬¡ã®ãƒ‡ãƒ¼ã‚¿ã«ç§»ã‚‹å‰ã«ãƒ‡ãƒ¼ã‚¿ã®æœ«å°¾ã‚’æ¤œçŸ¥ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ãŸã‚ã«é€Ÿåº¦ãŒçŠ ç‰²ã«ãªã‚Šã¾ã™ã€‚ãƒ–ãƒ­ã‚°ã®æŠ•ç¨¿ãªã©ã€å¤§ããªãƒ†ã‚­ã‚¹ãƒˆã«ã¯ TEXT ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚ TEXT ã§ã¯ãƒ–ãƒ¼ãƒªã‚¢ãƒ³å‹ã®æ¤œç´¢ã‚‚å¯èƒ½ã§ã™ã€‚ TEXT ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ã€ãƒ‡ã‚£ã‚¹ã‚¯ä¸Šã®å ´æ‰€ã¸ã®ãƒã‚¤ãƒ³ã‚¿ãƒ¼ãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚2ã®32ä¹—ã‚„40å„„ä»¥ä¸‹ã‚’è¶…ãˆãªã„ç¨‹åº¦ã®å¤§ããªæ•°ã«ã¯ INT ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚é€šè²¨ã«é–¢ã—ã¦ã¯å°æ•°ç‚¹è¡¨ç¤ºä¸Šã®ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã« DECIMAL ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚å¤§ããª BLOBS ã‚’ä¿å­˜ã™ã‚‹ã®ã¯é¿ã‘ã¾ã—ã‚‡ã†ã€‚ã©ã“ã‹ã‚‰ãã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–ã£ã¦ãã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã®æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚VARCHAR(255) ã¯8ãƒ“ãƒƒãƒˆã§æ•°ãˆã‚‰ã‚Œã‚‹æœ€å¤§ã®æ–‡å­—æ•°ã§ã™ã€‚ä¸€éƒ¨ã®DBMSã§ã¯ã€1ãƒã‚¤ãƒˆã®åˆ©ç”¨åŠ¹ç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«ã“ã®æ–‡å­—æ•°ãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚æ¤œç´¢æ€§èƒ½å‘ä¸Šã®ãŸã‚ ã€å¯èƒ½ã§ã‚ã‚Œã° NOT NULL åˆ¶ç´„ã‚’è¨­å®šã—ã¾ã—ã‚‡ã†ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åŠ¹æœçš„ã«ç”¨ã„ã‚‹ã‚¯ã‚¨ãƒª(SELECTã€ GROUP BYã€ ORDER BYã€ JOIN) ã®å¯¾è±¡ã¨ãªã‚‹åˆ—ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã†ã“ã¨ã§é€Ÿåº¦ã‚’å‘ä¸Šã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯é€šå¸¸ã€å¹³è¡¡æ¢ç´¢æœ¨ã§ã‚ã‚‹Bæœ¨ã®å½¢ã§è¡¨ã•ã‚Œã¾ã™ã€‚Bæœ¨ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ã¯å¸¸ã«ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸçŠ¶æ…‹ã«ãªã‚Šã¾ã™ã€‚ã¾ãŸæ¤œç´¢ã€é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ã€æŒ¿å…¥ã€å‰Šé™¤ã‚’å¯¾æ•°æ™‚é–“ã§è¡Œãˆã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é…ç½®ã™ã‚‹ã“ã¨ã¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªãƒ¼ã«æ®‹ã™ã“ã¨ã«ã¤ãªãŒã‚Šã‚ˆã‚Šå®¹é‡ã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°ã‚‚å¿…è¦ã«ãªã‚‹ãŸã‚æ›¸ãè¾¼ã¿ã‚‚é…ããªã‚Šã¾ã™ã€‚å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹éš›ã«ã¯ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ‡ã£ã¦ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å†ã³ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ“ãƒ«ãƒ‰ã—ãŸæ–¹ãŒé€Ÿã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚é«˜è² è·ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’é¿ã‘ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šå¿…è¦ãªã¨ã“ã‚ã«ã¯éæ­£è¦åŒ–ã‚’é©ç”¨ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆ†å‰²ã—ã€ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆã‚’ç‹¬ç«‹ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã«åˆ†é›¢ã—ã¦ãƒ¡ãƒ¢ãƒªãƒ¼ã«ä¹—ã›ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª¿æ•´ã™ã‚‹å ´åˆã«ã‚ˆã£ã¦ã¯ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°MySQLã‚¯ã‚¨ãƒªã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®TipsVARCHAR(255)ã‚’ã‚„ãŸã‚‰ã‚ˆãè¦‹ã‹ã‘ã‚‹ã®ã¯ãªã‚“ã§ï¼Ÿnullå€¤ã¯ã©ã®ã‚ˆã†ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã™ã‚‹ã®ã‹ï¼ŸSlow query logNoSQLNoSQL ã¯ key-value storeã€ document-storeã€ wide column storeã€ ã‚‚ã—ãã¯ graph databaseã«ã‚ˆã£ã¦è¡¨ç¾ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¤ãƒ†ãƒ ã®é›†åˆã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ä¸€èˆ¬çš„ã«æ­£è¦åŒ–ã•ã‚Œã¦ãŠã‚‰ãšã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã§ã‚¸ãƒ§ã‚¤ãƒ³ãŒè¡Œã‚ã‚Œã¾ã™ã€‚å¤§éƒ¨åˆ†ã®NoSQLã¯çœŸã®ACIDãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŒãŸãšã€ çµæœæ•´åˆæ€§ çš„ãªæŒ¯ã‚‹èˆã„ã®æ–¹ã‚’å¥½ã¿ã¾ã™ã€‚BASE ã¯ã—ã°ã—ã°NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚CAP Theorem ã¨å¯¾ç…§çš„ã«ã€BASEã¯ä¸€è²«æ€§ã‚ˆã‚Šã‚‚å¯ç”¨æ€§ã‚’å„ªå…ˆã—ã¾ã™ã€‚Basically available - ã‚·ã‚¹ãƒ†ãƒ ã¯å¯ç”¨æ€§ã‚’ä¿è¨¼ã—ã¾ã™ã€‚Soft state - ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã¯å…¥åŠ›ãŒãªãã¦ã‚‚æ™‚é–“çµŒéã¨ã¨ã‚‚ã«å¤‰åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚çµæœæ•´åˆæ€§ - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¯æ™‚é–“çµŒéã¨ã¨ã‚‚ã«ãã®é–“ã«å…¥åŠ›ãŒãªã„ã¨ã„ã†å‰æã®ã‚‚ã¨ã€ä¸€è²«æ€§ãŒé”æˆã•ã‚Œã¾ã™ã€‚SQLã‹ï¼ŸNoSQLã‹ï¼Ÿ ã‚’é¸æŠã™ã‚‹ã®ã«åŠ ãˆã¦ã€ã©ã®ã‚¿ã‚¤ãƒ—ã®NoSQLãŒã©ã®ä½¿ç”¨ä¾‹ã«æœ€ã‚‚é©ã™ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ã®ã¯ã¨ã¦ã‚‚æœ‰ç›Šã§ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã€ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã€ ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã€ ã¨ ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã«ã¤ã„ã¦è§¦ã‚Œã¦ã„ãã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢æ¦‚è¦: ãƒãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ä¸€èˆ¬çš„ã«O(1)ã®èª­ã¿æ›¸ããŒã§ãã€ãã‚Œã‚‰ã¯ãƒ¡ãƒ¢ãƒªãªã„ã—SSDã§è£ä»˜ã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¯ã‚­ãƒ¼ã‚’ è¾æ›¸çš„é †åº ã§ä¿æŒã™ã‚‹ã“ã¨ã§ã‚­ãƒ¼ã®åŠ¹ç‡çš„ãªå–å¾—ã‚’å¯èƒ½ã«ã—ã¦ã„ã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å€¤ã¨ã¨ã‚‚ã«ä¿æŒã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã¯ãƒã‚¤ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãªæŒ™å‹•ãŒå¯èƒ½ã§ã€å˜ç´”ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ãªã©ã®ãƒ‡ãƒ¼ã‚¿ãŒæ€¥é€Ÿã«å¤‰ã‚ã‚‹å ´åˆãªã©ã«ä½¿ã‚ã‚Œã¾ã™ã€‚å˜ç´”ãªå‡¦ç†ã®ã¿ã«æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€è¿½åŠ ã®å‡¦ç†æ©Ÿèƒ½ãŒå¿…è¦ãªå ´åˆã«ã¯ãã®è¤‡é›‘æ€§ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã«è¼‰ã›ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã¯ã‚‚ã£ã¨è¤‡é›‘ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã‚„ã€ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®åŸºæœ¬ã§ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã®æ¬ ç‚¹Redisã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢æ¦‚è¦: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãƒãƒªãƒ¥ãƒ¼ã¨ã—ã¦ä¿å­˜ã•ã‚ŒãŸã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«é–¢ã™ã‚‹å…¨ã¦ã®æƒ…å ±ã‚’æŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ(XMLã€ JSONã€ binaryãªã©)ã‚’ä¸­å¿ƒã«æ®ãˆãŸã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã§ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªèº«ã®å†…éƒ¨æ§‹é€ ã«åŸºã¥ã„ãŸã€APIã‚‚ã—ãã¯ã‚¯ã‚¨ãƒªè¨€èªã‚’æä¾›ã—ã¾ã™ã€‚ ãƒ¡ãƒ¢ï¼šå¤šãã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ã€å€¤ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†æ©Ÿèƒ½ã‚’å«ã‚“ã§ã„ã¾ã™ãŒã€ãã®ã“ã¨ã«ã‚ˆã£ã¦äºŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¨ã®å¢ƒç•Œç·šãŒæ›–æ˜§ã«ãªã£ã¦ã—ã¾ã£ã¦ã„ã¾ã™ã€‚ä»¥ä¸Šã®ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã€ã‚¿ã‚°ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã©ã¨ã—ã¦æ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒå£«ã¯ã¾ã¨ã‚ã¦ã‚°ãƒ«ãƒ¼ãƒ—ã«ã§ãã‚‹ã‚‚ã®ã®ã€ãã‚Œãã‚Œã§å…¨ãç•°ãªã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚MongoDB ã‚„ CouchDB ãªã©ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã‚‚ã€è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã®SQLã®ã‚ˆã†ãªè¨€èªã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚DynamoDB ã¯ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¯é«˜ã„æŸ”è»Ÿæ€§ã‚’æ‹…ä¿ã™ã‚‹ã®ã§ã€é »ç¹ã«å¤‰åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†æ™‚ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹MongoDB ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£CouchDB ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Elasticsearch ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢      Source: SQL & NoSQL, a brief historyæ¦‚è¦: ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒãƒƒãƒ— ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼<è¡Œã‚­ãƒ¼ã€ ã‚«ãƒ©ãƒ <ColKeyã€ Valueã€ Timestamp>>ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬å˜ä½ã¯ã‚«ãƒ©ãƒ ï¼ˆãƒãƒ¼ãƒ ãƒ»ãƒãƒªãƒ¥ãƒ¼ã®ãƒšã‚¢ï¼‰ã§ã™ã€‚ãã‚Œãã‚Œã®ã‚«ãƒ©ãƒ ã¯ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¨ã—ã¦ï¼ˆSQLãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚ˆã†ã«ï¼‰ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¯ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®é›†åˆã§ã™ã€‚ãã‚Œãã‚Œã®ã‚«ãƒ©ãƒ ã«ã¯è¡Œã‚­ãƒ¼ã§ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚åŒã˜è¡Œã‚­ãƒ¼ã‚’æŒã¤ã‚«ãƒ©ãƒ ã¯åŒã˜è¡Œã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã™ã€‚ãã‚Œãã‚Œã®å€¤ã¯ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãŒèµ·ããŸæ™‚ã®ãŸã‚ã«ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å«ã¿ã¾ã™ã€‚Googleã¯Bigtableã‚’åˆã®ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã¨ã—ã¦ç™ºè¡¨ã—ã¾ã—ãŸã€‚ãã‚ŒãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§Hadoopãªã©ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹HBase ã‚„Facebookã«ã‚ˆã‚‹Cassandra ãªã©ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å½±éŸ¿ã‚’ä¸ãˆã¾ã—ãŸã€‚BigTableã€HBaseã‚„Cassandraãªã©ã®ã‚¹ãƒˆã‚¢ã¯ã‚­ãƒ¼ã‚’è¾æ›¸å½¢å¼ã§ä¿æŒã™ã‚‹ã“ã¨ã§é¸æŠã—ãŸã‚­ãƒ¼ãƒ¬ãƒ³ã‚¸ã§ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’åŠ¹ç‡çš„ã«ã—ã¾ã™ã€‚ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã¯é«˜ã„å¯ç”¨æ€§ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’æ‹…ä¿ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã¨ã¦ã‚‚å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‰±ã†ã“ã¨ã«ã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢SQL & NoSQLç°¡å˜ã«æ­´å²ã‚’ã•ã‚‰ã†Bigtable ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HBase ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Cassandra ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹      Source: Graph databaseæ¦‚è¦: ã‚°ãƒ©ãƒ•ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã¯ã€ãã‚Œãã‚Œã®ãƒãƒ¼ãƒ‰ãŒãƒ¬ã‚³ãƒ¼ãƒ‰ã§ã€ãã‚Œãã‚Œã®ã‚¢ãƒ¼ã‚¯ã¯äºŒã¤ã®ãƒãƒ¼ãƒ‰ã‚’ç¹‹ãé–¢ä¿‚æ€§ã¨ã—ã¦å®šç¾©ã•ã‚Œã¾ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯å¤šæ•°ã®å¤–éƒ¨ã‚­ãƒ¼ã‚„å¤šå¯¾å¤šãªã©ã®è¤‡é›‘ãªé–¢ä¿‚æ€§ã‚’è¡¨ã™ã®ã«æœ€é©ã§ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯SNSãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹ã®è¤‡é›‘ãªé–¢ä¿‚æ€§ãƒ¢ãƒ‡ãƒ«ãªã©ã«ã¤ã„ã¦é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚æ¯”è¼ƒçš„æ–°ã—ãã€ã¾ã ä¸€èˆ¬çš„ã«ã¯ç”¨ã„ã‚‰ã‚Œã¦ã„ãªã„ã®ã§ã€é–‹ç™ºãƒ„ãƒ¼ãƒ«ã‚„ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¢ã™ã®ãŒä»–ã®æ–¹æ³•ã«æ¯”ã¹ã¦é›£ã—ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å¤šãã®ã‚°ãƒ©ãƒ•ã¯REST APIsã‚’é€šã˜ã¦ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ã‚°ãƒ©ãƒ•Graphãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹Neo4jFlockDBãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  NoSQLåŸºæœ¬ç”¨èªã®èª¬æ˜NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¤ã„ã¦èª¿æŸ»ã¨é¸æŠã‚¬ã‚¤ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£NoSQLã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³NoSQLãƒ‘ã‚¿ãƒ¼ãƒ³SQLã‹ï¼ŸNoSQLã‹ï¼Ÿ      Source: Transitioning from RDBMS to NoSQLSQL ã‚’é¸ã¶ç†ç”±:æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å³æ ¼ãªã‚¹ã‚­ãƒ¼ãƒãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿è¤‡é›‘ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’ã™ã‚‹å¿…è¦æ€§ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹éš›ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ˜ç¢ºãªã¨ãé–‹ç™ºè€…ã®æ•°ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã€ã‚³ãƒ¼ãƒ‰ç­‰ãŒã‚ˆã‚Šå……å®Ÿã—ã¦ã„ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã¯ã¨ã¦ã‚‚é€Ÿã„NoSQL ã‚’é¸ã¶ç†ç”±:æº–æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã„ã—ã€ãƒ•ãƒ¬ã‚­ã‚·ãƒ–ãƒ«ãªã‚¹ã‚­ãƒ¼ãƒãƒãƒ³ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãªãƒ‡ãƒ¼ã‚¿è¤‡é›‘ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’ã™ã‚‹å¿…è¦ãŒãªã„ãƒ‡ãƒ¼ã‚¿ã®å¤šãã®TB (ã‚‚ã—ãã¯ PB) ã‚’ä¿å­˜ã™ã‚‹é›†ä¸­çš„ã€å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿è² è·ã«è€ãˆã‚‰ã‚Œã‚‹IOPSã«ã¤ã„ã¦ã¯æ¥µã‚ã¦é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¤ºã™NoSQLã«é©ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:æ€¥æ¿€ãªã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚„ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã®åé›†ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã‚„ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚«ãƒ¼ãƒˆãªã©ã®ä¸€æ™‚çš„æƒ…å ±é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ ('ãƒ›ãƒƒãƒˆãª') ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ã€€SQLã‚‚ã—ãã¯NoSQLæœ€åˆã®1000ä¸‡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«SQLã¨NoSQLã®é•ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥      Source: Scalable system design patternsã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿æ™‚é–“ã‚’å‰Šæ¸›ã—ã€ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®è² è·ã‚’ä½æ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€å®Ÿéš›ã®å‡¦ç†ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«ã€ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒãƒ£ãƒ¼ãŒã¾ãšä»¥å‰ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒé€ä¿¡ã•ã‚ŒãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã€ç›´å‰ã®çµæœã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ãã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«æ¸¡ã£ã¦çµ±åˆã•ã‚ŒãŸèª­ã¿å–ã‚Šæ›¸ãè¾¼ã¿ã®åˆ†é…ã‚’è¦æ±‚ã—ã¾ã™ãŒã€äººæ°—ã‚¢ã‚¤ãƒ†ãƒ ã¯ãã®åˆ†é…ã‚’æ­ªã‚ã¦ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã£ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å·®ã—è¾¼ã‚€ã“ã¨ã§ã“ã®ã‚ˆã†ã«ã€å‡ä¸€ã§ãªã„è² è·ã‚„ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®æ€¥æ¿€ãªå¢—åŠ ã‚’å¸åã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯OSã‚„ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ãªã©ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã€ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ ã‚‚ã—ãã¯ç‹¬ç«‹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«è¨­ç½®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚CDNã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°CDN ã‚‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¸€ã¤ã¨ã—ã¦è€ƒãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Webã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· ã‚„ Varnish ãªã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯é™çš„ãã—ã¦å‹•çš„ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥é…ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ webã‚µãƒ¼ãƒãƒ¼ã‚‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã“ã¨ãªã—ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æ™®é€šã€ä¸€èˆ¬çš„ãªä½¿ç”¨çŠ¶æ³ã«é©ã™ã‚‹ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã®è¨­å®šã‚’åˆæœŸçŠ¶æ…‹ã§æŒã£ã¦ã„ã¾ã™ã€‚ã“ã®è¨­å®šã‚’ç‰¹å®šã®ä»•æ§˜ã«åˆã‚ã›ã¦èª¿æ•´ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã©ã®In-memoryã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„Redisã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®é–“ã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯RAMã§ä¿æŒã•ã‚Œã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ã‚£ã‚¹ã‚¯ã§ä¿å­˜ã•ã‚Œã‚‹ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚ˆã‚Šã‚‚ã ã„ã¶é€Ÿã„ã§ã™ã€‚RAMå®¹é‡ã¯ãƒ‡ã‚£ã‚¹ã‚¯ã‚ˆã‚Šã‚‚é™ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã€least recently used (LRU)ãªã©ã®cache invalidation ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒ 'ã‚³ãƒ¼ãƒ«ãƒ‰' ãªã‚¨ãƒ³ãƒˆãƒªã‚’å¼¾ãã€'ãƒ›ãƒƒãƒˆ' ãªãƒ‡ãƒ¼ã‚¿ã‚’RAMã«ä¿å­˜ã—ã¾ã™ã€‚Redisã¯ã•ã‚‰ã«ä»¥ä¸‹ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’å‚™ãˆã¦ã„ã¾ã™:ãƒ‘ãƒ¼ã‚¸ã‚¹ãƒ†ãƒ³ã‚¹è¨­å®šã‚½ãƒ¼ãƒˆæ¸ˆã¿ã‚»ãƒƒãƒˆã€ãƒªã‚¹ãƒˆãªã©ã®çµ„ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã¯æ§˜ã€…ãªãƒ¬ãƒ™ãƒ«ã®ã‚‚ã®ãŒã‚ã‚Šã¾ã™ãŒã€ã„ãšã‚Œã‚‚å¤§ããäºŒã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ã„ãšã‚Œã‹ã«åˆ†é¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª ã¨ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ ã§ã™:è¡Œãƒ¬ãƒ™ãƒ«ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«Fully-formed serializable objectsFully-rendered HTMLä¸€èˆ¬çš„ã«ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã¯ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’ä½œã‚Šå‡ºã—ã¦ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’é›£ã—ãã—ã¦ã—ã¾ã†ã®ã§é¿ã‘ã‚‹ã¹ãã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹éš›ã«ã¯å¿…ãšã‚¯ã‚¨ãƒªã‚’ã‚­ãƒ¼ã¨ã—ã¦ãƒãƒƒã‚·ãƒ¥ã—ã¦çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚ã“ã®æ‰‹æ³•ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœŸé™åˆ‡ã‚Œå•é¡Œã«æ‚©ã‚€ã“ã¨ã«ãªã‚Šã¾ã™:è¤‡é›‘ãªã‚¯ã‚¨ãƒªã«ã‚ˆã‚Šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçµæœã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ãŒå›°é›£ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ãƒ«ãªã©ã®ãƒ‡ãƒ¼ã‚¿æ–­ç‰‡ãŒå¤‰åŒ–ã—ãŸæ™‚ã«ã€ãã®å¤‰åŒ–ã—ãŸã‚»ãƒ«ã‚’å«ã‚€ã‹ã‚‚ã—ã‚Œãªã„å…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’å‰Šé™¤ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã†ã™ã‚‹ã‚ˆã†ã«ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰ãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨ã—ã¦çµ„ã¿ç«‹ã¦ã•ã›ã¾ã™ã€‚:ãã®ãƒ‡ãƒ¼ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‰Šé™¤ã™ã‚‹ã“ã¨éåŒæœŸå‡¦ç†ã‚’è¨±å®¹ã—ã¾ã™: ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸­ã§æœ€æ–°ã®ã‚‚ã®ã‚’é›†ã‚ã¦ãã¾ã™ä½•ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã‹:ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œå…¨ã«ãƒ¬ãƒ³ãƒ€ãƒ¼ã•ã‚ŒãŸã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‚¢ã‚¯ãƒ†ãƒ“ãƒ†ã‚£ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã§ãã‚‹å®¹é‡ã¯é™ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€è‡ªåˆ†ã®ã‚±ãƒ¼ã‚¹ã§ã¯ã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‰‹æ³•ãŒä¸€ç•ªã„ã„ã‹ã¯æ¤œè¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰      Source: From cache to in-memory data gridã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¸ã®èª­ã¿æ›¸ãã®å‡¦ç†ã‚’ã—ã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ã¯ç›´æ¥ã‚„ã‚Šã¨ã‚Šã‚’ã—ã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ã“ã¨ã‚’ã—ã¾ã™:ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¸­ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å‚ç…§ã—ã¾ã™ãŒã€çµæœã¨ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã«ãªã‚Šã¾ã™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—ã—ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ ã—ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã—ã¾ã™def get_user(self, user_id):    user = cache.get(\""user.{0}\"", user_id)    if user is None:        user = db.query(\""SELECT * FROM users WHERE user_id = {0}\"", user_id)        if user is not None:            key = \""user.{0}\"".format(user_id)            cache.set(key, json.dumps(user))    return userMemcached ã¯é€šå¸¸ã“ã®ã‚ˆã†ã«ä½¿ã‚ã‚Œã‚‹ã€‚ãã®å¾Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¯é€Ÿã„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã¯ãƒ¬ãƒ¼ã‚¸ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚ã‚‹ã¨ã‚‚è¨€ã‚ã‚Œã¾ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã¿ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæº¢ã‚Œã‚‹ã®ã‚’é˜²æ­¢ã—ã¾ã™ã€‚æ¬ ç‚¹: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰å„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã¯ä¸‰ã¤ã®ãƒˆãƒªãƒƒãƒ—ã‚’å‘¼ã³å‡ºã™ã“ã¨ã«ãªã‚Šã€ä½“æ„Ÿã§ãã‚‹ã»ã©ã®é…å»¶ãŒèµ·ãã¦ã—ã¾ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ãŒæ›´æ–°ã•ã‚Œã‚‹ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã¯å¤ã„ã‚‚ã®ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚time-to-live (TTL)ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã®æ›´æ–°ã‚’å¼·åˆ¶çš„ã«è¡Œã†ã€ã‚‚ã—ãã¯ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã¯ç·©å’Œã§ãã¾ã™ã€‚ãƒãƒ¼ãƒ‰ãŒè½ã¡ã‚‹ã¨ã€æ–°è¦ã®ç©ºã®ãƒãƒ¼ãƒ‰ã§ä»£æ›¿ã•ã‚Œã‚‹ã“ã¨ã§ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼      Source: Scalability, availability, stability, patternsã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¨ã—ã¦ä½¿ã„ã€ãã“ã«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿æ›¸ãã‚’è¡Œã„ã¾ã™ã€‚ä¸€æ–¹ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®èª­ã¿æ›¸ãã‚’æ‹…å½“ã—ã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚‹ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã™ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯åŒæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã«æ›¸ãè¾¼ã¿ã‚’è¡Œã„ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã—ã¾ã™ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰:set_user(12345, {\""foo\"":\""bar\""})ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚³ãƒ¼ãƒ‰:def set_user(user_id, values):    user = db.query(\""UPDATE Users WHERE id = {0}\"", user_id, values)    cache.set(user_id, user)ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã¯æ›¸ãè¾¼ã¿å‡¦ç†ã®ã›ã„ã§å…¨ä½“ã¨ã—ã¦ã¯é…ã„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ãŒã€æ›¸ãè¾¼ã¾ã‚ŒãŸã°ã‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹èª­ã¿è¾¼ã¿ã¯é€Ÿã„ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã¯ä¸€èˆ¬çš„ã«ãƒ‡ãƒ¼ã‚¿æ›´æ–°æ™‚ã®æ–¹ãŒèª­ã¿è¾¼ã¿æ™‚ã‚ˆã‚Šã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã«è¨±å®¹çš„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã¯æœ€æ–°ç‰ˆã§ä¿ãŸã‚Œã¾ã™ã€‚æ¬ ç‚¹: ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ãƒãƒ¼ãƒ‰ãŒè½ã¡ãŸã“ã¨ã€ã‚‚ã—ãã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦æ–°ã—ã„ãƒãƒ¼ãƒ‰ãŒä½œæˆã•ã‚ŒãŸæ™‚ã«ã€æ–°ã—ã„ãƒãƒ¼ãƒ‰ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒæ›´æ–°ã•ã‚Œã‚‹ã¾ã§ã¯ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã›ã‚“ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã¨ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚’ä½µç”¨ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã‚’ç·©å’Œã§ãã¾ã™ã€‚æ›¸ãè¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã¯ä¸€åº¦ã‚‚èª­ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯TTLã«ã‚ˆã£ã¦åœ§ç¸®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ (ãƒ©ã‚¤ãƒˆãƒãƒƒã‚¯)      Source: Scalability, availability, stability, patternsãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ã§ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ã“ã¨ã‚’ã—ã¾ã™:ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã™ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¸ã®æ›¸ãè¾¼ã¿ã‚’éåŒæœŸçš„ã«è¡Œã†ã“ã¨ã§ã€æ›¸ãè¾¼ã¿ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚æ¬ ç‚¹: ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢å†…ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ãƒ’ãƒƒãƒˆã™ã‚‹å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè½ã¡ã‚‹ã¨ãƒ‡ãƒ¼ã‚¿æ¬ æãŒèµ·ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã‚„ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚ˆã‚Šã‚‚å®Ÿè£…ãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰      Source: From cache to in-memory data gridæœŸé™åˆ‡ã‚Œã‚ˆã‚Šã‚‚å‰ã«ã€ç›´è¿‘ã§ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸå…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’è‡ªå‹•çš„ã«æ›´æ–°ã™ã‚‹ã‚ˆã†ã«è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚‚ã—ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå°†æ¥å¿…è¦ã«ãªã‚‹ã®ã‹ã‚’æ­£ç¢ºã«äºˆæ¸¬ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ãªã‚‰ã°ã€ãƒªãƒ¼ãƒ‰ã‚¹ãƒ«ãƒ¼ã‚ˆã‚Šã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬ ç‚¹: ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå¿…è¦ã«ãªã‚‹ã‹ã®äºˆæ¸¬ãŒæ­£ç¢ºã§ãªã„å ´åˆã«ã¯ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰ãŒãªã„æ–¹ãŒãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¯è‰¯ã„ã¨ã„ã†çµæœã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚æ¬ ç‚¹: ã‚­ãƒ£ãƒƒã‚·ãƒ¥cache invalidationãªã©ã‚’ç”¨ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®çœŸã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®é–“ã®ä¸€è²«æ€§ã‚’ä¿ã¤å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Redisã‚„memcachedã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹æˆã‚’å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Cache invalidationã‚‚é›£ã—ã„ã§ã™ãŒãã‚Œã«åŠ ãˆã¦ã€ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã‹ã¨ã„ã†è¤‡é›‘ãªå•é¡Œã«ã‚‚æ‚©ã¾ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸From cache to in-memory data gridã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€å¯ç”¨æ€§ã€å®‰å®šæ€§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£AWS ElastiCacheã®ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼WikipediaéåŒæœŸå‡¦ç†      Source: Intro to architecting systems for scaleéåŒæœŸã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ã‚‚ã—ã€é€£ç¶šçš„ã«è¡Œã‚ã‚Œã‚‹ã¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚é–“ã‚’åœ§è¿«ã—ã¦ã—ã¾ã†ã‚ˆã†ãªé‡ã„å‡¦ç†ã‚’åˆ¥ã§å‡¦ç†ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã¾ãŸã€å®šæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†åˆã•ã›ã‚‹ãªã©ã®æ™‚é–“ãŒã‹ã‹ã‚‹ã‚ˆã†ãªå‡¦ç†ã‚’å‰ã‚‚ã£ã¦å‡¦ç†ã—ã¦ãŠãã“ã¨ã«ã‚‚å½¹ç«‹ã¡ã¾ã™ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã€ä¿å­˜ã—ã€é…ä¿¡ã—ã¾ã™ã€‚ã‚‚ã—ã€å‡¦ç†ãŒã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã§è¡Œã†ã«ã¯é…ã™ãã‚‹å ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚’ç”¨ã„ã‚‹ã¨ã„ã„ã§ã—ã‚‡ã†:ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¸ãƒ§ãƒ–ã‚’ã‚­ãƒ¥ãƒ¼ã«é…ä¿¡ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ä¼ãˆã¾ã™ã€‚ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å—ã‘å–ã£ã¦ã€å‡¦ç†ã‚’è¡Œã„ã€çµ‚äº†ã—ãŸã‚‰ãã®ã‚·ã‚°ãƒŠãƒ«ã‚’è¿”ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‡¦ç†ãŒæ­¢ã¾ã‚‹ã“ã¨ã¯ãªãã€ã‚¸ãƒ§ãƒ–ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å‡¦ç†ã•ã‚Œã¾ã™ã€‚ã“ã®é–“ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã€ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ãŸã‹ã®ã‚ˆã†ã«è¦‹ã›ã‚‹ãŸã‚ã«å°è¦æ¨¡ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æŠ•ç¨¿ã™ã‚‹ã¨ãã«ã€ãƒ„ã‚¤ãƒ¼ãƒˆã¯ã™ãã«ã‚ãªãŸã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«åæ˜ ã•ã‚ŒãŸã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€ãã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒå®Ÿéš›ã«å…¨ã¦ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã«é…ä¿¡ã•ã‚Œã‚‹ã¾ã§ã«ã¯ã‚‚ã†å°‘ã—æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã‚‹ã§ã—ã‚‡ã†ã€‚Redis ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä»²ä»‹ã¨ã—ã¦ã¯ã„ã„ã§ã™ãŒã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚RabbitMQ ã¯ã‚ˆãä½¿ã‚ã‚Œã¦ã„ã¾ã™ãŒã€'AMQP'ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¯¾å¿œã—ã¦ã€è‡ªå‰ã®ãƒãƒ¼ãƒ‰ã‚’ç«‹ã¦ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Amazon SQS ã¨ã„ã†é¸æŠè‚¢ã‚‚ã‚ã‚Šã¾ã™ãŒã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒé«˜ãã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé‡è¤‡ã—ã¦é…ä¿¡ã•ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã¯ã‚¿ã‚¹ã‚¯ã¨ãã®é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€å‡¦ç†ã—ãŸä¸Šã§ãã®çµæœã‚’è¿”ã—ã¾ã™ã€‚ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã‚’ã§ãã‚‹ã»ã‹ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã¨ã¦ã‚‚é‡ã„ã‚¸ãƒ§ãƒ–ã‚’ã“ãªã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚Celery ã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨pythonã®ã‚µãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚‚ã—ã€ã‚­ãƒ¥ãƒ¼ãŒæ‹¡å¤§ã—ã™ãã‚‹ã¨ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã‚ˆã‚Šã‚‚ã‚­ãƒ¥ãƒ¼ã®æ–¹ãŒå¤§ãããªã‚Šã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ãŒèµ·ã“ã‚Šã€ãƒ‡ã‚£ã‚¹ã‚¯èª­ã¿å‡ºã—ã«ã¤ãªãŒã‚Šã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã«ã¤ãªãŒã‚Šã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã¯ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§å›é¿ã™ã‚‹ã“ã¨ãŒã§ãã€é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¢ºä¿ã—ã‚­ãƒ¥ãƒ¼ã«ã™ã§ã«ã‚ã‚‹ã‚¸ãƒ§ãƒ–ã«ã¤ã„ã¦ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’çŸ­ç¸®ã§ãã¾ã™ã€‚ã‚­ãƒ¥ãƒ¼ãŒã„ã£ã±ã„ã«ãªã‚‹ã¨ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã‚µãƒ¼ãƒãƒ¼ãƒ“ã‚¸ãƒ¼ã‚‚ã—ãã¯HTTP 503ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦å—ã‘å–ã‚Šã¾ãŸå¾Œã§æ™‚é–“ã‚’ãŠã„ã¦ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚ˆã†ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯exponential backoffãªã©ã«ã‚ˆã£ã¦å¾Œã»ã©å†åº¦æ™‚é–“ã‚’ç½®ã„ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬ ç‚¹: éåŒæœŸå‡¦ç†ã‚­ãƒ¥ãƒ¼ã‚’ç”¨ã„ã‚‹ã“ã¨ã§é…å»¶ãŒèµ·ã“ã‚Šã€è¤‡é›‘ã•ã‚‚å¢—ã™ãŸã‚ã€ã‚ã¾ã‚Šé‡ããªã„è¨ˆç®—å‡¦ç†ã‚„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ãŠã„ã¦ã¯åŒæœŸå‡¦ç†ã®æ–¹ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸It's all a numbers gameã‚ªãƒ¼ãƒãƒ¼ãƒ­ãƒ¼ãƒ‰ã—ãŸæ™‚ã«ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚’é©ç”¨ã™ã‚‹Little's lawãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¨ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã®é•ã„ã¨ã¯ï¼Ÿé€šä¿¡      Source: OSI 7 layer modelHypertext transfer protocol (HTTP)HTTP ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦è»¢é€ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã§ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«é–¢ã‚ã‚‹ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚µãƒ¼ãƒãƒ¼ã«æŠ•ã’ã€ã‚µãƒ¼ãƒãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã«é–¢ä¿‚ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨å®Œäº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚HTTPã¯è‡ªå·±å®Œçµã™ã‚‹ã®ã§ã€é–“ã«ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ³ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã€åœ§ç¸®ãªã©ã®ã©ã‚“ãªä¸­é–“ãƒ«ãƒ¼ã‚¿ãƒ¼ãŒå…¥ã£ã¦ã‚‚å‹•ãã‚ˆã†ã«ã§ãã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯HTTPå‹•è©(ãƒ¡ã‚½ãƒƒãƒ‰)ã¨ãƒªã‚½ãƒ¼ã‚¹(ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ)ã§æˆã‚Šç«‹ã£ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ãŒã‚ˆãã‚ã‚‹HTTPå‹•è©ã§ã™ã€‚:å‹•è©è©³ç´°å†ªç­‰æ€§*ã‚»ãƒ¼ãƒ•ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§ãã‚‹ã‹GETãƒªã‚½ãƒ¼ã‚¹ã‚’èª­ã¿å–ã‚‹YesYesYesPOSTãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹ã‚‚ã—ãã¯ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ãƒˆãƒªã‚¬ãƒ¼NoNoYes ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚€å ´åˆPUTãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã‚‚ã—ãã¯å…¥ã‚Œæ›¿ãˆã‚‹YesNoNoPATCHãƒªã‚½ãƒ¼ã‚¹ã‚’éƒ¨åˆ†çš„ã«æ›´æ–°ã™ã‚‹NoNoYes ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚€å ´åˆDELETEãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ã™ã‚‹YesNoNoä½•åº¦å‘¼ã‚“ã§ã‚‚åŒã˜çµæœãŒè¿”ã£ã¦ãã‚‹ã“ã¨HTTPã¯TCP ã‚„ UDP ãªã©ã®ä½ç´šãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: HTTPHTTPã£ã¦ãªã«?HTTP ã¨ TCPã®é•ã„PUT ã¨ PATCHã®é•ã„ä¼é€åˆ¶å¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ« (TCP)      Source: How to make a multiplayer gameTCPã¯IP networkã®ä¸Šã§æˆã‚Šç«‹ã¤æ¥ç¶šãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚æ¥ç¶šã¯handshakeã«ã‚ˆã£ã¦é–‹å§‹ã€è§£é™¤ã•ã‚Œã¾ã™ã€‚å…¨ã¦ã®é€ä¿¡ã•ã‚ŒãŸãƒ‘ã‚±ãƒƒãƒˆã¯æ¬ æãªã—ã§é€ä¿¡å…ˆã«é€ä¿¡ã•ã‚ŒãŸé †ç•ªã§åˆ°é”ã™ã‚‹ã‚ˆã†ã«ä»¥ä¸‹ã®æ–¹æ³•ã§ä¿è¨¼ã•ã‚Œã¦ã„ã¾ã™:ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã¨checksum fieldsãŒå…¨ã¦ã®ãƒ‘ã‚±ãƒƒãƒˆã«ç”¨æ„ã•ã‚Œã¦ã„ã‚‹Acknowledgementãƒ‘ã‚±ãƒƒãƒˆã¨è‡ªå‹•å†é€ä¿¡ã‚‚ã—é€ä¿¡è€…ãŒæ­£ã—ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ã‘å–ã‚‰ãªã‹ã£ãŸã¨ãã€ãƒ‘ã‚±ãƒƒãƒˆã‚’å†é€ä¿¡ã—ã¾ã™ã€‚è¤‡æ•°ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒã‚ã£ãŸã¨ãã€æ¥ç¶šã¯è§£é™¤ã•ã‚Œã¾ã™ã€‚TCP ã¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ ã¨ è¼»è¼³åˆ¶å¾¡ã‚‚å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã«ã‚ˆã£ã¦é€Ÿåº¦ã¯ä½ä¸‹ã—ã€ä¸€èˆ¬çš„ã«UDPã‚ˆã‚Šã‚‚éåŠ¹ç‡ãªè»¢é€æ‰‹æ®µã«ãªã£ã¦ã„ã¾ã™ã€‚ãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã¯ã‹ãªã‚Šå¤§ããªæ•°ã®TCPæ¥ç¶šã‚’é–‹ã„ã¦ãŠãã“ã¨ãŒã‚ã‚Šã€ãã®ã“ã¨ã§ãƒ¡ãƒ¢ãƒªãƒ¼ä½¿ç”¨ãŒåœ§è¿«ã•ã‚Œã¾ã™ã€‚ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã¨ä¾‹ãˆã°memcached ã‚µãƒ¼ãƒãƒ¼ã®é–“ã§å¤šæ•°ã®ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿ã£ã¦ãŠãã“ã¨ã¯é«˜ãã¤ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å¯èƒ½ãªã¨ã“ã‚ã§ã¯UDPã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã ã‘ã§ãªãã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãªã©ã‚‚å½¹ç«‹ã¤ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚TCPã¯é«˜ã„ä¾å­˜æ€§ã‚’è¦ã—ã€æ™‚é–“åˆ¶ç´„ãŒå³ã—ããªã„ã‚‚ã®ã«é©ã—ã¦ã„ã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã€SMTPã€FTPã‚„SSHãªã©ã®ä¾‹ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®æ™‚ã«UDPã‚ˆã‚Šã‚‚TCPã‚’ä½¿ã†ã¨ã„ã„ã§ã—ã‚‡ã†:å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒæ¬ æã™ã‚‹ã“ã¨ãªã—ã«å±Šã„ã¦ã»ã—ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®æœ€é©ãªè‡ªå‹•æ¨æ¸¬ã‚’ã—ã¦ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« (UDP)      Source: How to make a multiplayer gameUDPã¯ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ã‚¹ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ï¼ˆãƒ‘ã‚±ãƒƒãƒˆã®ã‚ˆã†ãªã‚‚ã®ï¼‰ã¯ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ¬ãƒ™ãƒ«ã§ã®ä¿è¨¼ã—ã‹ã•ã‚Œã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ã¯é †ä¸åŒã§å—ã‘å–ã‚Šå…ˆã«åˆ°ç€ã—ãŸã‚Šãã‚‚ãã‚‚ç€ã‹ãªã‹ã£ãŸã‚Šã—ã¾ã™ã€‚UDPã¯è¼»è¼³åˆ¶å¾¡ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã›ã‚“ã€‚TCPã«ãŠã„ã¦ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã“ã‚Œã‚‰ã®ä¿è¨¼ãŒãªã„ãŸã‚ã€UDPã¯ä¸€èˆ¬çš„ã«ã€TCPã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã™ã€‚UDPã¯ã‚µãƒ–ãƒãƒƒãƒˆä¸Šã®ã™ã¹ã¦ã®æ©Ÿå™¨ã«ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ã‚’é€ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã¯DHCP ã«ãŠã„ã¦å½¹ã«ç«‹ã¡ã¾ã™ã€‚ã¨ã„ã†ã®ã‚‚ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã¾ã IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—ã—ã¦ã„ãªã„ã®ã§ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å¿…è¦ã¨ã™ã‚‹TCPã«ã‚ˆã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒã§ããªã„ã‹ã‚‰ã§ã™ã€‚UDPã¯ä¿¡é ¼æ€§ã®é¢ã§ã¯åŠ£ã‚Šã¾ã™ãŒã€VoIPã€ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚„åŒæ™‚é€šä¿¡ãƒãƒ«ãƒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚²ãƒ¼ãƒ ãªã©ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒé‡è¦–ã•ã‚Œã‚‹æ™‚ã«ã¯ã¨ã¦ã‚‚åŠ¹æœçš„ã§ã™ã€‚TCPã‚ˆã‚Šã‚‚UDPã‚’ä½¿ã†ã®ã¯:ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’æœ€ä½é™ã«æŠ‘ãˆãŸã„æ™‚ãƒ‡ãƒ¼ã‚¿æ¬ æã‚ˆã‚Šã‚‚ã€ãƒ‡ãƒ¼ã‚¿é…å»¶ã‚’é‡è¦–ã™ã‚‹ã¨ãã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚’è‡ªå‰ã§å®Ÿè£…ã—ãŸã„ã¨ããã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: TCP ã¨ UDPã‚²ãƒ¼ãƒ ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ãŸã‚ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯TCP ã¨ UDP ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ä¸»ãªé•ã„TCP ã¨ UDPã®é•ã„Transmission control protocolUser datagram protocolFacebookã®ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°é éš”æ‰‹ç¶šå‘¼å‡º (RPC)      Source: Crack the system design interviewRPCã§ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒªãƒ¢ãƒ¼ãƒˆã‚µãƒ¼ãƒãƒ¼ãªã©ã®ç•°ãªã‚‹ã‚¢ãƒ‰ãƒ¬ã‚¹ç©ºé–“ã§ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ãŒå‡¦ç†ã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ã‚³ãƒ¼ãƒ«ã®ã‚ˆã†ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã«ã©ã®ã‚ˆã†ã«é€šä¿¡ã™ã‚‹ã‹ã¨ã„ã†è©³ç´°ã‚’çœã„ãŸçŠ¶æ…‹ã§ã‚³ãƒ¼ãƒ‰ãŒæ›¸ã‹ã‚Œã¾ã™ã€‚ãƒªãƒ¢ãƒ¼ãƒˆã®ã‚³ãƒ¼ãƒ«ã¯æ™®é€šã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ã‚³ãƒ¼ãƒ«ã‚ˆã‚Šã‚‚é…ãã€ä¿¡é ¼æ€§ã«æ¬ ã‘ã‚‹ãŸã‚ã€RPCã‚³ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‚³ãƒ¼ãƒ«ã¨åŒºåˆ¥ã•ã›ã¦ãŠãã“ã¨ãŒå¥½ã¾ã—ã„ã§ã—ã‚‡ã†ã€‚äººæ°—ã®RPCãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ä»¥ä¸‹ã§ã™ã€‚Protobufã€ Thriftã€AvroRPC ã¯ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒˆã‚³ãƒ«:ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ  - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚³ãƒ¼ãƒ«ã®ã‚ˆã†ã«ã‚¹ã‚¿ãƒƒã‚¯ã¸ã¨ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ãã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ - ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£IDã¨ã‚¢ãƒ¼ã‚®ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ‘ãƒƒã‚¯ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã—ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé€šä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - OSãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã¸ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚Šã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼é€šä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - OSãŒå—ã‘å–ã£ãŸãƒ‘ã‚±ãƒƒãƒˆã‚’ã‚µãƒ¼ãƒãƒ¼ã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã«å—ã‘æ¸¡ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ -  çµæœã‚’å±•é–‹ã—ã€ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼IDã«ãƒãƒƒãƒã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’è¿”ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ä¸Šè¨˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é€†é †ã§ç¹°ã‚Šè¿”ã—ã¾ã™ã€‚Sample RPC calls:GET /someoperation?data=anIdPOST /anotheroperation{  \""data\"":\""anId\"";  \""anotherdata\"": \""another value\""}RPCã¯æŒ¯ã‚‹èˆã„ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚RPCã¯å†…éƒ¨é€šä¿¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç†ç”±ã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ã¨ã„ã†ã®ã‚‚ã€ä½¿ç”¨ã™ã‚‹çŠ¶æ³ã«åˆã‚ã›ã¦ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚³ãƒ¼ãƒ«ã‚’è‡ªä½œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã‚‰ã§ã™ã€‚ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼ (aka SDK) ã‚’å‘¼ã¶ã®ã¯ä»¥ä¸‹ã®æ™‚:ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’çŸ¥ã£ã¦ã„ã‚‹æ™‚ãƒ­ã‚¸ãƒƒã‚¯ãŒã©ã®ã‚ˆã†ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ã®ã‹ã‚’ç®¡ç†ã—ãŸã„ã¨ããƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼å¤–ã§ã‚¨ãƒ©ãƒ¼ãŒã©ã®ã‚ˆã†ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã•ã‚Œã‚‹ã‹ã‚’ç®¡ç†ã—ãŸã„æ™‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ãŒæœ€å„ªå…ˆã®æ™‚REST ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¾“ã†HTTP APIã¯ãƒ‘ãƒ–ãƒªãƒƒã‚¯APIã«ãŠã„ã¦ã‚ˆãç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚æ¬ ç‚¹: RPCRPCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã¯ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…ã«ã‚ˆã‚Šå³å¯†ã«å·¦å³ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ–°ã—ã„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ä½¿ç”¨ä¾‹ãŒã‚ã‚‹ãŸã³ã«æ–°ã—ãAPIãŒå®šç¾©ã•ã‚Œãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚RPCã‚’ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ã®ã¯é›£ã—ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ—¢å­˜ã®ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚’ãã®ã¾ã¾ä½¿ã£ã¦ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€Squidãªã©ã®ã‚µãƒ¼ãƒãƒ¼ã«RPCã‚³ãƒ¼ãƒ«ãŒæ­£ã—ãã‚­ãƒ£ãƒƒã‚·ãƒ¥ ã•ã‚Œã‚‹ã‚ˆã†ã«è¿½åŠ ã§éª¨ã‚’æŠ˜ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚Representational state transfer (REST)RESTã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒã‚µãƒ¼ãƒãƒ¼ã«ã‚ˆã£ã¦ãƒãƒãƒ¼ã‚¸ã•ã‚Œã‚‹ãƒªã‚½ãƒ¼ã‚¹ã«å¯¾ã—ã¦å‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ»ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’æ”¯æŒã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚­ãƒãƒ£ã‚¹ã‚¿ã‚¤ãƒ«ã§ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯æ“ä½œã§ãã‚‹ã‚‚ã—ãã¯æ–°ã—ã„ãƒªã‚½ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ãªãƒªã‚½ãƒ¼ã‚¹ã‚„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ¬ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚ã™ã¹ã¦ã®é€šä¿¡ã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯èƒ½ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚RESTful ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«ã¯æ¬¡ã®å››ã¤ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™:ç‰¹å¾´çš„ãªãƒªã‚½ãƒ¼ã‚¹ (URI in HTTP) - ã©ã®ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚ã£ã¦ã‚‚åŒã˜URIã‚’ä½¿ã†ã€‚HTTPå‹•è©ã«ã‚ˆã£ã¦å¤‰ã‚ã‚‹ (Verbs in HTTP) - å‹•è©ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒœãƒ‡ã‚£ã‚’ä½¿ã†è‡ªå·±èª¬æ˜çš„ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (status response in HTTP) - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã„ã€æ–°ã—ãä½œã£ãŸã‚Šã—ãªã„ã“ã¨ã€‚HATEOAS (HTML interface for HTTP) - è‡ªåˆ†ã®webã‚µãƒ¼ãƒ“ã‚¹ãŒãƒ–ãƒ©ã‚¦ã‚¶ã§å®Œå…¨ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã“ã¨ã€‚ã‚µãƒ³ãƒ—ãƒ« REST ã‚³ãƒ¼ãƒ«:GET /someresources/anIdPUT /someresources/anId{\""anotherdata\"": \""another value\""}RESTã¯ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼ã®ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ã‚’æœ€å°é™ã«ã™ã‚‹ã‚‚ã®ã§ã€ãƒ‘ãƒ–ãƒªãƒƒã‚¯APIãªã©ã«ã‚ˆãç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚RESTã¯URIã€ representation through headersã€ãã—ã¦ã€GETã€POSTã€PUTã€ DELETEã€PATCHãªã©ã®HTTPå‹•è©ç­‰ã®ã‚ˆã‚Šã‚¸ã‚§ãƒãƒªãƒƒã‚¯ã§çµ±ä¸€ã•ã‚ŒãŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¾ã™ã€‚ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹ã®ã§RESTã¯æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã«æœ€é©ã§ã™ã€‚æ¬ ç‚¹: RESTRESTã¯ãƒ‡ãƒ¼ã‚¿å…¬é–‹ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã®ã§ã€ãƒªã‚½ãƒ¼ã‚¹ãŒè‡ªç„¶ã«æ•´ç†ã•ã‚Œã¦ã„ãªã‹ã£ãŸã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ã§è¡¨ã›ã‚‰ã‚Œãªã„æ™‚ã«ã¯ã‚ˆã„é¸æŠè‚¢ã¨ã¯è¨€ãˆãªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€ã¨ã‚ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã«ãƒãƒƒãƒã™ã‚‹ã™ã¹ã¦ã®æ›´æ–°æƒ…å ±ã‚’è¿”ã™ã¨è¨€ã£ãŸå‡¦ç†ã¯ç°¡å˜ã«ã¯ãƒ‘ã‚¹ã§è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚RESTã§ã¯ã€URIãƒ‘ã‚¹ã€ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãã—ã¦å ´åˆã«ã‚ˆã£ã¦ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ãªã©ã«ã‚ˆã£ã¦å®Ÿè£…ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã€‚RESTã¯å°‘æ•°ã®å‹•è©ã«ä¾å­˜ã—ã¦ã„ã¾ã™(GETã€POSTã€PUTã€DELETEã€ãã—ã¦ PATCH) ãŒæ™‚ã«ã¯ä½¿ã„ãŸã„äº‹ä¾‹ã«åˆã‚ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€æœŸé™ã®åˆ‡ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ç§»ã—ãŸã„å ´åˆãªã©ã¯ã“ã‚Œã‚‰ã®å‹•è©ã®ä¸­ã«ã¯ç¶ºéº—ã«ã¯ãƒ•ã‚£ãƒƒãƒˆã—ã¾ã›ã‚“ã€‚ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ã®ä¸­ã«ã‚ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚’ã¨ã£ã¦ãã‚‹ã®ã¯ã‚·ãƒ³ã‚°ãƒ«ãƒ“ãƒ¥ãƒ¼ã‚’æç”»ã™ã‚‹ã®ã«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã§æ•°å›ã‚„ã‚Šã¨ã‚Šã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ä¾‹ã¨ã—ã¦ã€ãƒ–ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ãã‚Œã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤ºã™ã‚‹å ´åˆãªã©ã§ã™ã€‚æ§˜ã€…ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒã§å‹•ä½œã™ã‚‹å¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã‚‹ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã¯ã“ã®ã‚ˆã†ãªè¤‡æ•°ã®ã‚„ã‚Šå–ã‚Šã¯å¥½ã¾ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚æ™‚ãŒçµŒã¤ã«ã¤ã‚Œã¦ã€APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚ˆã‚Šå¤šãã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸ãˆã‚‰ã‚Œã¦ã€å¤ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã™ã§ã«ã„ã‚‰ãªã„ã‚‚ã®ã‚‚å«ã‚ã¦ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å—ã‘å–ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ã“ã¨ã§ã€ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãŒå¤§ãããªã‚Šã™ãã¦ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚‚æ‹¡å¤§ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚RPCã¨RESTæ¯”è¼ƒOperationRPCRESTã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—POST /signupPOST /personsãƒªã‚¶ã‚¤ãƒ³POST /resign{\""personid\"": \""1234\""}DELETE /persons/1234Personèª­ã¿è¾¼ã¿GET /readPerson?personid=1234GET /persons/1234Personã®ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿GET /readUsersItemsList?personid=1234GET /persons/1234/itemsPersonã®ã‚¢ã‚¤ãƒ†ãƒ ã¸ã®ã‚¢ã‚¤ãƒ†ãƒ è¿½åŠ POST /addItemToUsersItemsList{\""personid\"": \""1234\"";\""itemid\"": \""456\""}POST /persons/1234/items{\""itemid\"": \""456\""}ã‚¢ã‚¤ãƒ†ãƒ æ›´æ–°POST /modifyItem{\""itemid\"": \""456\"";\""key\"": \""value\""}PUT /items/456{\""key\"": \""value\""}ã‚¢ã‚¤ãƒ†ãƒ å‰Šé™¤POST /removeItem{\""itemid\"": \""456\""}DELETE /items/456  Source: Do you really know why you prefer REST over RPCãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: REST ã¨ RPCDo you really know why you prefer REST over RPCWhen are RPC-ish approaches more appropriate than REST?REST vs JSON-RPCDebunking the myths of RPC and RESTWhat are the drawbacks of using RESTCrack the system design interviewThriftWhy REST for internal use and not RPCã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯æ›´æ–°ãŒå¿…è¦ã§ã™ã€‚contributingã—ã¦ãã ã•ã„ï¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¯å¹…åºƒã„ãƒˆãƒ”ãƒƒã‚¯ã§ã™ã€‚ååˆ†ãªçµŒé¨“ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†é‡ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãŒãªãã¦ã‚‚ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®çŸ¥è­˜ã‚’è¦ã™ã‚‹è·ã«å¿œå‹Ÿã™ã‚‹ã®ã§ãªã„é™ã‚Šã€åŸºæœ¬ä»¥ä¸Šã®ã“ã¨ã‚’çŸ¥ã‚‹å¿…è¦ã¯ãªã„ã§ã—ã‚‡ã†ã€‚æƒ…å ±ä¼é”ã€ä¿å­˜ã«ãŠã‘ã‚‹æš—å·åŒ–XSS ã‚„ SQL injectionã‚’é˜²ããŸã‚ã«ã€å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚‚ã—ãã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«éœ²å‡ºã•ã‚Œã‚‹å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã™ã‚‹SQL injectionã‚’é˜²ããŸã‚ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’ç”¨ã„ã‚‹ã€‚least privilegeã®åŸç†ã‚’ç”¨ã„ã‚‹ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:é–‹ç™ºè€…ã®ãŸã‚ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¬ã‚¤ãƒ‰OWASP top tenè£œéºæš—ç®—ã§ã€æ¨è¨ˆå€¤ã‚’æ±‚ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚‚æ™‚ã«ã¯ã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰100æšã‚¤ãƒ¡ãƒ¼ã‚¸åˆ†ã®ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ä½œã‚‹æ™‚é–“ã‚’æ±‚ã‚ãŸã‚Šã€ãã®æ™‚ã«ã©ã‚Œã ã‘ãƒ‡ã‚£ã‚¹ã‚¯ãƒ¡ãƒ¢ãƒªãƒ¼ãŒæ¶ˆè²»ã•ã‚Œã‚‹ã‹ãªã©ã®å€¤ã§ã™ã€‚2ã®ä¹—æ•°è¡¨ ã¨ å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ ã¯è‰¯ã„å‚è€ƒã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚2ã®ä¹—æ•°è¡¨ä¹—æ•°           å³å¯†ãªå€¤         ç´„        Bytes---------------------------------------------------------------7                             1288                             25610                           1024   1 thousand           1 KB16                         65,536                       64 KB20                      1,048,576   1 million            1 MB30                  1,073,741,824   1 billion            1 GB32                  4,294,967,296                        4 GB40              1,099,511,627,776   1 trillion           1 TBãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤Latency Comparison Numbers--------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy            10,000   ns       10 usSend 1 KB bytes over 1 Gbps network     10,000   ns       10 usRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSDRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSDSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 msNotes-----1 ns = 10^-9 seconds1 us = 10^-6 seconds = 1,000 ns1 ms = 10^-3 seconds = 1,000 us = 1,000,000 nsä¸Šè¨˜è¡¨ã«åŸºã¥ã„ãŸå½¹ã«ç«‹ã¤æ•°å€¤:ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 30 MB/s1 Gbps Ethernetã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ã€€100 MB/sSSDã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 1 GB/smain memoryã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 4 GB/s1ç§’ã§åœ°çƒ6-7å‘¨ã§ãã‚‹1ç§’ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã¨2000å‘¨ã‚„ã‚Šã¨ã‚Šã§ãã‚‹ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã®è¦–è¦šçš„è¡¨ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ - 1å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ - 2Designs, lessons, and advice from building large distributed systemsSoftware Engineering Advice from Building Large-Scale Distributed Systemsä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ä¾‹é¡Œé »å‡ºã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨ãã®è§£ç­”ã¸ã®ãƒªãƒ³ã‚¯è³ªå•è§£ç­”Dropboxã®ã‚ˆã†ãªãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹youtube.comGoogleã®ã‚ˆã†ãªæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­è¨ˆqueue.acm.orgstackexchange.comardendertat.comstanford.eduGoogleã®ã‚ˆã†ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªwebã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®è¨­è¨ˆquora.comGoogle docsã®è¨­è¨ˆcode.google.comneil.fraser.nameRedisã®ã‚ˆã†ãªã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã®è¨­è¨ˆslideshare.netMemcachedã®ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆslideshare.netAmazonã®ã‚ˆã†ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆhulu.comijcai13.orgBitlyã®ã‚ˆã†ãªURLçŸ­ç¸®ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆn00tc0d3r.blogspot.comWhatsAppã®ã‚ˆã†ãªãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã®è¨­è¨ˆhighscalability.comInstagramã®ã‚ˆã†ãªå†™çœŸå…±æœ‰ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆhighscalability.comhighscalability.comFacebookãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚£ãƒ¼ãƒ‰ã®è¨­è¨ˆquora.comquora.comslideshare.netFacebookã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®è¨­è¨ˆfacebook.comhighscalability.comFacebookãƒãƒ£ãƒƒãƒˆã®è¨­è¨ˆerlang-factory.comfacebook.comFacebookã®ã‚ˆã†ãªgraphæ¤œç´¢ã®è¨­è¨ˆfacebook.comfacebook.comfacebook.comCloudFlareã®ã‚ˆã†ãªCDNã®è¨­è¨ˆcmu.eduTwitterã®ãƒˆãƒ¬ãƒ³ãƒ‰æ©Ÿèƒ½ã®è¨­è¨ˆmichael-noll.comsnikolov .wordpress.comãƒ©ãƒ³ãƒ€ãƒ IDç™ºè¡Œã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆblog.twitter.comgithub.comä¸€å®šã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«æ™‚é–“ã§ã®ä¸Šä½kä»¶ã‚’è¿”ã™ucsb.eduwpi.eduè¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’é…ä¿¡ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆhighscalability.comã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®è¤‡æ•°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã®è¨­è¨ˆindieflashblog.combuildnewgames.comã‚¬ãƒ¼ãƒ™ãƒƒã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆstuffwithstuff.comwashington.eduã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆä¾‹é¡Œã‚’è¿½åŠ ã™ã‚‹Contributeå®Ÿä¸–ç•Œã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸–ã®ä¸­ã®ã‚·ã‚¹ãƒ†ãƒ ãŒã©ã®ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã®è¨˜äº‹      Source: Twitter timelines at scaleä»¥ä¸‹ã®è¨˜äº‹ã®é‡ç®±ã®éš…ã‚’ã¤ã¤ãã‚ˆã†ãªç´°ã‹ã„è©³ç´°ã«ã“ã ã‚ã‚‰ãªã„ã“ã¨ã€‚ã‚€ã—ã‚å…±é€šã®åŸç†ã€æŠ€è¡“ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã‚‹ã“ã¨ãã‚Œãã‚Œã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã©ã‚“ãªå•é¡ŒãŒè§£æ±ºã•ã‚Œã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¯ã©ã“ã§ã†ã¾ãä½¿ãˆã‚‚ã—ãã¯ä½¿ãˆãªã„ã‹ã‚’çŸ¥ã‚‹ã“ã¨å­¦ã‚“ã ã“ã¨ã‚’å¾©ç¿’ã™ã‚‹ã“ã¨ç¨®é¡ã‚·ã‚¹ãƒ†ãƒ å‚è€ƒãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿å‡¦ç†MapReduce - Googleã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ research.google.comãƒ‡ãƒ¼ã‚¿å‡¦ç†Spark - Databricksã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿å‡¦ç†Storm - Twitterã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Bigtable - Googleã®ã‚«ãƒ©ãƒ æŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹harvard.eduãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢HBase - Bigtableã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Cassandra - Facebookã®ã‚«ãƒ©ãƒ æŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢DynamoDB - Amazonã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹harvard.eduãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢MongoDB - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Spanner - Googleã®ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹research.google.comãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Memcached - åˆ†æ•£ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Redis - æ°¸ç¶šæ€§ã¨ãƒãƒªãƒ¥ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’å…¼ã­å‚™ãˆãŸåˆ†æ•£ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ Google File System (GFS) - åˆ†æ•£ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ research.google.comãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ Hadoop File System (HDFS) - GFSã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…apache.orgMiscChubby - ç–çµåˆã®åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ­ãƒƒã‚¯ã™ã‚‹Googleã®ã‚µãƒ¼ãƒ“ã‚¹research.google.comMiscDapper - åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’è¿½è·¡ã™ã‚‹ã‚¤ãƒ³ãƒ•ãƒ©research.google.comMiscKafka - LinkedInã«ã‚ˆã‚‹Pub/subãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼slideshare.netMiscZookeeper - åŒæœŸã‚’å¯èƒ½ã«ã™ã‚‹ä¸­å¤®é›†æ¨©ã‚¤ãƒ³ãƒ•ãƒ©ã¨ã‚µãƒ¼ãƒ“ã‚¹slideshare.netã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¿½åŠ ã™ã‚‹Contributeå„ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¼æ¥­å‚è€ƒãƒšãƒ¼ã‚¸AmazonAmazon architectureCinchcastProducing 1,500 hours of audio every dayDataSiftRealtime datamining At 120,000 tweets per secondDropBoxHow we've scaled DropboxESPNOperating At 100,000 duh nuh nuhs per secondGoogleGoogle architectureInstagram14 million users, terabytes of photosWhat powers InstagramJustin.tvJustin.Tv's live video broadcasting architectureFacebookScaling memcached at FacebookTAO: Facebookâ€™s distributed data store for the social graphFacebookâ€™s photo storageFlickrFlickr architectureMailboxFrom 0 to one million users in 6 weeksPinterestFrom 0 To 10s of billions of page views a month18 million visitors, 10x growth, 12 employeesPlayfish50 million monthly users and growingPlentyOfFishPlentyOfFish architectureSalesforceHow they handle 1.3 billion transactions a dayStack OverflowStack Overflow architectureTripAdvisor40M visitors, 200M dynamic page views, 30TB dataTumblr15 billion page views a monthTwitterMaking Twitter 10000 percent fasterStoring 250 million tweets a day using MySQL150M active users, 300K QPS, a 22 MB/S firehoseTimelines at scaleBig and small data at TwitterOperations at Twitter: scaling beyond 100 million usersUberHow Uber scales their real-time market platformWhatsAppThe WhatsApp architecture Facebook bought for $19 billionYouTubeYouTube scalabilityYouTube architectureä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°é¢æ¥ã‚’å—ã‘ã‚‹ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æŠ•ã’ã‚‰ã‚Œã‚‹è³ªå•ã¯åŒã˜åˆ†é‡ã‹ã‚‰æ¥ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã§ã—ã‚‡ã†Airbnb EngineeringAtlassian DevelopersAutodesk EngineeringAWS BlogBitly Engineering BlogBox BlogsCloudera Developer BlogDropbox Tech BlogEngineering at QuoraEbay Tech BlogEvernote Tech BlogEtsy Code as CraftFacebook EngineeringFlickr CodeFoursquare Engineering BlogGitHub Engineering BlogGoogle Research BlogGroupon Engineering BlogHeroku Engineering BlogHubspot Engineering BlogHigh ScalabilityInstagram EngineeringIntel Software BlogJane Street Tech BlogLinkedIn EngineeringMicrosoft EngineeringMicrosoft Python EngineeringNetflix Tech BlogPaypal Developer BlogPinterest Engineering BlogQuora EngineeringReddit BlogSalesforce Engineering BlogSlack Engineering BlogSpotify LabsTwilio Engineering BlogTwitter EngineeringUber Engineering BlogYahoo Engineering BlogYelp Engineering BlogZynga Engineering Blogãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:kilimchoi/engineering-blogsã“ã“ã«ã‚ã‚‹ãƒªã‚¹ãƒˆã¯æ¯”è¼ƒçš„å°è¦æ¨¡ãªã‚‚ã®ã«ã¨ã©ã‚ã€kilimchoi/engineering-blogsã«ã‚ˆã‚Šè©³ç´°ã«è¨˜ã™ã“ã¨ã§é‡è¤‡ã—ãªã„ã‚ˆã†ã«ã—ã¦ãŠãã“ã¨ã«ã™ã‚‹ã€‚ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°ã¸ã®ãƒªãƒ³ã‚¯ã‚’è¿½åŠ ã™ã‚‹å ´åˆã¯ã“ã“ã§ã¯ãªãã€engineering-blogsãƒ¬ãƒœã‚¸ãƒˆãƒªã«è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚é€²è¡Œä¸­ã®ä½œæ¥­ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¿½åŠ ã‚„ã€é€²è¡Œä¸­ã®ä½œæ¥­ã‚’æ‰‹ä¼ã£ã¦ã„ãŸã ã‘ã‚‹å ´åˆã¯ã“ã¡ã‚‰!MapReduceã«ã‚ˆã‚‹åˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°Consistent hashingScatter gatherContributeã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¯ãƒ¬ã‚¸ãƒƒãƒˆåŠã³ã€å‚ç…§ãƒšãƒ¼ã‚¸ã¯é©æ™‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªå†…ã«è¨˜è¼‰ã—ã¦ã‚ã‚Šã¾ã™Special thanks to:Hired in techCracking the coding interviewHigh scalabilitycheckcheckzz/system-design-interviewshashank88/system_designmmcgrana/services-engineeringSystem design cheat sheetA distributed systems reading listCracking the system design interviewContact infoFeel free to contact me to discuss any issues, questions, or comments.My contact info can be found on my GitHub page.LicenseI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2017 Donne MartinCreative Commons Attribution 4.0 International License (CC BY 4.0)http://creativecommons.org/licenses/by/4.0/"
49,AUTOMATIC1111/stable-diffusion-webui,https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/README.md,Python,"Stable Diffusion web UIA browser interface based on Gradio library for Stable Diffusion.FeaturesDetailed feature showcase with images:Original txt2img and img2img modesOne click install and run script (but you still must install python and git)OutpaintingInpaintingColor SketchPrompt MatrixStable Diffusion UpscaleAttention, specify parts of text that the model should pay more attention toa man in a ((tuxedo)) - will pay more attention to tuxedoa man in a (tuxedo:1.21) - alternative syntaxselect text and press Ctrl+Up or Ctrl+Down (or Command+Up or Command+Down if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)Loopback, run img2img processing multiple timesX/Y/Z plot, a way to draw a 3 dimensional plot of images with different parametersTextual Inversionhave as many embeddings as you want and use any names you like for themuse multiple embeddings with different numbers of vectors per tokenworks with half precision floating point numberstrain embeddings on 8GB (also reports of 6GB working)Extras tab with:GFPGAN, neural network that fixes facesCodeFormer, face restoration tool as an alternative to GFPGANRealESRGAN, neural network upscalerESRGAN, neural network upscaler with a lot of third party modelsSwinIR and Swin2SR (see here), neural network upscalersLDSR, Latent diffusion super resolution upscalingResizing aspect ratio optionsSampling method selectionAdjust sampler eta values (noise multiplier)More advanced noise setting optionsInterrupt processing at any time4GB video card support (also reports of 2GB working)Correct seeds for batchesLive prompt token length validationGeneration parametersparameters you used to generate images are saved with that imagein PNG chunks for PNG, in EXIF for JPEGcan drag the image to PNG info tab to restore generation parameters and automatically copy them into UIcan be disabled in settingsdrag and drop an image/text-parameters to promptboxRead Generation Parameters Button, loads parameters in promptbox to UISettings pageRunning arbitrary python code from UI (must run with --allow-code to enable)Mouseover hints for most UI elementsPossible to change defaults/mix/max/step values for UI elements via text configTiling support, a checkbox to create images that can be tiled like texturesProgress bar and live image generation previewCan use a separate neural network to produce previews with almost none VRAM or compute requirementNegative prompt, an extra text field that allows you to list what you don't want to see in generated imageStyles, a way to save part of prompt and easily apply them via dropdown laterVariations, a way to generate same image but with tiny differencesSeed resizing, a way to generate same image but at slightly different resolutionCLIP interrogator, a button that tries to guess prompt from an imagePrompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midwayBatch Processing, process a group of files using img2imgImg2img Alternative, reverse Euler method of cross attention controlHighres Fix, a convenience option to produce high resolution pictures in one click without usual distortionsReloading checkpoints on the flyCheckpoint Merger, a tab that allows you to merge up to 3 checkpoints into oneCustom scripts with many extensions from communityComposable-Diffusion, a way to use multiple prompts at onceseparate prompts using uppercase ANDalso supports weights for prompts: a cat :1.2 AND a dog AND a penguin :2.2No token limit for prompts (original stable diffusion lets you use up to 75 tokens)DeepDanbooru integration, creates danbooru style tags for anime promptsxformers, major speed increase for select cards: (add --xformers to commandline args)via extension: History tab: view, direct and delete images conveniently within the UIGenerate forever optionTraining tabhypernetworks and embeddings optionsPreprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)Clip skipHypernetworksLoras (same as Hypernetworks but more pretty)A sparate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your promptCan select to load a different VAE from settings screenEstimated completion time in progress barAPISupport for dedicated inpainting model by RunwayMLvia extension: Aesthetic Gradients, a way to generate images with a specific aesthetic by using clip images embeds (implementation of https://github.com/vicgalle/stable-diffusion-aesthetic-gradients)Stable Diffusion 2.0 support - see wiki for instructionsAlt-Diffusion support - see wiki for instructionsNow without any bad letters!Load checkpoints in safetensors formatEased resolution restriction: generated image's domension must be a multiple of 8 rather than 64Now with a license!Reorder elements in the UI from settings screenInstallation and RunningMake sure the required dependencies are met and follow the instructions available for both NVidia (recommended) and AMD GPUs.Alternatively, use online services (like Google Colab):List of Online ServicesInstallation on Windows 10/11 with NVidia-GPUs using release packageDownload sd.webui.zip from v1.0.0-pre and extract it's contents.Run update.bat.Run run.bat.For more details see Install-and-Run-on-NVidia-GPUsAutomatic Installation on WindowsInstall Python 3.10.6 (Newer version of Python does not support torch), checking \""Add Python to PATH\"".Install git.Download the stable-diffusion-webui repository, for example by running git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git.Run webui-user.bat from Windows Explorer as normal, non-administrator, user.Automatic Installation on LinuxInstall the dependencies:# Debian-based:sudo apt install wget git python3 python3-venv# Red Hat-based:sudo dnf install wget git python3# Arch-based:sudo pacman -S wget git python3Navigate to the directory you would like the webui to be installed and execute the following command:bash <(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)Run webui.sh.Check webui-user.sh for options.Installation on Apple SiliconFind the instructions here.ContributingHere's how to add code to this repo: ContributingDocumentationThe documentation was moved from this README over to the project's wiki.For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) crawlable wiki.CreditsLicenses for borrowed code can be found in Settings -> Licenses screen, and also in html/licenses.html file.Stable Diffusion - https://github.com/CompVis/stable-diffusion, https://github.com/CompVis/taming-transformersk-diffusion - https://github.com/crowsonkb/k-diffusion.gitGFPGAN - https://github.com/TencentARC/GFPGAN.gitCodeFormer - https://github.com/sczhou/CodeFormerESRGAN - https://github.com/xinntao/ESRGANSwinIR - https://github.com/JingyunLiang/SwinIRSwin2SR - https://github.com/mv-lab/swin2srLDSR - https://github.com/Hafiidz/latent-diffusionMiDaS - https://github.com/isl-org/MiDaSIdeas for optimizations - https://github.com/basujindal/stable-diffusionCross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)Sub-quadratic Cross Attention layer optimization - Alex Birch (Birch-san/diffusers#1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we're not using his code, but we are using his ideas).Idea for SD upscale - https://github.com/jquesnelle/txt2imghdNoise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-botCLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogatorIdea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorchxformers - https://github.com/facebookresearch/xformersDeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooruSampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pixSecurity advice - RyotaKUniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPCTAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesdLyCORIS - KohakuBlueleafInitial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.(You)"
50,geekcomputers/Python,https://github.com/geekcomputers/Python/blob/master/README.md,Python,"My Python Eggs ğŸ ğŸ˜„I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in Notepad++ ğŸ—’ï¸Feel free to explore the scripts and use them for your learning and automation needs!List of Scripts:batch_file_rename.py - Batch rename a group of files in a specified directory, changing their extensions.create_dir_if_not_there.py - Check if a directory exists in the user's home directory. Create it if it doesn't exist.Fast Youtube Downloader - Download YouTube videos quickly with parallel threads using aria2c.Google Image Downloader - Query a given term and retrieve images from the Google Image database.dir_test.py - Test if the directory testdir exists. If not, create it.env_check.py - Check if all the required environment variables are set.blackjack.py - Casino Blackjack-21 game in Python.fileinfo.py - Show file information for a given file.folder_size.py - Scan the current directory and all subdirectories and display their sizes.logs.py - Search for all *.log files in a directory, zip them using the specified program, and date stamp them.move_files_over_x_days.py - Move all files over a specified age (in days) from the source directory to the destination directory.nslookup_check.py - Open the file server_list.txt and perform nslookup for each server to check the DNS entry.osinfo.py - Display information about the operating system on which the script is running.ping_servers.py - Ping the servers associated with the specified application group.ping_subnet.py - Scan the final range of a given IP subnet for available addresses.powerdown_startup.py - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.puttylogs.py - Zip all the logs in the given directory.script_count.py - Scan the scripts directory and count the different types of scripts.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.script_listing.py - List all files in a given directory and its subdirectories.testlines.py - Open a file and print out 100 lines of the set line variable.tweeter.py - Tweet text or a picture from the terminal.serial_scanner.py - List available serial ports in use on Linux and Windows systems.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.CountMillionCharacter.py and CountMillionCharacter2.0 - Get character count of a text file.xkcd_downloader.py - Download the latest XKCD comic and place them in a new folder called \""comics\"".timymodule.py - An alternative to Python's 'timeit' module and easier to use.calculator.py - Implement a calculator using Python's eval() function.Google_News.py - Use BeautifulSoup to provide latest news headlines along with news links.cricket_live_score - Use BeautifulSoup to provide live cricket scores.youtube.py - Take a song name as input and fetch the YouTube URL of the best matching song and play it.site_health.py - Check the health of a remote server.SimpleStopWatch.py - Simple stop watch implementation using Python's time module.Changemac.py - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).whatsapp-monitor.py - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.whatsapp-chat-analyzer.py - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.JARVIS.py - Control Windows programs with your voice.Images Downloader - Download images from webpages on Unix-based systems.space_invader.py.py - Classical 2D space invader game to recall your childhood memories.Test Case Generator - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.Note: The content in this repository belongs to the respective authors and creators. I'm just providing a formatted README.md for better presentation."
51,AntonOsika/gpt-engineer,https://github.com/AntonOsika/gpt-engineer/blob/main/README.md,Python,"GPT EngineerSpecify what you want it to build, the AI asks for clarification, and then builds it.GPT Engineer is made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt.DemoProject philosophySimple to get valueFlexible and easy to add new own \""AI steps\"". See steps.py.Incrementally build towards a user experience of:high level promptinggiving feedback to the AI that it will remember over timeFast handovers back and forth between AI and humanSimplicity, all computation is \""resumable\"" and persisted to the filesystemUsageChoose either stable or development.For stable release:python -m pip install gpt-engineerFor development:git clone https://github.com/AntonOsika/gpt-engineer.gitcd gpt-engineerpython -m pip install -e .(or: make install && source venv/bin/activate for a venv)API KeyEither just:export OPENAI_API_KEY=[your api key]Or:Create a copy of .env.template named .envAdd your OPENAI_API_KEY in .envCheck the Windows README for windows usage.RunningCreate an empty folder. If inside the repo, you can run:cp -r projects/example/ projects/my-new-projectFill in the prompt file in your new foldergpt-engineer projects/my-new-project(Note, gpt-engineer --help lets you see all available options. For example --steps use_feedback lets you improve/fix code in a project)By running gpt-engineer you agree to our terms.ResultsCheck the generated files in projects/my-new-project/workspaceAlternativesYou can check Docker instructions to use Docker, or simplydo everything in your browser:FeaturesYou can specify the \""identity\"" of the AI agent by editing the files in the preprompts folder.Editing the preprompts, and evolving how you write the project prompt, is how you make the agent remember things between projects.Each step in steps.py will have its communication history with GPT4 stored in the logs folder, and can be rerun with scripts/rerun_edited_message_logs.py.VisionThe gpt-engineer community is building the open platform for devs to tinker with and build their personal code-generation toolbox.If you are interested in contributing to this, we would be interested in having you.If you want to see our broader ambitions, check out the roadmap, and joindiscordto get input on how you can contribute to it.We are currently looking for more maintainers and community organizers. Email anton.osika@gmail.com if you are interested in an official role.Example              Demo.mov          "
52,facebookresearch/Detectron,https://github.com/facebookresearch/Detectron/blob/main/README.md,Python,"Detectron is deprecated. Please see detectron2, a ground-up rewrite of Detectron in PyTorch.DetectronDetectron is Facebook AI Research's software system that implements state-of-the-art object detection algorithms, including Mask R-CNN. It is written in Python and powered by the Caffe2 deep learning framework.At FAIR, Detectron has enabled numerous research projects, including: Feature Pyramid Networks for Object Detection, Mask R-CNN, Detecting and Recognizing Human-Object Interactions, Focal Loss for Dense Object Detection, Non-local Neural Networks, Learning to Segment Every Thing, Data Distillation: Towards Omni-Supervised Learning, DensePose: Dense Human Pose Estimation In The Wild, and Group Normalization.    Example Mask R-CNN output.IntroductionThe goal of Detectron is to provide a high-quality, high-performancecodebase for object detection research. It is designed to be flexible in orderto support rapid implementation and evaluation of novel research. Detectronincludes implementations of the following object detection algorithms:Mask R-CNN -- Marr Prize at ICCV 2017RetinaNet -- Best Student Paper Award at ICCV 2017Faster R-CNNRPNFast R-CNNR-FCNusing the following backbone network architectures:ResNeXt{50,101,152}ResNet{50,101,152}Feature Pyramid Networks (with ResNet/ResNeXt)VGG16Additional backbone architectures may be easily implemented. For more details about these models, please see References below.Update4/2018: Support Group Normalization - see GN/README.mdLicenseDetectron is released under the Apache 2.0 license. See the NOTICE file for additional details.Citing DetectronIf you use Detectron in your research or wish to refer to the baseline results published in the Model Zoo, please use the following BibTeX entry.@misc{Detectron2018,  author =       {Ross Girshick and Ilija Radosavovic and Georgia Gkioxari and                  Piotr Doll\\'{a}r and Kaiming He},  title =        {Detectron},  howpublished = {\\url{https://github.com/facebookresearch/detectron}},  year =         {2018}}Model Zoo and BaselinesWe provide a large set of baseline results and trained models available for download in the Detectron Model Zoo.InstallationPlease find installation instructions for Caffe2 and Detectron in INSTALL.md.Quick Start: Using DetectronAfter installation, please see GETTING_STARTED.md for brief tutorials covering inference and training with Detectron.Getting HelpTo start, please check the troubleshooting section of our installation instructions as well as our FAQ. If you couldn't find help there, try searching our GitHub issues. We intend the issues page to be a forum in which the community collectively troubleshoots problems.If bugs are found, we appreciate pull requests (including adding Q&A's to FAQ.md and improving our installation instructions and troubleshooting documents). Please see CONTRIBUTING.md for more information about contributing to Detectron.ReferencesData Distillation: Towards Omni-Supervised Learning.Ilija Radosavovic, Piotr DollÃ¡r, Ross Girshick, Georgia Gkioxari, and Kaiming He.Tech report, arXiv, Dec. 2017.Learning to Segment Every Thing.Ronghang Hu, Piotr DollÃ¡r, Kaiming He, Trevor Darrell, and Ross Girshick.Tech report, arXiv, Nov. 2017.Non-Local Neural Networks.Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.Tech report, arXiv, Nov. 2017.Mask R-CNN.Kaiming He, Georgia Gkioxari, Piotr DollÃ¡r, and Ross Girshick.IEEE International Conference on Computer Vision (ICCV), 2017.Focal Loss for Dense Object Detection.Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr DollÃ¡r.IEEE International Conference on Computer Vision (ICCV), 2017.Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour.Priya Goyal, Piotr DollÃ¡r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.Tech report, arXiv, June 2017.Detecting and Recognizing Human-Object Interactions.Georgia Gkioxari, Ross Girshick, Piotr DollÃ¡r, and Kaiming He.Tech report, arXiv, Apr. 2017.Feature Pyramid Networks for Object Detection.Tsung-Yi Lin, Piotr DollÃ¡r, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.Aggregated Residual Transformations for Deep Neural Networks.Saining Xie, Ross Girshick, Piotr DollÃ¡r, Zhuowen Tu, and Kaiming He.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.R-FCN: Object Detection via Region-based Fully Convolutional Networks.Jifeng Dai, Yi Li, Kaiming He, and Jian Sun.Conference on Neural Information Processing Systems (NIPS), 2016.Deep Residual Learning for Image Recognition.Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.Faster R-CNN: Towards Real-Time Object Detection with Region Proposal NetworksShaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.Conference on Neural Information Processing Systems (NIPS), 2015.Fast R-CNN.Ross Girshick.IEEE International Conference on Computer Vision (ICCV), 2015."
53,Jack-Cherish/Machine-Learning,https://github.com/Jack-Cherish/Machine-Learning/blob/master/README-eng.md,Python,"Machine-Learningä¸­æ–‡ï¼ˆç®€ä½“ï¼‰Rome was not built in a dayBlogMachine-Learning in Practice (Detailed Comments + Training Datasets), Keep updating!Welcome to my[CSDN Column]Follow me on[Zhihu Column]QQ Group for Communication[328127489]My Website: http://cuijiahua.com/Article DebutDebut articles on my website and forward on orther platforms, click here to get the latest development: http://cuijiahua.com/Chapt. 2: K-Nearest Neighbors AlgorithmArticlePersonal WebsiteCSDNZhihuPython3  study notes (I): K-Nearest Neighbors Algorithm (Gorgeous and Splendid Tutorial)Personal WebsiteCSDNZhihuCode1. Entry Level k-NN2. Miss Helen Dating History3. Digits RecognitionChapt. 3: Decision TreeArticlePersonal WebsiteCSDNZhihuPython3  study notes (II): Decision Tree (Basic Concepts): Let's Start from DatingPersonal WebsiteCSDNZhihuPython3  study notes (III): Decision Tree (In Practice): I'm Looking for a Pair of Contact LensesPersonal WebsiteCSDNZhihuCode1. Loan Prediction2. Contact LensesChapt. 4: Navie BayesArticlePersonal WebsiteCSDNZhihuPython3 Python3  study notes (IV): Navie Bayes (Basic Concepts): Comment FilterPersonal WebsiteCSDNZhihuPython3 Python3  study notes (V): Navie Bayes (In Practice): Catalogues of Sina NewsPersonal WebsiteCSDNZhihuCode1. Comment Filter2. Spam Filter3. News CataloguesChapt. 5: Logistic RegressionArticlePersonal WebsiteCSDNZhihuPython3  study notes (VI): Logistic Regression (Basic Concepts): Gradient Ascent AlgorithmPersonal WebsiteCSDNZhihuPython3  study notes (VII): Logistic Regression (In Practice): Prediction of Horse MortalityPersonal WebsiteCSDNZhihuCode1. Entry Level Exercise for Logistic Regression2. Improved Random Gradient Ascent Algorithm3. Prediction of Horse MortalityChapt. 6: SVM (Support Vector Machine)ArticlePersonal WebsiteCSDNZhihuPython3  study notes (VIII): SVM (Basic Concepts): a Handcraft on Linear SVMPersonal WebsiteCSDNZhihuPython3  study notes (IX): SVM (In Practice): Another Handcraft on Nonlinear SVMPersonal WebsiteCSDNZhihuCode1. Simplified SMO Alogrithm2. Complete SMO Alogrithm3. Nonlinear SVM Alogrithm4. Sklearn SVCChapt. 7: AdaBoostArticlePersonal WebsiteCSDNZhihuPython3  study notes (X): Classifier Sharpener -- AdaBoostPersonal WebsiteCSDNZhihuCode1. Training Process of AdaBoost Based On Decision Stump2. AdaBoost on Hard Datasets3. Implement AdaBoost by sklearn4. ROC Curve PlotChapt. 8: Linear RegressionArticlePersonal WebsiteCSDNZhihuPython3  study notes (XI):Personal WebsiteCSDNZhihuPython3  study notes (XII):Personal WebsitenonoCode1. Linear Regression(Ordinary LR + Locally Weighted LR)2. Predicting the Age of Abalones(Ormers)3. Stepwise Regression4. Predicting the Price of Second Hand LegoChapt. 9: Regression TreeArticlePersonal WebsiteCSDNZhihuPython3  study notes (XIII): Regression Tree (Basic Concepts): CART Alogrithm and PruningPersonal WebsitenonoCode1. Regression Tree"
54,jenkins-docs/simple-python-pyinstaller-app,https://github.com/jenkins-docs/simple-python-pyinstaller-app/blob/master/README.md,Python,"simple-python-pyinstaller-appThis repository is for theBuild a Python app with PyInstallertutorial in the Jenkins User Documentation.The repository contains a simple Python application which is a command line tool \""add2vals\"" that outputs the addition of two values. If at least one of thevalues is a string, \""add2vals\"" treats both values as a string and insteadconcatenates the values. The \""add2\"" function in the \""calc\"" library (which\""add2vals\"" imports) is accompanied by a set of unit tests. These are tested with pytest to check that this function works as expected and the results are savedto a JUnit XML report.The delivery of the \""add2vals\"" tool through PyInstaller converts this tool intoa standalone executable file for Linux, which you can download through Jenkinsand execute at the command line on Linux machines without Python.The jenkins directory contains an example of the Jenkinsfile (i.e. Pipeline)you'll be creating yourself during the tutorial."
55,Turonk/character_creation_module,https://github.com/Turonk/character_creation_module/blob/main/README.md,Python,character_creation_moduleĞœĞ¾Ğ´ÑƒĞ»ÑŒ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶Ğ° Ğ´Ğ»Ñ RPG Ğ¸Ğ³Ñ€Ñ‹
56,yandex-praktikum/calc_and_win,https://github.com/yandex-praktikum/calc_and_win/blob/master/README.md,Python,"calc_and_winĞ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ¸Ğ³Ñ€Ñ‹ \""Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ğ¹ Ğ¸ Ğ¿Ğ¾Ğ±ĞµĞ´Ğ¸!\"""
57,huggingface/pytorch-image-models,https://github.com/huggingface/pytorch-image-models/blob/main/README.md,Python,"PyTorch Image ModelsSponsorsWhat's NewIntroductionModelsFeaturesResultsGetting Started (Documentation)Train, Validation, Inference ScriptsAwesome PyTorch ResourcesLicensesCitingSponsorsThanks to the following for hardware support:TPU Research Cloud (TRC) (https://sites.research.google/trc/about/)Nvidia (https://www.nvidia.com/en-us/)And a big thanks to all GitHub sponsors who helped with some of my costs before I joined Hugging Face.What's Newâ—Updates after Oct 10, 2022 are available in version >= 0.9â—Many changes since the last 0.6.x stable releases. They were previewed in 0.8.x dev releases but not everyone transitioned.timm.models.layers moved to timm.layers:from timm.models.layers import name will still work via deprecation mapping (but please transition to timm.layers).import timm.models.layers.module or from timm.models.layers.module import name needs to be changed now.Builder, helper, non-model modules in timm.models have a _ prefix added, ie timm.models.helpers -> timm.models._helpers, there are temporary deprecation mapping files but those will be removed.All models now support architecture.pretrained_tag naming (ex resnet50.rsb_a1).The pretrained_tag is the specific weight variant (different head) for the architecture.Using only architecture defaults to the first weights in the default_cfgs for that model architecture.In adding pretrained tags, many model names that existed to differentiate were renamed to use the tag  (ex: vit_base_patch16_224_in21k -> vit_base_patch16_224.augreg_in21k). There are deprecation mappings for these.A number of models had their checkpoints remaped to match architecture changes needed to better support features_only=True, there are checkpoint_filter_fn methods in any model module that was remapped. These can be passed to timm.models.load_checkpoint(..., filter_fn=timm.models.swin_transformer_v2.checkpoint_filter_fn) to remap your existing checkpoint.The Hugging Face Hub (https://huggingface.co/timm) is now the primary source for timm weights. Model cards include link to papers, original source, license.Previous 0.6.x can be cloned from 0.6.x branch or installed via pip with version.Aug 3, 2023Add GluonCV weights for HRNet w18_small and w18_small_v2. Converted by SeeFunFix selecsls* model naming regressionPatch and position embedding for ViT/EVA works for bfloat16/float16 weights on load (or activations for on-the-fly resize)v0.9.5 release prepJuly 27, 2023Added timm trained seresnextaa201d_32x8d.sw_in12k_ft_in1k_384 weights (and .sw_in12k pretrain) with 87.3% top-1 on ImageNet-1k, best ImageNet ResNet family model I'm aware of.RepViT model and weights (https://arxiv.org/abs/2307.09283) added by wangaoI-JEPA ViT feature weights (no classifier) added by SeeFunSAM-ViT (segment anything) feature weights (no classifier) added by SeeFunAdd support for alternative feat extraction methods and -ve indices to EfficientNetAdd NAdamW optimizerMisc fixesMay 11, 2023timm 0.9 released, transition from 0.8.xdev releasesMay 10, 2023Hugging Face Hub downloading is now default, 1132 models on https://huggingface.co/timm, 1163 weights in timmDINOv2 vit feature backbone weights added thanks to Leng YueFB MAE vit feature backbone weights addedOpenCLIP DataComp-XL L/14 feat backbone weights addedMetaFormer (poolformer-v2, caformer, convformer, updated poolformer (v1)) w/ weights added by Fredo GuanExperimental get_intermediate_layers function on vit/deit models for grabbing hidden states (inspired by DINO impl). This is WIP and may change significantly... feedback welcome.Model creation throws error if pretrained=True and no weights exist (instead of continuing with random initialization)Fix regression with inception / nasnet TF sourced weights with 1001 classes in original classifiersbitsandbytes (https://github.com/TimDettmers/bitsandbytes) optimizers added to factory, use bnb prefix, ie bnbadam8bitMisc cleanup and fixesFinal testing before switching to a 0.9 and bringing timm out of pre-release stateApril 27, 202397% of timm models uploaded to HF Hub and almost all updated to support multi-weight pretrained configsMinor cleanup and refactoring of another batch of models as multi-weight added. More fused_attn (F.sdpa) and features_only support, and torchscript fixes.April 21, 2023Gradient accumulation support added to train script and tested (--grad-accum-steps), thanks Taeksang KimMore weights on HF Hub (cspnet, cait, volo, xcit, tresnet, hardcorenas, densenet, dpn, vovnet, xception_aligned)Added --head-init-scale and --head-init-bias to train.py to scale classiifer head and set fixed bias for fine-tuneRemove all InplaceABN (inplace_abn) use, replaced use in tresnet with standard BatchNorm (modified weights accordingly).April 12, 2023Add ONNX export script, validate script, helpers that I've had kicking around for along time. Tweak 'same' padding for better export w/ recent ONNX + pytorch.Refactor dropout args for vit and vit-like models, separate drop_rate into drop_rate (classifier dropout), proj_drop_rate (block mlp / out projections), pos_drop_rate (position embedding drop), attn_drop_rate (attention dropout). Also add patch dropout (FLIP) to vit and eva models.fused F.scaled_dot_product_attention support to more vit models, add env var (TIMM_FUSED_ATTN) to control, and config interface to enable/disableAdd EVA-CLIP backbones w/ image tower weights, all the way up to 4B param 'enormous' model, and 336x336 OpenAI ViT mode that was missed.April 5, 2023ALL ResNet models pushed to Hugging Face Hub with multi-weight supportAll past timm trained weights added with recipe based tags to differentiateAll ResNet strikes back A1/A2/A3 (seed 0) and R50 example B/C1/C2/D weights availableAdd torchvision v2 recipe weights to existing torchvision originalsSee comparison table in https://huggingface.co/timm/seresnextaa101d_32x8d.sw_in12k_ft_in1k_288#model-comparisonNew ImageNet-12k + ImageNet-1k fine-tunes available for a few anti-aliased ResNet modelsresnetaa50d.sw_in12k_ft_in1k - 81.7 @ 224, 82.6 @ 288resnetaa101d.sw_in12k_ft_in1k - 83.5 @ 224, 84.1 @ 288seresnextaa101d_32x8d.sw_in12k_ft_in1k - 86.0 @ 224, 86.5 @ 288seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 - 86.5 @ 288, 86.7 @ 320March 31, 2023Add first ConvNext-XXLarge CLIP -> IN-1k fine-tune and IN-12k intermediate fine-tunes for convnext-base/large CLIP models.modeltop1top5img_sizeparam_countgmacsmactsconvnext_xxlarge.clip_laion2b_soup_ft_in1k88.61298.704256846.47198.09124.45convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_38488.31298.578384200.13101.11126.74convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_32087.96898.47320200.1370.2188.02convnext_base.clip_laion2b_augreg_ft_in12k_in1k_38487.13898.21238488.5945.2184.49convnext_base.clip_laion2b_augreg_ft_in12k_in1k86.34497.9725688.5920.0937.55Add EVA-02 MIM pretrained and fine-tuned weights, push to HF hub and update model cards for all EVA models. First model over 90% top-1 (99% top-5)! Check out the original code & weights at https://github.com/baaivision/EVA for more details on their work blending MIM, CLIP w/ many model, dataset, and train recipe tweaks.modeltop1top5param_countimg_sizeeva02_large_patch14_448.mim_m38m_ft_in22k_in1k90.05499.042305.08448eva02_large_patch14_448.mim_in22k_ft_in22k_in1k89.94699.01305.08448eva_giant_patch14_560.m30m_ft_in22k_in1k89.79298.9921014.45560eva02_large_patch14_448.mim_in22k_ft_in1k89.62698.954305.08448eva02_large_patch14_448.mim_m38m_ft_in1k89.5798.918305.08448eva_giant_patch14_336.m30m_ft_in22k_in1k89.5698.9561013.01336eva_giant_patch14_336.clip_ft_in1k89.46698.821013.01336eva_large_patch14_336.in22k_ft_in22k_in1k89.21498.854304.53336eva_giant_patch14_224.clip_ft_in1k88.88298.6781012.56224eva02_base_patch14_448.mim_in22k_ft_in22k_in1k88.69298.72287.12448eva_large_patch14_336.in22k_ft_in1k88.65298.722304.53336eva_large_patch14_196.in22k_ft_in22k_in1k88.59298.656304.14196eva02_base_patch14_448.mim_in22k_ft_in1k88.2398.56487.12448eva_large_patch14_196.in22k_ft_in1k87.93498.504304.14196eva02_small_patch14_336.mim_in22k_ft_in1k85.7497.61422.13336eva02_tiny_patch14_336.mim_in22k_ft_in1k80.65895.5245.76336Multi-weight and HF hub for DeiT and MLP-Mixer based modelsMarch 22, 2023More weights pushed to HF hub along with multi-weight support, including: regnet.py, rexnet.py, byobnet.py, resnetv2.py, swin_transformer.py, swin_transformer_v2.py, swin_transformer_v2_cr.pySwin Transformer models support feature extraction (NCHW feat maps for swinv2_cr_*, and NHWC for all others) and spatial embedding outputs.FocalNet (from https://github.com/microsoft/FocalNet) models and weights added with significant refactoring, feature extraction, no fixed resolution / sizing constraintRegNet weights increased with HF hub push, SWAG, SEER, and torchvision v2 weights. SEER is pretty poor wrt to performance for model size, but possibly useful.More ImageNet-12k pretrained and 1k fine-tuned timm weights:rexnetr_200.sw_in12k_ft_in1k - 82.6 @ 224, 83.2 @ 288rexnetr_300.sw_in12k_ft_in1k - 84.0 @ 224, 84.5 @ 288regnety_120.sw_in12k_ft_in1k - 85.0 @ 224, 85.4 @ 288regnety_160.lion_in12k_ft_in1k - 85.6 @ 224, 86.0 @ 288regnety_160.sw_in12k_ft_in1k - 85.6 @ 224, 86.0 @ 288  (compare to SWAG PT + 1k FT this is same BUT much lower res, blows SEER FT away)Model name deprecation + remapping functionality added (a milestone for bringing 0.8.x out of pre-release). Mappings being added...Minor bug fixes and improvements.Feb 26, 2023Add ConvNeXt-XXLarge CLIP pretrained image tower weights for fine-tune & features (fine-tuning TBD) -- see model cardUpdate convnext_xxlarge default LayerNorm eps to 1e-5 (for CLIP weights, improved stability)0.8.15dev0Feb 20, 2023Add 320x320 convnext_large_mlp.clip_laion2b_ft_320 and convnext_lage_mlp.clip_laion2b_ft_soup_320 CLIP image tower weights for features & fine-tune0.8.13dev0 pypi release for latest changes w/ move to huggingface orgFeb 16, 2023safetensor checkpoint support addedAdd ideas from 'Scaling Vision Transformers to 22 B. Params' (https://arxiv.org/abs/2302.05442) -- qk norm, RmsNorm, parallel blockAdd F.scaled_dot_product_attention support (PyTorch 2.0 only) to vit_*, vit_relpos*, coatnet / maxxvit (to start)Lion optimizer (w/ multi-tensor option) added (https://arxiv.org/abs/2302.06675)gradient checkpointing works with features_only=TrueFeb 7, 2023New inference benchmark numbers added in results folder.Add convnext LAION CLIP trained weights and initial set of in1k fine-tunesconvnext_base.clip_laion2b_augreg_ft_in1k - 86.2% @ 256x256convnext_base.clip_laiona_augreg_ft_in1k_384 - 86.5% @ 384x384convnext_large_mlp.clip_laion2b_augreg_ft_in1k - 87.3% @ 256x256convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 - 87.9% @ 384x384Add DaViT models. Supports features_only=True. Adapted from https://github.com/dingmyu/davit by Fredo.Use a common NormMlpClassifierHead across MaxViT, ConvNeXt, DaViTAdd EfficientFormer-V2 model, update EfficientFormer, and refactor LeViT (closely related architectures). Weights on HF hub.New EfficientFormer-V2 arch, significant refactor from original at (https://github.com/snap-research/EfficientFormer). Supports features_only=True.Minor updates to EfficientFormer.Refactor LeViT models to stages, add features_only=True support to new conv variants, weight remap required.Move ImageNet meta-data (synsets, indices) from /results to timm/data/_info.Add ImageNetInfo / DatasetInfo classes to provide labelling for various ImageNet classifier layouts in timmUpdate inference.py to use, try: python inference.py /folder/to/images --model convnext_small.in12k --label-type detail --topk 5Ready for 0.8.10 pypi pre-release (final testing).Jan 20, 2023Add two convnext 12k -> 1k fine-tunes at 384x384convnext_tiny.in12k_ft_in1k_384 - 85.1 @ 384convnext_small.in12k_ft_in1k_384 - 86.2 @ 384Push all MaxxViT weights to HF hub, and add new ImageNet-12k -> 1k fine-tunes for rw base MaxViT and CoAtNet 1/2 modelsmodeltop1top5samples / secParams (M)GMACAct (M)maxvit_xlarge_tf_512.in21k_ft_in1k88.5398.6421.76475.77534.141413.22maxvit_xlarge_tf_384.in21k_ft_in1k88.3298.5442.53475.32292.78668.76maxvit_base_tf_512.in21k_ft_in1k88.2098.5350.87119.88138.02703.99maxvit_large_tf_512.in21k_ft_in1k88.0498.4036.42212.33244.75942.15maxvit_large_tf_384.in21k_ft_in1k87.9898.5671.75212.03132.55445.84maxvit_base_tf_384.in21k_ft_in1k87.9298.54104.71119.6573.80332.90maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k87.8198.37106.55116.1470.97318.95maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k87.4798.37149.49116.0972.98213.74coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k87.3998.31160.8073.8847.69209.43maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k86.8998.02375.86116.1423.1592.64maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k86.6498.02501.03116.0924.2062.77maxvit_base_tf_512.in1k86.6097.9250.75119.88138.02703.99coatnet_2_rw_224.sw_in12k_ft_in1k86.5797.89631.8873.8715.0949.22maxvit_large_tf_512.in1k86.5297.8836.04212.33244.75942.15coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k86.4997.90620.5873.8815.1854.78maxvit_base_tf_384.in1k86.2997.80101.09119.6573.80332.90maxvit_large_tf_384.in1k86.2397.6970.56212.03132.55445.84maxvit_small_tf_512.in1k86.1097.7688.6369.1367.26383.77maxvit_tiny_tf_512.in1k85.6797.58144.2531.0533.49257.59maxvit_small_tf_384.in1k85.5497.46188.3569.0235.87183.65maxvit_tiny_tf_384.in1k85.1197.38293.4630.9817.53123.42maxvit_large_tf_224.in1k84.9396.97247.71211.7943.68127.35coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k84.9096.961025.4541.728.1140.13maxvit_base_tf_224.in1k84.8596.99358.25119.4724.0495.01maxxvit_rmlp_small_rw_256.sw_in1k84.6397.06575.5366.0114.6758.38coatnet_rmlp_2_rw_224.sw_in1k84.6196.74625.8173.8815.1854.78maxvit_rmlp_small_rw_224.sw_in1k84.4996.76693.8264.9010.7549.30maxvit_small_tf_224.in1k84.4396.83647.9668.9311.6653.17maxvit_rmlp_tiny_rw_256.sw_in1k84.2396.78807.2129.156.7746.92coatnet_1_rw_224.sw_in1k83.6296.38989.5941.728.0434.60maxvit_tiny_rw_224.sw_in1k83.5096.501100.5329.065.1133.11maxvit_tiny_tf_224.in1k83.4196.591004.9430.925.6035.78coatnet_rmlp_1_rw_224.sw_in1k83.3696.451093.0341.697.8535.47maxxvitv2_nano_rw_256.sw_in1k83.1196.331276.8823.706.2623.05maxxvit_rmlp_nano_rw_256.sw_in1k83.0396.341341.2416.784.3726.05maxvit_rmlp_nano_rw_256.sw_in1k82.9696.261283.2415.504.4731.92maxvit_nano_rw_256.sw_in1k82.9396.231218.1715.454.4630.28coatnet_bn_0_rw_224.sw_in1k82.3996.191600.1427.444.6722.04coatnet_0_rw_224.sw_in1k82.3995.841831.2127.444.4318.73coatnet_rmlp_nano_rw_224.sw_in1k82.0595.872109.0915.152.6220.34coatnext_nano_rw_224.sw_in1k81.9595.922525.5214.702.4712.80coatnet_nano_rw_224.sw_in1k81.7095.642344.5215.142.4115.41maxvit_rmlp_pico_rw_256.sw_in1k80.5395.211594.717.521.8524.86Jan 11, 2023Update ConvNeXt ImageNet-12k pretrain series w/ two new fine-tuned weights (and pre FT .in12k tags)convnext_nano.in12k_ft_in1k - 82.3 @ 224, 82.9 @ 288  (previously released)convnext_tiny.in12k_ft_in1k - 84.2 @ 224, 84.5 @ 288convnext_small.in12k_ft_in1k - 85.2 @ 224, 85.3 @ 288Jan 6, 2023Finally got around to adding --model-kwargs and --opt-kwargs to scripts to pass through rare args directly to model classes from cmd linetrain.py /imagenet --model resnet50 --amp --model-kwargs output_stride=16 act_layer=silutrain.py /imagenet --model vit_base_patch16_clip_224 --img-size 240 --amp --model-kwargs img_size=240 patch_size=12Cleanup some popular models to better support arg passthrough / merge with model configs, more to go.Jan 5, 2023ConvNeXt-V2 models and weights added to existing convnext.pyPaper: ConvNeXt V2: Co-designing and Scaling ConvNets with Masked AutoencodersReference impl: https://github.com/facebookresearch/ConvNeXt-V2 (NOTE: weights currently CC-BY-NC)Dec 23, 2022 ğŸ„â˜ƒAdd FlexiViT models and weights from https://github.com/google-research/big_vision (check out paper at https://arxiv.org/abs/2212.08013)NOTE currently resizing is static on model creation, on-the-fly dynamic / train patch size sampling is a WIPMany more models updated to multi-weight and downloadable via HF hub now (convnext, efficientnet, mobilenet, vision_transformer*, beit)More model pretrained tag and adjustments, some model names changed (working on deprecation translations, consider main branch DEV branch right now, use 0.6.x for stable use)More ImageNet-12k (subset of 22k) pretrain models popping up:efficientnet_b5.in12k_ft_in1k - 85.9 @ 448x448vit_medium_patch16_gap_384.in12k_ft_in1k - 85.5 @ 384x384vit_medium_patch16_gap_256.in12k_ft_in1k - 84.5 @ 256x256convnext_nano.in12k_ft_in1k - 82.9 @ 288x288Dec 8, 2022Add 'EVA l' to vision_transformer.py, MAE style ViT-L/14 MIM pretrain w/ EVA-CLIP targets, FT on ImageNet-1k (w/ ImageNet-22k intermediate for some)original source: https://github.com/baaivision/EVAmodeltop1param_countgmacmactshubeva_large_patch14_336.in22k_ft_in22k_in1k89.2304.5191.1270.2linkeva_large_patch14_336.in22k_ft_in1k88.7304.5191.1270.2linkeva_large_patch14_196.in22k_ft_in22k_in1k88.6304.161.663.5linkeva_large_patch14_196.in22k_ft_in1k87.9304.161.663.5linkDec 6, 2022Add 'EVA g', BEiT style ViT-g/14 model weights w/ both MIM pretrain and CLIP pretrain to beit.py.original source: https://github.com/baaivision/EVApaper: https://arxiv.org/abs/2211.07636modeltop1param_countgmacmactshubeva_giant_patch14_560.m30m_ft_in22k_in1k89.81014.41906.82577.2linkeva_giant_patch14_336.m30m_ft_in22k_in1k89.61013620.6550.7linkeva_giant_patch14_336.clip_ft_in1k89.41013620.6550.7linkeva_giant_patch14_224.clip_ft_in1k89.11012.6267.2192.6linkDec 5, 2022Pre-release (0.8.0dev0) of multi-weight support (model_arch.pretrained_tag). Install with pip install --pre timmvision_transformer, maxvit, convnext are the first three model impl w/ supportmodel names are changing with this (previous _21k, etc. fn will merge), still sorting out deprecation handlingbugs are likely, but I need feedback so please try it outif stability is needed, please use 0.6.x pypi releases or clone from 0.6.x branchSupport for PyTorch 2.0 compile is added in train/validate/inference/benchmark, use --torchcompile argumentInference script allows more control over output, select k for top-class index + prob json, csv or parquet outputAdd a full set of fine-tuned CLIP image tower weights from both LAION-2B and original OpenAI CLIP modelsmodeltop1param_countgmacmactshubvit_huge_patch14_clip_336.laion2b_ft_in12k_in1k88.6632.5391407.5linkvit_large_patch14_clip_336.openai_ft_in12k_in1k88.3304.5191.1270.2linkvit_huge_patch14_clip_224.laion2b_ft_in12k_in1k88.2632167.4139.4linkvit_large_patch14_clip_336.laion2b_ft_in12k_in1k88.2304.5191.1270.2linkvit_large_patch14_clip_224.openai_ft_in12k_in1k88.2304.281.188.8linkvit_large_patch14_clip_224.laion2b_ft_in12k_in1k87.9304.281.188.8linkvit_large_patch14_clip_224.openai_ft_in1k87.9304.281.188.8linkvit_large_patch14_clip_336.laion2b_ft_in1k87.9304.5191.1270.2linkvit_huge_patch14_clip_224.laion2b_ft_in1k87.6632167.4139.4linkvit_large_patch14_clip_224.laion2b_ft_in1k87.3304.281.188.8linkvit_base_patch16_clip_384.laion2b_ft_in12k_in1k87.286.955.5101.6linkvit_base_patch16_clip_384.openai_ft_in12k_in1k8786.955.5101.6linkvit_base_patch16_clip_384.laion2b_ft_in1k86.686.955.5101.6linkvit_base_patch16_clip_384.openai_ft_in1k86.286.955.5101.6linkvit_base_patch16_clip_224.laion2b_ft_in12k_in1k86.286.617.623.9linkvit_base_patch16_clip_224.openai_ft_in12k_in1k85.986.617.623.9linkvit_base_patch32_clip_448.laion2b_ft_in12k_in1k85.888.317.923.9linkvit_base_patch16_clip_224.laion2b_ft_in1k85.586.617.623.9linkvit_base_patch32_clip_384.laion2b_ft_in12k_in1k85.488.313.116.5linkvit_base_patch16_clip_224.openai_ft_in1k85.386.617.623.9linkvit_base_patch32_clip_384.openai_ft_in12k_in1k85.288.313.116.5linkvit_base_patch32_clip_224.laion2b_ft_in12k_in1k83.388.24.45linkvit_base_patch32_clip_224.laion2b_ft_in1k82.688.24.45linkvit_base_patch32_clip_224.openai_ft_in1k81.988.24.45linkPort of MaxViT Tensorflow Weights from official impl at https://github.com/google-research/maxvitThere was larger than expected drops for the upscaled 384/512 in21k fine-tune weights, possible detail missing, but the 21k FT did seem sensitive to small preprocessingmodeltop1param_countgmacmactshubmaxvit_xlarge_tf_512.in21k_ft_in1k88.5475.8534.11413.2linkmaxvit_xlarge_tf_384.in21k_ft_in1k88.3475.3292.8668.8linkmaxvit_base_tf_512.in21k_ft_in1k88.2119.9138704linkmaxvit_large_tf_512.in21k_ft_in1k88212.3244.8942.2linkmaxvit_large_tf_384.in21k_ft_in1k88212132.6445.8linkmaxvit_base_tf_384.in21k_ft_in1k87.9119.673.8332.9linkmaxvit_base_tf_512.in1k86.6119.9138704linkmaxvit_large_tf_512.in1k86.5212.3244.8942.2linkmaxvit_base_tf_384.in1k86.3119.673.8332.9linkmaxvit_large_tf_384.in1k86.2212132.6445.8linkmaxvit_small_tf_512.in1k86.169.167.3383.8linkmaxvit_tiny_tf_512.in1k85.73133.5257.6linkmaxvit_small_tf_384.in1k85.56935.9183.6linkmaxvit_tiny_tf_384.in1k85.13117.5123.4linkmaxvit_large_tf_224.in1k84.9211.843.7127.4linkmaxvit_base_tf_224.in1k84.9119.52495linkmaxvit_small_tf_224.in1k84.468.911.753.2linkmaxvit_tiny_tf_224.in1k83.430.95.635.8linkOct 15, 2022Train and validation script enhancementsNon-GPU (ie CPU) device supportSLURM compatibility for train scriptHF datasets support (via ReaderHfds)TFDS/WDS dataloading improvements (sample padding/wrap for distributed use fixed wrt sample count estimate)in_chans !=3 support for scripts / loaderAdan optimizerCan enable per-step LR scheduling via argsDataset 'parsers' renamed to 'readers', more descriptive of purposeAMP args changed, APEX via --amp-impl apex, bfloat16 supportedf via --amp-dtype bfloat16main branch switched to 0.7.x version, 0.6x forked for stable release of weight only addsmaster -> main branch renameOct 10, 2022More weights in maxxvit series, incl first ConvNeXt block based coatnext and maxxvit experiments:coatnext_nano_rw_224 - 82.0 @ 224 (G) -- (uses ConvNeXt conv block, no BatchNorm)maxxvit_rmlp_nano_rw_256 - 83.0 @ 256, 83.7 @ 320  (G) (uses ConvNeXt conv block, no BN)maxvit_rmlp_small_rw_224 - 84.5 @ 224, 85.1 @ 320 (G)maxxvit_rmlp_small_rw_256 - 84.6 @ 256, 84.9 @ 288 (G) -- could be trained better, hparams need tuning (uses ConvNeXt block, no BN)coatnet_rmlp_2_rw_224 - 84.6 @ 224, 85 @ 320  (T)NOTE: official MaxVit weights (in1k) have been released at https://github.com/google-research/maxvit -- some extra work is needed to port and adapt since my impl was created independently of theirs and has a few small differences + the whole TF same padding fun.Sept 23, 2022LAION-2B CLIP image towers supported as pretrained backbones for fine-tune or features (no classifier)vit_base_patch32_224_clip_laion2bvit_large_patch14_224_clip_laion2bvit_huge_patch14_224_clip_laion2bvit_giant_patch14_224_clip_laion2bSept 7, 2022Hugging Face timm docs home now exists, look for more here in the futureAdd BEiT-v2 weights for base and large 224x224 models from https://github.com/microsoft/unilm/tree/master/beit2Add more weights in maxxvit series incl a pico (7.5M params, 1.9 GMACs), two tiny variants:maxvit_rmlp_pico_rw_256 - 80.5 @ 256, 81.3 @ 320  (T)maxvit_tiny_rw_224 - 83.5 @ 224 (G)maxvit_rmlp_tiny_rw_256 - 84.2 @ 256, 84.8 @ 320 (T)Aug 29, 2022MaxVit window size scales with img_size by default. Add new RelPosMlp MaxViT weight that leverages this:maxvit_rmlp_nano_rw_256 - 83.0 @ 256, 83.6 @ 320  (T)Aug 26, 2022CoAtNet (https://arxiv.org/abs/2106.04803) and MaxVit (https://arxiv.org/abs/2204.01697) timm original modelsboth found in maxxvit.py model def, contains numerous experiments outside scope of original papersan unfinished Tensorflow version from MaxVit authors can be found https://github.com/google-research/maxvitInitial CoAtNet and MaxVit timm pretrained weights (working on more):coatnet_nano_rw_224 - 81.7 @ 224  (T)coatnet_rmlp_nano_rw_224 - 82.0 @ 224, 82.8 @ 320 (T)coatnet_0_rw_224 - 82.4  (T)  -- NOTE timm '0' coatnets have 2 more 3rd stage blockscoatnet_bn_0_rw_224 - 82.4  (T)maxvit_nano_rw_256 - 82.9 @ 256  (T)coatnet_rmlp_1_rw_224 - 83.4 @ 224, 84 @ 320  (T)coatnet_1_rw_224 - 83.6 @ 224 (G)(T) = TPU trained with bits_and_tpu branch training code, (G) = GPU trainedGCVit (weights adapted from https://github.com/NVlabs/GCVit, code 100% timm re-write for license purposes)MViT-V2 (multi-scale vit, adapted from https://github.com/facebookresearch/mvit)EfficientFormer (adapted from https://github.com/snap-research/EfficientFormer)PyramidVisionTransformer-V2 (adapted from https://github.com/whai362/PVT)'Fast Norm' support for LayerNorm and GroupNorm that avoids float32 upcast w/ AMP (uses APEX LN if available for further boost)Aug 15, 2022ConvNeXt atto weights addedconvnext_atto - 75.7 @ 224, 77.0 @ 288convnext_atto_ols - 75.9  @ 224, 77.2 @ 288Aug 5, 2022More custom ConvNeXt smaller model defs with weightsconvnext_femto - 77.5 @ 224, 78.7 @ 288convnext_femto_ols - 77.9  @ 224, 78.9 @ 288convnext_pico - 79.5 @ 224, 80.4 @ 288convnext_pico_ols - 79.5 @ 224, 80.5 @ 288convnext_nano_ols - 80.9 @ 224, 81.6 @ 288Updated EdgeNeXt to improve ONNX export, add new base variant and weights from original (https://github.com/mmaaz60/EdgeNeXt)July 28, 2022Add freshly minted DeiT-III Medium (width=512, depth=12, num_heads=8) model weights. Thanks Hugo Touvron!July 27, 2022All runtime benchmark and validation result csv files are finally up-to-date!A few more weights & model defs added:darknetaa53 -  79.8 @ 256, 80.5 @ 288convnext_nano - 80.8 @ 224, 81.5 @ 288cs3sedarknet_l - 81.2 @ 256, 81.8 @ 288cs3darknet_x - 81.8 @ 256, 82.2 @ 288cs3sedarknet_x - 82.2 @ 256, 82.7 @ 288cs3edgenet_x - 82.2 @ 256, 82.7 @ 288cs3se_edgenet_x - 82.8 @ 256, 83.5 @ 320cs3* weights above all trained on TPU w/ bits_and_tpu branch. Thanks to TRC program!Add output_stride=8 and 16 support to ConvNeXt (dilation)deit3 models not being able to resize pos_emb fixedVersion 0.6.7 PyPi release (/w above bug fixes and new weighs since 0.6.5)July 8, 2022More models, more fixesOfficial research models (w/ weights) added:EdgeNeXt from (https://github.com/mmaaz60/EdgeNeXt)MobileViT-V2 from (https://github.com/apple/ml-cvnets)DeiT III (Revenge of the ViT) from (https://github.com/facebookresearch/deit)My own models:Small ResNet defs added by request with 1 block repeats for both basic and bottleneck (resnet10 and resnet14)CspNet refactored with dataclass config, simplified CrossStage3 (cs3) option. These are closer to YOLO-v5+ backbone defs.More relative position vit fiddling. Two srelpos (shared relative position) models trained, and a medium w/ class token.Add an alternate downsample mode to EdgeNeXt and train a small model. Better than original small, but not their new USI trained weights.My own model weight results (all ImageNet-1k training)resnet10t - 66.5 @ 176, 68.3 @ 224resnet14t - 71.3 @ 176, 72.3 @ 224resnetaa50 - 80.6 @ 224 , 81.6 @ 288darknet53 -  80.0 @ 256, 80.5 @ 288cs3darknet_m - 77.0 @ 256, 77.6 @ 288cs3darknet_focus_m - 76.7 @ 256, 77.3 @ 288cs3darknet_l - 80.4 @ 256, 80.9 @ 288cs3darknet_focus_l - 80.3 @ 256, 80.9 @ 288vit_srelpos_small_patch16_224 - 81.1 @ 224, 82.1 @ 320vit_srelpos_medium_patch16_224 - 82.3 @ 224, 83.1 @ 320vit_relpos_small_patch16_cls_224 - 82.6 @ 224, 83.6 @ 320edgnext_small_rw - 79.6 @ 224, 80.4 @ 320cs3, darknet, and vit_*relpos weights above all trained on TPU thanks to TRC program! Rest trained on overheating GPUs.Hugging Face Hub support fixes verified, demo notebook TBAPretrained weights / configs can be loaded externally (ie from local disk) w/ support for head adaptation.Add support to change image extensions scanned by timm datasets/readers. See (#1274 (comment))Default ConvNeXt LayerNorm impl to use F.layer_norm(x.permute(0, 2, 3, 1), ...).permute(0, 3, 1, 2) via LayerNorm2d in all cases.a bit slower than previous custom impl on some hardware (ie Ampere w/ CL), but overall fewer regressions across wider HW / PyTorch version ranges.previous impl exists as LayerNormExp2d in models/layers/norm.pyNumerous bug fixesCurrently testing for imminent PyPi 0.6.x releaseLeViT pretraining of larger models still a WIP, they don't train well / easily without distillation. Time to add distill support (finally)?ImageNet-22k weight training + finetune ongoing, work on multi-weight support (slowly) chugging along (there are a LOT of weights, sigh) ...May 13, 2022Official Swin-V2 models and weights added from (https://github.com/microsoft/Swin-Transformer). Cleaned up to support torchscript.Some refactoring for existing timm Swin-V2-CR impl, will likely do a bit more to bring parts closer to official and decide whether to merge some aspects.More Vision Transformer relative position / residual post-norm experiments (all trained on TPU thanks to TRC program)vit_relpos_small_patch16_224 - 81.5 @ 224, 82.5 @ 320 -- rel pos, layer scale, no class token, avg poolvit_relpos_medium_patch16_rpn_224 - 82.3 @ 224, 83.1 @ 320 -- rel pos + res-post-norm, no class token, avg poolvit_relpos_medium_patch16_224 - 82.5 @ 224, 83.3 @ 320 -- rel pos, layer scale, no class token, avg poolvit_relpos_base_patch16_gapcls_224 - 82.8 @ 224, 83.9 @ 320 -- rel pos, layer scale, class token, avg pool (by mistake)Bring 512 dim, 8-head 'medium' ViT model variant back to life (after using in a pre DeiT 'small' model for first ViT impl back in 2020)Add ViT relative position support for switching btw existing impl and some additions in official Swin-V2 impl for future trialsSequencer2D impl (https://arxiv.org/abs/2205.01972), added via PR from author (https://github.com/okojoalg)May 2, 2022Vision Transformer experiments adding Relative Position (Swin-V2 log-coord) (vision_transformer_relpos.py) and Residual Post-Norm branches (from Swin-V2) (vision_transformer*.py)vit_relpos_base_patch32_plus_rpn_256 - 79.5 @ 256, 80.6 @ 320 -- rel pos + extended width + res-post-norm, no class token, avg poolvit_relpos_base_patch16_224 - 82.5 @ 224, 83.6 @ 320 -- rel pos, layer scale, no class token, avg poolvit_base_patch16_rpn_224 - 82.3 @ 224 -- rel pos + res-post-norm, no class token, avg poolVision Transformer refactor to remove representation layer that was only used in initial vit and rarely used since with newer pretrain (ie How to Train Your ViT)vit_* models support removal of class token, use of global average pool, use of fc_norm (ala beit, mae).April 22, 2022timm models are now officially supported in fast.ai! Just in time for the new Practical Deep Learning course. timmdocs documentation link updated to timm.fast.ai.Two more model weights added in the TPU trained series. Some In22k pretrain still in progress.seresnext101d_32x8d - 83.69 @ 224, 84.35 @ 288seresnextaa101d_32x8d (anti-aliased w/ AvgPool2d) - 83.85 @ 224, 84.57 @ 288March 23, 2022Add ParallelBlock and LayerScale option to base vit models to support model configs in Three things everyone should know about ViTconvnext_tiny_hnf (head norm first) weights trained with (close to) A2 recipe, 82.2% top-1, could do better with more epochs.March 21, 2022Merge norm_norm_norm. IMPORTANT this update for a coming 0.6.x release will likely de-stabilize the master branch for a while. Branch 0.5.x or a previous 0.5.x release can be used if stability is required.Significant weights update (all TPU trained) as described in this releaseregnety_040 - 82.3 @ 224, 82.96 @ 288regnety_064 - 83.0 @ 224, 83.65 @ 288regnety_080 - 83.17 @ 224, 83.86 @ 288regnetv_040 - 82.44 @ 224, 83.18 @ 288   (timm pre-act)regnetv_064 - 83.1 @ 224, 83.71 @ 288   (timm pre-act)regnetz_040 - 83.67 @ 256, 84.25 @ 320regnetz_040h - 83.77 @ 256, 84.5 @ 320 (w/ extra fc in head)resnetv2_50d_gn - 80.8 @ 224, 81.96 @ 288 (pre-act GroupNorm)resnetv2_50d_evos 80.77 @ 224, 82.04 @ 288 (pre-act EvoNormS)regnetz_c16_evos  - 81.9 @ 256, 82.64 @ 320 (EvoNormS)regnetz_d8_evos  - 83.42 @ 256, 84.04 @ 320 (EvoNormS)xception41p - 82 @ 299   (timm pre-act)xception65 -  83.17 @ 299xception65p -  83.14 @ 299   (timm pre-act)resnext101_64x4d - 82.46 @ 224, 83.16 @ 288seresnext101_32x8d - 83.57 @ 224, 84.270 @ 288resnetrs200 - 83.85 @ 256, 84.44 @ 320HuggingFace hub support fixed w/ initial groundwork for allowing alternative 'config sources' for pretrained model definitions and weights (generic local file / remote url support soon)SwinTransformer-V2 implementation added. Submitted by Christoph Reich. Training experiments and model changes by myself are ongoing so expect compat breaks.Swin-S3 (AutoFormerV2) models / weights added from https://github.com/microsoft/Cream/tree/main/AutoFormerV2MobileViT models w/ weights adapted from https://github.com/apple/ml-cvnetsPoolFormer models w/ weights adapted from https://github.com/sail-sg/poolformerVOLO models w/ weights adapted from https://github.com/sail-sg/voloSignificant work experimenting with non-BatchNorm norm layers such as EvoNorm, FilterResponseNorm, GroupNorm, etcEnhance support for alternate norm + act ('NormAct') layers added to a number of models, esp EfficientNet/MobileNetV3, RegNet, and aligned XceptionGrouped conv support added to EfficientNet familyAdd 'group matching' API to all models to allow grouping model parameters for application of 'layer-wise' LR decay, lr scale added to LR schedulerGradient checkpointing support added to many modelsforward_head(x, pre_logits=False) fn added to all models to allow separate calls of forward_features + forward_headAll vision transformer and vision MLP models update to return non-pooled / non-token selected features from foward_features, for consistency with CNN models, token selection or pooling now applied in forward_headFeb 2, 2022Chris Hughes posted an exhaustive run through of timm on his blog yesterday. Well worth a read. Getting Started with PyTorch Image Models (timm): A Practitionerâ€™s GuideI'm currently prepping to merge the norm_norm_norm branch back to master (ver 0.6.x) in next week or so.The changes are more extensive than usual and may destabilize and break some model API use (aiming for full backwards compat). So, beware pip install git+https://github.com/rwightman/pytorch-image-models installs!0.5.x releases and a 0.5.x branch will remain stable with a cherry pick or two until dust clears. Recommend sticking to pypi install for a bit if you want stable.Jan 14, 2022Version 0.5.4 w/ release to be pushed to pypi. It's been a while since last pypi update and riskier changes will be merged to main branch soon....Add ConvNeXT models /w weights from official impl (https://github.com/facebookresearch/ConvNeXt), a few perf tweaks, compatible with timm featuresTried training a few small (~1.8-3M param) / mobile optimized models, a few are good so far, more on the way...mnasnet_small - 65.6 top-1mobilenetv2_050 - 65.9lcnet_100/075/050 - 72.1 / 68.8 / 63.1semnasnet_075 - 73fbnetv3_b/d/g - 79.1 / 79.7 / 82.0TinyNet models added by rsomani95LCNet added via MobileNetV3 architectureIntroductionPyTorch Image Models (timm) is a collection of image models, layers, utilities, optimizers, schedulers, data-loaders / augmentations, and reference training / validation scripts that aim to pull together a wide variety of SOTA models with ability to reproduce ImageNet training results.The work of many others is present here. I've tried to make sure all source material is acknowledged via links to github, arxiv papers, etc in the README, documentation, and code docstrings. Please let me know if I missed anything.ModelsAll model architecture families include variants with pretrained weights. There are specific model variants without any weights, it is NOT a bug. Help training new or better weights is always appreciated.Aggregating Nested Transformers - https://arxiv.org/abs/2105.12723BEiT - https://arxiv.org/abs/2106.08254Big Transfer ResNetV2 (BiT) - https://arxiv.org/abs/1912.11370Bottleneck Transformers - https://arxiv.org/abs/2101.11605CaiT (Class-Attention in Image Transformers) - https://arxiv.org/abs/2103.17239CoaT (Co-Scale Conv-Attentional Image Transformers) - https://arxiv.org/abs/2104.06399CoAtNet (Convolution and Attention) - https://arxiv.org/abs/2106.04803ConvNeXt - https://arxiv.org/abs/2201.03545ConvNeXt-V2 - http://arxiv.org/abs/2301.00808ConViT (Soft Convolutional Inductive Biases Vision Transformers)- https://arxiv.org/abs/2103.10697CspNet (Cross-Stage Partial Networks) - https://arxiv.org/abs/1911.11929DeiT - https://arxiv.org/abs/2012.12877DeiT-III - https://arxiv.org/pdf/2204.07118.pdfDenseNet - https://arxiv.org/abs/1608.06993DLA - https://arxiv.org/abs/1707.06484DPN (Dual-Path Network) - https://arxiv.org/abs/1707.01629EdgeNeXt - https://arxiv.org/abs/2206.10589EfficientFormer - https://arxiv.org/abs/2206.01191EfficientNet (MBConvNet Family)EfficientNet NoisyStudent (B0-B7, L2) - https://arxiv.org/abs/1911.04252EfficientNet AdvProp (B0-B8) - https://arxiv.org/abs/1911.09665EfficientNet (B0-B7) - https://arxiv.org/abs/1905.11946EfficientNet-EdgeTPU (S, M, L) - https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.htmlEfficientNet V2 - https://arxiv.org/abs/2104.00298FBNet-C - https://arxiv.org/abs/1812.03443MixNet - https://arxiv.org/abs/1907.09595MNASNet B1, A1 (Squeeze-Excite), and Small - https://arxiv.org/abs/1807.11626MobileNet-V2 - https://arxiv.org/abs/1801.04381Single-Path NAS - https://arxiv.org/abs/1904.02877TinyNet - https://arxiv.org/abs/2010.14819EVA - https://arxiv.org/abs/2211.07636EVA-02 - https://arxiv.org/abs/2303.11331FlexiViT - https://arxiv.org/abs/2212.08013FocalNet (Focal Modulation Networks) - https://arxiv.org/abs/2203.11926GCViT (Global Context Vision Transformer) - https://arxiv.org/abs/2206.09959GhostNet - https://arxiv.org/abs/1911.11907gMLP - https://arxiv.org/abs/2105.08050GPU-Efficient Networks - https://arxiv.org/abs/2006.14090Halo Nets - https://arxiv.org/abs/2103.12731HRNet - https://arxiv.org/abs/1908.07919Inception-V3 - https://arxiv.org/abs/1512.00567Inception-ResNet-V2 and Inception-V4 - https://arxiv.org/abs/1602.07261Lambda Networks - https://arxiv.org/abs/2102.08602LeViT (Vision Transformer in ConvNet's Clothing) - https://arxiv.org/abs/2104.01136MaxViT (Multi-Axis Vision Transformer) - https://arxiv.org/abs/2204.01697MLP-Mixer - https://arxiv.org/abs/2105.01601MobileNet-V3 (MBConvNet w/ Efficient Head) - https://arxiv.org/abs/1905.02244FBNet-V3 - https://arxiv.org/abs/2006.02049HardCoRe-NAS - https://arxiv.org/abs/2102.11646LCNet - https://arxiv.org/abs/2109.15099MobileViT - https://arxiv.org/abs/2110.02178MobileViT-V2 - https://arxiv.org/abs/2206.02680MViT-V2 (Improved Multiscale Vision Transformer) - https://arxiv.org/abs/2112.01526NASNet-A - https://arxiv.org/abs/1707.07012NesT - https://arxiv.org/abs/2105.12723NFNet-F - https://arxiv.org/abs/2102.06171NF-RegNet / NF-ResNet - https://arxiv.org/abs/2101.08692PNasNet - https://arxiv.org/abs/1712.00559PoolFormer (MetaFormer) - https://arxiv.org/abs/2111.11418Pooling-based Vision Transformer (PiT) - https://arxiv.org/abs/2103.16302PVT-V2 (Improved Pyramid Vision Transformer) - https://arxiv.org/abs/2106.13797RegNet - https://arxiv.org/abs/2003.13678RegNetZ - https://arxiv.org/abs/2103.06877RepVGG - https://arxiv.org/abs/2101.03697ResMLP - https://arxiv.org/abs/2105.03404ResNet/ResNeXtResNet (v1b/v1.5) - https://arxiv.org/abs/1512.03385ResNeXt - https://arxiv.org/abs/1611.05431'Bag of Tricks' / Gluon C, D, E, S variations - https://arxiv.org/abs/1812.01187Weakly-supervised (WSL) Instagram pretrained / ImageNet tuned ResNeXt101 - https://arxiv.org/abs/1805.00932Semi-supervised (SSL) / Semi-weakly Supervised (SWSL) ResNet/ResNeXts - https://arxiv.org/abs/1905.00546ECA-Net (ECAResNet) - https://arxiv.org/abs/1910.03151v4Squeeze-and-Excitation Networks (SEResNet) - https://arxiv.org/abs/1709.01507ResNet-RS - https://arxiv.org/abs/2103.07579Res2Net - https://arxiv.org/abs/1904.01169ResNeSt - https://arxiv.org/abs/2004.08955ReXNet - https://arxiv.org/abs/2007.00992SelecSLS - https://arxiv.org/abs/1907.00837Selective Kernel Networks - https://arxiv.org/abs/1903.06586Sequencer2D - https://arxiv.org/abs/2205.01972Swin S3 (AutoFormerV2) - https://arxiv.org/abs/2111.14725Swin Transformer - https://arxiv.org/abs/2103.14030Swin Transformer V2 - https://arxiv.org/abs/2111.09883Transformer-iN-Transformer (TNT) - https://arxiv.org/abs/2103.00112TResNet - https://arxiv.org/abs/2003.13630Twins (Spatial Attention in Vision Transformers) - https://arxiv.org/pdf/2104.13840.pdfVisformer - https://arxiv.org/abs/2104.12533Vision Transformer - https://arxiv.org/abs/2010.11929VOLO (Vision Outlooker) - https://arxiv.org/abs/2106.13112VovNet V2 and V1 - https://arxiv.org/abs/1911.06667Xception - https://arxiv.org/abs/1610.02357Xception (Modified Aligned, Gluon) - https://arxiv.org/abs/1802.02611Xception (Modified Aligned, TF) - https://arxiv.org/abs/1802.02611XCiT (Cross-Covariance Image Transformers) - https://arxiv.org/abs/2106.09681FeaturesSeveral (less common) features that I often utilize in my projects are included. Many of their additions are the reason why I maintain my own set of models, instead of using others' via PIP:All models have a common default configuration interface and API foraccessing/changing the classifier - get_classifier and reset_classifierdoing a forward pass on just the features - forward_features (see documentation)these makes it easy to write consistent network wrappers that work with any of the modelsAll models support multi-scale feature map extraction (feature pyramids) via create_model (see documentation)create_model(name, features_only=True, out_indices=..., output_stride=...)out_indices creation arg specifies which feature maps to return, these indices are 0 based and generally correspond to the C(i + 1) feature level.output_stride creation arg controls output stride of the network by using dilated convolutions. Most networks are stride 32 by default. Not all networks support this.feature map channel counts, reduction level (stride) can be queried AFTER model creation via the .feature_info memberAll models have a consistent pretrained weight loader that adapts last linear if necessary, and from 3 to 1 channel input if desiredHigh performance reference training, validation, and inference scripts that work in several process/GPU modes:NVIDIA DDP w/ a single GPU per process, multiple processes with APEX present (AMP mixed-precision optional)PyTorch DistributedDataParallel w/ multi-gpu, single process (AMP disabled as it crashes when enabled)PyTorch w/ single GPU single process (AMP optional)A dynamic global pool implementation that allows selecting from average pooling, max pooling, average + max, or concat([average, max]) at model creation. All global pooling is adaptive average by default and compatible with pretrained weights.A 'Test Time Pool' wrapper that can wrap any of the included models and usually provides improved performance doing inference with input images larger than the training size. Idea adapted from original DPN implementation when I ported (https://github.com/cypw/DPNs)Learning rate schedulersIdeas adopted fromAllenNLP schedulersFAIRseq lr_schedulerSGDR: Stochastic Gradient Descent with Warm Restarts (https://arxiv.org/abs/1608.03983)Schedulers include step, cosine w/ restarts, tanh w/ restarts, plateauOptimizers:rmsprop_tf adapted from PyTorch RMSProp by myself. Reproduces much improved Tensorflow RMSProp behaviour.radam by Liyuan Liu (https://arxiv.org/abs/1908.03265)novograd by Masashi Kimura (https://arxiv.org/abs/1905.11286)lookahead adapted from impl by Liam (https://arxiv.org/abs/1907.08610)fused<name> optimizers by name with NVIDIA Apex installedadamp and sgdp by Naver ClovAI (https://arxiv.org/abs/2006.08217)adafactor adapted from FAIRSeq impl (https://arxiv.org/abs/1804.04235)adahessian by David Samuel (https://arxiv.org/abs/2006.00719)Random Erasing from Zhun Zhong  (https://arxiv.org/abs/1708.04896)Mixup (https://arxiv.org/abs/1710.09412)CutMix (https://arxiv.org/abs/1905.04899)AutoAugment (https://arxiv.org/abs/1805.09501) and RandAugment (https://arxiv.org/abs/1909.13719) ImageNet configurations modeled after impl for EfficientNet training (https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/autoaugment.py)AugMix w/ JSD loss (https://arxiv.org/abs/1912.02781), JSD w/ clean + augmented mixing support works with AutoAugment and RandAugment as wellSplitBachNorm - allows splitting batch norm layers between clean and augmented (auxiliary batch norm) dataDropPath aka \""Stochastic Depth\"" (https://arxiv.org/abs/1603.09382)DropBlock (https://arxiv.org/abs/1810.12890)Blur Pooling (https://arxiv.org/abs/1904.11486)Space-to-Depth by mrT23 (https://arxiv.org/abs/1801.04590) -- original paper?Adaptive Gradient Clipping (https://arxiv.org/abs/2102.06171, https://github.com/deepmind/deepmind-research/tree/master/nfnets)An extensive selection of channel and/or spatial attention modules:Bottleneck Transformer - https://arxiv.org/abs/2101.11605CBAM - https://arxiv.org/abs/1807.06521Effective Squeeze-Excitation (ESE) - https://arxiv.org/abs/1911.06667Efficient Channel Attention (ECA) - https://arxiv.org/abs/1910.03151Gather-Excite (GE) - https://arxiv.org/abs/1810.12348Global Context (GC) - https://arxiv.org/abs/1904.11492Halo - https://arxiv.org/abs/2103.12731Involution - https://arxiv.org/abs/2103.06255Lambda Layer - https://arxiv.org/abs/2102.08602Non-Local (NL) -  https://arxiv.org/abs/1711.07971Squeeze-and-Excitation (SE) - https://arxiv.org/abs/1709.01507Selective Kernel (SK) - (https://arxiv.org/abs/1903.06586Split (SPLAT) - https://arxiv.org/abs/2004.08955Shifted Window (SWIN) - https://arxiv.org/abs/2103.14030ResultsModel validation results can be found in the results tablesGetting Started (Documentation)The official documentation can be found at https://huggingface.co/docs/hub/timm. Documentation contributions are welcome.Getting Started with PyTorch Image Models (timm): A Practitionerâ€™s Guide by Chris Hughes is an extensive blog post covering many aspects of timm in detail.timmdocs is an alternate set of documentation for timm. A big thanks to Aman Arora for his efforts creating timmdocs.paperswithcode is a good resource for browsing the models within timm.Train, Validation, Inference ScriptsThe root folder of the repository contains reference train, validation, and inference scripts that work with the included models and other features of this repository. They are adaptable for other datasets and use cases with a little hacking. See documentation.Awesome PyTorch ResourcesOne of the greatest assets of PyTorch is the community and their contributions. A few of my favourite resources that pair well with the models and components here are listed below.Object Detection, Instance and Semantic SegmentationDetectron2 - https://github.com/facebookresearch/detectron2Segmentation Models (Semantic) - https://github.com/qubvel/segmentation_models.pytorchEfficientDet (Obj Det, Semantic soon) - https://github.com/rwightman/efficientdet-pytorchComputer Vision / Image AugmentationAlbumentations - https://github.com/albumentations-team/albumentationsKornia - https://github.com/kornia/korniaKnowledge DistillationRepDistiller - https://github.com/HobbitLong/RepDistillertorchdistill - https://github.com/yoshitomo-matsubara/torchdistillMetric LearningPyTorch Metric Learning - https://github.com/KevinMusgrave/pytorch-metric-learningTraining / Frameworksfastai - https://github.com/fastai/fastaiLicensesCodeThe code here is licensed Apache 2.0. I've taken care to make sure any third party code included or adapted has compatible (permissive) licenses such as MIT, BSD, etc. I've made an effort to avoid any GPL / LGPL conflicts. That said, it is your responsibility to ensure you comply with licenses here and conditions of any dependent licenses. Where applicable, I've linked the sources/references for various components in docstrings. If you think I've missed anything please create an issue.Pretrained WeightsSo far all of the pretrained weights available here are pretrained on ImageNet with a select few that have some additional pretraining (see extra note below). ImageNet was released for non-commercial research purposes only (https://image-net.org/download). It's not clear what the implications of that are for the use of pretrained weights from that dataset. Any models I have trained with ImageNet are done for research purposes and one should assume that the original dataset license applies to the weights. It's best to seek legal advice if you intend to use the pretrained weights in a commercial product.Pretrained on more than ImageNetSeveral weights included or references here were pretrained with proprietary datasets that I do not have access to. These include the Facebook WSL, SSL, SWSL ResNe(Xt) and the Google Noisy Student EfficientNet models. The Facebook models have an explicit non-commercial license (CC-BY-NC 4.0, https://github.com/facebookresearch/semi-supervised-ImageNet1K-models, https://github.com/facebookresearch/WSL-Images). The Google models do not appear to have any restriction beyond the Apache 2.0 license (and ImageNet concerns). In either case, you should contact Facebook or Google with any questions.CitingBibTeX@misc{rw2019timm,  author = {Ross Wightman},  title = {PyTorch Image Models},  year = {2019},  publisher = {GitHub},  journal = {GitHub repository},  doi = {10.5281/zenodo.4414861},  howpublished = {\\url{https://github.com/rwightman/pytorch-image-models}}}Latest DOI"
58,donnemartin/system-design-primer,https://github.com/donnemartin/system-design-primer/blob/master/README-ja.md,Python,"English âˆ™ æ—¥æœ¬èª âˆ™ ç®€ä½“ä¸­æ–‡ âˆ™ ç¹é«”ä¸­æ–‡ | Ø§Ù„Ø¹ÙØ±ÙØ¨ÙÙŠÙÙ‘Ø©â€ âˆ™ à¦¬à¦¾à¦‚à¦²à¦¾ âˆ™ PortuguÃªs do Brasil âˆ™ Deutsch âˆ™ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ âˆ™ ×¢×‘×¨×™×ª âˆ™ Italiano âˆ™ í•œêµ­ì–´ âˆ™ ÙØ§Ø±Ø³ÛŒ âˆ™ Polski âˆ™ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº âˆ™ EspaÃ±ol âˆ™ à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ âˆ™ TÃ¼rkÃ§e âˆ™ tiáº¿ng Viá»‡t âˆ™ FranÃ§ais | Add Translationã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå…¥é–€    å‹•æ©Ÿãƒ»ç›®çš„å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’å­¦ã¶ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«å‚™ãˆã‚‹å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆã‚’å­¦ã¶ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’å­¦ã¶ã“ã¨ã¯ã€ã‚ˆã‚Šè‰¯ã„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ãªã‚‹ã“ã¨ã«è³‡ã™ã‚‹ã§ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã¯ã¨ã¦ã‚‚åºƒç¯„ãªãƒˆãƒ”ãƒƒã‚¯ã‚’å«ã¿ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆåŸç†ã«ã¤ã„ã¦ã¯ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã«ã¯è†¨å¤§ãªé‡ã®æ–‡çŒ®ãŒæ•£ã‚‰ã°ã£ã¦ã„ã¾ã™ã€‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã«å¿…è¦ãªçŸ¥è­˜ã‚’å­¦ã¶ã“ã¨ãŒã§ãã‚‹ æ–‡çŒ®ãƒªã‚¹ãƒˆã‚’ä½“ç³»çš„ã«ã¾ã¨ã‚ãŸã‚‚ã® ã§ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰å­¦ã¶ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ã“ã‚Œã‹ã‚‰ã‚‚ãšã£ã¨æ›´æ–°ã•ã‚Œã¦ã„ãã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸæ®µéšã«ã™ãã¾ã›ã‚“ã€‚Contributions ã¯å¤§æ­“è¿ã§ã™ï¼ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«å‚™ãˆã‚‹ã‚³ãƒ¼ãƒ‰æŠ€è¡“é¢æ¥ã«åŠ ãˆã¦ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«é–¢ã™ã‚‹çŸ¥è­˜ã¯ã€å¤šãã®ãƒ†ãƒƒã‚¯ä¼æ¥­ã«ãŠã‘ã‚‹ æŠ€è¡“æ¡ç”¨é¢æ¥ãƒ—ãƒ­ã‚»ã‚¹ ã§ å¿…è¦ä¸å¯æ¬ ãªè¦ç´  ã§ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§ã®é »å‡ºè³ªå•ã«å‚™ãˆã€è‡ªåˆ†ã®è§£ç­”ã¨æ¨¡ç¯„è§£ç­”:ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã€ã‚³ãƒ¼ãƒ‰ãã—ã¦å›³è¡¨ãªã©ã‚’æ¯”è¼ƒã—ã¦å­¦ã³ã¾ã—ã‚‡ã†ã€‚é¢æ¥æº–å‚™ã«å½¹ç«‹ã¤ãã®ä»–ã®ãƒˆãƒ”ãƒƒã‚¯:å­¦ç¿’æŒ‡é‡ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«ã©ã®ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ ã¨ãã®è§£ç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆèª²é¡Œä¾‹ã€ ã¨ãã®è§£ç­”ãã®ä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œä¾‹æš—è¨˜ã‚«ãƒ¼ãƒ‰    ã“ã®Ankiç”¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒƒã‚­ ã¯ã€é–“éš”åå¾©ã‚’æ´»ç”¨ã—ã¦ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ã‚­ãƒ¼ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®å­¦ç¿’ã‚’æ”¯æ´ã—ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒ‡ãƒƒã‚­ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆç·´ç¿’èª²é¡Œãƒ‡ãƒƒã‚­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ç·´ç¿’èª²é¡Œãƒ‡ãƒƒã‚­å¤–å‡ºå…ˆã‚„ç§»å‹•ä¸­ã®å‹‰å¼·ã«å½¹ç«‹ã¤ã§ã—ã‚‡ã†ã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŠ€è¡“èª²é¡Œç”¨ã®å•é¡Œ: ç·´ç¿’ç”¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰æŠ€è¡“é¢æ¥ç”¨ã®å•é¡Œã‚’æ¢ã—ã¦ã„ã‚‹å ´åˆã¯ã“ã¡ã‚‰    å§‰å¦¹ãƒªãƒã‚¸ãƒˆãƒªã® Interactive Coding Challengesã‚‚è¦‹ã¦ã¿ã¦ãã ã•ã„ã€‚è¿½åŠ ã®æš—è¨˜ãƒ‡ãƒƒã‚­ã‚«ãƒ¼ãƒ‰ã‚‚å…¥ã£ã¦ã„ã¾ã™ã€‚Coding deckã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰å­¦ã¶ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆç­‰ã®è²¢çŒ®ã¯ç©æ¥µçš„ã«ãŠé¡˜ã„ã—ã¾ã™:ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹æ”¹å–„æ–°è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ ç¿»è¨³ã™ã‚‹ç¾åœ¨ã€å†…å®¹ã®æ”¹å–„ãŒå¿…è¦ãªä½œæ¥­ä¸­ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã“ã¡ã‚‰ã§ã™ã€‚ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã®å‰ã«Contributing Guidelinesã‚’èª­ã¿ã¾ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆç›®æ¬¡è³›å¦ã‚‚å«ã‚ãŸæ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®å„ãƒˆãƒ”ãƒƒã‚¯ã®æ¦‚è¦ã€‚ å…¨ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚Šã¾ã™ã€‚ãã‚Œãã‚Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ˆã‚Šå­¦ã³ã‚’æ·±ã‚ã‚‹ã‚ˆã†ãªä»–ã®æ–‡çŒ®ã¸ã®ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚    ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯: ã¾ãšã¯ã“ã“ã‹ã‚‰Step 1: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹å‹•ç”»ã‚’è¦‹ã‚‹Step 2: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹è¨˜äº‹ã‚’èª­ã‚€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¯ç”¨æ€§ vs ä¸€è²«æ€§CAPç†è«–CP - ä¸€è²«æ€§(consistency)ã¨åˆ†å‰²æ€§(partition)è€æ€§AP - å¯ç”¨æ€§(availability)ã¨åˆ†å‰²æ€§(partition)è€æ€§ä¸€è²«æ€§ ãƒ‘ã‚¿ãƒ¼ãƒ³å¼±ã„ä¸€è²«æ€§çµæœæ•´åˆæ€§å¼·ã„ä¸€è²«æ€§å¯ç”¨æ€§ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ (DNS)ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CDN)ãƒ—ãƒƒã‚·ãƒ¥CDNãƒ—ãƒ«CDNãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ–/ãƒ‘ãƒƒã‚·ãƒ–æ§‹æˆã‚¢ã‚¯ãƒ†ã‚£ãƒ–/ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ§‹æˆLayer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· (WEBã‚µãƒ¼ãƒãƒ¼)ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ vs ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (RDBMS)ãƒã‚¹ã‚¿ãƒ¼/ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼/ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ãƒãƒ¼ãƒãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³SQL ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°NoSQLã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã‚°ãƒ©ãƒ• ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹SQL or NoSQLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°CDNã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°Webã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã™ã‚‹ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã®ã‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ (ãƒ©ã‚¤ãƒˆãƒãƒƒã‚¯)ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰éåŒæœŸå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼é€šä¿¡ä¼é€åˆ¶å¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ« (TCP)ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« (UDP)é éš”æ‰‹ç¶šå‘¼å‡º (RPC)Representational state transfer (REST)ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è£œéº2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ä¾‹é¡Œå®Ÿä¸–ç•Œã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å„ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°ä½œæ¥­ä¸­ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆé€£çµ¡æƒ…å ±ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å­¦ç¿’æŒ‡é‡å­¦ç¿’ã‚¹ãƒ‘ãƒ³ã«å¿œã˜ã¦ã¿ã‚‹ã¹ããƒˆãƒ”ãƒƒã‚¯ã‚¹ (short, medium, long)Q: é¢æ¥ã®ãŸã‚ã«ã¯ã€ã“ã“ã«ã‚ã‚‹ã‚‚ã®ã™ã¹ã¦ã‚’ã‚„ã‚‰ãªã„ã¨ã„ã‘ãªã„ã®ã§ã—ã‚‡ã†ã‹ï¼ŸA: ã„ãˆã€ã“ã“ã«ã‚ã‚‹ã™ã¹ã¦ã‚’ã‚„ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚é¢æ¥ã§ä½•ã‚’èã‹ã‚Œã‚‹ã‹ã¯ä»¥ä¸‹ã®æ¡ä»¶ã«ã‚ˆã£ã¦å¤‰ã‚ã£ã¦ãã¾ã™:ã©ã‚Œã ã‘ã®æŠ€è¡“çµŒé¨“ãŒã‚ã‚‹ã‹ã‚ãªãŸã®æŠ€è¡“èƒŒæ™¯ãŒä½•ã§ã‚ã‚‹ã‹ã©ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ãŸã‚ã«é¢æ¥ã‚’å—ã‘ã¦ã„ã‚‹ã‹ã©ã®ä¼æ¥­ã®é¢æ¥ã‚’å—ã‘ã¦ã„ã‚‹ã‹é‹ã‚ˆã‚ŠçµŒé¨“ã®ã‚ã‚‹å€™è£œè€…ã¯ä¸€èˆ¬çš„ã«ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«ã¤ã„ã¦ã‚ˆã‚Šæ·±ã„çŸ¥è­˜ã‚’æœ‰ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¦æ±‚ã•ã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã‚„ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ã¯å„ãƒ¡ãƒ³ãƒãƒ¼ã®æŒã¤ã‚ˆã†ãªçŸ¥è­˜ã‚ˆã‚Šã¯æ·±ã„è¦‹è­˜ã‚’æŒã£ã¦ã„ã‚‹ã¹ãã§ã—ã‚‡ã†ã€‚ä¸€æµãƒ†ãƒƒã‚¯ä¼æ¥­ã§ã¯è¤‡æ•°å›ã®è¨­è¨ˆé¢æ¥ã‚’èª²ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ã¾ãšã¯åºƒãå§‹ã‚ã¦ã€ãã“ã‹ã‚‰ã„ãã¤ã‹ã®åˆ†é‡ã«çµã£ã¦æ·±ã‚ã¦ã„ãã®ãŒã„ã„ã§ã—ã‚‡ã†ã€‚æ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦å°‘ã—ãšã¤çŸ¥ã£ã¦ãŠãã“ã¨ã¯ã„ã„ã“ã¨ã§ã™ã€‚ä»¥ä¸‹ã®å­¦ç¿’ã‚¬ã‚¤ãƒ‰ã‚’è‡ªåˆ†ã®å­¦ç¿’ã«å½“ã¦ã‚‰ã‚Œã‚‹æ™‚é–“ã€æŠ€è¡“çµŒé¨“ã€ã©ã®è·ä½ã€ã©ã®ä¼šç¤¾ã«å¿œå‹Ÿã—ã¦ã„ã‚‹ã‹ãªã©ã‚’åŠ å‘³ã—ã¦è‡ªåˆ†ç”¨ã«èª¿æ•´ã—ã¦ä½¿ã†ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚çŸ­æœŸé–“ - å¹…åºƒã ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚ã„ãã¤ã‹ã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚ä¸­æœŸé–“ - å¹…åºƒã ãã—ã¦ ãã‚Œãªã‚Šã«æ·±ãã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚å¤šãã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚é•·æœŸé–“ - å¹…åºƒã ãã—ã¦ ã‚‚ã£ã¨æ·±ãã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚ã»ã¼å…¨ã¦ã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚çŸ­æœŸé–“ä¸­æœŸé–“é•·æœŸé–“ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ ã‚’èª­ã¿ã€ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œæ©Ÿåºã«ã¤ã„ã¦åºƒãçŸ¥ã‚‹ğŸ‘ğŸ‘ğŸ‘æ¬¡ã®ãƒªãƒ³ã‚¯å…ˆã®ã„ãã¤ã‹ã®ãƒšãƒ¼ã‚¸ã‚’èª­ã‚“ã§ å„ä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ–ãƒ­ã‚° å¿œå‹Ÿã™ã‚‹ä¼šç¤¾ã«ã¤ã„ã¦çŸ¥ã‚‹ğŸ‘ğŸ‘ğŸ‘æ¬¡ã®ãƒªãƒ³ã‚¯å…ˆã®ã„ãã¤ã‹ã®ãƒšãƒ¼ã‚¸ã‚’èª­ã‚€ å®Ÿä¸–ç•Œã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ğŸ‘ğŸ‘ğŸ‘å¾©ç¿’ã™ã‚‹ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«ã©ã®ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã‹ğŸ‘ğŸ‘ğŸ‘ã¨ã‚Šã‚ãˆãšä¸€å‘¨ã™ã‚‹ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹SomeManyMostã¨ã‚Šã‚ãˆãšä¸€å‘¨ã™ã‚‹ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆå•é¡Œã¨è§£ç­”SomeManyMostå¾©ç¿’ã™ã‚‹ ãã®ä»–ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§ã®è³ªå•ä¾‹SomeManyMostã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã«ã©ã®ã‚ˆã†ã«ã—ã¦è‡¨ã‚ã°ã„ã„ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥è©¦é¨“å•é¡Œã«ã©ã®ã‚ˆã†ã«å–ã‚Šçµ„ã‚€ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã¯ open-ended conversation(Yes/Noã§ã¯ç­”ãˆã‚‰ã‚Œãªã„å£é ­è³ªå•)ã§ã™ã€‚ è‡ªåˆ†ã§ä¼šè©±ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã«å¾“ã£ã¦è­°è«–ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã“ã¨ãŒã§ãã‚‹ã§ã—ã‚‡ã†ã€‚ã“ã®éç¨‹ã‚’ç¢ºã‹ãªã‚‚ã®ã«ã™ã‚‹ãŸã‚ã«ã€æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ã¨ãã®è§£ç­” ã‚’ä»¥ä¸‹ã®æŒ‡é‡ã«å¾“ã£ã¦èª­ã¿è¾¼ã‚€ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚ã‚¹ãƒ†ãƒƒãƒ— 1: ãã®ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ä¾‹ã®æ¦‚è¦ã€åˆ¶ç´„ã€æ¨è¨ˆå€¤ç­‰ã‚’èãå‡ºã—ã€ã¾ã¨ã‚ã‚‹ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜ã®è¦æ±‚äº‹é …ã‚’èãå‡ºã—ã€å•é¡Œç®‡æ‰€ã‚’ç‰¹å®šã—ã¾ã—ã‚‡ã†ã€‚ä½¿ç”¨ä¾‹ã¨åˆ¶ç´„ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã®è³ªå•ã‚’æŠ•ã’ã‹ã‘ã¾ã—ã‚‡ã†ã€‚è¦æ±‚ã™ã‚‹æ¨è¨ˆå€¤ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚èª°ãŒãã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã†ã®ã‹ï¼Ÿã©ã®ã‚ˆã†ã«ä½¿ã†ã®ã‹ï¼Ÿä½•äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã„ã‚‹ã®ã‹ï¼Ÿã‚·ã‚¹ãƒ†ãƒ ã¯ã©ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’æœãŸã™ã®ã‹ï¼Ÿã‚·ã‚¹ãƒ†ãƒ ã¸ã®å…¥åŠ›ã¨å‡ºåŠ›ã¯ï¼Ÿã©ã‚Œã ã‘ã®å®¹é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒãå¿…è¦ãŒã‚ã‚‹ã®ã‹ï¼Ÿä¸€ç§’é–“ã«ä½•ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é€ä¿¡ãŒæƒ³å®šã•ã‚Œã‚‹ã‹ï¼Ÿèª­ã¿æ›¸ãæ¯”ç‡ã®æ¨å®šå€¤ã¯ã„ãã‚‰ç¨‹åº¦ã‹ï¼Ÿã‚¹ãƒ†ãƒƒãƒ— 2: ã‚ˆã‚Šé«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’çµ„ã¿ç«‹ã¦ã‚‹é‡è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å…¨ã¦è€ƒæ…®ã—ãŸé«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ¦‚è¦ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¨æ¥ç¶šã‚’ã‚¹ã‚±ãƒƒãƒã—ã¦æ›¸ãå‡ºã™è€ƒãˆã®è£ä»˜ã‘ã‚’ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ— 3: æ ¸ã¨ãªã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è¨­è¨ˆã™ã‚‹ãã‚Œãã‚Œã®ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦ã®è©³ç´°ã‚’å­¦ã¶ã€‚ä¾‹ãˆã°ã€urlçŸ­ç¸®ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆã‚’å•ã‚ã‚ŒãŸéš›ã«ã¯æ¬¡ã®ã‚ˆã†ã«ã™ã‚‹ã¨ã„ã„ã§ã—ã‚‡ã†:å…ƒã®URLã®ãƒãƒƒã‚·ãƒ¥åŒ–ã—ãŸã‚‚ã®ã‚’ä½œã‚Šã€ãã‚Œã‚’ä¿å­˜ã™ã‚‹MD5 ã¨ Base62ãƒãƒƒã‚·ãƒ¥è¡çªSQL ã‚‚ã—ãã¯ NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚ŒãŸURLã‚’å…ƒã®URLã«å†ç¿»è¨³ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‚ç…§API & ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã®è¨­è¨ˆã‚¹ãƒ†ãƒƒãƒ— 4: ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ã‚¹ã‚±ãƒ¼ãƒ«ä¸ãˆã‚‰ã‚ŒãŸåˆ¶ç´„æ¡ä»¶ã‹ã‚‰ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚Šãã†ãªã¨ã“ã‚ã‚’å‰²ã‚Šå‡ºã—ã€æ˜ç¢ºåŒ–ã™ã‚‹ã€‚  ä¾‹ãˆã°ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®å•é¡Œè§£æ±ºã®ãŸã‚ã«ä»¥ä¸‹ã®è¦ç´ ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å–ã‚Šã†ã‚‹è§£æ±ºç­–ã¨ãã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦è­°è«–ã‚’ã—ã‚ˆã†ã€‚å…¨ã¦ã®ã“ã¨ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ã€‚ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ã¤ã„ã¦ã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®åŸç†ã‚’èª­ã‚€ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚ã¡ã‚‡ã£ã¨ã—ãŸæš—ç®—å•é¡Œã¡ã‚‡ã£ã¨ã—ãŸæ¨è¨ˆå€¤ã‚’æ‰‹è¨ˆç®—ã§ã™ã‚‹ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚è£œéºã®ä»¥ä¸‹ã®é …ç›®ãŒå½¹ã«ç«‹ã¤ã§ã—ã‚‡ã†:ãƒãƒ©è£è¨ˆç®—ã§ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã™ã‚‹2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã£ã¦ãŠãã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®å‚è€ƒå€¤æ–‡çŒ®ã¨ãã®ä»–ã®å‚è€ƒè³‡æ–™ä»¥ä¸‹ã®ãƒªãƒ³ã‚¯å…ˆãƒšãƒ¼ã‚¸ã‚’è¦‹ã¦ã©ã®ã‚ˆã†ãªè³ªå•ã‚’æŠ•ã’ã‹ã‘ã‚‰ã‚Œã‚‹ã‹æ¦‚è¦ã‚’é ­ã«å…¥ã‚Œã¦ãŠãã¾ã—ã‚‡ã†:ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§æˆåŠŸã™ã‚‹ã«ã¯ï¼Ÿã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã¸ã®å°å…¥ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ã¨ãã®è§£ç­”é »å‡ºã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨å‚è€ƒè§£ç­”ã€ã‚³ãƒ¼ãƒ‰åŠã³ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è§£ç­”ã¯ solutions/ ãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã‚‹å•é¡ŒPastebin.com (ã‚‚ã—ãã¯ Bit.ly) ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Twitterã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ (ã‚‚ã—ãã¯Facebookãƒ•ã‚£ãƒ¼ãƒ‰)ã‚’è¨­è¨ˆã™ã‚‹Twitteræ¤œç´¢(ã‚‚ã—ãã¯Facebookæ¤œç´¢)æ©Ÿèƒ½ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”ã‚¦ã‚§ãƒ–ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Mint.comã‚’è¨­è¨ˆã™ã‚‹è§£ç­”SNSã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Amazonã®ã‚«ãƒ†ã‚´ãƒªæ¯ã®å£²ã‚Šä¸Šã’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”AWSä¸Šã§100ä¸‡äººè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå•é¡Œã‚’è¿½åŠ ã™ã‚‹ContributePastebin.com (ã‚‚ã—ãã¯ Bit.ly) ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Twitterã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³&æ¤œç´¢ (ã‚‚ã—ãã¯Facebookãƒ•ã‚£ãƒ¼ãƒ‰&æ¤œç´¢)ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹ã‚¦ã‚§ãƒ–ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®è¨­è¨ˆå•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Mint.comã®è¨­è¨ˆå•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹SNSã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Amazonã®ã‚«ãƒ†ã‚´ãƒªæ¯ã®å£²ã‚Šä¸Šã’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹AWSä¸Šã§100ä¸‡äººè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆå•é¡Œã¨è§£ç­”é »å‡ºã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨å‚è€ƒè§£ç­”ã€ã‚³ãƒ¼ãƒ‰åŠã³ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è§£ç­”ã¯ solutions/ ãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã‚‹å‚™è€ƒ: ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ä½œæ¥­ä¸­ã§ã™å•é¡Œãƒãƒƒã‚·ãƒ¥ãƒãƒƒãƒ—ã®è¨­è¨ˆè§£ç­”LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¨­è¨ˆè§£ç­”ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼ã®è¨­è¨ˆè§£ç­”ã‚«ãƒ¼ãƒ‰ã®ãƒ‡ãƒƒã‚­ã®è¨­è¨ˆè§£ç­”é§è»Šå ´ã®è¨­è¨ˆè§£ç­”ãƒãƒ£ãƒƒãƒˆã‚µãƒ¼ãƒãƒ¼ã®è¨­è¨ˆè§£ç­”å††å½¢é…åˆ—ã®è¨­è¨ˆContributeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå•é¡Œã‚’è¿½åŠ ã™ã‚‹Contributeã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚¹: ã¾ãšã¯ã“ã“ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®å‹‰å¼·ã¯åˆã‚ã¦ï¼Ÿã¾ãšåˆã‚ã«ã€ã‚ˆãä½¿ã‚ã‚Œã‚‹è¨­è¨ˆåŸç†ã«ã¤ã„ã¦ã€ãã‚Œã‚‰ãŒä½•ã§ã‚ã‚‹ã‹ã€ã©ã®ã‚ˆã†ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã‹ã€é•·æ‰€çŸ­æ‰€ã«ã¤ã„ã¦åŸºæœ¬çš„ãªçŸ¥è­˜ã‚’å¾—ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‚¹ãƒ†ãƒƒãƒ— 1: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹å‹•ç”»ã‚’è¦³ã¦å¾©ç¿’ã™ã‚‹Harvardã§ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®è¬›ç¾©ã“ã“ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚¹:å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒƒãƒ— 2: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹è³‡æ–™ã‚’èª­ã‚“ã§å¾©ç¿’ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã“ã“ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚¹:ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥éåŒæœŸæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—æ¬¡ã«ã€ãƒã‚¤ãƒ¬ãƒ™ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦ã¿ã¦ã„ã:ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¯ç”¨æ€§ vs ä¸€è²«æ€§å…¨ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ã¨ã„ã†ã®ã‚’è‚ã«å‘½ã˜ã¦ãŠãã¾ã—ã‚‡ã†ã€‚ãã‚Œã‹ã‚‰ã€ã‚ˆã‚Šæ·±ã„å†…å®¹ã€DNSã‚„CDNãã—ã¦ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãªã©ã«ã¤ã„ã¦å­¦ç¿’ã‚’é€²ã‚ã¦ã„ãã¾ã—ã‚‡ã†ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒªã‚½ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚Œã‚‹ã®ã«ã¤ã‚Œã¦ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãŒå‘ä¸Šã™ã‚‹å ´åˆãã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ« ã§ã‚ã‚‹ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚ä¸€èˆ¬çš„ã«ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã¨ã„ã†ã®ã¯ã™ãªã‚ã¡è¨ˆç®—å‡¦ç†ã‚’å¢—ã‚„ã™ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¢—ãˆãŸæ™‚ãªã©ã‚ˆã‚Šå¤§ããªå‡¦ç†ã‚’æŒã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚1ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹vsã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’ã¨ã‚‰ãˆã‚‹ä»–ã®è€ƒãˆæ–¹:ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ã§ã®å•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹æ™‚ã€ã‚ãªãŸã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä¸€äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦é…ã„ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ ã§ã®å•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹ã¨ãã€ä¸€äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã¯é€Ÿã„ã§ã™ãŒã€å¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚ã‚‹æ™‚ã«ã¯é…ããªã£ã¦ã—ã¾ã†ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«ã¤ã„ã¦ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€å¯ç”¨æ€§ã€å®‰å®šæ€§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ã¨ã¯ãªã«ãŒã—ã‹ã®å‹•ä½œã‚’è¡Œã†ã€ã‚‚ã—ãã¯çµæœã‚’ç®—å‡ºã™ã‚‹ã®ã«è¦ã™ã‚‹æ™‚é–“ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ ã¨ã¯ãã®ã‚ˆã†ãªå‹•ä½œã‚„çµæœç®—å‡ºãŒå˜ä½æ™‚é–“ã«è¡Œã‚ã‚Œã‚‹å›æ•°ä¸€èˆ¬çš„ã«ã€ æœ€å¤§é™ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ ã‚’ è¨±å®¹ç¯„å›²å†…ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ã§å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã®ãŒæ™®é€šã ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç†è§£ã™ã‚‹å¯ç”¨æ€§ vs ä¸€è²«æ€§CAP ç†è«–      Source: CAP theorem revisitedåˆ†æ•£å‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã¯ä¸‹ã®ä¸‰ã¤ã®ã†ã¡äºŒã¤ã¾ã§ã—ã‹åŒæ™‚ã«ä¿è¨¼ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€‚:ä¸€è²«æ€§ - å…¨ã¦ã®èª­ã¿è¾¼ã¿ã¯æœ€æ–°ã®æ›¸ãè¾¼ã¿ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã‚’å—ã‘å–ã‚‹å¯ç”¨æ€§ - å—ã‘å–ã‚‹æƒ…å ±ãŒæœ€æ–°ã®ã‚‚ã®ã ã¨ã„ã†ä¿è¨¼ã¯ãªã„ãŒã€å…¨ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¿…ãšå—ã‘å–ã‚‹åˆ†æ–­è€æ€§ - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œã«ã‚ˆã£ã¦é †ä¸åŒã®åˆ†æ–­ãŒèµ·ãã¦ã‚‚ã‚·ã‚¹ãƒ†ãƒ ãŒå‹•ä½œã‚’ç¶šã‘ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ä¿¡é ¼ã§ããªã„ã®ã§ã€åˆ†æ–­è€æ€§ã¯å¿…ãšä¿è¨¼ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ã¤ã¾ã‚Šã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã¯ã€ä¸€è²«æ€§ã‚’å–ã‚‹ã‹ã€å¯ç”¨æ€§ã‚’å–ã‚‹ã‹ã‚’è€ƒãˆãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚CP - ä¸€è²«æ€§ã¨åˆ†æ–­è€æ€§(consistency and partition tolerance)åˆ†æ–­ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¾…ã¡ç¶šã‘ã¦ã„ã‚‹ã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã«é™¥ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚CPã¯ã‚ãªãŸã®ã‚µãƒ¼ãƒ“ã‚¹ãŒã‚¢ãƒˆãƒŸãƒƒã‚¯ãªèª­ã¿æ›¸ãï¼ˆä¸å¯åˆ†æ“ä½œï¼‰ã‚’å¿…è¦ã¨ã™ã‚‹éš›ã«ã¯ã„ã„é¸æŠè‚¢ã§ã—ã‚‡ã†ã€‚AP - å¯ç”¨æ€§ã¨åˆ†æ–­è€æ€§(availability and partition tolerance)ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ãƒãƒ¼ãƒ‰ä¸Šã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã§æœ€æ–°ã®ã‚‚ã®ã‚’è¿”ã—ã¾ã™ã€‚ã¤ã¾ã‚Šã€æœ€æ–°ç‰ˆã®ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚åˆ†æ–­ãŒè§£æ¶ˆã•ã‚ŒãŸå¾Œã‚‚ã€æ›¸ãè¾¼ã¿ãŒåæ˜ ã•ã‚Œã‚‹ã®ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚çµæœæ•´åˆæ€§ã€€ã‚’æ±‚ã‚ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®éš›ã«ã¯APã‚’æ¡ç”¨ã™ã‚‹ã®ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã‚‚ã—ãã¯ã€å¤–éƒ¨ã‚¨ãƒ©ãƒ¼ã«é–¢ã‚ã‚‰ãšã‚·ã‚¹ãƒ†ãƒ ãŒç¨¼åƒã™ã‚‹å¿…è¦ãŒã‚ã‚‹éš›ã«ã‚‚åŒæ§˜ã§ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸CAP ç†è«–ã‚’æŒ¯ã‚Šè¿”ã‚‹å¹³æ˜“ãªè‹±èªã§ã®CAP ç†è«–ã®ã‚¤ãƒ³ãƒˆãƒ­CAP FAQä¸€è²«æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³åŒã˜ãƒ‡ãƒ¼ã‚¿ã®è¤‡è£½ãŒè¤‡æ•°ã‚ã‚‹çŠ¶æ…‹ã§ã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒä¸€è²«ã—ãŸãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚’å—ã‘å–ã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ã«ãã‚Œã‚‰ã‚’åŒæœŸã™ã‚Œã°ã„ã„ã®ã‹ã¨ã„ã†èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ CAP ç†è«– ã«ãŠã‘ã‚‹ä¸€è²«æ€§ã®å®šç¾©ã‚’æ€ã„å‡ºã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚å…¨ã¦ã®èª­ã¿å–ã‚Šã¯æœ€æ–°ã®æ›¸ãè¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã‚’å—ã‘å–ã‚‹ã¯ãšã§ã™ã€‚å¼±ã„ä¸€è²«æ€§æ›¸ãè¾¼ã¿å¾Œã®èª­ã¿å–ã‚Šã§ã¯ã€ãã®æœ€æ–°ã®æ›¸ãè¾¼ã¿ã‚’èª­ã‚ãŸã‚Šèª­ã‚ãªã‹ã£ãŸã‚Šã™ã‚‹ã€‚ãƒ™ã‚¹ãƒˆã‚¨ãƒ•ã‚©ãƒ¼ãƒˆå‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«åŸºã¥ãã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯memcachedãªã©ã®ã‚·ã‚¹ãƒ†ãƒ ã«è¦‹ã‚‰ã‚Œã¾ã™ã€‚å¼±ã„ä¸€è²«æ€§ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒå¿…è¦ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã€ä¾‹ãˆã°VoIPã€ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ«ãƒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚²ãƒ¼ãƒ ãªã©ã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ä¾‹ãˆã°ã€é›»è©±ã«å‡ºã¦ã„ã‚‹ã¨ãã«æ•°ç§’é–“éŸ³å£°ãŒå—ã‘å–ã‚Œãªããªã£ãŸã¨ã—ãŸã‚‰ã€ãã®å¾Œã«æ¥ç¶šãŒå›å¾©ã—ã¦ã‚‚ãã®æ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¦ã„ãŸé–“ã«è©±ã•ã‚Œã¦ã„ãŸã“ã¨ã¯èãå–ã‚Œãªã„ã¨ã„ã†ã‚ˆã†ãªæ„Ÿã˜ã§ã™ã€‚çµæœæ•´åˆæ€§æ›¸ãè¾¼ã¿ã®å¾Œã€èª­ã¿å–ã‚Šã¯æœ€çµ‚çš„ã«ã¯ãã®çµæœã‚’èª­ã¿å–ã‚‹ã“ã¨ãŒã§ãã‚‹(ãƒŸãƒªç§’ã»ã©é…ã‚Œã¦ã¨ã„ã†ã®ãŒä¸€èˆ¬çš„ã§ã™)ã€‚ãƒ‡ãƒ¼ã‚¿ã¯éåŒæœŸçš„ã«è¤‡è£½ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯DNSã‚„ãƒ¡ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãªã©ã«æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚çµæœæ•´åˆæ€§ã¯å¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚å¼·ã„ä¸€è²«æ€§æ›¸ãè¾¼ã¿ã®å¾Œã€èª­ã¿å–ã‚Šã¯ãã‚Œã‚’å¿…ãšèª­ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯åŒæœŸçš„ã«è¤‡è£½ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚„RDBMSãªã©ã§æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ‰±ã†ã‚µãƒ¼ãƒ“ã‚¹ã§ã¯å¼·ã„ä¸€è²«æ€§ãŒå¿…è¦ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼é–“ã§ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¯ç”¨æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³é«˜ã„å¯ç”¨æ€§ã‚’æ‹…ä¿ã™ã‚‹ã«ã¯ä¸»ã«æ¬¡ã®äºŒã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã™: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ ã¨ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã§ã™ã€‚ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã«ãŠã„ã¦ã¯ã€å‘¨æœŸä¿¡å·ã¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚‚ã—ãã¯ã‚¹ã‚¿ãƒ³ãƒã‚¤ä¸­ã®ãƒ‘ãƒƒã‚·ãƒ–ãªã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œã¾ã™ã€‚å‘¨æœŸä¿¡å·ãŒä¸­æ–­ã•ã‚ŒãŸæ™‚ã«ã¯ã€ãƒ‘ãƒƒã‚·ãƒ–ã ã£ãŸã‚µãƒ¼ãƒãƒ¼ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒ¼ãƒãƒ¼ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å¼•ãç¶™ã„ã§ã‚µãƒ¼ãƒ“ã‚¹ã‚’å†é–‹ã—ã¾ã™ã€‚èµ·å‹•ã¾ã§ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã¯ãƒ‘ãƒƒã‚·ãƒ–ã‚µãƒ¼ãƒãƒ¼ãŒã€Œãƒ›ãƒƒãƒˆã€ãªã‚¹ã‚¿ãƒ³ãƒã‚¤çŠ¶æ…‹ã«ã‚ã‚‹ã‹ã€ã€Œã‚³ãƒ¼ãƒ«ãƒ‰ã€ãªã‚¹ã‚¿ãƒ³ãƒã‚¤çŠ¶æ…‹ã«ã‚ã‚‹ã‹ã§å¤‰ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚µãƒ¼ãƒãƒ¼ã®ã¿ãŒãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ§‹æˆã§ã¯ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã“ã¨ã§è² è·ã‚’åˆ†æ•£ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒ‘ãƒ–ãƒªãƒƒã‚¯ãªã‚‚ã®ã®å ´åˆã€DNSã¯ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ã®ãƒ‘ãƒ–ãƒªãƒƒã‚¯IPã‚’çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚‚ã—ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªã‚‚ã®ãªå ´åˆã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ãŒä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã«ã¤ã„ã¦çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚çŸ­æ‰€: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã§ã¯ã‚ˆã‚Šå¤šãã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’è¦ã—ã€è¤‡é›‘ã•ãŒå¢—ã—ã¾ã™ã€‚æœ€æ–°ã®æ›¸ãè¾¼ã¿ãŒãƒ‘ãƒƒã‚·ãƒ–ã‚µãƒ¼ãƒãƒ¼ã«è¤‡è£½ã•ã‚Œã‚‹å‰ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãŒè½ã¡ã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿æ¬ æãŒèµ·ãã‚‹æ½œåœ¨å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–ã€€ã¨ã€€ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã¯ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã‚ˆã‚Šè©³ç´°ã«è§£èª¬ã•ã‚Œã¦ã„ã¾ã™:ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ       Source: DNS security presentationãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (DNS) ã¯ www.example.com ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚’IPã‚¢ãƒ‰ãƒ¬ã‚¹ã¸ã¨ç¿»è¨³ã—ã¾ã™ã€‚DNSã¯å°‘æ•°ã®ã‚ªãƒ¼ã‚½ãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ãŒä¸Šä½ã«ä½ç½®ã™ã‚‹éšå±¤çš„æ§‹é€ ã§ã™ã€‚ã‚ãªãŸã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚‚ã—ãã¯ISPã¯æ¤œç´¢ã‚’ã™ã‚‹éš›ã«ã©ã®DNSã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã‹ã¨ã„ã†æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚ä½ã„éšå±¤ã®DNSã‚µãƒ¼ãƒãƒ¼ã¯ãã®çµŒè·¯ãƒãƒƒãƒ—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚ãŸã ã€ã“ã®æƒ…å ±ã¯ä¼æ¬é…å»¶ã«ã‚ˆã£ã¦é™³è…åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚DNSã®çµæœã¯ã‚ãªãŸã®ãƒ–ãƒ©ã‚¦ã‚¶ã‚‚ã—ãã¯OSã«ä¸€å®šæœŸé–“ï¼ˆtime to live (TTL)ã«è¨­å®šã•ã‚ŒãŸæœŸé–“ï¼‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ã€‚NS record (name server) - ã‚ãªãŸã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®DNSã‚µãƒ¼ãƒãƒ¼ã‚’ç‰¹å®šã—ã¾ã™ã€‚MX record (mail exchange) - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚µãƒ¼ãƒãƒ¼ã‚’ç‰¹å®šã—ã¾ã™ã€‚A record (address) - IPã‚¢ãƒ‰ãƒ¬ã‚¹ã«åå‰ã‚’ã¤ã‘ã¾ã™ã€‚CNAME (canonical) - ä»–ã®åå‰ã‚‚ã—ãã¯ã€€CNAME (example.com ã‚’ www.example.com) ã‚‚ã—ãã¯ A recordã¸ã¨åå‰ã‚’æŒ‡ã—ç¤ºã™ã€‚CloudFlare ã‚„ Route 53 ãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒãƒãƒ¼ã‚¸ãƒ‰DNSã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã„ãã¤ã‹ã®DNSã‚µãƒ¼ãƒ“ã‚¹ã§ã¯æ§˜ã€…ãªæ‰‹æ³•ã‚’ä½¿ã£ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã“ã¨ãŒã§ãã¾ã™:åŠ é‡ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã®ã‚µãƒ¼ãƒãƒ¼ã«è¡Œãã®ã‚’é˜²ãã¾ã™æ§˜ã€…ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´ã—ã¾ã™A/B ãƒ†ã‚¹ãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãƒ™ãƒ¼ã‚¹åœ°ç†ãƒ™ãƒ¼ã‚¹æ¬ ç‚¹: DNSä¸Šè¨˜ã§ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã«ã‚ˆã£ã¦ç·©å’Œã•ã‚Œã¦ã„ã‚‹ã¨ã¯ã„ãˆã€DNSã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã«ã¯å°‘ã—é…å»¶ãŒç”Ÿã˜ã‚‹ã€‚DNSã‚µãƒ¼ãƒãƒ¼ã¯ã€æ”¿åºœã€ISPä¼æ¥­,ãã—ã¦å¤§ä¼æ¥­ã«ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãŒã€ãã‚Œã‚‰ã®ç®¡ç†ã¯è¤‡é›‘ã§ã‚ã‚‹ã€‚DNSã‚µãƒ¼ãƒ“ã‚¹ã¯DDoS attackã®ä¾‹ã§ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ãªã—ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒTwitterãªã©ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªããªã£ãŸã‚ˆã†ã«ã€æ”»æ’ƒã‚’å—ã‘ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸DNS ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£WikipediaDNS è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(Content delivery network)      Source: Why use a CDNã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CDN)ã¯ä¸–ç•Œä¸­ã«é…ç½®ã•ã‚ŒãŸãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¸€ç•ªåœ°ç†çš„ã«è¿‘ã„ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é…ä¿¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®ã“ã¨ã§ã™ã€‚Amazonã®CloudFrontãªã©ã¯ä¾‹å¤–çš„ã«ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚é…ä¿¡ã—ã¾ã™ãŒã€ä¸€èˆ¬çš„ã«ã€HTML/CSS/JSã€å†™çœŸã€ãã—ã¦å‹•ç”»ãªã©ã®é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãŒCDNã‚’é€šã˜ã¦é…ä¿¡ã•ã‚Œã¾ã™ã€‚ãã®ã‚µã‚¤ãƒˆã®DNSãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã©ã®ã‚µãƒ¼ãƒãƒ¼ã¨äº¤ä¿¡ã™ã‚‹ã‹ã¨ã„ã†æƒ…å ±ã‚’ä¼ãˆã¾ã™ã€‚CDNã‚’ç”¨ã„ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é…ä¿¡ã™ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®äºŒã¤ã®ç†ç”±ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒåŠ‡çš„ã«å‘ä¸Šã—ã¾ã™:ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è¿‘ãã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰å—ä¿¡ã§ãã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã¯CDNãŒå‡¦ç†ã—ã¦ãã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«é–¢ã—ã¦ã¯å‡¦ç†ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ãƒ—ãƒƒã‚·ãƒ¥CDNãƒ—ãƒƒã‚·ãƒ¥CDNã§ã¯ã‚µãƒ¼ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ã«æ›´æ–°ãŒã‚ã£ãŸæ™‚ã«ã¯å¿…ãšã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å—ã‘å–ã‚‹æ–¹å¼ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”¨æ„ã—ã€CDNã«ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€URLã‚’CDNã‚’æŒ‡ã™ã‚ˆã†ã«æŒ‡å®šã™ã‚‹ã¨ã“ã‚ã¾ã§ã€å…¨ã¦è‡ªåˆ†ã§è²¬ä»»ã‚’è² ã†å½¢ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã„ã¤æœŸé™åˆ‡ã‚Œã«ãªã‚‹ã®ã‹æ›´æ–°ã•ã‚Œã‚‹ã®ã‹ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ–°è¦ä½œæˆæ™‚ã€æ›´æ–°æ™‚ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã“ã¨ã§ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã¯æœ€å°åŒ–ã•ã‚Œã‚‹ä¸€æ–¹ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¯æœ€å¤§é™æ¶ˆè²»ã•ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å°‘ãªã„ã€ã‚‚ã—ãã¯é »ç¹ã«ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ›´æ–°ã•ã‚Œãªã„ã‚µã‚¤ãƒˆã®å ´åˆã«ã¯ãƒ—ãƒƒã‚·ãƒ¥CDNã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å®šæœŸçš„ã«å†ã³ãƒ—ãƒ«ã•ã‚Œã‚‹ã®ã§ã¯ãªãã€CDNã«ä¸€åº¦ã®ã¿é…ç½®ã•ã‚Œã¾ã™ã€‚ãƒ—ãƒ«CDNãƒ—ãƒ«CDNã§ã¯ä¸€äººç›®ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãŸæ™‚ã«ã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å–å¾—ã—ã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯è‡ªåˆ†ã®ã‚µãƒ¼ãƒãƒ¼ã«ä¿å­˜ã—ã¦ã€CDNã‚’æŒ‡ã™URLã‚’æ›¸ãæ›ãˆã¾ã™ã€‚çµæœã¨ã—ã¦ã€CDNã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã¾ã§ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ãŒé…ããªã‚Šã¾ã™ã€‚time-to-live (TTL) ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã©ã‚Œã ã‘ã®æœŸé–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã‹ã‚’è¦å®šã—ã¾ã™ã€‚ãƒ—ãƒ«CDNã¯CDN ä¸Šã§ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¹ãƒšãƒ¼ã‚¹ã‚’æœ€å°åŒ–ã—ã¾ã™ãŒã€æœ‰åŠ¹æœŸé™ãŒåˆ‡ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›´æ–°å‰ã«ãƒ—ãƒ«ã•ã‚Œã¦ã—ã¾ã†ã“ã¨ã§å†—é•·ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«ç¹‹ãŒã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å¤§è¦æ¨¡ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ã‚ã‚‹ã‚µã‚¤ãƒˆã§ã¯ãƒ—ãƒ«CDNãŒç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã¨ã„ã†ã®ã‚‚ã€ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å¤§éƒ¨åˆ†ã¯æœ€è¿‘ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚Œã€CDNã«æ®‹ã£ã¦ã„ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã‹ã‚‰ã§ã™ã€‚æ¬ ç‚¹: CDNCDNã®ã‚³ã‚¹ãƒˆã¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯é‡ã«ã‚ˆã£ã¦å¤‰ã‚ã‚Šã¾ã™ã€‚ã‚‚ã¡ã‚ã‚“ã€CDNã‚’ä½¿ã‚ãªã„å ´åˆã®ã‚³ã‚¹ãƒˆã¨æ¯”è¼ƒã™ã‚‹ã¹ãã§ã—ã‚‡ã†ã€‚TTLãŒåˆ‡ã‚Œã‚‹å‰ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ›´æ–°ã•ã‚Œã‚‹ã¨é™³è…åŒ–ã™ã‚‹æã‚ŒãŒã‚ã‚Šã¾ã™ã€‚CDNã§ã¯é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒCDNã‚’æŒ‡ã™ã‚ˆã†ã«URLã‚’æ›´æ–°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«åˆ†æ•£ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ—ãƒƒã‚·ãƒ¥CDNã¨ãƒ—ãƒ«CDNã®é•ã„Wikipediaãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼      Source: Scalable system design patternsãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯å…¥åŠ›ã•ã‚Œã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã¨åˆ†æ•£ã•ã›ã‚‹ã€‚ã©ã®ã‚±ãƒ¼ã‚¹ã§ã‚‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ã‚µãƒ¼ãƒãƒ¼ç­‰è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é©åˆ‡ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è¿”ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ä»¥ä¸‹ã®ã“ã¨ã«åŠ¹æœçš„ã§ã™:ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒçŠ¶æ…‹ã®è‰¯ããªã„ã‚µãƒ¼ãƒãƒ¼ã«è¡Œãã®ã‚’é˜²ããƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’éå‰°ã«é€ã‚‹ã®ã‚’é˜²ãç‰¹å®šç®‡æ‰€ã®æ¬ é™¥ã§ã‚µãƒ¼ãƒ“ã‚¹ãŒè½ã¡ã‚‹ã“ã¨ã‚’é˜²ããƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ (è²»ç”¨ã®é«˜ã„) ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚‚ã—ãã¯HAProxyãªã©ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã§å®Ÿç¾ã§ãã‚‹ã€‚ä»–ã®åˆ©ç‚¹ã¨ã—ã¦ã¯:SSL termination - å…¥åŠ›ã•ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£èª­ã™ã‚‹ã€ã¾ãŸã€ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æš—å·åŒ–ã™ã‚‹ã“ã¨ã§ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã‚µãƒ¼ãƒãƒ¼ãŒã“ã®ã‚³ã‚¹ãƒˆãŒé«˜ãã¤ããŒã¡ãªå‡¦ç†ã‚’è«‹ã‘è² ã‚ãªãã¦ã„ã„ã‚ˆã†ã«è‚©ä»£ã‚ã‚Šã—ã¾ã™ã€‚X.509 certificates ã‚’ãã‚Œãã‚Œã®ã‚µãƒ¼ãƒãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ã‚’ãªãã—ã¾ã™ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† - ã‚¯ãƒƒã‚­ãƒ¼ã‚’å–ã‚Šæ‰±ã†ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªãŒã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ãªã„æ™‚ãªã©ã«ã€ç‰¹å®šã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åŒã˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¸ã¨æµã—ã¾ã™ã€‚éšœå®³ã«å¯¾å¿œã™ã‚‹ãŸã‚ã«ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ– ã‚‚ã—ãã¯ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ– ãƒ¢ãƒ¼ãƒ‰ã®ã©ã¡ã‚‰ã«ãŠã„ã¦ã‚‚ã€è¤‡æ•°ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’é…ç½®ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªç¨®ã€…ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç”¨ã„ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™:ãƒ©ãƒ³ãƒ€ãƒ Least loadedã‚»ãƒƒã‚·ãƒ§ãƒ³/ã‚¯ãƒƒã‚­ãƒ¼ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ã‚‚ã—ãã¯åŠ é‡ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³Layer 4Layer 7Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ ã‚’å‚ç…§ã—ã¦ã©ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é…åˆ†ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ã—ã¦ã¯ã€ã‚½ãƒ¼ã‚¹ã€é€ä¿¡å…ˆIPã‚¢ãƒ‰ãƒ¬ã‚¹ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã«è¨˜è¿°ã•ã‚ŒãŸãƒãƒ¼ãƒˆç•ªå·ãŒå«ã¾ã‚Œã¾ã™ãŒã€ãƒ‘ã‚±ãƒƒãƒˆã®ä¸­èº«ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å«ã¿ã¾ã›ã‚“ã€‚ Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‘ã‚±ãƒƒãƒˆã‚’ä¸Šæµã‚µãƒ¼ãƒãƒ¼ã¸å±Šã‘ã€ä¸Šæµã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰é…ä¿¡ã™ã‚‹ã“ã¨ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ‰ãƒ¬ã‚¹å¤‰æ› Network Address Translation (NAT) ã‚’å®Ÿç¾ã—ã¾ã™ã€‚Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ ã‚’å‚ç…§ã—ã¦ã©ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é…åˆ†ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ã‚¯ãƒƒã‚­ãƒ¼ãªã©ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã“ã¨ã§ã™ã€‚Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®çµ‚ç«¯ã‚’å—ã‘æŒã¡ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã®åˆ¤æ–­ã‚’ã—ã€é¸æŠã—ãŸã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šã‚’ç¹‹ãã¾ã™ã€‚ä¾‹ãˆã° layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯å‹•ç”»ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ç›´æ¥ã€ãã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ›ã‚¹ãƒˆã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒãƒ¼ã«ã¤ãªãã¨åŒæ™‚ã«ã€æ±ºæ¸ˆå‡¦ç†ãªã©ã®ã‚ˆã‚Šç¹Šç´°ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ã«æµã™ã¨ã„ã†ã“ã¨ã‚‚ã§ãã‚‹ã€‚æŸ”è»Ÿæ€§ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãªã‚Šã¾ã™ãŒã€ layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ã¯Layer 7ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚ˆã‚Šã‚‚æ‰€è¦æ™‚é–“ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å°‘ãªãæ¸ˆã¾ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãŸã ã—ã€æ˜¨ä»Šã®æ±ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯æœ€å°é™ã®ã¿ã—ã‹ç™ºæ®ã§ããªã„ã§ã—ã‚‡ã†ã€‚æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ã¯æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å¯ç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ‰‹é ƒãªæ±ç”¨ãƒã‚·ãƒ³ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã•ã›ã‚‹æ–¹ãŒã€ä¸€ã¤ã®ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚ˆã‚Šé«˜ä¾¡ãªãƒã‚·ãƒ³ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ï¼ˆå‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã‚ˆã‚Šè²»ç”¨å¯¾åŠ¹æœã‚‚é«˜ããªã‚Šã€çµæœçš„ã«å¯ç”¨æ€§ã‚‚é«˜ããªã‚Šã¾ã™ã€‚ã¾ãŸã€æ±ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ‰±ãˆã‚‹äººæã‚’é›‡ã†æ–¹ãŒã€ç‰¹åŒ–å‹ã®å•†ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ‰±ãˆã‚‹äººæã‚’é›‡ã†ã‚ˆã‚Šã‚‚ç°¡å˜ã§ã—ã‚‡ã†ã€‚æ¬ ç‚¹: æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ°´å¹³çš„ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã„ãã¨ã€è¤‡é›‘ã•ãŒå¢—ã™ä¸Šã«ã€ã‚µãƒ¼ãƒãƒ¼ã®ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã«ãªã‚‹ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢é€£ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚„ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å†™çœŸãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã¯ã„ã‘ãªã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ä¸€å…ƒçš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (SQLã€ NoSQL)ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã«ã‚¹ãƒˆã‚¢ã•ã‚Œã‚‹ã‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ (Redisã€ Memcached)ã«æ®‹ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®ä¸‹æµã‚µãƒ¼ãƒãƒ¼ã¯ä¸Šæµã‚µãƒ¼ãƒãƒ¼ãŒã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã™ã‚‹ã«ã¤ã‚Œã¦ã‚ˆã‚Šå¤šãã®åŒæ™‚æ¥ç¶šã‚’ä¿ãŸãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚æ¬ ç‚¹: ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒªã‚½ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ãŸã‚Šã€è¨­å®šãŒé©åˆ‡ã§ãªã„å ´åˆã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å˜ä¸€éšœå®³ç‚¹ã‚’é™¤ã“ã†ã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’å°å…¥ã—ãŸçµæœã€è¤‡é›‘ã•ãŒå¢—ã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãŒä¸€ã¤ã ã‘ã ã¨ãã“ãŒå˜ä¸€éšœå®³ç‚¹ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚ä¸€æ–¹ã§ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’è¤‡æ•°ã«ã™ã‚‹ã¨ã€ã•ã‚‰ã«è¤‡é›‘ã•ãŒå¢—ã—ã¦ã—ã¾ã„ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸NGINX ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HAProxy ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¬ã‚¤ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£WikipediaLayer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ELB listener configãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·(webã‚µãƒ¼ãƒãƒ¼)      Source: Wikipedia  ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã¯å†…éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã¾ã¨ã‚ã¦å¤–éƒ¨ã«çµ±ä¸€ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãã‚Œã«å¯¾å¿œã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œã¦ã€ãã®å¾Œãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è¿”ã—ã¾ã™ã€‚ä»–ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªåˆ©ç‚¹ãŒã‚ã‚Šã¾ã™:ã‚ˆã‚Šå …ç‰¢ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã‚’éš ã—ãŸã‚Šã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆåŒ–ã—ãŸã‚Šã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã”ã¨ã®æ¥ç¶šæ•°ã‚’åˆ¶é™ã—ãŸã‚Šã§ãã¾ã™ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚„æŸ”è»Ÿæ€§ãŒå¢—ã—ã¾ã™ - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã®IPã—ã‹è¦‹ãªã„ã®ã§ã€è£ã§ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã—ãŸã‚Šã€è¨­å®šã‚’å¤‰ãˆã‚„ã™ããªã‚Šã¾ã™ã€‚SSL termination - å…¥åŠ›ã•ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£èª­ã—ã€ã‚µãƒ¼ãƒãƒ¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æš—å·åŒ–ã™ã‚‹ã“ã¨ã§ã‚µãƒ¼ãƒãƒ¼ãŒã“ã®ã‚³ã‚¹ãƒˆã®ã‹ã‹ã‚Šã†ã‚‹å‡¦ç†ã‚’ã—ãªãã¦æ¸ˆã‚€ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚X.509 è¨¼æ˜æ›¸ ã‚’å„ã‚µãƒ¼ãƒãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚åœ§ç¸® - ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åœ§ç¸®ã§ãã¾ã™ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚° - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã—ã¾ã™é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ - é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥é€ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚HTML/CSS/JSå†™çœŸå‹•ç”»ãªã©ãªã©ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ vs ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·è¤‡æ•°ã®ã‚µãƒ¼ãƒãƒ¼ãŒã‚ã‚‹æ™‚ã«ã¯ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨å½¹ã«ç«‹ã¤ã§ã—ã‚‡ã†ã€‚ ã—ã°ã—ã°ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯åŒã˜æ©Ÿèƒ½ã‚’æœãŸã™ã‚µãƒ¼ãƒãƒ¼ç¾¤ã¸ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã¾ã™ã€‚ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã§ã¯ã€ä¸Šè¨˜ã«è¿°ã¹ãŸã‚ˆã†ãªåˆ©ç‚¹ã‚’ã€å˜ä¸€ã®ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã‚„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å¯¾ã—ã¦ã‚‚ç¤ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚NGINX ã‚„ HAProxy ãªã©ã®æŠ€è¡“ã¯layer 7 ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚æ¬ ç‚¹: ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’å°å…¥ã™ã‚‹ã¨ã‚·ã‚¹ãƒ†ãƒ ã®è¤‡é›‘æ€§ãŒå¢—ã—ã¾ã™ã€‚å˜ä¸€ã®ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã¯å˜ä¸€éšœå®³ç‚¹ã«ãªã‚Šãˆã¾ã™ã€‚ä¸€æ–¹ã§ã€è¤‡æ•°ã®ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’å°å…¥ã™ã‚‹ã¨(ä¾‹: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼) è¤‡é›‘æ€§ã¯ã‚ˆã‚Šå¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· vs ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼NGINX ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HAProxy ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ã‚¬ã‚¤ãƒ‰Wikipediaã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤      Source: Intro to architecting systems for scaleã‚¦ã‚§ãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ (ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å±¤ã¨ã‚‚è¨€ã‚ã‚Œã‚‹) ã¨åˆ†é›¢ã™ã‚‹ã“ã¨ã§ãã‚Œãã‚Œã®å±¤ã‚’ç‹¬ç«‹ã«ã‚¹ã‚±ãƒ¼ãƒ«ã€è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚æ–°ã—ã„APIã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã«è¿½åŠ ã™ã‚‹éš›ã«ã€ä¸å¿…è¦ã«ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚å˜ä¸€è²¬ä»»ã®åŸå‰‡ ã§ã¯ã€å°ã•ã„è‡ªå¾‹çš„ãªã‚µãƒ¼ãƒ“ã‚¹ãŒå”èª¿ã—ã¦å‹•ãã‚ˆã†ã«æå”±ã—ã¦ã„ã¾ã™ã€‚å°ã•ã„ã‚µãƒ¼ãƒ“ã‚¹ã®å°ã•ã„ãƒãƒ¼ãƒ ãŒæ€¥æˆé•·ã®ãŸã‚ã«ã‚ˆã‚Šç©æ¥µçš„ãªè¨ˆç”»ã‚’ç«‹ã¦ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã¯éåŒæœŸå‡¦ç†ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ç‹¬ç«‹ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹ã€å°è¦æ¨¡ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§˜å¼ã§ã‚ã‚‹ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚‚ã“ã®è­°è«–ã«é–¢ä¿‚ã—ã¦ãã‚‹æŠ€è¡“ã§ã—ã‚‡ã†ã€‚ãã‚Œãã‚Œã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ç‹¬è‡ªã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å‡¦ç†ã—ã€æ˜ç¢ºã§è»½é‡ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§é€šä¿¡ã—ã¦ã€ãã®ç›®çš„ã¨ã™ã‚‹æ©Ÿèƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚1ä¾‹ãˆã°Pinterestã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã€ãƒ•ã‚£ãƒ¼ãƒ‰ã€æ¤œç´¢ã€å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãªã©ã§ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼Consulã€ Etcdã€ Zookeeper ãªã©ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®åå‰ã€ã‚¢ãƒ‰ãƒ¬ã‚¹ã€ãƒãƒ¼ãƒˆã®æƒ…å ±ã‚’ç›£è¦–ã™ã‚‹ã“ã¨ã§ã€ã‚µãƒ¼ãƒ“ã‚¹åŒå£«ãŒäº’ã„ã‚’è¦‹ã¤ã‘ã‚„ã™ãã—ã¦ã„ã¾ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ã®å®Œå…¨æ€§ã®ç¢ºèªã«ã¯ Health checks ãŒä¾¿åˆ©ã§ã€ã“ã‚Œã«ã¯ HTTP ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚ Consul ã¨ Etcd ã®ã„ãšã‚Œã‚‚çµ„ã¿è¾¼ã¿ã® key-value store ã‚’æŒã£ã¦ãŠã‚Šã€è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚„å…±æœ‰ãƒ‡ãƒ¼ã‚¿ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¦ãŠãã“ã¨ã«ä½¿ã‚ã‚Œã¾ã™ã€‚æ¬ ç‚¹: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€é‹ç”¨ã€ãã—ã¦ãƒ—ãƒ­ã‚»ã‚¹ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ç·©ãçµã³ä»˜ã‘ã‚‰ã‚ŒãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‚’è¿½åŠ ã™ã‚‹ã«ã¯ã€ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒ‡ãƒ—ãƒ­ã‚¤ã¨é‹ç”¨ã®ç‚¹ã‹ã‚‰è¦‹ã‚‹ã¨è¤‡é›‘æ€§ãŒå¢—ã™ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒˆãƒ­ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’ç´è§£ãã‚µãƒ¼ãƒ“ã‚¹æŒ‡å‘ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Zookeeperã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½œã‚‹ãŸã‚ã«çŸ¥ã£ã¦ãŠããŸã„ã“ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹      Source: Scaling up to your first 10 million usersãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (RDBMS)SQLãªã©ã®ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ•´ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®é›†åˆã§ã‚ã‚‹ã€‚ACID ã¯ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãŠã‘ã‚‹ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®é›†åˆã§ã‚ã‚‹ä¸å¯åˆ†æ€§ - ãã‚Œãã‚Œã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ã‚‹ã‹ãªã„ã‹ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹ä¸€è²«æ€§ - ã©ã‚“ãªãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚ã‚‹ç¢ºã‹ãªçŠ¶æ…‹ã‹ã‚‰æ¬¡ã®çŠ¶æ…‹ã«é·ç§»ã•ã›ã‚‹ã€‚ç‹¬ç«‹æ€§ - åŒæ™‚ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ã¯ã€é€£ç¶šçš„ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã®ã¨åŒã˜çµæœã‚’ã‚‚ãŸã‚‰ã™ã€‚æ°¸ç¶šæ€§ - ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãŒå‡¦ç†ã•ã‚ŒãŸã‚‰ã€ãã®ã‚ˆã†ã«ä¿å­˜ã•ã‚Œã‚‹ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ãŸã‚ã«ã¯ãŸãã•ã‚“ã®æŠ€è¡“ãŒã‚ã‚‹: ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ federationã€ ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ éæ­£è¦åŒ–ã€ ãã—ã¦ SQL ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒèª­ã¿å–ã‚Šã¨æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã—ã€æ›¸ãè¾¼ã¿ã‚’ä¸€ã¤ä»¥ä¸Šã®ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¤‡è£½ã—ã¾ã™ã€‚ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯èª­ã¿å–ã‚Šã®ã¿ã‚’å‡¦ç†ã—ã¾ã™ã€‚ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æœ¨æ§‹é€ ã®ã‚ˆã†ã«è¿½åŠ ã®ã‚¹ãƒ¬ãƒ¼ãƒ–ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã«ãªã£ãŸå ´åˆã«ã¯ã€ã„ãšã‚Œã‹ã®ã‚¹ãƒ¬ãƒ¼ãƒ–ãŒãƒã‚¹ã‚¿ãƒ¼ã«æ˜‡æ ¼ã™ã‚‹ã‹ã€æ–°ã—ã„ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚Œã‚‹ã¾ã§ã¯èª­ã¿å–ã‚Šå°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ã§ç¨¼åƒã—ã¾ã™ã€‚      Source: Scalability, availability, stability, patternsæ¬ ç‚¹: ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ãƒ¬ãƒ¼ãƒ–ã‚’ãƒã‚¹ã‚¿ãƒ¼ã«æ˜‡æ ¼ã•ã›ã‚‹ã«ã¯è¿½åŠ ã®ãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…è¦ã«ãªã‚‹ã€‚ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® ä¸¡æ–¹ ã®æ¬ ç‚¹ã¯æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã„ãšã‚Œã®ãƒã‚¹ã‚¿ãƒ¼ã‚‚èª­ã¿å–ã‚Šæ›¸ãè¾¼ã¿ã®ä¸¡æ–¹ã«å¯¾å¿œã™ã‚‹ã€‚æ›¸ãè¾¼ã¿ã«é–¢ã—ã¦ã¯ãã‚Œãã‚Œå”èª¿ã™ã‚‹ã€‚ã„ãšã‚Œã‹ã®ãƒã‚¹ã‚¿ãƒ¼ãŒè½ã¡ã¦ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¨ã—ã¦ã¯èª­ã¿æ›¸ãä¸¡æ–¹ã«å¯¾å¿œã—ãŸã¾ã¾é‹ç”¨ã§ãã‚‹ã€‚      Source: Scalability, availability, stability, patternsæ¬ ç‚¹: ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’å°å…¥ã™ã‚‹ã‹ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã©ã“ã«æ›¸ãè¾¼ã‚€ã‹ã‚’æŒ‡å®šã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚å¤§ä½“ã®ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä¸€è²«æ€§ãŒç·©ã„ï¼ˆACIDåŸç†ã‚’å®ˆã£ã¦ã„ãªã„ï¼‰ã‚‚ã—ãã¯ã€åŒæœŸã™ã‚‹æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã«æ›¸ãè¾¼ã¿ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã€‚æ›¸ãè¾¼ã¿ãƒãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚Œã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œæ›¸ãè¾¼ã¿ã®è¡çªã®å¯èƒ½æ€§ãŒå¢—ãˆã‚‹ã€‚ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® ä¸¡æ–¹ ã®æ¬ ç‚¹ã¯æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã‚’å‚ç…§æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚’è¤‡è£½ã™ã‚‹å‰ã«ãƒã‚¹ã‚¿ãƒ¼ãŒè½ã¡ãŸå ´åˆã«ã¯ãã®ãƒ‡ãƒ¼ã‚¿ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æ›¸ãè¾¼ã¿ã¯èª­ã¿å–ã‚Šãƒ¬ãƒ—ãƒªã‚«ã«ãŠã„ã¦ãƒªãƒ—ãƒ¬ã‚¤ã•ã‚Œã‚‹ã€‚æ›¸ãè¾¼ã¿ãŒå¤šã„å ´åˆã€è¤‡è£½ãƒãƒ¼ãƒ‰ãŒæ›¸ãè¾¼ã¿ã®å‡¦ç†ã®ã¿ã§è¡Œãè©°ã¾ã£ã¦ã€èª­ã¿å–ã‚Šã®å‡¦ç†ã‚’æº€è¶³ã«è¡Œãˆãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚èª­ã¿å–ã‚Šã‚¹ãƒ¬ãƒ¼ãƒ–ãƒãƒ¼ãƒ‰ã®æ•°ãŒå¤šã‘ã‚Œã°å¤šã„ã»ã©ã€è¤‡è£½ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„æ•°ã‚‚å¢—ãˆã€è¤‡è£½æ™‚é–“ãŒä¼¸ã³ã¦ã—ã¾ã„ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã£ã¦ã¯ã€ãƒã‚¹ã‚¿ãƒ¼ã¸ã®æ›¸ãè¾¼ã¿ã¯ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§ä¸¦åˆ—å‡¦ç†ã§ãã‚‹ä¸€æ–¹ã€ã‚¹ãƒ¬ãƒ¼ãƒ–ã¸ã®è¤‡è£½ã¯å˜ä¸€ã‚¹ãƒ¬ãƒƒãƒ‰ã§é€£ç¶šçš„ã«å‡¦ç†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€ å¯ç”¨æ€§ã€ ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒ«ãƒãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³Federation      Source: Scaling up to your first 10 million usersãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (ã‚‚ã—ãã¯æ©Ÿèƒ½åˆ†å‰²åŒ–ã¨ã‚‚è¨€ã†) ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ©Ÿèƒ½ã”ã¨ã«åˆ†å‰²ã™ã‚‹ã€‚ä¾‹ãˆã°ã€ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªå˜ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä»£ã‚ã‚Šã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã€ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ ã®ã‚ˆã†ã«ä¸‰ã¤ã«ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸€ã¤ã‚ãŸã‚Šã®æ›¸ãè¾¼ã¿ãƒ»èª­ã¿å–ã‚Šã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒæ¸›ã‚Šã€ãã®çµæœãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ©ã‚°ã‚‚çŸ­ããªã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå°ã•ããªã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã«åã¾ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒå¢—ãˆã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å±€æ‰€æ€§ãŒé«˜ã¾ã‚‹ãŸã‚ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã‚‚ä¸ŠãŒã‚Šã¾ã™ã€‚å˜ä¸€ã®ä¸­å¤®ãƒã‚¹ã‚¿ãƒ¼ã§æ›¸ãè¾¼ã¿ã‚’ç›´åˆ—åŒ–ã—ãŸã‚Šã—ãªã„ãŸã‚ã€ä¸¦åˆ—ã§æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚æ¬ ç‚¹: federationå¤§è¦æ¨¡ãªå‡¦ç†ã‚„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¦ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒã®å ´åˆã€ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯åŠ¹æœçš„ã¨ã¯è¨€ãˆãªã„ã§ã—ã‚‡ã†ã€‚ã©ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«èª­ã¿æ›¸ãã‚’ã™ã‚‹ã®ã‹ã‚’æŒ‡å®šã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ›´æ–°ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚server linkã§äºŒã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€£çµã™ã‚‹ã®ã¯ã‚ˆã‚Šè¤‡é›‘ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: federationScaling up to your first 10 million usersã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°      Source: Scalability, availability, stability, patternsã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãã‚Œãã‚ŒãŒãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ–ã‚»ãƒƒãƒˆæ–­ç‰‡ã®ã¿ã‚’æŒã¤ã‚ˆã†ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¾‹ã«ã¨ã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«ã¯ã‚ˆã‚Šå¤šãã®æ–­ç‰‡ãŒåŠ ãˆã‚‰ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚federationã®åˆ©ç‚¹ã«ä¼¼ã¦ã„ã¦ã€ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯èª­ã¿æ›¸ãã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æ¸›ã‚‰ã—ã€ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¸›ã‚‰ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã‚’å¢—ã‚„ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚‚æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™ã¨ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã‚¯ã‚¨ãƒªé€Ÿåº¦ãŒé€Ÿããªã‚Šã¾ã™ã€‚ãªã«ãŒã—ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡è£½ã™ã‚‹æ©Ÿèƒ½ãŒãªã‘ã‚Œã°ãƒ‡ãƒ¼ã‚¿ãƒ­ã‚¹ã«ã¤ãªãŒã‚Šã¾ã™ãŒã€ã‚‚ã—ã€ä¸€ã¤ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒè½ã¡ã¦ã‚‚ã€ä»–ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒå‹•ã„ã¦ã„ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜ãã€å˜ä¸€ã®ä¸­å¤®ãƒã‚¹ã‚¿ãƒ¼ãŒæ›¸ãè¾¼ã¿ã®å‡¦ç†ã‚’ã—ãªãã¦ã‚‚ã€ä¸¦åˆ—ã§æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ä¸€èˆ¬çš„ãªæ–¹æ³•ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ©ã‚¹ãƒˆãƒãƒ¼ãƒ ã‚¤ãƒ‹ã‚·ãƒ£ãƒ«ã§ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åœ°ç†çš„é…ç½®ã§ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ãªã©ã§ã™ã€‚æ¬ ç‚¹: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒ£ãƒ¼ãƒ‰ã«å¯¾å¿œã™ã‚‹ã‚ˆã†ã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚çµæœã¨ã—ã¦SQLã‚¯ã‚¨ãƒªãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ‰ã§ã¯ãƒ‡ãƒ¼ã‚¿é…åˆ†ãŒã„ã³ã¤ã«ãªã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€æ¨™æº–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é›†åˆã‚’æŒã¤ã‚·ãƒ£ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã€ãã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒä»–ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚ˆã‚Šã‚‚é‡ã„è² è·ã‚’è² ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒªãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã‚’ã™ã‚‹ã¨è¤‡é›‘æ€§ãŒã‚ˆã‚Šå¢—ã—ã¾ã™ã€‚consistent hashing ã«åŸºã¥ã„ãŸã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ã€é€šä¿¡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚è¤‡æ•°ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€£çµã™ã‚‹ã®ã¯ã‚ˆã‚Šè¤‡é›‘ã§ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒ£ãƒ¼ãƒ‰ã®ç™»å ´ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Consistent hashingéæ­£è¦åŒ–éæ­£è¦åŒ–ã§ã¯ã€æ›¸ãè¾¼ã¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã„ãã‚‰ã‹çŠ ç‰²ã«ã—ã¦èª­ã¿è¾¼ã¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚ˆã†ã¨ã—ã¾ã™ã€‚è¨ˆç®—çš„ã«é‡ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµåˆãªã©ã‚’ã›ãšã«ã€è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«å†—é•·ãªãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ãŒæ›¸ãè¾¼ã¾ã‚Œã‚‹ã®ã‚’è¨±å®¹ã—ã¾ã™ã€‚ã„ãã¤ã‹ã®RDBMSä¾‹ãˆã°ã€PostgreSQL ã‚„Oracleã¯ã“ã®å†—é•·ãªæƒ…å ±ã‚’å–ã‚Šæ‰±ã„ã€ä¸€è²«æ€§ã‚’ä¿ã¤ãŸã‚ã®materialized views ã¨ã„ã†æ©Ÿèƒ½ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ã‚„ ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã«ã‚ˆã£ã¦ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã«åˆ†é…ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’åˆä¸€ã•ã›ã‚‹ã“ã¨ã¯ã¨ã¦ã‚‚è¤‡é›‘ãªä½œæ¥­ã§ã™ã€‚éæ­£è¦åŒ–ã«ã‚ˆã£ã¦ãã®ã‚ˆã†ãªè¤‡é›‘ãªå‡¦ç†ã‚’ã—ãªãã¦æ¸ˆã‚€ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚å¤šãã®ã‚·ã‚¹ãƒ†ãƒ ã§ã€100å¯¾1ã‚ã‚‹ã„ã¯1000å¯¾1ãã‚‰ã„ã«ãªã‚‹ãã‚‰ã„èª­ã¿å–ã‚Šã®æ–¹ãŒã€æ›¸ãè¾¼ã¿ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚ˆã‚Šã‚‚å¤šã„ã“ã¨ã§ã—ã‚‡ã†ã€‚èª­ã¿è¾¼ã¿ã‚’è¡Œã†ãŸã‚ã«ã€è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¸ãƒ§ã‚¤ãƒ³å‡¦ç†ãŒå«ã¾ã‚Œã‚‹ã‚‚ã®ã¯è¨ˆç®—çš„ã«é«˜ä¾¡ã«ã¤ãã¾ã™ã—ã€ãƒ‡ã‚£ã‚¹ã‚¯ã®å‡¦ç†æ™‚é–“ã§è†¨å¤§ãªæ™‚é–“ã‚’è²»æ¶ˆã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ¬ ç‚¹: éæ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ãŒè¤‡è£½ã•ã‚Œã‚‹ã€‚å†—é•·ãªãƒ‡ãƒ¼ã‚¿ã®è¤‡è£½ãŒåŒæœŸã•ã‚Œã‚‹ã‚ˆã†ã«åˆ¶ç´„ãŒå­˜åœ¨ã—ã€ãã®ã“ã¨ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®è¨­è¨ˆãŒè¤‡é›‘åŒ–ã™ã‚‹ã€‚éæ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯éå¤§ãªæ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å ´åˆã€æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ãã‚Œã‚ˆã‚Šã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ãŠã„ã¦åŠ£ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: éæ­£è¦åŒ–DenormalizationSQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯åºƒç¯„ãªçŸ¥è­˜ã‚’å¿…è¦ã¨ã™ã‚‹åˆ†é‡ã§å¤šãã® æœ¬ ãŒæ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’æ˜ã‚‰ã‹ã«ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ä¸Šã§ã€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ã‚’å®šã‚ã€ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« ã™ã‚‹ã“ã¨ã¯ã¨ã¦ã‚‚é‡è¦ã§ã™ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - abãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€é«˜è² è·ã®çŠ¶æ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« - slow query log ãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çŠ¶æ³ã®ç¢ºèªã‚’ã—ã¾ã—ã‚‡ã†ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¨ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®ã‚ˆã†ãªåŠ¹ç‡åŒ–ã®é¸æŠè‚¢ã‚’ã¨ã‚‹ã“ã¨ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¹ã‚­ãƒ¼ãƒã‚’çµã‚‹MySQLã¯ã‚¢ã‚¯ã‚»ã‚¹é€Ÿåº¦å‘ä¸Šã®ãŸã‚ã€ãƒ‡ã‚£ã‚¹ã‚¯ä¸Šã®é€£ç¶šã—ãŸãƒ–ãƒ­ãƒƒã‚¯ã¸ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã—ã¦ã„ã¾ã™ã€‚é•·ã•ã®æ±ºã¾ã£ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å¯¾ã—ã¦ã¯ VARCHAR ã‚ˆã‚Šã‚‚ CHAR ã‚’ä½¿ã†ã‚ˆã†ã«ã—ã¾ã—ã‚‡ã†ã€‚CHAR ã®æ–¹ãŒåŠ¹ç‡çš„ã«é€Ÿããƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ ä¸€æ–¹ã€ VARCHAR ã§ã¯æ¬¡ã®ãƒ‡ãƒ¼ã‚¿ã«ç§»ã‚‹å‰ã«ãƒ‡ãƒ¼ã‚¿ã®æœ«å°¾ã‚’æ¤œçŸ¥ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ãŸã‚ã«é€Ÿåº¦ãŒçŠ ç‰²ã«ãªã‚Šã¾ã™ã€‚ãƒ–ãƒ­ã‚°ã®æŠ•ç¨¿ãªã©ã€å¤§ããªãƒ†ã‚­ã‚¹ãƒˆã«ã¯ TEXT ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚ TEXT ã§ã¯ãƒ–ãƒ¼ãƒªã‚¢ãƒ³å‹ã®æ¤œç´¢ã‚‚å¯èƒ½ã§ã™ã€‚ TEXT ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ã€ãƒ‡ã‚£ã‚¹ã‚¯ä¸Šã®å ´æ‰€ã¸ã®ãƒã‚¤ãƒ³ã‚¿ãƒ¼ãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚2ã®32ä¹—ã‚„40å„„ä»¥ä¸‹ã‚’è¶…ãˆãªã„ç¨‹åº¦ã®å¤§ããªæ•°ã«ã¯ INT ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚é€šè²¨ã«é–¢ã—ã¦ã¯å°æ•°ç‚¹è¡¨ç¤ºä¸Šã®ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã« DECIMAL ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚å¤§ããª BLOBS ã‚’ä¿å­˜ã™ã‚‹ã®ã¯é¿ã‘ã¾ã—ã‚‡ã†ã€‚ã©ã“ã‹ã‚‰ãã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–ã£ã¦ãã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã®æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚VARCHAR(255) ã¯8ãƒ“ãƒƒãƒˆã§æ•°ãˆã‚‰ã‚Œã‚‹æœ€å¤§ã®æ–‡å­—æ•°ã§ã™ã€‚ä¸€éƒ¨ã®DBMSã§ã¯ã€1ãƒã‚¤ãƒˆã®åˆ©ç”¨åŠ¹ç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«ã“ã®æ–‡å­—æ•°ãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚æ¤œç´¢æ€§èƒ½å‘ä¸Šã®ãŸã‚ ã€å¯èƒ½ã§ã‚ã‚Œã° NOT NULL åˆ¶ç´„ã‚’è¨­å®šã—ã¾ã—ã‚‡ã†ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åŠ¹æœçš„ã«ç”¨ã„ã‚‹ã‚¯ã‚¨ãƒª(SELECTã€ GROUP BYã€ ORDER BYã€ JOIN) ã®å¯¾è±¡ã¨ãªã‚‹åˆ—ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã†ã“ã¨ã§é€Ÿåº¦ã‚’å‘ä¸Šã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯é€šå¸¸ã€å¹³è¡¡æ¢ç´¢æœ¨ã§ã‚ã‚‹Bæœ¨ã®å½¢ã§è¡¨ã•ã‚Œã¾ã™ã€‚Bæœ¨ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ã¯å¸¸ã«ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸçŠ¶æ…‹ã«ãªã‚Šã¾ã™ã€‚ã¾ãŸæ¤œç´¢ã€é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ã€æŒ¿å…¥ã€å‰Šé™¤ã‚’å¯¾æ•°æ™‚é–“ã§è¡Œãˆã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é…ç½®ã™ã‚‹ã“ã¨ã¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªãƒ¼ã«æ®‹ã™ã“ã¨ã«ã¤ãªãŒã‚Šã‚ˆã‚Šå®¹é‡ã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°ã‚‚å¿…è¦ã«ãªã‚‹ãŸã‚æ›¸ãè¾¼ã¿ã‚‚é…ããªã‚Šã¾ã™ã€‚å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹éš›ã«ã¯ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ‡ã£ã¦ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å†ã³ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ“ãƒ«ãƒ‰ã—ãŸæ–¹ãŒé€Ÿã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚é«˜è² è·ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’é¿ã‘ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šå¿…è¦ãªã¨ã“ã‚ã«ã¯éæ­£è¦åŒ–ã‚’é©ç”¨ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆ†å‰²ã—ã€ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆã‚’ç‹¬ç«‹ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã«åˆ†é›¢ã—ã¦ãƒ¡ãƒ¢ãƒªãƒ¼ã«ä¹—ã›ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª¿æ•´ã™ã‚‹å ´åˆã«ã‚ˆã£ã¦ã¯ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°MySQLã‚¯ã‚¨ãƒªã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®TipsVARCHAR(255)ã‚’ã‚„ãŸã‚‰ã‚ˆãè¦‹ã‹ã‘ã‚‹ã®ã¯ãªã‚“ã§ï¼Ÿnullå€¤ã¯ã©ã®ã‚ˆã†ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã™ã‚‹ã®ã‹ï¼ŸSlow query logNoSQLNoSQL ã¯ key-value storeã€ document-storeã€ wide column storeã€ ã‚‚ã—ãã¯ graph databaseã«ã‚ˆã£ã¦è¡¨ç¾ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¤ãƒ†ãƒ ã®é›†åˆã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ä¸€èˆ¬çš„ã«æ­£è¦åŒ–ã•ã‚Œã¦ãŠã‚‰ãšã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã§ã‚¸ãƒ§ã‚¤ãƒ³ãŒè¡Œã‚ã‚Œã¾ã™ã€‚å¤§éƒ¨åˆ†ã®NoSQLã¯çœŸã®ACIDãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŒãŸãšã€ çµæœæ•´åˆæ€§ çš„ãªæŒ¯ã‚‹èˆã„ã®æ–¹ã‚’å¥½ã¿ã¾ã™ã€‚BASE ã¯ã—ã°ã—ã°NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚CAP Theorem ã¨å¯¾ç…§çš„ã«ã€BASEã¯ä¸€è²«æ€§ã‚ˆã‚Šã‚‚å¯ç”¨æ€§ã‚’å„ªå…ˆã—ã¾ã™ã€‚Basically available - ã‚·ã‚¹ãƒ†ãƒ ã¯å¯ç”¨æ€§ã‚’ä¿è¨¼ã—ã¾ã™ã€‚Soft state - ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã¯å…¥åŠ›ãŒãªãã¦ã‚‚æ™‚é–“çµŒéã¨ã¨ã‚‚ã«å¤‰åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚çµæœæ•´åˆæ€§ - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¯æ™‚é–“çµŒéã¨ã¨ã‚‚ã«ãã®é–“ã«å…¥åŠ›ãŒãªã„ã¨ã„ã†å‰æã®ã‚‚ã¨ã€ä¸€è²«æ€§ãŒé”æˆã•ã‚Œã¾ã™ã€‚SQLã‹ï¼ŸNoSQLã‹ï¼Ÿ ã‚’é¸æŠã™ã‚‹ã®ã«åŠ ãˆã¦ã€ã©ã®ã‚¿ã‚¤ãƒ—ã®NoSQLãŒã©ã®ä½¿ç”¨ä¾‹ã«æœ€ã‚‚é©ã™ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ã®ã¯ã¨ã¦ã‚‚æœ‰ç›Šã§ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã€ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã€ ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã€ ã¨ ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã«ã¤ã„ã¦è§¦ã‚Œã¦ã„ãã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢æ¦‚è¦: ãƒãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ä¸€èˆ¬çš„ã«O(1)ã®èª­ã¿æ›¸ããŒã§ãã€ãã‚Œã‚‰ã¯ãƒ¡ãƒ¢ãƒªãªã„ã—SSDã§è£ä»˜ã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¯ã‚­ãƒ¼ã‚’ è¾æ›¸çš„é †åº ã§ä¿æŒã™ã‚‹ã“ã¨ã§ã‚­ãƒ¼ã®åŠ¹ç‡çš„ãªå–å¾—ã‚’å¯èƒ½ã«ã—ã¦ã„ã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å€¤ã¨ã¨ã‚‚ã«ä¿æŒã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã¯ãƒã‚¤ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãªæŒ™å‹•ãŒå¯èƒ½ã§ã€å˜ç´”ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ãªã©ã®ãƒ‡ãƒ¼ã‚¿ãŒæ€¥é€Ÿã«å¤‰ã‚ã‚‹å ´åˆãªã©ã«ä½¿ã‚ã‚Œã¾ã™ã€‚å˜ç´”ãªå‡¦ç†ã®ã¿ã«æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€è¿½åŠ ã®å‡¦ç†æ©Ÿèƒ½ãŒå¿…è¦ãªå ´åˆã«ã¯ãã®è¤‡é›‘æ€§ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã«è¼‰ã›ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã¯ã‚‚ã£ã¨è¤‡é›‘ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã‚„ã€ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®åŸºæœ¬ã§ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã®æ¬ ç‚¹Redisã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢æ¦‚è¦: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãƒãƒªãƒ¥ãƒ¼ã¨ã—ã¦ä¿å­˜ã•ã‚ŒãŸã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«é–¢ã™ã‚‹å…¨ã¦ã®æƒ…å ±ã‚’æŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ(XMLã€ JSONã€ binaryãªã©)ã‚’ä¸­å¿ƒã«æ®ãˆãŸã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã§ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªèº«ã®å†…éƒ¨æ§‹é€ ã«åŸºã¥ã„ãŸã€APIã‚‚ã—ãã¯ã‚¯ã‚¨ãƒªè¨€èªã‚’æä¾›ã—ã¾ã™ã€‚ ãƒ¡ãƒ¢ï¼šå¤šãã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ã€å€¤ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†æ©Ÿèƒ½ã‚’å«ã‚“ã§ã„ã¾ã™ãŒã€ãã®ã“ã¨ã«ã‚ˆã£ã¦äºŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¨ã®å¢ƒç•Œç·šãŒæ›–æ˜§ã«ãªã£ã¦ã—ã¾ã£ã¦ã„ã¾ã™ã€‚ä»¥ä¸Šã®ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã€ã‚¿ã‚°ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã©ã¨ã—ã¦æ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒå£«ã¯ã¾ã¨ã‚ã¦ã‚°ãƒ«ãƒ¼ãƒ—ã«ã§ãã‚‹ã‚‚ã®ã®ã€ãã‚Œãã‚Œã§å…¨ãç•°ãªã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚MongoDB ã‚„ CouchDB ãªã©ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã‚‚ã€è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã®SQLã®ã‚ˆã†ãªè¨€èªã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚DynamoDB ã¯ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¯é«˜ã„æŸ”è»Ÿæ€§ã‚’æ‹…ä¿ã™ã‚‹ã®ã§ã€é »ç¹ã«å¤‰åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†æ™‚ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹MongoDB ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£CouchDB ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Elasticsearch ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢      Source: SQL & NoSQL, a brief historyæ¦‚è¦: ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒãƒƒãƒ— ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼<è¡Œã‚­ãƒ¼ã€ ã‚«ãƒ©ãƒ <ColKeyã€ Valueã€ Timestamp>>ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬å˜ä½ã¯ã‚«ãƒ©ãƒ ï¼ˆãƒãƒ¼ãƒ ãƒ»ãƒãƒªãƒ¥ãƒ¼ã®ãƒšã‚¢ï¼‰ã§ã™ã€‚ãã‚Œãã‚Œã®ã‚«ãƒ©ãƒ ã¯ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¨ã—ã¦ï¼ˆSQLãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚ˆã†ã«ï¼‰ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¯ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®é›†åˆã§ã™ã€‚ãã‚Œãã‚Œã®ã‚«ãƒ©ãƒ ã«ã¯è¡Œã‚­ãƒ¼ã§ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚åŒã˜è¡Œã‚­ãƒ¼ã‚’æŒã¤ã‚«ãƒ©ãƒ ã¯åŒã˜è¡Œã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã™ã€‚ãã‚Œãã‚Œã®å€¤ã¯ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãŒèµ·ããŸæ™‚ã®ãŸã‚ã«ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å«ã¿ã¾ã™ã€‚Googleã¯Bigtableã‚’åˆã®ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã¨ã—ã¦ç™ºè¡¨ã—ã¾ã—ãŸã€‚ãã‚ŒãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§Hadoopãªã©ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹HBase ã‚„Facebookã«ã‚ˆã‚‹Cassandra ãªã©ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å½±éŸ¿ã‚’ä¸ãˆã¾ã—ãŸã€‚BigTableã€HBaseã‚„Cassandraãªã©ã®ã‚¹ãƒˆã‚¢ã¯ã‚­ãƒ¼ã‚’è¾æ›¸å½¢å¼ã§ä¿æŒã™ã‚‹ã“ã¨ã§é¸æŠã—ãŸã‚­ãƒ¼ãƒ¬ãƒ³ã‚¸ã§ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’åŠ¹ç‡çš„ã«ã—ã¾ã™ã€‚ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã¯é«˜ã„å¯ç”¨æ€§ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’æ‹…ä¿ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã¨ã¦ã‚‚å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‰±ã†ã“ã¨ã«ã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢SQL & NoSQLç°¡å˜ã«æ­´å²ã‚’ã•ã‚‰ã†Bigtable ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HBase ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Cassandra ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹      Source: Graph databaseæ¦‚è¦: ã‚°ãƒ©ãƒ•ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã¯ã€ãã‚Œãã‚Œã®ãƒãƒ¼ãƒ‰ãŒãƒ¬ã‚³ãƒ¼ãƒ‰ã§ã€ãã‚Œãã‚Œã®ã‚¢ãƒ¼ã‚¯ã¯äºŒã¤ã®ãƒãƒ¼ãƒ‰ã‚’ç¹‹ãé–¢ä¿‚æ€§ã¨ã—ã¦å®šç¾©ã•ã‚Œã¾ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯å¤šæ•°ã®å¤–éƒ¨ã‚­ãƒ¼ã‚„å¤šå¯¾å¤šãªã©ã®è¤‡é›‘ãªé–¢ä¿‚æ€§ã‚’è¡¨ã™ã®ã«æœ€é©ã§ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯SNSãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹ã®è¤‡é›‘ãªé–¢ä¿‚æ€§ãƒ¢ãƒ‡ãƒ«ãªã©ã«ã¤ã„ã¦é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚æ¯”è¼ƒçš„æ–°ã—ãã€ã¾ã ä¸€èˆ¬çš„ã«ã¯ç”¨ã„ã‚‰ã‚Œã¦ã„ãªã„ã®ã§ã€é–‹ç™ºãƒ„ãƒ¼ãƒ«ã‚„ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¢ã™ã®ãŒä»–ã®æ–¹æ³•ã«æ¯”ã¹ã¦é›£ã—ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å¤šãã®ã‚°ãƒ©ãƒ•ã¯REST APIsã‚’é€šã˜ã¦ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ã‚°ãƒ©ãƒ•Graphãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹Neo4jFlockDBãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  NoSQLåŸºæœ¬ç”¨èªã®èª¬æ˜NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¤ã„ã¦èª¿æŸ»ã¨é¸æŠã‚¬ã‚¤ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£NoSQLã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³NoSQLãƒ‘ã‚¿ãƒ¼ãƒ³SQLã‹ï¼ŸNoSQLã‹ï¼Ÿ      Source: Transitioning from RDBMS to NoSQLSQL ã‚’é¸ã¶ç†ç”±:æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å³æ ¼ãªã‚¹ã‚­ãƒ¼ãƒãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿è¤‡é›‘ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’ã™ã‚‹å¿…è¦æ€§ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹éš›ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ˜ç¢ºãªã¨ãé–‹ç™ºè€…ã®æ•°ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã€ã‚³ãƒ¼ãƒ‰ç­‰ãŒã‚ˆã‚Šå……å®Ÿã—ã¦ã„ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã¯ã¨ã¦ã‚‚é€Ÿã„NoSQL ã‚’é¸ã¶ç†ç”±:æº–æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã„ã—ã€ãƒ•ãƒ¬ã‚­ã‚·ãƒ–ãƒ«ãªã‚¹ã‚­ãƒ¼ãƒãƒãƒ³ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãªãƒ‡ãƒ¼ã‚¿è¤‡é›‘ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’ã™ã‚‹å¿…è¦ãŒãªã„ãƒ‡ãƒ¼ã‚¿ã®å¤šãã®TB (ã‚‚ã—ãã¯ PB) ã‚’ä¿å­˜ã™ã‚‹é›†ä¸­çš„ã€å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿è² è·ã«è€ãˆã‚‰ã‚Œã‚‹IOPSã«ã¤ã„ã¦ã¯æ¥µã‚ã¦é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¤ºã™NoSQLã«é©ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:æ€¥æ¿€ãªã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚„ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã®åé›†ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã‚„ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚«ãƒ¼ãƒˆãªã©ã®ä¸€æ™‚çš„æƒ…å ±é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ ('ãƒ›ãƒƒãƒˆãª') ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ã€€SQLã‚‚ã—ãã¯NoSQLæœ€åˆã®1000ä¸‡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«SQLã¨NoSQLã®é•ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥      Source: Scalable system design patternsã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿æ™‚é–“ã‚’å‰Šæ¸›ã—ã€ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®è² è·ã‚’ä½æ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€å®Ÿéš›ã®å‡¦ç†ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«ã€ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒãƒ£ãƒ¼ãŒã¾ãšä»¥å‰ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒé€ä¿¡ã•ã‚ŒãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã€ç›´å‰ã®çµæœã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ãã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«æ¸¡ã£ã¦çµ±åˆã•ã‚ŒãŸèª­ã¿å–ã‚Šæ›¸ãè¾¼ã¿ã®åˆ†é…ã‚’è¦æ±‚ã—ã¾ã™ãŒã€äººæ°—ã‚¢ã‚¤ãƒ†ãƒ ã¯ãã®åˆ†é…ã‚’æ­ªã‚ã¦ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã£ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å·®ã—è¾¼ã‚€ã“ã¨ã§ã“ã®ã‚ˆã†ã«ã€å‡ä¸€ã§ãªã„è² è·ã‚„ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®æ€¥æ¿€ãªå¢—åŠ ã‚’å¸åã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯OSã‚„ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ãªã©ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã€ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ ã‚‚ã—ãã¯ç‹¬ç«‹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«è¨­ç½®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚CDNã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°CDN ã‚‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¸€ã¤ã¨ã—ã¦è€ƒãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Webã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· ã‚„ Varnish ãªã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯é™çš„ãã—ã¦å‹•çš„ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥é…ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ webã‚µãƒ¼ãƒãƒ¼ã‚‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã“ã¨ãªã—ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æ™®é€šã€ä¸€èˆ¬çš„ãªä½¿ç”¨çŠ¶æ³ã«é©ã™ã‚‹ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã®è¨­å®šã‚’åˆæœŸçŠ¶æ…‹ã§æŒã£ã¦ã„ã¾ã™ã€‚ã“ã®è¨­å®šã‚’ç‰¹å®šã®ä»•æ§˜ã«åˆã‚ã›ã¦èª¿æ•´ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã©ã®In-memoryã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„Redisã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®é–“ã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯RAMã§ä¿æŒã•ã‚Œã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ã‚£ã‚¹ã‚¯ã§ä¿å­˜ã•ã‚Œã‚‹ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚ˆã‚Šã‚‚ã ã„ã¶é€Ÿã„ã§ã™ã€‚RAMå®¹é‡ã¯ãƒ‡ã‚£ã‚¹ã‚¯ã‚ˆã‚Šã‚‚é™ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã€least recently used (LRU)ãªã©ã®cache invalidation ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒ 'ã‚³ãƒ¼ãƒ«ãƒ‰' ãªã‚¨ãƒ³ãƒˆãƒªã‚’å¼¾ãã€'ãƒ›ãƒƒãƒˆ' ãªãƒ‡ãƒ¼ã‚¿ã‚’RAMã«ä¿å­˜ã—ã¾ã™ã€‚Redisã¯ã•ã‚‰ã«ä»¥ä¸‹ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’å‚™ãˆã¦ã„ã¾ã™:ãƒ‘ãƒ¼ã‚¸ã‚¹ãƒ†ãƒ³ã‚¹è¨­å®šã‚½ãƒ¼ãƒˆæ¸ˆã¿ã‚»ãƒƒãƒˆã€ãƒªã‚¹ãƒˆãªã©ã®çµ„ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã¯æ§˜ã€…ãªãƒ¬ãƒ™ãƒ«ã®ã‚‚ã®ãŒã‚ã‚Šã¾ã™ãŒã€ã„ãšã‚Œã‚‚å¤§ããäºŒã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ã„ãšã‚Œã‹ã«åˆ†é¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª ã¨ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ ã§ã™:è¡Œãƒ¬ãƒ™ãƒ«ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«Fully-formed serializable objectsFully-rendered HTMLä¸€èˆ¬çš„ã«ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã¯ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’ä½œã‚Šå‡ºã—ã¦ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’é›£ã—ãã—ã¦ã—ã¾ã†ã®ã§é¿ã‘ã‚‹ã¹ãã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹éš›ã«ã¯å¿…ãšã‚¯ã‚¨ãƒªã‚’ã‚­ãƒ¼ã¨ã—ã¦ãƒãƒƒã‚·ãƒ¥ã—ã¦çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚ã“ã®æ‰‹æ³•ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœŸé™åˆ‡ã‚Œå•é¡Œã«æ‚©ã‚€ã“ã¨ã«ãªã‚Šã¾ã™:è¤‡é›‘ãªã‚¯ã‚¨ãƒªã«ã‚ˆã‚Šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçµæœã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ãŒå›°é›£ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ãƒ«ãªã©ã®ãƒ‡ãƒ¼ã‚¿æ–­ç‰‡ãŒå¤‰åŒ–ã—ãŸæ™‚ã«ã€ãã®å¤‰åŒ–ã—ãŸã‚»ãƒ«ã‚’å«ã‚€ã‹ã‚‚ã—ã‚Œãªã„å…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’å‰Šé™¤ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã†ã™ã‚‹ã‚ˆã†ã«ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰ãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨ã—ã¦çµ„ã¿ç«‹ã¦ã•ã›ã¾ã™ã€‚:ãã®ãƒ‡ãƒ¼ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‰Šé™¤ã™ã‚‹ã“ã¨éåŒæœŸå‡¦ç†ã‚’è¨±å®¹ã—ã¾ã™: ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸­ã§æœ€æ–°ã®ã‚‚ã®ã‚’é›†ã‚ã¦ãã¾ã™ä½•ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã‹:ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œå…¨ã«ãƒ¬ãƒ³ãƒ€ãƒ¼ã•ã‚ŒãŸã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‚¢ã‚¯ãƒ†ãƒ“ãƒ†ã‚£ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã§ãã‚‹å®¹é‡ã¯é™ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€è‡ªåˆ†ã®ã‚±ãƒ¼ã‚¹ã§ã¯ã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‰‹æ³•ãŒä¸€ç•ªã„ã„ã‹ã¯æ¤œè¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰      Source: From cache to in-memory data gridã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¸ã®èª­ã¿æ›¸ãã®å‡¦ç†ã‚’ã—ã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ã¯ç›´æ¥ã‚„ã‚Šã¨ã‚Šã‚’ã—ã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ã“ã¨ã‚’ã—ã¾ã™:ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¸­ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å‚ç…§ã—ã¾ã™ãŒã€çµæœã¨ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã«ãªã‚Šã¾ã™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—ã—ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ ã—ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã—ã¾ã™def get_user(self, user_id):    user = cache.get(\""user.{0}\"", user_id)    if user is None:        user = db.query(\""SELECT * FROM users WHERE user_id = {0}\"", user_id)        if user is not None:            key = \""user.{0}\"".format(user_id)            cache.set(key, json.dumps(user))    return userMemcached ã¯é€šå¸¸ã“ã®ã‚ˆã†ã«ä½¿ã‚ã‚Œã‚‹ã€‚ãã®å¾Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¯é€Ÿã„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã¯ãƒ¬ãƒ¼ã‚¸ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚ã‚‹ã¨ã‚‚è¨€ã‚ã‚Œã¾ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã¿ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæº¢ã‚Œã‚‹ã®ã‚’é˜²æ­¢ã—ã¾ã™ã€‚æ¬ ç‚¹: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰å„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã¯ä¸‰ã¤ã®ãƒˆãƒªãƒƒãƒ—ã‚’å‘¼ã³å‡ºã™ã“ã¨ã«ãªã‚Šã€ä½“æ„Ÿã§ãã‚‹ã»ã©ã®é…å»¶ãŒèµ·ãã¦ã—ã¾ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ãŒæ›´æ–°ã•ã‚Œã‚‹ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã¯å¤ã„ã‚‚ã®ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚time-to-live (TTL)ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã®æ›´æ–°ã‚’å¼·åˆ¶çš„ã«è¡Œã†ã€ã‚‚ã—ãã¯ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã¯ç·©å’Œã§ãã¾ã™ã€‚ãƒãƒ¼ãƒ‰ãŒè½ã¡ã‚‹ã¨ã€æ–°è¦ã®ç©ºã®ãƒãƒ¼ãƒ‰ã§ä»£æ›¿ã•ã‚Œã‚‹ã“ã¨ã§ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼      Source: Scalability, availability, stability, patternsã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¨ã—ã¦ä½¿ã„ã€ãã“ã«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿æ›¸ãã‚’è¡Œã„ã¾ã™ã€‚ä¸€æ–¹ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®èª­ã¿æ›¸ãã‚’æ‹…å½“ã—ã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚‹ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã™ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯åŒæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã«æ›¸ãè¾¼ã¿ã‚’è¡Œã„ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã—ã¾ã™ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰:set_user(12345, {\""foo\"":\""bar\""})ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚³ãƒ¼ãƒ‰:def set_user(user_id, values):    user = db.query(\""UPDATE Users WHERE id = {0}\"", user_id, values)    cache.set(user_id, user)ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã¯æ›¸ãè¾¼ã¿å‡¦ç†ã®ã›ã„ã§å…¨ä½“ã¨ã—ã¦ã¯é…ã„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ãŒã€æ›¸ãè¾¼ã¾ã‚ŒãŸã°ã‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹èª­ã¿è¾¼ã¿ã¯é€Ÿã„ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã¯ä¸€èˆ¬çš„ã«ãƒ‡ãƒ¼ã‚¿æ›´æ–°æ™‚ã®æ–¹ãŒèª­ã¿è¾¼ã¿æ™‚ã‚ˆã‚Šã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã«è¨±å®¹çš„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã¯æœ€æ–°ç‰ˆã§ä¿ãŸã‚Œã¾ã™ã€‚æ¬ ç‚¹: ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ãƒãƒ¼ãƒ‰ãŒè½ã¡ãŸã“ã¨ã€ã‚‚ã—ãã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦æ–°ã—ã„ãƒãƒ¼ãƒ‰ãŒä½œæˆã•ã‚ŒãŸæ™‚ã«ã€æ–°ã—ã„ãƒãƒ¼ãƒ‰ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒæ›´æ–°ã•ã‚Œã‚‹ã¾ã§ã¯ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã›ã‚“ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã¨ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚’ä½µç”¨ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã‚’ç·©å’Œã§ãã¾ã™ã€‚æ›¸ãè¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã¯ä¸€åº¦ã‚‚èª­ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯TTLã«ã‚ˆã£ã¦åœ§ç¸®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ (ãƒ©ã‚¤ãƒˆãƒãƒƒã‚¯)      Source: Scalability, availability, stability, patternsãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ã§ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ã“ã¨ã‚’ã—ã¾ã™:ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã™ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¸ã®æ›¸ãè¾¼ã¿ã‚’éåŒæœŸçš„ã«è¡Œã†ã“ã¨ã§ã€æ›¸ãè¾¼ã¿ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚æ¬ ç‚¹: ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢å†…ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ãƒ’ãƒƒãƒˆã™ã‚‹å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè½ã¡ã‚‹ã¨ãƒ‡ãƒ¼ã‚¿æ¬ æãŒèµ·ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã‚„ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚ˆã‚Šã‚‚å®Ÿè£…ãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰      Source: From cache to in-memory data gridæœŸé™åˆ‡ã‚Œã‚ˆã‚Šã‚‚å‰ã«ã€ç›´è¿‘ã§ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸå…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’è‡ªå‹•çš„ã«æ›´æ–°ã™ã‚‹ã‚ˆã†ã«è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚‚ã—ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå°†æ¥å¿…è¦ã«ãªã‚‹ã®ã‹ã‚’æ­£ç¢ºã«äºˆæ¸¬ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ãªã‚‰ã°ã€ãƒªãƒ¼ãƒ‰ã‚¹ãƒ«ãƒ¼ã‚ˆã‚Šã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬ ç‚¹: ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå¿…è¦ã«ãªã‚‹ã‹ã®äºˆæ¸¬ãŒæ­£ç¢ºã§ãªã„å ´åˆã«ã¯ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰ãŒãªã„æ–¹ãŒãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¯è‰¯ã„ã¨ã„ã†çµæœã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚æ¬ ç‚¹: ã‚­ãƒ£ãƒƒã‚·ãƒ¥cache invalidationãªã©ã‚’ç”¨ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®çœŸã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®é–“ã®ä¸€è²«æ€§ã‚’ä¿ã¤å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Redisã‚„memcachedã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹æˆã‚’å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Cache invalidationã‚‚é›£ã—ã„ã§ã™ãŒãã‚Œã«åŠ ãˆã¦ã€ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã‹ã¨ã„ã†è¤‡é›‘ãªå•é¡Œã«ã‚‚æ‚©ã¾ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸From cache to in-memory data gridã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€å¯ç”¨æ€§ã€å®‰å®šæ€§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£AWS ElastiCacheã®ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼WikipediaéåŒæœŸå‡¦ç†      Source: Intro to architecting systems for scaleéåŒæœŸã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ã‚‚ã—ã€é€£ç¶šçš„ã«è¡Œã‚ã‚Œã‚‹ã¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚é–“ã‚’åœ§è¿«ã—ã¦ã—ã¾ã†ã‚ˆã†ãªé‡ã„å‡¦ç†ã‚’åˆ¥ã§å‡¦ç†ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã¾ãŸã€å®šæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†åˆã•ã›ã‚‹ãªã©ã®æ™‚é–“ãŒã‹ã‹ã‚‹ã‚ˆã†ãªå‡¦ç†ã‚’å‰ã‚‚ã£ã¦å‡¦ç†ã—ã¦ãŠãã“ã¨ã«ã‚‚å½¹ç«‹ã¡ã¾ã™ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã€ä¿å­˜ã—ã€é…ä¿¡ã—ã¾ã™ã€‚ã‚‚ã—ã€å‡¦ç†ãŒã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã§è¡Œã†ã«ã¯é…ã™ãã‚‹å ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚’ç”¨ã„ã‚‹ã¨ã„ã„ã§ã—ã‚‡ã†:ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¸ãƒ§ãƒ–ã‚’ã‚­ãƒ¥ãƒ¼ã«é…ä¿¡ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ä¼ãˆã¾ã™ã€‚ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å—ã‘å–ã£ã¦ã€å‡¦ç†ã‚’è¡Œã„ã€çµ‚äº†ã—ãŸã‚‰ãã®ã‚·ã‚°ãƒŠãƒ«ã‚’è¿”ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‡¦ç†ãŒæ­¢ã¾ã‚‹ã“ã¨ã¯ãªãã€ã‚¸ãƒ§ãƒ–ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å‡¦ç†ã•ã‚Œã¾ã™ã€‚ã“ã®é–“ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã€ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ãŸã‹ã®ã‚ˆã†ã«è¦‹ã›ã‚‹ãŸã‚ã«å°è¦æ¨¡ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æŠ•ç¨¿ã™ã‚‹ã¨ãã«ã€ãƒ„ã‚¤ãƒ¼ãƒˆã¯ã™ãã«ã‚ãªãŸã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«åæ˜ ã•ã‚ŒãŸã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€ãã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒå®Ÿéš›ã«å…¨ã¦ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã«é…ä¿¡ã•ã‚Œã‚‹ã¾ã§ã«ã¯ã‚‚ã†å°‘ã—æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã‚‹ã§ã—ã‚‡ã†ã€‚Redis ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä»²ä»‹ã¨ã—ã¦ã¯ã„ã„ã§ã™ãŒã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚RabbitMQ ã¯ã‚ˆãä½¿ã‚ã‚Œã¦ã„ã¾ã™ãŒã€'AMQP'ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¯¾å¿œã—ã¦ã€è‡ªå‰ã®ãƒãƒ¼ãƒ‰ã‚’ç«‹ã¦ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Amazon SQS ã¨ã„ã†é¸æŠè‚¢ã‚‚ã‚ã‚Šã¾ã™ãŒã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒé«˜ãã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé‡è¤‡ã—ã¦é…ä¿¡ã•ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã¯ã‚¿ã‚¹ã‚¯ã¨ãã®é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€å‡¦ç†ã—ãŸä¸Šã§ãã®çµæœã‚’è¿”ã—ã¾ã™ã€‚ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã‚’ã§ãã‚‹ã»ã‹ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã¨ã¦ã‚‚é‡ã„ã‚¸ãƒ§ãƒ–ã‚’ã“ãªã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚Celery ã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨pythonã®ã‚µãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚‚ã—ã€ã‚­ãƒ¥ãƒ¼ãŒæ‹¡å¤§ã—ã™ãã‚‹ã¨ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã‚ˆã‚Šã‚‚ã‚­ãƒ¥ãƒ¼ã®æ–¹ãŒå¤§ãããªã‚Šã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ãŒèµ·ã“ã‚Šã€ãƒ‡ã‚£ã‚¹ã‚¯èª­ã¿å‡ºã—ã«ã¤ãªãŒã‚Šã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã«ã¤ãªãŒã‚Šã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã¯ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§å›é¿ã™ã‚‹ã“ã¨ãŒã§ãã€é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¢ºä¿ã—ã‚­ãƒ¥ãƒ¼ã«ã™ã§ã«ã‚ã‚‹ã‚¸ãƒ§ãƒ–ã«ã¤ã„ã¦ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’çŸ­ç¸®ã§ãã¾ã™ã€‚ã‚­ãƒ¥ãƒ¼ãŒã„ã£ã±ã„ã«ãªã‚‹ã¨ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã‚µãƒ¼ãƒãƒ¼ãƒ“ã‚¸ãƒ¼ã‚‚ã—ãã¯HTTP 503ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦å—ã‘å–ã‚Šã¾ãŸå¾Œã§æ™‚é–“ã‚’ãŠã„ã¦ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚ˆã†ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯exponential backoffãªã©ã«ã‚ˆã£ã¦å¾Œã»ã©å†åº¦æ™‚é–“ã‚’ç½®ã„ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬ ç‚¹: éåŒæœŸå‡¦ç†ã‚­ãƒ¥ãƒ¼ã‚’ç”¨ã„ã‚‹ã“ã¨ã§é…å»¶ãŒèµ·ã“ã‚Šã€è¤‡é›‘ã•ã‚‚å¢—ã™ãŸã‚ã€ã‚ã¾ã‚Šé‡ããªã„è¨ˆç®—å‡¦ç†ã‚„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ãŠã„ã¦ã¯åŒæœŸå‡¦ç†ã®æ–¹ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸It's all a numbers gameã‚ªãƒ¼ãƒãƒ¼ãƒ­ãƒ¼ãƒ‰ã—ãŸæ™‚ã«ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚’é©ç”¨ã™ã‚‹Little's lawãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¨ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã®é•ã„ã¨ã¯ï¼Ÿé€šä¿¡      Source: OSI 7 layer modelHypertext transfer protocol (HTTP)HTTP ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦è»¢é€ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã§ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«é–¢ã‚ã‚‹ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚µãƒ¼ãƒãƒ¼ã«æŠ•ã’ã€ã‚µãƒ¼ãƒãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã«é–¢ä¿‚ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨å®Œäº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚HTTPã¯è‡ªå·±å®Œçµã™ã‚‹ã®ã§ã€é–“ã«ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ³ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã€åœ§ç¸®ãªã©ã®ã©ã‚“ãªä¸­é–“ãƒ«ãƒ¼ã‚¿ãƒ¼ãŒå…¥ã£ã¦ã‚‚å‹•ãã‚ˆã†ã«ã§ãã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯HTTPå‹•è©(ãƒ¡ã‚½ãƒƒãƒ‰)ã¨ãƒªã‚½ãƒ¼ã‚¹(ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ)ã§æˆã‚Šç«‹ã£ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ãŒã‚ˆãã‚ã‚‹HTTPå‹•è©ã§ã™ã€‚:å‹•è©è©³ç´°å†ªç­‰æ€§*ã‚»ãƒ¼ãƒ•ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§ãã‚‹ã‹GETãƒªã‚½ãƒ¼ã‚¹ã‚’èª­ã¿å–ã‚‹YesYesYesPOSTãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹ã‚‚ã—ãã¯ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ãƒˆãƒªã‚¬ãƒ¼NoNoYes ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚€å ´åˆPUTãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã‚‚ã—ãã¯å…¥ã‚Œæ›¿ãˆã‚‹YesNoNoPATCHãƒªã‚½ãƒ¼ã‚¹ã‚’éƒ¨åˆ†çš„ã«æ›´æ–°ã™ã‚‹NoNoYes ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚€å ´åˆDELETEãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ã™ã‚‹YesNoNoä½•åº¦å‘¼ã‚“ã§ã‚‚åŒã˜çµæœãŒè¿”ã£ã¦ãã‚‹ã“ã¨HTTPã¯TCP ã‚„ UDP ãªã©ã®ä½ç´šãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: HTTPHTTPã£ã¦ãªã«?HTTP ã¨ TCPã®é•ã„PUT ã¨ PATCHã®é•ã„ä¼é€åˆ¶å¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ« (TCP)      Source: How to make a multiplayer gameTCPã¯IP networkã®ä¸Šã§æˆã‚Šç«‹ã¤æ¥ç¶šãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚æ¥ç¶šã¯handshakeã«ã‚ˆã£ã¦é–‹å§‹ã€è§£é™¤ã•ã‚Œã¾ã™ã€‚å…¨ã¦ã®é€ä¿¡ã•ã‚ŒãŸãƒ‘ã‚±ãƒƒãƒˆã¯æ¬ æãªã—ã§é€ä¿¡å…ˆã«é€ä¿¡ã•ã‚ŒãŸé †ç•ªã§åˆ°é”ã™ã‚‹ã‚ˆã†ã«ä»¥ä¸‹ã®æ–¹æ³•ã§ä¿è¨¼ã•ã‚Œã¦ã„ã¾ã™:ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã¨checksum fieldsãŒå…¨ã¦ã®ãƒ‘ã‚±ãƒƒãƒˆã«ç”¨æ„ã•ã‚Œã¦ã„ã‚‹Acknowledgementãƒ‘ã‚±ãƒƒãƒˆã¨è‡ªå‹•å†é€ä¿¡ã‚‚ã—é€ä¿¡è€…ãŒæ­£ã—ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ã‘å–ã‚‰ãªã‹ã£ãŸã¨ãã€ãƒ‘ã‚±ãƒƒãƒˆã‚’å†é€ä¿¡ã—ã¾ã™ã€‚è¤‡æ•°ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒã‚ã£ãŸã¨ãã€æ¥ç¶šã¯è§£é™¤ã•ã‚Œã¾ã™ã€‚TCP ã¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ ã¨ è¼»è¼³åˆ¶å¾¡ã‚‚å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã«ã‚ˆã£ã¦é€Ÿåº¦ã¯ä½ä¸‹ã—ã€ä¸€èˆ¬çš„ã«UDPã‚ˆã‚Šã‚‚éåŠ¹ç‡ãªè»¢é€æ‰‹æ®µã«ãªã£ã¦ã„ã¾ã™ã€‚ãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã¯ã‹ãªã‚Šå¤§ããªæ•°ã®TCPæ¥ç¶šã‚’é–‹ã„ã¦ãŠãã“ã¨ãŒã‚ã‚Šã€ãã®ã“ã¨ã§ãƒ¡ãƒ¢ãƒªãƒ¼ä½¿ç”¨ãŒåœ§è¿«ã•ã‚Œã¾ã™ã€‚ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã¨ä¾‹ãˆã°memcached ã‚µãƒ¼ãƒãƒ¼ã®é–“ã§å¤šæ•°ã®ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿ã£ã¦ãŠãã“ã¨ã¯é«˜ãã¤ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å¯èƒ½ãªã¨ã“ã‚ã§ã¯UDPã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã ã‘ã§ãªãã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãªã©ã‚‚å½¹ç«‹ã¤ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚TCPã¯é«˜ã„ä¾å­˜æ€§ã‚’è¦ã—ã€æ™‚é–“åˆ¶ç´„ãŒå³ã—ããªã„ã‚‚ã®ã«é©ã—ã¦ã„ã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã€SMTPã€FTPã‚„SSHãªã©ã®ä¾‹ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®æ™‚ã«UDPã‚ˆã‚Šã‚‚TCPã‚’ä½¿ã†ã¨ã„ã„ã§ã—ã‚‡ã†:å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒæ¬ æã™ã‚‹ã“ã¨ãªã—ã«å±Šã„ã¦ã»ã—ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®æœ€é©ãªè‡ªå‹•æ¨æ¸¬ã‚’ã—ã¦ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« (UDP)      Source: How to make a multiplayer gameUDPã¯ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ã‚¹ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ï¼ˆãƒ‘ã‚±ãƒƒãƒˆã®ã‚ˆã†ãªã‚‚ã®ï¼‰ã¯ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ¬ãƒ™ãƒ«ã§ã®ä¿è¨¼ã—ã‹ã•ã‚Œã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ã¯é †ä¸åŒã§å—ã‘å–ã‚Šå…ˆã«åˆ°ç€ã—ãŸã‚Šãã‚‚ãã‚‚ç€ã‹ãªã‹ã£ãŸã‚Šã—ã¾ã™ã€‚UDPã¯è¼»è¼³åˆ¶å¾¡ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã›ã‚“ã€‚TCPã«ãŠã„ã¦ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã“ã‚Œã‚‰ã®ä¿è¨¼ãŒãªã„ãŸã‚ã€UDPã¯ä¸€èˆ¬çš„ã«ã€TCPã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã™ã€‚UDPã¯ã‚µãƒ–ãƒãƒƒãƒˆä¸Šã®ã™ã¹ã¦ã®æ©Ÿå™¨ã«ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ã‚’é€ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã¯DHCP ã«ãŠã„ã¦å½¹ã«ç«‹ã¡ã¾ã™ã€‚ã¨ã„ã†ã®ã‚‚ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã¾ã IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—ã—ã¦ã„ãªã„ã®ã§ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å¿…è¦ã¨ã™ã‚‹TCPã«ã‚ˆã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒã§ããªã„ã‹ã‚‰ã§ã™ã€‚UDPã¯ä¿¡é ¼æ€§ã®é¢ã§ã¯åŠ£ã‚Šã¾ã™ãŒã€VoIPã€ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚„åŒæ™‚é€šä¿¡ãƒãƒ«ãƒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚²ãƒ¼ãƒ ãªã©ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒé‡è¦–ã•ã‚Œã‚‹æ™‚ã«ã¯ã¨ã¦ã‚‚åŠ¹æœçš„ã§ã™ã€‚TCPã‚ˆã‚Šã‚‚UDPã‚’ä½¿ã†ã®ã¯:ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’æœ€ä½é™ã«æŠ‘ãˆãŸã„æ™‚ãƒ‡ãƒ¼ã‚¿æ¬ æã‚ˆã‚Šã‚‚ã€ãƒ‡ãƒ¼ã‚¿é…å»¶ã‚’é‡è¦–ã™ã‚‹ã¨ãã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚’è‡ªå‰ã§å®Ÿè£…ã—ãŸã„ã¨ããã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: TCP ã¨ UDPã‚²ãƒ¼ãƒ ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ãŸã‚ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯TCP ã¨ UDP ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ä¸»ãªé•ã„TCP ã¨ UDPã®é•ã„Transmission control protocolUser datagram protocolFacebookã®ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°é éš”æ‰‹ç¶šå‘¼å‡º (RPC)      Source: Crack the system design interviewRPCã§ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒªãƒ¢ãƒ¼ãƒˆã‚µãƒ¼ãƒãƒ¼ãªã©ã®ç•°ãªã‚‹ã‚¢ãƒ‰ãƒ¬ã‚¹ç©ºé–“ã§ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ãŒå‡¦ç†ã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ã‚³ãƒ¼ãƒ«ã®ã‚ˆã†ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã«ã©ã®ã‚ˆã†ã«é€šä¿¡ã™ã‚‹ã‹ã¨ã„ã†è©³ç´°ã‚’çœã„ãŸçŠ¶æ…‹ã§ã‚³ãƒ¼ãƒ‰ãŒæ›¸ã‹ã‚Œã¾ã™ã€‚ãƒªãƒ¢ãƒ¼ãƒˆã®ã‚³ãƒ¼ãƒ«ã¯æ™®é€šã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ã‚³ãƒ¼ãƒ«ã‚ˆã‚Šã‚‚é…ãã€ä¿¡é ¼æ€§ã«æ¬ ã‘ã‚‹ãŸã‚ã€RPCã‚³ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‚³ãƒ¼ãƒ«ã¨åŒºåˆ¥ã•ã›ã¦ãŠãã“ã¨ãŒå¥½ã¾ã—ã„ã§ã—ã‚‡ã†ã€‚äººæ°—ã®RPCãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ä»¥ä¸‹ã§ã™ã€‚Protobufã€ Thriftã€AvroRPC ã¯ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒˆã‚³ãƒ«:ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ  - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚³ãƒ¼ãƒ«ã®ã‚ˆã†ã«ã‚¹ã‚¿ãƒƒã‚¯ã¸ã¨ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ãã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ - ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£IDã¨ã‚¢ãƒ¼ã‚®ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ‘ãƒƒã‚¯ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã—ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé€šä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - OSãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã¸ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚Šã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼é€šä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - OSãŒå—ã‘å–ã£ãŸãƒ‘ã‚±ãƒƒãƒˆã‚’ã‚µãƒ¼ãƒãƒ¼ã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã«å—ã‘æ¸¡ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ -  çµæœã‚’å±•é–‹ã—ã€ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼IDã«ãƒãƒƒãƒã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’è¿”ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ä¸Šè¨˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é€†é †ã§ç¹°ã‚Šè¿”ã—ã¾ã™ã€‚Sample RPC calls:GET /someoperation?data=anIdPOST /anotheroperation{  \""data\"":\""anId\"";  \""anotherdata\"": \""another value\""}RPCã¯æŒ¯ã‚‹èˆã„ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚RPCã¯å†…éƒ¨é€šä¿¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç†ç”±ã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ã¨ã„ã†ã®ã‚‚ã€ä½¿ç”¨ã™ã‚‹çŠ¶æ³ã«åˆã‚ã›ã¦ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚³ãƒ¼ãƒ«ã‚’è‡ªä½œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã‚‰ã§ã™ã€‚ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼ (aka SDK) ã‚’å‘¼ã¶ã®ã¯ä»¥ä¸‹ã®æ™‚:ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’çŸ¥ã£ã¦ã„ã‚‹æ™‚ãƒ­ã‚¸ãƒƒã‚¯ãŒã©ã®ã‚ˆã†ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ã®ã‹ã‚’ç®¡ç†ã—ãŸã„ã¨ããƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼å¤–ã§ã‚¨ãƒ©ãƒ¼ãŒã©ã®ã‚ˆã†ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã•ã‚Œã‚‹ã‹ã‚’ç®¡ç†ã—ãŸã„æ™‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ãŒæœ€å„ªå…ˆã®æ™‚REST ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¾“ã†HTTP APIã¯ãƒ‘ãƒ–ãƒªãƒƒã‚¯APIã«ãŠã„ã¦ã‚ˆãç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚æ¬ ç‚¹: RPCRPCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã¯ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…ã«ã‚ˆã‚Šå³å¯†ã«å·¦å³ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ–°ã—ã„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ä½¿ç”¨ä¾‹ãŒã‚ã‚‹ãŸã³ã«æ–°ã—ãAPIãŒå®šç¾©ã•ã‚Œãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚RPCã‚’ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ã®ã¯é›£ã—ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ—¢å­˜ã®ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚’ãã®ã¾ã¾ä½¿ã£ã¦ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€Squidãªã©ã®ã‚µãƒ¼ãƒãƒ¼ã«RPCã‚³ãƒ¼ãƒ«ãŒæ­£ã—ãã‚­ãƒ£ãƒƒã‚·ãƒ¥ ã•ã‚Œã‚‹ã‚ˆã†ã«è¿½åŠ ã§éª¨ã‚’æŠ˜ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚Representational state transfer (REST)RESTã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒã‚µãƒ¼ãƒãƒ¼ã«ã‚ˆã£ã¦ãƒãƒãƒ¼ã‚¸ã•ã‚Œã‚‹ãƒªã‚½ãƒ¼ã‚¹ã«å¯¾ã—ã¦å‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ»ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’æ”¯æŒã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚­ãƒãƒ£ã‚¹ã‚¿ã‚¤ãƒ«ã§ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯æ“ä½œã§ãã‚‹ã‚‚ã—ãã¯æ–°ã—ã„ãƒªã‚½ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ãªãƒªã‚½ãƒ¼ã‚¹ã‚„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ¬ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚ã™ã¹ã¦ã®é€šä¿¡ã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯èƒ½ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚RESTful ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«ã¯æ¬¡ã®å››ã¤ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™:ç‰¹å¾´çš„ãªãƒªã‚½ãƒ¼ã‚¹ (URI in HTTP) - ã©ã®ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚ã£ã¦ã‚‚åŒã˜URIã‚’ä½¿ã†ã€‚HTTPå‹•è©ã«ã‚ˆã£ã¦å¤‰ã‚ã‚‹ (Verbs in HTTP) - å‹•è©ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒœãƒ‡ã‚£ã‚’ä½¿ã†è‡ªå·±èª¬æ˜çš„ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (status response in HTTP) - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã„ã€æ–°ã—ãä½œã£ãŸã‚Šã—ãªã„ã“ã¨ã€‚HATEOAS (HTML interface for HTTP) - è‡ªåˆ†ã®webã‚µãƒ¼ãƒ“ã‚¹ãŒãƒ–ãƒ©ã‚¦ã‚¶ã§å®Œå…¨ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã“ã¨ã€‚ã‚µãƒ³ãƒ—ãƒ« REST ã‚³ãƒ¼ãƒ«:GET /someresources/anIdPUT /someresources/anId{\""anotherdata\"": \""another value\""}RESTã¯ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼ã®ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ã‚’æœ€å°é™ã«ã™ã‚‹ã‚‚ã®ã§ã€ãƒ‘ãƒ–ãƒªãƒƒã‚¯APIãªã©ã«ã‚ˆãç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚RESTã¯URIã€ representation through headersã€ãã—ã¦ã€GETã€POSTã€PUTã€ DELETEã€PATCHãªã©ã®HTTPå‹•è©ç­‰ã®ã‚ˆã‚Šã‚¸ã‚§ãƒãƒªãƒƒã‚¯ã§çµ±ä¸€ã•ã‚ŒãŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¾ã™ã€‚ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹ã®ã§RESTã¯æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã«æœ€é©ã§ã™ã€‚æ¬ ç‚¹: RESTRESTã¯ãƒ‡ãƒ¼ã‚¿å…¬é–‹ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã®ã§ã€ãƒªã‚½ãƒ¼ã‚¹ãŒè‡ªç„¶ã«æ•´ç†ã•ã‚Œã¦ã„ãªã‹ã£ãŸã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ã§è¡¨ã›ã‚‰ã‚Œãªã„æ™‚ã«ã¯ã‚ˆã„é¸æŠè‚¢ã¨ã¯è¨€ãˆãªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€ã¨ã‚ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã«ãƒãƒƒãƒã™ã‚‹ã™ã¹ã¦ã®æ›´æ–°æƒ…å ±ã‚’è¿”ã™ã¨è¨€ã£ãŸå‡¦ç†ã¯ç°¡å˜ã«ã¯ãƒ‘ã‚¹ã§è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚RESTã§ã¯ã€URIãƒ‘ã‚¹ã€ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãã—ã¦å ´åˆã«ã‚ˆã£ã¦ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ãªã©ã«ã‚ˆã£ã¦å®Ÿè£…ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã€‚RESTã¯å°‘æ•°ã®å‹•è©ã«ä¾å­˜ã—ã¦ã„ã¾ã™(GETã€POSTã€PUTã€DELETEã€ãã—ã¦ PATCH) ãŒæ™‚ã«ã¯ä½¿ã„ãŸã„äº‹ä¾‹ã«åˆã‚ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€æœŸé™ã®åˆ‡ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ç§»ã—ãŸã„å ´åˆãªã©ã¯ã“ã‚Œã‚‰ã®å‹•è©ã®ä¸­ã«ã¯ç¶ºéº—ã«ã¯ãƒ•ã‚£ãƒƒãƒˆã—ã¾ã›ã‚“ã€‚ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ã®ä¸­ã«ã‚ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚’ã¨ã£ã¦ãã‚‹ã®ã¯ã‚·ãƒ³ã‚°ãƒ«ãƒ“ãƒ¥ãƒ¼ã‚’æç”»ã™ã‚‹ã®ã«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã§æ•°å›ã‚„ã‚Šã¨ã‚Šã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ä¾‹ã¨ã—ã¦ã€ãƒ–ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ãã‚Œã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤ºã™ã‚‹å ´åˆãªã©ã§ã™ã€‚æ§˜ã€…ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒã§å‹•ä½œã™ã‚‹å¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã‚‹ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã¯ã“ã®ã‚ˆã†ãªè¤‡æ•°ã®ã‚„ã‚Šå–ã‚Šã¯å¥½ã¾ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚æ™‚ãŒçµŒã¤ã«ã¤ã‚Œã¦ã€APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚ˆã‚Šå¤šãã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸ãˆã‚‰ã‚Œã¦ã€å¤ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã™ã§ã«ã„ã‚‰ãªã„ã‚‚ã®ã‚‚å«ã‚ã¦ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å—ã‘å–ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ã“ã¨ã§ã€ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãŒå¤§ãããªã‚Šã™ãã¦ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚‚æ‹¡å¤§ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚RPCã¨RESTæ¯”è¼ƒOperationRPCRESTã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—POST /signupPOST /personsãƒªã‚¶ã‚¤ãƒ³POST /resign{\""personid\"": \""1234\""}DELETE /persons/1234Personèª­ã¿è¾¼ã¿GET /readPerson?personid=1234GET /persons/1234Personã®ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿GET /readUsersItemsList?personid=1234GET /persons/1234/itemsPersonã®ã‚¢ã‚¤ãƒ†ãƒ ã¸ã®ã‚¢ã‚¤ãƒ†ãƒ è¿½åŠ POST /addItemToUsersItemsList{\""personid\"": \""1234\"";\""itemid\"": \""456\""}POST /persons/1234/items{\""itemid\"": \""456\""}ã‚¢ã‚¤ãƒ†ãƒ æ›´æ–°POST /modifyItem{\""itemid\"": \""456\"";\""key\"": \""value\""}PUT /items/456{\""key\"": \""value\""}ã‚¢ã‚¤ãƒ†ãƒ å‰Šé™¤POST /removeItem{\""itemid\"": \""456\""}DELETE /items/456  Source: Do you really know why you prefer REST over RPCãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: REST ã¨ RPCDo you really know why you prefer REST over RPCWhen are RPC-ish approaches more appropriate than REST?REST vs JSON-RPCDebunking the myths of RPC and RESTWhat are the drawbacks of using RESTCrack the system design interviewThriftWhy REST for internal use and not RPCã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯æ›´æ–°ãŒå¿…è¦ã§ã™ã€‚contributingã—ã¦ãã ã•ã„ï¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¯å¹…åºƒã„ãƒˆãƒ”ãƒƒã‚¯ã§ã™ã€‚ååˆ†ãªçµŒé¨“ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†é‡ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãŒãªãã¦ã‚‚ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®çŸ¥è­˜ã‚’è¦ã™ã‚‹è·ã«å¿œå‹Ÿã™ã‚‹ã®ã§ãªã„é™ã‚Šã€åŸºæœ¬ä»¥ä¸Šã®ã“ã¨ã‚’çŸ¥ã‚‹å¿…è¦ã¯ãªã„ã§ã—ã‚‡ã†ã€‚æƒ…å ±ä¼é”ã€ä¿å­˜ã«ãŠã‘ã‚‹æš—å·åŒ–XSS ã‚„ SQL injectionã‚’é˜²ããŸã‚ã«ã€å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚‚ã—ãã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«éœ²å‡ºã•ã‚Œã‚‹å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã™ã‚‹SQL injectionã‚’é˜²ããŸã‚ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’ç”¨ã„ã‚‹ã€‚least privilegeã®åŸç†ã‚’ç”¨ã„ã‚‹ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:é–‹ç™ºè€…ã®ãŸã‚ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¬ã‚¤ãƒ‰OWASP top tenè£œéºæš—ç®—ã§ã€æ¨è¨ˆå€¤ã‚’æ±‚ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚‚æ™‚ã«ã¯ã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰100æšã‚¤ãƒ¡ãƒ¼ã‚¸åˆ†ã®ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ä½œã‚‹æ™‚é–“ã‚’æ±‚ã‚ãŸã‚Šã€ãã®æ™‚ã«ã©ã‚Œã ã‘ãƒ‡ã‚£ã‚¹ã‚¯ãƒ¡ãƒ¢ãƒªãƒ¼ãŒæ¶ˆè²»ã•ã‚Œã‚‹ã‹ãªã©ã®å€¤ã§ã™ã€‚2ã®ä¹—æ•°è¡¨ ã¨ å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ ã¯è‰¯ã„å‚è€ƒã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚2ã®ä¹—æ•°è¡¨ä¹—æ•°           å³å¯†ãªå€¤         ç´„        Bytes---------------------------------------------------------------7                             1288                             25610                           1024   1 thousand           1 KB16                         65,536                       64 KB20                      1,048,576   1 million            1 MB30                  1,073,741,824   1 billion            1 GB32                  4,294,967,296                        4 GB40              1,099,511,627,776   1 trillion           1 TBãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤Latency Comparison Numbers--------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy            10,000   ns       10 usSend 1 KB bytes over 1 Gbps network     10,000   ns       10 usRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSDRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSDSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 msNotes-----1 ns = 10^-9 seconds1 us = 10^-6 seconds = 1,000 ns1 ms = 10^-3 seconds = 1,000 us = 1,000,000 nsä¸Šè¨˜è¡¨ã«åŸºã¥ã„ãŸå½¹ã«ç«‹ã¤æ•°å€¤:ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 30 MB/s1 Gbps Ethernetã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ã€€100 MB/sSSDã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 1 GB/smain memoryã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 4 GB/s1ç§’ã§åœ°çƒ6-7å‘¨ã§ãã‚‹1ç§’ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã¨2000å‘¨ã‚„ã‚Šã¨ã‚Šã§ãã‚‹ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã®è¦–è¦šçš„è¡¨ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ - 1å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ - 2Designs, lessons, and advice from building large distributed systemsSoftware Engineering Advice from Building Large-Scale Distributed Systemsä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ä¾‹é¡Œé »å‡ºã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨ãã®è§£ç­”ã¸ã®ãƒªãƒ³ã‚¯è³ªå•è§£ç­”Dropboxã®ã‚ˆã†ãªãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹youtube.comGoogleã®ã‚ˆã†ãªæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­è¨ˆqueue.acm.orgstackexchange.comardendertat.comstanford.eduGoogleã®ã‚ˆã†ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªwebã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®è¨­è¨ˆquora.comGoogle docsã®è¨­è¨ˆcode.google.comneil.fraser.nameRedisã®ã‚ˆã†ãªã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã®è¨­è¨ˆslideshare.netMemcachedã®ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆslideshare.netAmazonã®ã‚ˆã†ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆhulu.comijcai13.orgBitlyã®ã‚ˆã†ãªURLçŸ­ç¸®ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆn00tc0d3r.blogspot.comWhatsAppã®ã‚ˆã†ãªãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã®è¨­è¨ˆhighscalability.comInstagramã®ã‚ˆã†ãªå†™çœŸå…±æœ‰ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆhighscalability.comhighscalability.comFacebookãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚£ãƒ¼ãƒ‰ã®è¨­è¨ˆquora.comquora.comslideshare.netFacebookã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®è¨­è¨ˆfacebook.comhighscalability.comFacebookãƒãƒ£ãƒƒãƒˆã®è¨­è¨ˆerlang-factory.comfacebook.comFacebookã®ã‚ˆã†ãªgraphæ¤œç´¢ã®è¨­è¨ˆfacebook.comfacebook.comfacebook.comCloudFlareã®ã‚ˆã†ãªCDNã®è¨­è¨ˆcmu.eduTwitterã®ãƒˆãƒ¬ãƒ³ãƒ‰æ©Ÿèƒ½ã®è¨­è¨ˆmichael-noll.comsnikolov .wordpress.comãƒ©ãƒ³ãƒ€ãƒ IDç™ºè¡Œã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆblog.twitter.comgithub.comä¸€å®šã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«æ™‚é–“ã§ã®ä¸Šä½kä»¶ã‚’è¿”ã™ucsb.eduwpi.eduè¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’é…ä¿¡ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆhighscalability.comã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®è¤‡æ•°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã®è¨­è¨ˆindieflashblog.combuildnewgames.comã‚¬ãƒ¼ãƒ™ãƒƒã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆstuffwithstuff.comwashington.eduã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆä¾‹é¡Œã‚’è¿½åŠ ã™ã‚‹Contributeå®Ÿä¸–ç•Œã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸–ã®ä¸­ã®ã‚·ã‚¹ãƒ†ãƒ ãŒã©ã®ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã®è¨˜äº‹      Source: Twitter timelines at scaleä»¥ä¸‹ã®è¨˜äº‹ã®é‡ç®±ã®éš…ã‚’ã¤ã¤ãã‚ˆã†ãªç´°ã‹ã„è©³ç´°ã«ã“ã ã‚ã‚‰ãªã„ã“ã¨ã€‚ã‚€ã—ã‚å…±é€šã®åŸç†ã€æŠ€è¡“ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã‚‹ã“ã¨ãã‚Œãã‚Œã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã©ã‚“ãªå•é¡ŒãŒè§£æ±ºã•ã‚Œã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¯ã©ã“ã§ã†ã¾ãä½¿ãˆã‚‚ã—ãã¯ä½¿ãˆãªã„ã‹ã‚’çŸ¥ã‚‹ã“ã¨å­¦ã‚“ã ã“ã¨ã‚’å¾©ç¿’ã™ã‚‹ã“ã¨ç¨®é¡ã‚·ã‚¹ãƒ†ãƒ å‚è€ƒãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿å‡¦ç†MapReduce - Googleã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ research.google.comãƒ‡ãƒ¼ã‚¿å‡¦ç†Spark - Databricksã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿å‡¦ç†Storm - Twitterã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Bigtable - Googleã®ã‚«ãƒ©ãƒ æŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹harvard.eduãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢HBase - Bigtableã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Cassandra - Facebookã®ã‚«ãƒ©ãƒ æŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢DynamoDB - Amazonã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹harvard.eduãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢MongoDB - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Spanner - Googleã®ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹research.google.comãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Memcached - åˆ†æ•£ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Redis - æ°¸ç¶šæ€§ã¨ãƒãƒªãƒ¥ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’å…¼ã­å‚™ãˆãŸåˆ†æ•£ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ Google File System (GFS) - åˆ†æ•£ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ research.google.comãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ Hadoop File System (HDFS) - GFSã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…apache.orgMiscChubby - ç–çµåˆã®åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ­ãƒƒã‚¯ã™ã‚‹Googleã®ã‚µãƒ¼ãƒ“ã‚¹research.google.comMiscDapper - åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’è¿½è·¡ã™ã‚‹ã‚¤ãƒ³ãƒ•ãƒ©research.google.comMiscKafka - LinkedInã«ã‚ˆã‚‹Pub/subãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼slideshare.netMiscZookeeper - åŒæœŸã‚’å¯èƒ½ã«ã™ã‚‹ä¸­å¤®é›†æ¨©ã‚¤ãƒ³ãƒ•ãƒ©ã¨ã‚µãƒ¼ãƒ“ã‚¹slideshare.netã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¿½åŠ ã™ã‚‹Contributeå„ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¼æ¥­å‚è€ƒãƒšãƒ¼ã‚¸AmazonAmazon architectureCinchcastProducing 1,500 hours of audio every dayDataSiftRealtime datamining At 120,000 tweets per secondDropBoxHow we've scaled DropboxESPNOperating At 100,000 duh nuh nuhs per secondGoogleGoogle architectureInstagram14 million users, terabytes of photosWhat powers InstagramJustin.tvJustin.Tv's live video broadcasting architectureFacebookScaling memcached at FacebookTAO: Facebookâ€™s distributed data store for the social graphFacebookâ€™s photo storageFlickrFlickr architectureMailboxFrom 0 to one million users in 6 weeksPinterestFrom 0 To 10s of billions of page views a month18 million visitors, 10x growth, 12 employeesPlayfish50 million monthly users and growingPlentyOfFishPlentyOfFish architectureSalesforceHow they handle 1.3 billion transactions a dayStack OverflowStack Overflow architectureTripAdvisor40M visitors, 200M dynamic page views, 30TB dataTumblr15 billion page views a monthTwitterMaking Twitter 10000 percent fasterStoring 250 million tweets a day using MySQL150M active users, 300K QPS, a 22 MB/S firehoseTimelines at scaleBig and small data at TwitterOperations at Twitter: scaling beyond 100 million usersUberHow Uber scales their real-time market platformWhatsAppThe WhatsApp architecture Facebook bought for $19 billionYouTubeYouTube scalabilityYouTube architectureä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°é¢æ¥ã‚’å—ã‘ã‚‹ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æŠ•ã’ã‚‰ã‚Œã‚‹è³ªå•ã¯åŒã˜åˆ†é‡ã‹ã‚‰æ¥ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã§ã—ã‚‡ã†Airbnb EngineeringAtlassian DevelopersAutodesk EngineeringAWS BlogBitly Engineering BlogBox BlogsCloudera Developer BlogDropbox Tech BlogEngineering at QuoraEbay Tech BlogEvernote Tech BlogEtsy Code as CraftFacebook EngineeringFlickr CodeFoursquare Engineering BlogGitHub Engineering BlogGoogle Research BlogGroupon Engineering BlogHeroku Engineering BlogHubspot Engineering BlogHigh ScalabilityInstagram EngineeringIntel Software BlogJane Street Tech BlogLinkedIn EngineeringMicrosoft EngineeringMicrosoft Python EngineeringNetflix Tech BlogPaypal Developer BlogPinterest Engineering BlogQuora EngineeringReddit BlogSalesforce Engineering BlogSlack Engineering BlogSpotify LabsTwilio Engineering BlogTwitter EngineeringUber Engineering BlogYahoo Engineering BlogYelp Engineering BlogZynga Engineering Blogãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:kilimchoi/engineering-blogsã“ã“ã«ã‚ã‚‹ãƒªã‚¹ãƒˆã¯æ¯”è¼ƒçš„å°è¦æ¨¡ãªã‚‚ã®ã«ã¨ã©ã‚ã€kilimchoi/engineering-blogsã«ã‚ˆã‚Šè©³ç´°ã«è¨˜ã™ã“ã¨ã§é‡è¤‡ã—ãªã„ã‚ˆã†ã«ã—ã¦ãŠãã“ã¨ã«ã™ã‚‹ã€‚ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°ã¸ã®ãƒªãƒ³ã‚¯ã‚’è¿½åŠ ã™ã‚‹å ´åˆã¯ã“ã“ã§ã¯ãªãã€engineering-blogsãƒ¬ãƒœã‚¸ãƒˆãƒªã«è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚é€²è¡Œä¸­ã®ä½œæ¥­ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¿½åŠ ã‚„ã€é€²è¡Œä¸­ã®ä½œæ¥­ã‚’æ‰‹ä¼ã£ã¦ã„ãŸã ã‘ã‚‹å ´åˆã¯ã“ã¡ã‚‰!MapReduceã«ã‚ˆã‚‹åˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°Consistent hashingScatter gatherContributeã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¯ãƒ¬ã‚¸ãƒƒãƒˆåŠã³ã€å‚ç…§ãƒšãƒ¼ã‚¸ã¯é©æ™‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªå†…ã«è¨˜è¼‰ã—ã¦ã‚ã‚Šã¾ã™Special thanks to:Hired in techCracking the coding interviewHigh scalabilitycheckcheckzz/system-design-interviewshashank88/system_designmmcgrana/services-engineeringSystem design cheat sheetA distributed systems reading listCracking the system design interviewContact infoFeel free to contact me to discuss any issues, questions, or comments.My contact info can be found on my GitHub page.LicenseI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2017 Donne MartinCreative Commons Attribution 4.0 International License (CC BY 4.0)http://creativecommons.org/licenses/by/4.0/"
59,AUTOMATIC1111/stable-diffusion-webui,https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/README.md,Python,"Stable Diffusion web UIA browser interface based on Gradio library for Stable Diffusion.FeaturesDetailed feature showcase with images:Original txt2img and img2img modesOne click install and run script (but you still must install python and git)OutpaintingInpaintingColor SketchPrompt MatrixStable Diffusion UpscaleAttention, specify parts of text that the model should pay more attention toa man in a ((tuxedo)) - will pay more attention to tuxedoa man in a (tuxedo:1.21) - alternative syntaxselect text and press Ctrl+Up or Ctrl+Down (or Command+Up or Command+Down if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)Loopback, run img2img processing multiple timesX/Y/Z plot, a way to draw a 3 dimensional plot of images with different parametersTextual Inversionhave as many embeddings as you want and use any names you like for themuse multiple embeddings with different numbers of vectors per tokenworks with half precision floating point numberstrain embeddings on 8GB (also reports of 6GB working)Extras tab with:GFPGAN, neural network that fixes facesCodeFormer, face restoration tool as an alternative to GFPGANRealESRGAN, neural network upscalerESRGAN, neural network upscaler with a lot of third party modelsSwinIR and Swin2SR (see here), neural network upscalersLDSR, Latent diffusion super resolution upscalingResizing aspect ratio optionsSampling method selectionAdjust sampler eta values (noise multiplier)More advanced noise setting optionsInterrupt processing at any time4GB video card support (also reports of 2GB working)Correct seeds for batchesLive prompt token length validationGeneration parametersparameters you used to generate images are saved with that imagein PNG chunks for PNG, in EXIF for JPEGcan drag the image to PNG info tab to restore generation parameters and automatically copy them into UIcan be disabled in settingsdrag and drop an image/text-parameters to promptboxRead Generation Parameters Button, loads parameters in promptbox to UISettings pageRunning arbitrary python code from UI (must run with --allow-code to enable)Mouseover hints for most UI elementsPossible to change defaults/mix/max/step values for UI elements via text configTiling support, a checkbox to create images that can be tiled like texturesProgress bar and live image generation previewCan use a separate neural network to produce previews with almost none VRAM or compute requirementNegative prompt, an extra text field that allows you to list what you don't want to see in generated imageStyles, a way to save part of prompt and easily apply them via dropdown laterVariations, a way to generate same image but with tiny differencesSeed resizing, a way to generate same image but at slightly different resolutionCLIP interrogator, a button that tries to guess prompt from an imagePrompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midwayBatch Processing, process a group of files using img2imgImg2img Alternative, reverse Euler method of cross attention controlHighres Fix, a convenience option to produce high resolution pictures in one click without usual distortionsReloading checkpoints on the flyCheckpoint Merger, a tab that allows you to merge up to 3 checkpoints into oneCustom scripts with many extensions from communityComposable-Diffusion, a way to use multiple prompts at onceseparate prompts using uppercase ANDalso supports weights for prompts: a cat :1.2 AND a dog AND a penguin :2.2No token limit for prompts (original stable diffusion lets you use up to 75 tokens)DeepDanbooru integration, creates danbooru style tags for anime promptsxformers, major speed increase for select cards: (add --xformers to commandline args)via extension: History tab: view, direct and delete images conveniently within the UIGenerate forever optionTraining tabhypernetworks and embeddings optionsPreprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)Clip skipHypernetworksLoras (same as Hypernetworks but more pretty)A sparate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your promptCan select to load a different VAE from settings screenEstimated completion time in progress barAPISupport for dedicated inpainting model by RunwayMLvia extension: Aesthetic Gradients, a way to generate images with a specific aesthetic by using clip images embeds (implementation of https://github.com/vicgalle/stable-diffusion-aesthetic-gradients)Stable Diffusion 2.0 support - see wiki for instructionsAlt-Diffusion support - see wiki for instructionsNow without any bad letters!Load checkpoints in safetensors formatEased resolution restriction: generated image's domension must be a multiple of 8 rather than 64Now with a license!Reorder elements in the UI from settings screenInstallation and RunningMake sure the required dependencies are met and follow the instructions available for both NVidia (recommended) and AMD GPUs.Alternatively, use online services (like Google Colab):List of Online ServicesInstallation on Windows 10/11 with NVidia-GPUs using release packageDownload sd.webui.zip from v1.0.0-pre and extract it's contents.Run update.bat.Run run.bat.For more details see Install-and-Run-on-NVidia-GPUsAutomatic Installation on WindowsInstall Python 3.10.6 (Newer version of Python does not support torch), checking \""Add Python to PATH\"".Install git.Download the stable-diffusion-webui repository, for example by running git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git.Run webui-user.bat from Windows Explorer as normal, non-administrator, user.Automatic Installation on LinuxInstall the dependencies:# Debian-based:sudo apt install wget git python3 python3-venv# Red Hat-based:sudo dnf install wget git python3# Arch-based:sudo pacman -S wget git python3Navigate to the directory you would like the webui to be installed and execute the following command:bash <(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)Run webui.sh.Check webui-user.sh for options.Installation on Apple SiliconFind the instructions here.ContributingHere's how to add code to this repo: ContributingDocumentationThe documentation was moved from this README over to the project's wiki.For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) crawlable wiki.CreditsLicenses for borrowed code can be found in Settings -> Licenses screen, and also in html/licenses.html file.Stable Diffusion - https://github.com/CompVis/stable-diffusion, https://github.com/CompVis/taming-transformersk-diffusion - https://github.com/crowsonkb/k-diffusion.gitGFPGAN - https://github.com/TencentARC/GFPGAN.gitCodeFormer - https://github.com/sczhou/CodeFormerESRGAN - https://github.com/xinntao/ESRGANSwinIR - https://github.com/JingyunLiang/SwinIRSwin2SR - https://github.com/mv-lab/swin2srLDSR - https://github.com/Hafiidz/latent-diffusionMiDaS - https://github.com/isl-org/MiDaSIdeas for optimizations - https://github.com/basujindal/stable-diffusionCross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)Sub-quadratic Cross Attention layer optimization - Alex Birch (Birch-san/diffusers#1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we're not using his code, but we are using his ideas).Idea for SD upscale - https://github.com/jquesnelle/txt2imghdNoise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-botCLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogatorIdea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorchxformers - https://github.com/facebookresearch/xformersDeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooruSampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pixSecurity advice - RyotaKUniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPCTAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesdLyCORIS - KohakuBlueleafInitial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.(You)"
60,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
61,geekcomputers/Python,https://github.com/geekcomputers/Python/blob/master/README.md,Python,"My Python Eggs ğŸ ğŸ˜„I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in Notepad++ ğŸ—’ï¸Feel free to explore the scripts and use them for your learning and automation needs!List of Scripts:batch_file_rename.py - Batch rename a group of files in a specified directory, changing their extensions.create_dir_if_not_there.py - Check if a directory exists in the user's home directory. Create it if it doesn't exist.Fast Youtube Downloader - Download YouTube videos quickly with parallel threads using aria2c.Google Image Downloader - Query a given term and retrieve images from the Google Image database.dir_test.py - Test if the directory testdir exists. If not, create it.env_check.py - Check if all the required environment variables are set.blackjack.py - Casino Blackjack-21 game in Python.fileinfo.py - Show file information for a given file.folder_size.py - Scan the current directory and all subdirectories and display their sizes.logs.py - Search for all *.log files in a directory, zip them using the specified program, and date stamp them.move_files_over_x_days.py - Move all files over a specified age (in days) from the source directory to the destination directory.nslookup_check.py - Open the file server_list.txt and perform nslookup for each server to check the DNS entry.osinfo.py - Display information about the operating system on which the script is running.ping_servers.py - Ping the servers associated with the specified application group.ping_subnet.py - Scan the final range of a given IP subnet for available addresses.powerdown_startup.py - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.puttylogs.py - Zip all the logs in the given directory.script_count.py - Scan the scripts directory and count the different types of scripts.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.script_listing.py - List all files in a given directory and its subdirectories.testlines.py - Open a file and print out 100 lines of the set line variable.tweeter.py - Tweet text or a picture from the terminal.serial_scanner.py - List available serial ports in use on Linux and Windows systems.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.CountMillionCharacter.py and CountMillionCharacter2.0 - Get character count of a text file.xkcd_downloader.py - Download the latest XKCD comic and place them in a new folder called \""comics\"".timymodule.py - An alternative to Python's 'timeit' module and easier to use.calculator.py - Implement a calculator using Python's eval() function.Google_News.py - Use BeautifulSoup to provide latest news headlines along with news links.cricket_live_score - Use BeautifulSoup to provide live cricket scores.youtube.py - Take a song name as input and fetch the YouTube URL of the best matching song and play it.site_health.py - Check the health of a remote server.SimpleStopWatch.py - Simple stop watch implementation using Python's time module.Changemac.py - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).whatsapp-monitor.py - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.whatsapp-chat-analyzer.py - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.JARVIS.py - Control Windows programs with your voice.Images Downloader - Download images from webpages on Unix-based systems.space_invader.py.py - Classical 2D space invader game to recall your childhood memories.Test Case Generator - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.Note: The content in this repository belongs to the respective authors and creators. I'm just providing a formatted README.md for better presentation."
62,ibm-developer-skills-network/jbbmo-Introduction-to-Git-and-GitHub,https://github.com/ibm-developer-skills-network/jbbmo-Introduction-to-Git-and-GitHub/blob/master/README.md,Python,"Introduction to Git and GitHubSimple Interest CalculatorA calculator that calculates simple interest given principal, annual rate of interest and time period in years.Input:   p, principal amount   t, time period in years   r, annual rate of interestOutput   simple interest = p*t*rÂ© 2022 XYZ, Inc."
63,AntonOsika/gpt-engineer,https://github.com/AntonOsika/gpt-engineer/blob/main/README.md,Python,"GPT EngineerSpecify what you want it to build, the AI asks for clarification, and then builds it.GPT Engineer is made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt.DemoProject philosophySimple to get valueFlexible and easy to add new own \""AI steps\"". See steps.py.Incrementally build towards a user experience of:high level promptinggiving feedback to the AI that it will remember over timeFast handovers back and forth between AI and humanSimplicity, all computation is \""resumable\"" and persisted to the filesystemUsageChoose either stable or development.For stable release:python -m pip install gpt-engineerFor development:git clone https://github.com/AntonOsika/gpt-engineer.gitcd gpt-engineerpython -m pip install -e .(or: make install && source venv/bin/activate for a venv)API KeyEither just:export OPENAI_API_KEY=[your api key]Or:Create a copy of .env.template named .envAdd your OPENAI_API_KEY in .envCheck the Windows README for windows usage.RunningCreate an empty folder. If inside the repo, you can run:cp -r projects/example/ projects/my-new-projectFill in the prompt file in your new foldergpt-engineer projects/my-new-project(Note, gpt-engineer --help lets you see all available options. For example --steps use_feedback lets you improve/fix code in a project)By running gpt-engineer you agree to our terms.ResultsCheck the generated files in projects/my-new-project/workspaceAlternativesYou can check Docker instructions to use Docker, or simplydo everything in your browser:FeaturesYou can specify the \""identity\"" of the AI agent by editing the files in the preprompts folder.Editing the preprompts, and evolving how you write the project prompt, is how you make the agent remember things between projects.Each step in steps.py will have its communication history with GPT4 stored in the logs folder, and can be rerun with scripts/rerun_edited_message_logs.py.VisionThe gpt-engineer community is building the open platform for devs to tinker with and build their personal code-generation toolbox.If you are interested in contributing to this, we would be interested in having you.If you want to see our broader ambitions, check out the roadmap, and joindiscordto get input on how you can contribute to it.We are currently looking for more maintainers and community organizers. Email anton.osika@gmail.com if you are interested in an official role.Example              Demo.mov          "
64,fxsjy/jieba,https://github.com/fxsjy/jieba/blob/master/README.md,Python,"jiebaâ€œç»“å·´â€ä¸­æ–‡åˆ†è¯ï¼šåšæœ€å¥½çš„ Python ä¸­æ–‡åˆ†è¯ç»„ä»¶\""Jieba\"" (Chinese for \""to stutter\"") Chinese text segmentation: built to be the best Python Chinese word segmentation module.Scroll down for English documentation.ç‰¹ç‚¹æ”¯æŒå››ç§åˆ†è¯æ¨¡å¼ï¼šç²¾ç¡®æ¨¡å¼ï¼Œè¯•å›¾å°†å¥å­æœ€ç²¾ç¡®åœ°åˆ‡å¼€ï¼Œé€‚åˆæ–‡æœ¬åˆ†æï¼›å…¨æ¨¡å¼ï¼ŒæŠŠå¥å­ä¸­æ‰€æœ‰çš„å¯ä»¥æˆè¯çš„è¯è¯­éƒ½æ‰«æå‡ºæ¥, é€Ÿåº¦éå¸¸å¿«ï¼Œä½†æ˜¯ä¸èƒ½è§£å†³æ­§ä¹‰ï¼›æœç´¢å¼•æ“æ¨¡å¼ï¼Œåœ¨ç²¾ç¡®æ¨¡å¼çš„åŸºç¡€ä¸Šï¼Œå¯¹é•¿è¯å†æ¬¡åˆ‡åˆ†ï¼Œæé«˜å¬å›ç‡ï¼Œé€‚åˆç”¨äºæœç´¢å¼•æ“åˆ†è¯ã€‚paddleæ¨¡å¼ï¼Œåˆ©ç”¨PaddlePaddleæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè®­ç»ƒåºåˆ—æ ‡æ³¨ï¼ˆåŒå‘GRUï¼‰ç½‘ç»œæ¨¡å‹å®ç°åˆ†è¯ã€‚åŒæ—¶æ”¯æŒè¯æ€§æ ‡æ³¨ã€‚paddleæ¨¡å¼ä½¿ç”¨éœ€å®‰è£…paddlepaddle-tinyï¼Œpip install paddlepaddle-tiny==1.6.1ã€‚ç›®å‰paddleæ¨¡å¼æ”¯æŒjieba v0.40åŠä»¥ä¸Šç‰ˆæœ¬ã€‚jieba v0.40ä»¥ä¸‹ç‰ˆæœ¬ï¼Œè¯·å‡çº§jiebaï¼Œpip install jieba --upgrade ã€‚PaddlePaddleå®˜ç½‘æ”¯æŒç¹ä½“åˆ†è¯æ”¯æŒè‡ªå®šä¹‰è¯å…¸MIT æˆæƒåè®®å®‰è£…è¯´æ˜ä»£ç å¯¹ Python 2/3 å‡å…¼å®¹å…¨è‡ªåŠ¨å®‰è£…ï¼šeasy_install jieba æˆ–è€… pip install jieba / pip3 install jiebaåŠè‡ªåŠ¨å®‰è£…ï¼šå…ˆä¸‹è½½ http://pypi.python.org/pypi/jieba/ ï¼Œè§£å‹åè¿è¡Œ python setup.py installæ‰‹åŠ¨å®‰è£…ï¼šå°† jieba ç›®å½•æ”¾ç½®äºå½“å‰ç›®å½•æˆ–è€… site-packages ç›®å½•é€šè¿‡ import jieba æ¥å¼•ç”¨å¦‚æœéœ€è¦ä½¿ç”¨paddleæ¨¡å¼ä¸‹çš„åˆ†è¯å’Œè¯æ€§æ ‡æ³¨åŠŸèƒ½ï¼Œè¯·å…ˆå®‰è£…paddlepaddle-tinyï¼Œpip install paddlepaddle-tiny==1.6.1ã€‚ç®—æ³•åŸºäºå‰ç¼€è¯å…¸å®ç°é«˜æ•ˆçš„è¯å›¾æ‰«æï¼Œç”Ÿæˆå¥å­ä¸­æ±‰å­—æ‰€æœ‰å¯èƒ½æˆè¯æƒ…å†µæ‰€æ„æˆçš„æœ‰å‘æ— ç¯å›¾ (DAG)é‡‡ç”¨äº†åŠ¨æ€è§„åˆ’æŸ¥æ‰¾æœ€å¤§æ¦‚ç‡è·¯å¾„, æ‰¾å‡ºåŸºäºè¯é¢‘çš„æœ€å¤§åˆ‡åˆ†ç»„åˆå¯¹äºæœªç™»å½•è¯ï¼Œé‡‡ç”¨äº†åŸºäºæ±‰å­—æˆè¯èƒ½åŠ›çš„ HMM æ¨¡å‹ï¼Œä½¿ç”¨äº† Viterbi ç®—æ³•ä¸»è¦åŠŸèƒ½åˆ†è¯jieba.cut æ–¹æ³•æ¥å—å››ä¸ªè¾“å…¥å‚æ•°: éœ€è¦åˆ†è¯çš„å­—ç¬¦ä¸²ï¼›cut_all å‚æ•°ç”¨æ¥æ§åˆ¶æ˜¯å¦é‡‡ç”¨å…¨æ¨¡å¼ï¼›HMM å‚æ•°ç”¨æ¥æ§åˆ¶æ˜¯å¦ä½¿ç”¨ HMM æ¨¡å‹ï¼›use_paddle å‚æ•°ç”¨æ¥æ§åˆ¶æ˜¯å¦ä½¿ç”¨paddleæ¨¡å¼ä¸‹çš„åˆ†è¯æ¨¡å¼ï¼Œpaddleæ¨¡å¼é‡‡ç”¨å»¶è¿ŸåŠ è½½æ–¹å¼ï¼Œé€šè¿‡enable_paddleæ¥å£å®‰è£…paddlepaddle-tinyï¼Œå¹¶ä¸”importç›¸å…³ä»£ç ï¼›jieba.cut_for_search æ–¹æ³•æ¥å—ä¸¤ä¸ªå‚æ•°ï¼šéœ€è¦åˆ†è¯çš„å­—ç¬¦ä¸²ï¼›æ˜¯å¦ä½¿ç”¨ HMM æ¨¡å‹ã€‚è¯¥æ–¹æ³•é€‚åˆç”¨äºæœç´¢å¼•æ“æ„å»ºå€’æ’ç´¢å¼•çš„åˆ†è¯ï¼Œç²’åº¦æ¯”è¾ƒç»†å¾…åˆ†è¯çš„å­—ç¬¦ä¸²å¯ä»¥æ˜¯ unicode æˆ– UTF-8 å­—ç¬¦ä¸²ã€GBK å­—ç¬¦ä¸²ã€‚æ³¨æ„ï¼šä¸å»ºè®®ç›´æ¥è¾“å…¥ GBK å­—ç¬¦ä¸²ï¼Œå¯èƒ½æ— æ³•é¢„æ–™åœ°é”™è¯¯è§£ç æˆ UTF-8jieba.cut ä»¥åŠ jieba.cut_for_search è¿”å›çš„ç»“æ„éƒ½æ˜¯ä¸€ä¸ªå¯è¿­ä»£çš„ generatorï¼Œå¯ä»¥ä½¿ç”¨ for å¾ªç¯æ¥è·å¾—åˆ†è¯åå¾—åˆ°çš„æ¯ä¸€ä¸ªè¯è¯­(unicode)ï¼Œæˆ–è€…ç”¨jieba.lcut ä»¥åŠ jieba.lcut_for_search ç›´æ¥è¿”å› listjieba.Tokenizer(dictionary=DEFAULT_DICT) æ–°å»ºè‡ªå®šä¹‰åˆ†è¯å™¨ï¼Œå¯ç”¨äºåŒæ—¶ä½¿ç”¨ä¸åŒè¯å…¸ã€‚jieba.dt ä¸ºé»˜è®¤åˆ†è¯å™¨ï¼Œæ‰€æœ‰å…¨å±€åˆ†è¯ç›¸å…³å‡½æ•°éƒ½æ˜¯è¯¥åˆ†è¯å™¨çš„æ˜ å°„ã€‚ä»£ç ç¤ºä¾‹# encoding=utf-8import jiebajieba.enable_paddle()# å¯åŠ¨paddleæ¨¡å¼ã€‚ 0.40ç‰ˆä¹‹åå¼€å§‹æ”¯æŒï¼Œæ—©æœŸç‰ˆæœ¬ä¸æ”¯æŒstrs=[\""æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦\"",\""ä¹’ä¹“çƒæ‹å–å®Œäº†\"",\""ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦\""]for str in strs:    seg_list = jieba.cut(str,use_paddle=True) # ä½¿ç”¨paddleæ¨¡å¼    print(\""Paddle Mode: \"" + '/'.join(list(seg_list)))seg_list = jieba.cut(\""æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦\"", cut_all=True)print(\""Full Mode: \"" + \""/ \"".join(seg_list))  # å…¨æ¨¡å¼seg_list = jieba.cut(\""æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦\"", cut_all=False)print(\""Default Mode: \"" + \""/ \"".join(seg_list))  # ç²¾ç¡®æ¨¡å¼seg_list = jieba.cut(\""ä»–æ¥åˆ°äº†ç½‘æ˜“æ­ç ”å¤§å¦\"")  # é»˜è®¤æ˜¯ç²¾ç¡®æ¨¡å¼print(\"", \"".join(seg_list))seg_list = jieba.cut_for_search(\""å°æ˜ç¡•å£«æ¯•ä¸šäºä¸­å›½ç§‘å­¦é™¢è®¡ç®—æ‰€ï¼Œååœ¨æ—¥æœ¬äº¬éƒ½å¤§å­¦æ·±é€ \"")  # æœç´¢å¼•æ“æ¨¡å¼print(\"", \"".join(seg_list))è¾“å‡º:ã€å…¨æ¨¡å¼ã€‘: æˆ‘/ æ¥åˆ°/ åŒ—äº¬/ æ¸…å/ æ¸…åå¤§å­¦/ åå¤§/ å¤§å­¦ã€ç²¾ç¡®æ¨¡å¼ã€‘: æˆ‘/ æ¥åˆ°/ åŒ—äº¬/ æ¸…åå¤§å­¦ã€æ–°è¯è¯†åˆ«ã€‘ï¼šä»–, æ¥åˆ°, äº†, ç½‘æ˜“, æ­ç ”, å¤§å¦    (æ­¤å¤„ï¼Œâ€œæ­ç ”â€å¹¶æ²¡æœ‰åœ¨è¯å…¸ä¸­ï¼Œä½†æ˜¯ä¹Ÿè¢«Viterbiç®—æ³•è¯†åˆ«å‡ºæ¥äº†)ã€æœç´¢å¼•æ“æ¨¡å¼ã€‘ï¼š å°æ˜, ç¡•å£«, æ¯•ä¸š, äº, ä¸­å›½, ç§‘å­¦, å­¦é™¢, ç§‘å­¦é™¢, ä¸­å›½ç§‘å­¦é™¢, è®¡ç®—, è®¡ç®—æ‰€, å, åœ¨, æ—¥æœ¬, äº¬éƒ½, å¤§å­¦, æ—¥æœ¬äº¬éƒ½å¤§å­¦, æ·±é€ æ·»åŠ è‡ªå®šä¹‰è¯å…¸è½½å…¥è¯å…¸å¼€å‘è€…å¯ä»¥æŒ‡å®šè‡ªå·±è‡ªå®šä¹‰çš„è¯å…¸ï¼Œä»¥ä¾¿åŒ…å« jieba è¯åº“é‡Œæ²¡æœ‰çš„è¯ã€‚è™½ç„¶ jieba æœ‰æ–°è¯è¯†åˆ«èƒ½åŠ›ï¼Œä½†æ˜¯è‡ªè¡Œæ·»åŠ æ–°è¯å¯ä»¥ä¿è¯æ›´é«˜çš„æ­£ç¡®ç‡ç”¨æ³•ï¼š jieba.load_userdict(file_name) # file_name ä¸ºæ–‡ä»¶ç±»å¯¹è±¡æˆ–è‡ªå®šä¹‰è¯å…¸çš„è·¯å¾„è¯å…¸æ ¼å¼å’Œ dict.txt ä¸€æ ·ï¼Œä¸€ä¸ªè¯å ä¸€è¡Œï¼›æ¯ä¸€è¡Œåˆ†ä¸‰éƒ¨åˆ†ï¼šè¯è¯­ã€è¯é¢‘ï¼ˆå¯çœç•¥ï¼‰ã€è¯æ€§ï¼ˆå¯çœç•¥ï¼‰ï¼Œç”¨ç©ºæ ¼éš”å¼€ï¼Œé¡ºåºä¸å¯é¢ å€’ã€‚file_name è‹¥ä¸ºè·¯å¾„æˆ–äºŒè¿›åˆ¶æ–¹å¼æ‰“å¼€çš„æ–‡ä»¶ï¼Œåˆ™æ–‡ä»¶å¿…é¡»ä¸º UTF-8 ç¼–ç ã€‚è¯é¢‘çœç•¥æ—¶ä½¿ç”¨è‡ªåŠ¨è®¡ç®—çš„èƒ½ä¿è¯åˆ†å‡ºè¯¥è¯çš„è¯é¢‘ã€‚ä¾‹å¦‚ï¼šåˆ›æ–°åŠ 3 iäº‘è®¡ç®— 5å‡±ç‰¹ç³ nzå°ä¸­æ›´æ”¹åˆ†è¯å™¨ï¼ˆé»˜è®¤ä¸º jieba.dtï¼‰çš„ tmp_dir å’Œ cache_file å±æ€§ï¼Œå¯åˆ†åˆ«æŒ‡å®šç¼“å­˜æ–‡ä»¶æ‰€åœ¨çš„æ–‡ä»¶å¤¹åŠå…¶æ–‡ä»¶åï¼Œç”¨äºå—é™çš„æ–‡ä»¶ç³»ç»Ÿã€‚èŒƒä¾‹ï¼šè‡ªå®šä¹‰è¯å…¸ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/userdict.txtç”¨æ³•ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/test_userdict.pyä¹‹å‰ï¼š æå°ç¦ / æ˜¯ / åˆ›æ–° / åŠ / ä¸»ä»» / ä¹Ÿ / æ˜¯ / äº‘ / è®¡ç®— / æ–¹é¢ / çš„ / ä¸“å®¶ /åŠ è½½è‡ªå®šä¹‰è¯åº“åï¼šã€€æå°ç¦ / æ˜¯ / åˆ›æ–°åŠ / ä¸»ä»» / ä¹Ÿ / æ˜¯ / äº‘è®¡ç®— / æ–¹é¢ / çš„ / ä¸“å®¶ /è°ƒæ•´è¯å…¸ä½¿ç”¨ add_word(word, freq=None, tag=None) å’Œ del_word(word) å¯åœ¨ç¨‹åºä¸­åŠ¨æ€ä¿®æ”¹è¯å…¸ã€‚ä½¿ç”¨ suggest_freq(segment, tune=True) å¯è°ƒèŠ‚å•ä¸ªè¯è¯­çš„è¯é¢‘ï¼Œä½¿å…¶èƒ½ï¼ˆæˆ–ä¸èƒ½ï¼‰è¢«åˆ†å‡ºæ¥ã€‚æ³¨æ„ï¼šè‡ªåŠ¨è®¡ç®—çš„è¯é¢‘åœ¨ä½¿ç”¨ HMM æ–°è¯å‘ç°åŠŸèƒ½æ—¶å¯èƒ½æ— æ•ˆã€‚ä»£ç ç¤ºä¾‹ï¼š>>> print('/'.join(jieba.cut('å¦‚æœæ”¾åˆ°postä¸­å°†å‡ºé”™ã€‚', HMM=False)))å¦‚æœ/æ”¾åˆ°/post/ä¸­å°†/å‡ºé”™/ã€‚>>> jieba.suggest_freq(('ä¸­', 'å°†'), True)494>>> print('/'.join(jieba.cut('å¦‚æœæ”¾åˆ°postä¸­å°†å‡ºé”™ã€‚', HMM=False)))å¦‚æœ/æ”¾åˆ°/post/ä¸­/å°†/å‡ºé”™/ã€‚>>> print('/'.join(jieba.cut('ã€Œå°ä¸­ã€æ­£ç¡®åº”è¯¥ä¸ä¼šè¢«åˆ‡å¼€', HMM=False)))ã€Œ/å°/ä¸­/ã€/æ­£ç¡®/åº”è¯¥/ä¸ä¼š/è¢«/åˆ‡å¼€>>> jieba.suggest_freq('å°ä¸­', True)69>>> print('/'.join(jieba.cut('ã€Œå°ä¸­ã€æ­£ç¡®åº”è¯¥ä¸ä¼šè¢«åˆ‡å¼€', HMM=False)))ã€Œ/å°ä¸­/ã€/æ­£ç¡®/åº”è¯¥/ä¸ä¼š/è¢«/åˆ‡å¼€\""é€šè¿‡ç”¨æˆ·è‡ªå®šä¹‰è¯å…¸æ¥å¢å¼ºæ­§ä¹‰çº é”™èƒ½åŠ›\"" --- #14å…³é”®è¯æå–åŸºäº TF-IDF ç®—æ³•çš„å…³é”®è¯æŠ½å–import jieba.analysejieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())sentence ä¸ºå¾…æå–çš„æ–‡æœ¬topK ä¸ºè¿”å›å‡ ä¸ª TF/IDF æƒé‡æœ€å¤§çš„å…³é”®è¯ï¼Œé»˜è®¤å€¼ä¸º 20withWeight ä¸ºæ˜¯å¦ä¸€å¹¶è¿”å›å…³é”®è¯æƒé‡å€¼ï¼Œé»˜è®¤å€¼ä¸º FalseallowPOS ä»…åŒ…æ‹¬æŒ‡å®šè¯æ€§çš„è¯ï¼Œé»˜è®¤å€¼ä¸ºç©ºï¼Œå³ä¸ç­›é€‰jieba.analyse.TFIDF(idf_path=None) æ–°å»º TFIDF å®ä¾‹ï¼Œidf_path ä¸º IDF é¢‘ç‡æ–‡ä»¶ä»£ç ç¤ºä¾‹ ï¼ˆå…³é”®è¯æå–ï¼‰https://github.com/fxsjy/jieba/blob/master/test/extract_tags.pyå…³é”®è¯æå–æ‰€ä½¿ç”¨é€†å‘æ–‡ä»¶é¢‘ç‡ï¼ˆIDFï¼‰æ–‡æœ¬è¯­æ–™åº“å¯ä»¥åˆ‡æ¢æˆè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„ç”¨æ³•ï¼š jieba.analyse.set_idf_path(file_name) # file_nameä¸ºè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„è‡ªå®šä¹‰è¯­æ–™åº“ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.bigç”¨æ³•ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.pyå…³é”®è¯æå–æ‰€ä½¿ç”¨åœæ­¢è¯ï¼ˆStop Wordsï¼‰æ–‡æœ¬è¯­æ–™åº“å¯ä»¥åˆ‡æ¢æˆè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„ç”¨æ³•ï¼š jieba.analyse.set_stop_words(file_name) # file_nameä¸ºè‡ªå®šä¹‰è¯­æ–™åº“çš„è·¯å¾„è‡ªå®šä¹‰è¯­æ–™åº“ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txtç”¨æ³•ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.pyå…³é”®è¯ä¸€å¹¶è¿”å›å…³é”®è¯æƒé‡å€¼ç¤ºä¾‹ç”¨æ³•ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.pyåŸºäº TextRank ç®—æ³•çš„å…³é”®è¯æŠ½å–jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) ç›´æ¥ä½¿ç”¨ï¼Œæ¥å£ç›¸åŒï¼Œæ³¨æ„é»˜è®¤è¿‡æ»¤è¯æ€§ã€‚jieba.analyse.TextRank() æ–°å»ºè‡ªå®šä¹‰ TextRank å®ä¾‹ç®—æ³•è®ºæ–‡ï¼š TextRank: Bringing Order into TextsåŸºæœ¬æ€æƒ³:å°†å¾…æŠ½å–å…³é”®è¯çš„æ–‡æœ¬è¿›è¡Œåˆ†è¯ä»¥å›ºå®šçª—å£å¤§å°(é»˜è®¤ä¸º5ï¼Œé€šè¿‡spanå±æ€§è°ƒæ•´)ï¼Œè¯ä¹‹é—´çš„å…±ç°å…³ç³»ï¼Œæ„å»ºå›¾è®¡ç®—å›¾ä¸­èŠ‚ç‚¹çš„PageRankï¼Œæ³¨æ„æ˜¯æ— å‘å¸¦æƒå›¾ä½¿ç”¨ç¤ºä¾‹:è§ test/demo.pyè¯æ€§æ ‡æ³¨jieba.posseg.POSTokenizer(tokenizer=None) æ–°å»ºè‡ªå®šä¹‰åˆ†è¯å™¨ï¼Œtokenizer å‚æ•°å¯æŒ‡å®šå†…éƒ¨ä½¿ç”¨çš„ jieba.Tokenizer åˆ†è¯å™¨ã€‚jieba.posseg.dt ä¸ºé»˜è®¤è¯æ€§æ ‡æ³¨åˆ†è¯å™¨ã€‚æ ‡æ³¨å¥å­åˆ†è¯åæ¯ä¸ªè¯çš„è¯æ€§ï¼Œé‡‡ç”¨å’Œ ictclas å…¼å®¹çš„æ ‡è®°æ³•ã€‚é™¤äº†jiebaé»˜è®¤åˆ†è¯æ¨¡å¼ï¼Œæä¾›paddleæ¨¡å¼ä¸‹çš„è¯æ€§æ ‡æ³¨åŠŸèƒ½ã€‚paddleæ¨¡å¼é‡‡ç”¨å»¶è¿ŸåŠ è½½æ–¹å¼ï¼Œé€šè¿‡enable_paddle()å®‰è£…paddlepaddle-tinyï¼Œå¹¶ä¸”importç›¸å…³ä»£ç ï¼›ç”¨æ³•ç¤ºä¾‹>>> import jieba>>> import jieba.posseg as pseg>>> words = pseg.cut(\""æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨\"") #jiebaé»˜è®¤æ¨¡å¼>>> jieba.enable_paddle() #å¯åŠ¨paddleæ¨¡å¼ã€‚ 0.40ç‰ˆä¹‹åå¼€å§‹æ”¯æŒï¼Œæ—©æœŸç‰ˆæœ¬ä¸æ”¯æŒ>>> words = pseg.cut(\""æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨\"",use_paddle=True) #paddleæ¨¡å¼>>> for word, flag in words:...    print('%s %s' % (word, flag))...æˆ‘ rçˆ± våŒ—äº¬ nså¤©å®‰é—¨ nspaddleæ¨¡å¼è¯æ€§æ ‡æ³¨å¯¹åº”è¡¨å¦‚ä¸‹ï¼špaddleæ¨¡å¼è¯æ€§å’Œä¸“åç±»åˆ«æ ‡ç­¾é›†åˆå¦‚ä¸‹è¡¨ï¼Œå…¶ä¸­è¯æ€§æ ‡ç­¾ 24 ä¸ªï¼ˆå°å†™å­—æ¯ï¼‰ï¼Œä¸“åç±»åˆ«æ ‡ç­¾ 4 ä¸ªï¼ˆå¤§å†™å­—æ¯ï¼‰ã€‚æ ‡ç­¾å«ä¹‰æ ‡ç­¾å«ä¹‰æ ‡ç­¾å«ä¹‰æ ‡ç­¾å«ä¹‰næ™®é€šåè¯fæ–¹ä½åè¯så¤„æ‰€åè¯tæ—¶é—´nräººånsåœ°åntæœºæ„ånwä½œå“ånzå…¶ä»–ä¸“åvæ™®é€šåŠ¨è¯vdåŠ¨å‰¯è¯vnååŠ¨è¯aå½¢å®¹è¯adå‰¯å½¢è¯anåå½¢è¯då‰¯è¯mæ•°é‡è¯qé‡è¯rä»£è¯pä»‹è¯cè¿è¯uåŠ©è¯xcå…¶ä»–è™šè¯wæ ‡ç‚¹ç¬¦å·PERäººåLOCåœ°åORGæœºæ„åTIMEæ—¶é—´å¹¶è¡Œåˆ†è¯åŸç†ï¼šå°†ç›®æ ‡æ–‡æœ¬æŒ‰è¡Œåˆ†éš”åï¼ŒæŠŠå„è¡Œæ–‡æœ¬åˆ†é…åˆ°å¤šä¸ª Python è¿›ç¨‹å¹¶è¡Œåˆ†è¯ï¼Œç„¶åå½’å¹¶ç»“æœï¼Œä»è€Œè·å¾—åˆ†è¯é€Ÿåº¦çš„å¯è§‚æå‡åŸºäº python è‡ªå¸¦çš„ multiprocessing æ¨¡å—ï¼Œç›®å‰æš‚ä¸æ”¯æŒ Windowsç”¨æ³•ï¼šjieba.enable_parallel(4) # å¼€å¯å¹¶è¡Œåˆ†è¯æ¨¡å¼ï¼Œå‚æ•°ä¸ºå¹¶è¡Œè¿›ç¨‹æ•°jieba.disable_parallel() # å…³é—­å¹¶è¡Œåˆ†è¯æ¨¡å¼ä¾‹å­ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.pyå®éªŒç»“æœï¼šåœ¨ 4 æ ¸ 3.4GHz Linux æœºå™¨ä¸Šï¼Œå¯¹é‡‘åº¸å…¨é›†è¿›è¡Œç²¾ç¡®åˆ†è¯ï¼Œè·å¾—äº† 1MB/s çš„é€Ÿåº¦ï¼Œæ˜¯å•è¿›ç¨‹ç‰ˆçš„ 3.3 å€ã€‚æ³¨æ„ï¼šå¹¶è¡Œåˆ†è¯ä»…æ”¯æŒé»˜è®¤åˆ†è¯å™¨ jieba.dt å’Œ jieba.posseg.dtã€‚Tokenizeï¼šè¿”å›è¯è¯­åœ¨åŸæ–‡çš„èµ·æ­¢ä½ç½®æ³¨æ„ï¼Œè¾“å…¥å‚æ•°åªæ¥å— unicodeé»˜è®¤æ¨¡å¼result = jieba.tokenize(u'æ°¸å’Œæœè£…é¥°å“æœ‰é™å…¬å¸')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word æ°¸å’Œ                start: 0                end:2word æœè£…                start: 2                end:4word é¥°å“                start: 4                end:6word æœ‰é™å…¬å¸            start: 6                end:10æœç´¢æ¨¡å¼result = jieba.tokenize(u'æ°¸å’Œæœè£…é¥°å“æœ‰é™å…¬å¸', mode='search')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word æ°¸å’Œ                start: 0                end:2word æœè£…                start: 2                end:4word é¥°å“                start: 4                end:6word æœ‰é™                start: 6                end:8word å…¬å¸                start: 8                end:10word æœ‰é™å…¬å¸            start: 6                end:10ChineseAnalyzer for Whoosh æœç´¢å¼•æ“å¼•ç”¨ï¼š from jieba.analyse import ChineseAnalyzerç”¨æ³•ç¤ºä¾‹ï¼šhttps://github.com/fxsjy/jieba/blob/master/test/test_whoosh.pyå‘½ä»¤è¡Œåˆ†è¯ä½¿ç”¨ç¤ºä¾‹ï¼špython -m jieba news.txt > cut_result.txtå‘½ä»¤è¡Œé€‰é¡¹ï¼ˆç¿»è¯‘ï¼‰ï¼šä½¿ç”¨: python -m jieba [options] filenameç»“å·´å‘½ä»¤è¡Œç•Œé¢ã€‚å›ºå®šå‚æ•°:  filename              è¾“å…¥æ–‡ä»¶å¯é€‰å‚æ•°:  -h, --help            æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º  -d [DELIM], --delimiter [DELIM]                        ä½¿ç”¨ DELIM åˆ†éš”è¯è¯­ï¼Œè€Œä¸æ˜¯ç”¨é»˜è®¤çš„' / 'ã€‚                        è‹¥ä¸æŒ‡å®š DELIMï¼Œåˆ™ä½¿ç”¨ä¸€ä¸ªç©ºæ ¼åˆ†éš”ã€‚  -p [DELIM], --pos [DELIM]                        å¯ç”¨è¯æ€§æ ‡æ³¨ï¼›å¦‚æœæŒ‡å®š DELIMï¼Œè¯è¯­å’Œè¯æ€§ä¹‹é—´                        ç”¨å®ƒåˆ†éš”ï¼Œå¦åˆ™ç”¨ _ åˆ†éš”  -D DICT, --dict DICT  ä½¿ç”¨ DICT ä»£æ›¿é»˜è®¤è¯å…¸  -u USER_DICT, --user-dict USER_DICT                        ä½¿ç”¨ USER_DICT ä½œä¸ºé™„åŠ è¯å…¸ï¼Œä¸é»˜è®¤è¯å…¸æˆ–è‡ªå®šä¹‰è¯å…¸é…åˆä½¿ç”¨  -a, --cut-all         å…¨æ¨¡å¼åˆ†è¯ï¼ˆä¸æ”¯æŒè¯æ€§æ ‡æ³¨ï¼‰  -n, --no-hmm          ä¸ä½¿ç”¨éšå«é©¬å°”å¯å¤«æ¨¡å‹  -q, --quiet           ä¸è¾“å‡ºè½½å…¥ä¿¡æ¯åˆ° STDERR  -V, --version         æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯å¹¶é€€å‡ºå¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶åï¼Œåˆ™ä½¿ç”¨æ ‡å‡†è¾“å…¥ã€‚--help é€‰é¡¹è¾“å‡ºï¼š$> python -m jieba --helpJieba command line interface.positional arguments:  filename              input fileoptional arguments:  -h, --help            show this help message and exit  -d [DELIM], --delimiter [DELIM]                        use DELIM instead of ' / ' for word delimiter; or a                        space if it is used without DELIM  -p [DELIM], --pos [DELIM]                        enable POS tagging; if DELIM is specified, use DELIM                        instead of '_' for POS delimiter  -D DICT, --dict DICT  use DICT as dictionary  -u USER_DICT, --user-dict USER_DICT                        use USER_DICT together with the default dictionary or                        DICT (if specified)  -a, --cut-all         full pattern cutting (ignored with POS tagging)  -n, --no-hmm          don't use the Hidden Markov Model  -q, --quiet           don't print loading messages to stderr  -V, --version         show program's version number and exitIf no filename specified, use STDIN instead.å»¶è¿ŸåŠ è½½æœºåˆ¶jieba é‡‡ç”¨å»¶è¿ŸåŠ è½½ï¼Œimport jieba å’Œ jieba.Tokenizer() ä¸ä¼šç«‹å³è§¦å‘è¯å…¸çš„åŠ è½½ï¼Œä¸€æ—¦æœ‰å¿…è¦æ‰å¼€å§‹åŠ è½½è¯å…¸æ„å»ºå‰ç¼€å­—å…¸ã€‚å¦‚æœä½ æƒ³æ‰‹å·¥åˆå§‹ jiebaï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨åˆå§‹åŒ–ã€‚import jiebajieba.initialize()  # æ‰‹åŠ¨åˆå§‹åŒ–ï¼ˆå¯é€‰ï¼‰åœ¨ 0.28 ä¹‹å‰çš„ç‰ˆæœ¬æ˜¯ä¸èƒ½æŒ‡å®šä¸»è¯å…¸çš„è·¯å¾„çš„ï¼Œæœ‰äº†å»¶è¿ŸåŠ è½½æœºåˆ¶åï¼Œä½ å¯ä»¥æ”¹å˜ä¸»è¯å…¸çš„è·¯å¾„:jieba.set_dictionary('data/dict.txt.big')ä¾‹å­ï¼š https://github.com/fxsjy/jieba/blob/master/test/test_change_dictpath.pyå…¶ä»–è¯å…¸å ç”¨å†…å­˜è¾ƒå°çš„è¯å…¸æ–‡ä»¶https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.smallæ”¯æŒç¹ä½“åˆ†è¯æ›´å¥½çš„è¯å…¸æ–‡ä»¶https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.bigä¸‹è½½ä½ æ‰€éœ€è¦çš„è¯å…¸ï¼Œç„¶åè¦†ç›– jieba/dict.txt å³å¯ï¼›æˆ–è€…ç”¨ jieba.set_dictionary('data/dict.txt.big')å…¶ä»–è¯­è¨€å®ç°ç»“å·´åˆ†è¯ Java ç‰ˆæœ¬ä½œè€…ï¼špiaolingxueåœ°å€ï¼šhttps://github.com/huaban/jieba-analysisç»“å·´åˆ†è¯ C++ ç‰ˆæœ¬ä½œè€…ï¼šyanyiwuåœ°å€ï¼šhttps://github.com/yanyiwu/cppjiebaç»“å·´åˆ†è¯ Rust ç‰ˆæœ¬ä½œè€…ï¼šmessense, MnO2åœ°å€ï¼šhttps://github.com/messense/jieba-rsç»“å·´åˆ†è¯ Node.js ç‰ˆæœ¬ä½œè€…ï¼šyanyiwuåœ°å€ï¼šhttps://github.com/yanyiwu/nodejiebaç»“å·´åˆ†è¯ Erlang ç‰ˆæœ¬ä½œè€…ï¼šfaloodåœ°å€ï¼šhttps://github.com/falood/exjiebaç»“å·´åˆ†è¯ R ç‰ˆæœ¬ä½œè€…ï¼šqinwfåœ°å€ï¼šhttps://github.com/qinwf/jiebaRç»“å·´åˆ†è¯ iOS ç‰ˆæœ¬ä½œè€…ï¼šyanyiwuåœ°å€ï¼šhttps://github.com/yanyiwu/iosjiebaç»“å·´åˆ†è¯ PHP ç‰ˆæœ¬ä½œè€…ï¼šfukuballåœ°å€ï¼šhttps://github.com/fukuball/jieba-phpç»“å·´åˆ†è¯ .NET(C#) ç‰ˆæœ¬ä½œè€…ï¼šanderscuiåœ°å€ï¼šhttps://github.com/anderscui/jieba.NET/ç»“å·´åˆ†è¯ Go ç‰ˆæœ¬ä½œè€…: wangbin åœ°å€: https://github.com/wangbin/jiebagoä½œè€…: yanyiwu åœ°å€: https://github.com/yanyiwu/gojiebaç»“å·´åˆ†è¯Androidç‰ˆæœ¬ä½œè€…   Dongliang.W  åœ°å€ï¼šhttps://github.com/452896915/jieba-androidå‹æƒ…é“¾æ¥https://github.com/baidu/lac   ç™¾åº¦ä¸­æ–‡è¯æ³•åˆ†æï¼ˆåˆ†è¯+è¯æ€§+ä¸“åï¼‰ç³»ç»Ÿhttps://github.com/baidu/AnyQ  ç™¾åº¦FAQè‡ªåŠ¨é—®ç­”ç³»ç»Ÿhttps://github.com/baidu/Senta ç™¾åº¦æƒ…æ„Ÿè¯†åˆ«ç³»ç»Ÿç³»ç»Ÿé›†æˆSolr: https://github.com/sing1ee/jieba-solråˆ†è¯é€Ÿåº¦1.5 MB / Second in Full Mode400 KB / Second in Default Modeæµ‹è¯•ç¯å¢ƒ: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHzï¼›ã€Šå›´åŸã€‹.txtå¸¸è§é—®é¢˜1. æ¨¡å‹çš„æ•°æ®æ˜¯å¦‚ä½•ç”Ÿæˆçš„ï¼Ÿè¯¦è§ï¼š #72. â€œå°ä¸­â€æ€»æ˜¯è¢«åˆ‡æˆâ€œå° ä¸­â€ï¼Ÿï¼ˆä»¥åŠç±»ä¼¼æƒ…å†µï¼‰P(å°ä¸­) ï¼œ P(å°)Ã—P(ä¸­)ï¼Œâ€œå°ä¸­â€è¯é¢‘ä¸å¤Ÿå¯¼è‡´å…¶æˆè¯æ¦‚ç‡è¾ƒä½è§£å†³æ–¹æ³•ï¼šå¼ºåˆ¶è°ƒé«˜è¯é¢‘jieba.add_word('å°ä¸­') æˆ–è€… jieba.suggest_freq('å°ä¸­', True)3. â€œä»Šå¤©å¤©æ°” ä¸é”™â€åº”è¯¥è¢«åˆ‡æˆâ€œä»Šå¤© å¤©æ°” ä¸é”™â€ï¼Ÿï¼ˆä»¥åŠç±»ä¼¼æƒ…å†µï¼‰è§£å†³æ–¹æ³•ï¼šå¼ºåˆ¶è°ƒä½è¯é¢‘jieba.suggest_freq(('ä»Šå¤©', 'å¤©æ°”'), True)æˆ–è€…ç›´æ¥åˆ é™¤è¯¥è¯ jieba.del_word('ä»Šå¤©å¤©æ°”')4. åˆ‡å‡ºäº†è¯å…¸ä¸­æ²¡æœ‰çš„è¯è¯­ï¼Œæ•ˆæœä¸ç†æƒ³ï¼Ÿè§£å†³æ–¹æ³•ï¼šå…³é—­æ–°è¯å‘ç°jieba.cut('ä¸°ç”°å¤ªçœäº†', HMM=False)jieba.cut('æˆ‘ä»¬ä¸­å‡ºäº†ä¸€ä¸ªå›å¾’', HMM=False)æ›´å¤šé—®é¢˜è¯·ç‚¹å‡»ï¼šhttps://github.com/fxsjy/jieba/issues?sort=updated&state=closedä¿®è®¢å†å²https://github.com/fxsjy/jieba/blob/master/Changelogjieba\""Jieba\"" (Chinese for \""to stutter\"") Chinese text segmentation: built to be the best Python Chinese word segmentation module.FeaturesSupport three types of segmentation mode:Accurate Mode attempts to cut the sentence into the most accurate segmentations, which is suitable for text analysis.Full Mode gets all the possible words from the sentence. Fast but not accurate.Search Engine Mode, based on the Accurate Mode, attempts to cut long words into several short words, which can raise the recall rate. Suitable for search engines.Supports Traditional ChineseSupports customized dictionariesMIT LicenseOnline demohttp://jiebademo.ap01.aws.af.cm/(Powered by Appfog)UsageFully automatic installation: easy_install jieba or pip install jiebaSemi-automatic installation: Download http://pypi.python.org/pypi/jieba/ , run python setup.py install after extracting.Manual installation: place the jieba directory in the current directory or python site-packages directory.import jieba.AlgorithmBased on a prefix dictionary structure to achieve efficient word graph scanning. Build a directed acyclic graph (DAG) for all possible word combinations.Use dynamic programming to find the most probable combination based on the word frequency.For unknown words, a HMM-based model is used with the Viterbi algorithm.Main FunctionsCutThe jieba.cut function accepts three input parameters: the first parameter is the string to be cut; the second parameter is cut_all, controlling the cut mode; the third parameter is to control whether to use the Hidden Markov Model.jieba.cut_for_search accepts two parameter: the string to be cut; whether to use the Hidden Markov Model. This will cut the sentence into short words suitable for search engines.The input string can be an unicode/str object, or a str/bytes object which is encoded in UTF-8 or GBK. Note that using GBK encoding is not recommended because it may be unexpectly decoded as UTF-8.jieba.cut and jieba.cut_for_search returns an generator, from which you can use a for loop to get the segmentation result (in unicode).jieba.lcut and jieba.lcut_for_search returns a list.jieba.Tokenizer(dictionary=DEFAULT_DICT) creates a new customized Tokenizer, which enables you to use different dictionaries at the same time. jieba.dt is the default Tokenizer, to which almost all global functions are mapped.Code example: segmentation#encoding=utf-8import jiebaseg_list = jieba.cut(\""æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦\"", cut_all=True)print(\""Full Mode: \"" + \""/ \"".join(seg_list))  # å…¨æ¨¡å¼seg_list = jieba.cut(\""æˆ‘æ¥åˆ°åŒ—äº¬æ¸…åå¤§å­¦\"", cut_all=False)print(\""Default Mode: \"" + \""/ \"".join(seg_list))  # é»˜è®¤æ¨¡å¼seg_list = jieba.cut(\""ä»–æ¥åˆ°äº†ç½‘æ˜“æ­ç ”å¤§å¦\"")print(\"", \"".join(seg_list))seg_list = jieba.cut_for_search(\""å°æ˜ç¡•å£«æ¯•ä¸šäºä¸­å›½ç§‘å­¦é™¢è®¡ç®—æ‰€ï¼Œååœ¨æ—¥æœ¬äº¬éƒ½å¤§å­¦æ·±é€ \"")  # æœç´¢å¼•æ“æ¨¡å¼print(\"", \"".join(seg_list))Output:[Full Mode]: æˆ‘/ æ¥åˆ°/ åŒ—äº¬/ æ¸…å/ æ¸…åå¤§å­¦/ åå¤§/ å¤§å­¦[Accurate Mode]: æˆ‘/ æ¥åˆ°/ åŒ—äº¬/ æ¸…åå¤§å­¦[Unknown Words Recognize] ä»–, æ¥åˆ°, äº†, ç½‘æ˜“, æ­ç ”, å¤§å¦    (In this case, \""æ­ç ”\"" is not in the dictionary, but is identified by the Viterbi algorithm)[Search Engine Mode]ï¼š å°æ˜, ç¡•å£«, æ¯•ä¸š, äº, ä¸­å›½, ç§‘å­¦, å­¦é™¢, ç§‘å­¦é™¢, ä¸­å›½ç§‘å­¦é™¢, è®¡ç®—, è®¡ç®—æ‰€, å, åœ¨, æ—¥æœ¬, äº¬éƒ½, å¤§å­¦, æ—¥æœ¬äº¬éƒ½å¤§å­¦, æ·±é€ Add a custom dictionaryLoad dictionaryDevelopers can specify their own custom dictionary to be included in the jieba default dictionary. Jieba is able to identify new words, but you can add your own new words can ensure a higher accuracy.Usageï¼š jieba.load_userdict(file_name) # file_name is a file-like object or the path of the custom dictionaryThe dictionary format is the same as that of dict.txt: one word per line; each line is divided into three parts separated by a space: word, word frequency, POS tag. If file_name is a path or a file opened in binary mode, the dictionary must be UTF-8 encoded.The word frequency and POS tag can be omitted respectively. The word frequency will be filled with a suitable value if omitted.For example:åˆ›æ–°åŠ 3 iäº‘è®¡ç®— 5å‡±ç‰¹ç³ nzå°ä¸­Change a Tokenizer's tmp_dir and cache_file to specify the path of the cache file, for using on a restricted file system.Example:  äº‘è®¡ç®— 5  æå°ç¦ 2  åˆ›æ–°åŠ 3  [Before]ï¼š æå°ç¦ / æ˜¯ / åˆ›æ–° / åŠ / ä¸»ä»» / ä¹Ÿ / æ˜¯ / äº‘ / è®¡ç®— / æ–¹é¢ / çš„ / ä¸“å®¶ /  [After]ï¼šã€€æå°ç¦ / æ˜¯ / åˆ›æ–°åŠ / ä¸»ä»» / ä¹Ÿ / æ˜¯ / äº‘è®¡ç®— / æ–¹é¢ / çš„ / ä¸“å®¶ /Modify dictionaryUse add_word(word, freq=None, tag=None) and del_word(word) to modify the dictionary dynamically in programs.Use suggest_freq(segment, tune=True) to adjust the frequency of a single word so that it can (or cannot) be segmented.Note that HMM may affect the final result.Example:>>> print('/'.join(jieba.cut('å¦‚æœæ”¾åˆ°postä¸­å°†å‡ºé”™ã€‚', HMM=False)))å¦‚æœ/æ”¾åˆ°/post/ä¸­å°†/å‡ºé”™/ã€‚>>> jieba.suggest_freq(('ä¸­', 'å°†'), True)494>>> print('/'.join(jieba.cut('å¦‚æœæ”¾åˆ°postä¸­å°†å‡ºé”™ã€‚', HMM=False)))å¦‚æœ/æ”¾åˆ°/post/ä¸­/å°†/å‡ºé”™/ã€‚>>> print('/'.join(jieba.cut('ã€Œå°ä¸­ã€æ­£ç¡®åº”è¯¥ä¸ä¼šè¢«åˆ‡å¼€', HMM=False)))ã€Œ/å°/ä¸­/ã€/æ­£ç¡®/åº”è¯¥/ä¸ä¼š/è¢«/åˆ‡å¼€>>> jieba.suggest_freq('å°ä¸­', True)69>>> print('/'.join(jieba.cut('ã€Œå°ä¸­ã€æ­£ç¡®åº”è¯¥ä¸ä¼šè¢«åˆ‡å¼€', HMM=False)))ã€Œ/å°ä¸­/ã€/æ­£ç¡®/åº”è¯¥/ä¸ä¼š/è¢«/åˆ‡å¼€Keyword Extractionimport jieba.analysejieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())sentence: the text to be extractedtopK: return how many keywords with the highest TF/IDF weights. The default value is 20withWeight: whether return TF/IDF weights with the keywords. The default value is FalseallowPOS: filter words with which POSs are included. Empty for no filtering.jieba.analyse.TFIDF(idf_path=None) creates a new TFIDF instance, idf_path specifies IDF file path.Example (keyword extraction)https://github.com/fxsjy/jieba/blob/master/test/extract_tags.pyDevelopers can specify their own custom IDF corpus in jieba keyword extractionUsageï¼š jieba.analyse.set_idf_path(file_name) # file_name is the path for the custom corpusCustom Corpus Sampleï¼šhttps://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.bigSample Codeï¼šhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.pyDevelopers can specify their own custom stop words corpus in jieba keyword extractionUsageï¼š jieba.analyse.set_stop_words(file_name) # file_name is the path for the custom corpusCustom Corpus Sampleï¼šhttps://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txtSample Codeï¼šhttps://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.pyThere's also a TextRank implementation available.Use: jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))Note that it filters POS by default.jieba.analyse.TextRank() creates a new TextRank instance.Part of Speech Taggingjieba.posseg.POSTokenizer(tokenizer=None) creates a new customized Tokenizer. tokenizer specifies the jieba.Tokenizer to internally use. jieba.posseg.dt is the default POSTokenizer.Tags the POS of each word after segmentation, using labels compatible with ictclas.Example:>>> import jieba.posseg as pseg>>> words = pseg.cut(\""æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨\"")>>> for w in words:...    print('%s %s' % (w.word, w.flag))...æˆ‘ rçˆ± våŒ—äº¬ nså¤©å®‰é—¨ nsParallel ProcessingPrinciple: Split target text by line, assign the lines into multiple Python processes, and then merge the results, which is considerably faster.Based on the multiprocessing module of Python.Usage:jieba.enable_parallel(4) # Enable parallel processing. The parameter is the number of processes.jieba.disable_parallel() # Disable parallel processing.Example:https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.pyResult: On a four-core 3.4GHz Linux machine, do accurate word segmentation on Complete Works of Jin Yong, and the speed reaches 1MB/s, which is 3.3 times faster than the single-process version.Note that parallel processing supports only default tokenizers, jieba.dt and jieba.posseg.dt.Tokenize: return words with positionThe input must be unicodeDefault moderesult = jieba.tokenize(u'æ°¸å’Œæœè£…é¥°å“æœ‰é™å…¬å¸')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word æ°¸å’Œ                start: 0                end:2word æœè£…                start: 2                end:4word é¥°å“                start: 4                end:6word æœ‰é™å…¬å¸            start: 6                end:10Search moderesult = jieba.tokenize(u'æ°¸å’Œæœè£…é¥°å“æœ‰é™å…¬å¸',mode='search')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word æ°¸å’Œ                start: 0                end:2word æœè£…                start: 2                end:4word é¥°å“                start: 4                end:6word æœ‰é™                start: 6                end:8word å…¬å¸                start: 8                end:10word æœ‰é™å…¬å¸            start: 6                end:10ChineseAnalyzer for Whooshfrom jieba.analyse import ChineseAnalyzerExample: https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.pyCommand Line Interface$> python -m jieba --helpJieba command line interface.positional arguments:  filename              input fileoptional arguments:  -h, --help            show this help message and exit  -d [DELIM], --delimiter [DELIM]                        use DELIM instead of ' / ' for word delimiter; or a                        space if it is used without DELIM  -p [DELIM], --pos [DELIM]                        enable POS tagging; if DELIM is specified, use DELIM                        instead of '_' for POS delimiter  -D DICT, --dict DICT  use DICT as dictionary  -u USER_DICT, --user-dict USER_DICT                        use USER_DICT together with the default dictionary or                        DICT (if specified)  -a, --cut-all         full pattern cutting (ignored with POS tagging)  -n, --no-hmm          don't use the Hidden Markov Model  -q, --quiet           don't print loading messages to stderr  -V, --version         show program's version number and exitIf no filename specified, use STDIN instead.InitializationBy default, Jieba don't build the prefix dictionary unless it's necessary. This takes 1-3 seconds, after which it is not initialized again. If you want to initialize Jieba manually, you can call:import jiebajieba.initialize()  # (optional)You can also specify the dictionary (not supported before version 0.28) :jieba.set_dictionary('data/dict.txt.big')Using Other DictionariesIt is possible to use your own dictionary with Jieba, and there are also two dictionaries ready for download:A smaller dictionary for a smaller memory footprint:https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.smallThere is also a bigger dictionary that has better support for traditional Chinese (ç¹é«”):https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.bigBy default, an in-between dictionary is used, called dict.txt and included in the distribution.In either case, download the file you want, and then call jieba.set_dictionary('data/dict.txt.big') or just replace the existing dict.txt.Segmentation speed1.5 MB / Second in Full Mode400 KB / Second in Default ModeTest Env: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHzï¼›ã€Šå›´åŸã€‹.txt"
65,PaddlePaddle/PaddleOCR,https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/README.md,Python,"English | ç®€ä½“ä¸­æ–‡ | à¤¹à¤¿à¤¨à¥à¤¦à¥€ | æ—¥æœ¬èª | í•œêµ­ì¸ | PÑƒÌÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹ÌĞº                             ç®€ä»‹PaddleOCRæ—¨åœ¨æ‰“é€ ä¸€å¥—ä¸°å¯Œã€é¢†å…ˆã€ä¸”å®ç”¨çš„OCRå·¥å…·åº“ï¼ŒåŠ©åŠ›å¼€å‘è€…è®­ç»ƒå‡ºæ›´å¥½çš„æ¨¡å‹ï¼Œå¹¶åº”ç”¨è½åœ°ã€‚        ğŸ“£ è¿‘æœŸæ›´æ–°ğŸ”¥2023.8.7 å‘å¸ƒ PaddleOCR release/2.7å‘å¸ƒPP-OCRv4ï¼Œæä¾›mobileå’Œserverä¸¤ç§æ¨¡å‹PP-OCRv4-mobileï¼šé€Ÿåº¦å¯æ¯”æƒ…å†µä¸‹ï¼Œä¸­æ–‡åœºæ™¯æ•ˆæœç›¸æ¯”äºPP-OCRv3å†æå‡4.5%ï¼Œè‹±æ–‡åœºæ™¯æå‡10%ï¼Œ80è¯­ç§å¤šè¯­è¨€æ¨¡å‹å¹³å‡è¯†åˆ«å‡†ç¡®ç‡æå‡8%ä»¥ä¸ŠPP-OCRv4-serverï¼šå‘å¸ƒäº†ç›®å‰ç²¾åº¦æœ€é«˜çš„OCRæ¨¡å‹ï¼Œä¸­è‹±æ–‡åœºæ™¯ä¸Šæ£€æµ‹æ¨¡å‹ç²¾åº¦æå‡4.9%ï¼Œ è¯†åˆ«æ¨¡å‹ç²¾åº¦æå‡2%å¯å‚è€ƒå¿«é€Ÿå¼€å§‹ ä¸€è¡Œå‘½ä»¤å¿«é€Ÿä½¿ç”¨ï¼ŒåŒæ—¶ä¹Ÿå¯åœ¨é£æ¡¨AIå¥—ä»¶(PaddleX)ä¸­çš„é€šç”¨OCRäº§ä¸šæ–¹æ¡ˆä¸­ä½ä»£ç å®Œæˆæ¨¡å‹è®­ç»ƒã€æ¨ç†ã€é«˜æ€§èƒ½éƒ¨ç½²å…¨æµç¨‹å‘å¸ƒPP-ChatOCR ,ä½¿ç”¨èåˆPP-OCRæ¨¡å‹å’Œæ–‡å¿ƒå¤§æ¨¡å‹çš„é€šç”¨åœºæ™¯å…³é”®ä¿¡æ¯æŠ½å–å…¨æ–°æ–¹æ¡ˆğŸ”¨2022.11 æ–°å¢å®ç°4ç§å‰æ²¿ç®—æ³•ï¼šæ–‡æœ¬æ£€æµ‹ DRRG,  æ–‡æœ¬è¯†åˆ« RFL, æ–‡æœ¬è¶…åˆ†Text Telescopeï¼Œå…¬å¼è¯†åˆ«CAN2022.10 ä¼˜åŒ–JSç‰ˆPP-OCRv3æ¨¡å‹ï¼šæ¨¡å‹å¤§å°ä»…4.3Mï¼Œé¢„æµ‹é€Ÿåº¦æå‡8å€ï¼Œé…å¥—web demoå¼€ç®±å³ç”¨ğŸ’¥ ç›´æ’­å›æ”¾ï¼šPaddleOCRç ”å‘å›¢é˜Ÿè¯¦è§£PP-StructureV2ä¼˜åŒ–ç­–ç•¥ã€‚å¾®ä¿¡æ‰«æä¸‹æ–¹äºŒç»´ç ï¼Œå…³æ³¨å…¬ä¼—å·å¹¶å¡«å†™é—®å·åè¿›å…¥å®˜æ–¹äº¤æµç¾¤ï¼Œè·å–ç›´æ’­å›æ”¾é“¾æ¥ä¸20Gé‡ç£…OCRå­¦ä¹ å¤§ç¤¼åŒ…ï¼ˆå†…å«PDFè½¬Wordåº”ç”¨ç¨‹åºã€10ç§å‚ç±»æ¨¡å‹ã€ã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ç­‰ï¼‰ğŸ”¥2022.8.24 å‘å¸ƒ PaddleOCR release/2.6å‘å¸ƒPP-StructureV2ï¼Œç³»ç»ŸåŠŸèƒ½æ€§èƒ½å…¨é¢å‡çº§ï¼Œé€‚é…ä¸­æ–‡åœºæ™¯ï¼Œæ–°å¢æ”¯æŒç‰ˆé¢å¤åŸï¼Œæ”¯æŒä¸€è¡Œå‘½ä»¤å®ŒæˆPDFè½¬Wordï¼›ç‰ˆé¢åˆ†ææ¨¡å‹ä¼˜åŒ–ï¼šæ¨¡å‹å­˜å‚¨å‡å°‘95%ï¼Œé€Ÿåº¦æå‡11å€ï¼Œå¹³å‡CPUè€—æ—¶ä»…éœ€41msï¼›è¡¨æ ¼è¯†åˆ«æ¨¡å‹ä¼˜åŒ–ï¼šè®¾è®¡3å¤§ä¼˜åŒ–ç­–ç•¥ï¼Œé¢„æµ‹è€—æ—¶ä¸å˜æƒ…å†µä¸‹ï¼Œæ¨¡å‹ç²¾åº¦æå‡6%ï¼›å…³é”®ä¿¡æ¯æŠ½å–æ¨¡å‹ä¼˜åŒ–ï¼šè®¾è®¡è§†è§‰æ— å…³æ¨¡å‹ç»“æ„ï¼Œè¯­ä¹‰å®ä½“è¯†åˆ«ç²¾åº¦æå‡2.8%ï¼Œå…³ç³»æŠ½å–ç²¾åº¦æå‡9.1%ã€‚ğŸ”¥2022.8 å‘å¸ƒ OCRåœºæ™¯åº”ç”¨é›†åˆï¼šåŒ…å«æ•°ç ç®¡ã€æ¶²æ™¶å±ã€è½¦ç‰Œã€é«˜ç²¾åº¦SVTRæ¨¡å‹ã€æ‰‹å†™ä½“è¯†åˆ«ç­‰9ä¸ªå‚ç±»æ¨¡å‹ï¼Œè¦†ç›–é€šç”¨ï¼Œåˆ¶é€ ã€é‡‘èã€äº¤é€šè¡Œä¸šçš„ä¸»è¦OCRå‚ç±»åº”ç”¨ã€‚æ›´å¤šğŸŒŸ ç‰¹æ€§æ”¯æŒå¤šç§OCRç›¸å…³å‰æ²¿ç®—æ³•ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šæ‰“é€ äº§ä¸šçº§ç‰¹è‰²æ¨¡å‹PP-OCRã€PP-Structureå’ŒPP-ChatOCRï¼Œå¹¶æ‰“é€šæ•°æ®ç”Ÿäº§ã€æ¨¡å‹è®­ç»ƒã€å‹ç¼©ã€é¢„æµ‹éƒ¨ç½²å…¨æµç¨‹ã€‚    ä¸Šè¿°å†…å®¹çš„ä½¿ç”¨æ–¹æ³•å»ºè®®ä»æ–‡æ¡£æ•™ç¨‹ä¸­çš„å¿«é€Ÿå¼€å§‹ä½“éªŒâš¡ å¿«é€Ÿå¼€å§‹åœ¨çº¿ç½‘ç«™ä½“éªŒï¼šPP-OCRv4 åœ¨çº¿ä½“éªŒåœ°å€ï¼šhttps://aistudio.baidu.com/aistudio/projectdetail/6611435PP-ChatOCR åœ¨çº¿ä½“éªŒåœ°å€ï¼šhttps://aistudio.baidu.com/aistudio/projectdetail/6488689ä¸€è¡Œå‘½ä»¤å¿«é€Ÿä½¿ç”¨ï¼šå¿«é€Ÿå¼€å§‹ï¼ˆä¸­è‹±æ–‡/å¤šè¯­è¨€/æ–‡æ¡£åˆ†æï¼‰é£æ¡¨AIå¥—ä»¶ï¼ˆPaddleXï¼‰ä¸­è®­ç»ƒã€æ¨ç†ã€é«˜æ€§èƒ½éƒ¨ç½²å…¨æµç¨‹ä½“éªŒï¼šPP-OCRv4ï¼šhttps://aistudio.baidu.com/aistudio/modelsdetail?modelId=286PP-ChatOCRï¼šhttps://aistudio.baidu.com/aistudio/modelsdetail?modelId=332ç§»åŠ¨ç«¯demoä½“éªŒï¼šå®‰è£…åŒ…DEMOä¸‹è½½åœ°å€(åŸºäºEasyEdgeå’ŒPaddle-Lite, æ”¯æŒiOSå’ŒAndroidç³»ç»Ÿ)ğŸ“– æŠ€æœ¯äº¤æµåˆä½œé£æ¡¨AIå¥—ä»¶(PaddleX)æä¾›äº†é£æ¡¨æ¨¡å‹è®­å‹æ¨ä¸€ç«™å¼å…¨æµç¨‹é«˜æ•ˆç‡å¼€å‘å¹³å°ï¼Œå…¶ä½¿å‘½æ˜¯åŠ©åŠ›AIæŠ€æœ¯å¿«é€Ÿè½åœ°ï¼Œæ„¿æ™¯æ˜¯ä½¿äººäººæˆä¸ºAI Developerï¼PaddleX ç›®å‰è¦†ç›–å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²ã€3Dã€OCRå’Œæ—¶åºé¢„æµ‹ç­‰é¢†åŸŸæ–¹å‘ï¼Œå·²å†…ç½®äº†36ç§åŸºç¡€å•æ¨¡å‹ï¼Œä¾‹å¦‚RT-DETRã€PP-YOLOEã€PP-HGNetã€PP-LCNetã€PP-LiteSegç­‰ï¼›é›†æˆäº†12ç§å®ç”¨çš„äº§ä¸šæ–¹æ¡ˆï¼Œä¾‹å¦‚PP-OCRv4ã€PP-ChatOCRã€PP-ShiTuã€PP-TSã€è½¦è½½è·¯é¢åƒåœ¾æ£€æµ‹ã€é‡ç”ŸåŠ¨ç‰©è¿ç¦åˆ¶å“è¯†åˆ«ç­‰ã€‚PaddleX æä¾›äº†â€œå·¥å…·ç®±â€å’Œâ€œå¼€å‘è€…â€ä¸¤ç§AIå¼€å‘æ¨¡å¼ã€‚å·¥å…·ç®±æ¨¡å¼å¯ä»¥æ— ä»£ç è°ƒä¼˜å…³é”®è¶…å‚ï¼Œå¼€å‘è€…æ¨¡å¼å¯ä»¥ä½ä»£ç è¿›è¡Œå•æ¨¡å‹è®­å‹æ¨å’Œå¤šæ¨¡å‹ä¸²è”æ¨ç†ï¼ŒåŒæ—¶æ”¯æŒäº‘ç«¯å’Œæœ¬åœ°ç«¯ã€‚PaddleX è¿˜æ”¯æŒè”åˆ›å¼€å‘ï¼Œåˆ©æ¶¦åˆ†æˆï¼ç›®å‰ PaddleX æ­£åœ¨å¿«é€Ÿè¿­ä»£ï¼Œæ¬¢è¿å¹¿å¤§çš„ä¸ªäººå¼€å‘è€…å’Œä¼ä¸šå¼€å‘è€…å‚ä¸è¿›æ¥ï¼Œå…±åˆ›ç¹è£çš„ AI æŠ€æœ¯ç”Ÿæ€ï¼å¾®ä¿¡æ‰«æä¸‹é¢äºŒç»´ç æ·»åŠ è¿è¥åŒå­¦ï¼Œå¹¶å›å¤ã€paddlexã€‘ï¼Œè¿è¥åŒå­¦ä¼šé‚€è¯·æ‚¨åŠ å…¥å®˜æ–¹äº¤æµç¾¤ï¼Œè·å¾—æ›´é«˜æ•ˆçš„é—®é¢˜ç­”ç–‘ã€‚é£æ¡¨AIå¥—ä»¶ã€PaddleXã€‘æŠ€æœ¯äº¤æµç¾¤äºŒç»´ç ğŸ“šã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ğŸš€ å¼€æºå…±å»ºğŸ‘« åŠ å…¥ç¤¾åŒºï¼šæ„Ÿè°¢å¤§å®¶é•¿ä¹…ä»¥æ¥å¯¹ PaddleOCR çš„æ”¯æŒå’Œå…³æ³¨ï¼Œä¸å¹¿å¤§å¼€å‘è€…å…±åŒæ„å»ºä¸€ä¸ªä¸“ä¸šã€å’Œè°ã€ç›¸äº’å¸®åŠ©çš„å¼€æºç¤¾åŒºæ˜¯ PaddleOCR çš„ç›®æ ‡ã€‚æˆ‘ä»¬éå¸¸æ¬¢è¿å„ä½å¼€å‘è€…å‚ä¸åˆ°é£æ¡¨ç¤¾åŒºçš„å¼€æºå»ºè®¾ä¸­ï¼ŒåŠ å…¥å¼€æºã€å…±å»ºé£æ¡¨ã€‚ä¸ºæ„Ÿè°¢ç¤¾åŒºå¼€å‘è€…åœ¨ PaddleOCR release2.7 ä¸­åšå‡ºçš„ä»£ç è´¡çŒ®ï¼Œæˆ‘ä»¬å°†ä¸ºè´¡çŒ®è€…åˆ¶ä½œä¸é‚®å¯„å¼€æºè´¡çŒ®è¯ä¹¦ï¼Œçƒ¦è¯·å¡«å†™é—®å·æä¾›å¿…è¦çš„é‚®å¯„ä¿¡æ¯ã€‚ğŸ¤© ç¤¾åŒºæ´»åŠ¨ï¼šé£æ¡¨å¼€æºç¤¾åŒºé•¿æœŸè¿è¥ä¸å‘å¸ƒå„ç±»ä¸°å¯Œçš„æ´»åŠ¨ä¸å¼€å‘ä»»åŠ¡ï¼Œåœ¨ PaddleOCR ç¤¾åŒºï¼Œä½ å¯ä»¥å…³æ³¨ä»¥ä¸‹ç¤¾åŒºæ´»åŠ¨ï¼Œå¹¶é€‰æ‹©è‡ªå·±æ„Ÿå…´è¶£çš„å†…å®¹å‚ä¸å¼€æºå…±å»ºï¼šğŸ é£æ¡¨å¥—ä»¶å¿«ä¹å¼€æºå¸¸è§„èµ› | ä¼ é€é—¨ï¼šOCR ç¤¾åŒºå¸¸è§„èµ›å‡çº§ç‰ˆï¼Œä»¥å»ºè®¾æ›´å¥½ç”¨çš„ OCR å¥—ä»¶ä¸ºç›®æ ‡ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºå­¦æœ¯å‰æ²¿æ¨¡å‹è®­ç»ƒä¸æ¨ç†ã€æ‰“ç£¨ä¼˜åŒ– OCR å·¥å…·ä¸åº”ç”¨é¡¹ç›®å¼€å‘ç­‰ï¼Œä»»ä½•æœ‰åˆ©äºç¤¾åŒºæ„è§æµåŠ¨å’Œé—®é¢˜è§£å†³çš„è¡Œä¸ºéƒ½çƒ­åˆ‡å¸Œæœ›å¤§å®¶çš„å‚ä¸ã€‚è®©æˆ‘ä»¬å…±åŒæˆé•¿ä¸ºé£æ¡¨å¥—ä»¶çš„é‡è¦ Contributor ğŸ‰ğŸ‰ğŸ‰ã€‚ğŸ’¡ æ–°éœ€æ±‚å¾é›† | ä¼ é€é—¨ï¼šä½ åœ¨æ—¥å¸¸ç ”ç©¶å’Œå®è·µæ·±åº¦å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œæœ‰å“ªäº›ä½ æœŸæœ›çš„ feature äºŸå¾…å®ç°ï¼Ÿè¯·æŒ‰ç…§æ ¼å¼æè¿°ä½ æƒ³å®ç°çš„ feature å’Œä½ æå‡ºçš„åˆæ­¥å®ç°æ€è·¯ï¼Œæˆ‘ä»¬ä¼šå®šæœŸæ²Ÿé€šä¸è®¨è®ºè¿™äº›éœ€æ±‚ï¼Œå¹¶å°†å…¶çº³å…¥æœªæ¥çš„ç‰ˆæœ¬è§„åˆ’ä¸­ã€‚ğŸ’¬ PP-SIG æŠ€æœ¯ç ”è®¨ä¼š | ä¼ é€é—¨ï¼šPP-SIG æ˜¯é£æ¡¨ç¤¾åŒºå¼€å‘è€…ç”±äºç›¸åŒçš„å…´è¶£æ±‡èšåœ¨ä¸€èµ·å½¢æˆçš„è™šæ‹Ÿç»„ç»‡ï¼Œé€šè¿‡å®šæœŸå¬å¼€æŠ€æœ¯ç ”è®¨ä¼šçš„æ–¹å¼ï¼Œåˆ†äº«è¡Œä¸šå‰æ²¿åŠ¨æ€ã€æ¢è®¨ç¤¾åŒºéœ€æ±‚ä¸æŠ€æœ¯å¼€å‘ç»†èŠ‚ã€å‘èµ·ç¤¾åŒºè”åˆè´¡çŒ®ä»»åŠ¡ã€‚PaddleOCR å¸Œæœ›å¯ä»¥é€šè¿‡ AI çš„åŠ›é‡åŠ©åŠ›ä»»ä½•ä¸€ä½æœ‰æ¢¦æƒ³çš„å¼€å‘è€…å®ç°è‡ªå·±çš„æƒ³æ³•ï¼Œäº«å—åˆ›é€ ä»·å€¼å¸¦æ¥çš„æ„‰æ‚¦ã€‚ğŸ“‘ é¡¹ç›®åˆä½œï¼šå¦‚æœä½ æœ‰ä¼ä¸šä¸­æ˜ç¡®çš„ OCR å‚ç±»åº”ç”¨éœ€æ±‚ï¼Œæˆ‘ä»¬æ¨èä½ ä½¿ç”¨è®­å‹æ¨ä¸€ç«™å¼å…¨æµç¨‹é«˜æ•ˆç‡å¼€å‘å¹³å° PaddleXï¼ŒåŠ©åŠ› AI æŠ€æœ¯å¿«é€Ÿè½åœ°ã€‚PaddleX è¿˜æ”¯æŒè”åˆ›å¼€å‘ï¼Œåˆ©æ¶¦åˆ†æˆï¼æ¬¢è¿å¹¿å¤§çš„ä¸ªäººå¼€å‘è€…å’Œä¼ä¸šå¼€å‘è€…å‚ä¸è¿›æ¥ï¼Œå…±åˆ›ç¹è£çš„ AI æŠ€æœ¯ç”Ÿæ€ï¼ğŸ› ï¸ PP-OCRç³»åˆ—æ¨¡å‹åˆ—è¡¨ï¼ˆæ›´æ–°ä¸­ï¼‰æ¨¡å‹ç®€ä»‹æ¨¡å‹åç§°æ¨èåœºæ™¯æ£€æµ‹æ¨¡å‹æ–¹å‘åˆ†ç±»å™¨è¯†åˆ«æ¨¡å‹ä¸­è‹±æ–‡è¶…è½»é‡PP-OCRv4æ¨¡å‹ï¼ˆ15.8Mï¼‰ch_PP-OCRv4_xxç§»åŠ¨ç«¯&æœåŠ¡å™¨ç«¯æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹ä¸­è‹±æ–‡è¶…è½»é‡PP-OCRv3æ¨¡å‹ï¼ˆ16.2Mï¼‰ch_PP-OCRv3_xxç§»åŠ¨ç«¯&æœåŠ¡å™¨ç«¯æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹è‹±æ–‡è¶…è½»é‡PP-OCRv3æ¨¡å‹ï¼ˆ13.4Mï¼‰en_PP-OCRv3_xxç§»åŠ¨ç«¯&æœåŠ¡å™¨ç«¯æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹æ¨ç†æ¨¡å‹ / è®­ç»ƒæ¨¡å‹è¶…è½»é‡OCRç³»åˆ—æ›´å¤šæ¨¡å‹ä¸‹è½½ï¼ˆåŒ…æ‹¬å¤šè¯­è¨€ï¼‰ï¼Œå¯ä»¥å‚è€ƒPP-OCRç³»åˆ—æ¨¡å‹ä¸‹è½½ï¼Œæ–‡æ¡£åˆ†æç›¸å…³æ¨¡å‹å‚è€ƒPP-Structureç³»åˆ—æ¨¡å‹ä¸‹è½½PaddleOCRåœºæ™¯åº”ç”¨æ¨¡å‹è¡Œä¸šç±»åˆ«äº®ç‚¹æ–‡æ¡£è¯´æ˜æ¨¡å‹ä¸‹è½½åˆ¶é€ æ•°ç ç®¡è¯†åˆ«æ•°ç ç®¡æ•°æ®åˆæˆã€æ¼è¯†åˆ«è°ƒä¼˜å…‰åŠŸç‡è®¡æ•°ç ç®¡å­—ç¬¦è¯†åˆ«ä¸‹è½½é“¾æ¥é‡‘èé€šç”¨è¡¨å•è¯†åˆ«å¤šæ¨¡æ€é€šç”¨è¡¨å•ç»“æ„åŒ–æå–å¤šæ¨¡æ€è¡¨å•è¯†åˆ«ä¸‹è½½é“¾æ¥äº¤é€šè½¦ç‰Œè¯†åˆ«å¤šè§’åº¦å›¾åƒå¤„ç†ã€è½»é‡æ¨¡å‹ã€ç«¯ä¾§éƒ¨ç½²è½»é‡çº§è½¦ç‰Œè¯†åˆ«ä¸‹è½½é“¾æ¥æ›´å¤šåˆ¶é€ ã€é‡‘èã€äº¤é€šè¡Œä¸šçš„ä¸»è¦OCRå‚ç±»åº”ç”¨æ¨¡å‹ï¼ˆå¦‚ç”µè¡¨ã€æ¶²æ™¶å±ã€é«˜ç²¾åº¦SVTRæ¨¡å‹ç­‰ï¼‰ï¼Œå¯å‚è€ƒåœºæ™¯åº”ç”¨æ¨¡å‹ä¸‹è½½ğŸ“– æ–‡æ¡£æ•™ç¨‹è¿è¡Œç¯å¢ƒå‡†å¤‡PP-OCRæ–‡æœ¬æ£€æµ‹è¯†åˆ«ğŸ”¥å¿«é€Ÿå¼€å§‹æ¨¡å‹åº“æ¨¡å‹è®­ç»ƒæ–‡æœ¬æ£€æµ‹æ–‡æœ¬è¯†åˆ«æ–‡æœ¬æ–¹å‘åˆ†ç±»å™¨æ¨¡å‹å‹ç¼©æ¨¡å‹é‡åŒ–æ¨¡å‹è£å‰ªçŸ¥è¯†è’¸é¦æ¨ç†éƒ¨ç½²åŸºäºPythoné¢„æµ‹å¼•æ“æ¨ç†åŸºäºC++é¢„æµ‹å¼•æ“æ¨ç†æœåŠ¡åŒ–éƒ¨ç½²ç«¯ä¾§éƒ¨ç½²Paddle2ONNXæ¨¡å‹è½¬åŒ–ä¸é¢„æµ‹äº‘ä¸Šé£æ¡¨éƒ¨ç½²å·¥å…·BenchmarkPP-Structureæ–‡æ¡£åˆ†æğŸ”¥å¿«é€Ÿå¼€å§‹æ¨¡å‹åº“æ¨¡å‹è®­ç»ƒç‰ˆé¢åˆ†æè¡¨æ ¼è¯†åˆ«å…³é”®ä¿¡æ¯æå–æ¨ç†éƒ¨ç½²åŸºäºPythoné¢„æµ‹å¼•æ“æ¨ç†åŸºäºC++é¢„æµ‹å¼•æ“æ¨ç†æœåŠ¡åŒ–éƒ¨ç½²å‰æ²¿ç®—æ³•ä¸æ¨¡å‹ğŸš€æ–‡æœ¬æ£€æµ‹ç®—æ³•æ–‡æœ¬è¯†åˆ«ç®—æ³•ç«¯åˆ°ç«¯OCRç®—æ³•è¡¨æ ¼è¯†åˆ«ç®—æ³•å…³é”®ä¿¡æ¯æŠ½å–ç®—æ³•ä½¿ç”¨PaddleOCRæ¶æ„æ·»åŠ æ–°ç®—æ³•åœºæ™¯åº”ç”¨æ•°æ®æ ‡æ³¨ä¸åˆæˆåŠè‡ªåŠ¨æ ‡æ³¨å·¥å…·PPOCRLabelæ•°æ®åˆæˆå·¥å…·Style-Textå…¶å®ƒæ•°æ®æ ‡æ³¨å·¥å…·å…¶å®ƒæ•°æ®åˆæˆå·¥å…·æ•°æ®é›†é€šç”¨ä¸­è‹±æ–‡OCRæ•°æ®é›†æ‰‹å†™ä¸­æ–‡OCRæ•°æ®é›†å‚ç±»å¤šè¯­è¨€OCRæ•°æ®é›†ç‰ˆé¢åˆ†ææ•°æ®é›†è¡¨æ ¼è¯†åˆ«æ•°æ®é›†å…³é”®ä¿¡æ¯æå–æ•°æ®é›†ä»£ç ç»„ç»‡ç»“æ„æ•ˆæœå±•ç¤ºã€ŠåŠ¨æ‰‹å­¦OCRã€‹ç”µå­ä¹¦ğŸ“šå¼€æºç¤¾åŒºFAQé€šç”¨é—®é¢˜PaddleOCRå®æˆ˜é—®é¢˜å‚è€ƒæ–‡çŒ®è®¸å¯è¯ä¹¦ğŸ‘€ æ•ˆæœå±•ç¤º morePP-OCRv3 ä¸­æ–‡æ¨¡å‹            PP-OCRv3 è‹±æ–‡æ¨¡å‹        PP-OCRv3 å¤šè¯­è¨€æ¨¡å‹        PP-Structure æ–‡æ¡£åˆ†æç‰ˆé¢åˆ†æ+è¡¨æ ¼è¯†åˆ«    SERï¼ˆè¯­ä¹‰å®ä½“è¯†åˆ«ï¼‰            REï¼ˆå…³ç³»æå–ï¼‰            è®¸å¯è¯ä¹¦æœ¬é¡¹ç›®çš„å‘å¸ƒå—Apache 2.0 licenseè®¸å¯è®¤è¯ã€‚"
66,lazyprogrammer/machine_learning_examples,https://github.com/lazyprogrammer/machine_learning_examples/blob/master/README.md,Python,"machine_learning_examplesA collection of machine learning examples and tutorials.Find associated tutorials at https://lazyprogrammer.meFind associated courses at https://deeplearningcourses.comPlease note that not all code from all courses will be found in this repository. Some newer code examples (e.g. most of Tensorflow 2.0) were done in Google Colab. Therefore, you should check the instructions given in the lectures for the course you are taking.How to I find the code for a particular course?The code for each course is separated by folder. You can determine which folder corresponds with which course by watching the \""Where to get the code\"" lecture inside the course (usually Lecture 2 or 3).Remember: one folder = one course.Why you should not fork this repoI've noticed that many people have out-of-date forks. Thus, I recommend not forking this repository if you take one of my courses. I am constantly updating my courses, and your fork will soon become out-of-date. You should clone the repository instead to make it easy to get updates (i.e. just \""git pull\"" randomly and frequently).Where is the code for your latest courses?Beginning with Tensorflow 2, I started to use Google Colab. For those courses, unless otherwise noted, the code will be on Google Colab. Links to the notebooks are provided in the course. See the lecture \""Where to get the code\"" for further details.VIP Course LinksData Science: Transformers for Natural Language Processinghttps://deeplearningcourses.com/c/data-science-transformers-nlpMachine Learning: Natural Language Processing in Python (V2)https://deeplearningcourses.com/c/natural-language-processing-in-pythonTime Series Analysis, Forecasting, and Machine Learninghttps://deeplearningcourses.com/c/time-series-analysisFinancial Engineering and Artificial Intelligence in Pythonhttps://deeplearningcourses.com/c/ai-financePyTorch: Deep Learning and Artificial Intelligencehttps://deeplearningcourses.com/c/pytorch-deep-learningTensorflow 2.0: Deep Learning and Artificial Intelligence (VIP Version)https://deeplearningcourses.com/c/deep-learning-tensorflow-2Deep Learning Courses ExclusivesData Science: Bayesian Linear Regression in Pythonhttps://deeplearningcourses.com/c/bayesian-linear-regression-in-pythonData Science: Bayesian Classification in Pythonhttps://deeplearningcourses.com/c/bayesian-classification-in-pythonClassical Statistical Inference and A/B Testing in Pythonhttps://deeplearningcourses.com/c/statistical-inference-in-pythonLinear Programming for Linear Regression in Pythonhttps://deeplearningcourses.com/c/linear-programming-pythonMATLAB for Students, Engineers, and Professionals in STEMhttps://deeplearningcourses.com/c/matlabOther Course LinksFinancial Analysis: Build a ChatGPT Pairs Trading Bothttps://deeplearningcourses.com/c/chatgpt-pairs-tradingMath 0-1: Calculus for Data Science & Machine Learninghttps://deeplearningcourses.com/c/calculus-data-scienceData Science & Machine Learning: Naive Bayes in Pythonhttps://deeplearningcourses.com/c/data-science-machine-learning-naive-bayes-in-pythonCutting-Edge AI: Deep Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/cutting-edge-artificial-intelligenceRecommender Systems and Deep Learning in Pythonhttps://deeplearningcourses.com/c/recommender-systemsMachine Learning and AI: Support Vector Machines in Pythonhttps://deeplearningcourses.com/c/support-vector-machines-in-pythonDeep Learning: Advanced Computer Visionhttps://deeplearningcourses.com/c/advanced-computer-visionDeep Learning: Advanced NLP and RNNshttps://deeplearningcourses.com/c/deep-learning-advanced-nlpDeep Learning: GANs and Variational Autoencodershttps://deeplearningcourses.com/c/deep-learning-gans-and-variational-autoencodersAdvanced AI: Deep Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/deep-reinforcement-learning-in-pythonArtificial Intelligence: Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-pythonNatural Language Processing with Deep Learning in Pythonhttps://deeplearningcourses.com/c/natural-language-processing-with-deep-learning-in-pythonDeep Learning: Recurrent Neural Networks in Pythonhttps://deeplearningcourses.com/c/deep-learning-recurrent-neural-networks-in-pythonUnsupervised Machine Learning: Hidden Markov Models in Pythonhttps://deeplearningcourses.com/c/unsupervised-machine-learning-hidden-markov-models-in-pythonDeep Learning Prerequisites: The Numpy Stack in Pythonhttps://deeplearningcourses.com/c/deep-learning-prerequisites-the-numpy-stack-in-pythonDeep Learning Prerequisites: Linear Regression in Pythonhttps://deeplearningcourses.com/c/data-science-linear-regression-in-pythonDeep Learning Prerequisites: Logistic Regression in Pythonhttps://deeplearningcourses.com/c/data-science-logistic-regression-in-pythonData Science: Deep Learning and Neural Networks in Pythonhttps://deeplearningcourses.com/c/data-science-deep-learning-in-pythonCluster Analysis and Unsupervised Machine Learning in Pythonhttps://deeplearningcourses.com/c/cluster-analysis-unsupervised-machine-learning-pythonData Science: Supervised Machine Learning in Pythonhttps://deeplearningcourses.com/c/data-science-supervised-machine-learning-in-pythonBayesian Machine Learning in Python: A/B Testinghttps://deeplearningcourses.com/c/bayesian-machine-learning-in-python-ab-testingData Science: Natural Language Processing in Pythonhttps://deeplearningcourses.com/c/data-science-natural-language-processing-in-pythonModern Deep Learning in Pythonhttps://deeplearningcourses.com/c/data-science-deep-learning-in-theano-tensorflowEnsemble Machine Learning in Python: Random Forest and AdaBoosthttps://deeplearningcourses.com/c/machine-learning-in-python-random-forest-adaboostDeep Learning: Convolutional Neural Networks in Pythonhttps://deeplearningcourses.com/c/deep-learning-convolutional-neural-networks-theano-tensorflowUnsupervised Deep Learning in Pythonhttps://deeplearningcourses.com/c/unsupervised-deep-learning-in-python"
67,TgCatUB/catuserbot,https://github.com/TgCatUB/catuserbot/blob/master/README.md,Python,"CatUserbotA simple Telegram userbot based on Telethon .How to deploy catuserbotHeroku DeploySelf hostCheck DocsSupportInspirationX-tra-TelegramUniborg & Uniborg forkNana-RemixUserge-XDisclaimer              YOU ARE FOREWARNEDYour Telegram account may get banned.   Catuserbot or we are not responsible for your account, This bot is intended for the purpose of having fun with some fun commands and group management with some helpfull commands.If  you ended up spamming groups, getting reported left and right, and you ended up in being fight with Telegram and at the end Telegram Team deleted your account. DON'T BLAME US.No personal support will be provided / We won't spoon feed you. If you need help ask in our support group and we or our friends will try to help you.Thanks for using our bot ğŸ˜ºCreditsSpecial thanks to LonamiWebs for Telethon library.To all devs of these UserbotsFinally to all contributors of Catuserbot"
68,donnemartin/system-design-primer,https://github.com/donnemartin/system-design-primer/blob/master/README-ja.md,Python,"English âˆ™ æ—¥æœ¬èª âˆ™ ç®€ä½“ä¸­æ–‡ âˆ™ ç¹é«”ä¸­æ–‡ | Ø§Ù„Ø¹ÙØ±ÙØ¨ÙÙŠÙÙ‘Ø©â€ âˆ™ à¦¬à¦¾à¦‚à¦²à¦¾ âˆ™ PortuguÃªs do Brasil âˆ™ Deutsch âˆ™ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬ âˆ™ ×¢×‘×¨×™×ª âˆ™ Italiano âˆ™ í•œêµ­ì–´ âˆ™ ÙØ§Ø±Ø³ÛŒ âˆ™ Polski âˆ™ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº âˆ™ EspaÃ±ol âˆ™ à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ âˆ™ TÃ¼rkÃ§e âˆ™ tiáº¿ng Viá»‡t âˆ™ FranÃ§ais | Add Translationã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå…¥é–€    å‹•æ©Ÿãƒ»ç›®çš„å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’å­¦ã¶ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«å‚™ãˆã‚‹å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆã‚’å­¦ã¶ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’å­¦ã¶ã“ã¨ã¯ã€ã‚ˆã‚Šè‰¯ã„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ãªã‚‹ã“ã¨ã«è³‡ã™ã‚‹ã§ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã¯ã¨ã¦ã‚‚åºƒç¯„ãªãƒˆãƒ”ãƒƒã‚¯ã‚’å«ã¿ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆåŸç†ã«ã¤ã„ã¦ã¯ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã«ã¯è†¨å¤§ãªé‡ã®æ–‡çŒ®ãŒæ•£ã‚‰ã°ã£ã¦ã„ã¾ã™ã€‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã«å¿…è¦ãªçŸ¥è­˜ã‚’å­¦ã¶ã“ã¨ãŒã§ãã‚‹ æ–‡çŒ®ãƒªã‚¹ãƒˆã‚’ä½“ç³»çš„ã«ã¾ã¨ã‚ãŸã‚‚ã® ã§ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰å­¦ã¶ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ã“ã‚Œã‹ã‚‰ã‚‚ãšã£ã¨æ›´æ–°ã•ã‚Œã¦ã„ãã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸæ®µéšã«ã™ãã¾ã›ã‚“ã€‚Contributions ã¯å¤§æ­“è¿ã§ã™ï¼ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«å‚™ãˆã‚‹ã‚³ãƒ¼ãƒ‰æŠ€è¡“é¢æ¥ã«åŠ ãˆã¦ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«é–¢ã™ã‚‹çŸ¥è­˜ã¯ã€å¤šãã®ãƒ†ãƒƒã‚¯ä¼æ¥­ã«ãŠã‘ã‚‹ æŠ€è¡“æ¡ç”¨é¢æ¥ãƒ—ãƒ­ã‚»ã‚¹ ã§ å¿…è¦ä¸å¯æ¬ ãªè¦ç´  ã§ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§ã®é »å‡ºè³ªå•ã«å‚™ãˆã€è‡ªåˆ†ã®è§£ç­”ã¨æ¨¡ç¯„è§£ç­”:ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã€ã‚³ãƒ¼ãƒ‰ãã—ã¦å›³è¡¨ãªã©ã‚’æ¯”è¼ƒã—ã¦å­¦ã³ã¾ã—ã‚‡ã†ã€‚é¢æ¥æº–å‚™ã«å½¹ç«‹ã¤ãã®ä»–ã®ãƒˆãƒ”ãƒƒã‚¯:å­¦ç¿’æŒ‡é‡ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«ã©ã®ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ ã¨ãã®è§£ç­”ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆèª²é¡Œä¾‹ã€ ã¨ãã®è§£ç­”ãã®ä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œä¾‹æš—è¨˜ã‚«ãƒ¼ãƒ‰    ã“ã®Ankiç”¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒƒã‚­ ã¯ã€é–“éš”åå¾©ã‚’æ´»ç”¨ã—ã¦ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ã‚­ãƒ¼ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®å­¦ç¿’ã‚’æ”¯æ´ã—ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒ‡ãƒƒã‚­ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆç·´ç¿’èª²é¡Œãƒ‡ãƒƒã‚­ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ç·´ç¿’èª²é¡Œãƒ‡ãƒƒã‚­å¤–å‡ºå…ˆã‚„ç§»å‹•ä¸­ã®å‹‰å¼·ã«å½¹ç«‹ã¤ã§ã—ã‚‡ã†ã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŠ€è¡“èª²é¡Œç”¨ã®å•é¡Œ: ç·´ç¿’ç”¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰æŠ€è¡“é¢æ¥ç”¨ã®å•é¡Œã‚’æ¢ã—ã¦ã„ã‚‹å ´åˆã¯ã“ã¡ã‚‰    å§‰å¦¹ãƒªãƒã‚¸ãƒˆãƒªã® Interactive Coding Challengesã‚‚è¦‹ã¦ã¿ã¦ãã ã•ã„ã€‚è¿½åŠ ã®æš—è¨˜ãƒ‡ãƒƒã‚­ã‚«ãƒ¼ãƒ‰ã‚‚å…¥ã£ã¦ã„ã¾ã™ã€‚Coding deckã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰å­¦ã¶ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆç­‰ã®è²¢çŒ®ã¯ç©æ¥µçš„ã«ãŠé¡˜ã„ã—ã¾ã™:ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹æ”¹å–„æ–°è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ ç¿»è¨³ã™ã‚‹ç¾åœ¨ã€å†…å®¹ã®æ”¹å–„ãŒå¿…è¦ãªä½œæ¥­ä¸­ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã“ã¡ã‚‰ã§ã™ã€‚ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã®å‰ã«Contributing Guidelinesã‚’èª­ã¿ã¾ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆç›®æ¬¡è³›å¦ã‚‚å«ã‚ãŸæ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®å„ãƒˆãƒ”ãƒƒã‚¯ã®æ¦‚è¦ã€‚ å…¨ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚Šã¾ã™ã€‚ãã‚Œãã‚Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ˆã‚Šå­¦ã³ã‚’æ·±ã‚ã‚‹ã‚ˆã†ãªä»–ã®æ–‡çŒ®ã¸ã®ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚    ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯: ã¾ãšã¯ã“ã“ã‹ã‚‰Step 1: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹å‹•ç”»ã‚’è¦‹ã‚‹Step 2: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹è¨˜äº‹ã‚’èª­ã‚€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¯ç”¨æ€§ vs ä¸€è²«æ€§CAPç†è«–CP - ä¸€è²«æ€§(consistency)ã¨åˆ†å‰²æ€§(partition)è€æ€§AP - å¯ç”¨æ€§(availability)ã¨åˆ†å‰²æ€§(partition)è€æ€§ä¸€è²«æ€§ ãƒ‘ã‚¿ãƒ¼ãƒ³å¼±ã„ä¸€è²«æ€§çµæœæ•´åˆæ€§å¼·ã„ä¸€è²«æ€§å¯ç”¨æ€§ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ (DNS)ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CDN)ãƒ—ãƒƒã‚·ãƒ¥CDNãƒ—ãƒ«CDNãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ–/ãƒ‘ãƒƒã‚·ãƒ–æ§‹æˆã‚¢ã‚¯ãƒ†ã‚£ãƒ–/ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ§‹æˆLayer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· (WEBã‚µãƒ¼ãƒãƒ¼)ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ vs ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (RDBMS)ãƒã‚¹ã‚¿ãƒ¼/ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼/ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‡ãƒãƒ¼ãƒãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³SQL ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°NoSQLã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã‚°ãƒ©ãƒ• ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹SQL or NoSQLã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°CDNã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°Webã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã§ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã™ã‚‹ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã®ã‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ (ãƒ©ã‚¤ãƒˆãƒãƒƒã‚¯)ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰éåŒæœŸå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼é€šä¿¡ä¼é€åˆ¶å¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ« (TCP)ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« (UDP)é éš”æ‰‹ç¶šå‘¼å‡º (RPC)Representational state transfer (REST)ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è£œéº2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ä¾‹é¡Œå®Ÿä¸–ç•Œã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å„ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°ä½œæ¥­ä¸­ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆé€£çµ¡æƒ…å ±ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å­¦ç¿’æŒ‡é‡å­¦ç¿’ã‚¹ãƒ‘ãƒ³ã«å¿œã˜ã¦ã¿ã‚‹ã¹ããƒˆãƒ”ãƒƒã‚¯ã‚¹ (short, medium, long)Q: é¢æ¥ã®ãŸã‚ã«ã¯ã€ã“ã“ã«ã‚ã‚‹ã‚‚ã®ã™ã¹ã¦ã‚’ã‚„ã‚‰ãªã„ã¨ã„ã‘ãªã„ã®ã§ã—ã‚‡ã†ã‹ï¼ŸA: ã„ãˆã€ã“ã“ã«ã‚ã‚‹ã™ã¹ã¦ã‚’ã‚„ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚é¢æ¥ã§ä½•ã‚’èã‹ã‚Œã‚‹ã‹ã¯ä»¥ä¸‹ã®æ¡ä»¶ã«ã‚ˆã£ã¦å¤‰ã‚ã£ã¦ãã¾ã™:ã©ã‚Œã ã‘ã®æŠ€è¡“çµŒé¨“ãŒã‚ã‚‹ã‹ã‚ãªãŸã®æŠ€è¡“èƒŒæ™¯ãŒä½•ã§ã‚ã‚‹ã‹ã©ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã®ãŸã‚ã«é¢æ¥ã‚’å—ã‘ã¦ã„ã‚‹ã‹ã©ã®ä¼æ¥­ã®é¢æ¥ã‚’å—ã‘ã¦ã„ã‚‹ã‹é‹ã‚ˆã‚ŠçµŒé¨“ã®ã‚ã‚‹å€™è£œè€…ã¯ä¸€èˆ¬çš„ã«ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«ã¤ã„ã¦ã‚ˆã‚Šæ·±ã„çŸ¥è­˜ã‚’æœ‰ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¦æ±‚ã•ã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã‚„ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ã¯å„ãƒ¡ãƒ³ãƒãƒ¼ã®æŒã¤ã‚ˆã†ãªçŸ¥è­˜ã‚ˆã‚Šã¯æ·±ã„è¦‹è­˜ã‚’æŒã£ã¦ã„ã‚‹ã¹ãã§ã—ã‚‡ã†ã€‚ä¸€æµãƒ†ãƒƒã‚¯ä¼æ¥­ã§ã¯è¤‡æ•°å›ã®è¨­è¨ˆé¢æ¥ã‚’èª²ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ã¾ãšã¯åºƒãå§‹ã‚ã¦ã€ãã“ã‹ã‚‰ã„ãã¤ã‹ã®åˆ†é‡ã«çµã£ã¦æ·±ã‚ã¦ã„ãã®ãŒã„ã„ã§ã—ã‚‡ã†ã€‚æ§˜ã€…ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦å°‘ã—ãšã¤çŸ¥ã£ã¦ãŠãã“ã¨ã¯ã„ã„ã“ã¨ã§ã™ã€‚ä»¥ä¸‹ã®å­¦ç¿’ã‚¬ã‚¤ãƒ‰ã‚’è‡ªåˆ†ã®å­¦ç¿’ã«å½“ã¦ã‚‰ã‚Œã‚‹æ™‚é–“ã€æŠ€è¡“çµŒé¨“ã€ã©ã®è·ä½ã€ã©ã®ä¼šç¤¾ã«å¿œå‹Ÿã—ã¦ã„ã‚‹ã‹ãªã©ã‚’åŠ å‘³ã—ã¦è‡ªåˆ†ç”¨ã«èª¿æ•´ã—ã¦ä½¿ã†ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚çŸ­æœŸé–“ - å¹…åºƒã ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚ã„ãã¤ã‹ã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚ä¸­æœŸé–“ - å¹…åºƒã ãã—ã¦ ãã‚Œãªã‚Šã«æ·±ãã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚å¤šãã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚é•·æœŸé–“ - å¹…åºƒã ãã—ã¦ ã‚‚ã£ã¨æ·±ãã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚’å­¦ã¶ã€‚ã»ã¼å…¨ã¦ã® é¢æ¥èª²é¡Œã‚’è§£ãã“ã¨ã§å¯¾ç­–ã™ã‚‹ã€‚çŸ­æœŸé–“ä¸­æœŸé–“é•·æœŸé–“ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ ã‚’èª­ã¿ã€ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œæ©Ÿåºã«ã¤ã„ã¦åºƒãçŸ¥ã‚‹ğŸ‘ğŸ‘ğŸ‘æ¬¡ã®ãƒªãƒ³ã‚¯å…ˆã®ã„ãã¤ã‹ã®ãƒšãƒ¼ã‚¸ã‚’èª­ã‚“ã§ å„ä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ–ãƒ­ã‚° å¿œå‹Ÿã™ã‚‹ä¼šç¤¾ã«ã¤ã„ã¦çŸ¥ã‚‹ğŸ‘ğŸ‘ğŸ‘æ¬¡ã®ãƒªãƒ³ã‚¯å…ˆã®ã„ãã¤ã‹ã®ãƒšãƒ¼ã‚¸ã‚’èª­ã‚€ å®Ÿä¸–ç•Œã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ğŸ‘ğŸ‘ğŸ‘å¾©ç¿’ã™ã‚‹ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã«ã©ã®ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã‹ğŸ‘ğŸ‘ğŸ‘ã¨ã‚Šã‚ãˆãšä¸€å‘¨ã™ã‚‹ ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹SomeManyMostã¨ã‚Šã‚ãˆãšä¸€å‘¨ã™ã‚‹ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆå•é¡Œã¨è§£ç­”SomeManyMostå¾©ç¿’ã™ã‚‹ ãã®ä»–ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§ã®è³ªå•ä¾‹SomeManyMostã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã«ã©ã®ã‚ˆã†ã«ã—ã¦è‡¨ã‚ã°ã„ã„ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥è©¦é¨“å•é¡Œã«ã©ã®ã‚ˆã†ã«å–ã‚Šçµ„ã‚€ã‹ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã¯ open-ended conversation(Yes/Noã§ã¯ç­”ãˆã‚‰ã‚Œãªã„å£é ­è³ªå•)ã§ã™ã€‚ è‡ªåˆ†ã§ä¼šè©±ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã«å¾“ã£ã¦è­°è«–ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã“ã¨ãŒã§ãã‚‹ã§ã—ã‚‡ã†ã€‚ã“ã®éç¨‹ã‚’ç¢ºã‹ãªã‚‚ã®ã«ã™ã‚‹ãŸã‚ã«ã€æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ã¨ãã®è§£ç­” ã‚’ä»¥ä¸‹ã®æŒ‡é‡ã«å¾“ã£ã¦èª­ã¿è¾¼ã‚€ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚ã‚¹ãƒ†ãƒƒãƒ— 1: ãã®ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ä¾‹ã®æ¦‚è¦ã€åˆ¶ç´„ã€æ¨è¨ˆå€¤ç­‰ã‚’èãå‡ºã—ã€ã¾ã¨ã‚ã‚‹ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜ã®è¦æ±‚äº‹é …ã‚’èãå‡ºã—ã€å•é¡Œç®‡æ‰€ã‚’ç‰¹å®šã—ã¾ã—ã‚‡ã†ã€‚ä½¿ç”¨ä¾‹ã¨åˆ¶ç´„ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã®è³ªå•ã‚’æŠ•ã’ã‹ã‘ã¾ã—ã‚‡ã†ã€‚è¦æ±‚ã™ã‚‹æ¨è¨ˆå€¤ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¦ãŠãã¾ã—ã‚‡ã†ã€‚èª°ãŒãã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã†ã®ã‹ï¼Ÿã©ã®ã‚ˆã†ã«ä½¿ã†ã®ã‹ï¼Ÿä½•äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã„ã‚‹ã®ã‹ï¼Ÿã‚·ã‚¹ãƒ†ãƒ ã¯ã©ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’æœãŸã™ã®ã‹ï¼Ÿã‚·ã‚¹ãƒ†ãƒ ã¸ã®å…¥åŠ›ã¨å‡ºåŠ›ã¯ï¼Ÿã©ã‚Œã ã‘ã®å®¹é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒãå¿…è¦ãŒã‚ã‚‹ã®ã‹ï¼Ÿä¸€ç§’é–“ã«ä½•ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é€ä¿¡ãŒæƒ³å®šã•ã‚Œã‚‹ã‹ï¼Ÿèª­ã¿æ›¸ãæ¯”ç‡ã®æ¨å®šå€¤ã¯ã„ãã‚‰ç¨‹åº¦ã‹ï¼Ÿã‚¹ãƒ†ãƒƒãƒ— 2: ã‚ˆã‚Šé«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’çµ„ã¿ç«‹ã¦ã‚‹é‡è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å…¨ã¦è€ƒæ…®ã—ãŸé«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ¦‚è¦ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¨æ¥ç¶šã‚’ã‚¹ã‚±ãƒƒãƒã—ã¦æ›¸ãå‡ºã™è€ƒãˆã®è£ä»˜ã‘ã‚’ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ— 3: æ ¸ã¨ãªã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è¨­è¨ˆã™ã‚‹ãã‚Œãã‚Œã®ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã¤ã„ã¦ã®è©³ç´°ã‚’å­¦ã¶ã€‚ä¾‹ãˆã°ã€urlçŸ­ç¸®ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆã‚’å•ã‚ã‚ŒãŸéš›ã«ã¯æ¬¡ã®ã‚ˆã†ã«ã™ã‚‹ã¨ã„ã„ã§ã—ã‚‡ã†:å…ƒã®URLã®ãƒãƒƒã‚·ãƒ¥åŒ–ã—ãŸã‚‚ã®ã‚’ä½œã‚Šã€ãã‚Œã‚’ä¿å­˜ã™ã‚‹MD5 ã¨ Base62ãƒãƒƒã‚·ãƒ¥è¡çªSQL ã‚‚ã—ãã¯ NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚ŒãŸURLã‚’å…ƒã®URLã«å†ç¿»è¨³ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‚ç…§API & ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã®è¨­è¨ˆã‚¹ãƒ†ãƒƒãƒ— 4: ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®ã‚¹ã‚±ãƒ¼ãƒ«ä¸ãˆã‚‰ã‚ŒãŸåˆ¶ç´„æ¡ä»¶ã‹ã‚‰ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚Šãã†ãªã¨ã“ã‚ã‚’å‰²ã‚Šå‡ºã—ã€æ˜ç¢ºåŒ–ã™ã‚‹ã€‚  ä¾‹ãˆã°ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®å•é¡Œè§£æ±ºã®ãŸã‚ã«ä»¥ä¸‹ã®è¦ç´ ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å–ã‚Šã†ã‚‹è§£æ±ºç­–ã¨ãã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦è­°è«–ã‚’ã—ã‚ˆã†ã€‚å…¨ã¦ã®ã“ã¨ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ã€‚ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ã¤ã„ã¦ã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®åŸç†ã‚’èª­ã‚€ã¨ã„ã„ã§ã—ã‚‡ã†ã€‚ã¡ã‚‡ã£ã¨ã—ãŸæš—ç®—å•é¡Œã¡ã‚‡ã£ã¨ã—ãŸæ¨è¨ˆå€¤ã‚’æ‰‹è¨ˆç®—ã§ã™ã‚‹ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚è£œéºã®ä»¥ä¸‹ã®é …ç›®ãŒå½¹ã«ç«‹ã¤ã§ã—ã‚‡ã†:ãƒãƒ©è£è¨ˆç®—ã§ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã™ã‚‹2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã£ã¦ãŠãã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®å‚è€ƒå€¤æ–‡çŒ®ã¨ãã®ä»–ã®å‚è€ƒè³‡æ–™ä»¥ä¸‹ã®ãƒªãƒ³ã‚¯å…ˆãƒšãƒ¼ã‚¸ã‚’è¦‹ã¦ã©ã®ã‚ˆã†ãªè³ªå•ã‚’æŠ•ã’ã‹ã‘ã‚‰ã‚Œã‚‹ã‹æ¦‚è¦ã‚’é ­ã«å…¥ã‚Œã¦ãŠãã¾ã—ã‚‡ã†:ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã§æˆåŠŸã™ã‚‹ã«ã¯ï¼Ÿã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ã¸ã®å°å…¥ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆèª²é¡Œä¾‹ã¨ãã®è§£ç­”é »å‡ºã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨å‚è€ƒè§£ç­”ã€ã‚³ãƒ¼ãƒ‰åŠã³ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è§£ç­”ã¯ solutions/ ãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã‚‹å•é¡ŒPastebin.com (ã‚‚ã—ãã¯ Bit.ly) ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Twitterã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ (ã‚‚ã—ãã¯Facebookãƒ•ã‚£ãƒ¼ãƒ‰)ã‚’è¨­è¨ˆã™ã‚‹Twitteræ¤œç´¢(ã‚‚ã—ãã¯Facebookæ¤œç´¢)æ©Ÿèƒ½ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”ã‚¦ã‚§ãƒ–ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Mint.comã‚’è¨­è¨ˆã™ã‚‹è§£ç­”SNSã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”Amazonã®ã‚«ãƒ†ã‚´ãƒªæ¯ã®å£²ã‚Šä¸Šã’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”AWSä¸Šã§100ä¸‡äººè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹è§£ç­”ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå•é¡Œã‚’è¿½åŠ ã™ã‚‹ContributePastebin.com (ã‚‚ã—ãã¯ Bit.ly) ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Twitterã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³&æ¤œç´¢ (ã‚‚ã—ãã¯Facebookãƒ•ã‚£ãƒ¼ãƒ‰&æ¤œç´¢)ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹ã‚¦ã‚§ãƒ–ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®è¨­è¨ˆå•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Mint.comã®è¨­è¨ˆå•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹SNSã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚­ãƒ¼/ãƒãƒªãƒ¥ãƒ¼æ§‹é€ ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹Amazonã®ã‚«ãƒ†ã‚´ãƒªæ¯ã®å£²ã‚Šä¸Šã’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹AWSä¸Šã§100ä¸‡äººè¦æ¨¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹å•é¡Œã¨è§£ç­”ã‚’è¦‹ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘è¨­è¨ˆå•é¡Œã¨è§£ç­”é »å‡ºã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨å‚è€ƒè§£ç­”ã€ã‚³ãƒ¼ãƒ‰åŠã³ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è§£ç­”ã¯ solutions/ ãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ãƒªãƒ³ã‚¯ãŒè²¼ã‚‰ã‚Œã¦ã„ã‚‹å‚™è€ƒ: ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ä½œæ¥­ä¸­ã§ã™å•é¡Œãƒãƒƒã‚·ãƒ¥ãƒãƒƒãƒ—ã®è¨­è¨ˆè§£ç­”LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¨­è¨ˆè§£ç­”ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼ã®è¨­è¨ˆè§£ç­”ã‚«ãƒ¼ãƒ‰ã®ãƒ‡ãƒƒã‚­ã®è¨­è¨ˆè§£ç­”é§è»Šå ´ã®è¨­è¨ˆè§£ç­”ãƒãƒ£ãƒƒãƒˆã‚µãƒ¼ãƒãƒ¼ã®è¨­è¨ˆè§£ç­”å††å½¢é…åˆ—ã®è¨­è¨ˆContributeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå•é¡Œã‚’è¿½åŠ ã™ã‚‹Contributeã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆãƒˆãƒ”ãƒƒã‚¯ã‚¹: ã¾ãšã¯ã“ã“ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã®å‹‰å¼·ã¯åˆã‚ã¦ï¼Ÿã¾ãšåˆã‚ã«ã€ã‚ˆãä½¿ã‚ã‚Œã‚‹è¨­è¨ˆåŸç†ã«ã¤ã„ã¦ã€ãã‚Œã‚‰ãŒä½•ã§ã‚ã‚‹ã‹ã€ã©ã®ã‚ˆã†ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã‹ã€é•·æ‰€çŸ­æ‰€ã«ã¤ã„ã¦åŸºæœ¬çš„ãªçŸ¥è­˜ã‚’å¾—ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã‚¹ãƒ†ãƒƒãƒ— 1: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹å‹•ç”»ã‚’è¦³ã¦å¾©ç¿’ã™ã‚‹Harvardã§ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®è¬›ç¾©ã“ã“ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚¹:å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒƒãƒ— 2: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«é–¢ã™ã‚‹è³‡æ–™ã‚’èª­ã‚“ã§å¾©ç¿’ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã“ã“ã§è§¦ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚¹:ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥éåŒæœŸæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—æ¬¡ã«ã€ãƒã‚¤ãƒ¬ãƒ™ãƒ«ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã¤ã„ã¦ã¿ã¦ã„ã:ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå¯ç”¨æ€§ vs ä¸€è²«æ€§å…¨ã¦ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ã¨ã„ã†ã®ã‚’è‚ã«å‘½ã˜ã¦ãŠãã¾ã—ã‚‡ã†ã€‚ãã‚Œã‹ã‚‰ã€ã‚ˆã‚Šæ·±ã„å†…å®¹ã€DNSã‚„CDNãã—ã¦ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãªã©ã«ã¤ã„ã¦å­¦ç¿’ã‚’é€²ã‚ã¦ã„ãã¾ã—ã‚‡ã†ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ vs ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒªã‚½ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚Œã‚‹ã®ã«ã¤ã‚Œã¦ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ãŒå‘ä¸Šã™ã‚‹å ´åˆãã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ« ã§ã‚ã‚‹ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚ä¸€èˆ¬çš„ã«ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã¨ã„ã†ã®ã¯ã™ãªã‚ã¡è¨ˆç®—å‡¦ç†ã‚’å¢—ã‚„ã™ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå¢—ãˆãŸæ™‚ãªã©ã‚ˆã‚Šå¤§ããªå‡¦ç†ã‚’æŒã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚1ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹vsã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’ã¨ã‚‰ãˆã‚‹ä»–ã®è€ƒãˆæ–¹:ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ã§ã®å•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹æ™‚ã€ã‚ãªãŸã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä¸€äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦é…ã„ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ ã§ã®å•é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹ã¨ãã€ä¸€äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ã¯é€Ÿã„ã§ã™ãŒã€å¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚ã‚‹æ™‚ã«ã¯é…ããªã£ã¦ã—ã¾ã†ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«ã¤ã„ã¦ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€å¯ç”¨æ€§ã€å®‰å®šæ€§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ã¨ã¯ãªã«ãŒã—ã‹ã®å‹•ä½œã‚’è¡Œã†ã€ã‚‚ã—ãã¯çµæœã‚’ç®—å‡ºã™ã‚‹ã®ã«è¦ã™ã‚‹æ™‚é–“ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ ã¨ã¯ãã®ã‚ˆã†ãªå‹•ä½œã‚„çµæœç®—å‡ºãŒå˜ä½æ™‚é–“ã«è¡Œã‚ã‚Œã‚‹å›æ•°ä¸€èˆ¬çš„ã«ã€ æœ€å¤§é™ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ ã‚’ è¨±å®¹ç¯„å›²å†…ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ã§å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã®ãŒæ™®é€šã ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ vs ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç†è§£ã™ã‚‹å¯ç”¨æ€§ vs ä¸€è²«æ€§CAP ç†è«–      Source: CAP theorem revisitedåˆ†æ•£å‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã¯ä¸‹ã®ä¸‰ã¤ã®ã†ã¡äºŒã¤ã¾ã§ã—ã‹åŒæ™‚ã«ä¿è¨¼ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€‚:ä¸€è²«æ€§ - å…¨ã¦ã®èª­ã¿è¾¼ã¿ã¯æœ€æ–°ã®æ›¸ãè¾¼ã¿ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã‚’å—ã‘å–ã‚‹å¯ç”¨æ€§ - å—ã‘å–ã‚‹æƒ…å ±ãŒæœ€æ–°ã®ã‚‚ã®ã ã¨ã„ã†ä¿è¨¼ã¯ãªã„ãŒã€å…¨ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¿…ãšå—ã‘å–ã‚‹åˆ†æ–­è€æ€§ - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œã«ã‚ˆã£ã¦é †ä¸åŒã®åˆ†æ–­ãŒèµ·ãã¦ã‚‚ã‚·ã‚¹ãƒ†ãƒ ãŒå‹•ä½œã‚’ç¶šã‘ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ä¿¡é ¼ã§ããªã„ã®ã§ã€åˆ†æ–­è€æ€§ã¯å¿…ãšä¿è¨¼ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ã¤ã¾ã‚Šã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã¯ã€ä¸€è²«æ€§ã‚’å–ã‚‹ã‹ã€å¯ç”¨æ€§ã‚’å–ã‚‹ã‹ã‚’è€ƒãˆãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚CP - ä¸€è²«æ€§ã¨åˆ†æ–­è€æ€§(consistency and partition tolerance)åˆ†æ–­ã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¾…ã¡ç¶šã‘ã¦ã„ã‚‹ã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã«é™¥ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚CPã¯ã‚ãªãŸã®ã‚µãƒ¼ãƒ“ã‚¹ãŒã‚¢ãƒˆãƒŸãƒƒã‚¯ãªèª­ã¿æ›¸ãï¼ˆä¸å¯åˆ†æ“ä½œï¼‰ã‚’å¿…è¦ã¨ã™ã‚‹éš›ã«ã¯ã„ã„é¸æŠè‚¢ã§ã—ã‚‡ã†ã€‚AP - å¯ç”¨æ€§ã¨åˆ†æ–­è€æ€§(availability and partition tolerance)ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ãƒãƒ¼ãƒ‰ä¸Šã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã§æœ€æ–°ã®ã‚‚ã®ã‚’è¿”ã—ã¾ã™ã€‚ã¤ã¾ã‚Šã€æœ€æ–°ç‰ˆã®ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚åˆ†æ–­ãŒè§£æ¶ˆã•ã‚ŒãŸå¾Œã‚‚ã€æ›¸ãè¾¼ã¿ãŒåæ˜ ã•ã‚Œã‚‹ã®ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚çµæœæ•´åˆæ€§ã€€ã‚’æ±‚ã‚ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®éš›ã«ã¯APã‚’æ¡ç”¨ã™ã‚‹ã®ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã‚‚ã—ãã¯ã€å¤–éƒ¨ã‚¨ãƒ©ãƒ¼ã«é–¢ã‚ã‚‰ãšã‚·ã‚¹ãƒ†ãƒ ãŒç¨¼åƒã™ã‚‹å¿…è¦ãŒã‚ã‚‹éš›ã«ã‚‚åŒæ§˜ã§ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸CAP ç†è«–ã‚’æŒ¯ã‚Šè¿”ã‚‹å¹³æ˜“ãªè‹±èªã§ã®CAP ç†è«–ã®ã‚¤ãƒ³ãƒˆãƒ­CAP FAQä¸€è²«æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³åŒã˜ãƒ‡ãƒ¼ã‚¿ã®è¤‡è£½ãŒè¤‡æ•°ã‚ã‚‹çŠ¶æ…‹ã§ã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒä¸€è²«ã—ãŸãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚’å—ã‘å–ã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ã«ãã‚Œã‚‰ã‚’åŒæœŸã™ã‚Œã°ã„ã„ã®ã‹ã¨ã„ã†èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ CAP ç†è«– ã«ãŠã‘ã‚‹ä¸€è²«æ€§ã®å®šç¾©ã‚’æ€ã„å‡ºã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚å…¨ã¦ã®èª­ã¿å–ã‚Šã¯æœ€æ–°ã®æ›¸ãè¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã‚’å—ã‘å–ã‚‹ã¯ãšã§ã™ã€‚å¼±ã„ä¸€è²«æ€§æ›¸ãè¾¼ã¿å¾Œã®èª­ã¿å–ã‚Šã§ã¯ã€ãã®æœ€æ–°ã®æ›¸ãè¾¼ã¿ã‚’èª­ã‚ãŸã‚Šèª­ã‚ãªã‹ã£ãŸã‚Šã™ã‚‹ã€‚ãƒ™ã‚¹ãƒˆã‚¨ãƒ•ã‚©ãƒ¼ãƒˆå‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«åŸºã¥ãã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯memcachedãªã©ã®ã‚·ã‚¹ãƒ†ãƒ ã«è¦‹ã‚‰ã‚Œã¾ã™ã€‚å¼±ã„ä¸€è²«æ€§ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒå¿…è¦ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã€ä¾‹ãˆã°VoIPã€ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ«ãƒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚²ãƒ¼ãƒ ãªã©ã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ä¾‹ãˆã°ã€é›»è©±ã«å‡ºã¦ã„ã‚‹ã¨ãã«æ•°ç§’é–“éŸ³å£°ãŒå—ã‘å–ã‚Œãªããªã£ãŸã¨ã—ãŸã‚‰ã€ãã®å¾Œã«æ¥ç¶šãŒå›å¾©ã—ã¦ã‚‚ãã®æ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¦ã„ãŸé–“ã«è©±ã•ã‚Œã¦ã„ãŸã“ã¨ã¯èãå–ã‚Œãªã„ã¨ã„ã†ã‚ˆã†ãªæ„Ÿã˜ã§ã™ã€‚çµæœæ•´åˆæ€§æ›¸ãè¾¼ã¿ã®å¾Œã€èª­ã¿å–ã‚Šã¯æœ€çµ‚çš„ã«ã¯ãã®çµæœã‚’èª­ã¿å–ã‚‹ã“ã¨ãŒã§ãã‚‹(ãƒŸãƒªç§’ã»ã©é…ã‚Œã¦ã¨ã„ã†ã®ãŒä¸€èˆ¬çš„ã§ã™)ã€‚ãƒ‡ãƒ¼ã‚¿ã¯éåŒæœŸçš„ã«è¤‡è£½ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯DNSã‚„ãƒ¡ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãªã©ã«æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚çµæœæ•´åˆæ€§ã¯å¤šãã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æŒãã‚µãƒ¼ãƒ“ã‚¹ã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚å¼·ã„ä¸€è²«æ€§æ›¸ãè¾¼ã¿ã®å¾Œã€èª­ã¿å–ã‚Šã¯ãã‚Œã‚’å¿…ãšèª­ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯åŒæœŸçš„ã«è¤‡è£½ã•ã‚Œã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚„RDBMSãªã©ã§æ¡ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ‰±ã†ã‚µãƒ¼ãƒ“ã‚¹ã§ã¯å¼·ã„ä¸€è²«æ€§ãŒå¿…è¦ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼é–“ã§ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¯ç”¨æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³é«˜ã„å¯ç”¨æ€§ã‚’æ‹…ä¿ã™ã‚‹ã«ã¯ä¸»ã«æ¬¡ã®äºŒã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã™: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ ã¨ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã§ã™ã€‚ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã«ãŠã„ã¦ã¯ã€å‘¨æœŸä¿¡å·ã¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚‚ã—ãã¯ã‚¹ã‚¿ãƒ³ãƒã‚¤ä¸­ã®ãƒ‘ãƒƒã‚·ãƒ–ãªã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œã¾ã™ã€‚å‘¨æœŸä¿¡å·ãŒä¸­æ–­ã•ã‚ŒãŸæ™‚ã«ã¯ã€ãƒ‘ãƒƒã‚·ãƒ–ã ã£ãŸã‚µãƒ¼ãƒãƒ¼ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒ¼ãƒãƒ¼ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å¼•ãç¶™ã„ã§ã‚µãƒ¼ãƒ“ã‚¹ã‚’å†é–‹ã—ã¾ã™ã€‚èµ·å‹•ã¾ã§ã®ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã¯ãƒ‘ãƒƒã‚·ãƒ–ã‚µãƒ¼ãƒãƒ¼ãŒã€Œãƒ›ãƒƒãƒˆã€ãªã‚¹ã‚¿ãƒ³ãƒã‚¤çŠ¶æ…‹ã«ã‚ã‚‹ã‹ã€ã€Œã‚³ãƒ¼ãƒ«ãƒ‰ã€ãªã‚¹ã‚¿ãƒ³ãƒã‚¤çŠ¶æ…‹ã«ã‚ã‚‹ã‹ã§å¤‰ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚µãƒ¼ãƒãƒ¼ã®ã¿ãŒãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ§‹æˆã§ã¯ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã“ã¨ã§è² è·ã‚’åˆ†æ•£ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒ‘ãƒ–ãƒªãƒƒã‚¯ãªã‚‚ã®ã®å ´åˆã€DNSã¯ä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ã®ãƒ‘ãƒ–ãƒªãƒƒã‚¯IPã‚’çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚‚ã—ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªã‚‚ã®ãªå ´åˆã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ãŒä¸¡æ–¹ã®ã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã«ã¤ã„ã¦çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¯ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚çŸ­æ‰€: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã§ã¯ã‚ˆã‚Šå¤šãã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’è¦ã—ã€è¤‡é›‘ã•ãŒå¢—ã—ã¾ã™ã€‚æœ€æ–°ã®æ›¸ãè¾¼ã¿ãŒãƒ‘ãƒƒã‚·ãƒ–ã‚µãƒ¼ãƒãƒ¼ã«è¤‡è£½ã•ã‚Œã‚‹å‰ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãŒè½ã¡ã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿æ¬ æãŒèµ·ãã‚‹æ½œåœ¨å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–ã€€ã¨ã€€ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã¯ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã‚ˆã‚Šè©³ç´°ã«è§£èª¬ã•ã‚Œã¦ã„ã¾ã™:ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ       Source: DNS security presentationãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚·ã‚¹ãƒ†ãƒ  (DNS) ã¯ www.example.com ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚’IPã‚¢ãƒ‰ãƒ¬ã‚¹ã¸ã¨ç¿»è¨³ã—ã¾ã™ã€‚DNSã¯å°‘æ•°ã®ã‚ªãƒ¼ã‚½ãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ãŒä¸Šä½ã«ä½ç½®ã™ã‚‹éšå±¤çš„æ§‹é€ ã§ã™ã€‚ã‚ãªãŸã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚‚ã—ãã¯ISPã¯æ¤œç´¢ã‚’ã™ã‚‹éš›ã«ã©ã®DNSã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã‹ã¨ã„ã†æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚ä½ã„éšå±¤ã®DNSã‚µãƒ¼ãƒãƒ¼ã¯ãã®çµŒè·¯ãƒãƒƒãƒ—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚ãŸã ã€ã“ã®æƒ…å ±ã¯ä¼æ¬é…å»¶ã«ã‚ˆã£ã¦é™³è…åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚DNSã®çµæœã¯ã‚ãªãŸã®ãƒ–ãƒ©ã‚¦ã‚¶ã‚‚ã—ãã¯OSã«ä¸€å®šæœŸé–“ï¼ˆtime to live (TTL)ã«è¨­å®šã•ã‚ŒãŸæœŸé–“ï¼‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ã€‚NS record (name server) - ã‚ãªãŸã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®DNSã‚µãƒ¼ãƒãƒ¼ã‚’ç‰¹å®šã—ã¾ã™ã€‚MX record (mail exchange) - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚µãƒ¼ãƒãƒ¼ã‚’ç‰¹å®šã—ã¾ã™ã€‚A record (address) - IPã‚¢ãƒ‰ãƒ¬ã‚¹ã«åå‰ã‚’ã¤ã‘ã¾ã™ã€‚CNAME (canonical) - ä»–ã®åå‰ã‚‚ã—ãã¯ã€€CNAME (example.com ã‚’ www.example.com) ã‚‚ã—ãã¯ A recordã¸ã¨åå‰ã‚’æŒ‡ã—ç¤ºã™ã€‚CloudFlare ã‚„ Route 53 ãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒãƒãƒ¼ã‚¸ãƒ‰DNSã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã„ãã¤ã‹ã®DNSã‚µãƒ¼ãƒ“ã‚¹ã§ã¯æ§˜ã€…ãªæ‰‹æ³•ã‚’ä½¿ã£ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã“ã¨ãŒã§ãã¾ã™:åŠ é‡ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã®ã‚µãƒ¼ãƒãƒ¼ã«è¡Œãã®ã‚’é˜²ãã¾ã™æ§˜ã€…ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚µã‚¤ã‚ºã«å¿œã˜ã¦èª¿æ•´ã—ã¾ã™A/B ãƒ†ã‚¹ãƒˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãƒ™ãƒ¼ã‚¹åœ°ç†ãƒ™ãƒ¼ã‚¹æ¬ ç‚¹: DNSä¸Šè¨˜ã§ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã«ã‚ˆã£ã¦ç·©å’Œã•ã‚Œã¦ã„ã‚‹ã¨ã¯ã„ãˆã€DNSã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã«ã¯å°‘ã—é…å»¶ãŒç”Ÿã˜ã‚‹ã€‚DNSã‚µãƒ¼ãƒãƒ¼ã¯ã€æ”¿åºœã€ISPä¼æ¥­,ãã—ã¦å¤§ä¼æ¥­ã«ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãŒã€ãã‚Œã‚‰ã®ç®¡ç†ã¯è¤‡é›‘ã§ã‚ã‚‹ã€‚DNSã‚µãƒ¼ãƒ“ã‚¹ã¯DDoS attackã®ä¾‹ã§ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ãªã—ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒTwitterãªã©ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªããªã£ãŸã‚ˆã†ã«ã€æ”»æ’ƒã‚’å—ã‘ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸DNS ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£WikipediaDNS è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(Content delivery network)      Source: Why use a CDNã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯(CDN)ã¯ä¸–ç•Œä¸­ã«é…ç½®ã•ã‚ŒãŸãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¸€ç•ªåœ°ç†çš„ã«è¿‘ã„ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é…ä¿¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®ã“ã¨ã§ã™ã€‚Amazonã®CloudFrontãªã©ã¯ä¾‹å¤–çš„ã«ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚é…ä¿¡ã—ã¾ã™ãŒã€ä¸€èˆ¬çš„ã«ã€HTML/CSS/JSã€å†™çœŸã€ãã—ã¦å‹•ç”»ãªã©ã®é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ãŒCDNã‚’é€šã˜ã¦é…ä¿¡ã•ã‚Œã¾ã™ã€‚ãã®ã‚µã‚¤ãƒˆã®DNSãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã©ã®ã‚µãƒ¼ãƒãƒ¼ã¨äº¤ä¿¡ã™ã‚‹ã‹ã¨ã„ã†æƒ…å ±ã‚’ä¼ãˆã¾ã™ã€‚CDNã‚’ç”¨ã„ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é…ä¿¡ã™ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®äºŒã¤ã®ç†ç”±ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒåŠ‡çš„ã«å‘ä¸Šã—ã¾ã™:ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è¿‘ãã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰å—ä¿¡ã§ãã‚‹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã¯CDNãŒå‡¦ç†ã—ã¦ãã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«é–¢ã—ã¦ã¯å‡¦ç†ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ãƒ—ãƒƒã‚·ãƒ¥CDNãƒ—ãƒƒã‚·ãƒ¥CDNã§ã¯ã‚µãƒ¼ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ã«æ›´æ–°ãŒã‚ã£ãŸæ™‚ã«ã¯å¿…ãšã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å—ã‘å–ã‚‹æ–¹å¼ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”¨æ„ã—ã€CDNã«ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€URLã‚’CDNã‚’æŒ‡ã™ã‚ˆã†ã«æŒ‡å®šã™ã‚‹ã¨ã“ã‚ã¾ã§ã€å…¨ã¦è‡ªåˆ†ã§è²¬ä»»ã‚’è² ã†å½¢ã§ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã„ã¤æœŸé™åˆ‡ã‚Œã«ãªã‚‹ã®ã‹æ›´æ–°ã•ã‚Œã‚‹ã®ã‹ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯æ–°è¦ä½œæˆæ™‚ã€æ›´æ–°æ™‚ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã“ã¨ã§ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã¯æœ€å°åŒ–ã•ã‚Œã‚‹ä¸€æ–¹ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¯æœ€å¤§é™æ¶ˆè²»ã•ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å°‘ãªã„ã€ã‚‚ã—ãã¯é »ç¹ã«ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ›´æ–°ã•ã‚Œãªã„ã‚µã‚¤ãƒˆã®å ´åˆã«ã¯ãƒ—ãƒƒã‚·ãƒ¥CDNã¨ç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å®šæœŸçš„ã«å†ã³ãƒ—ãƒ«ã•ã‚Œã‚‹ã®ã§ã¯ãªãã€CDNã«ä¸€åº¦ã®ã¿é…ç½®ã•ã‚Œã¾ã™ã€‚ãƒ—ãƒ«CDNãƒ—ãƒ«CDNã§ã¯ä¸€äººç›®ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãŸæ™‚ã«ã€æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å–å¾—ã—ã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯è‡ªåˆ†ã®ã‚µãƒ¼ãƒãƒ¼ã«ä¿å­˜ã—ã¦ã€CDNã‚’æŒ‡ã™URLã‚’æ›¸ãæ›ãˆã¾ã™ã€‚çµæœã¨ã—ã¦ã€CDNã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã¾ã§ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ãŒé…ããªã‚Šã¾ã™ã€‚time-to-live (TTL) ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã©ã‚Œã ã‘ã®æœŸé–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã‹ã‚’è¦å®šã—ã¾ã™ã€‚ãƒ—ãƒ«CDNã¯CDN ä¸Šã§ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¹ãƒšãƒ¼ã‚¹ã‚’æœ€å°åŒ–ã—ã¾ã™ãŒã€æœ‰åŠ¹æœŸé™ãŒåˆ‡ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›´æ–°å‰ã«ãƒ—ãƒ«ã•ã‚Œã¦ã—ã¾ã†ã“ã¨ã§å†—é•·ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«ç¹‹ãŒã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å¤§è¦æ¨¡ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ã‚ã‚‹ã‚µã‚¤ãƒˆã§ã¯ãƒ—ãƒ«CDNãŒç›¸æ€§ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ã¨ã„ã†ã®ã‚‚ã€ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å¤§éƒ¨åˆ†ã¯æœ€è¿‘ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚Œã€CDNã«æ®‹ã£ã¦ã„ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã‹ã‚‰ã§ã™ã€‚æ¬ ç‚¹: CDNCDNã®ã‚³ã‚¹ãƒˆã¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯é‡ã«ã‚ˆã£ã¦å¤‰ã‚ã‚Šã¾ã™ã€‚ã‚‚ã¡ã‚ã‚“ã€CDNã‚’ä½¿ã‚ãªã„å ´åˆã®ã‚³ã‚¹ãƒˆã¨æ¯”è¼ƒã™ã‚‹ã¹ãã§ã—ã‚‡ã†ã€‚TTLãŒåˆ‡ã‚Œã‚‹å‰ã«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ›´æ–°ã•ã‚Œã‚‹ã¨é™³è…åŒ–ã™ã‚‹æã‚ŒãŒã‚ã‚Šã¾ã™ã€‚CDNã§ã¯é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒCDNã‚’æŒ‡ã™ã‚ˆã†ã«URLã‚’æ›´æ–°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«åˆ†æ•£ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ—ãƒƒã‚·ãƒ¥CDNã¨ãƒ—ãƒ«CDNã®é•ã„Wikipediaãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼      Source: Scalable system design patternsãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯å…¥åŠ›ã•ã‚Œã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã¨åˆ†æ•£ã•ã›ã‚‹ã€‚ã©ã®ã‚±ãƒ¼ã‚¹ã§ã‚‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ã‚µãƒ¼ãƒãƒ¼ç­‰è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é©åˆ‡ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è¿”ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ä»¥ä¸‹ã®ã“ã¨ã«åŠ¹æœçš„ã§ã™:ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒçŠ¶æ…‹ã®è‰¯ããªã„ã‚µãƒ¼ãƒãƒ¼ã«è¡Œãã®ã‚’é˜²ããƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’éå‰°ã«é€ã‚‹ã®ã‚’é˜²ãç‰¹å®šç®‡æ‰€ã®æ¬ é™¥ã§ã‚µãƒ¼ãƒ“ã‚¹ãŒè½ã¡ã‚‹ã“ã¨ã‚’é˜²ããƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ (è²»ç”¨ã®é«˜ã„) ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚‚ã—ãã¯HAProxyãªã©ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã§å®Ÿç¾ã§ãã‚‹ã€‚ä»–ã®åˆ©ç‚¹ã¨ã—ã¦ã¯:SSL termination - å…¥åŠ›ã•ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£èª­ã™ã‚‹ã€ã¾ãŸã€ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æš—å·åŒ–ã™ã‚‹ã“ã¨ã§ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã‚µãƒ¼ãƒãƒ¼ãŒã“ã®ã‚³ã‚¹ãƒˆãŒé«˜ãã¤ããŒã¡ãªå‡¦ç†ã‚’è«‹ã‘è² ã‚ãªãã¦ã„ã„ã‚ˆã†ã«è‚©ä»£ã‚ã‚Šã—ã¾ã™ã€‚X.509 certificates ã‚’ãã‚Œãã‚Œã®ã‚µãƒ¼ãƒãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ã‚’ãªãã—ã¾ã™ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† - ã‚¯ãƒƒã‚­ãƒ¼ã‚’å–ã‚Šæ‰±ã†ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªãŒã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ãªã„æ™‚ãªã©ã«ã€ç‰¹å®šã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åŒã˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¸ã¨æµã—ã¾ã™ã€‚éšœå®³ã«å¯¾å¿œã™ã‚‹ãŸã‚ã«ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‘ãƒƒã‚·ãƒ– ã‚‚ã—ãã¯ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¯ãƒ†ã‚£ãƒ– ãƒ¢ãƒ¼ãƒ‰ã®ã©ã¡ã‚‰ã«ãŠã„ã¦ã‚‚ã€è¤‡æ•°ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’é…ç½®ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªç¨®ã€…ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç”¨ã„ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™:ãƒ©ãƒ³ãƒ€ãƒ Least loadedã‚»ãƒƒã‚·ãƒ§ãƒ³/ã‚¯ãƒƒã‚­ãƒ¼ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ã‚‚ã—ãã¯åŠ é‡ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³Layer 4Layer 7Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ ã‚’å‚ç…§ã—ã¦ã©ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é…åˆ†ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ã—ã¦ã¯ã€ã‚½ãƒ¼ã‚¹ã€é€ä¿¡å…ˆIPã‚¢ãƒ‰ãƒ¬ã‚¹ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã«è¨˜è¿°ã•ã‚ŒãŸãƒãƒ¼ãƒˆç•ªå·ãŒå«ã¾ã‚Œã¾ã™ãŒã€ãƒ‘ã‚±ãƒƒãƒˆã®ä¸­èº«ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å«ã¿ã¾ã›ã‚“ã€‚ Layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‘ã‚±ãƒƒãƒˆã‚’ä¸Šæµã‚µãƒ¼ãƒãƒ¼ã¸å±Šã‘ã€ä¸Šæµã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰é…ä¿¡ã™ã‚‹ã“ã¨ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ‰ãƒ¬ã‚¹å¤‰æ› Network Address Translation (NAT) ã‚’å®Ÿç¾ã—ã¾ã™ã€‚Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ ã‚’å‚ç…§ã—ã¦ã©ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é…åˆ†ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ã‚¯ãƒƒã‚­ãƒ¼ãªã©ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã“ã¨ã§ã™ã€‚Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®çµ‚ç«¯ã‚’å—ã‘æŒã¡ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã®åˆ¤æ–­ã‚’ã—ã€é¸æŠã—ãŸã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šã‚’ç¹‹ãã¾ã™ã€‚ä¾‹ãˆã° layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯å‹•ç”»ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ç›´æ¥ã€ãã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ›ã‚¹ãƒˆã—ã¦ã„ã‚‹ã‚µãƒ¼ãƒãƒ¼ã«ã¤ãªãã¨åŒæ™‚ã«ã€æ±ºæ¸ˆå‡¦ç†ãªã©ã®ã‚ˆã‚Šç¹Šç´°ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ã«æµã™ã¨ã„ã†ã“ã¨ã‚‚ã§ãã‚‹ã€‚æŸ”è»Ÿæ€§ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãªã‚Šã¾ã™ãŒã€ layer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ã¯Layer 7ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚ˆã‚Šã‚‚æ‰€è¦æ™‚é–“ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å°‘ãªãæ¸ˆã¾ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãŸã ã—ã€æ˜¨ä»Šã®æ±ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯æœ€å°é™ã®ã¿ã—ã‹ç™ºæ®ã§ããªã„ã§ã—ã‚‡ã†ã€‚æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ã¯æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å¯ç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ‰‹é ƒãªæ±ç”¨ãƒã‚·ãƒ³ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã•ã›ã‚‹æ–¹ãŒã€ä¸€ã¤ã®ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚ˆã‚Šé«˜ä¾¡ãªãƒã‚·ãƒ³ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ï¼ˆå‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã‚ˆã‚Šè²»ç”¨å¯¾åŠ¹æœã‚‚é«˜ããªã‚Šã€çµæœçš„ã«å¯ç”¨æ€§ã‚‚é«˜ããªã‚Šã¾ã™ã€‚ã¾ãŸã€æ±ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ‰±ãˆã‚‹äººæã‚’é›‡ã†æ–¹ãŒã€ç‰¹åŒ–å‹ã®å•†ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’æ‰±ãˆã‚‹äººæã‚’é›‡ã†ã‚ˆã‚Šã‚‚ç°¡å˜ã§ã—ã‚‡ã†ã€‚æ¬ ç‚¹: æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ°´å¹³çš„ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã„ãã¨ã€è¤‡é›‘ã•ãŒå¢—ã™ä¸Šã«ã€ã‚µãƒ¼ãƒãƒ¼ã®ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã«ãªã‚‹ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢é€£ã™ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚„ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å†™çœŸãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã¯ã„ã‘ãªã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ä¸€å…ƒçš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (SQLã€ NoSQL)ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã«ã‚¹ãƒˆã‚¢ã•ã‚Œã‚‹ã‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ (Redisã€ Memcached)ã«æ®‹ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®ä¸‹æµã‚µãƒ¼ãƒãƒ¼ã¯ä¸Šæµã‚µãƒ¼ãƒãƒ¼ãŒã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã™ã‚‹ã«ã¤ã‚Œã¦ã‚ˆã‚Šå¤šãã®åŒæ™‚æ¥ç¶šã‚’ä¿ãŸãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚æ¬ ç‚¹: ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯ãƒªã‚½ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ãŸã‚Šã€è¨­å®šãŒé©åˆ‡ã§ãªã„å ´åˆã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å˜ä¸€éšœå®³ç‚¹ã‚’é™¤ã“ã†ã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’å°å…¥ã—ãŸçµæœã€è¤‡é›‘ã•ãŒå¢—ã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãŒä¸€ã¤ã ã‘ã ã¨ãã“ãŒå˜ä¸€éšœå®³ç‚¹ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚ä¸€æ–¹ã§ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’è¤‡æ•°ã«ã™ã‚‹ã¨ã€ã•ã‚‰ã«è¤‡é›‘ã•ãŒå¢—ã—ã¦ã—ã¾ã„ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸NGINX ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HAProxy ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¬ã‚¤ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£WikipediaLayer 4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°Layer 7 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ELB listener configãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·(webã‚µãƒ¼ãƒãƒ¼)      Source: Wikipedia  ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼ã¯å†…éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã¾ã¨ã‚ã¦å¤–éƒ¨ã«çµ±ä¸€ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ãã‚Œã«å¯¾å¿œã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ã«é€ã‚‰ã‚Œã¦ã€ãã®å¾Œãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è¿”ã—ã¾ã™ã€‚ä»–ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªåˆ©ç‚¹ãŒã‚ã‚Šã¾ã™:ã‚ˆã‚Šå …ç‰¢ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã®æƒ…å ±ã‚’éš ã—ãŸã‚Šã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆåŒ–ã—ãŸã‚Šã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã”ã¨ã®æ¥ç¶šæ•°ã‚’åˆ¶é™ã—ãŸã‚Šã§ãã¾ã™ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚„æŸ”è»Ÿæ€§ãŒå¢—ã—ã¾ã™ - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã®IPã—ã‹è¦‹ãªã„ã®ã§ã€è£ã§ã‚µãƒ¼ãƒãƒ¼ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã—ãŸã‚Šã€è¨­å®šã‚’å¤‰ãˆã‚„ã™ããªã‚Šã¾ã™ã€‚SSL termination - å…¥åŠ›ã•ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£èª­ã—ã€ã‚µãƒ¼ãƒãƒ¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æš—å·åŒ–ã™ã‚‹ã“ã¨ã§ã‚µãƒ¼ãƒãƒ¼ãŒã“ã®ã‚³ã‚¹ãƒˆã®ã‹ã‹ã‚Šã†ã‚‹å‡¦ç†ã‚’ã—ãªãã¦æ¸ˆã‚€ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚X.509 è¨¼æ˜æ›¸ ã‚’å„ã‚µãƒ¼ãƒãƒ¼ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚åœ§ç¸® - ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åœ§ç¸®ã§ãã¾ã™ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚° - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã—ã¾ã™é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ - é™çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥é€ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚HTML/CSS/JSå†™çœŸå‹•ç”»ãªã©ãªã©ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ vs ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·è¤‡æ•°ã®ã‚µãƒ¼ãƒãƒ¼ãŒã‚ã‚‹æ™‚ã«ã¯ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨å½¹ã«ç«‹ã¤ã§ã—ã‚‡ã†ã€‚ ã—ã°ã—ã°ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯åŒã˜æ©Ÿèƒ½ã‚’æœãŸã™ã‚µãƒ¼ãƒãƒ¼ç¾¤ã¸ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æŒãã¾ã™ã€‚ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã§ã¯ã€ä¸Šè¨˜ã«è¿°ã¹ãŸã‚ˆã†ãªåˆ©ç‚¹ã‚’ã€å˜ä¸€ã®ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã‚„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å¯¾ã—ã¦ã‚‚ç¤ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚NGINX ã‚„ HAProxy ãªã©ã®æŠ€è¡“ã¯layer 7 ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚æ¬ ç‚¹: ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’å°å…¥ã™ã‚‹ã¨ã‚·ã‚¹ãƒ†ãƒ ã®è¤‡é›‘æ€§ãŒå¢—ã—ã¾ã™ã€‚å˜ä¸€ã®ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã¯å˜ä¸€éšœå®³ç‚¹ã«ãªã‚Šãˆã¾ã™ã€‚ä¸€æ–¹ã§ã€è¤‡æ•°ã®ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·ã‚’å°å…¥ã™ã‚‹ã¨(ä¾‹: ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼) è¤‡é›‘æ€§ã¯ã‚ˆã‚Šå¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· vs ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼NGINX ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HAProxy ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ ã‚¬ã‚¤ãƒ‰Wikipediaã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤      Source: Intro to architecting systems for scaleã‚¦ã‚§ãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ (ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å±¤ã¨ã‚‚è¨€ã‚ã‚Œã‚‹) ã¨åˆ†é›¢ã™ã‚‹ã“ã¨ã§ãã‚Œãã‚Œã®å±¤ã‚’ç‹¬ç«‹ã«ã‚¹ã‚±ãƒ¼ãƒ«ã€è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚æ–°ã—ã„APIã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã«è¿½åŠ ã™ã‚‹éš›ã«ã€ä¸å¿…è¦ã«ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã™ã€‚å˜ä¸€è²¬ä»»ã®åŸå‰‡ ã§ã¯ã€å°ã•ã„è‡ªå¾‹çš„ãªã‚µãƒ¼ãƒ“ã‚¹ãŒå”èª¿ã—ã¦å‹•ãã‚ˆã†ã«æå”±ã—ã¦ã„ã¾ã™ã€‚å°ã•ã„ã‚µãƒ¼ãƒ“ã‚¹ã®å°ã•ã„ãƒãƒ¼ãƒ ãŒæ€¥æˆé•·ã®ãŸã‚ã«ã‚ˆã‚Šç©æ¥µçš„ãªè¨ˆç”»ã‚’ç«‹ã¦ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã¯éåŒæœŸå‡¦ç†ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ç‹¬ç«‹ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹ã€å°è¦æ¨¡ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§˜å¼ã§ã‚ã‚‹ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚‚ã“ã®è­°è«–ã«é–¢ä¿‚ã—ã¦ãã‚‹æŠ€è¡“ã§ã—ã‚‡ã†ã€‚ãã‚Œãã‚Œã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ç‹¬è‡ªã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å‡¦ç†ã—ã€æ˜ç¢ºã§è»½é‡ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§é€šä¿¡ã—ã¦ã€ãã®ç›®çš„ã¨ã™ã‚‹æ©Ÿèƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚1ä¾‹ãˆã°Pinterestã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã€ãƒ•ã‚£ãƒ¼ãƒ‰ã€æ¤œç´¢ã€å†™çœŸã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãªã©ã§ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼Consulã€ Etcdã€ Zookeeper ãªã©ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®åå‰ã€ã‚¢ãƒ‰ãƒ¬ã‚¹ã€ãƒãƒ¼ãƒˆã®æƒ…å ±ã‚’ç›£è¦–ã™ã‚‹ã“ã¨ã§ã€ã‚µãƒ¼ãƒ“ã‚¹åŒå£«ãŒäº’ã„ã‚’è¦‹ã¤ã‘ã‚„ã™ãã—ã¦ã„ã¾ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹ã®å®Œå…¨æ€§ã®ç¢ºèªã«ã¯ Health checks ãŒä¾¿åˆ©ã§ã€ã“ã‚Œã«ã¯ HTTP ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚ Consul ã¨ Etcd ã®ã„ãšã‚Œã‚‚çµ„ã¿è¾¼ã¿ã® key-value store ã‚’æŒã£ã¦ãŠã‚Šã€è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚„å…±æœ‰ãƒ‡ãƒ¼ã‚¿ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¦ãŠãã“ã¨ã«ä½¿ã‚ã‚Œã¾ã™ã€‚æ¬ ç‚¹: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€é‹ç”¨ã€ãã—ã¦ãƒ—ãƒ­ã‚»ã‚¹ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ç·©ãçµã³ä»˜ã‘ã‚‰ã‚ŒãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã‚’è¿½åŠ ã™ã‚‹ã«ã¯ã€ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒ‡ãƒ—ãƒ­ã‚¤ã¨é‹ç”¨ã®ç‚¹ã‹ã‚‰è¦‹ã‚‹ã¨è¤‡é›‘æ€§ãŒå¢—ã™ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒˆãƒ­ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’ç´è§£ãã‚µãƒ¼ãƒ“ã‚¹æŒ‡å‘ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Zookeeperã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½œã‚‹ãŸã‚ã«çŸ¥ã£ã¦ãŠããŸã„ã“ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹      Source: Scaling up to your first 10 million usersãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (RDBMS)SQLãªã©ã®ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ•´ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®é›†åˆã§ã‚ã‚‹ã€‚ACID ã¯ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãŠã‘ã‚‹ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®é›†åˆã§ã‚ã‚‹ä¸å¯åˆ†æ€§ - ãã‚Œãã‚Œã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ã‚‹ã‹ãªã„ã‹ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹ä¸€è²«æ€§ - ã©ã‚“ãªãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚ã‚‹ç¢ºã‹ãªçŠ¶æ…‹ã‹ã‚‰æ¬¡ã®çŠ¶æ…‹ã«é·ç§»ã•ã›ã‚‹ã€‚ç‹¬ç«‹æ€§ - åŒæ™‚ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ã¯ã€é€£ç¶šçš„ã«ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã™ã‚‹ã®ã¨åŒã˜çµæœã‚’ã‚‚ãŸã‚‰ã™ã€‚æ°¸ç¶šæ€§ - ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãŒå‡¦ç†ã•ã‚ŒãŸã‚‰ã€ãã®ã‚ˆã†ã«ä¿å­˜ã•ã‚Œã‚‹ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ãŸã‚ã«ã¯ãŸãã•ã‚“ã®æŠ€è¡“ãŒã‚ã‚‹: ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ federationã€ ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ éæ­£è¦åŒ–ã€ ãã—ã¦ SQL ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒèª­ã¿å–ã‚Šã¨æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã—ã€æ›¸ãè¾¼ã¿ã‚’ä¸€ã¤ä»¥ä¸Šã®ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¤‡è£½ã—ã¾ã™ã€‚ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯èª­ã¿å–ã‚Šã®ã¿ã‚’å‡¦ç†ã—ã¾ã™ã€‚ã‚¹ãƒ¬ãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æœ¨æ§‹é€ ã®ã‚ˆã†ã«è¿½åŠ ã®ã‚¹ãƒ¬ãƒ¼ãƒ–ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã«ãªã£ãŸå ´åˆã«ã¯ã€ã„ãšã‚Œã‹ã®ã‚¹ãƒ¬ãƒ¼ãƒ–ãŒãƒã‚¹ã‚¿ãƒ¼ã«æ˜‡æ ¼ã™ã‚‹ã‹ã€æ–°ã—ã„ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚Œã‚‹ã¾ã§ã¯èª­ã¿å–ã‚Šå°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ã§ç¨¼åƒã—ã¾ã™ã€‚      Source: Scalability, availability, stability, patternsæ¬ ç‚¹: ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ãƒ¬ãƒ¼ãƒ–ã‚’ãƒã‚¹ã‚¿ãƒ¼ã«æ˜‡æ ¼ã•ã›ã‚‹ã«ã¯è¿½åŠ ã®ãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…è¦ã«ãªã‚‹ã€‚ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® ä¸¡æ–¹ ã®æ¬ ç‚¹ã¯æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã„ãšã‚Œã®ãƒã‚¹ã‚¿ãƒ¼ã‚‚èª­ã¿å–ã‚Šæ›¸ãè¾¼ã¿ã®ä¸¡æ–¹ã«å¯¾å¿œã™ã‚‹ã€‚æ›¸ãè¾¼ã¿ã«é–¢ã—ã¦ã¯ãã‚Œãã‚Œå”èª¿ã™ã‚‹ã€‚ã„ãšã‚Œã‹ã®ãƒã‚¹ã‚¿ãƒ¼ãŒè½ã¡ã¦ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¨ã—ã¦ã¯èª­ã¿æ›¸ãä¸¡æ–¹ã«å¯¾å¿œã—ãŸã¾ã¾é‹ç”¨ã§ãã‚‹ã€‚      Source: Scalability, availability, stability, patternsæ¬ ç‚¹: ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’å°å…¥ã™ã‚‹ã‹ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã©ã“ã«æ›¸ãè¾¼ã‚€ã‹ã‚’æŒ‡å®šã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚å¤§ä½“ã®ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä¸€è²«æ€§ãŒç·©ã„ï¼ˆACIDåŸç†ã‚’å®ˆã£ã¦ã„ãªã„ï¼‰ã‚‚ã—ãã¯ã€åŒæœŸã™ã‚‹æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã«æ›¸ãè¾¼ã¿ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã€‚æ›¸ãè¾¼ã¿ãƒãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚Œã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œæ›¸ãè¾¼ã¿ã®è¡çªã®å¯èƒ½æ€§ãŒå¢—ãˆã‚‹ã€‚ãƒã‚¹ã‚¿ãƒ¼ã‚¹ãƒ¬ãƒ¼ãƒ– ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã® ä¸¡æ–¹ ã®æ¬ ç‚¹ã¯æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ã‚’å‚ç…§æ¬ ç‚¹: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚’è¤‡è£½ã™ã‚‹å‰ã«ãƒã‚¹ã‚¿ãƒ¼ãŒè½ã¡ãŸå ´åˆã«ã¯ãã®ãƒ‡ãƒ¼ã‚¿ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æ›¸ãè¾¼ã¿ã¯èª­ã¿å–ã‚Šãƒ¬ãƒ—ãƒªã‚«ã«ãŠã„ã¦ãƒªãƒ—ãƒ¬ã‚¤ã•ã‚Œã‚‹ã€‚æ›¸ãè¾¼ã¿ãŒå¤šã„å ´åˆã€è¤‡è£½ãƒãƒ¼ãƒ‰ãŒæ›¸ãè¾¼ã¿ã®å‡¦ç†ã®ã¿ã§è¡Œãè©°ã¾ã£ã¦ã€èª­ã¿å–ã‚Šã®å‡¦ç†ã‚’æº€è¶³ã«è¡Œãˆãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚èª­ã¿å–ã‚Šã‚¹ãƒ¬ãƒ¼ãƒ–ãƒãƒ¼ãƒ‰ã®æ•°ãŒå¤šã‘ã‚Œã°å¤šã„ã»ã©ã€è¤‡è£½ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„æ•°ã‚‚å¢—ãˆã€è¤‡è£½æ™‚é–“ãŒä¼¸ã³ã¦ã—ã¾ã„ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã£ã¦ã¯ã€ãƒã‚¹ã‚¿ãƒ¼ã¸ã®æ›¸ãè¾¼ã¿ã¯ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§ä¸¦åˆ—å‡¦ç†ã§ãã‚‹ä¸€æ–¹ã€ã‚¹ãƒ¬ãƒ¼ãƒ–ã¸ã®è¤‡è£½ã¯å˜ä¸€ã‚¹ãƒ¬ãƒƒãƒ‰ã§é€£ç¶šçš„ã«å‡¦ç†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€ å¯ç”¨æ€§ã€ ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£ ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒ«ãƒãƒã‚¹ã‚¿ãƒ¼ ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³Federation      Source: Scaling up to your first 10 million usersãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (ã‚‚ã—ãã¯æ©Ÿèƒ½åˆ†å‰²åŒ–ã¨ã‚‚è¨€ã†) ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ©Ÿèƒ½ã”ã¨ã«åˆ†å‰²ã™ã‚‹ã€‚ä¾‹ãˆã°ã€ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªå˜ä¸€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä»£ã‚ã‚Šã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã€ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ ã®ã‚ˆã†ã«ä¸‰ã¤ã«ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸€ã¤ã‚ãŸã‚Šã®æ›¸ãè¾¼ã¿ãƒ»èª­ã¿å–ã‚Šã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒæ¸›ã‚Šã€ãã®çµæœãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ©ã‚°ã‚‚çŸ­ããªã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå°ã•ããªã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã«åã¾ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒå¢—ãˆã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å±€æ‰€æ€§ãŒé«˜ã¾ã‚‹ãŸã‚ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã‚‚ä¸ŠãŒã‚Šã¾ã™ã€‚å˜ä¸€ã®ä¸­å¤®ãƒã‚¹ã‚¿ãƒ¼ã§æ›¸ãè¾¼ã¿ã‚’ç›´åˆ—åŒ–ã—ãŸã‚Šã—ãªã„ãŸã‚ã€ä¸¦åˆ—ã§æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚æ¬ ç‚¹: federationå¤§è¦æ¨¡ãªå‡¦ç†ã‚„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¦ã™ã‚‹ã‚¹ã‚­ãƒ¼ãƒã®å ´åˆã€ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯åŠ¹æœçš„ã¨ã¯è¨€ãˆãªã„ã§ã—ã‚‡ã†ã€‚ã©ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«èª­ã¿æ›¸ãã‚’ã™ã‚‹ã®ã‹ã‚’æŒ‡å®šã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ›´æ–°ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚server linkã§äºŒã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€£çµã™ã‚‹ã®ã¯ã‚ˆã‚Šè¤‡é›‘ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: federationScaling up to your first 10 million usersã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°      Source: Scalability, availability, stability, patternsã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãã‚Œãã‚ŒãŒãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ–ã‚»ãƒƒãƒˆæ–­ç‰‡ã®ã¿ã‚’æŒã¤ã‚ˆã†ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¾‹ã«ã¨ã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«ã¯ã‚ˆã‚Šå¤šãã®æ–­ç‰‡ãŒåŠ ãˆã‚‰ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚federationã®åˆ©ç‚¹ã«ä¼¼ã¦ã„ã¦ã€ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯èª­ã¿æ›¸ãã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’æ¸›ã‚‰ã—ã€ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¸›ã‚‰ã—ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆã‚’å¢—ã‚„ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚‚æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™ã¨ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã‚¯ã‚¨ãƒªé€Ÿåº¦ãŒé€Ÿããªã‚Šã¾ã™ã€‚ãªã«ãŒã—ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡è£½ã™ã‚‹æ©Ÿèƒ½ãŒãªã‘ã‚Œã°ãƒ‡ãƒ¼ã‚¿ãƒ­ã‚¹ã«ã¤ãªãŒã‚Šã¾ã™ãŒã€ã‚‚ã—ã€ä¸€ã¤ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒè½ã¡ã¦ã‚‚ã€ä»–ã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒå‹•ã„ã¦ã„ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜ãã€å˜ä¸€ã®ä¸­å¤®ãƒã‚¹ã‚¿ãƒ¼ãŒæ›¸ãè¾¼ã¿ã®å‡¦ç†ã‚’ã—ãªãã¦ã‚‚ã€ä¸¦åˆ—ã§æ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ä¸€èˆ¬çš„ãªæ–¹æ³•ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ©ã‚¹ãƒˆãƒãƒ¼ãƒ ã‚¤ãƒ‹ã‚·ãƒ£ãƒ«ã§ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åœ°ç†çš„é…ç½®ã§ã‚·ãƒ£ãƒ¼ãƒ‰ã™ã‚‹ãªã©ã§ã™ã€‚æ¬ ç‚¹: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒ£ãƒ¼ãƒ‰ã«å¯¾å¿œã™ã‚‹ã‚ˆã†ã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¤‰æ›´ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚çµæœã¨ã—ã¦SQLã‚¯ã‚¨ãƒªãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ‰ã§ã¯ãƒ‡ãƒ¼ã‚¿é…åˆ†ãŒã„ã³ã¤ã«ãªã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€æ¨™æº–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é›†åˆã‚’æŒã¤ã‚·ãƒ£ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã€ãã®ã‚·ãƒ£ãƒ¼ãƒ‰ãŒä»–ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‚ˆã‚Šã‚‚é‡ã„è² è·ã‚’è² ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒªãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã‚’ã™ã‚‹ã¨è¤‡é›‘æ€§ãŒã‚ˆã‚Šå¢—ã—ã¾ã™ã€‚consistent hashing ã«åŸºã¥ã„ãŸã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ã€é€šä¿¡ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚è¤‡æ•°ã®ã‚·ãƒ£ãƒ¼ãƒ‰ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€£çµã™ã‚‹ã®ã¯ã‚ˆã‚Šè¤‡é›‘ã§ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯è¿½åŠ ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãŒå¿…è¦ã«ãªã‚Šã€è¤‡é›‘æ€§ã‚‚å¢—ã—ã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ãƒ£ãƒ¼ãƒ‰ã®ç™»å ´ã‚·ãƒ£ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Consistent hashingéæ­£è¦åŒ–éæ­£è¦åŒ–ã§ã¯ã€æ›¸ãè¾¼ã¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã„ãã‚‰ã‹çŠ ç‰²ã«ã—ã¦èª­ã¿è¾¼ã¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚ˆã†ã¨ã—ã¾ã™ã€‚è¨ˆç®—çš„ã«é‡ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµåˆãªã©ã‚’ã›ãšã«ã€è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«å†—é•·ãªãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ãŒæ›¸ãè¾¼ã¾ã‚Œã‚‹ã®ã‚’è¨±å®¹ã—ã¾ã™ã€‚ã„ãã¤ã‹ã®RDBMSä¾‹ãˆã°ã€PostgreSQL ã‚„Oracleã¯ã“ã®å†—é•·ãªæƒ…å ±ã‚’å–ã‚Šæ‰±ã„ã€ä¸€è²«æ€§ã‚’ä¿ã¤ãŸã‚ã®materialized views ã¨ã„ã†æ©Ÿèƒ½ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãƒ•ã‚§ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ã‚„ ã‚·ãƒ£ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã«ã‚ˆã£ã¦ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã«åˆ†é…ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’åˆä¸€ã•ã›ã‚‹ã“ã¨ã¯ã¨ã¦ã‚‚è¤‡é›‘ãªä½œæ¥­ã§ã™ã€‚éæ­£è¦åŒ–ã«ã‚ˆã£ã¦ãã®ã‚ˆã†ãªè¤‡é›‘ãªå‡¦ç†ã‚’ã—ãªãã¦æ¸ˆã‚€ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚å¤šãã®ã‚·ã‚¹ãƒ†ãƒ ã§ã€100å¯¾1ã‚ã‚‹ã„ã¯1000å¯¾1ãã‚‰ã„ã«ãªã‚‹ãã‚‰ã„èª­ã¿å–ã‚Šã®æ–¹ãŒã€æ›¸ãè¾¼ã¿ã®ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚ˆã‚Šã‚‚å¤šã„ã“ã¨ã§ã—ã‚‡ã†ã€‚èª­ã¿è¾¼ã¿ã‚’è¡Œã†ãŸã‚ã«ã€è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚¸ãƒ§ã‚¤ãƒ³å‡¦ç†ãŒå«ã¾ã‚Œã‚‹ã‚‚ã®ã¯è¨ˆç®—çš„ã«é«˜ä¾¡ã«ã¤ãã¾ã™ã—ã€ãƒ‡ã‚£ã‚¹ã‚¯ã®å‡¦ç†æ™‚é–“ã§è†¨å¤§ãªæ™‚é–“ã‚’è²»æ¶ˆã—ã¦ã—ã¾ã†ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ¬ ç‚¹: éæ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ãŒè¤‡è£½ã•ã‚Œã‚‹ã€‚å†—é•·ãªãƒ‡ãƒ¼ã‚¿ã®è¤‡è£½ãŒåŒæœŸã•ã‚Œã‚‹ã‚ˆã†ã«åˆ¶ç´„ãŒå­˜åœ¨ã—ã€ãã®ã“ã¨ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®è¨­è¨ˆãŒè¤‡é›‘åŒ–ã™ã‚‹ã€‚éæ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯éå¤§ãªæ›¸ãè¾¼ã¿ã‚’å‡¦ç†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å ´åˆã€æ­£è¦åŒ–ã•ã‚Œã¦ã„ã‚‹ãã‚Œã‚ˆã‚Šã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ãŠã„ã¦åŠ£ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: éæ­£è¦åŒ–DenormalizationSQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯åºƒç¯„ãªçŸ¥è­˜ã‚’å¿…è¦ã¨ã™ã‚‹åˆ†é‡ã§å¤šãã® æœ¬ ãŒæ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’æ˜ã‚‰ã‹ã«ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ä¸Šã§ã€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ã‚’å®šã‚ã€ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« ã™ã‚‹ã“ã¨ã¯ã¨ã¦ã‚‚é‡è¦ã§ã™ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - abãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€é«˜è² è·ã®çŠ¶æ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« - slow query log ãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çŠ¶æ³ã®ç¢ºèªã‚’ã—ã¾ã—ã‚‡ã†ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¨ã‚‹ã“ã¨ã§ä»¥ä¸‹ã®ã‚ˆã†ãªåŠ¹ç‡åŒ–ã®é¸æŠè‚¢ã‚’ã¨ã‚‹ã“ã¨ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¹ã‚­ãƒ¼ãƒã‚’çµã‚‹MySQLã¯ã‚¢ã‚¯ã‚»ã‚¹é€Ÿåº¦å‘ä¸Šã®ãŸã‚ã€ãƒ‡ã‚£ã‚¹ã‚¯ä¸Šã®é€£ç¶šã—ãŸãƒ–ãƒ­ãƒƒã‚¯ã¸ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã—ã¦ã„ã¾ã™ã€‚é•·ã•ã®æ±ºã¾ã£ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å¯¾ã—ã¦ã¯ VARCHAR ã‚ˆã‚Šã‚‚ CHAR ã‚’ä½¿ã†ã‚ˆã†ã«ã—ã¾ã—ã‚‡ã†ã€‚CHAR ã®æ–¹ãŒåŠ¹ç‡çš„ã«é€Ÿããƒ©ãƒ³ãƒ€ãƒ ã«ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ ä¸€æ–¹ã€ VARCHAR ã§ã¯æ¬¡ã®ãƒ‡ãƒ¼ã‚¿ã«ç§»ã‚‹å‰ã«ãƒ‡ãƒ¼ã‚¿ã®æœ«å°¾ã‚’æ¤œçŸ¥ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ãŸã‚ã«é€Ÿåº¦ãŒçŠ ç‰²ã«ãªã‚Šã¾ã™ã€‚ãƒ–ãƒ­ã‚°ã®æŠ•ç¨¿ãªã©ã€å¤§ããªãƒ†ã‚­ã‚¹ãƒˆã«ã¯ TEXT ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚ TEXT ã§ã¯ãƒ–ãƒ¼ãƒªã‚¢ãƒ³å‹ã®æ¤œç´¢ã‚‚å¯èƒ½ã§ã™ã€‚ TEXT ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ã€ãƒ‡ã‚£ã‚¹ã‚¯ä¸Šã®å ´æ‰€ã¸ã®ãƒã‚¤ãƒ³ã‚¿ãƒ¼ãŒä¿å­˜ã•ã‚Œã¾ã™ã€‚2ã®32ä¹—ã‚„40å„„ä»¥ä¸‹ã‚’è¶…ãˆãªã„ç¨‹åº¦ã®å¤§ããªæ•°ã«ã¯ INT ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚é€šè²¨ã«é–¢ã—ã¦ã¯å°æ•°ç‚¹è¡¨ç¤ºä¸Šã®ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã« DECIMAL ã‚’ä½¿ã„ã¾ã—ã‚‡ã†ã€‚å¤§ããª BLOBS ã‚’ä¿å­˜ã™ã‚‹ã®ã¯é¿ã‘ã¾ã—ã‚‡ã†ã€‚ã©ã“ã‹ã‚‰ãã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–ã£ã¦ãã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã®æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚VARCHAR(255) ã¯8ãƒ“ãƒƒãƒˆã§æ•°ãˆã‚‰ã‚Œã‚‹æœ€å¤§ã®æ–‡å­—æ•°ã§ã™ã€‚ä¸€éƒ¨ã®DBMSã§ã¯ã€1ãƒã‚¤ãƒˆã®åˆ©ç”¨åŠ¹ç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«ã“ã®æ–‡å­—æ•°ãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚æ¤œç´¢æ€§èƒ½å‘ä¸Šã®ãŸã‚ ã€å¯èƒ½ã§ã‚ã‚Œã° NOT NULL åˆ¶ç´„ã‚’è¨­å®šã—ã¾ã—ã‚‡ã†ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åŠ¹æœçš„ã«ç”¨ã„ã‚‹ã‚¯ã‚¨ãƒª(SELECTã€ GROUP BYã€ ORDER BYã€ JOIN) ã®å¯¾è±¡ã¨ãªã‚‹åˆ—ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã†ã“ã¨ã§é€Ÿåº¦ã‚’å‘ä¸Šã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯é€šå¸¸ã€å¹³è¡¡æ¢ç´¢æœ¨ã§ã‚ã‚‹Bæœ¨ã®å½¢ã§è¡¨ã•ã‚Œã¾ã™ã€‚Bæœ¨ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ã¯å¸¸ã«ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸçŠ¶æ…‹ã«ãªã‚Šã¾ã™ã€‚ã¾ãŸæ¤œç´¢ã€é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹ã€æŒ¿å…¥ã€å‰Šé™¤ã‚’å¯¾æ•°æ™‚é–“ã§è¡Œãˆã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é…ç½®ã™ã‚‹ã“ã¨ã¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªãƒ¼ã«æ®‹ã™ã“ã¨ã«ã¤ãªãŒã‚Šã‚ˆã‚Šå®¹é‡ã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°ã‚‚å¿…è¦ã«ãªã‚‹ãŸã‚æ›¸ãè¾¼ã¿ã‚‚é…ããªã‚Šã¾ã™ã€‚å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹éš›ã«ã¯ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ‡ã£ã¦ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å†ã³ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ“ãƒ«ãƒ‰ã—ãŸæ–¹ãŒé€Ÿã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚é«˜è² è·ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’é¿ã‘ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šå¿…è¦ãªã¨ã“ã‚ã«ã¯éæ­£è¦åŒ–ã‚’é©ç”¨ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆ†å‰²ã—ã€ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆã‚’ç‹¬ç«‹ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã«åˆ†é›¢ã—ã¦ãƒ¡ãƒ¢ãƒªãƒ¼ã«ä¹—ã›ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª¿æ•´ã™ã‚‹å ´åˆã«ã‚ˆã£ã¦ã¯ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: SQLãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°MySQLã‚¯ã‚¨ãƒªã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®TipsVARCHAR(255)ã‚’ã‚„ãŸã‚‰ã‚ˆãè¦‹ã‹ã‘ã‚‹ã®ã¯ãªã‚“ã§ï¼Ÿnullå€¤ã¯ã©ã®ã‚ˆã†ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã™ã‚‹ã®ã‹ï¼ŸSlow query logNoSQLNoSQL ã¯ key-value storeã€ document-storeã€ wide column storeã€ ã‚‚ã—ãã¯ graph databaseã«ã‚ˆã£ã¦è¡¨ç¾ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¤ãƒ†ãƒ ã®é›†åˆã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ä¸€èˆ¬çš„ã«æ­£è¦åŒ–ã•ã‚Œã¦ãŠã‚‰ãšã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã§ã‚¸ãƒ§ã‚¤ãƒ³ãŒè¡Œã‚ã‚Œã¾ã™ã€‚å¤§éƒ¨åˆ†ã®NoSQLã¯çœŸã®ACIDãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŒãŸãšã€ çµæœæ•´åˆæ€§ çš„ãªæŒ¯ã‚‹èˆã„ã®æ–¹ã‚’å¥½ã¿ã¾ã™ã€‚BASE ã¯ã—ã°ã—ã°NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚CAP Theorem ã¨å¯¾ç…§çš„ã«ã€BASEã¯ä¸€è²«æ€§ã‚ˆã‚Šã‚‚å¯ç”¨æ€§ã‚’å„ªå…ˆã—ã¾ã™ã€‚Basically available - ã‚·ã‚¹ãƒ†ãƒ ã¯å¯ç”¨æ€§ã‚’ä¿è¨¼ã—ã¾ã™ã€‚Soft state - ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã¯å…¥åŠ›ãŒãªãã¦ã‚‚æ™‚é–“çµŒéã¨ã¨ã‚‚ã«å¤‰åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚çµæœæ•´åˆæ€§ - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã¯æ™‚é–“çµŒéã¨ã¨ã‚‚ã«ãã®é–“ã«å…¥åŠ›ãŒãªã„ã¨ã„ã†å‰æã®ã‚‚ã¨ã€ä¸€è²«æ€§ãŒé”æˆã•ã‚Œã¾ã™ã€‚SQLã‹ï¼ŸNoSQLã‹ï¼Ÿ ã‚’é¸æŠã™ã‚‹ã®ã«åŠ ãˆã¦ã€ã©ã®ã‚¿ã‚¤ãƒ—ã®NoSQLãŒã©ã®ä½¿ç”¨ä¾‹ã«æœ€ã‚‚é©ã™ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ã®ã¯ã¨ã¦ã‚‚æœ‰ç›Šã§ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã€ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã€ ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã€ ã¨ ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ã«ã¤ã„ã¦è§¦ã‚Œã¦ã„ãã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢æ¦‚è¦: ãƒãƒƒã‚·ãƒ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ä¸€èˆ¬çš„ã«O(1)ã®èª­ã¿æ›¸ããŒã§ãã€ãã‚Œã‚‰ã¯ãƒ¡ãƒ¢ãƒªãªã„ã—SSDã§è£ä»˜ã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¯ã‚­ãƒ¼ã‚’ è¾æ›¸çš„é †åº ã§ä¿æŒã™ã‚‹ã“ã¨ã§ã‚­ãƒ¼ã®åŠ¹ç‡çš„ãªå–å¾—ã‚’å¯èƒ½ã«ã—ã¦ã„ã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å€¤ã¨ã¨ã‚‚ã«ä¿æŒã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã¯ãƒã‚¤ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãªæŒ™å‹•ãŒå¯èƒ½ã§ã€å˜ç´”ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ãªã©ã®ãƒ‡ãƒ¼ã‚¿ãŒæ€¥é€Ÿã«å¤‰ã‚ã‚‹å ´åˆãªã©ã«ä½¿ã‚ã‚Œã¾ã™ã€‚å˜ç´”ãªå‡¦ç†ã®ã¿ã«æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€è¿½åŠ ã®å‡¦ç†æ©Ÿèƒ½ãŒå¿…è¦ãªå ´åˆã«ã¯ãã®è¤‡é›‘æ€§ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã«è¼‰ã›ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã¯ã‚‚ã£ã¨è¤‡é›‘ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã‚„ã€ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®åŸºæœ¬ã§ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã®æ¬ ç‚¹Redisã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢æ¦‚è¦: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãƒãƒªãƒ¥ãƒ¼ã¨ã—ã¦ä¿å­˜ã•ã‚ŒãŸã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«é–¢ã™ã‚‹å…¨ã¦ã®æƒ…å ±ã‚’æŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ(XMLã€ JSONã€ binaryãªã©)ã‚’ä¸­å¿ƒã«æ®ãˆãŸã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã§ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªèº«ã®å†…éƒ¨æ§‹é€ ã«åŸºã¥ã„ãŸã€APIã‚‚ã—ãã¯ã‚¯ã‚¨ãƒªè¨€èªã‚’æä¾›ã—ã¾ã™ã€‚ ãƒ¡ãƒ¢ï¼šå¤šãã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã¯ã€å€¤ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†æ©Ÿèƒ½ã‚’å«ã‚“ã§ã„ã¾ã™ãŒã€ãã®ã“ã¨ã«ã‚ˆã£ã¦äºŒã¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¨ã®å¢ƒç•Œç·šãŒæ›–æ˜§ã«ãªã£ã¦ã—ã¾ã£ã¦ã„ã¾ã™ã€‚ä»¥ä¸Šã®ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã€ã‚¿ã‚°ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã©ã¨ã—ã¦æ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒå£«ã¯ã¾ã¨ã‚ã¦ã‚°ãƒ«ãƒ¼ãƒ—ã«ã§ãã‚‹ã‚‚ã®ã®ã€ãã‚Œãã‚Œã§å…¨ãç•°ãªã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚MongoDB ã‚„ CouchDB ãªã©ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã‚‚ã€è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã®SQLã®ã‚ˆã†ãªè¨€èªã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚DynamoDB ã¯ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ã¯é«˜ã„æŸ”è»Ÿæ€§ã‚’æ‹…ä¿ã™ã‚‹ã®ã§ã€é »ç¹ã«å¤‰åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†æ™‚ã«ç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹MongoDB ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£CouchDB ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Elasticsearch ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢      Source: SQL & NoSQL, a brief historyæ¦‚è¦: ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒãƒƒãƒ— ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼<è¡Œã‚­ãƒ¼ã€ ã‚«ãƒ©ãƒ <ColKeyã€ Valueã€ Timestamp>>ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬å˜ä½ã¯ã‚«ãƒ©ãƒ ï¼ˆãƒãƒ¼ãƒ ãƒ»ãƒãƒªãƒ¥ãƒ¼ã®ãƒšã‚¢ï¼‰ã§ã™ã€‚ãã‚Œãã‚Œã®ã‚«ãƒ©ãƒ ã¯ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¨ã—ã¦ï¼ˆSQLãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚ˆã†ã«ï¼‰ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¯ã‚«ãƒ©ãƒ ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®é›†åˆã§ã™ã€‚ãã‚Œãã‚Œã®ã‚«ãƒ©ãƒ ã«ã¯è¡Œã‚­ãƒ¼ã§ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚åŒã˜è¡Œã‚­ãƒ¼ã‚’æŒã¤ã‚«ãƒ©ãƒ ã¯åŒã˜è¡Œã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã™ã€‚ãã‚Œãã‚Œã®å€¤ã¯ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãŒèµ·ããŸæ™‚ã®ãŸã‚ã«ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å«ã¿ã¾ã™ã€‚Googleã¯Bigtableã‚’åˆã®ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã¨ã—ã¦ç™ºè¡¨ã—ã¾ã—ãŸã€‚ãã‚ŒãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§Hadoopãªã©ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹HBase ã‚„Facebookã«ã‚ˆã‚‹Cassandra ãªã©ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å½±éŸ¿ã‚’ä¸ãˆã¾ã—ãŸã€‚BigTableã€HBaseã‚„Cassandraãªã©ã®ã‚¹ãƒˆã‚¢ã¯ã‚­ãƒ¼ã‚’è¾æ›¸å½¢å¼ã§ä¿æŒã™ã‚‹ã“ã¨ã§é¸æŠã—ãŸã‚­ãƒ¼ãƒ¬ãƒ³ã‚¸ã§ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’åŠ¹ç‡çš„ã«ã—ã¾ã™ã€‚ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢ã¯é«˜ã„å¯ç”¨æ€§ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’æ‹…ä¿ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã¨ã¦ã‚‚å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‰±ã†ã“ã¨ã«ã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã‚¹ãƒˆã‚¢SQL & NoSQLç°¡å˜ã«æ­´å²ã‚’ã•ã‚‰ã†Bigtable ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£HBase ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Cassandra ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹      Source: Graph databaseæ¦‚è¦: ã‚°ãƒ©ãƒ•ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã¯ã€ãã‚Œãã‚Œã®ãƒãƒ¼ãƒ‰ãŒãƒ¬ã‚³ãƒ¼ãƒ‰ã§ã€ãã‚Œãã‚Œã®ã‚¢ãƒ¼ã‚¯ã¯äºŒã¤ã®ãƒãƒ¼ãƒ‰ã‚’ç¹‹ãé–¢ä¿‚æ€§ã¨ã—ã¦å®šç¾©ã•ã‚Œã¾ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯å¤šæ•°ã®å¤–éƒ¨ã‚­ãƒ¼ã‚„å¤šå¯¾å¤šãªã©ã®è¤‡é›‘ãªé–¢ä¿‚æ€§ã‚’è¡¨ã™ã®ã«æœ€é©ã§ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯SNSãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹ã®è¤‡é›‘ãªé–¢ä¿‚æ€§ãƒ¢ãƒ‡ãƒ«ãªã©ã«ã¤ã„ã¦é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚æ¯”è¼ƒçš„æ–°ã—ãã€ã¾ã ä¸€èˆ¬çš„ã«ã¯ç”¨ã„ã‚‰ã‚Œã¦ã„ãªã„ã®ã§ã€é–‹ç™ºãƒ„ãƒ¼ãƒ«ã‚„ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¢ã™ã®ãŒä»–ã®æ–¹æ³•ã«æ¯”ã¹ã¦é›£ã—ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å¤šãã®ã‚°ãƒ©ãƒ•ã¯REST APIsã‚’é€šã˜ã¦ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ã‚°ãƒ©ãƒ•Graphãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹Neo4jFlockDBãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  NoSQLåŸºæœ¬ç”¨èªã®èª¬æ˜NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¤ã„ã¦èª¿æŸ»ã¨é¸æŠã‚¬ã‚¤ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£NoSQLã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³NoSQLãƒ‘ã‚¿ãƒ¼ãƒ³SQLã‹ï¼ŸNoSQLã‹ï¼Ÿ      Source: Transitioning from RDBMS to NoSQLSQL ã‚’é¸ã¶ç†ç”±:æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å³æ ¼ãªã‚¹ã‚­ãƒ¼ãƒãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿è¤‡é›‘ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’ã™ã‚‹å¿…è¦æ€§ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹éš›ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ˜ç¢ºãªã¨ãé–‹ç™ºè€…ã®æ•°ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã€ã‚³ãƒ¼ãƒ‰ç­‰ãŒã‚ˆã‚Šå……å®Ÿã—ã¦ã„ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã¯ã¨ã¦ã‚‚é€Ÿã„NoSQL ã‚’é¸ã¶ç†ç”±:æº–æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã„ã—ã€ãƒ•ãƒ¬ã‚­ã‚·ãƒ–ãƒ«ãªã‚¹ã‚­ãƒ¼ãƒãƒãƒ³ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãªãƒ‡ãƒ¼ã‚¿è¤‡é›‘ãªã‚¸ãƒ§ã‚¤ãƒ³ã‚’ã™ã‚‹å¿…è¦ãŒãªã„ãƒ‡ãƒ¼ã‚¿ã®å¤šãã®TB (ã‚‚ã—ãã¯ PB) ã‚’ä¿å­˜ã™ã‚‹é›†ä¸­çš„ã€å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿è² è·ã«è€ãˆã‚‰ã‚Œã‚‹IOPSã«ã¤ã„ã¦ã¯æ¥µã‚ã¦é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¤ºã™NoSQLã«é©ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:æ€¥æ¿€ãªã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚„ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã®åé›†ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã‚„ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã‚«ãƒ¼ãƒˆãªã©ã®ä¸€æ™‚çš„æƒ…å ±é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ ('ãƒ›ãƒƒãƒˆãª') ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:  ã€€SQLã‚‚ã—ãã¯NoSQLæœ€åˆã®1000ä¸‡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«SQLã¨NoSQLã®é•ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥      Source: Scalable system design patternsã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿æ™‚é–“ã‚’å‰Šæ¸›ã—ã€ã‚µãƒ¼ãƒãƒ¼ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®è² è·ã‚’ä½æ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€å®Ÿéš›ã®å‡¦ç†ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«ã€ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒãƒ£ãƒ¼ãŒã¾ãšä»¥å‰ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒé€ä¿¡ã•ã‚ŒãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã€ç›´å‰ã®çµæœã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ãã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«æ¸¡ã£ã¦çµ±åˆã•ã‚ŒãŸèª­ã¿å–ã‚Šæ›¸ãè¾¼ã¿ã®åˆ†é…ã‚’è¦æ±‚ã—ã¾ã™ãŒã€äººæ°—ã‚¢ã‚¤ãƒ†ãƒ ã¯ãã®åˆ†é…ã‚’æ­ªã‚ã¦ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã£ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å·®ã—è¾¼ã‚€ã“ã¨ã§ã“ã®ã‚ˆã†ã«ã€å‡ä¸€ã§ãªã„è² è·ã‚„ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®æ€¥æ¿€ãªå¢—åŠ ã‚’å¸åã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯OSã‚„ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ãªã©ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰ã€ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ ã‚‚ã—ãã¯ç‹¬ç«‹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«è¨­ç½®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚CDNã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°CDN ã‚‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¸€ã¤ã¨ã—ã¦è€ƒãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Webã‚µãƒ¼ãƒãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· ã‚„ Varnish ãªã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯é™çš„ãã—ã¦å‹•çš„ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç›´æ¥é…ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ webã‚µãƒ¼ãƒãƒ¼ã‚‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ã“ã¨ãªã—ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯æ™®é€šã€ä¸€èˆ¬çš„ãªä½¿ç”¨çŠ¶æ³ã«é©ã™ã‚‹ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã®è¨­å®šã‚’åˆæœŸçŠ¶æ…‹ã§æŒã£ã¦ã„ã¾ã™ã€‚ã“ã®è¨­å®šã‚’ç‰¹å®šã®ä»•æ§˜ã«åˆã‚ã›ã¦èª¿æ•´ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã©ã®In-memoryã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚„Redisã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®é–“ã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯RAMã§ä¿æŒã•ã‚Œã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ã‚£ã‚¹ã‚¯ã§ä¿å­˜ã•ã‚Œã‚‹ä¸€èˆ¬çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚ˆã‚Šã‚‚ã ã„ã¶é€Ÿã„ã§ã™ã€‚RAMå®¹é‡ã¯ãƒ‡ã‚£ã‚¹ã‚¯ã‚ˆã‚Šã‚‚é™ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã€least recently used (LRU)ãªã©ã®cache invalidation ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒ 'ã‚³ãƒ¼ãƒ«ãƒ‰' ãªã‚¨ãƒ³ãƒˆãƒªã‚’å¼¾ãã€'ãƒ›ãƒƒãƒˆ' ãªãƒ‡ãƒ¼ã‚¿ã‚’RAMã«ä¿å­˜ã—ã¾ã™ã€‚Redisã¯ã•ã‚‰ã«ä»¥ä¸‹ã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’å‚™ãˆã¦ã„ã¾ã™:ãƒ‘ãƒ¼ã‚¸ã‚¹ãƒ†ãƒ³ã‚¹è¨­å®šã‚½ãƒ¼ãƒˆæ¸ˆã¿ã‚»ãƒƒãƒˆã€ãƒªã‚¹ãƒˆãªã©ã®çµ„ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã¯æ§˜ã€…ãªãƒ¬ãƒ™ãƒ«ã®ã‚‚ã®ãŒã‚ã‚Šã¾ã™ãŒã€ã„ãšã‚Œã‚‚å¤§ããäºŒã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ã„ãšã‚Œã‹ã«åˆ†é¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª ã¨ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ ã§ã™:è¡Œãƒ¬ãƒ™ãƒ«ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«Fully-formed serializable objectsFully-rendered HTMLä¸€èˆ¬çš„ã«ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã¯ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’ä½œã‚Šå‡ºã—ã¦ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’é›£ã—ãã—ã¦ã—ã¾ã†ã®ã§é¿ã‘ã‚‹ã¹ãã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹éš›ã«ã¯å¿…ãšã‚¯ã‚¨ãƒªã‚’ã‚­ãƒ¼ã¨ã—ã¦ãƒãƒƒã‚·ãƒ¥ã—ã¦çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚ã“ã®æ‰‹æ³•ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœŸé™åˆ‡ã‚Œå•é¡Œã«æ‚©ã‚€ã“ã¨ã«ãªã‚Šã¾ã™:è¤‡é›‘ãªã‚¯ã‚¨ãƒªã«ã‚ˆã‚Šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçµæœã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ãŒå›°é›£ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ãƒ«ãªã©ã®ãƒ‡ãƒ¼ã‚¿æ–­ç‰‡ãŒå¤‰åŒ–ã—ãŸæ™‚ã«ã€ãã®å¤‰åŒ–ã—ãŸã‚»ãƒ«ã‚’å«ã‚€ã‹ã‚‚ã—ã‚Œãªã„å…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’å‰Šé™¤ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã†ã™ã‚‹ã‚ˆã†ã«ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ‰ãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨ã—ã¦çµ„ã¿ç«‹ã¦ã•ã›ã¾ã™ã€‚:ãã®ãƒ‡ãƒ¼ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å‰Šé™¤ã™ã‚‹ã“ã¨éåŒæœŸå‡¦ç†ã‚’è¨±å®¹ã—ã¾ã™: ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸­ã§æœ€æ–°ã®ã‚‚ã®ã‚’é›†ã‚ã¦ãã¾ã™ä½•ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã‹:ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œå…¨ã«ãƒ¬ãƒ³ãƒ€ãƒ¼ã•ã‚ŒãŸã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‚¢ã‚¯ãƒ†ãƒ“ãƒ†ã‚£ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã§ãã‚‹å®¹é‡ã¯é™ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€è‡ªåˆ†ã®ã‚±ãƒ¼ã‚¹ã§ã¯ã©ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‰‹æ³•ãŒä¸€ç•ªã„ã„ã‹ã¯æ¤œè¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰      Source: From cache to in-memory data gridã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¸ã®èª­ã¿æ›¸ãã®å‡¦ç†ã‚’ã—ã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ã¯ç›´æ¥ã‚„ã‚Šã¨ã‚Šã‚’ã—ã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ã“ã¨ã‚’ã—ã¾ã™:ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¸­ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å‚ç…§ã—ã¾ã™ãŒã€çµæœã¨ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã«ãªã‚Šã¾ã™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—ã—ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¿½åŠ ã—ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã—ã¾ã™def get_user(self, user_id):    user = cache.get(\""user.{0}\"", user_id)    if user is None:        user = db.query(\""SELECT * FROM users WHERE user_id = {0}\"", user_id)        if user is not None:            key = \""user.{0}\"".format(user_id)            cache.set(key, json.dumps(user))    return userMemcached ã¯é€šå¸¸ã“ã®ã‚ˆã†ã«ä½¿ã‚ã‚Œã‚‹ã€‚ãã®å¾Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¯é€Ÿã„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã¯ãƒ¬ãƒ¼ã‚¸ãƒ¼ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚ã‚‹ã¨ã‚‚è¨€ã‚ã‚Œã¾ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã¿ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæº¢ã‚Œã‚‹ã®ã‚’é˜²æ­¢ã—ã¾ã™ã€‚æ¬ ç‚¹: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰å„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ã¯ä¸‰ã¤ã®ãƒˆãƒªãƒƒãƒ—ã‚’å‘¼ã³å‡ºã™ã“ã¨ã«ãªã‚Šã€ä½“æ„Ÿã§ãã‚‹ã»ã©ã®é…å»¶ãŒèµ·ãã¦ã—ã¾ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ãŒæ›´æ–°ã•ã‚Œã‚‹ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã¯å¤ã„ã‚‚ã®ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚time-to-live (TTL)ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã®æ›´æ–°ã‚’å¼·åˆ¶çš„ã«è¡Œã†ã€ã‚‚ã—ãã¯ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã¯ç·©å’Œã§ãã¾ã™ã€‚ãƒãƒ¼ãƒ‰ãŒè½ã¡ã‚‹ã¨ã€æ–°è¦ã®ç©ºã®ãƒãƒ¼ãƒ‰ã§ä»£æ›¿ã•ã‚Œã‚‹ã“ã¨ã§ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒå¢—åŠ ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼      Source: Scalability, availability, stability, patternsã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¨ã—ã¦ä½¿ã„ã€ãã“ã«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿æ›¸ãã‚’è¡Œã„ã¾ã™ã€‚ä¸€æ–¹ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®èª­ã¿æ›¸ãã‚’æ‹…å½“ã—ã¾ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã‚ã‚‹ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã™ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯åŒæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã«æ›¸ãè¾¼ã¿ã‚’è¡Œã„ã¾ã™ã‚¨ãƒ³ãƒˆãƒªã‚’è¿”ã—ã¾ã™ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰:set_user(12345, {\""foo\"":\""bar\""})ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚³ãƒ¼ãƒ‰:def set_user(user_id, values):    user = db.query(\""UPDATE Users WHERE id = {0}\"", user_id, values)    cache.set(user_id, user)ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã¯æ›¸ãè¾¼ã¿å‡¦ç†ã®ã›ã„ã§å…¨ä½“ã¨ã—ã¦ã¯é…ã„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ãŒã€æ›¸ãè¾¼ã¾ã‚ŒãŸã°ã‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹èª­ã¿è¾¼ã¿ã¯é€Ÿã„ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å´ã¯ä¸€èˆ¬çš„ã«ãƒ‡ãƒ¼ã‚¿æ›´æ–°æ™‚ã®æ–¹ãŒèª­ã¿è¾¼ã¿æ™‚ã‚ˆã‚Šã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã«è¨±å®¹çš„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã¯æœ€æ–°ç‰ˆã§ä¿ãŸã‚Œã¾ã™ã€‚æ¬ ç‚¹: ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ãƒãƒ¼ãƒ‰ãŒè½ã¡ãŸã“ã¨ã€ã‚‚ã—ãã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦æ–°ã—ã„ãƒãƒ¼ãƒ‰ãŒä½œæˆã•ã‚ŒãŸæ™‚ã«ã€æ–°ã—ã„ãƒãƒ¼ãƒ‰ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒæ›´æ–°ã•ã‚Œã‚‹ã¾ã§ã¯ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã›ã‚“ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã¨ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚’ä½µç”¨ã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã‚’ç·©å’Œã§ãã¾ã™ã€‚æ›¸ãè¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã¯ä¸€åº¦ã‚‚èª­ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯TTLã«ã‚ˆã£ã¦åœ§ç¸®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ (ãƒ©ã‚¤ãƒˆãƒãƒƒã‚¯)      Source: Scalability, availability, stability, patternsãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ã§ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ã“ã¨ã‚’ã—ã¾ã™:ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’è¿½åŠ ãƒ»æ›´æ–°ã—ã¾ã™ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢ã¸ã®æ›¸ãè¾¼ã¿ã‚’éåŒæœŸçš„ã«è¡Œã†ã“ã¨ã§ã€æ›¸ãè¾¼ã¿ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚æ¬ ç‚¹: ãƒ©ã‚¤ãƒˆãƒ“ãƒã‚¤ãƒ³ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢å†…ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ãƒ’ãƒƒãƒˆã™ã‚‹å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè½ã¡ã‚‹ã¨ãƒ‡ãƒ¼ã‚¿æ¬ æãŒèµ·ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚µã‚¤ãƒ‰ã‚„ãƒ©ã‚¤ãƒˆã‚¹ãƒ«ãƒ¼ã‚ˆã‚Šã‚‚å®Ÿè£…ãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰      Source: From cache to in-memory data gridæœŸé™åˆ‡ã‚Œã‚ˆã‚Šã‚‚å‰ã«ã€ç›´è¿‘ã§ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸå…¨ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªã‚’è‡ªå‹•çš„ã«æ›´æ–°ã™ã‚‹ã‚ˆã†ã«è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚‚ã—ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå°†æ¥å¿…è¦ã«ãªã‚‹ã®ã‹ã‚’æ­£ç¢ºã«äºˆæ¸¬ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ãªã‚‰ã°ã€ãƒªãƒ¼ãƒ‰ã‚¹ãƒ«ãƒ¼ã‚ˆã‚Šã‚‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬ ç‚¹: ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå¿…è¦ã«ãªã‚‹ã‹ã®äºˆæ¸¬ãŒæ­£ç¢ºã§ãªã„å ´åˆã«ã¯ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚¢ãƒ˜ãƒƒãƒ‰ãŒãªã„æ–¹ãŒãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¯è‰¯ã„ã¨ã„ã†çµæœã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚æ¬ ç‚¹: ã‚­ãƒ£ãƒƒã‚·ãƒ¥cache invalidationãªã©ã‚’ç”¨ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®çœŸã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®é–“ã®ä¸€è²«æ€§ã‚’ä¿ã¤å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Redisã‚„memcachedã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹æˆã‚’å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Cache invalidationã‚‚é›£ã—ã„ã§ã™ãŒãã‚Œã«åŠ ãˆã¦ã€ã„ã¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã‹ã¨ã„ã†è¤‡é›‘ãªå•é¡Œã«ã‚‚æ‚©ã¾ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸From cache to in-memory data gridã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€å¯ç”¨æ€§ã€å®‰å®šæ€§ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£AWS ElastiCacheã®ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼WikipediaéåŒæœŸå‡¦ç†      Source: Intro to architecting systems for scaleéåŒæœŸã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ã‚‚ã—ã€é€£ç¶šçš„ã«è¡Œã‚ã‚Œã‚‹ã¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚é–“ã‚’åœ§è¿«ã—ã¦ã—ã¾ã†ã‚ˆã†ãªé‡ã„å‡¦ç†ã‚’åˆ¥ã§å‡¦ç†ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã¾ãŸã€å®šæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†åˆã•ã›ã‚‹ãªã©ã®æ™‚é–“ãŒã‹ã‹ã‚‹ã‚ˆã†ãªå‡¦ç†ã‚’å‰ã‚‚ã£ã¦å‡¦ç†ã—ã¦ãŠãã“ã¨ã«ã‚‚å½¹ç«‹ã¡ã¾ã™ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã€ä¿å­˜ã—ã€é…ä¿¡ã—ã¾ã™ã€‚ã‚‚ã—ã€å‡¦ç†ãŒã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã§è¡Œã†ã«ã¯é…ã™ãã‚‹å ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã‚’ç”¨ã„ã‚‹ã¨ã„ã„ã§ã—ã‚‡ã†:ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚¸ãƒ§ãƒ–ã‚’ã‚­ãƒ¥ãƒ¼ã«é…ä¿¡ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ä¼ãˆã¾ã™ã€‚ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å—ã‘å–ã£ã¦ã€å‡¦ç†ã‚’è¡Œã„ã€çµ‚äº†ã—ãŸã‚‰ãã®ã‚·ã‚°ãƒŠãƒ«ã‚’è¿”ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‡¦ç†ãŒæ­¢ã¾ã‚‹ã“ã¨ã¯ãªãã€ã‚¸ãƒ§ãƒ–ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å‡¦ç†ã•ã‚Œã¾ã™ã€‚ã“ã®é–“ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã€ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ãŸã‹ã®ã‚ˆã†ã«è¦‹ã›ã‚‹ãŸã‚ã«å°è¦æ¨¡ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æŠ•ç¨¿ã™ã‚‹ã¨ãã«ã€ãƒ„ã‚¤ãƒ¼ãƒˆã¯ã™ãã«ã‚ãªãŸã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«åæ˜ ã•ã‚ŒãŸã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€ãã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒå®Ÿéš›ã«å…¨ã¦ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã«é…ä¿¡ã•ã‚Œã‚‹ã¾ã§ã«ã¯ã‚‚ã†å°‘ã—æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã‚‹ã§ã—ã‚‡ã†ã€‚Redis ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä»²ä»‹ã¨ã—ã¦ã¯ã„ã„ã§ã™ãŒã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚RabbitMQ ã¯ã‚ˆãä½¿ã‚ã‚Œã¦ã„ã¾ã™ãŒã€'AMQP'ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¯¾å¿œã—ã¦ã€è‡ªå‰ã®ãƒãƒ¼ãƒ‰ã‚’ç«‹ã¦ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚Amazon SQS ã¨ã„ã†é¸æŠè‚¢ã‚‚ã‚ã‚Šã¾ã™ãŒã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãŒé«˜ãã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé‡è¤‡ã—ã¦é…ä¿¡ã•ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã¯ã‚¿ã‚¹ã‚¯ã¨ãã®é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€å‡¦ç†ã—ãŸä¸Šã§ãã®çµæœã‚’è¿”ã—ã¾ã™ã€‚ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã‚’ã§ãã‚‹ã»ã‹ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã¨ã¦ã‚‚é‡ã„ã‚¸ãƒ§ãƒ–ã‚’ã“ãªã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚Celery ã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¨pythonã®ã‚µãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚‚ã—ã€ã‚­ãƒ¥ãƒ¼ãŒæ‹¡å¤§ã—ã™ãã‚‹ã¨ã€ãƒ¡ãƒ¢ãƒªãƒ¼ã‚ˆã‚Šã‚‚ã‚­ãƒ¥ãƒ¼ã®æ–¹ãŒå¤§ãããªã‚Šã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ãŒèµ·ã“ã‚Šã€ãƒ‡ã‚£ã‚¹ã‚¯èª­ã¿å‡ºã—ã«ã¤ãªãŒã‚Šã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã«ã¤ãªãŒã‚Šã¾ã™ã€‚ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã¯ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§å›é¿ã™ã‚‹ã“ã¨ãŒã§ãã€é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¢ºä¿ã—ã‚­ãƒ¥ãƒ¼ã«ã™ã§ã«ã‚ã‚‹ã‚¸ãƒ§ãƒ–ã«ã¤ã„ã¦ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚’çŸ­ç¸®ã§ãã¾ã™ã€‚ã‚­ãƒ¥ãƒ¼ãŒã„ã£ã±ã„ã«ãªã‚‹ã¨ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã‚µãƒ¼ãƒãƒ¼ãƒ“ã‚¸ãƒ¼ã‚‚ã—ãã¯HTTP 503ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦å—ã‘å–ã‚Šã¾ãŸå¾Œã§æ™‚é–“ã‚’ãŠã„ã¦ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚ˆã†ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯exponential backoffãªã©ã«ã‚ˆã£ã¦å¾Œã»ã©å†åº¦æ™‚é–“ã‚’ç½®ã„ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ¬ ç‚¹: éåŒæœŸå‡¦ç†ã‚­ãƒ¥ãƒ¼ã‚’ç”¨ã„ã‚‹ã“ã¨ã§é…å»¶ãŒèµ·ã“ã‚Šã€è¤‡é›‘ã•ã‚‚å¢—ã™ãŸã‚ã€ã‚ã¾ã‚Šé‡ããªã„è¨ˆç®—å‡¦ç†ã‚„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ãŠã„ã¦ã¯åŒæœŸå‡¦ç†ã®æ–¹ãŒã„ã„ã§ã—ã‚‡ã†ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸It's all a numbers gameã‚ªãƒ¼ãƒãƒ¼ãƒ­ãƒ¼ãƒ‰ã—ãŸæ™‚ã«ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚’é©ç”¨ã™ã‚‹Little's lawãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã¨ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã®é•ã„ã¨ã¯ï¼Ÿé€šä¿¡      Source: OSI 7 layer modelHypertext transfer protocol (HTTP)HTTP ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦è»¢é€ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã§ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«é–¢ã‚ã‚‹ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚µãƒ¼ãƒãƒ¼ã«æŠ•ã’ã€ã‚µãƒ¼ãƒãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã«é–¢ä¿‚ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨å®Œäº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚HTTPã¯è‡ªå·±å®Œçµã™ã‚‹ã®ã§ã€é–“ã«ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ³ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã€åœ§ç¸®ãªã©ã®ã©ã‚“ãªä¸­é–“ãƒ«ãƒ¼ã‚¿ãƒ¼ãŒå…¥ã£ã¦ã‚‚å‹•ãã‚ˆã†ã«ã§ãã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯HTTPå‹•è©(ãƒ¡ã‚½ãƒƒãƒ‰)ã¨ãƒªã‚½ãƒ¼ã‚¹(ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ)ã§æˆã‚Šç«‹ã£ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ãŒã‚ˆãã‚ã‚‹HTTPå‹•è©ã§ã™ã€‚:å‹•è©è©³ç´°å†ªç­‰æ€§*ã‚»ãƒ¼ãƒ•ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§ãã‚‹ã‹GETãƒªã‚½ãƒ¼ã‚¹ã‚’èª­ã¿å–ã‚‹YesYesYesPOSTãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹ã‚‚ã—ãã¯ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ãƒˆãƒªã‚¬ãƒ¼NoNoYes ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚€å ´åˆPUTãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã‚‚ã—ãã¯å…¥ã‚Œæ›¿ãˆã‚‹YesNoNoPATCHãƒªã‚½ãƒ¼ã‚¹ã‚’éƒ¨åˆ†çš„ã«æ›´æ–°ã™ã‚‹NoNoYes ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚€å ´åˆDELETEãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ã™ã‚‹YesNoNoä½•åº¦å‘¼ã‚“ã§ã‚‚åŒã˜çµæœãŒè¿”ã£ã¦ãã‚‹ã“ã¨HTTPã¯TCP ã‚„ UDP ãªã©ã®ä½ç´šãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹ã€‚ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: HTTPHTTPã£ã¦ãªã«?HTTP ã¨ TCPã®é•ã„PUT ã¨ PATCHã®é•ã„ä¼é€åˆ¶å¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ« (TCP)      Source: How to make a multiplayer gameTCPã¯IP networkã®ä¸Šã§æˆã‚Šç«‹ã¤æ¥ç¶šãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚æ¥ç¶šã¯handshakeã«ã‚ˆã£ã¦é–‹å§‹ã€è§£é™¤ã•ã‚Œã¾ã™ã€‚å…¨ã¦ã®é€ä¿¡ã•ã‚ŒãŸãƒ‘ã‚±ãƒƒãƒˆã¯æ¬ æãªã—ã§é€ä¿¡å…ˆã«é€ä¿¡ã•ã‚ŒãŸé †ç•ªã§åˆ°é”ã™ã‚‹ã‚ˆã†ã«ä»¥ä¸‹ã®æ–¹æ³•ã§ä¿è¨¼ã•ã‚Œã¦ã„ã¾ã™:ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã¨checksum fieldsãŒå…¨ã¦ã®ãƒ‘ã‚±ãƒƒãƒˆã«ç”¨æ„ã•ã‚Œã¦ã„ã‚‹Acknowledgementãƒ‘ã‚±ãƒƒãƒˆã¨è‡ªå‹•å†é€ä¿¡ã‚‚ã—é€ä¿¡è€…ãŒæ­£ã—ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ã‘å–ã‚‰ãªã‹ã£ãŸã¨ãã€ãƒ‘ã‚±ãƒƒãƒˆã‚’å†é€ä¿¡ã—ã¾ã™ã€‚è¤‡æ•°ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒã‚ã£ãŸã¨ãã€æ¥ç¶šã¯è§£é™¤ã•ã‚Œã¾ã™ã€‚TCP ã¯ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ ã¨ è¼»è¼³åˆ¶å¾¡ã‚‚å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã«ã‚ˆã£ã¦é€Ÿåº¦ã¯ä½ä¸‹ã—ã€ä¸€èˆ¬çš„ã«UDPã‚ˆã‚Šã‚‚éåŠ¹ç‡ãªè»¢é€æ‰‹æ®µã«ãªã£ã¦ã„ã¾ã™ã€‚ãƒã‚¤ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã¯ã‹ãªã‚Šå¤§ããªæ•°ã®TCPæ¥ç¶šã‚’é–‹ã„ã¦ãŠãã“ã¨ãŒã‚ã‚Šã€ãã®ã“ã¨ã§ãƒ¡ãƒ¢ãƒªãƒ¼ä½¿ç”¨ãŒåœ§è¿«ã•ã‚Œã¾ã™ã€‚ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã¨ä¾‹ãˆã°memcached ã‚µãƒ¼ãƒãƒ¼ã®é–“ã§å¤šæ•°ã®ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿ã£ã¦ãŠãã“ã¨ã¯é«˜ãã¤ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚å¯èƒ½ãªã¨ã“ã‚ã§ã¯UDPã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã ã‘ã§ãªãã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãªã©ã‚‚å½¹ç«‹ã¤ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚TCPã¯é«˜ã„ä¾å­˜æ€§ã‚’è¦ã—ã€æ™‚é–“åˆ¶ç´„ãŒå³ã—ããªã„ã‚‚ã®ã«é©ã—ã¦ã„ã‚‹ã§ã—ã‚‡ã†ã€‚ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±ã€SMTPã€FTPã‚„SSHãªã©ã®ä¾‹ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã®æ™‚ã«UDPã‚ˆã‚Šã‚‚TCPã‚’ä½¿ã†ã¨ã„ã„ã§ã—ã‚‡ã†:å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒæ¬ æã™ã‚‹ã“ã¨ãªã—ã«å±Šã„ã¦ã»ã—ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®æœ€é©ãªè‡ªå‹•æ¨æ¸¬ã‚’ã—ã¦ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« (UDP)      Source: How to make a multiplayer gameUDPã¯ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ¬ã‚¹ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ï¼ˆãƒ‘ã‚±ãƒƒãƒˆã®ã‚ˆã†ãªã‚‚ã®ï¼‰ã¯ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ãƒ¬ãƒ™ãƒ«ã§ã®ä¿è¨¼ã—ã‹ã•ã‚Œã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ã¯é †ä¸åŒã§å—ã‘å–ã‚Šå…ˆã«åˆ°ç€ã—ãŸã‚Šãã‚‚ãã‚‚ç€ã‹ãªã‹ã£ãŸã‚Šã—ã¾ã™ã€‚UDPã¯è¼»è¼³åˆ¶å¾¡ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã›ã‚“ã€‚TCPã«ãŠã„ã¦ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã“ã‚Œã‚‰ã®ä¿è¨¼ãŒãªã„ãŸã‚ã€UDPã¯ä¸€èˆ¬çš„ã«ã€TCPã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã™ã€‚UDPã¯ã‚µãƒ–ãƒãƒƒãƒˆä¸Šã®ã™ã¹ã¦ã®æ©Ÿå™¨ã«ãƒ‡ãƒ¼ã‚¿ã‚°ãƒ©ãƒ ã‚’é€ä¿¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã¯DHCP ã«ãŠã„ã¦å½¹ã«ç«‹ã¡ã¾ã™ã€‚ã¨ã„ã†ã®ã‚‚ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã¾ã IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—ã—ã¦ã„ãªã„ã®ã§ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å¿…è¦ã¨ã™ã‚‹TCPã«ã‚ˆã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒã§ããªã„ã‹ã‚‰ã§ã™ã€‚UDPã¯ä¿¡é ¼æ€§ã®é¢ã§ã¯åŠ£ã‚Šã¾ã™ãŒã€VoIPã€ãƒ“ãƒ‡ã‚ªãƒãƒ£ãƒƒãƒˆã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚„åŒæ™‚é€šä¿¡ãƒãƒ«ãƒãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚²ãƒ¼ãƒ ãªã©ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ãŒé‡è¦–ã•ã‚Œã‚‹æ™‚ã«ã¯ã¨ã¦ã‚‚åŠ¹æœçš„ã§ã™ã€‚TCPã‚ˆã‚Šã‚‚UDPã‚’ä½¿ã†ã®ã¯:ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚’æœ€ä½é™ã«æŠ‘ãˆãŸã„æ™‚ãƒ‡ãƒ¼ã‚¿æ¬ æã‚ˆã‚Šã‚‚ã€ãƒ‡ãƒ¼ã‚¿é…å»¶ã‚’é‡è¦–ã™ã‚‹ã¨ãã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚’è‡ªå‰ã§å®Ÿè£…ã—ãŸã„ã¨ããã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: TCP ã¨ UDPã‚²ãƒ¼ãƒ ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ãŸã‚ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯TCP ã¨ UDP ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ä¸»ãªé•ã„TCP ã¨ UDPã®é•ã„Transmission control protocolUser datagram protocolFacebookã®ãƒ¡ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°é éš”æ‰‹ç¶šå‘¼å‡º (RPC)      Source: Crack the system design interviewRPCã§ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒªãƒ¢ãƒ¼ãƒˆã‚µãƒ¼ãƒãƒ¼ãªã©ã®ç•°ãªã‚‹ã‚¢ãƒ‰ãƒ¬ã‚¹ç©ºé–“ã§ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ãŒå‡¦ç†ã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ã‚³ãƒ¼ãƒ«ã®ã‚ˆã†ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã«ã©ã®ã‚ˆã†ã«é€šä¿¡ã™ã‚‹ã‹ã¨ã„ã†è©³ç´°ã‚’çœã„ãŸçŠ¶æ…‹ã§ã‚³ãƒ¼ãƒ‰ãŒæ›¸ã‹ã‚Œã¾ã™ã€‚ãƒªãƒ¢ãƒ¼ãƒˆã®ã‚³ãƒ¼ãƒ«ã¯æ™®é€šã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ã‚³ãƒ¼ãƒ«ã‚ˆã‚Šã‚‚é…ãã€ä¿¡é ¼æ€§ã«æ¬ ã‘ã‚‹ãŸã‚ã€RPCã‚³ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‚³ãƒ¼ãƒ«ã¨åŒºåˆ¥ã•ã›ã¦ãŠãã“ã¨ãŒå¥½ã¾ã—ã„ã§ã—ã‚‡ã†ã€‚äººæ°—ã®RPCãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ä»¥ä¸‹ã§ã™ã€‚Protobufã€ Thriftã€AvroRPC ã¯ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒˆã‚³ãƒ«:ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ  - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚³ãƒ¼ãƒ«ã®ã‚ˆã†ã«ã‚¹ã‚¿ãƒƒã‚¯ã¸ã¨ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ãã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ - ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£IDã¨ã‚¢ãƒ¼ã‚®ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ‘ãƒƒã‚¯ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã—ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé€šä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - OSãŒã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚µãƒ¼ãƒãƒ¼ã¸ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚Šã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼é€šä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - OSãŒå—ã‘å–ã£ãŸãƒ‘ã‚±ãƒƒãƒˆã‚’ã‚µãƒ¼ãƒãƒ¼ã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã«å—ã‘æ¸¡ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã‚¹ã‚¿ãƒ–ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ -  çµæœã‚’å±•é–‹ã—ã€ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼IDã«ãƒãƒƒãƒã™ã‚‹ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚·ãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å‘¼ã³å‡ºã—ã€çµæœã‚’è¿”ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ä¸Šè¨˜ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é€†é †ã§ç¹°ã‚Šè¿”ã—ã¾ã™ã€‚Sample RPC calls:GET /someoperation?data=anIdPOST /anotheroperation{  \""data\"":\""anId\"";  \""anotherdata\"": \""another value\""}RPCã¯æŒ¯ã‚‹èˆã„ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚RPCã¯å†…éƒ¨é€šä¿¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç†ç”±ã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚ã¨ã„ã†ã®ã‚‚ã€ä½¿ç”¨ã™ã‚‹çŠ¶æ³ã«åˆã‚ã›ã¦ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚³ãƒ¼ãƒ«ã‚’è‡ªä½œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã‚‰ã§ã™ã€‚ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼ (aka SDK) ã‚’å‘¼ã¶ã®ã¯ä»¥ä¸‹ã®æ™‚:ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’çŸ¥ã£ã¦ã„ã‚‹æ™‚ãƒ­ã‚¸ãƒƒã‚¯ãŒã©ã®ã‚ˆã†ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ã®ã‹ã‚’ç®¡ç†ã—ãŸã„ã¨ããƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼å¤–ã§ã‚¨ãƒ©ãƒ¼ãŒã©ã®ã‚ˆã†ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã•ã‚Œã‚‹ã‹ã‚’ç®¡ç†ã—ãŸã„æ™‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ãŒæœ€å„ªå…ˆã®æ™‚REST ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¾“ã†HTTP APIã¯ãƒ‘ãƒ–ãƒªãƒƒã‚¯APIã«ãŠã„ã¦ã‚ˆãç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚æ¬ ç‚¹: RPCRPCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã¯ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…ã«ã‚ˆã‚Šå³å¯†ã«å·¦å³ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚æ–°ã—ã„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ä½¿ç”¨ä¾‹ãŒã‚ã‚‹ãŸã³ã«æ–°ã—ãAPIãŒå®šç¾©ã•ã‚Œãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚RPCã‚’ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ã®ã¯é›£ã—ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ—¢å­˜ã®ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚’ãã®ã¾ã¾ä½¿ã£ã¦ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€Squidãªã©ã®ã‚µãƒ¼ãƒãƒ¼ã«RPCã‚³ãƒ¼ãƒ«ãŒæ­£ã—ãã‚­ãƒ£ãƒƒã‚·ãƒ¥ ã•ã‚Œã‚‹ã‚ˆã†ã«è¿½åŠ ã§éª¨ã‚’æŠ˜ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚Representational state transfer (REST)RESTã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒã‚µãƒ¼ãƒãƒ¼ã«ã‚ˆã£ã¦ãƒãƒãƒ¼ã‚¸ã•ã‚Œã‚‹ãƒªã‚½ãƒ¼ã‚¹ã«å¯¾ã—ã¦å‡¦ç†ã‚’è¡Œã†ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ»ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’æ”¯æŒã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚­ãƒãƒ£ã‚¹ã‚¿ã‚¤ãƒ«ã§ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯æ“ä½œã§ãã‚‹ã‚‚ã—ãã¯æ–°ã—ã„ãƒªã‚½ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ãªãƒªã‚½ãƒ¼ã‚¹ã‚„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ¬ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚ã™ã¹ã¦ã®é€šä¿¡ã¯ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯èƒ½ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚RESTful ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«ã¯æ¬¡ã®å››ã¤ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™:ç‰¹å¾´çš„ãªãƒªã‚½ãƒ¼ã‚¹ (URI in HTTP) - ã©ã®ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚ã£ã¦ã‚‚åŒã˜URIã‚’ä½¿ã†ã€‚HTTPå‹•è©ã«ã‚ˆã£ã¦å¤‰ã‚ã‚‹ (Verbs in HTTP) - å‹•è©ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒœãƒ‡ã‚£ã‚’ä½¿ã†è‡ªå·±èª¬æ˜çš„ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (status response in HTTP) - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ã„ã€æ–°ã—ãä½œã£ãŸã‚Šã—ãªã„ã“ã¨ã€‚HATEOAS (HTML interface for HTTP) - è‡ªåˆ†ã®webã‚µãƒ¼ãƒ“ã‚¹ãŒãƒ–ãƒ©ã‚¦ã‚¶ã§å®Œå…¨ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã“ã¨ã€‚ã‚µãƒ³ãƒ—ãƒ« REST ã‚³ãƒ¼ãƒ«:GET /someresources/anIdPUT /someresources/anId{\""anotherdata\"": \""another value\""}RESTã¯ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼ã®ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ã‚’æœ€å°é™ã«ã™ã‚‹ã‚‚ã®ã§ã€ãƒ‘ãƒ–ãƒªãƒƒã‚¯APIãªã©ã«ã‚ˆãç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚RESTã¯URIã€ representation through headersã€ãã—ã¦ã€GETã€POSTã€PUTã€ DELETEã€PATCHãªã©ã®HTTPå‹•è©ç­‰ã®ã‚ˆã‚Šã‚¸ã‚§ãƒãƒªãƒƒã‚¯ã§çµ±ä¸€ã•ã‚ŒãŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¾ã™ã€‚ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã§ã‚ã‚‹ã®ã§RESTã¯æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã«æœ€é©ã§ã™ã€‚æ¬ ç‚¹: RESTRESTã¯ãƒ‡ãƒ¼ã‚¿å…¬é–‹ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã®ã§ã€ãƒªã‚½ãƒ¼ã‚¹ãŒè‡ªç„¶ã«æ•´ç†ã•ã‚Œã¦ã„ãªã‹ã£ãŸã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ã§è¡¨ã›ã‚‰ã‚Œãªã„æ™‚ã«ã¯ã‚ˆã„é¸æŠè‚¢ã¨ã¯è¨€ãˆãªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€ã¨ã‚ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã«ãƒãƒƒãƒã™ã‚‹ã™ã¹ã¦ã®æ›´æ–°æƒ…å ±ã‚’è¿”ã™ã¨è¨€ã£ãŸå‡¦ç†ã¯ç°¡å˜ã«ã¯ãƒ‘ã‚¹ã§è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚RESTã§ã¯ã€URIãƒ‘ã‚¹ã€ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãã—ã¦å ´åˆã«ã‚ˆã£ã¦ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ãªã©ã«ã‚ˆã£ã¦å®Ÿè£…ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã§ã—ã‚‡ã†ã€‚RESTã¯å°‘æ•°ã®å‹•è©ã«ä¾å­˜ã—ã¦ã„ã¾ã™(GETã€POSTã€PUTã€DELETEã€ãã—ã¦ PATCH) ãŒæ™‚ã«ã¯ä½¿ã„ãŸã„äº‹ä¾‹ã«åˆã‚ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€æœŸé™ã®åˆ‡ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ç§»ã—ãŸã„å ´åˆãªã©ã¯ã“ã‚Œã‚‰ã®å‹•è©ã®ä¸­ã«ã¯ç¶ºéº—ã«ã¯ãƒ•ã‚£ãƒƒãƒˆã—ã¾ã›ã‚“ã€‚ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼ã®ä¸­ã«ã‚ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚’ã¨ã£ã¦ãã‚‹ã®ã¯ã‚·ãƒ³ã‚°ãƒ«ãƒ“ãƒ¥ãƒ¼ã‚’æç”»ã™ã‚‹ã®ã«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã‚µãƒ¼ãƒãƒ¼é–“ã§æ•°å›ã‚„ã‚Šã¨ã‚Šã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ä¾‹ã¨ã—ã¦ã€ãƒ–ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ãã‚Œã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤ºã™ã‚‹å ´åˆãªã©ã§ã™ã€‚æ§˜ã€…ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç’°å¢ƒã§å‹•ä½œã™ã‚‹å¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã‚‹ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã¯ã“ã®ã‚ˆã†ãªè¤‡æ•°ã®ã‚„ã‚Šå–ã‚Šã¯å¥½ã¾ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚æ™‚ãŒçµŒã¤ã«ã¤ã‚Œã¦ã€APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã‚ˆã‚Šå¤šãã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸ãˆã‚‰ã‚Œã¦ã€å¤ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ã™ã§ã«ã„ã‚‰ãªã„ã‚‚ã®ã‚‚å«ã‚ã¦ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å—ã‘å–ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚ãã®ã“ã¨ã§ã€ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãŒå¤§ãããªã‚Šã™ãã¦ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚‚æ‹¡å¤§ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚RPCã¨RESTæ¯”è¼ƒOperationRPCRESTã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—POST /signupPOST /personsãƒªã‚¶ã‚¤ãƒ³POST /resign{\""personid\"": \""1234\""}DELETE /persons/1234Personèª­ã¿è¾¼ã¿GET /readPerson?personid=1234GET /persons/1234Personã®ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿GET /readUsersItemsList?personid=1234GET /persons/1234/itemsPersonã®ã‚¢ã‚¤ãƒ†ãƒ ã¸ã®ã‚¢ã‚¤ãƒ†ãƒ è¿½åŠ POST /addItemToUsersItemsList{\""personid\"": \""1234\"";\""itemid\"": \""456\""}POST /persons/1234/items{\""itemid\"": \""456\""}ã‚¢ã‚¤ãƒ†ãƒ æ›´æ–°POST /modifyItem{\""itemid\"": \""456\"";\""key\"": \""value\""}PUT /items/456{\""key\"": \""value\""}ã‚¢ã‚¤ãƒ†ãƒ å‰Šé™¤POST /removeItem{\""itemid\"": \""456\""}DELETE /items/456  Source: Do you really know why you prefer REST over RPCãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸: REST ã¨ RPCDo you really know why you prefer REST over RPCWhen are RPC-ish approaches more appropriate than REST?REST vs JSON-RPCDebunking the myths of RPC and RESTWhat are the drawbacks of using RESTCrack the system design interviewThriftWhy REST for internal use and not RPCã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯æ›´æ–°ãŒå¿…è¦ã§ã™ã€‚contributingã—ã¦ãã ã•ã„ï¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¯å¹…åºƒã„ãƒˆãƒ”ãƒƒã‚¯ã§ã™ã€‚ååˆ†ãªçµŒé¨“ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†é‡ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãŒãªãã¦ã‚‚ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®çŸ¥è­˜ã‚’è¦ã™ã‚‹è·ã«å¿œå‹Ÿã™ã‚‹ã®ã§ãªã„é™ã‚Šã€åŸºæœ¬ä»¥ä¸Šã®ã“ã¨ã‚’çŸ¥ã‚‹å¿…è¦ã¯ãªã„ã§ã—ã‚‡ã†ã€‚æƒ…å ±ä¼é”ã€ä¿å­˜ã«ãŠã‘ã‚‹æš—å·åŒ–XSS ã‚„ SQL injectionã‚’é˜²ããŸã‚ã«ã€å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚‚ã—ãã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«éœ²å‡ºã•ã‚Œã‚‹å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã™ã‚‹SQL injectionã‚’é˜²ããŸã‚ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’ç”¨ã„ã‚‹ã€‚least privilegeã®åŸç†ã‚’ç”¨ã„ã‚‹ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:é–‹ç™ºè€…ã®ãŸã‚ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¬ã‚¤ãƒ‰OWASP top tenè£œéºæš—ç®—ã§ã€æ¨è¨ˆå€¤ã‚’æ±‚ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚‚æ™‚ã«ã¯ã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰100æšã‚¤ãƒ¡ãƒ¼ã‚¸åˆ†ã®ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ä½œã‚‹æ™‚é–“ã‚’æ±‚ã‚ãŸã‚Šã€ãã®æ™‚ã«ã©ã‚Œã ã‘ãƒ‡ã‚£ã‚¹ã‚¯ãƒ¡ãƒ¢ãƒªãƒ¼ãŒæ¶ˆè²»ã•ã‚Œã‚‹ã‹ãªã©ã®å€¤ã§ã™ã€‚2ã®ä¹—æ•°è¡¨ ã¨ å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ ã¯è‰¯ã„å‚è€ƒã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚2ã®ä¹—æ•°è¡¨ä¹—æ•°           å³å¯†ãªå€¤         ç´„        Bytes---------------------------------------------------------------7                             1288                             25610                           1024   1 thousand           1 KB16                         65,536                       64 KB20                      1,048,576   1 million            1 MB30                  1,073,741,824   1 billion            1 GB32                  4,294,967,296                        4 GB40              1,099,511,627,776   1 trillion           1 TBãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:2ã®ä¹—æ•°è¡¨å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤Latency Comparison Numbers--------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy            10,000   ns       10 usSend 1 KB bytes over 1 Gbps network     10,000   ns       10 usRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSDRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSDSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 msNotes-----1 ns = 10^-9 seconds1 us = 10^-6 seconds = 1,000 ns1 ms = 10^-3 seconds = 1,000 us = 1,000,000 nsä¸Šè¨˜è¡¨ã«åŸºã¥ã„ãŸå½¹ã«ç«‹ã¤æ•°å€¤:ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 30 MB/s1 Gbps Ethernetã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ã€€100 MB/sSSDã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 1 GB/smain memoryã‹ã‚‰ã®é€£ç¶šèª­ã¿å–ã‚Šé€Ÿåº¦ 4 GB/s1ç§’ã§åœ°çƒ6-7å‘¨ã§ãã‚‹1ç§’ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã¨2000å‘¨ã‚„ã‚Šã¨ã‚Šã§ãã‚‹ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã®è¦–è¦šçš„è¡¨ãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ - 1å…¨ã¦ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒçŸ¥ã‚‹ã¹ããƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼å€¤ - 2Designs, lessons, and advice from building large distributed systemsSoftware Engineering Advice from Building Large-Scale Distributed Systemsä»–ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥ä¾‹é¡Œé »å‡ºã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆé¢æ¥èª²é¡Œã¨ãã®è§£ç­”ã¸ã®ãƒªãƒ³ã‚¯è³ªå•è§£ç­”Dropboxã®ã‚ˆã†ãªãƒ•ã‚¡ã‚¤ãƒ«åŒæœŸã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­è¨ˆã™ã‚‹youtube.comGoogleã®ã‚ˆã†ãªæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­è¨ˆqueue.acm.orgstackexchange.comardendertat.comstanford.eduGoogleã®ã‚ˆã†ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªwebã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã®è¨­è¨ˆquora.comGoogle docsã®è¨­è¨ˆcode.google.comneil.fraser.nameRedisã®ã‚ˆã†ãªã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã®è¨­è¨ˆslideshare.netMemcachedã®ã‚ˆã†ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆslideshare.netAmazonã®ã‚ˆã†ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆhulu.comijcai13.orgBitlyã®ã‚ˆã†ãªURLçŸ­ç¸®ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆn00tc0d3r.blogspot.comWhatsAppã®ã‚ˆã†ãªãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã®è¨­è¨ˆhighscalability.comInstagramã®ã‚ˆã†ãªå†™çœŸå…±æœ‰ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆhighscalability.comhighscalability.comFacebookãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚£ãƒ¼ãƒ‰ã®è¨­è¨ˆquora.comquora.comslideshare.netFacebookã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®è¨­è¨ˆfacebook.comhighscalability.comFacebookãƒãƒ£ãƒƒãƒˆã®è¨­è¨ˆerlang-factory.comfacebook.comFacebookã®ã‚ˆã†ãªgraphæ¤œç´¢ã®è¨­è¨ˆfacebook.comfacebook.comfacebook.comCloudFlareã®ã‚ˆã†ãªCDNã®è¨­è¨ˆcmu.eduTwitterã®ãƒˆãƒ¬ãƒ³ãƒ‰æ©Ÿèƒ½ã®è¨­è¨ˆmichael-noll.comsnikolov .wordpress.comãƒ©ãƒ³ãƒ€ãƒ IDç™ºè¡Œã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆblog.twitter.comgithub.comä¸€å®šã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«æ™‚é–“ã§ã®ä¸Šä½kä»¶ã‚’è¿”ã™ucsb.eduwpi.eduè¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’é…ä¿¡ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­è¨ˆhighscalability.comã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®è¤‡æ•°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ ã®è¨­è¨ˆindieflashblog.combuildnewgames.comã‚¬ãƒ¼ãƒ™ãƒƒã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆstuffwithstuff.comwashington.eduã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆä¾‹é¡Œã‚’è¿½åŠ ã™ã‚‹Contributeå®Ÿä¸–ç•Œã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸–ã®ä¸­ã®ã‚·ã‚¹ãƒ†ãƒ ãŒã©ã®ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã®è¨˜äº‹      Source: Twitter timelines at scaleä»¥ä¸‹ã®è¨˜äº‹ã®é‡ç®±ã®éš…ã‚’ã¤ã¤ãã‚ˆã†ãªç´°ã‹ã„è©³ç´°ã«ã“ã ã‚ã‚‰ãªã„ã“ã¨ã€‚ã‚€ã—ã‚å…±é€šã®åŸç†ã€æŠ€è¡“ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã‚‹ã“ã¨ãã‚Œãã‚Œã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã©ã‚“ãªå•é¡ŒãŒè§£æ±ºã•ã‚Œã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¯ã©ã“ã§ã†ã¾ãä½¿ãˆã‚‚ã—ãã¯ä½¿ãˆãªã„ã‹ã‚’çŸ¥ã‚‹ã“ã¨å­¦ã‚“ã ã“ã¨ã‚’å¾©ç¿’ã™ã‚‹ã“ã¨ç¨®é¡ã‚·ã‚¹ãƒ†ãƒ å‚è€ƒãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿å‡¦ç†MapReduce - Googleã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ research.google.comãƒ‡ãƒ¼ã‚¿å‡¦ç†Spark - Databricksã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿å‡¦ç†Storm - Twitterã®åˆ†æ•£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Bigtable - Googleã®ã‚«ãƒ©ãƒ æŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹harvard.eduãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢HBase - Bigtableã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Cassandra - Facebookã®ã‚«ãƒ©ãƒ æŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢DynamoDB - Amazonã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹harvard.eduãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢MongoDB - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŒ‡å‘åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Spanner - Googleã®ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆ†æ•£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹research.google.comãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Memcached - åˆ†æ•£ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢Redis - æ°¸ç¶šæ€§ã¨ãƒãƒªãƒ¥ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’å…¼ã­å‚™ãˆãŸåˆ†æ•£ãƒ¡ãƒ¢ãƒªãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ slideshare.netãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ Google File System (GFS) - åˆ†æ•£ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ research.google.comãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ Hadoop File System (HDFS) - GFSã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…apache.orgMiscChubby - ç–çµåˆã®åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ­ãƒƒã‚¯ã™ã‚‹Googleã®ã‚µãƒ¼ãƒ“ã‚¹research.google.comMiscDapper - åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ã‚’è¿½è·¡ã™ã‚‹ã‚¤ãƒ³ãƒ•ãƒ©research.google.comMiscKafka - LinkedInã«ã‚ˆã‚‹Pub/subãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼slideshare.netMiscZookeeper - åŒæœŸã‚’å¯èƒ½ã«ã™ã‚‹ä¸­å¤®é›†æ¨©ã‚¤ãƒ³ãƒ•ãƒ©ã¨ã‚µãƒ¼ãƒ“ã‚¹slideshare.netã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¿½åŠ ã™ã‚‹Contributeå„ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¼æ¥­å‚è€ƒãƒšãƒ¼ã‚¸AmazonAmazon architectureCinchcastProducing 1,500 hours of audio every dayDataSiftRealtime datamining At 120,000 tweets per secondDropBoxHow we've scaled DropboxESPNOperating At 100,000 duh nuh nuhs per secondGoogleGoogle architectureInstagram14 million users, terabytes of photosWhat powers InstagramJustin.tvJustin.Tv's live video broadcasting architectureFacebookScaling memcached at FacebookTAO: Facebookâ€™s distributed data store for the social graphFacebookâ€™s photo storageFlickrFlickr architectureMailboxFrom 0 to one million users in 6 weeksPinterestFrom 0 To 10s of billions of page views a month18 million visitors, 10x growth, 12 employeesPlayfish50 million monthly users and growingPlentyOfFishPlentyOfFish architectureSalesforceHow they handle 1.3 billion transactions a dayStack OverflowStack Overflow architectureTripAdvisor40M visitors, 200M dynamic page views, 30TB dataTumblr15 billion page views a monthTwitterMaking Twitter 10000 percent fasterStoring 250 million tweets a day using MySQL150M active users, 300K QPS, a 22 MB/S firehoseTimelines at scaleBig and small data at TwitterOperations at Twitter: scaling beyond 100 million usersUberHow Uber scales their real-time market platformWhatsAppThe WhatsApp architecture Facebook bought for $19 billionYouTubeYouTube scalabilityYouTube architectureä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°é¢æ¥ã‚’å—ã‘ã‚‹ä¼æ¥­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æŠ•ã’ã‚‰ã‚Œã‚‹è³ªå•ã¯åŒã˜åˆ†é‡ã‹ã‚‰æ¥ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã§ã—ã‚‡ã†Airbnb EngineeringAtlassian DevelopersAutodesk EngineeringAWS BlogBitly Engineering BlogBox BlogsCloudera Developer BlogDropbox Tech BlogEngineering at QuoraEbay Tech BlogEvernote Tech BlogEtsy Code as CraftFacebook EngineeringFlickr CodeFoursquare Engineering BlogGitHub Engineering BlogGoogle Research BlogGroupon Engineering BlogHeroku Engineering BlogHubspot Engineering BlogHigh ScalabilityInstagram EngineeringIntel Software BlogJane Street Tech BlogLinkedIn EngineeringMicrosoft EngineeringMicrosoft Python EngineeringNetflix Tech BlogPaypal Developer BlogPinterest Engineering BlogQuora EngineeringReddit BlogSalesforce Engineering BlogSlack Engineering BlogSpotify LabsTwilio Engineering BlogTwitter EngineeringUber Engineering BlogYahoo Engineering BlogYelp Engineering BlogZynga Engineering Blogãã®ä»–ã®å‚è€ƒè³‡æ–™ã€ãƒšãƒ¼ã‚¸:kilimchoi/engineering-blogsã“ã“ã«ã‚ã‚‹ãƒªã‚¹ãƒˆã¯æ¯”è¼ƒçš„å°è¦æ¨¡ãªã‚‚ã®ã«ã¨ã©ã‚ã€kilimchoi/engineering-blogsã«ã‚ˆã‚Šè©³ç´°ã«è¨˜ã™ã“ã¨ã§é‡è¤‡ã—ãªã„ã‚ˆã†ã«ã—ã¦ãŠãã“ã¨ã«ã™ã‚‹ã€‚ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ–ãƒ­ã‚°ã¸ã®ãƒªãƒ³ã‚¯ã‚’è¿½åŠ ã™ã‚‹å ´åˆã¯ã“ã“ã§ã¯ãªãã€engineering-blogsãƒ¬ãƒœã‚¸ãƒˆãƒªã«è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚é€²è¡Œä¸­ã®ä½œæ¥­ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¿½åŠ ã‚„ã€é€²è¡Œä¸­ã®ä½œæ¥­ã‚’æ‰‹ä¼ã£ã¦ã„ãŸã ã‘ã‚‹å ´åˆã¯ã“ã¡ã‚‰!MapReduceã«ã‚ˆã‚‹åˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°Consistent hashingScatter gatherContributeã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¯ãƒ¬ã‚¸ãƒƒãƒˆåŠã³ã€å‚ç…§ãƒšãƒ¼ã‚¸ã¯é©æ™‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªå†…ã«è¨˜è¼‰ã—ã¦ã‚ã‚Šã¾ã™Special thanks to:Hired in techCracking the coding interviewHigh scalabilitycheckcheckzz/system-design-interviewshashank88/system_designmmcgrana/services-engineeringSystem design cheat sheetA distributed systems reading listCracking the system design interviewContact infoFeel free to contact me to discuss any issues, questions, or comments.My contact info can be found on my GitHub page.LicenseI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2017 Donne MartinCreative Commons Attribution 4.0 International License (CC BY 4.0)http://creativecommons.org/licenses/by/4.0/"
69,AUTOMATIC1111/stable-diffusion-webui,https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/README.md,Python,"Stable Diffusion web UIA browser interface based on Gradio library for Stable Diffusion.FeaturesDetailed feature showcase with images:Original txt2img and img2img modesOne click install and run script (but you still must install python and git)OutpaintingInpaintingColor SketchPrompt MatrixStable Diffusion UpscaleAttention, specify parts of text that the model should pay more attention toa man in a ((tuxedo)) - will pay more attention to tuxedoa man in a (tuxedo:1.21) - alternative syntaxselect text and press Ctrl+Up or Ctrl+Down (or Command+Up or Command+Down if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)Loopback, run img2img processing multiple timesX/Y/Z plot, a way to draw a 3 dimensional plot of images with different parametersTextual Inversionhave as many embeddings as you want and use any names you like for themuse multiple embeddings with different numbers of vectors per tokenworks with half precision floating point numberstrain embeddings on 8GB (also reports of 6GB working)Extras tab with:GFPGAN, neural network that fixes facesCodeFormer, face restoration tool as an alternative to GFPGANRealESRGAN, neural network upscalerESRGAN, neural network upscaler with a lot of third party modelsSwinIR and Swin2SR (see here), neural network upscalersLDSR, Latent diffusion super resolution upscalingResizing aspect ratio optionsSampling method selectionAdjust sampler eta values (noise multiplier)More advanced noise setting optionsInterrupt processing at any time4GB video card support (also reports of 2GB working)Correct seeds for batchesLive prompt token length validationGeneration parametersparameters you used to generate images are saved with that imagein PNG chunks for PNG, in EXIF for JPEGcan drag the image to PNG info tab to restore generation parameters and automatically copy them into UIcan be disabled in settingsdrag and drop an image/text-parameters to promptboxRead Generation Parameters Button, loads parameters in promptbox to UISettings pageRunning arbitrary python code from UI (must run with --allow-code to enable)Mouseover hints for most UI elementsPossible to change defaults/mix/max/step values for UI elements via text configTiling support, a checkbox to create images that can be tiled like texturesProgress bar and live image generation previewCan use a separate neural network to produce previews with almost none VRAM or compute requirementNegative prompt, an extra text field that allows you to list what you don't want to see in generated imageStyles, a way to save part of prompt and easily apply them via dropdown laterVariations, a way to generate same image but with tiny differencesSeed resizing, a way to generate same image but at slightly different resolutionCLIP interrogator, a button that tries to guess prompt from an imagePrompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midwayBatch Processing, process a group of files using img2imgImg2img Alternative, reverse Euler method of cross attention controlHighres Fix, a convenience option to produce high resolution pictures in one click without usual distortionsReloading checkpoints on the flyCheckpoint Merger, a tab that allows you to merge up to 3 checkpoints into oneCustom scripts with many extensions from communityComposable-Diffusion, a way to use multiple prompts at onceseparate prompts using uppercase ANDalso supports weights for prompts: a cat :1.2 AND a dog AND a penguin :2.2No token limit for prompts (original stable diffusion lets you use up to 75 tokens)DeepDanbooru integration, creates danbooru style tags for anime promptsxformers, major speed increase for select cards: (add --xformers to commandline args)via extension: History tab: view, direct and delete images conveniently within the UIGenerate forever optionTraining tabhypernetworks and embeddings optionsPreprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)Clip skipHypernetworksLoras (same as Hypernetworks but more pretty)A sparate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your promptCan select to load a different VAE from settings screenEstimated completion time in progress barAPISupport for dedicated inpainting model by RunwayMLvia extension: Aesthetic Gradients, a way to generate images with a specific aesthetic by using clip images embeds (implementation of https://github.com/vicgalle/stable-diffusion-aesthetic-gradients)Stable Diffusion 2.0 support - see wiki for instructionsAlt-Diffusion support - see wiki for instructionsNow without any bad letters!Load checkpoints in safetensors formatEased resolution restriction: generated image's domension must be a multiple of 8 rather than 64Now with a license!Reorder elements in the UI from settings screenInstallation and RunningMake sure the required dependencies are met and follow the instructions available for both NVidia (recommended) and AMD GPUs.Alternatively, use online services (like Google Colab):List of Online ServicesInstallation on Windows 10/11 with NVidia-GPUs using release packageDownload sd.webui.zip from v1.0.0-pre and extract it's contents.Run update.bat.Run run.bat.For more details see Install-and-Run-on-NVidia-GPUsAutomatic Installation on WindowsInstall Python 3.10.6 (Newer version of Python does not support torch), checking \""Add Python to PATH\"".Install git.Download the stable-diffusion-webui repository, for example by running git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git.Run webui-user.bat from Windows Explorer as normal, non-administrator, user.Automatic Installation on LinuxInstall the dependencies:# Debian-based:sudo apt install wget git python3 python3-venv# Red Hat-based:sudo dnf install wget git python3# Arch-based:sudo pacman -S wget git python3Navigate to the directory you would like the webui to be installed and execute the following command:bash <(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)Run webui.sh.Check webui-user.sh for options.Installation on Apple SiliconFind the instructions here.ContributingHere's how to add code to this repo: ContributingDocumentationThe documentation was moved from this README over to the project's wiki.For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) crawlable wiki.CreditsLicenses for borrowed code can be found in Settings -> Licenses screen, and also in html/licenses.html file.Stable Diffusion - https://github.com/CompVis/stable-diffusion, https://github.com/CompVis/taming-transformersk-diffusion - https://github.com/crowsonkb/k-diffusion.gitGFPGAN - https://github.com/TencentARC/GFPGAN.gitCodeFormer - https://github.com/sczhou/CodeFormerESRGAN - https://github.com/xinntao/ESRGANSwinIR - https://github.com/JingyunLiang/SwinIRSwin2SR - https://github.com/mv-lab/swin2srLDSR - https://github.com/Hafiidz/latent-diffusionMiDaS - https://github.com/isl-org/MiDaSIdeas for optimizations - https://github.com/basujindal/stable-diffusionCross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)Sub-quadratic Cross Attention layer optimization - Alex Birch (Birch-san/diffusers#1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we're not using his code, but we are using his ideas).Idea for SD upscale - https://github.com/jquesnelle/txt2imghdNoise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-botCLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogatorIdea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorchxformers - https://github.com/facebookresearch/xformersDeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooruSampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pixSecurity advice - RyotaKUniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPCTAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesdLyCORIS - KohakuBlueleafInitial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.(You)"
70,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
71,pallets/flask,https://github.com/pallets/flask/blob/main/README.rst,Python,"FlaskFlask is a lightweight WSGI web application framework. It is designedto make getting started quick and easy, with the ability to scale up tocomplex applications. It began as a simple wrapper around Werkzeugand Jinja and has become one of the most popular Python webapplication frameworks.Flask offers suggestions, but doesn't enforce any dependencies orproject layout. It is up to the developer to choose the tools andlibraries they want to use. There are many extensions provided by thecommunity that make adding new functionality easy.InstallingInstall and update using pip:$ pip install -U FlaskA Simple Example# save this as app.pyfrom flask import Flaskapp = Flask(__name__)@app.route(\""/\"")def hello():    return \""Hello, World!\""$ flask run  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)ContributingFor guidance on setting up a development environment and how to make acontribution to Flask, see the contributing guidelines.DonateThe Pallets organization develops and supports Flask and the librariesit uses. In order to grow the community of contributors and users, andallow the maintainers to devote more time to the projects, pleasedonate today.LinksDocumentation: https://flask.palletsprojects.com/Changes: https://flask.palletsprojects.com/changes/PyPI Releases: https://pypi.org/project/Flask/Source Code: https://github.com/pallets/flask/Issue Tracker: https://github.com/pallets/flask/issues/Chat: https://discord.gg/pallets"
72,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.âš ï¸ IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!âš ï¸ IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means youâ€™ve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the projectâ€™s direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a projectâ€™s website for a â€œteamâ€ page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participantsâ€™ behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, â€œHow do Iâ€¦â€œ or â€œWhat do you think aboutâ€¦â€œ instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
73,geekcomputers/Python,https://github.com/geekcomputers/Python/blob/master/README.md,Python,"My Python Eggs ğŸ ğŸ˜„I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in Notepad++ ğŸ—’ï¸Feel free to explore the scripts and use them for your learning and automation needs!List of Scripts:batch_file_rename.py - Batch rename a group of files in a specified directory, changing their extensions.create_dir_if_not_there.py - Check if a directory exists in the user's home directory. Create it if it doesn't exist.Fast Youtube Downloader - Download YouTube videos quickly with parallel threads using aria2c.Google Image Downloader - Query a given term and retrieve images from the Google Image database.dir_test.py - Test if the directory testdir exists. If not, create it.env_check.py - Check if all the required environment variables are set.blackjack.py - Casino Blackjack-21 game in Python.fileinfo.py - Show file information for a given file.folder_size.py - Scan the current directory and all subdirectories and display their sizes.logs.py - Search for all *.log files in a directory, zip them using the specified program, and date stamp them.move_files_over_x_days.py - Move all files over a specified age (in days) from the source directory to the destination directory.nslookup_check.py - Open the file server_list.txt and perform nslookup for each server to check the DNS entry.osinfo.py - Display information about the operating system on which the script is running.ping_servers.py - Ping the servers associated with the specified application group.ping_subnet.py - Scan the final range of a given IP subnet for available addresses.powerdown_startup.py - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.puttylogs.py - Zip all the logs in the given directory.script_count.py - Scan the scripts directory and count the different types of scripts.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.script_listing.py - List all files in a given directory and its subdirectories.testlines.py - Open a file and print out 100 lines of the set line variable.tweeter.py - Tweet text or a picture from the terminal.serial_scanner.py - List available serial ports in use on Linux and Windows systems.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.CountMillionCharacter.py and CountMillionCharacter2.0 - Get character count of a text file.xkcd_downloader.py - Download the latest XKCD comic and place them in a new folder called \""comics\"".timymodule.py - An alternative to Python's 'timeit' module and easier to use.calculator.py - Implement a calculator using Python's eval() function.Google_News.py - Use BeautifulSoup to provide latest news headlines along with news links.cricket_live_score - Use BeautifulSoup to provide live cricket scores.youtube.py - Take a song name as input and fetch the YouTube URL of the best matching song and play it.site_health.py - Check the health of a remote server.SimpleStopWatch.py - Simple stop watch implementation using Python's time module.Changemac.py - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).whatsapp-monitor.py - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.whatsapp-chat-analyzer.py - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.JARVIS.py - Control Windows programs with your voice.Images Downloader - Download images from webpages on Unix-based systems.space_invader.py.py - Classical 2D space invader game to recall your childhood memories.Test Case Generator - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.Note: The content in this repository belongs to the respective authors and creators. I'm just providing a formatted README.md for better presentation."
74,udacity/fullstack-nanodegree-vm,https://github.com/udacity/fullstack-nanodegree-vm/blob/master/README.md,Python,"Full Stack Web Developer Nanodegree program virtual machine  Virtual machine for the Relational Databases and Full Stack Foundations courses in the Full Stack Web Developer Nanodegree programTable of ContentsTable of ContentsIntroInstallationInstructionsTroubleshootingSupporting MaterialsIntroIn the next part of this course, you'll use a virtual machine (VM) to run an SQL database server and a web app that uses it. The VM is a Linux server system that runs on top of your own computer. You can share files easily between your computer and the VM; and you'll be running a web service inside the VM which you'll be able to access from your regular browser.We're using tools called Vagrant and VirtualBox to install and manage the VM. You'll need to install these to do some of the exercises. The instructions on this page will help you do this.Conceptual overviewThis video offers a conceptual overview of virtual machines and Vagrant. You don't need to watch it to proceed, but you may find it informative.Use a terminalYou'll be doing these exercises using a Unix-style terminal on your computer. If you are using a Mac or Linux system, your regular terminal program will do just fine. On Windows, we recommend using the Git Bash terminal that comes with the Git software. If you don't already have Git installed, download Git from git-scm.com.For a refresher on using the Unix shell, look back at our Shell Workshop.If you'd like to learn more about Git, take a look at our course about Git.InstallationInstall VirtualBoxVirtualBox is the software that actually runs the virtual machine. You can download it from virtualbox.org, here. Install the platform package for your operating system. You do not need the extension pack or the SDK. You do not need to launch VirtualBox after installing it; Vagrant will do that.Currently (October 2017), the supported version of VirtualBox to install is version 5.1. Newer versions do not work with the current release of Vagrant.Ubuntu users: If you are running Ubuntu 14.04, install VirtualBox using the Ubuntu Software Center instead. Due to a reported bug, installing VirtualBox from the site may uninstall other software you need.Install VagrantVagrant is the software that configures the VM and lets you share files between your host computer and the VM's filesystem. Download it from vagrantup.com. Install the version for your operating system.Windows users: The Installer may ask you to grant network permissions to Vagrant or make a firewall exception. Be sure to allow this.If Vagrant is successfully installed, you will be able to run vagrant --versionin your terminal to see the version number.The shell prompt in your terminal may differ. Here, the $ sign is the shell prompt.Download the VM configurationUse Github to fork and clone, or download, the repository https://github.com/udacity/fullstack-nanodegree-vm.You will end up with a new directory containing the VM files. Change to this directory in your terminal with cd. Inside, you will find another directory called vagrant. Change directory to the vagrant directory:Navigating to the FSND-Virtual-Machine directory and listing the files in it.This picture was taken on a Mac, but the commands will look the same on Git Bash on Windows.InstructionsStart the virtual machineFrom your terminal, inside the vagrant subdirectory, run the command vagrant up. This will cause Vagrant to download the Linux operating system and install it. This may take quite a while (many minutes) depending on how fast your Internet connection is.Starting the Ubuntu Linux installation with vagrant up.This screenshot shows just the beginning of many, many pages of output in a lot of colors.When vagrant up is finished running, you will get your shell prompt back. At this point, you can run vagrant ssh to log in to your newly installed Linux VM!Logging into the Linux VM with vagrant ssh.Logged inIf you are now looking at a shell prompt that starts with the word vagrant (as in the above screenshot), congratulations â€” you've gotten logged into your Linux VM.If not, take a look at the Troubleshooting section below.The files for this courseInside the VM, change directory to /vagrant and look around with ls.The files you see here are the same as the ones in the vagrant subdirectory on your computer (where you started Vagrant from). Any file you create in one will be automatically shared to the other. This means that you can edit code in your favorite text editor, and run it inside the VM.Files in the VM's /vagrant directory are shared with the vagrant folder on your computer. But other data inside the VM is not. For instance, the PostgreSQL database itself lives only inside the VM.Running the databaseThe PostgreSQL database server will automatically be started inside the VM. You can use the psql command-line tool to access it and run SQL statements:Running psql, the PostgreSQL command interface, inside the VM.Logging out and inIf you type exit (or Ctrl-D) at the shell prompt inside the VM, you will be logged out, and put back into your host computer's shell. To log back in, make sure you're in the same directory and type vagrant ssh again.If you reboot your computer, you will need to run vagrant up to restart the VM.TroubleshootingI'm not sure if it workedIf you can type vagrant ssh and log into your VM, then it worked! It's normal for the vagrant up process to display a lot of text in many colors, including sometimes scary-looking messages in red, green, and purple. If you get your shell prompt back at the end, and you can log in, it should be OK.vagrant up is taking a long timeBecause it's downloading a whole Linux operating system from the Internet.I'm on Windows, and when I run vagrant ssh, I don't get a shell promptSome versions of Windows and Vagrant have a problem communicating the right settings for the terminal. There is a workaround: Instead of vagrant ssh, run the command winpty vagrant ssh instead.I'm on Windows and getting an error about virtualizationSometimes other virtualization programs such as Docker or Hyper-V can interfere with VirtualBox. Try shutting these other programs down first.In addition, some Windows PCs have settings in the BIOS or UEFI (firmware) or in the operating system that disable the use of virtualization. To change this, you may need to reboot your computer and access the firmware settings. A web search can help you find the settings for your computer and operating system. Unfortunately there are so many different versions of Windows and PCs that we can't offer a simple guide to doing this.Why are we using a VM, it seems complicatedIt is complicated. In this case, the point of it is to be able to offer the same software (Linux and PostgreSQL) regardless of what kind of computer you're running on.I got some other error messageIf you're getting a specific textual error message, try looking it up on your favorite search engine. If that doesn't help, take a screenshot and post it to the discussion forums, along with as much detail as you can provide about the process you went through to get there.If all else fails, try an older versionUdacity mentors have noticed that some newer versions of Vagrant don't work on all operating systems. Version 1.9.2 is reported to be stabler on some systems, and version 1.9.1 is the supported version on Ubuntu 17.04. You can download older versions of Vagrant from the Vagrant releases index.Supporting MaterialsVirtual machine repository on GitHub(Back to TOC)"
75,apachecn/ailearning,https://github.com/apachecn/ailearning/blob/master/README.md,Python,"                                AI learningåè®®ï¼šCC BY-NC-SA 4.0ä¸€ç§æ–°æŠ€æœ¯ä¸€æ—¦å¼€å§‹æµè¡Œï¼Œä½ è¦ä¹ˆåä¸Šå‹è·¯æœºï¼Œè¦ä¹ˆæˆä¸ºé“ºè·¯çŸ³ã€‚â€”â€”Stewart Brandåœ¨çº¿é˜…è¯»åœ¨çº¿é˜…è¯»ï¼ˆv1ï¼‰QuantLearningApacheCN ä¸­æ–‡ç¿»è¯‘ç»„ 713436582ApacheCN å­¦ä¹ èµ„æºæ³¨: å¹¿å‘Šä½åˆä½œ(ç‰©ç¾ä»·å»‰)ï¼Œè¯·è”ç³» apachecn@163.comè·¯çº¿å›¾å…¥é—¨åªçœ‹: æ­¥éª¤ 1 => 2 => 3ï¼Œä½ å¯ä»¥å½“å¤§ç‰›ï¼ä¸­çº§è¡¥å…… - èµ„æ–™åº“: https://github.com/apachecn/ai-roadmapè¡¥å……ç®—æ³•åˆ·é¢˜: https://www.ixigua.com/pseries/6822642486343631363/é¢è¯•æ±‚èŒ: https://www.ixigua.com/pseries/6822563009391493636/æœºå™¨å­¦ä¹ å®æˆ˜: https://www.ixigua.com/pseries/6822816341615968772/NLPæ•™å­¦è§†é¢‘: https://www.ixigua.com/pseries/6828241431295951373/AIå¸¸ç”¨å‡½æ•°è¯´æ˜: https://github.com/apachecn/AiLearning/tree/master/AIå¸¸ç”¨å‡½æ•°è¯´æ˜.md1.æœºå™¨å­¦ä¹  - åŸºç¡€æ”¯æŒç‰ˆæœ¬VersionSupported3.6.xâŒ2.7.xâœ…æ³¨æ„äº‹é¡¹:æœºå™¨å­¦ä¹ å®æˆ˜: ä»…ä»…åªæ˜¯å­¦ä¹ ï¼Œè¯·ä½¿ç”¨ python 2.7.x ç‰ˆæœ¬ ï¼ˆ3.6.x åªæ˜¯ä¿®æ”¹äº†éƒ¨åˆ†ï¼‰åŸºæœ¬ä»‹ç»èµ„æ–™æ¥æº: Machine Learning in Action(æœºå™¨å­¦ä¹ å®æˆ˜-ä¸ªäººç¬”è®°)ç»Ÿä¸€æ•°æ®åœ°å€: https://github.com/apachecn/dataç™¾åº¦äº‘æ‰“åŒ…åœ°å€: apachecn/data#3ä¹¦ç±ä¸‹è½½åœ°å€: https://github.com/apachecn/data/tree/master/bookæœºå™¨å­¦ä¹ ä¸‹è½½åœ°å€: https://github.com/apachecn/data/tree/master/æœºå™¨å­¦ä¹ æ·±åº¦å­¦ä¹ æ•°æ®åœ°å€: https://github.com/apachecn/data/tree/master/æ·±åº¦å­¦ä¹ æ¨èç³»ç»Ÿæ•°æ®åœ°å€: https://github.com/apachecn/data/tree/master/æ¨èç³»ç»Ÿè§†é¢‘ç½‘ç«™: ä¼˜é…· ï¼bilibili / Acfun / ç½‘æ˜“äº‘è¯¾å ‚ï¼Œå¯ç›´æ¥åœ¨çº¿æ’­æ”¾ã€‚ï¼ˆæœ€ä¸‹æ–¹æœ‰ç›¸åº”é“¾æ¥ï¼‰-- æ¨è çº¢è‰²çŸ³å¤´: å°æ¹¾å¤§å­¦æ—è½©ç”°æœºå™¨å­¦ä¹ ç¬”è®°-- æ¨è æœºå™¨å­¦ä¹ ç¬”è®°: https://feisky.xyz/machine-learningå­¦ä¹ æ–‡æ¡£æ¨¡å—ç« èŠ‚ç±»å‹è´Ÿè´£äºº(GitHub)QQæœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 1 ç« : æœºå™¨å­¦ä¹ åŸºç¡€ä»‹ç»@æ¯›çº¢åŠ¨1306014226æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 2 ç« : KNN è¿‘é‚»ç®—æ³•åˆ†ç±»@å°¤æ°¸æ±Ÿ279393323æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 3 ç« : å†³ç­–æ ‘åˆ†ç±»@æ™¯æ¶›844300439æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 4 ç« : æœ´ç´ è´å¶æ–¯åˆ†ç±»@wnma3mz@åˆ†æ1003324213244970749æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 5 ç« : Logisticå›å½’åˆ†ç±»@å¾®å…‰åŒå°˜529925688æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 6 ç« : SVM æ”¯æŒå‘é‡æœºåˆ†ç±»@ç‹å¾·çº¢934969547ç½‘ä¸Šç»„åˆå†…å®¹ç¬¬ 7 ç« : é›†æˆæ–¹æ³•ï¼ˆéšæœºæ£®æ—å’Œ AdaBoostï¼‰åˆ†ç±»@ç‰‡åˆ»529815144æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 8 ç« : å›å½’å›å½’@å¾®å…‰åŒå°˜529925688æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 9 ç« : æ ‘å›å½’å›å½’@å¾®å…‰åŒå°˜529925688æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 10 ç« : K-Means èšç±»èšç±»@å¾æ˜­æ¸…827106588æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 11 ç« : åˆ©ç”¨ Apriori ç®—æ³•è¿›è¡Œå…³è”åˆ†æé¢‘ç¹é¡¹é›†@åˆ˜æµ·é£1049498972æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 12 ç« : FP-growth é«˜æ•ˆå‘ç°é¢‘ç¹é¡¹é›†é¢‘ç¹é¡¹é›†@ç¨‹å¨842725815æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 13 ç« : åˆ©ç”¨ PCA æ¥ç®€åŒ–æ•°æ®å·¥å…·@å»–ç«‹å¨Ÿ835670618æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 14 ç« : åˆ©ç”¨ SVD æ¥ç®€åŒ–æ•°æ®å·¥å…·@å¼ ä¿Šçš“714974242æœºå™¨å­¦ä¹ å®æˆ˜ç¬¬ 15 ç« : å¤§æ•°æ®ä¸ MapReduceå·¥å…·@wnma3mz1003324213Mlé¡¹ç›®å®æˆ˜ç¬¬ 16 ç« : æ¨èç³»ç»Ÿï¼ˆå·²è¿ç§»ï¼‰é¡¹ç›®æ¨èç³»ç»Ÿï¼ˆè¿ç§»ååœ°å€ï¼‰ç¬¬ä¸€æœŸçš„æ€»ç»“2017-04-08: ç¬¬ä¸€æœŸçš„æ€»ç»“æ€»ç»“æ€»ç»“529815144ç½‘ç«™è§†é¢‘çŸ¥ä¹é—®ç­”-çˆ†ç‚¸å•¦-æœºå™¨å­¦ä¹ è¯¥æ€ä¹ˆå…¥é—¨ï¼Ÿå½“ç„¶æˆ‘çŸ¥é“ï¼Œç¬¬ä¸€å¥å°±ä¼šè¢«åæ§½ï¼Œå› ä¸ºç§‘ç­å‡ºèº«çš„äººï¼Œä¸å±‘çš„åäº†ä¸€å£å”¾æ²«ï¼Œè¯´å‚»Xï¼Œè¿˜è¯„è®º Andrew Ng çš„è§†é¢‘ã€‚ã€‚æˆ‘è¿˜çŸ¥é“è¿˜æœ‰ä¸€éƒ¨åˆ†äººï¼Œçœ‹ Andrew Ng çš„è§†é¢‘å°±æ˜¯çœ‹ä¸æ‡‚ï¼Œé‚£ç¥ç§˜çš„æ•°å­¦æ¨å¯¼ï¼Œé‚£è¿·ä¹‹å¾®ç¬‘çš„è‹±æ–‡ç‰ˆçš„æ•™å­¦ï¼Œæˆ‘ä½•å°åˆä¸æ˜¯è¿™æ ·èµ°è¿‡æ¥çš„ï¼Ÿï¼Ÿ æˆ‘çš„å¿ƒå¯èƒ½æ¯”ä½ ä»¬éƒ½ç—›ï¼Œå› ä¸ºæˆ‘åœ¨ç½‘ä¸Šæ”¶è—è¿‡ä¸Š10éƒ¨ã€Šæœºå™¨å­¦ä¹ ã€‹ç›¸å…³è§†é¢‘ï¼Œå¤–åŠ å›½å†…æœ¬åœŸé£æ ¼çš„æ•™ç¨‹: 7æœˆ+å°è±¡ ç­‰ç­‰ï¼Œæˆ‘éƒ½å¾ˆéš¾å»å¬æ‡‚ï¼Œç›´åˆ°æœ‰ä¸€å¤©ï¼Œè¢«ä¸€ä¸ªç™¾åº¦çš„é«˜çº§ç®—æ³•åˆ†æå¸ˆæ¨èè¯´: ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹è¿˜ä¸é”™ï¼Œé€šä¿—æ˜“æ‡‚ï¼Œä½ å»è¯•è¯•ï¼Ÿï¼Ÿæˆ‘è¯•äº†è¯•ï¼Œè¿˜å¥½æˆ‘çš„PythonåŸºç¡€å’Œè°ƒè¯•èƒ½åŠ›è¿˜ä¸é”™ï¼ŒåŸºæœ¬ä¸Šä»£ç éƒ½è°ƒè¯•è¿‡ä¸€éï¼Œå¾ˆå¤šé«˜å¤§ä¸Šçš„ \""ç†è®º+æ¨å¯¼\""ï¼Œåœ¨æˆ‘çœ¼ä¸­å˜æˆäº†å‡ ä¸ª \""åŠ å‡ä¹˜é™¤+å¾ªç¯\""ï¼Œæˆ‘æƒ³è¿™ä¸å°±æ˜¯åƒæˆ‘è¿™æ ·çš„ç¨‹åºå‘˜æƒ³è¦çš„å…¥é—¨æ•™ç¨‹ä¹ˆï¼Ÿå¾ˆå¤šç¨‹åºå‘˜è¯´æœºå™¨å­¦ä¹  TM å¤ªéš¾å­¦äº†ï¼Œæ˜¯çš„ï¼ŒçœŸ TM éš¾å­¦ï¼Œæˆ‘æƒ³æœ€éš¾çš„æ˜¯: æ²¡æœ‰ä¸€æœ¬åƒã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹é‚£æ ·çš„ä½œè€…æ„¿æ„ä»¥ç¨‹åºå‘˜ Coding è§’åº¦å»ç»™å¤§å®¶è®²è§£ï¼ï¼æœ€è¿‘å‡ å¤©ï¼ŒGitHub æ¶¨äº† 300é¢— starï¼ŒåŠ ç¾¤çš„200äººï¼Œ ç°åœ¨è¿˜åœ¨ä¸æ–­çš„å¢åŠ ++ï¼Œæˆ‘æƒ³å¤§å®¶å¯èƒ½éƒ½æ˜¯æ„ŸåŒèº«å—å§ï¼å¾ˆå¤šæƒ³å…¥é—¨æ–°æ‰‹å°±æ˜¯è¢«å¿½æ‚ ç€æ”¶è—æ”¶è—å†æ”¶è—ï¼Œä½†æ˜¯æœ€åè¿˜æ˜¯ä»€ä¹ˆéƒ½æ²¡æœ‰å­¦åˆ°ï¼Œä¹Ÿå°±æ˜¯\""èµ„æºæ”¶è—å®¶\""ï¼Œä¹Ÿè®¸æ–°æ‰‹è¦çš„å°±æ˜¯ MachineLearning(æœºå™¨å­¦ä¹ ) å­¦ä¹ è·¯çº¿å›¾ã€‚æ²¡é”™ï¼Œæˆ‘å¯ä»¥ç»™ä½ ä»¬çš„ä¸€ä»½ï¼Œå› ä¸ºæˆ‘ä»¬è¿˜é€šè¿‡è§†é¢‘è®°å½•ä¸‹æ¥æˆ‘ä»¬çš„å­¦ä¹ è¿‡ç¨‹ã€‚æ°´å¹³å½“ç„¶ä¹Ÿæœ‰é™ï¼Œä¸è¿‡å¯¹äºæ–°æ‰‹å…¥é—¨ï¼Œç»å¯¹æ²¡é—®é¢˜ï¼Œå¦‚æœä½ è¿˜ä¸ä¼šï¼Œé‚£ç®—æˆ‘è¾“ï¼ï¼è§†é¢‘æ€ä¹ˆçœ‹ï¼Ÿç†è®ºç§‘ç­å‡ºèº«-å»ºè®®å»å­¦ä¹  Andrew Ng çš„è§†é¢‘ï¼ˆNg çš„è§†é¢‘ç»å¯¹æ˜¯æƒå¨ï¼Œè¿™ä¸ªæ¯‹åº¸ç½®ç–‘ï¼‰ç¼–ç èƒ½åŠ›å¼º - å»ºè®®çœ‹æˆ‘ä»¬çš„ã€Šæœºå™¨å­¦ä¹ å®æˆ˜-æ•™å­¦ç‰ˆã€‹ç¼–ç èƒ½åŠ›å¼± - å»ºè®®çœ‹æˆ‘ä»¬çš„ã€Šæœºå™¨å­¦ä¹ å®æˆ˜-è®¨è®ºç‰ˆã€‹ï¼Œä¸è¿‡åœ¨çœ‹ç†è®ºçš„æ—¶å€™ï¼Œçœ‹ æ•™å­¦ç‰ˆ-ç†è®ºéƒ¨åˆ†ï¼›è®¨è®ºç‰ˆçš„åºŸè¯å¤ªå¤šï¼Œä¸è¿‡åœ¨è®²è§£ä»£ç çš„æ—¶å€™æ˜¯ä¸€è¡Œä¸€è¡Œè®²è§£çš„ï¼›æ‰€ä»¥ï¼Œæ ¹æ®è‡ªå·±çš„éœ€æ±‚ï¼Œè‡ªç”±çš„ç»„åˆã€‚ã€å…è´¹ã€‘æ•°å­¦æ•™å­¦è§†é¢‘ - å¯æ±—å­¦é™¢ å…¥é—¨ç¯‡@äºæŒ¯æ¢“ æ¨è: å¯æ±—å­¦é™¢-ç½‘æ˜“å…¬å¼€è¯¾æ¦‚ç‡ç»Ÿè®¡çº¿æ€§ä»£æ•°å¯æ±—å­¦é™¢(æ¦‚ç‡)å¯æ±—å­¦é™¢(ç»Ÿè®¡å­¦)å¯æ±—å­¦é™¢(çº¿æ€§ä»£æ•°)æœºå™¨å­¦ä¹ è§†é¢‘ - ApacheCN æ•™å­¦ç‰ˆAcFunBç«™ä¼˜é…·ç½‘æ˜“äº‘è¯¾å ‚ã€å…è´¹ã€‘æœºå™¨/æ·±åº¦å­¦ä¹ è§†é¢‘ - å´æ©è¾¾æœºå™¨å­¦ä¹ æ·±åº¦å­¦ä¹ å´æ©è¾¾æœºå™¨å­¦ä¹ ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ 2.æ·±åº¦å­¦ä¹ æ”¯æŒç‰ˆæœ¬VersionSupported3.6.xâœ…2.7.xâŒå…¥é—¨åŸºç¡€åå‘ä¼ é€’: https://www.cnblogs.com/charlotte77/p/5629865.htmlCNNåŸç†: http://www.cnblogs.com/charlotte77/p/7759802.htmlRNNåŸç†: https://blog.csdn.net/qq_39422642/article/details/78676567LSTMåŸç†: https://blog.csdn.net/weixin_42111770/article/details/80900575Pytorch - æ•™ç¨‹-- å¾…æ›´æ–°TensorFlow 2.0 - æ•™ç¨‹-- å¾…æ›´æ–°ç›®å½•ç»“æ„:å®‰è£…æŒ‡å—Keras å¿«é€Ÿå…¥é—¨å®æˆ˜é¡¹ç›® 1 ç”µå½±æƒ…æ„Ÿåˆ†ç±»å®æˆ˜é¡¹ç›® 2 æ±½è½¦ç‡ƒæ²¹æ•ˆç‡å®æˆ˜é¡¹ç›® 3 ä¼˜åŒ– è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆå®æˆ˜é¡¹ç›® 4 å¤è¯—è¯è‡ªåŠ¨ç”Ÿæˆåˆ‡åˆ†ï¼ˆåˆ†è¯ï¼‰è¯æ€§æ ‡æ³¨å‘½åå®ä½“è¯†åˆ«å¥æ³•åˆ†æWordNetå¯ä»¥è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªåŒä¹‰è¯è¯å…¸è¯å¹²æå–ï¼ˆstemmingï¼‰ä¸è¯å½¢è¿˜åŸï¼ˆlemmatizationï¼‰https://www.biaodianfu.com/nltk.html/ampTensorFlow 2.0å­¦ä¹ ç½‘å€https://github.com/lyhue1991/eat_tensorflow2_in_30_days3.è‡ªç„¶è¯­è¨€å¤„ç†æ”¯æŒç‰ˆæœ¬VersionSupported3.6.xâœ…2.7.xâŒå­¦ä¹ è¿‡ç¨‹ä¸­-å†…å¿ƒå¤æ‚çš„å˜åŒ–ï¼ï¼ï¼è‡ªä»å­¦ä¹ NLPä»¥åï¼Œæ‰å‘ç°å›½å†…ä¸å›½å¤–çš„å…¸å‹åŒºåˆ«:1. å¯¹èµ„æºçš„æ€åº¦æ˜¯å®Œå…¨ç›¸åçš„:  1) å›½å†…: å°±å¥½åƒä¸ºäº†åæ°”ï¼Œä¸¾åŠå·¥ä½œè£…é€¼çš„ä¼šè®®ï¼Œå°±æ˜¯æ²¡æœ‰å¹²è´§ï¼Œå…¨éƒ¨éƒ½æ˜¯è±¡å¾æ€§çš„PPTä»‹ç»ï¼Œä¸æ˜¯é’ˆå¯¹åœ¨åšçš„å„ä½  2ï¼‰å›½å¤–: å°±å¥½åƒæ˜¯ä¸ºäº†æ¨åŠ¨nlpè¿›æ­¥ä¸€æ ·ï¼Œåˆ†äº«è€…å„ç§å¹²è´§èµ„æ–™å’Œå…·ä½“çš„å®ç°ã€‚ï¼ˆç‰¹åˆ«æ˜¯: pythonè‡ªç„¶è¯­è¨€å¤„ç†ï¼‰2. è®ºæ–‡çš„å®ç°:   1) å„ç§é«˜å¤§ä¸Šçš„è®ºæ–‡å®ç°ï¼Œå´è¿˜æ˜¯æ²¡çœ‹åˆ°ä¸€ä¸ªåƒæ ·çš„GitHubé¡¹ç›®ï¼ï¼ˆå¯èƒ½æˆ‘çš„æœç´¢èƒ½åŠ›å·®äº†ç‚¹ï¼Œä¸€ç›´æ²¡æ‰¾åˆ°ï¼‰  2ï¼‰å›½å¤–å°±ä¸ä¸¾ä¾‹äº†ï¼Œæˆ‘çœ‹ä¸æ‡‚ï¼3. å¼€æºçš„æ¡†æ¶  1ï¼‰å›½å¤–çš„å¼€æºæ¡†æ¶:  tensorflow/pytorch æ–‡æ¡£+æ•™ç¨‹+è§†é¢‘ï¼ˆå®˜æ–¹æä¾›ï¼‰  2) å›½å†…çš„å¼€æºæ¡†æ¶: é¢é¢ï¼Œè¿˜çœŸä¸¾ä¾‹ä¸å‡ºæ¥ï¼ä½†æ˜¯ç‰›é€¼å¹å¾—ä¸æ¯”å›½å¤–å·®ï¼ï¼ˆMXNetè™½ç„¶æœ‰ä¼—å¤šå›½äººå‚ä¸å¼€å‘ï¼Œä½†ä¸èƒ½ç®—æ˜¯å›½å†…å¼€æºæ¡†æ¶ã€‚åŸºäºMXNetçš„åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ (http://zh.d2l.ai & https://discuss.gluon.ai/t/topic/753)ä¸­æ–‡æ•™ç¨‹,å·²ç»ç”±æ²ç¥(ææ²)ä»¥åŠé˜¿æ–¯é¡¿Â·å¼ è®²æˆå½•åˆ¶ï¼Œå…¬å¼€å‘å¸ƒ(æ–‡æ¡£+ç¬¬ä¸€å­£æ•™ç¨‹+è§†é¢‘ï¼‰ã€‚)æ¯ä¸€æ¬¡æ·±å…¥éƒ½è¦å»ç¿»å¢™ï¼Œæ¯ä¸€æ¬¡æ·±å…¥éƒ½è¦Googleï¼Œæ¯ä¸€æ¬¡çœ‹ç€å›½å†…çš„è¯´: å“ˆå·¥å¤§ã€è®¯é£ã€ä¸­ç§‘å¤§ã€ç™¾åº¦ã€é˜¿é‡Œå¤šç‰›é€¼ï¼Œä½†æ˜¯èµ„æ–™è¿˜æ˜¯å¾—å›½å¤–å»æ‰¾ï¼æœ‰æ—¶å€™çœŸçš„æŒºæ¨çš„ï¼çœŸçš„æœ‰ç‚¹ç§ä¸èµ·è‡ªå·±å›½å†…çš„æŠ€æœ¯ç¯å¢ƒï¼å½“ç„¶è°¢è°¢å›½å†…å¾ˆå¤šåšå®¢å¤§ä½¬ï¼Œç‰¹åˆ«æ˜¯ä¸€äº›å…¥é—¨çš„Demoå’ŒåŸºæœ¬æ¦‚å¿µã€‚ã€æ·±å…¥çš„æ°´å¹³æœ‰é™ï¼Œæ²¡çœ‹æ‡‚ã€‘ã€å…¥é—¨é¡»çŸ¥ã€‘å¿…é¡»äº†è§£: https://github.com/apachecn/AiLearning/tree/master/nlpã€å…¥é—¨æ•™ç¨‹ã€‘å¼ºçƒˆæ¨è: PyTorch è‡ªç„¶è¯­è¨€å¤„ç†: https://github.com/apachecn/NLP-with-PyTorchPython è‡ªç„¶è¯­è¨€å¤„ç† ç¬¬äºŒç‰ˆ: https://usyiyi.github.io/nlp-py-2e-zhæ¨èä¸€ä¸ªliuhuanyongå¤§ä½¬æ•´ç†çš„nlpå…¨é¢çŸ¥è¯†ä½“ç³»: https://liuhuanyong.github.ioå¼€æº - è¯å‘é‡åº“é›†åˆ:https://www.cnblogs.com/Darwin2000/p/5786984.htmlhttps://ai.tencent.com/ailab/nlp/embedding.htmlhttps://blog.csdn.net/xiezj007/article/details/85073890https://github.com/Embedding/Chinese-Word-Vectorshttps://github.com/brightmart/nlp_chinese_corpushttps://github.com/codemayq/chinese_chatbot_corpushttps://github.com/candlewill/Dialog_Corpus1.ä½¿ç”¨åœºæ™¯ ï¼ˆç™¾åº¦å…¬å¼€è¯¾ï¼‰ç¬¬ä¸€éƒ¨åˆ† å…¥é—¨ä»‹ç»1.) è‡ªç„¶è¯­è¨€å¤„ç†å…¥é—¨ä»‹ç»ç¬¬äºŒéƒ¨åˆ† æœºå™¨ç¿»è¯‘2.) æœºå™¨ç¿»è¯‘ç¬¬ä¸‰éƒ¨åˆ† ç¯‡ç« åˆ†æ3.1.) ç¯‡ç« åˆ†æ-å†…å®¹æ¦‚è¿°3.2.) ç¯‡ç« åˆ†æ-å†…å®¹æ ‡ç­¾3.3.) ç¯‡ç« åˆ†æ-æƒ…æ„Ÿåˆ†æ3.4.) ç¯‡ç« åˆ†æ-è‡ªåŠ¨æ‘˜è¦ç¬¬å››éƒ¨åˆ† UNIT-è¯­è¨€ç†è§£ä¸äº¤äº’æŠ€æœ¯4.) UNIT-è¯­è¨€ç†è§£ä¸äº¤äº’æŠ€æœ¯åº”ç”¨é¢†åŸŸä¸­æ–‡åˆ†è¯:æ„å»ºDAGå›¾åŠ¨æ€è§„åˆ’æŸ¥æ‰¾ï¼Œç»¼åˆæ­£åå‘ï¼ˆæ­£å‘åŠ æƒåå‘è¾“å‡ºï¼‰æ±‚å¾—DAGæœ€å¤§æ¦‚ç‡è·¯å¾„ä½¿ç”¨äº†SBMEè¯­æ–™è®­ç»ƒäº†ä¸€å¥— HMM + Viterbi æ¨¡å‹ï¼Œè§£å†³æœªç™»å½•è¯é—®é¢˜1.æ–‡æœ¬åˆ†ç±»ï¼ˆText Classificationï¼‰æ–‡æœ¬åˆ†ç±»æ˜¯æŒ‡æ ‡è®°å¥å­æˆ–æ–‡æ¡£ï¼Œä¾‹å¦‚ç”µå­é‚®ä»¶åƒåœ¾é‚®ä»¶åˆ†ç±»å’Œæƒ…æ„Ÿåˆ†æã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…æ–‡æœ¬åˆ†ç±»æ•°æ®é›†ã€‚è·¯é€ç¤¾Newswireä¸»é¢˜åˆ†ç±»ï¼ˆè·¯é€ç¤¾-21578ï¼‰ã€‚1987å¹´è·¯é€ç¤¾å‡ºç°çš„ä¸€ç³»åˆ—æ–°é—»æ–‡ä»¶ï¼ŒæŒ‰ç±»åˆ«ç¼–åˆ¶ç´¢å¼•ã€‚å¦è§RCV1ï¼ŒRCV2å’ŒTRC2ã€‚IMDBç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ç±»ï¼ˆæ–¯å¦ç¦ï¼‰ã€‚æ¥è‡ªç½‘ç«™imdb.comçš„ä¸€ç³»åˆ—ç”µå½±è¯„è®ºåŠå…¶ç§¯ææˆ–æ¶ˆæçš„æƒ…ç»ªã€‚æ–°é—»ç»„ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ç±»ï¼ˆåº·å¥ˆå°”ï¼‰ã€‚æ¥è‡ªç½‘ç«™imdb.comçš„ä¸€ç³»åˆ—ç”µå½±è¯„è®ºåŠå…¶ç§¯ææˆ–æ¶ˆæçš„æƒ…ç»ªã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…å¸–å­:å•æ ‡ç­¾æ–‡æœ¬åˆ†ç±»çš„æ•°æ®é›†ã€‚æƒ…æ„Ÿåˆ†ææ¯”èµ›åœ°å€: https://www.kaggle.com/c/word2vec-nlp-tutorialæ–¹æ¡ˆä¸€(0.86): WordCount + æœ´ç´  Bayesæ–¹æ¡ˆäºŒ(0.94): LDA + åˆ†ç±»æ¨¡å‹ï¼ˆknn/å†³ç­–æ ‘/é€»è¾‘å›å½’/svm/xgboost/éšæœºæ£®æ—ï¼‰a) å†³ç­–æ ‘æ•ˆæœä¸æ˜¯å¾ˆå¥½ï¼Œè¿™ç§è¿ç»­ç‰¹å¾ä¸å¤ªé€‚åˆçš„b) é€šè¿‡å‚æ•°è°ƒæ•´ 200 ä¸ªtopicï¼Œä¿¡æ¯é‡ä¿å­˜æ•ˆæœè¾ƒä¼˜ï¼ˆè®¡ç®—ä¸»é¢˜ï¼‰æ–¹æ¡ˆä¸‰(0.72): word2vec + CNNè¯´å®è¯: æ²¡æœ‰ä¸€ä¸ªå¥½çš„æœºå™¨ï¼Œæ˜¯è°ƒä¸å‡ºæ¥ä¸€ä¸ªå¥½çš„ç»“æœ (: é€ƒé€šè¿‡AUC æ¥è¯„ä¼°æ¨¡å‹çš„æ•ˆæœ2.è¯­è¨€æ¨¡å‹ï¼ˆLanguage Modelingï¼‰è¯­è¨€å»ºæ¨¡æ¶‰åŠå¼€å‘ä¸€ç§ç»Ÿè®¡æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹å¥å­ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯æˆ–ä¸€ä¸ªå•è¯ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚å®ƒæ˜¯è¯­éŸ³è¯†åˆ«å’Œæœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ä¸­çš„å‰ç½®ä»»åŠ¡ã€‚å®ƒæ˜¯è¯­éŸ³è¯†åˆ«å’Œæœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ä¸­çš„å‰ç½®ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…è¯­è¨€å»ºæ¨¡æ•°æ®é›†ã€‚å¤è…¾å ¡é¡¹ç›®ï¼Œä¸€ç³»åˆ—å…è´¹ä¹¦ç±ï¼Œå¯ä»¥ç”¨çº¯æ–‡æœ¬æ£€ç´¢å„ç§è¯­è¨€ã€‚è¿˜æœ‰æ›´å¤šæ­£å¼çš„è¯­æ–™åº“å¾—åˆ°äº†å¾ˆå¥½çš„ç ”ç©¶; ä¾‹å¦‚:å¸ƒæœ—å¤§å­¦ç°ä»£ç¾å›½è‹±è¯­æ ‡å‡†è¯­æ–™åº“ã€‚å¤§é‡è‹±è¯­å•è¯æ ·æœ¬ã€‚è°·æ­Œ10äº¿å­—è¯­æ–™åº“ã€‚æ–°è¯å‘ç°ä¸­æ–‡åˆ†è¯æ–°è¯å‘ç°python3åˆ©ç”¨äº’ä¿¡æ¯å’Œå·¦å³ä¿¡æ¯ç†µçš„ä¸­æ–‡åˆ†è¯æ–°è¯å‘ç°https://github.com/zhanzecheng/Chinese_segment_augmentå¥å­ç›¸ä¼¼åº¦è¯†åˆ«é¡¹ç›®åœ°å€: https://www.kaggle.com/c/quora-question-pairsè§£å†³æ–¹æ¡ˆ: word2vec + Bi-GRUæ–‡æœ¬çº é”™bi-gram + levenshtein3.å›¾åƒå­—å¹•ï¼ˆImage Captioningï¼‰mageå­—å¹•æ˜¯ä¸ºç»™å®šå›¾åƒç”Ÿæˆæ–‡æœ¬æè¿°çš„ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…å›¾åƒå­—å¹•æ•°æ®é›†ã€‚ä¸Šä¸‹æ–‡ä¸­çš„å…¬å…±å¯¹è±¡ï¼ˆCOCOï¼‰ã€‚åŒ…å«è¶…è¿‡12ä¸‡å¼ å¸¦æè¿°çš„å›¾åƒçš„é›†åˆFlickr 8Kã€‚ä»flickr.comè·å–çš„8åƒä¸ªæè¿°å›¾åƒçš„é›†åˆã€‚Flickr 30Kã€‚ä»flickr.comè·å–çš„3ä¸‡ä¸ªæè¿°å›¾åƒçš„é›†åˆã€‚æ¬²äº†è§£æ›´å¤šï¼Œè¯·çœ‹å¸–å­:æ¢ç´¢å›¾åƒå­—å¹•æ•°æ®é›†ï¼Œ2016å¹´4.æœºå™¨ç¿»è¯‘ï¼ˆMachine Translationï¼‰æœºå™¨ç¿»è¯‘æ˜¯å°†æ–‡æœ¬ä»ä¸€ç§è¯­è¨€ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€çš„ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…æœºå™¨ç¿»è¯‘æ•°æ®é›†ã€‚åŠ æ‹¿å¤§ç¬¬36å±Šè®®ä¼šçš„åè°ƒå›½ä¼šè®®å‘˜ã€‚æˆå¯¹çš„è‹±è¯­å’Œæ³•è¯­å¥å­ã€‚æ¬§æ´²è®®ä¼šè¯‰è®¼å¹³è¡Œè¯­æ–™åº“1996-2011ã€‚å¥å­å¯¹ä¸€å¥—æ¬§æ´²è¯­è¨€ã€‚æœ‰å¤§é‡æ ‡å‡†æ•°æ®é›†ç”¨äºå¹´åº¦æœºå™¨ç¿»è¯‘æŒ‘æˆ˜; çœ‹åˆ°:ç»Ÿè®¡æœºå™¨ç¿»è¯‘æœºå™¨ç¿»è¯‘Encoder + Decoder(Attention)å‚è€ƒæ¡ˆä¾‹: http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html5.é—®ç­”ç³»ç»Ÿï¼ˆQuestion Answeringï¼‰é—®ç­”æ˜¯ä¸€é¡¹ä»»åŠ¡ï¼Œå…¶ä¸­æä¾›äº†ä¸€ä¸ªå¥å­æˆ–æ–‡æœ¬æ ·æœ¬ï¼Œä»ä¸­æå‡ºé—®é¢˜å¹¶ä¸”å¿…é¡»å›ç­”é—®é¢˜ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…é—®é¢˜å›ç­”æ•°æ®é›†ã€‚æ–¯å¦ç¦é—®é¢˜å›ç­”æ•°æ®é›†ï¼ˆSQuADï¼‰ã€‚å›ç­”æœ‰å…³ç»´åŸºç™¾ç§‘æ–‡ç« çš„é—®é¢˜ã€‚Deepmindé—®é¢˜å›ç­”è¯­æ–™åº“ã€‚ä»æ¯æ—¥é‚®æŠ¥å›ç­”æœ‰å…³æ–°é—»æ–‡ç« çš„é—®é¢˜ã€‚äºšé©¬é€Šé—®ç­”æ•°æ®ã€‚å›ç­”æœ‰å…³äºšé©¬é€Šäº§å“çš„é—®é¢˜ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…å¸–å­:æ•°æ®é›†: æˆ‘å¦‚ä½•è·å¾—é—®ç­”ç½‘ç«™çš„è¯­æ–™åº“ï¼Œå¦‚Quoraæˆ–Yahoo Answersæˆ–Stack Overflowæ¥åˆ†æç­”æ¡ˆè´¨é‡ï¼Ÿ6.è¯­éŸ³è¯†åˆ«ï¼ˆSpeech Recognitionï¼‰è¯­éŸ³è¯†åˆ«æ˜¯å°†å£è¯­çš„éŸ³é¢‘è½¬æ¢ä¸ºäººç±»å¯è¯»æ–‡æœ¬çš„ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…è¯­éŸ³è¯†åˆ«æ•°æ®é›†ã€‚TIMITå£°å­¦ - è¯­éŸ³è¿ç»­è¯­éŸ³è¯­æ–™åº“ã€‚ä¸æ˜¯å…è´¹çš„ï¼Œä½†å› å…¶å¹¿æ³›ä½¿ç”¨è€Œä¸Šå¸‚ã€‚å£è¯­ç¾å›½è‹±è¯­å’Œç›¸å…³çš„è½¬å½•ã€‚VoxForgeã€‚ç”¨äºæ„å»ºç”¨äºè¯­éŸ³è¯†åˆ«çš„å¼€æºæ•°æ®åº“çš„é¡¹ç›®ã€‚LibriSpeech ASRè¯­æ–™åº“ã€‚ä»LibriVoxæ”¶é›†çš„å¤§é‡è‹±è¯­æœ‰å£°è¯»ç‰©ã€‚7.è‡ªåŠ¨æ–‡æ‘˜ï¼ˆDocument Summarizationï¼‰æ–‡æ¡£æ‘˜è¦æ˜¯åˆ›å»ºè¾ƒå¤§æ–‡æ¡£çš„ç®€çŸ­æœ‰æ„ä¹‰æè¿°çš„ä»»åŠ¡ã€‚ä¸‹é¢æ˜¯ä¸€äº›å¾ˆå¥½çš„åˆå­¦è€…æ–‡æ¡£æ‘˜è¦æ•°æ®é›†ã€‚æ³•å¾‹æ¡ˆä¾‹æŠ¥å‘Šæ•°æ®é›†ã€‚æ”¶é›†äº†4000ä»½æ³•å¾‹æ¡ˆä»¶åŠå…¶æ‘˜è¦ã€‚TIPSTERæ–‡æœ¬æ‘˜è¦è¯„ä¼°ä¼šè®®è¯­æ–™åº“ã€‚æ”¶é›†äº†è¿‘200ä»½æ–‡ä»¶åŠå…¶æ‘˜è¦ã€‚è‹±è¯­æ–°é—»æ–‡æœ¬çš„AQUAINTè¯­æ–™åº“ã€‚ä¸æ˜¯å…è´¹çš„ï¼Œè€Œæ˜¯å¹¿æ³›ä½¿ç”¨çš„ã€‚æ–°é—»æ–‡ç« çš„è¯­æ–™åº“ã€‚æ¬²äº†è§£æ›´å¤šä¿¡æ¯:æ–‡æ¡£ç†è§£ä¼šè®®ï¼ˆDUCï¼‰ä»»åŠ¡ã€‚åœ¨å“ªé‡Œå¯ä»¥æ‰¾åˆ°ç”¨äºæ–‡æœ¬æ‘˜è¦çš„è‰¯å¥½æ•°æ®é›†ï¼Ÿå‘½åå®ä½“è¯†åˆ«Bi-LSTM CRFå‚è€ƒæ¡ˆä¾‹: http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.htmlCRFæ¨èæ–‡æ¡£: https://www.jianshu.com/p/55755fc649b1æ–‡æœ¬æ‘˜è¦æŠ½å–å¼word2vec + textrankword2vecæ¨èæ–‡æ¡£: https://www.zhihu.com/question/44832436/answer/266068967textrankæ¨èæ–‡æ¡£: https://blog.csdn.net/BaiHuaXiu123/article/details/77847232Graphå›¾è®¡ç®—ã€æ…¢æ…¢æ›´æ–°ã€‘æ•°æ®é›†: https://github.com/apachecn/data/tree/master/graphå­¦ä¹ èµ„æ–™: spark graphXå®æˆ˜.pdf ã€æ–‡ä»¶å¤ªå¤§ä¸æ–¹ä¾¿æä¾›ï¼Œè‡ªå·±ç™¾åº¦ã€‘çŸ¥è¯†å›¾è°±çŸ¥è¯†å›¾è°±ï¼Œæˆ‘åªè®¤ SimmerChan: ã€çŸ¥è¯†å›¾è°±-ç»™AIè£…ä¸ªå¤§è„‘ã€‘è¯´å®è¯ï¼Œæˆ‘æ˜¯çœ‹è¿™åšä¸»è€å“¥å†™çš„åšå®¢é•¿å¤§çš„ï¼Œå†™çš„çœŸçš„æ˜¯æ·±å…¥æµ…å‡ºã€‚æˆ‘å¾ˆå–œæ¬¢ï¼Œæ‰€ä»¥å°±åˆ†äº«ç»™å¤§å®¶ï¼Œå¸Œæœ›ä½ ä»¬ä¹Ÿå–œæ¬¢ã€‚è¿›ä¸€æ­¥é˜…è¯»å¦‚æœæ‚¨å¸Œæœ›æ›´æ·±å…¥ï¼Œæœ¬èŠ‚æä¾›äº†å…¶ä»–æ•°æ®é›†åˆ—è¡¨ã€‚ç»´åŸºç™¾ç§‘ç ”ç©¶ä¸­ä½¿ç”¨çš„æ–‡æœ¬æ•°æ®é›†æ•°æ®é›†: è®¡ç®—è¯­è¨€å­¦å®¶å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶äººå‘˜ä½¿ç”¨çš„ä¸»è¦æ–‡æœ¬è¯­æ–™åº“æ˜¯ä»€ä¹ˆï¼Ÿæ–¯å¦ç¦ç»Ÿè®¡è‡ªç„¶è¯­è¨€å¤„ç†è¯­æ–™åº“æŒ‰å­—æ¯é¡ºåºæ’åˆ—çš„NLPæ•°æ®é›†åˆ—è¡¨è¯¥æœºæ„NLTKåœ¨DL4Jä¸Šæ‰“å¼€æ·±åº¦å­¦ä¹ æ•°æ®NLPæ•°æ®é›†å›½å†…å¼€æ”¾æ•°æ®é›†: https://bosonnlp.com/dev/resourceå‚è€ƒæ¯”èµ›æ”¶é›†å¹³å°pbharrin/machinelearninginactionML Masteryè‡´è°¢æœ€è¿‘æ— æ„æ”¶åˆ°ç¾¤å‹æ¨é€çš„é“¾æ¥ï¼Œå‘ç°å¾—åˆ°å¤§ä½¬é«˜åº¦çš„è®¤å¯ï¼Œå¹¶åœ¨çƒ­å¿ƒçš„æ¨å¹¿ã€‚åœ¨æ­¤æ„Ÿè°¢:é‡å­ä½äººå·¥æ™ºèƒ½å‰æ²¿è®²ä¹ èµåŠ©æˆ‘ä»¬"
76,langchain-ai/langchain,https://github.com/langchain-ai/langchain/blob/master/README.md,Python,"ğŸ¦œï¸ğŸ”— LangChainâš¡ Building applications with LLMs through composability âš¡Looking for the JS/TS version? Check out LangChain.js.Production Support: As you move your LangChains into production, we'd love to offer more hands-on support.Fill out this form to share more about what you're building, and our team will get in touch.ğŸš¨Breaking Changes for select chains (SQLDatabase) on 7/28/23In an effort to make langchain leaner and safer, we are moving select chains to langchain_experimental.This migration has already started, but we are remaining backwards compatible until 7/28.On that date, we will remove functionality from langchain.Read more about the motivation and the progress here.Read how to migrate your code here.Quick Installpip install langchainorpip install langsmith && conda install langchain -c conda-forgeğŸ¤” What is this?Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. However, using these LLMs in isolation is often insufficient for creating a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.This library aims to assist in the development of those types of applications. Common examples of these applications include:â“ Question Answering over specific documentsDocumentationEnd-to-end Example: Question Answering over Notion DatabaseğŸ’¬ ChatbotsDocumentationEnd-to-end Example: Chat-LangChainğŸ¤– AgentsDocumentationEnd-to-end Example: GPT+WolframAlphağŸ“– DocumentationPlease see here for full documentation on:Getting started (installation, setting up the environment, simple examples)How-To examples (demos, integrations, helper functions)Reference (full API docs)Resources (high-level explanation of core concepts)ğŸš€ What can this help with?There are six main areas that LangChain is designed to help with.These are, in increasing order of complexity:ğŸ“ƒ LLMs and Prompts:This includes prompt management, prompt optimization, a generic interface for all LLMs, and common utilities for working with LLMs.ğŸ”— Chains:Chains go beyond a single LLM call and involve sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.ğŸ“š Data Augmented Generation:Data Augmented Generation involves specific types of chains that first interact with an external data source to fetch data for use in the generation step. Examples include summarization of long pieces of text and question/answering over specific data sources.ğŸ¤– Agents:Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end-to-end agents.ğŸ§  Memory:Memory refers to persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.ğŸ§ Evaluation:[BETA] Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this.For more information on these concepts, please see our full documentation.ğŸ’ ContributingAs an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.For detailed information on how to contribute, see here."
77,floodsung/Deep-Learning-Papers-Reading-Roadmap,https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md,Python,"Deep Learning Papers Reading RoadmapIf you are a newcomer to the Deep Learning area, the first question you may have is \""Which paper should I start reading from?\""Here is a reading roadmap of Deep Learning papers!The roadmap is constructed in accordance with the following four guidelines:From outline to detailFrom old to state-of-the-artfrom generic to specific areasfocus on state-of-the-artYou will find many papers that are quite new but really worth reading.I would continue adding papers to this roadmap.1 Deep Learning History and Basics1.0 Book[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. \""Deep learning.\"" An MIT Press book. (2015). [html] (Deep Learning Bible, you can read this book while reading following papers.) â­â­â­â­â­1.1 Survey[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. \""Deep learning.\"" Nature 521.7553 (2015): 436-444. [pdf] (Three Giants' Survey) â­â­â­â­â­1.2 Deep Belief Network(DBN)(Milestone of Deep Learning Eve)[2] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. \""A fast learning algorithm for deep belief nets.\"" Neural computation 18.7 (2006): 1527-1554. [pdf](Deep Learning Eve) â­â­â­[3] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. \""Reducing the dimensionality of data with neural networks.\"" Science 313.5786 (2006): 504-507. [pdf] (Milestone, Show the promise of deep learning) â­â­â­1.3 ImageNet Evolutionï¼ˆDeep Learning broke out from hereï¼‰[4] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \""Imagenet classification with deep convolutional neural networks.\"" Advances in neural information processing systems. 2012. [pdf] (AlexNet, Deep Learning Breakthrough) â­â­â­â­â­[5] Simonyan, Karen, and Andrew Zisserman. \""Very deep convolutional networks for large-scale image recognition.\"" arXiv preprint arXiv:1409.1556 (2014). [pdf] (VGGNet,Neural Networks become very deep!) â­â­â­[6] Szegedy, Christian, et al. \""Going deeper with convolutions.\"" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [pdf] (GoogLeNet) â­â­â­[7] He, Kaiming, et al. \""Deep residual learning for image recognition.\"" arXiv preprint arXiv:1512.03385 (2015). [pdf] (ResNet,Very very deep networks, CVPR best paper) â­â­â­â­â­1.4 Speech Recognition Evolution[8] Hinton, Geoffrey, et al. \""Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups.\"" IEEE Signal Processing Magazine 29.6 (2012): 82-97. [pdf] (Breakthrough in speech recognition)â­â­â­â­[9] Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. \""Speech recognition with deep recurrent neural networks.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (RNN)â­â­â­[10] Graves, Alex, and Navdeep Jaitly. \""Towards End-To-End Speech Recognition with Recurrent Neural Networks.\"" ICML. Vol. 14. 2014. [pdf]â­â­â­[11] Sak, HaÅŸim, et al. \""Fast and accurate recurrent neural network acoustic models for speech recognition.\"" arXiv preprint arXiv:1507.06947 (2015). [pdf] (Google Speech Recognition System) â­â­â­[12] Amodei, Dario, et al. \""Deep speech 2: End-to-end speech recognition in english and mandarin.\"" arXiv preprint arXiv:1512.02595 (2015). [pdf] (Baidu Speech Recognition System) â­â­â­â­[13] W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig \""Achieving Human Parity in Conversational Speech Recognition.\"" arXiv preprint arXiv:1610.05256 (2016). [pdf] (State-of-the-art in speech recognition, Microsoft) â­â­â­â­After reading above papers, you will have a basic understanding of the Deep Learning history, the basic architectures of Deep Learning model(including CNN, RNN, LSTM) and how deep learning can be applied to image and speech recognition issues. The following papers will take you in-depth understanding of the Deep Learning method, Deep Learning in different areas of application and the frontiers. I suggest that you can choose the following papers based on your interests and research direction.#2 Deep Learning Method2.1 Model[14] Hinton, Geoffrey E., et al. \""Improving neural networks by preventing co-adaptation of feature detectors.\"" arXiv preprint arXiv:1207.0580 (2012). [pdf] (Dropout) â­â­â­[15] Srivastava, Nitish, et al. \""Dropout: a simple way to prevent neural networks from overfitting.\"" Journal of Machine Learning Research 15.1 (2014): 1929-1958. [pdf] â­â­â­[16] Ioffe, Sergey, and Christian Szegedy. \""Batch normalization: Accelerating deep network training by reducing internal covariate shift.\"" arXiv preprint arXiv:1502.03167 (2015). [pdf] (An outstanding Work in 2015) â­â­â­â­[17] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \""Layer normalization.\"" arXiv preprint arXiv:1607.06450 (2016). [pdf] (Update of Batch Normalization) â­â­â­â­[18] Courbariaux, Matthieu, et al. \""Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 orâˆ’1.\"" [pdf] (New Model,Fast)  â­â­â­[19] Jaderberg, Max, et al. \""Decoupled neural interfaces using synthetic gradients.\"" arXiv preprint arXiv:1608.05343 (2016). [pdf] (Innovation of Training Method,Amazing Work) â­â­â­â­â­[20] Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. \""Net2net: Accelerating learning via knowledge transfer.\"" arXiv preprint arXiv:1511.05641 (2015). [pdf] (Modify previously trained network to reduce training epochs) â­â­â­[21] Wei, Tao, et al. \""Network Morphism.\"" arXiv preprint arXiv:1603.01670 (2016). [pdf] (Modify previously trained network to reduce training epochs) â­â­â­2.2 Optimization[22] Sutskever, Ilya, et al. \""On the importance of initialization and momentum in deep learning.\"" ICML (3) 28 (2013): 1139-1147. [pdf] (Momentum optimizer) â­â­[23] Kingma, Diederik, and Jimmy Ba. \""Adam: A method for stochastic optimization.\"" arXiv preprint arXiv:1412.6980 (2014). [pdf] (Maybe used most often currently) â­â­â­[24] Andrychowicz, Marcin, et al. \""Learning to learn by gradient descent by gradient descent.\"" arXiv preprint arXiv:1606.04474 (2016). [pdf] (Neural Optimizer,Amazing Work) â­â­â­â­â­[25] Han, Song, Huizi Mao, and William J. Dally. \""Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding.\"" CoRR, abs/1510.00149 2 (2015). [pdf] (ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup) â­â­â­â­â­[26] Iandola, Forrest N., et al. \""SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size.\"" arXiv preprint arXiv:1602.07360 (2016). [pdf] (Also a new direction to optimize NN,DeePhi Tech Startup) â­â­â­â­[27] Glorat Xavier, Bengio Yoshua, et al. \""Understanding the difficulty of training deep forward neural networks.\"" Proceedings of the thirteenth International Conference on Artificial Intelligence and Statistics, PMLR 9:249-256,2010. [pdf] â­â­â­â­2.3 Unsupervised Learning / Deep Generative Model[28] Le, Quoc V. \""Building high-level features using large scale unsupervised learning.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (Milestone, Andrew Ng, Google Brain Project, Cat) â­â­â­â­[29] Kingma, Diederik P., and Max Welling. \""Auto-encoding variational bayes.\"" arXiv preprint arXiv:1312.6114 (2013). [pdf] (VAE) â­â­â­â­[30] Goodfellow, Ian, et al. \""Generative adversarial nets.\"" Advances in Neural Information Processing Systems. 2014. [pdf] (GAN,super cool idea) â­â­â­â­â­[31] Radford, Alec, Luke Metz, and Soumith Chintala. \""Unsupervised representation learning with deep convolutional generative adversarial networks.\"" arXiv preprint arXiv:1511.06434 (2015). [pdf] (DCGAN) â­â­â­â­[32] Gregor, Karol, et al. \""DRAW: A recurrent neural network for image generation.\"" arXiv preprint arXiv:1502.04623 (2015). [pdf] (VAE with attention, outstanding work) â­â­â­â­â­[33] Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. \""Pixel recurrent neural networks.\"" arXiv preprint arXiv:1601.06759 (2016). [pdf] (PixelRNN) â­â­â­â­[34] Oord, Aaron van den, et al. \""Conditional image generation with PixelCNN decoders.\"" arXiv preprint arXiv:1606.05328 (2016). [pdf] (PixelCNN) â­â­â­â­[34] S. Mehri et al., \""SampleRNN: An Unconditional End-to-End Neural Audio Generation Model.\"" arXiv preprint \tarXiv:1612.07837 (2016). [pdf] â­â­â­â­â­2.4 RNN / Sequence-to-Sequence Model[35] Graves, Alex. \""Generating sequences with recurrent neural networks.\"" arXiv preprint arXiv:1308.0850 (2013). [pdf] (LSTM, very nice generating result, show the power of RNN) â­â­â­â­[36] Cho, Kyunghyun, et al. \""Learning phrase representations using RNN encoder-decoder for statistical machine translation.\"" arXiv preprint arXiv:1406.1078 (2014). [pdf] (First Seq-to-Seq Paper) â­â­â­â­[37] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \""Sequence to sequence learning with neural networks.\"" Advances in neural information processing systems. 2014. [pdf] (Outstanding Work) â­â­â­â­â­[38] Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. \""Neural Machine Translation by Jointly Learning to Align and Translate.\"" arXiv preprint arXiv:1409.0473 (2014). [pdf] â­â­â­â­[39] Vinyals, Oriol, and Quoc Le. \""A neural conversational model.\"" arXiv preprint arXiv:1506.05869 (2015). [pdf] (Seq-to-Seq on Chatbot) â­â­â­2.5 Neural Turing Machine[40] Graves, Alex, Greg Wayne, and Ivo Danihelka. \""Neural turing machines.\"" arXiv preprint arXiv:1410.5401 (2014). [pdf] (Basic Prototype of Future Computer) â­â­â­â­â­[41] Zaremba, Wojciech, and Ilya Sutskever. \""Reinforcement learning neural Turing machines.\"" arXiv preprint arXiv:1505.00521 362 (2015). [pdf] â­â­â­[42] Weston, Jason, Sumit Chopra, and Antoine Bordes. \""Memory networks.\"" arXiv preprint arXiv:1410.3916 (2014). [pdf] â­â­â­[43] Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. \""End-to-end memory networks.\"" Advances in neural information processing systems. 2015. [pdf] â­â­â­â­[44] Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. \""Pointer networks.\"" Advances in Neural Information Processing Systems. 2015. [pdf] â­â­â­â­[45] Graves, Alex, et al. \""Hybrid computing using a neural network with dynamic external memory.\"" Nature (2016). [pdf] (Milestone,combine above papers' ideas) â­â­â­â­â­2.6 Deep Reinforcement Learning[46] Mnih, Volodymyr, et al. \""Playing atari with deep reinforcement learning.\"" arXiv preprint arXiv:1312.5602 (2013). [pdf]) (First Paper named deep reinforcement learning) â­â­â­â­[47] Mnih, Volodymyr, et al. \""Human-level control through deep reinforcement learning.\"" Nature 518.7540 (2015): 529-533. [pdf] (Milestone) â­â­â­â­â­[48] Wang, Ziyu, Nando de Freitas, and Marc Lanctot. \""Dueling network architectures for deep reinforcement learning.\"" arXiv preprint arXiv:1511.06581 (2015). [pdf] (ICLR best paper,great idea)  â­â­â­â­[49] Mnih, Volodymyr, et al. \""Asynchronous methods for deep reinforcement learning.\"" arXiv preprint arXiv:1602.01783 (2016). [pdf] (State-of-the-art method) â­â­â­â­â­[50] Lillicrap, Timothy P., et al. \""Continuous control with deep reinforcement learning.\"" arXiv preprint arXiv:1509.02971 (2015). [pdf] (DDPG) â­â­â­â­[51] Gu, Shixiang, et al. \""Continuous Deep Q-Learning with Model-based Acceleration.\"" arXiv preprint arXiv:1603.00748 (2016). [pdf] (NAF) â­â­â­â­[52] Schulman, John, et al. \""Trust region policy optimization.\"" CoRR, abs/1502.05477 (2015). [pdf] (TRPO) â­â­â­â­[53] Silver, David, et al. \""Mastering the game of Go with deep neural networks and tree search.\"" Nature 529.7587 (2016): 484-489. [pdf] (AlphaGo) â­â­â­â­â­2.7 Deep Transfer Learning / Lifelong Learning / especially for RL[54] Bengio, Yoshua. \""Deep Learning of Representations for Unsupervised and Transfer Learning.\"" ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [pdf] (A Tutorial) â­â­â­[55] Silver, Daniel L., Qiang Yang, and Lianghao Li. \""Lifelong Machine Learning Systems: Beyond Learning Algorithms.\"" AAAI Spring Symposium: Lifelong Machine Learning. 2013. [pdf] (A brief discussion about lifelong learning)  â­â­â­[56] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \""Distilling the knowledge in a neural network.\"" arXiv preprint arXiv:1503.02531 (2015). [pdf] (Godfather's Work) â­â­â­â­[57] Rusu, Andrei A., et al. \""Policy distillation.\"" arXiv preprint arXiv:1511.06295 (2015). [pdf] (RL domain) â­â­â­[58] Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. \""Actor-mimic: Deep multitask and transfer reinforcement learning.\"" arXiv preprint arXiv:1511.06342 (2015). [pdf] (RL domain) â­â­â­[59] Rusu, Andrei A., et al. \""Progressive neural networks.\"" arXiv preprint arXiv:1606.04671 (2016). [pdf] (Outstanding Work, A novel idea) â­â­â­â­â­2.8 One Shot Deep Learning[60] Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. \""Human-level concept learning through probabilistic program induction.\"" Science 350.6266 (2015): 1332-1338. [pdf] (No Deep Learning,but worth reading) â­â­â­â­â­[61] Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. \""Siamese Neural Networks for One-shot Image Recognition.\""(2015) [pdf] â­â­â­[62] Santoro, Adam, et al. \""One-shot Learning with Memory-Augmented Neural Networks.\"" arXiv preprint arXiv:1605.06065 (2016). [pdf] (A basic step to one shot learning) â­â­â­â­[63] Vinyals, Oriol, et al. \""Matching Networks for One Shot Learning.\"" arXiv preprint arXiv:1606.04080 (2016). [pdf] â­â­â­[64] Hariharan, Bharath, and Ross Girshick. \""Low-shot visual object recognition.\"" arXiv preprint arXiv:1606.02819 (2016). [pdf] (A step to large data) â­â­â­â­3 Applications3.1 NLP(Natural Language Processing)[1] Antoine Bordes, et al. \""Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing.\"" AISTATS(2012) [pdf] â­â­â­â­[2] Mikolov, et al. \""Distributed representations of words and phrases and their compositionality.\"" ANIPS(2013): 3111-3119 [pdf] (word2vec) â­â­â­[3] Sutskever, et al. \""â€œSequence to sequence learning with neural networks.\"" ANIPS(2014) [pdf] â­â­â­[4] Ankit Kumar, et al. \""â€œAsk Me Anything: Dynamic Memory Networks for Natural Language Processing.\"" arXiv preprint arXiv:1506.07285(2015) [pdf] â­â­â­â­[5] Yoon Kim, et al. \""Character-Aware Neural Language Models.\"" NIPS(2015) arXiv preprint arXiv:1508.06615(2015) [pdf] â­â­â­â­[6] Jason Weston, et al. \""Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.\"" arXiv preprint arXiv:1502.05698(2015) [pdf] (bAbI tasks) â­â­â­[7] Karl Moritz Hermann, et al. \""Teaching Machines to Read and Comprehend.\"" arXiv preprint arXiv:1506.03340(2015) [pdf] (CNN/DailyMail cloze style questions) â­â­[8] Alexis Conneau, et al. \""Very Deep Convolutional Networks for Natural Language Processing.\"" arXiv preprint arXiv:1606.01781(2016) [pdf] (state-of-the-art in text classification) â­â­â­[9] Armand Joulin, et al. \""Bag of Tricks for Efficient Text Classification.\"" arXiv preprint arXiv:1607.01759(2016) [pdf] (slightly worse than state-of-the-art, but a lot faster) â­â­â­3.2 Object Detection[1] Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. \""Deep neural networks for object detection.\"" Advances in Neural Information Processing Systems. 2013. [pdf] â­â­â­[2] Girshick, Ross, et al. \""Rich feature hierarchies for accurate object detection and semantic segmentation.\"" Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [pdf] (RCNN) â­â­â­â­â­[3] He, Kaiming, et al. \""Spatial pyramid pooling in deep convolutional networks for visual recognition.\"" European Conference on Computer Vision. Springer International Publishing, 2014. [pdf] (SPPNet) â­â­â­â­[4] Girshick, Ross. \""Fast r-cnn.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] â­â­â­â­[5] Ren, Shaoqing, et al. \""Faster R-CNN: Towards real-time object detection with region proposal networks.\"" Advances in neural information processing systems. 2015. [pdf] â­â­â­â­[6] Redmon, Joseph, et al. \""You only look once: Unified, real-time object detection.\"" arXiv preprint arXiv:1506.02640 (2015). [pdf] (YOLO,Oustanding Work, really practical) â­â­â­â­â­[7] Liu, Wei, et al. \""SSD: Single Shot MultiBox Detector.\"" arXiv preprint arXiv:1512.02325 (2015). [pdf] â­â­â­[8] Dai, Jifeng, et al. \""R-FCN: Object Detection viaRegion-based Fully Convolutional Networks.\"" arXiv preprint arXiv:1605.06409 (2016). [pdf] â­â­â­â­[9] He, Gkioxari, et al. \""Mask R-CNN\"" arXiv preprint arXiv:1703.06870 (2017). [pdf] â­â­â­â­[10] Bochkovskiy, Alexey, et al. \""YOLOv4: Optimal Speed and Accuracy of Object Detection.\""  arXiv preprint arXiv:2004.10934 (2020). [pdf] â­â­â­â­[11] Tan, Mingxing, et al. â€œEfficientDet: Scalable and Efficient Object Detection.\"" arXiv preprint arXiv:1911.09070 (2019). [pdf] â­â­â­â­â­3.3 Visual Tracking[1] Wang, Naiyan, and Dit-Yan Yeung. \""Learning a deep compact image representation for visual tracking.\"" Advances in neural information processing systems. 2013. [pdf] (First Paper to do visual tracking using Deep Learning,DLT Tracker) â­â­â­[2] Wang, Naiyan, et al. \""Transferring rich feature hierarchies for robust visual tracking.\"" arXiv preprint arXiv:1501.04587 (2015). [pdf] (SO-DLT) â­â­â­â­[3] Wang, Lijun, et al. \""Visual tracking with fully convolutional networks.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] (FCNT) â­â­â­â­[4] Held, David, Sebastian Thrun, and Silvio Savarese. \""Learning to Track at 100 FPS with Deep Regression Networks.\"" arXiv preprint arXiv:1604.01802 (2016). [pdf] (GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods) â­â­â­â­[5] Bertinetto, Luca, et al. \""Fully-Convolutional Siamese Networks for Object Tracking.\"" arXiv preprint arXiv:1606.09549 (2016). [pdf] (SiameseFC,New state-of-the-art for real-time object tracking) â­â­â­â­[6] Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. \""Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking.\"" ECCV (2016) [pdf] (C-COT) â­â­â­â­[7] Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. \""Modeling and Propagating CNNs in a Tree Structure for Visual Tracking.\"" arXiv preprint arXiv:1608.07242 (2016). [pdf] (VOT2016 Winner,TCNN) â­â­â­â­3.4 Image Caption[1] Farhadi,Ali,etal. \""Every picture tells a story: Generating sentences from images\"". In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. [pdf] â­â­â­[2] Kulkarni, Girish, et al. \""Baby talk: Understanding and generating image descriptions\"". In Proceedings of the 24th CVPR, 2011. [pdf]â­â­â­â­[3] Vinyals, Oriol, et al. \""Show and tell: A neural image caption generator\"". In arXiv preprint arXiv:1411.4555, 2014. [pdf]â­â­â­[4] Donahue, Jeff, et al. \""Long-term recurrent convolutional networks for visual recognition and description\"". In arXiv preprint arXiv:1411.4389 ,2014. [pdf][5] Karpathy, Andrej, and Li Fei-Fei. \""Deep visual-semantic alignments for generating image descriptions\"". In arXiv preprint arXiv:1412.2306, 2014. [pdf]â­â­â­â­â­[6] Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. \""Deep fragment embeddings for bidirectional image sentence mapping\"". In Advances in neural information processing systems, 2014. [pdf]â­â­â­â­[7] Fang, Hao, et al. \""From captions to visual concepts and back\"". In arXiv preprint arXiv:1411.4952, 2014. [pdf]â­â­â­â­â­[8] Chen, Xinlei, and C. Lawrence Zitnick. \""Learning a recurrent visual representation for image caption generation\"". In arXiv preprint arXiv:1411.5654, 2014. [pdf]â­â­â­â­[9] Mao, Junhua, et al. \""Deep captioning with multimodal recurrent neural networks (m-rnn)\"". In arXiv preprint arXiv:1412.6632, 2014. [pdf]â­â­â­[10] Xu, Kelvin, et al. \""Show, attend and tell: Neural image caption generation with visual attention\"". In arXiv preprint arXiv:1502.03044, 2015. [pdf]â­â­â­â­â­3.5 Machine TranslationSome milestone papers are listed in RNN / Seq-to-Seq topic.[1] Luong, Minh-Thang, et al. \""Addressing the rare word problem in neural machine translation.\"" arXiv preprint arXiv:1410.8206 (2014). [pdf] â­â­â­â­[2] Sennrich, et al. \""Neural Machine Translation of Rare Words with Subword Units\"". In arXiv preprint arXiv:1508.07909, 2015. [pdf]â­â­â­[3] Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. \""Effective approaches to attention-based neural machine translation.\"" arXiv preprint arXiv:1508.04025 (2015). [pdf] â­â­â­â­[4] Chung, et al. \""A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation\"". In arXiv preprint arXiv:1603.06147, 2016. [pdf]â­â­[5] Lee, et al. \""Fully Character-Level Neural Machine Translation without Explicit Segmentation\"". In arXiv preprint arXiv:1610.03017, 2016. [pdf]â­â­â­â­â­[6] Wu, Schuster, Chen, Le, et al. \""Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\"". In arXiv preprint arXiv:1609.08144v2, 2016. [pdf] (Milestone) â­â­â­â­3.6 Robotics[1] KoutnÃ­k, Jan, et al. \""Evolving large-scale neural networks for vision-based reinforcement learning.\"" Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [pdf] â­â­â­[2] Levine, Sergey, et al. \""End-to-end training of deep visuomotor policies.\"" Journal of Machine Learning Research 17.39 (2016): 1-40. [pdf] â­â­â­â­â­[3] Pinto, Lerrel, and Abhinav Gupta. \""Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours.\"" arXiv preprint arXiv:1509.06825 (2015). [pdf] â­â­â­[4] Levine, Sergey, et al. \""Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection.\"" arXiv preprint arXiv:1603.02199 (2016). [pdf] â­â­â­â­[5] Zhu, Yuke, et al. \""Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning.\"" arXiv preprint arXiv:1609.05143 (2016). [pdf] â­â­â­â­[6] Yahya, Ali, et al. \""Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search.\"" arXiv preprint arXiv:1610.00673 (2016). [pdf] â­â­â­â­[7] Gu, Shixiang, et al. \""Deep Reinforcement Learning for Robotic Manipulation.\"" arXiv preprint arXiv:1610.00633 (2016). [pdf] â­â­â­â­[8] A Rusu, M Vecerik, Thomas RothÃ¶rl, N Heess, R Pascanu, R Hadsell.\""Sim-to-Real Robot Learning from Pixels with Progressive Nets.\"" arXiv preprint arXiv:1610.04286 (2016). [pdf] â­â­â­â­[9] Mirowski, Piotr, et al. \""Learning to navigate in complex environments.\"" arXiv preprint arXiv:1611.03673 (2016). [pdf] â­â­â­â­3.7 Art[1] Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). \""Inceptionism: Going Deeper into Neural Networks\"". Google Research. [html] (Deep Dream)â­â­â­â­[2] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. \""A neural algorithm of artistic style.\"" arXiv preprint arXiv:1508.06576 (2015). [pdf] (Outstanding Work, most successful method currently) â­â­â­â­â­[3] Zhu, Jun-Yan, et al. \""Generative Visual Manipulation on the Natural Image Manifold.\"" European Conference on Computer Vision. Springer International Publishing, 2016. [pdf] (iGAN) â­â­â­â­[4] Champandard, Alex J. \""Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks.\"" arXiv preprint arXiv:1603.01768 (2016). [pdf] (Neural Doodle) â­â­â­â­[5] Zhang, Richard, Phillip Isola, and Alexei A. Efros. \""Colorful Image Colorization.\"" arXiv preprint arXiv:1603.08511 (2016). [pdf] â­â­â­â­[6] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. \""Perceptual losses for real-time style transfer and super-resolution.\"" arXiv preprint arXiv:1603.08155 (2016). [pdf] â­â­â­â­[7] Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. \""A learned representation for artistic style.\"" arXiv preprint arXiv:1610.07629 (2016). [pdf] â­â­â­â­[8] Gatys, Leon and Ecker, et al.\""Controlling Perceptual Factors in Neural Style Transfer.\"" arXiv preprint arXiv:1611.07865 (2016). [pdf] (control style transfer over spatial location,colour information and across spatial scale)â­â­â­â­[9] Ulyanov, Dmitry and Lebedev, Vadim, et al. \""Texture Networks: Feed-forward Synthesis of Textures and Stylized Images.\"" arXiv preprint arXiv:1603.03417(2016). [pdf] (texture generation and style transfer) â­â­â­â­[10] Yijun Li, Ming-Yu Liu ,Xueting Li, Ming-Hsuan Yang,Jan Kautz (NVIDIA). \""A Closed-form Solution to Photorealistic Image Stylization.\"" arXiv preprint arXiv:1802.06474(2018). [pdf] (Very fast and ultra realistic style transfer) â­â­â­â­3.8 Object Segmentation[1] J. Long, E. Shelhamer, and T. Darrell, â€œFully convolutional networks for semantic segmentation.â€ in CVPR, 2015. [pdf] â­â­â­â­â­[2] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. \""Semantic image segmentation with deep convolutional nets and fully connected crfs.\"" In ICLR, 2015. [pdf] â­â­â­â­â­[3] Pinheiro, P.O., Collobert, R., Dollar, P. \""Learning to segment object candidates.\"" In: NIPS. 2015. [pdf] â­â­â­â­[4] Dai, J., He, K., Sun, J. \""Instance-aware semantic segmentation via multi-task network cascades.\"" in CVPR. 2016 [pdf] â­â­â­[5] Dai, J., He, K., Sun, J. \""Instance-sensitive Fully Convolutional Networks.\"" arXiv preprint arXiv:1603.08678 (2016). [pdf] â­â­â­"
78,jackfrued/Python-100-Days,https://github.com/jackfrued/Python-100-Days/blob/master/README.md,Python,"Python - 100å¤©ä»æ–°æ‰‹åˆ°å¤§å¸ˆä½œè€…ï¼šéª†æ˜Šè¯´æ˜ï¼šä»é¡¹ç›®ä¸Šçº¿åˆ°è·å¾—8w+æ˜Ÿæ ‡ä»¥æ¥ï¼Œä¸€ç›´æ”¶åˆ°åé¦ˆè¯´åŸºç¡€éƒ¨åˆ†ï¼ˆå‰15å¤©çš„å†…å®¹ï¼‰å¯¹æ–°æ‰‹æ¥è¯´æ˜¯æ¯”è¾ƒå›°éš¾çš„ï¼Œå»ºè®®æœ‰é…å¥—è§†é¢‘è¿›è¡Œè®²è§£ã€‚æœ€è¿‘æŠŠåŸºç¡€éƒ¨åˆ†çš„å†…å®¹é‡æ–°åˆ¶ä½œäº†ä¸€ä¸ªåä¸ºâ€œPython-Core-50-Coursesâ€çš„é¡¹ç›®ï¼Œç”¨æ›´ä¸ºç®€å•é€šä¿—çš„æ–¹å¼é‡å†™äº†è¿™éƒ¨åˆ†å†…å®¹å¹¶é™„å¸¦äº†è§†é¢‘è®²è§£ï¼Œåˆå­¦è€…å¯ä»¥å…³æ³¨ä¸‹è¿™ä¸ªæ–°é¡¹ç›®ã€‚å¦‚æœéœ€è¦PythonåŸºç¡€è§†é¢‘ï¼Œå¯ä»¥åœ¨â€œBç«™â€æœç´¢ã€ŠPythoné›¶åŸºç¡€å¿«é€Ÿä¸Šæ‰‹ã€‹ï¼Œè¿™å¥—è§†é¢‘æ˜¯æˆ‘è®²è¯¾çš„æ—¶å€™å½•åˆ¶çš„éšå ‚è§†é¢‘ï¼Œç”»è´¨å°šå¯ã€éŸ³è´¨ä¸€èˆ¬ï¼Œä½†æ˜¯å¯¹åˆå­¦è€…åº”è¯¥ä¼šæœ‰äº›å¸®åŠ©ï¼Œæ¬¢è¿å¤§å®¶ç•™è¨€ã€è¯„è®ºã€å‘å¼¹å¹•ã€‚å­¦ä¹ ä¹‹åè§‰å¾—æœ‰æ”¶è·çš„å°ä¼™ä¼´å¯ä»¥â€œä¸€é”®ä¸‰è¿â€æ¥æ”¯æŒUPä¸»ï¼ˆåƒé”‹Pythonï¼‰ã€‚å›½å†…ç”¨æˆ·å¦‚æœè®¿é—®GitHubæ¯”è¾ƒæ…¢çš„è¯ï¼Œå¯ä»¥å…³æ³¨æˆ‘çš„çŸ¥ä¹å·Python-Jackï¼Œä¸Šé¢çš„â€œä»é›¶å¼€å§‹å­¦Pythonâ€ä¸“æ æ¯”è¾ƒé€‚åˆåˆå­¦è€…ï¼Œå…¶ä»–çš„ä¸“æ ä¹Ÿåœ¨æŒç»­åˆ›ä½œå’Œæ›´æ–°ä¸­ï¼Œæ¬¢è¿å¤§å®¶å…³æ³¨å¹¶ç‚¹èµè¯„è®ºã€‚åˆ›ä½œä¸æ˜“ï¼Œæ„Ÿè°¢å¤§å®¶çš„æ‰“èµæ”¯æŒï¼Œè¿™äº›é’±ä¸ä¼šç”¨äºä¸ªäººæ¶ˆè´¹ï¼ˆä¾‹å¦‚ï¼šè´­ä¹°å’–å•¡ï¼‰ï¼Œè€Œæ˜¯é€šè¿‡è…¾è®¯å…¬ç›Šã€ç¾å›¢å…¬ç›Šã€æ°´æ»´ç­¹ç­‰å¹³å°æèµ ç»™éœ€è¦å¸®åŠ©çš„äººï¼ˆç‚¹å‡»äº†è§£æèµ æƒ…å†µï¼‰ã€‚éœ€è¦åŠ å…¥QQå­¦ä¹ ç¾¤çš„å¯ä»¥æ‰«æä¸‹é¢çš„äºŒç»´ç ï¼Œä¸‰ä¸ªç¾¤åŠ ä¸€ä¸ªå³å¯ï¼Œä¸è¦é‡å¤è¿›ç¾¤ã€‚å­¦ä¹ ç¾¤ä¼šä¸ºå¤§å®¶æä¾›å­¦ä¹ èµ„æºå’Œé—®é¢˜è§£ç­”ï¼Œå¦‚æœæœ‰Pythonä½“éªŒè¯¾å’Œè¡Œä¸šå…¬å¼€è¯¾ä¼šæå‰åœ¨ç¾¤é‡Œé€šçŸ¥å¤§å®¶ï¼Œæ¬¢è¿å¤§å®¶åŠ å…¥ã€‚é¡¹ç›®â€œDay80~90â€éƒ¨åˆ†ç›®å‰ä»åœ¨åˆ›ä½œä¸­ï¼Œå› ä¸ºä½œè€…å¹³æ—¶ä¹ŸæŒ¤ä¸å‡ºå¤ªå¤šæ—¶é—´æ¥å†™æ–‡æ¡£ï¼Œå› æ­¤æ›´æ–°çš„é€Ÿåº¦æ¯”è¾ƒç¼“æ…¢ï¼Œæ„Ÿè°¢å¤§å®¶çš„ç†è§£ã€‚Pythonåº”ç”¨é¢†åŸŸå’ŒèŒä¸šå‘å±•åˆ†æç®€å•çš„è¯´ï¼ŒPythonæ˜¯ä¸€ä¸ªâ€œä¼˜é›…â€ã€â€œæ˜ç¡®â€ã€â€œç®€å•â€çš„ç¼–ç¨‹è¯­è¨€ã€‚å­¦ä¹ æ›²çº¿ä½ï¼Œéä¸“ä¸šäººå£«ä¹Ÿèƒ½ä¸Šæ‰‹å¼€æºç³»ç»Ÿï¼Œæ‹¥æœ‰å¼ºå¤§çš„ç”Ÿæ€åœˆè§£é‡Šå‹è¯­è¨€ï¼Œå®Œç¾çš„å¹³å°å¯ç§»æ¤æ€§åŠ¨æ€ç±»å‹è¯­è¨€ï¼Œæ”¯æŒé¢å‘å¯¹è±¡å’Œå‡½æ•°å¼ç¼–ç¨‹ä»£ç è§„èŒƒç¨‹åº¦é«˜ï¼Œå¯è¯»æ€§å¼ºPythonåœ¨ä»¥ä¸‹é¢†åŸŸéƒ½æœ‰ç”¨æ­¦ä¹‹åœ°ã€‚åç«¯å¼€å‘ - Python / Java / Go / PHPDevOps - Python / Shell / Rubyæ•°æ®é‡‡é›† - Python / C++ / Javaé‡åŒ–äº¤æ˜“ - Python / C++ / Ræ•°æ®ç§‘å­¦ - Python / R / Julia / Matlabæœºå™¨å­¦ä¹  - Python / R / C++ / Juliaè‡ªåŠ¨åŒ–æµ‹è¯• - Python / Shellä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œæ ¹æ®ä¸ªäººçš„å–œå¥½å’ŒèŒä¸šè§„åˆ’ï¼Œå¯ä»¥é€‰æ‹©çš„å°±ä¸šé¢†åŸŸä¹Ÿéå¸¸å¤šã€‚Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼ˆæœåŠ¡å™¨ã€äº‘å¹³å°ã€æ•°æ®æ¥å£ï¼‰Pythonè¿ç»´å·¥ç¨‹å¸ˆï¼ˆè‡ªåŠ¨åŒ–è¿ç»´ã€SREã€DevOpsï¼‰Pythonæ•°æ®åˆ†æå¸ˆï¼ˆæ•°æ®åˆ†æã€å•†ä¸šæ™ºèƒ½ã€æ•°å­—åŒ–è¿è¥ï¼‰Pythonæ•°æ®æŒ–æ˜å·¥ç¨‹å¸ˆï¼ˆæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€ç®—æ³•ä¸“å®¶ï¼‰Pythonçˆ¬è™«å·¥ç¨‹å¸ˆPythonæµ‹è¯•å·¥ç¨‹å¸ˆï¼ˆè‡ªåŠ¨åŒ–æµ‹è¯•ã€æµ‹è¯•å¼€å‘ï¼‰è¯´æ˜ï¼šç›®å‰ï¼Œæ•°æ®åˆ†æå’Œæ•°æ®æŒ–æ˜æ˜¯éå¸¸çƒ­é—¨çš„æ–¹å‘ï¼Œå› ä¸ºä¸ç®¡æ˜¯äº’è”ç½‘è¡Œä¸šè¿˜æ˜¯ä¼ ç»Ÿè¡Œä¸šéƒ½å·²ç»ç§¯ç´¯äº†å¤§é‡çš„æ•°æ®ï¼Œå„è¡Œå„ä¸šéƒ½éœ€è¦æ•°æ®åˆ†æå¸ˆä»å·²æœ‰çš„æ•°æ®ä¸­å‘ç°æ›´å¤šçš„å•†ä¸šä»·å€¼ï¼Œä»è€Œä¸ºä¼ä¸šçš„å†³ç­–æä¾›æ•°æ®çš„æ”¯æ’‘ï¼Œè¿™å°±æ˜¯æ‰€è°“çš„æ•°æ®é©±åŠ¨å†³ç­–ã€‚ç»™åˆå­¦è€…çš„å‡ ä¸ªå»ºè®®ï¼šMake English as your working language. ï¼ˆè®©è‹±è¯­æˆä¸ºä½ çš„å·¥ä½œè¯­è¨€ï¼‰Practice makes perfect. ï¼ˆç†Ÿèƒ½ç”Ÿå·§ï¼‰All experience comes from mistakes. ï¼ˆæ‰€æœ‰çš„ç»éªŒéƒ½æºäºä½ çŠ¯è¿‡çš„é”™è¯¯ï¼‰Don't be one of the leeches. ï¼ˆä¸è¦å½“ä¼¸æ‰‹å…šï¼‰Either outstanding or out. ï¼ˆè¦ä¹ˆå‡ºä¼—ï¼Œè¦ä¹ˆå‡ºå±€ï¼‰Day01~15 - Pythonè¯­è¨€åŸºç¡€Day01 - åˆè¯†PythonPythonç®€ä»‹ - Pythonçš„å†å² / Pythonçš„ä¼˜ç¼ºç‚¹ / Pythonçš„åº”ç”¨é¢†åŸŸæ­å»ºç¼–ç¨‹ç¯å¢ƒ - Windowsç¯å¢ƒ / Linuxç¯å¢ƒ / MacOSç¯å¢ƒä»ç»ˆç«¯è¿è¡ŒPythonç¨‹åº - Hello, world / printå‡½æ•° / è¿è¡Œç¨‹åºä½¿ç”¨IDLE - äº¤äº’å¼ç¯å¢ƒ(REPL) / ç¼–å†™å¤šè¡Œä»£ç  / è¿è¡Œç¨‹åº / é€€å‡ºIDLEæ³¨é‡Š - æ³¨é‡Šçš„ä½œç”¨ / å•è¡Œæ³¨é‡Š / å¤šè¡Œæ³¨é‡ŠDay02 - è¯­è¨€å…ƒç´ ç¨‹åºå’Œè¿›åˆ¶ - æŒ‡ä»¤å’Œç¨‹åº / å†¯è¯ºä¾æ›¼æœº / äºŒè¿›åˆ¶å’Œåè¿›åˆ¶ / å…«è¿›åˆ¶å’Œåå…­è¿›åˆ¶å˜é‡å’Œç±»å‹ - å˜é‡çš„å‘½å / å˜é‡çš„ä½¿ç”¨ / inputå‡½æ•° / æ£€æŸ¥å˜é‡ç±»å‹ / ç±»å‹è½¬æ¢æ•°å­—å’Œå­—ç¬¦ä¸² - æ•´æ•° / æµ®ç‚¹æ•° / å¤æ•° / å­—ç¬¦ä¸² / å­—ç¬¦ä¸²åŸºæœ¬æ“ä½œ / å­—ç¬¦ç¼–ç è¿ç®—ç¬¦ - æ•°å­¦è¿ç®—ç¬¦ / èµ‹å€¼è¿ç®—ç¬¦ / æ¯”è¾ƒè¿ç®—ç¬¦ / é€»è¾‘è¿ç®—ç¬¦ / èº«ä»½è¿ç®—ç¬¦ / è¿ç®—ç¬¦çš„ä¼˜å…ˆçº§åº”ç”¨æ¡ˆä¾‹ - åæ°æ¸©åº¦è½¬æ¢æˆæ‘„æ°æ¸©åº¦ / è¾“å…¥åœ†çš„åŠå¾„è®¡ç®—å‘¨é•¿å’Œé¢ç§¯ / è¾“å…¥å¹´ä»½åˆ¤æ–­æ˜¯å¦æ˜¯é—°å¹´Day03 - åˆ†æ”¯ç»“æ„åˆ†æ”¯ç»“æ„çš„åº”ç”¨åœºæ™¯ - æ¡ä»¶ / ç¼©è¿› / ä»£ç å— / æµç¨‹å›¾ifè¯­å¥ - ç®€å•çš„if / if-elseç»“æ„ / if-elif-elseç»“æ„ / åµŒå¥—çš„ifåº”ç”¨æ¡ˆä¾‹ - ç”¨æˆ·èº«ä»½éªŒè¯ / è‹±åˆ¶å•ä½ä¸å…¬åˆ¶å•ä½äº’æ¢ / æ·éª°å­å†³å®šåšä»€ä¹ˆ / ç™¾åˆ†åˆ¶æˆç»©è½¬ç­‰çº§åˆ¶ / åˆ†æ®µå‡½æ•°æ±‚å€¼ / è¾“å…¥ä¸‰æ¡è¾¹çš„é•¿åº¦å¦‚æœèƒ½æ„æˆä¸‰è§’å½¢å°±è®¡ç®—å‘¨é•¿å’Œé¢ç§¯Day04 - å¾ªç¯ç»“æ„å¾ªç¯ç»“æ„çš„åº”ç”¨åœºæ™¯ - æ¡ä»¶ / ç¼©è¿› / ä»£ç å— / æµç¨‹å›¾whileå¾ªç¯ - åŸºæœ¬ç»“æ„ / breakè¯­å¥ / continueè¯­å¥forå¾ªç¯ - åŸºæœ¬ç»“æ„ / rangeç±»å‹ / å¾ªç¯ä¸­çš„åˆ†æ”¯ç»“æ„ / åµŒå¥—çš„å¾ªç¯ / æå‰ç»“æŸç¨‹åºåº”ç”¨æ¡ˆä¾‹ - 1~100æ±‚å’Œ / åˆ¤æ–­ç´ æ•° / çŒœæ•°å­—æ¸¸æˆ / æ‰“å°ä¹ä¹è¡¨ / æ‰“å°ä¸‰è§’å½¢å›¾æ¡ˆ / çŒ´å­åƒæ¡ƒ / ç™¾é’±ç™¾é¸¡Day05 - æ„é€ ç¨‹åºé€»è¾‘ç»å…¸æ¡ˆä¾‹ï¼šæ°´ä»™èŠ±æ•° / ç™¾é’±ç™¾é¸¡ / CrapsèµŒåšæ¸¸æˆç»ƒä¹ é¢˜ç›®ï¼šæ–æ³¢é‚£å¥‘æ•°åˆ— / å®Œç¾æ•° / ç´ æ•°Day06 - å‡½æ•°å’Œæ¨¡å—çš„ä½¿ç”¨å‡½æ•°çš„ä½œç”¨ - ä»£ç çš„åå‘³é“ / ç”¨å‡½æ•°å°è£…åŠŸèƒ½æ¨¡å—å®šä¹‰å‡½æ•° - defå…³é”®å­— / å‡½æ•°å / å‚æ•°åˆ—è¡¨ / returnè¯­å¥ / è°ƒç”¨è‡ªå®šä¹‰å‡½æ•°è°ƒç”¨å‡½æ•° - Pythonå†…ç½®å‡½æ•° /  å¯¼å…¥æ¨¡å—å’Œå‡½æ•°å‡½æ•°çš„å‚æ•° - é»˜è®¤å‚æ•° / å¯å˜å‚æ•° / å…³é”®å­—å‚æ•° / å‘½åå…³é”®å­—å‚æ•°å‡½æ•°çš„è¿”å›å€¼ - æ²¡æœ‰è¿”å›å€¼  / è¿”å›å•ä¸ªå€¼ / è¿”å›å¤šä¸ªå€¼ä½œç”¨åŸŸé—®é¢˜ - å±€éƒ¨ä½œç”¨åŸŸ / åµŒå¥—ä½œç”¨åŸŸ / å…¨å±€ä½œç”¨åŸŸ / å†…ç½®ä½œç”¨åŸŸ / å’Œä½œç”¨åŸŸç›¸å…³çš„å…³é”®å­—ç”¨æ¨¡å—ç®¡ç†å‡½æ•° - æ¨¡å—çš„æ¦‚å¿µ / ç”¨è‡ªå®šä¹‰æ¨¡å—ç®¡ç†å‡½æ•° / å‘½åå†²çªçš„æ—¶å€™ä¼šæ€æ ·ï¼ˆåŒä¸€ä¸ªæ¨¡å—å’Œä¸åŒçš„æ¨¡å—ï¼‰Day07 - å­—ç¬¦ä¸²å’Œå¸¸ç”¨æ•°æ®ç»“æ„å­—ç¬¦ä¸²çš„ä½¿ç”¨ - è®¡ç®—é•¿åº¦ / ä¸‹æ ‡è¿ç®— / åˆ‡ç‰‡ / å¸¸ç”¨æ–¹æ³•åˆ—è¡¨åŸºæœ¬ç”¨æ³• - å®šä¹‰åˆ—è¡¨ / ç”¨ä¸‹è¡¨è®¿é—®å…ƒç´  / ä¸‹æ ‡è¶Šç•Œ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  / ä¿®æ”¹å…ƒç´  / åˆ‡ç‰‡ / å¾ªç¯éå†åˆ—è¡¨å¸¸ç”¨æ“ä½œ - è¿æ¥ / å¤åˆ¶(å¤åˆ¶å…ƒç´ å’Œå¤åˆ¶æ•°ç»„) / é•¿åº¦ / æ’åº / å€’è½¬ / æŸ¥æ‰¾ç”Ÿæˆåˆ—è¡¨ - ä½¿ç”¨rangeåˆ›å»ºæ•°å­—åˆ—è¡¨ / ç”Ÿæˆè¡¨è¾¾å¼ / ç”Ÿæˆå™¨å…ƒç»„çš„ä½¿ç”¨ - å®šä¹‰å…ƒç»„ / ä½¿ç”¨å…ƒç»„ä¸­çš„å€¼ / ä¿®æ”¹å…ƒç»„å˜é‡ / å…ƒç»„å’Œåˆ—è¡¨è½¬æ¢é›†åˆåŸºæœ¬ç”¨æ³• - é›†åˆå’Œåˆ—è¡¨çš„åŒºåˆ« /  åˆ›å»ºé›†åˆ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  /  æ¸…ç©ºé›†åˆå¸¸ç”¨æ“ä½œ - äº¤é›† / å¹¶é›† / å·®é›† / å¯¹ç§°å·® / å­é›† / è¶…é›†å­—å…¸çš„åŸºæœ¬ç”¨æ³• - å­—å…¸çš„ç‰¹ç‚¹ / åˆ›å»ºå­—å…¸ / æ·»åŠ å…ƒç´  / åˆ é™¤å…ƒç´  / å–å€¼ / æ¸…ç©ºå­—å…¸å¸¸ç”¨æ“ä½œ - keysæ–¹æ³• / valuesæ–¹æ³• / itemsæ–¹æ³• / setdefaultæ–¹æ³•åŸºç¡€ç»ƒä¹  - è·‘é©¬ç¯æ•ˆæœ / åˆ—è¡¨æ‰¾æœ€å¤§å…ƒç´  / ç»Ÿè®¡è€ƒè¯•æˆç»©çš„å¹³å‡åˆ† / Fibonacciæ•°åˆ— / æ¨è¾‰ä¸‰è§’ç»¼åˆæ¡ˆä¾‹ - åŒè‰²çƒé€‰å· / äº•å­—æ£‹Day08 - é¢å‘å¯¹è±¡ç¼–ç¨‹åŸºç¡€ç±»å’Œå¯¹è±¡ - ä»€ä¹ˆæ˜¯ç±» / ä»€ä¹ˆæ˜¯å¯¹è±¡ / é¢å‘å¯¹è±¡å…¶ä»–ç›¸å…³æ¦‚å¿µå®šä¹‰ç±» - åŸºæœ¬ç»“æ„ / å±æ€§å’Œæ–¹æ³• / æ„é€ å™¨ / ææ„å™¨ / __str__æ–¹æ³•ä½¿ç”¨å¯¹è±¡ - åˆ›å»ºå¯¹è±¡ / ç»™å¯¹è±¡å‘æ¶ˆæ¯é¢å‘å¯¹è±¡çš„å››å¤§æ”¯æŸ± - æŠ½è±¡ / å°è£… / ç»§æ‰¿ / å¤šæ€åŸºç¡€ç»ƒä¹  - å®šä¹‰å­¦ç”Ÿç±» / å®šä¹‰æ—¶é’Ÿç±» / å®šä¹‰å›¾å½¢ç±» / å®šä¹‰æ±½è½¦ç±»Day09 - é¢å‘å¯¹è±¡è¿›é˜¶å±æ€§ - ç±»å±æ€§ / å®ä¾‹å±æ€§ / å±æ€§è®¿é—®å™¨ / å±æ€§ä¿®æ”¹å™¨ / å±æ€§åˆ é™¤å™¨ / ä½¿ç”¨__slots__ç±»ä¸­çš„æ–¹æ³• - å®ä¾‹æ–¹æ³• / ç±»æ–¹æ³• / é™æ€æ–¹æ³•è¿ç®—ç¬¦é‡è½½ - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__ç±»(çš„å¯¹è±¡)ä¹‹é—´çš„å…³ç³» - å…³è” / ç»§æ‰¿ / ä¾èµ–ç»§æ‰¿å’Œå¤šæ€ - ä»€ä¹ˆæ˜¯ç»§æ‰¿ / ç»§æ‰¿çš„è¯­æ³• / è°ƒç”¨çˆ¶ç±»æ–¹æ³• / æ–¹æ³•é‡å†™ / ç±»å‹åˆ¤å®š / å¤šé‡ç»§æ‰¿ / è±å½¢ç»§æ‰¿(é’»çŸ³ç»§æ‰¿)å’ŒC3ç®—æ³•ç»¼åˆæ¡ˆä¾‹ - å·¥èµ„ç»“ç®—ç³»ç»Ÿ / å›¾ä¹¦è‡ªåŠ¨æŠ˜æ‰£ç³»ç»Ÿ / è‡ªå®šä¹‰åˆ†æ•°ç±»Day10 - å›¾å½¢ç”¨æˆ·ç•Œé¢å’Œæ¸¸æˆå¼€å‘ä½¿ç”¨tkinterå¼€å‘GUIç¨‹åºä½¿ç”¨pygameä¸‰æ–¹åº“å¼€å‘æ¸¸æˆåº”ç”¨â€œå¤§çƒåƒå°çƒâ€æ¸¸æˆDay11 - æ–‡ä»¶å’Œå¼‚å¸¸è¯»æ–‡ä»¶ - è¯»å–æ•´ä¸ªæ–‡ä»¶ / é€è¡Œè¯»å– / æ–‡ä»¶è·¯å¾„å†™æ–‡ä»¶ - è¦†ç›–å†™å…¥ / è¿½åŠ å†™å…¥ / æ–‡æœ¬æ–‡ä»¶ / äºŒè¿›åˆ¶æ–‡ä»¶å¼‚å¸¸å¤„ç† - å¼‚å¸¸æœºåˆ¶çš„é‡è¦æ€§ / try-exceptä»£ç å— / elseä»£ç å— / finallyä»£ç å— / å†…ç½®å¼‚å¸¸ç±»å‹ / å¼‚å¸¸æ ˆ / raiseè¯­å¥æ•°æ®æŒä¹…åŒ– - CSVæ–‡ä»¶æ¦‚è¿° / csvæ¨¡å—çš„åº”ç”¨ / JSONæ•°æ®æ ¼å¼ / jsonæ¨¡å—çš„åº”ç”¨Day12 - å­—ç¬¦ä¸²å’Œæ­£åˆ™è¡¨è¾¾å¼å­—ç¬¦ä¸²é«˜çº§æ“ä½œ - è½¬ä¹‰å­—ç¬¦ / åŸå§‹å­—ç¬¦ä¸² / å¤šè¡Œå­—ç¬¦ä¸² / inå’Œnot inè¿ç®—ç¬¦ / is_xxxæ–¹æ³• / joinå’Œsplitæ–¹æ³• / stripç›¸å…³æ–¹æ³• / pyperclipæ¨¡å— / ä¸å˜å­—ç¬¦ä¸²å’Œå¯å˜å­—ç¬¦ä¸² / StringIOçš„ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å…¥é—¨ - æ­£åˆ™è¡¨è¾¾å¼çš„ä½œç”¨ / å…ƒå­—ç¬¦ / è½¬ä¹‰ / é‡è¯ / åˆ†ç»„ / é›¶å®½æ–­è¨€ /è´ªå©ªåŒ¹é…ä¸æƒ°æ€§åŒ¹é…æ‡’æƒ° / ä½¿ç”¨reæ¨¡å—å®ç°æ­£åˆ™è¡¨è¾¾å¼æ“ä½œï¼ˆåŒ¹é…ã€æœç´¢ã€æ›¿æ¢ã€æ•è·ï¼‰ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ - reæ¨¡å— / compileå‡½æ•° / groupå’Œgroupsæ–¹æ³• / matchæ–¹æ³• / searchæ–¹æ³• / findallå’Œfinditeræ–¹æ³• / subå’Œsubnæ–¹æ³• / splitæ–¹æ³•åº”ç”¨æ¡ˆä¾‹ - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼éªŒè¯è¾“å…¥çš„å­—ç¬¦ä¸²Day13 - è¿›ç¨‹å’Œçº¿ç¨‹è¿›ç¨‹å’Œçº¿ç¨‹çš„æ¦‚å¿µ - ä»€ä¹ˆæ˜¯è¿›ç¨‹ / ä»€ä¹ˆæ˜¯çº¿ç¨‹ / å¤šçº¿ç¨‹çš„åº”ç”¨åœºæ™¯ä½¿ç”¨è¿›ç¨‹ - forkå‡½æ•° / multiprocessingæ¨¡å— / è¿›ç¨‹æ±  / è¿›ç¨‹é—´é€šä¿¡ä½¿ç”¨çº¿ç¨‹ -  threadingæ¨¡å— / Threadç±» / RLockç±» / Conditionç±» / çº¿ç¨‹æ± Day14 - ç½‘ç»œç¼–ç¨‹å…¥é—¨å’Œç½‘ç»œåº”ç”¨å¼€å‘è®¡ç®—æœºç½‘ç»œåŸºç¡€ - è®¡ç®—æœºç½‘ç»œå‘å±•å² / â€œTCP-IPâ€æ¨¡å‹ / IPåœ°å€ / ç«¯å£ / åè®® / å…¶ä»–ç›¸å…³æ¦‚å¿µç½‘ç»œåº”ç”¨æ¨¡å¼ - â€œå®¢æˆ·ç«¯-æœåŠ¡å™¨â€æ¨¡å¼ / â€œæµè§ˆå™¨-æœåŠ¡å™¨â€æ¨¡å¼åŸºäºHTTPåè®®è®¿é—®ç½‘ç»œèµ„æº - ç½‘ç»œAPIæ¦‚è¿° / è®¿é—®URL / requestsä¸‰æ–¹åº“ / è§£æJSONæ ¼å¼æ•°æ®Pythonç½‘ç»œç¼–ç¨‹ - å¥—æ¥å­—çš„æ¦‚å¿µ / socketæ¨¡å— /  socketå‡½æ•° / åˆ›å»ºTCPæœåŠ¡å™¨ / åˆ›å»ºTCPå®¢æˆ·ç«¯ / åˆ›å»ºUDPæœåŠ¡å™¨ / åˆ›å»ºUDPå®¢æˆ·ç«¯ç”µå­é‚®ä»¶ - SMTPåè®® / POP3åè®® / IMAPåè®® / smtplibæ¨¡å— / poplibæ¨¡å— / imaplibæ¨¡å—çŸ­ä¿¡æœåŠ¡ - è°ƒç”¨çŸ­ä¿¡æœåŠ¡ç½‘å…³Day15 - å›¾åƒå’Œæ–‡æ¡£å¤„ç†ç”¨Pillowå¤„ç†å›¾ç‰‡ - å›¾ç‰‡è¯»å†™ / å›¾ç‰‡åˆæˆ / å‡ ä½•å˜æ¢ / è‰²å½©è½¬æ¢ / æ»¤é•œæ•ˆæœè¯»å†™Wordæ–‡æ¡£ - æ–‡æœ¬å†…å®¹çš„å¤„ç† / æ®µè½ / é¡µçœ‰å’Œé¡µè„š / æ ·å¼çš„å¤„ç†è¯»å†™Excelæ–‡ä»¶ - xlrd / xlwt / openpyxlDay16~Day20 - Pythonè¯­è¨€è¿›é˜¶ å¸¸ç”¨æ•°æ®ç»“æ„å‡½æ•°çš„é«˜çº§ç”¨æ³• - â€œä¸€ç­‰å…¬æ°‘â€ / é«˜é˜¶å‡½æ•° / Lambdaå‡½æ•° / ä½œç”¨åŸŸå’Œé—­åŒ… / è£…é¥°å™¨é¢å‘å¯¹è±¡é«˜çº§çŸ¥è¯† - â€œä¸‰å¤§æ”¯æŸ±â€ / ç±»ä¸ç±»ä¹‹é—´çš„å…³ç³» / åƒåœ¾å›æ”¶ / é­”æœ¯å±æ€§å’Œæ–¹æ³• / æ··å…¥ / å…ƒç±» / é¢å‘å¯¹è±¡è®¾è®¡åŸåˆ™ / GoFè®¾è®¡æ¨¡å¼è¿­ä»£å™¨å’Œç”Ÿæˆå™¨ - ç›¸å…³é­”æœ¯æ–¹æ³• / åˆ›å»ºç”Ÿæˆå™¨çš„ä¸¤ç§æ–¹å¼ /å¹¶å‘å’Œå¼‚æ­¥ç¼–ç¨‹ - å¤šçº¿ç¨‹ / å¤šè¿›ç¨‹ / å¼‚æ­¥IO / asyncå’ŒawaitDay21~30 - Webå‰ç«¯å…¥é—¨ç”¨HTMLæ ‡ç­¾æ‰¿è½½é¡µé¢å†…å®¹ç”¨CSSæ¸²æŸ“é¡µé¢ç”¨JavaScriptå¤„ç†äº¤äº’å¼è¡Œä¸ºjQueryå…¥é—¨å’Œæé«˜Vue.jså…¥é—¨Elementçš„ä½¿ç”¨Bootstrapçš„ä½¿ç”¨Day31~35 - ç©è½¬Linuxæ“ä½œç³»ç»Ÿæ“ä½œç³»ç»Ÿå‘å±•å²å’ŒLinuxæ¦‚è¿°LinuxåŸºç¡€å‘½ä»¤Linuxä¸­çš„å®ç”¨ç¨‹åºLinuxçš„æ–‡ä»¶ç³»ç»ŸVimç¼–è¾‘å™¨çš„åº”ç”¨ç¯å¢ƒå˜é‡å’ŒShellç¼–ç¨‹è½¯ä»¶çš„å®‰è£…å’ŒæœåŠ¡çš„é…ç½®ç½‘ç»œè®¿é—®å’Œç®¡ç†å…¶ä»–ç›¸å…³å†…å®¹Day36~40 - æ•°æ®åº“åŸºç¡€å’Œè¿›é˜¶å…³ç³»å‹æ•°æ®åº“æ¦‚è¿°MySQLçš„å®‰è£…å’Œä½¿ç”¨SQLçš„ä½¿ç”¨DDL - æ•°æ®å®šä¹‰è¯­è¨€ - create / drop / alterDML - æ•°æ®æ“ä½œè¯­è¨€ - insert / delete / updateDQL - æ•°æ®æŸ¥è¯¢è¯­è¨€ - selectDCL - æ•°æ®æ§åˆ¶è¯­è¨€ - grant / revokeMySQLæ–°ç‰¹æ€§çª—å£å‡½æ•°çš„åº”ç”¨JSONæ•°æ®ç±»å‹ç›¸å…³çŸ¥è¯†æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§è§†å›¾ã€å‡½æ•°ã€è¿‡ç¨‹ã€è§¦å‘å™¨äº‹åŠ¡å’Œé”æ‰§è¡Œè®¡åˆ’å’Œç´¢å¼•èŒƒå¼ç†è®ºå’ŒåèŒƒå¼è®¾è®¡åœ¨Pythonä¸­æ“ä½œMySQLDay41~55 - å®æˆ˜DjangoDay41 - Djangoå¿«é€Ÿä¸Šæ‰‹Webåº”ç”¨å·¥ä½œæœºåˆ¶HTTPè¯·æ±‚å’Œå“åº”Djangoæ¡†æ¶æ¦‚è¿°5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹Day42 - æ·±å…¥æ¨¡å‹å…³ç³»å‹æ•°æ®åº“é…ç½®ä½¿ç”¨ORMå®Œæˆå¯¹æ¨¡å‹çš„CRUDæ“ä½œç®¡ç†åå°çš„ä½¿ç”¨Djangoæ¨¡å‹æœ€ä½³å®è·µæ¨¡å‹å®šä¹‰å‚è€ƒDay43 - é™æ€èµ„æºå’ŒAjaxè¯·æ±‚åŠ è½½é™æ€èµ„æºAjaxæ¦‚è¿°ç”¨Ajaxå®ç°æŠ•ç¥¨åŠŸèƒ½Day44 - Cookieå’ŒSessionå®ç°ç”¨æˆ·è·Ÿè¸ªcookieå’Œsessionçš„å…³ç³»Djangoæ¡†æ¶å¯¹sessionçš„æ”¯æŒè§†å›¾å‡½æ•°ä¸­çš„cookieè¯»å†™æ“ä½œDay45 - æŠ¥è¡¨å’Œæ—¥å¿—é€šè¿‡HttpResponseä¿®æ”¹å“åº”å¤´ä½¿ç”¨StreamingHttpResponseå¤„ç†å¤§æ–‡ä»¶ä½¿ç”¨xlwtç”ŸæˆExcelæŠ¥è¡¨ä½¿ç”¨reportlabç”ŸæˆPDFæŠ¥è¡¨ä½¿ç”¨EChartsç”Ÿæˆå‰ç«¯å›¾è¡¨Day46 - æ—¥å¿—å’Œè°ƒè¯•å·¥å…·æ é…ç½®æ—¥å¿—é…ç½®Django-Debug-Toolbarä¼˜åŒ–ORMä»£ç Day47 - ä¸­é—´ä»¶çš„åº”ç”¨ä»€ä¹ˆæ˜¯ä¸­é—´ä»¶Djangoæ¡†æ¶å†…ç½®çš„ä¸­é—´ä»¶è‡ªå®šä¹‰ä¸­é—´ä»¶åŠå…¶åº”ç”¨åœºæ™¯Day48 - å‰åç«¯åˆ†ç¦»å¼€å‘å…¥é—¨è¿”å›JSONæ ¼å¼çš„æ•°æ®ç”¨Vue.jsæ¸²æŸ“é¡µé¢Day49 - RESTfulæ¶æ„å’ŒDRFå…¥é—¨Day50 - RESTfulæ¶æ„å’ŒDRFè¿›é˜¶Day51 - ä½¿ç”¨ç¼“å­˜ç½‘ç«™ä¼˜åŒ–ç¬¬ä¸€å®šå¾‹åœ¨Djangoé¡¹ç›®ä¸­ä½¿ç”¨Redisæä¾›ç¼“å­˜æœåŠ¡åœ¨è§†å›¾å‡½æ•°ä¸­è¯»å†™ç¼“å­˜ä½¿ç”¨è£…é¥°å™¨å®ç°é¡µé¢ç¼“å­˜ä¸ºæ•°æ®æ¥å£æä¾›ç¼“å­˜æœåŠ¡Day52 - æ¥å…¥ä¸‰æ–¹å¹³å°æ–‡ä»¶ä¸Šä¼ è¡¨å•æ§ä»¶å’Œå›¾ç‰‡æ–‡ä»¶é¢„è§ˆæœåŠ¡å™¨ç«¯å¦‚ä½•å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶Day53 - å¼‚æ­¥ä»»åŠ¡å’Œå®šæ—¶ä»»åŠ¡ç½‘ç«™ä¼˜åŒ–ç¬¬äºŒå®šå¾‹é…ç½®æ¶ˆæ¯é˜Ÿåˆ—æœåŠ¡åœ¨é¡¹ç›®ä¸­ä½¿ç”¨Celeryå®ç°ä»»åŠ¡å¼‚æ­¥åŒ–åœ¨é¡¹ç›®ä¸­ä½¿ç”¨Celeryå®ç°å®šæ—¶ä»»åŠ¡Day54 - å•å…ƒæµ‹è¯•Day55 - é¡¹ç›®ä¸Šçº¿Pythonä¸­çš„å•å…ƒæµ‹è¯•Djangoæ¡†æ¶å¯¹å•å…ƒæµ‹è¯•çš„æ”¯æŒä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿé…ç½®å’Œä½¿ç”¨uWSGIåŠ¨é™åˆ†ç¦»å’ŒNginxé…ç½®é…ç½®HTTPSé…ç½®åŸŸåè§£æDay56~60 - ç”¨FastAPIå¼€å‘æ•°æ®æ¥å£FastAPIäº”åˆ†é’Ÿä¸Šæ‰‹è¯·æ±‚å’Œå“åº”æ¥å…¥å…³ç³»å‹æ•°æ®åº“ä¾èµ–æ³¨å…¥ä¸­é—´ä»¶å¼‚æ­¥åŒ–è™šæ‹ŸåŒ–éƒ¨ç½²ï¼ˆDockerï¼‰é¡¹ç›®å®æˆ˜ï¼šè½¦è¾†è¿ç« æŸ¥è¯¢é¡¹ç›®Day61~65 - çˆ¬è™«å¼€å‘Day61 - ç½‘ç»œæ•°æ®é‡‡é›†æ¦‚è¿°ç½‘ç»œçˆ¬è™«çš„æ¦‚å¿µåŠå…¶åº”ç”¨é¢†åŸŸç½‘ç»œçˆ¬è™«çš„åˆæ³•æ€§æ¢è®¨å¼€å‘ç½‘ç»œçˆ¬è™«çš„ç›¸å…³å·¥å…·ä¸€ä¸ªçˆ¬è™«ç¨‹åºçš„æ„æˆDay62 - æ•°æ®æŠ“å–å’Œè§£æä½¿ç”¨requestsä¸‰æ–¹åº“å®ç°æ•°æ®æŠ“å–é¡µé¢è§£æçš„ä¸‰ç§æ–¹å¼æ­£åˆ™è¡¨è¾¾å¼è§£æXPathè§£æCSSé€‰æ‹©å™¨è§£æDay63 - Pythonä¸­çš„å¹¶å‘ç¼–ç¨‹å¤šçº¿ç¨‹å¤šè¿›ç¨‹å¼‚æ­¥I/ODay64 - ä½¿ç”¨SeleniumæŠ“å–ç½‘é¡µåŠ¨æ€å†…å®¹Day65 - çˆ¬è™«æ¡†æ¶Scrapyç®€ä»‹Day66~80 - æ•°æ®åˆ†æDay66 - æ•°æ®åˆ†ææ¦‚è¿°Day67 - ç¯å¢ƒå‡†å¤‡Day68 - NumPyçš„åº”ç”¨-1Day69 - NumPyçš„åº”ç”¨-2Day70 - Pandasçš„åº”ç”¨-1Day71 - Pandasçš„åº”ç”¨-2Day72 - Pandasçš„åº”ç”¨-3Day73 - Pandasçš„åº”ç”¨-4Day74 - Pandasçš„åº”ç”¨-5Day75 - æ•°æ®å¯è§†åŒ–-1Day76 - æ•°æ®å¯è§†åŒ–-2Day77 - æ¦‚ç‡ç»Ÿè®¡åŸºç¡€Day78 - æ–¹å·®åˆ†æå’Œå‚æ•°ä¼°è®¡Day79 - ç›¸å…³å’Œå›å½’Day80 - æ•°æ®åˆ†ææ–¹æ³•è®ºDay81~90 - æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ Day81 - æœºå™¨å­¦ä¹ åŸºç¡€Day82 - kæœ€è¿‘é‚»åˆ†ç±»Day83 - å†³ç­–æ ‘Day84 - è´å¶æ–¯åˆ†ç±»Day85 - æ”¯æŒå‘é‡æœºDay86 - K-å‡å€¼èšç±»Day87 - å›å½’åˆ†æDay88 - æ·±åº¦å­¦ä¹ å…¥é—¨Day89 - PyTorchæ¦‚è¿°Day90 - PyTorchå®æˆ˜Day91~100 - å›¢é˜Ÿé¡¹ç›®å¼€å‘ç¬¬91å¤©ï¼šå›¢é˜Ÿé¡¹ç›®å¼€å‘çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆè½¯ä»¶è¿‡ç¨‹æ¨¡å‹ç»å…¸è¿‡ç¨‹æ¨¡å‹ï¼ˆç€‘å¸ƒæ¨¡å‹ï¼‰å¯è¡Œæ€§åˆ†æï¼ˆç ”ç©¶åšè¿˜æ˜¯ä¸åšï¼‰ï¼Œè¾“å‡ºã€Šå¯è¡Œæ€§åˆ†ææŠ¥å‘Šã€‹ã€‚éœ€æ±‚åˆ†æï¼ˆç ”ç©¶åšä»€ä¹ˆï¼‰ï¼Œè¾“å‡ºã€Šéœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦ã€‹å’Œäº§å“ç•Œé¢åŸå‹å›¾ã€‚æ¦‚è¦è®¾è®¡å’Œè¯¦ç»†è®¾è®¡ï¼Œè¾“å‡ºæ¦‚å¿µæ¨¡å‹å›¾ï¼ˆERå›¾ï¼‰ã€ç‰©ç†æ¨¡å‹å›¾ã€ç±»å›¾ã€æ—¶åºå›¾ç­‰ã€‚ç¼–ç  / æµ‹è¯•ã€‚ä¸Šçº¿ / ç»´æŠ¤ã€‚ç€‘å¸ƒæ¨¡å‹æœ€å¤§çš„ç¼ºç‚¹æ˜¯æ— æ³•æ‹¥æŠ±éœ€æ±‚å˜åŒ–ï¼Œæ•´å¥—æµç¨‹ç»“æŸåæ‰èƒ½çœ‹åˆ°äº§å“ï¼Œå›¢é˜Ÿå£«æ°”ä½è½ã€‚æ•æ·å¼€å‘ï¼ˆScrumï¼‰- äº§å“æ‰€æœ‰è€…ã€Scrum Masterã€ç ”å‘äººå‘˜ - Sprintäº§å“çš„Backlogï¼ˆç”¨æˆ·æ•…äº‹ã€äº§å“åŸå‹ï¼‰ã€‚è®¡åˆ’ä¼šè®®ï¼ˆè¯„ä¼°å’Œé¢„ç®—ï¼‰ã€‚æ—¥å¸¸å¼€å‘ï¼ˆç«™ç«‹ä¼šè®®ã€ç•ªèŒ„å·¥ä½œæ³•ã€ç»“å¯¹ç¼–ç¨‹ã€æµ‹è¯•å…ˆè¡Œã€ä»£ç é‡æ„â€¦â€¦ï¼‰ã€‚ä¿®å¤bugï¼ˆé—®é¢˜æè¿°ã€é‡ç°æ­¥éª¤ã€æµ‹è¯•äººå‘˜ã€è¢«æŒ‡æ´¾äººï¼‰ã€‚å‘å¸ƒç‰ˆæœ¬ã€‚è¯„å®¡ä¼šè®®ï¼ˆShowcaseï¼Œç”¨æˆ·éœ€è¦å‚ä¸ï¼‰ã€‚å›é¡¾ä¼šè®®ï¼ˆå¯¹å½“å‰è¿­ä»£å‘¨æœŸåšä¸€ä¸ªæ€»ç»“ï¼‰ã€‚è¡¥å……ï¼šæ•æ·è½¯ä»¶å¼€å‘å®£è¨€ä¸ªä½“å’Œäº’åŠ¨ é«˜äº æµç¨‹å’Œå·¥å…·å·¥ä½œçš„è½¯ä»¶ é«˜äº è¯¦å°½çš„æ–‡æ¡£å®¢æˆ·åˆä½œ é«˜äº åˆåŒè°ˆåˆ¤å“åº”å˜åŒ– é«˜äº éµå¾ªè®¡åˆ’è§’è‰²ï¼šäº§å“æ‰€æœ‰è€…ï¼ˆå†³å®šåšä»€ä¹ˆï¼Œèƒ½å¯¹éœ€æ±‚æ‹æ¿çš„äººï¼‰ã€å›¢é˜Ÿè´Ÿè´£äººï¼ˆè§£å†³å„ç§é—®é¢˜ï¼Œä¸“æ³¨å¦‚ä½•æ›´å¥½çš„å·¥ä½œï¼Œå±è”½å¤–éƒ¨å¯¹å¼€å‘å›¢é˜Ÿçš„å½±å“ï¼‰ã€å¼€å‘å›¢é˜Ÿï¼ˆé¡¹ç›®æ‰§è¡Œäººå‘˜ï¼Œå…·ä½“æŒ‡å¼€å‘äººå‘˜å’Œæµ‹è¯•äººå‘˜ï¼‰ã€‚å‡†å¤‡å·¥ä½œï¼šå•†ä¸šæ¡ˆä¾‹å’Œèµ„é‡‘ã€åˆåŒã€æ†§æ†¬ã€åˆå§‹äº§å“éœ€æ±‚ã€åˆå§‹å‘å¸ƒè®¡åˆ’ã€å…¥è‚¡ã€ç»„å»ºå›¢é˜Ÿã€‚æ•æ·å›¢é˜Ÿé€šå¸¸äººæ•°ä¸º8-10äººã€‚å·¥ä½œé‡ä¼°ç®—ï¼šå°†å¼€å‘ä»»åŠ¡é‡åŒ–ï¼ŒåŒ…æ‹¬åŸå‹ã€Logoè®¾è®¡ã€UIè®¾è®¡ã€å‰ç«¯å¼€å‘ç­‰ï¼Œå°½é‡æŠŠæ¯ä¸ªå·¥ä½œåˆ†è§£åˆ°æœ€å°ä»»åŠ¡é‡ï¼Œæœ€å°ä»»åŠ¡é‡æ ‡å‡†ä¸ºå·¥ä½œæ—¶é—´ä¸èƒ½è¶…è¿‡ä¸¤å¤©ï¼Œç„¶åä¼°ç®—æ€»ä½“é¡¹ç›®æ—¶é—´ã€‚æŠŠæ¯ä¸ªä»»åŠ¡éƒ½è´´åœ¨çœ‹æ¿ä¸Šé¢ï¼Œçœ‹æ¿ä¸Šåˆ†ä¸‰éƒ¨åˆ†ï¼što doï¼ˆå¾…å®Œæˆï¼‰ã€in progressï¼ˆè¿›è¡Œä¸­ï¼‰å’Œdoneï¼ˆå·²å®Œæˆï¼‰ã€‚é¡¹ç›®å›¢é˜Ÿç»„å»ºå›¢é˜Ÿçš„æ„æˆå’Œè§’è‰²è¯´æ˜ï¼šè°¢è°¢ä»˜ç¥¥è‹±å¥³å£«å¸®åŠ©æˆ‘ç»˜åˆ¶äº†ä¸‹é¢è¿™å¼ ç²¾ç¾çš„å…¬å¸ç»„ç»‡æ¶æ„å›¾ã€‚ç¼–ç¨‹è§„èŒƒå’Œä»£ç å®¡æŸ¥ï¼ˆflake8ã€pylintï¼‰Pythonä¸­çš„ä¸€äº›â€œæƒ¯ä¾‹â€ï¼ˆè¯·å‚è€ƒã€ŠPythonæƒ¯ä¾‹-å¦‚ä½•ç¼–å†™Pythonicçš„ä»£ç ã€‹ï¼‰å½±å“ä»£ç å¯è¯»æ€§çš„åŸå› ï¼šä»£ç æ³¨é‡Šå¤ªå°‘æˆ–è€…æ²¡æœ‰æ³¨é‡Šä»£ç ç ´åäº†è¯­è¨€çš„æœ€ä½³å®è·µåæ¨¡å¼ç¼–ç¨‹ï¼ˆæ„å¤§åˆ©é¢ä»£ç ã€å¤åˆ¶-é»è´´ç¼–ç¨‹ã€è‡ªè´Ÿç¼–ç¨‹ã€â€¦â€¦ï¼‰å›¢é˜Ÿå¼€å‘å·¥å…·ä»‹ç»ç‰ˆæœ¬æ§åˆ¶ï¼šGitã€Mercuryç¼ºé™·ç®¡ç†ï¼šGitlabã€Redmineæ•æ·é—­ç¯å·¥å…·ï¼šç¦…é“ã€JIRAæŒç»­é›†æˆï¼šJenkinsã€Travis-CIè¯·å‚è€ƒã€Šå›¢é˜Ÿé¡¹ç›®å¼€å‘çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆã€‹ã€‚é¡¹ç›®é€‰é¢˜å’Œç†è§£ä¸šåŠ¡é€‰é¢˜èŒƒå›´è®¾å®šCMSï¼ˆç”¨æˆ·ç«¯ï¼‰ï¼šæ–°é—»èšåˆç½‘ç«™ã€é—®ç­”/åˆ†äº«ç¤¾åŒºã€å½±è¯„/ä¹¦è¯„ç½‘ç«™ç­‰ã€‚MISï¼ˆç”¨æˆ·ç«¯+ç®¡ç†ç«¯ï¼‰ï¼šKMSã€KPIè€ƒæ ¸ç³»ç»Ÿã€HRSã€CRMç³»ç»Ÿã€ä¾›åº”é“¾ç³»ç»Ÿã€ä»“å‚¨ç®¡ç†ç³»ç»Ÿç­‰ã€‚Appåå°ï¼ˆç®¡ç†ç«¯+æ•°æ®æ¥å£ï¼‰ï¼šäºŒæ‰‹äº¤æ˜“ç±»ã€æŠ¥åˆŠæ‚å¿—ç±»ã€å°ä¼—ç”µå•†ç±»ã€æ–°é—»èµ„è®¯ç±»ã€æ—…æ¸¸ç±»ã€ç¤¾äº¤ç±»ã€é˜…è¯»ç±»ç­‰ã€‚å…¶ä»–ç±»å‹ï¼šè‡ªèº«è¡Œä¸šèƒŒæ™¯å’Œå·¥ä½œç»éªŒã€ä¸šåŠ¡å®¹æ˜“ç†è§£å’ŒæŠŠæ§ã€‚éœ€æ±‚ç†è§£ã€æ¨¡å—åˆ’åˆ†å’Œä»»åŠ¡åˆ†é…éœ€æ±‚ç†è§£ï¼šå¤´è„‘é£æš´å’Œç«å“åˆ†æã€‚æ¨¡å—åˆ’åˆ†ï¼šç”»æ€ç»´å¯¼å›¾ï¼ˆXMindï¼‰ï¼Œæ¯ä¸ªæ¨¡å—æ˜¯ä¸€ä¸ªæèŠ‚ç‚¹ï¼Œæ¯ä¸ªå…·ä½“çš„åŠŸèƒ½æ˜¯ä¸€ä¸ªå¶èŠ‚ç‚¹ï¼ˆç”¨åŠ¨è¯è¡¨è¿°ï¼‰ï¼Œéœ€è¦ç¡®ä¿æ¯ä¸ªå¶èŠ‚ç‚¹æ— æ³•å†ç”Ÿå‡ºæ–°èŠ‚ç‚¹ï¼Œç¡®å®šæ¯ä¸ªå¶å­èŠ‚ç‚¹çš„é‡è¦æ€§ã€ä¼˜å…ˆçº§å’Œå·¥ä½œé‡ã€‚ä»»åŠ¡åˆ†é…ï¼šç”±é¡¹ç›®è´Ÿè´£äººæ ¹æ®ä¸Šé¢çš„æŒ‡æ ‡ä¸ºæ¯ä¸ªå›¢é˜Ÿæˆå‘˜åˆ†é…ä»»åŠ¡ã€‚åˆ¶å®šé¡¹ç›®è¿›åº¦è¡¨ï¼ˆæ¯æ—¥æ›´æ–°ï¼‰æ¨¡å—åŠŸèƒ½äººå‘˜çŠ¶æ€å®Œæˆå·¥æ—¶è®¡åˆ’å¼€å§‹å®é™…å¼€å§‹è®¡åˆ’ç»“æŸå®é™…ç»“æŸå¤‡æ³¨è¯„è®ºæ·»åŠ è¯„è®ºç‹å¤§é”¤æ­£åœ¨è¿›è¡Œ50%42018/8/72018/8/7åˆ é™¤è¯„è®ºç‹å¤§é”¤ç­‰å¾…0%22018/8/72018/8/7æŸ¥çœ‹è¯„è®ºç™½å…ƒèŠ³æ­£åœ¨è¿›è¡Œ20%42018/8/72018/8/7éœ€è¦è¿›è¡Œä»£ç å®¡æŸ¥è¯„è®ºæŠ•ç¥¨ç™½å…ƒèŠ³ç­‰å¾…0%42018/8/82018/8/8OOADå’Œæ•°æ®åº“è®¾è®¡UMLï¼ˆç»Ÿä¸€å»ºæ¨¡è¯­è¨€ï¼‰çš„ç±»å›¾é€šè¿‡æ¨¡å‹åˆ›å»ºè¡¨ï¼ˆæ­£å‘å·¥ç¨‹ï¼‰ï¼Œä¾‹å¦‚åœ¨Djangoé¡¹ç›®ä¸­å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤åˆ›å»ºäºŒç»´è¡¨ã€‚python manage.py makemigrations apppython manage.py migrateä½¿ç”¨PowerDesignerç»˜åˆ¶ç‰©ç†æ¨¡å‹å›¾ã€‚é€šè¿‡æ•°æ®è¡¨åˆ›å»ºæ¨¡å‹ï¼ˆåå‘å·¥ç¨‹ï¼‰ï¼Œä¾‹å¦‚åœ¨Djangoé¡¹ç›®ä¸­å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤ç”Ÿæˆæ¨¡å‹ã€‚python manage.py inspectdb > app/models.pyç¬¬92å¤©ï¼šDockerå®¹å™¨è¯¦è§£Dockerç®€ä»‹å®‰è£…Dockerä½¿ç”¨Dockeråˆ›å»ºå®¹å™¨ï¼ˆNginxã€MySQLã€Redisã€Gitlabã€Jenkinsï¼‰æ„å»ºDockeré•œåƒï¼ˆDockerfileçš„ç¼–å†™å’Œç›¸å…³æŒ‡ä»¤ï¼‰å®¹å™¨ç¼–æ’ï¼ˆDocker-composeï¼‰é›†ç¾¤ç®¡ç†ï¼ˆKubernetesï¼‰ç¬¬93å¤©ï¼šMySQLæ€§èƒ½ä¼˜åŒ–ç¬¬94å¤©ï¼šç½‘ç»œAPIæ¥å£è®¾è®¡ç¬¬95å¤©ï¼š[ä½¿ç”¨Djangoå¼€å‘å•†ä¸šé¡¹ç›®](./Day91-100/95.ä½¿ç”¨Djangoå¼€å‘å•†ä¸šé¡¹\tç›®.md)é¡¹ç›®å¼€å‘ä¸­çš„å…¬å…±é—®é¢˜æ•°æ®åº“çš„é…ç½®ï¼ˆå¤šæ•°æ®åº“ã€ä¸»ä»å¤åˆ¶ã€æ•°æ®åº“è·¯ç”±ï¼‰ç¼“å­˜çš„é…ç½®ï¼ˆåˆ†åŒºç¼“å­˜ã€é”®è®¾ç½®ã€è¶…æ—¶è®¾ç½®ã€ä¸»ä»å¤åˆ¶ã€æ•…éšœæ¢å¤ï¼ˆå“¨å…µï¼‰ï¼‰æ—¥å¿—çš„é…ç½®åˆ†æå’Œè°ƒè¯•ï¼ˆDjango-Debug-ToolBarï¼‰å¥½ç”¨çš„Pythonæ¨¡å—ï¼ˆæ—¥æœŸè®¡ç®—ã€å›¾åƒå¤„ç†ã€æ•°æ®åŠ å¯†ã€ä¸‰æ–¹APIï¼‰REST APIè®¾è®¡RESTfulæ¶æ„ç†è§£RESTfulæ¶æ„RESTful APIè®¾è®¡æŒ‡å—RESTful APIæœ€ä½³å®è·µAPIæ¥å£æ–‡æ¡£çš„æ’°å†™RAP2YAPIdjango-REST-frameworkçš„åº”ç”¨é¡¹ç›®ä¸­çš„é‡ç‚¹éš¾ç‚¹å‰–æä½¿ç”¨ç¼“å­˜ç¼“è§£æ•°æ®åº“å‹åŠ› - Redisä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—åšè§£è€¦åˆå’Œå‰Šå³° - Celery + RabbitMQç¬¬96å¤©ï¼šè½¯ä»¶æµ‹è¯•å’Œè‡ªåŠ¨åŒ–æµ‹è¯•å•å…ƒæµ‹è¯•æµ‹è¯•çš„ç§ç±»ç¼–å†™å•å…ƒæµ‹è¯•ï¼ˆunittestã€pytestã€nose2ã€toxã€ddtã€â€¦â€¦ï¼‰æµ‹è¯•è¦†ç›–ç‡ï¼ˆcoverageï¼‰Djangoé¡¹ç›®éƒ¨ç½²éƒ¨ç½²å‰çš„å‡†å¤‡å·¥ä½œå…³é”®è®¾ç½®ï¼ˆSECRET_KEY / DEBUG / ALLOWED_HOSTS / ç¼“å­˜ / æ•°æ®åº“ï¼‰HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECUREæ—¥å¿—ç›¸å…³é…ç½®Linuxå¸¸ç”¨å‘½ä»¤å›é¡¾Linuxå¸¸ç”¨æœåŠ¡çš„å®‰è£…å’Œé…ç½®uWSGI/Gunicornå’ŒNginxçš„ä½¿ç”¨Gunicornå’ŒuWSGIçš„æ¯”è¾ƒå¯¹äºä¸éœ€è¦å¤§é‡å®šåˆ¶åŒ–çš„ç®€å•åº”ç”¨ç¨‹åºï¼ŒGunicornæ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ï¼ŒuWSGIçš„å­¦ä¹ æ›²çº¿æ¯”Gunicornè¦é™¡å³­å¾—å¤šï¼ŒGunicornçš„é»˜è®¤å‚æ•°å°±å·²ç»èƒ½å¤Ÿé€‚åº”å¤§å¤šæ•°åº”ç”¨ç¨‹åºã€‚uWSGIæ”¯æŒå¼‚æ„éƒ¨ç½²ã€‚ç”±äºNginxæœ¬èº«æ”¯æŒuWSGIï¼Œåœ¨çº¿ä¸Šä¸€èˆ¬éƒ½å°†Nginxå’ŒuWSGIæ†ç»‘åœ¨ä¸€èµ·éƒ¨ç½²ï¼Œè€Œä¸”uWSGIå±äºåŠŸèƒ½é½å…¨ä¸”é«˜åº¦å®šåˆ¶çš„WSGIä¸­é—´ä»¶ã€‚åœ¨æ€§èƒ½ä¸Šï¼ŒGunicornå’ŒuWSGIå…¶å®è¡¨ç°ç›¸å½“ã€‚ä½¿ç”¨è™šæ‹ŸåŒ–æŠ€æœ¯ï¼ˆDockerï¼‰éƒ¨ç½²æµ‹è¯•ç¯å¢ƒå’Œç”Ÿäº§ç¯å¢ƒæ€§èƒ½æµ‹è¯•ABçš„ä½¿ç”¨SQLslapçš„ä½¿ç”¨sysbenchçš„ä½¿ç”¨è‡ªåŠ¨åŒ–æµ‹è¯•ä½¿ç”¨Shellå’ŒPythonè¿›è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•ä½¿ç”¨Seleniumå®ç°è‡ªåŠ¨åŒ–æµ‹è¯•Selenium IDESelenium WebDriverSelenium Remote Controlæµ‹è¯•å·¥å…·Robot Frameworkä»‹ç»ç¬¬97å¤©ï¼šç”µå•†ç½‘ç«™æŠ€æœ¯è¦ç‚¹å‰–æç¬¬98å¤©ï¼šé¡¹ç›®éƒ¨ç½²ä¸Šçº¿å’Œæ€§èƒ½è°ƒä¼˜MySQLæ•°æ®åº“è°ƒä¼˜WebæœåŠ¡å™¨æ€§èƒ½ä¼˜åŒ–Nginxè´Ÿè½½å‡è¡¡é…ç½®Keepalivedå®ç°é«˜å¯ç”¨ä»£ç æ€§èƒ½è°ƒä¼˜å¤šçº¿ç¨‹å¼‚æ­¥åŒ–é™æ€èµ„æºè®¿é—®ä¼˜åŒ–äº‘å­˜å‚¨CDNç¬¬99å¤©ï¼šé¢è¯•ä¸­çš„å…¬å…±é—®é¢˜ç¬¬100å¤©ï¼šPythoné¢è¯•é¢˜å®å½•"
79,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
80,Significant-Gravitas/Auto-GPT,https://github.com/Significant-Gravitas/Auto-GPT/blob/master/README.md,Python,"Auto-GPT: An Autonomous GPT-4 ExperimentğŸ’¡ Get help - Q&A or Discord ğŸ’¬ğŸ”´ USE stable not master ğŸ”´Download the latest stable release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.The master branch is under heavy development and may often be in a broken state.Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \""thoughts\"", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI. Demo April 16th 2023               AutoGPTDemo_Subs_WithoutFinalScreen.mp4          Demo made by Blake WerlingerğŸš€ FeaturesğŸŒ Internet access for searches and information gatheringğŸ’¾ Long-term and short-term memory managementğŸ§  GPT-4 instances for text generationğŸ”— Access to popular websites and platformsğŸ—ƒï¸ File storage and summarization with GPT-3.5ğŸ”Œ Extensibility with PluginsQuickstartCheck out the wikiGet an OpenAI API KeyDownload the latest releaseFollow the installation instructionsConfigure any additional features you want, or install some pluginsRun the appPlease see the documentation for full setup instructions and configuration options.ğŸ“– Documentationâš™ï¸ SetupğŸ’» UsageğŸ”Œ PluginsConfigurationğŸ” Web SearchğŸ§  MemoryğŸ—£ï¸ Voice (TTS)ğŸ–¼ï¸ Image Generation ğŸ’– Help Fund Auto-GPT's Development ğŸ’–If you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help to push the boundaries of fully autonomous AI!Your support is greatly appreciated. Development of this free, open-source project is made possible by all the contributors and sponsors. If you'd like to sponsor this project and have your avatar or company logo appear below click here.                Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â âš ï¸ LimitationsThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:Not a polished application or product, just an experimentMay not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!Quite expensive to run, so set and monitor your API key limits with OpenAI!ğŸ›¡ DisclaimerThis project, Auto-GPT, is an experimental application and is provided \""as-is\"" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.The developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.Please note that the use of the GPT-4 language model can be expensive due to its token usage. By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.As an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.By using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.ğŸ¦ Connect with Us on TwitterStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.Developer: Follow @siggravitas for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!        "
81,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        ç®€ä½“ä¸­æ–‡ |        ç¹é«”ä¸­æ–‡ |        í•œêµ­ì–´ |        EspaÃ±ol |        æ—¥æœ¬èª |        à¤¹à¤¿à¤¨à¥à¤¦à¥€        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    ğŸ¤— Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:ğŸ“ Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.ğŸ–¼ï¸ Images, for tasks like image classification, object detection, and segmentation.ğŸ—£ï¸ Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.ğŸ¤— Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.ğŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install ğŸ¤— Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, ğŸ¤— Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.ğŸ¤— Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by ğŸ¤— Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: ğŸ¤— Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from Ã‰cole polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz SuÃ¡rez*, Yoann Dupont, Laurent Romary, Ã‰ric Villemonte de la Clergerie, DjamÃ© Seddah and BenoÃ®t Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of GÃ¶ttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo LÃ¼ddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, HervÃ© JÃ©gou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp KrÃ¤henbÃ¼hl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, TimothÃ©e Darcet, ThÃ©o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, HervÃ© Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas OÄŸuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by RenÃ© Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre DÃ©fossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, LoÃ¯c Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, BenoÃ®t CrabbÃ©, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey Ã–hman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo GarcÃ­a del RÃ­o, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, HervÃ© JÃ©gou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by JÃ¶rg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre DÃ©fossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noahâ€™s Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NystrÃ¶mformer (from the University of Wisconsin - Madison) released with the paper NystrÃ¶mformer: A NystrÃ¶m-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier HÃ©naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, JoÃ£o Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, Åukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr DollÃ¡r.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault FÃ©vry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of WÃ¼rzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, PaweÅ‚ Krzysztof Nowak, Thomas MÃ¼ller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÃ¡r, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario LuÄiÄ‡, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper â€‹XLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the ğŸ¤— Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by ğŸ¤— TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by ğŸ¤— Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the ğŸ¤— Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
82,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answersâš ï¸ DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]ğŸ™ PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!ğŸ‰ AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.â“ Need help?Open new issueğŸ”¥ Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accountingâ—needs updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustratorâ—needs updating  7674Adobe-InDesignâ—needs updating  4240Adobe-Lightroomâ—needs updating  2020Adobe-Photoshopâ—needs updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effectsâ—needs updating  2413Agile Methodologiesâ—needs updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCADâ—needs updating  7775@djayorAutodesk Fusion 360â—needs updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambdaâ—needs updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++â—needs updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurityâ—needs updating10196Django7171@PROCW.NET Framework6359@declarckEclipseâ—needs updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSONâ—needs updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excelâ—needs updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Projectâ—needs updating4443Microsoft Wordâ—needs updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooksâ—needs updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revitâ—needs updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePointâ—needs updating5338Sketchup22SOLIDWORKSâ—needs updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnityâ—needs updating4746@uno-sebastianVisual Basic for Applications (VBA)â—needs updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors âœ¨Thanks goes to these wonderful people (emoji key):            EvgeniiğŸ’» ğŸ–‹      Sergei StadnikğŸ’» ğŸ” ğŸ¤” ğŸ“–      SanthoshğŸ’»      Jacob DsağŸ’» ğŸ–‹      Aaron MeeseğŸ’» ğŸ–‹      arqarqğŸ’» ğŸ–‹      Amit YadavğŸ’» ğŸ–‹              Javokhir NazarovğŸ’» ğŸ–‹      saurav kumarğŸ–‹      ChetanğŸ–‹      Amir Hossein ShekariğŸ¨ ğŸ–‹ ğŸ’»      SergDautğŸ¨      Nilotpal PramanikğŸ¨ ğŸ’» ğŸ–‹ ğŸ’¼ ğŸ“– ğŸ”£ ğŸ’¡      Abhishek KumarğŸ¨              Monu GuptağŸ¨      KARTIKEYA GUPTAğŸ’» ğŸ–‹      kenkyushağŸ’» ğŸ–‹      juandavidtowersğŸ’» ğŸ–‹      cyber-neticsğŸ’» ğŸ–‹      jtriswğŸ’» ğŸ–‹      Renato RegaladoğŸ’» ğŸ–‹              MatthewğŸ’» ğŸ–‹      Jan S.ğŸ’» ğŸ–‹      ManoliğŸ’» ğŸ–‹      Faraz tanveerğŸ’» ğŸ–‹      mohnishkarriğŸ’» ğŸ–‹ ğŸ¨      andyzhuğŸ’» ğŸ–‹      Vishal KushwahğŸ’» ğŸ–‹              Yurii YakymenkoğŸ’» ğŸ–‹      Swetabh SumanğŸ’» ğŸ–‹      AJAY DANDGEğŸ’» ğŸ–‹      Mehmet YesinğŸ¨      Lok Chun WaiğŸ¨      Adria de JuanğŸ¨      GL-ManğŸ¨              Jheel PatelğŸ¨      Sameer WaskarğŸ¨      Alexander AndrewsğŸ¨      Alexander MaxwellğŸ¨      SlavağŸ¨      Mayur KhatriğŸ¨      MascantoshğŸ’» ğŸ–‹ ğŸ“¢ ğŸ¤”              Kivanc EnesğŸ¨      Ritika DasğŸ¨      Zer07793ğŸ¨      Andrew CheungğŸ¨      SadhağŸ¨      tainenkoğŸ¨ ğŸ’»      github-star-coderğŸ¨              Danilo OliveirağŸ¨      lordekoğŸ¨      Shubham KumarğŸ¨ ğŸ’»      testtreeğŸ¨      Cheryl MurphyğŸ¨ ğŸ’»      Bipin ThomasğŸ¨      Abdulrahman HishamğŸ¨              Dakshitha DissanayakağŸ¨      BADR KACIMIğŸ¨      Alex WangğŸ¨      MaximğŸ¨      GordonGrantğŸ¨ ğŸ’»      Ephrem DemelashğŸ¨      JonOrcuttğŸ¨              topdev10ğŸ¨      cookwellwebsiteğŸ¨      xren935ğŸ¨      Nemo FrenkelğŸ¨      MD SAIF ALAMğŸ¨      Boris LÃ³pez ArayağŸ¨      Larry ChiemğŸ¨              Muhammad Bilal IlyasğŸ¨      AliMilaniğŸ¨ ğŸ’»      Suraj SahaniğŸ¨      FlyingSquirrelğŸ¨      Erick TijeroğŸ¨      Jaskaran KukrejağŸ¨      MichaelLğŸ¨              MagicLegendğŸ¨      Dereck BearsongğŸ¨      Pappu Kumar PashiğŸ¨      Venkata Kishore TavvağŸ¨      Rafat Touqir RafsunğŸ¨      Snehesh DuttağŸ¨      Timo KÃ¶rnerğŸ¨ ğŸ’»              alexxxanğŸ¨      GGJasonğŸ¨      LeeAnna EwingğŸ¨ ğŸ¤”      kamal JyotwalğŸ¨      Bob-JohnsğŸ¨ ğŸ’» ğŸ–‹      yunussalmanlyitğŸ¨ ğŸ’»      chilcotğŸ¨ ğŸ’»              Jacky LiğŸ’» ğŸ–‹ ğŸ¨      Sarthak TrivediğŸ¨      Ayush AggarwalğŸ¨ ğŸ’»      Nic BallariniğŸ¨      Luigi ZambettiğŸ¨ ğŸ’»      govindhaswinğŸ¨      Addy RoyğŸ’» ğŸ¨              Akshat TamrakarğŸ¨ ğŸ’»      Sai Bhargava RamuğŸ¨      GurkanğŸ’»      Spencer Hayes-LaverdiereğŸ’»      Aniket SoniğŸ’»      tanmay5792ğŸ’»      Dina TaklitğŸ’» ğŸ¨ ğŸ–‹              Dushyant SinghğŸ’»      Ravi Prakash SinghğŸ’»      Nihal JoshiğŸ’»      Guy KlagesğŸ’»      ArvindğŸ¨ ğŸ’»      mujeeb91ğŸ’»      josercağŸ¨ ğŸ’»              Prateek AgrawalğŸ’»      Teoh Tze Chuin(ã‚µãƒ©)ğŸ’» ğŸ¨      Jayant JainğŸ’»      Ayush SahuğŸ’»      Hridya Krishna RğŸ’» ğŸ¨      Rahul BaliğŸ’» ğŸ¨      S.ZHengğŸ¨ ğŸ’» ğŸ’¼              Shriya MadanğŸ¨ ğŸ’»      mahalrupiğŸ¨      Lucas LermagneğŸ¨      Jeff DeutschğŸ¨ ğŸ’»      Betoxx1ğŸ¨      Wingman4l7ğŸ¨      Martin EspericuetağŸ¨              Mh-TahirğŸ¨      Zdravko Å plajtğŸ¨ ğŸ’»      Ms3105ğŸ¨ ğŸ’» ğŸ–‹      Ambika SidheswareğŸ’»      mundogueroğŸ’»      Darkus24ğŸ–‹      Sou-786ğŸ–‹ ğŸ¨              BanurekhağŸ–‹      ShiraStarLğŸ¨      Ilya KomarovğŸ¨      DemigodMsğŸ–‹ ğŸ“–      Mekha HridyağŸ¨ ğŸ”      Andrey SafonovğŸ¨ ğŸ”      TommasoğŸ¨ ğŸ’»              Jessica SalbertğŸ’» ğŸ¨      JAYANTH DOLAIğŸ’» ğŸ¨      silverstroomğŸ’» ğŸ¨ ğŸ’¼      Furkan SayÄ±mğŸ’» ğŸ¨      Sukumar ChandrasekaranğŸ¨      Yejin ParkğŸ¨ ğŸ’»      Ali NooshabadiğŸ¨ ğŸ’»              imitavorğŸ¨ ğŸ’»      Salih KilicliğŸ¨ ğŸ’»      Marcelo MenesesğŸ¨ ğŸ’»      Anton KrekotunğŸ¨ ğŸš§ ğŸ–‹ ğŸ’» ğŸ“– ğŸ’¼      Arnav SarmağŸ’» ğŸ’¡ ğŸ¨      meghatikuğŸ’» ğŸ¨      Anshu TrivediğŸ¨              Taylor DorsettğŸ’» ğŸ–‹ ğŸ¨      Havit RovikğŸ’»      pushpapuneğŸ’» ğŸ¨      Ramtin RadfarğŸ¨ ğŸ¤” ğŸ’¼ ğŸ’µ ğŸ’» ğŸ–‹ ğŸ’¬      Abdulmajeed IsağŸ’» ğŸ¨      vikassaxena02ğŸ¨      RobTablesğŸ¨ ğŸ’» ğŸ’¼              DanielğŸ¨ ğŸ’» ğŸ’¼ ğŸ”      Zahid AliğŸ’» ğŸ¨      Chad ChaiğŸ’» ğŸ¨      Marco BiedermannğŸ’» ğŸ¨ ğŸ’¼ ğŸ¤”      Srinidhi MurthyğŸ¨      Miao CaiğŸ’» ğŸ¨      Dionicio DiazğŸ¨ ğŸ’»              Mir Monoarul AlamğŸ¨      Shawn OhnğŸ’» ğŸ¨      Amanbolat BalabekovğŸ¨ ğŸ’»      black-mamba-codeğŸ’»      Jian-forksğŸ¨ ğŸ’»      shivani patelğŸ¨      Akash ChowrasiağŸ¨              yairg98ğŸ¨      Jay GajjarğŸ¨      coolerboolerğŸ’»      Md Zinnatul Islam MorolğŸ¨      shresthashok550ğŸ¨ ğŸ“–      Alan PallathğŸ“–      Adrian WongğŸ’»              vsDizzyğŸ’» ğŸ¨      Frex CuadillerağŸ¨ ğŸ’»      ashish570ğŸ’» ğŸ¨      ruchpeanutsğŸ’» ğŸ¨      ArtmasqueğŸ¨ ğŸ’»      Amirhossein Mojiri ForoushaniğŸ¨      forğŸ’» ğŸ¨              LukeğŸ¨ ğŸ’»      Hector EspinozağŸ¨      AdriÃ¡n BuenfilğŸ¨ ğŸ’»      Amit KumarğŸ¨      schoppfeğŸ¨ ğŸ’»      Sofiyal CğŸ¨ ğŸ’»      spitliskğŸ’» ğŸ¨              PRAVIN SHARMAğŸ¨      NIDZAAA1ğŸ¨ ğŸ’»      John MaiğŸ¨ ğŸ’»      kimsoyeongğŸ¨      Dona GhoshğŸ’»      Ryan HillğŸ¨ ğŸ’»      j42zğŸ¨ ğŸ’»              Ashish SangaleğŸ¨ ğŸ’»      Derek YangğŸ¨ ğŸ’»      mohsinmsmğŸ¨ ğŸ’»      Gokulkrish2302ğŸ’»      BhaavishekğŸ’» ğŸ¨      Louis LiaoğŸ¨      sengc92ğŸ¨ ğŸ’»              Alex MarvinğŸ¨      Balkrishna BhattğŸ¨ ğŸ’»      Evaldas LavrinoviÄiusğŸ¨ ğŸ’»      Adam ErchegyiğŸ¨ ğŸ’»      Truman HungğŸ¨ ğŸ’»      rzamora11ğŸ¨      gaurav0224ğŸ¨              Lee GyeongJunğŸ¨      MirekğŸ¨ ğŸ’»      surajm245ğŸ¨      ArisLaodeğŸ¨ ğŸ’»      RaviDhoriyağŸ¨ ğŸ’»      sarai-84ğŸ¨ ğŸ’»      VishnuğŸ¨ ğŸ’»              Muhammad MinhajğŸ’»      Chandrika DebğŸ¨ ğŸ’»      Gitgit101-bitğŸ’» ğŸ¨      Hedi SellamiğŸ’» ğŸ¨      saurabhvaish93ğŸ’» ğŸ¨      Nikola BegovicğŸ’» ğŸ¨      WangğŸ’» ğŸ¨              Manuel Eusebio de Paz CarmonağŸ¨      Basim Al-JawaheryğŸ¨ ğŸ’»      RAJA AHMEDğŸ¨ ğŸ’»      Abhik LodhğŸ’»      Md. Pial AhamedğŸ’» ğŸ¨      Hassan ShahzadğŸ’» ğŸ¨      Christian Sosa GagoğŸ’»              Hasnain RasheedğŸ’» ğŸ¨      T-RadfordğŸ’»      dahiyashishğŸ’» ğŸ¨      RahulSharma468ğŸ’» ğŸ¨      Jumpod PlekhongthuğŸ’» ğŸ¨      Thomas Young-AudetğŸ’» ğŸ¨      VinayagamBabuğŸ’» ğŸ¨              Deniz KoÃ§ğŸ’» ğŸ¨      Azhar KhanğŸ’» ğŸ¨ ğŸ–‹ ğŸ“– ğŸ”£ ğŸš§      Jacob ShortğŸ’» ğŸ¨      Uchimura85ğŸ’» ğŸ¨      Leo NugrahağŸ’» ğŸ¨ ğŸ“–      Mujtaba MehdiğŸ“– ğŸ–‹      Jim-dsğŸ’» ğŸ¨              Sreehari KğŸ’» ğŸ¨      Florian MartinezğŸ’» ğŸ¨      AaronğŸ’» ğŸ¨      apoageğŸ¨      Ignacio Guillermo Martinez ğŸ’» ğŸ¨      AirlineDogğŸ¨ ğŸ’»      MekelğŸ¨ ğŸ’»              hmosharrofğŸ¨ ğŸ’»      Ben EmamianğŸ’» ğŸ¨      babesharkğŸ’» ğŸ¨      Leonardo JaquesğŸ’» ğŸ¨      Stefanos ApkarianğŸ’» ğŸ¨      Ayhan AlbayrakğŸ’» ğŸ¨      KidusMTğŸ’» ğŸ¨              hectormarroquin20ğŸ’» ğŸ¨      Edelweiss35ğŸ’» ğŸ¨      MihaiDğŸ’» ğŸ¨      AnveshReddyAnnemğŸ’» ğŸ¨      Hyunjae ParkğŸ’» ğŸ¨      Rajiv AlbinoğŸ’» ğŸ¨      AtishayğŸ’»              Yusuf NaheemğŸ¨      WinduğŸ¨ ğŸ’»      Superv1sorğŸ’» ğŸ¨      Karine (:ğŸ¨ ğŸ’»      Eduard PechğŸ¨ ğŸ’»      jjeshwaniğŸ¨ ğŸ’»      SteveğŸ¨ ğŸ’»              Aleigh OhslundğŸ’»      Abhinav SumanğŸ¨ ğŸ’»      Hamza Ehtesham FarooqğŸ¨ ğŸ’»      IamNotPeterPanğŸ’» ğŸ’µ ğŸ¨      CetgerğŸ¨      pkonopackiğŸ¨      Yang YangğŸ¨ ğŸ’»              Muhammad Shoaib SarwarğŸ’»      Murilo HenriqueğŸ’» ğŸ¨      emilianoalvzğŸ¨ ğŸ’»      Sumana SahağŸ¨ ğŸ’»      Yurii17KğŸ¨ ğŸ’»      Rupesh BhandariğŸ¨ ğŸ’»      salmos3718ğŸ’»              John BakerğŸ¨ ğŸ’»      SanjaySathirajuğŸ¨ ğŸ’»      Donat KabashiğŸ¨      Arul Prasad JğŸ¨ ğŸ’»      Qi ChenğŸ¨ ğŸ’»      Maksym DmyterkoğŸ¨ ğŸ’»      ilovepullrequestsğŸ’»              Samira MalekiğŸ¨ ğŸ’»      NIKITA MAHOVIYAğŸ’»      jesuisdev.NetğŸ¨ ğŸ’»      Ashraf NazarğŸ¨      Naveed AhmadğŸ¨      Ajmain NaqibğŸ¨ ğŸ’»      Avinash TingreğŸ’» ğŸ¨              nicktidsğŸ¨      Keith DinhğŸ’» ğŸ¨      AndrÃ© FerreirağŸ’» ğŸ¨      eliottkespiğŸ’» ğŸ¨      praveenpnoğŸ’» ğŸ¨      vitowidigdoğŸ’» ğŸ¨      Devesh Pratap SinghğŸ’» ğŸ¨              Dario RodriguezğŸ’» ğŸ¨      charmander_didiğŸ’» ğŸ¨      PHBasinğŸ’» ğŸ¨      Ritvik Singh ChauhanğŸ’» ğŸ¨      Riya P MathewğŸ’» ğŸ¨      Stephanie CherubinğŸ’» ğŸ¨      BenitesGuiğŸ’» ğŸ¨              FarikBearğŸ’» ğŸ¨      Dmytro HavrilovğŸ’» ğŸ¨      Parvesh MonuğŸ’» ğŸ¨      Dipen PanchasarağŸ’» ğŸ¨      gudatağŸ¨ ğŸ’»      gawadeditorğŸ’» ğŸ¨      Kirill TaletskiğŸ¨ ğŸ’»              SaajanğŸ¨ ğŸ’»      Kushagra SğŸ¨ ğŸ’»      Oanh LeğŸ¨ ğŸ’»      Frane MedvidoviÄ‡ğŸ¨ ğŸ’»      YormanğŸ¨ ğŸ’»      Bill ChanğŸ¨ ğŸ’»      Pratik LomteğŸ¨ ğŸ’»              LOC LAMğŸ¨ ğŸ’»      TUSAR RANJAN MAHAPATRAğŸ’»      BhargavKanjarlağŸ’»      Karel De SmetğŸ’» ğŸ¨      sidisanğŸ¨      ygnzayarphyoğŸ¨ ğŸ’»      svansteelandtğŸ’»              KebechetğŸ¨      Daniel Selvan DğŸ¨ ğŸ’»      Mahdi RazaviğŸ¨ ğŸ’»      Niklas TiedeğŸ’» ğŸ¨      narutubaderddinğŸ’» ğŸ¨      dylandhoodğŸ’»      Dheeraj GuptağŸ’»              Pieter ClaerhoutğŸ’» ğŸ¨      Shivam AgnihotriğŸ’»      RanjithReddy-NarrağŸ’»      Nikita WadhwaniğŸ¨ ğŸ’»      rsholokhğŸ’» ğŸ¨      Ayaan HossainğŸ’» ğŸ¨      Rajesh SwarnağŸ’»              Deniz EtkarğŸ¨ ğŸ’»      pro335ğŸ’» ğŸ¨      Jakub RadzikğŸ’» ğŸ¨      Hamza KhanzadağŸ’»      ARNONğŸ¨      Vikram SinghğŸ’»      ShoxruxbekğŸ’» ğŸ¨              Amit KhatriğŸ’» ğŸ¨      Wali UllahğŸ¨ ğŸ’»      Amit11794ğŸ’» ğŸ¨      metis-macys-66898ğŸ’» ğŸ¨      Faisal MaqboolğŸ¨ ğŸ’»      Kumar NeerajğŸ’» ğŸ¨      Maurizio MariniğŸ¨ ğŸ’»              Saket KothariğŸ¨ ğŸ’»      Szymon ZborowskiğŸ¨ ğŸ’»      iks3000ğŸ¨ ğŸ’»      Ehsan SeyediğŸ¨ ğŸ’»      vanekbrğŸ¨ ğŸ’»      Princy_MğŸ¨ ğŸ’»      Shijie ZhouğŸ¨ ğŸ’»              lakshyamcs16ğŸ¨ ğŸ’»      Filippo FaccoğŸ¨ ğŸ’»      mendel5ğŸ¨ ğŸ’»      PatrykğŸ¨ ğŸ’»      VishwaSanganiğŸ¨ ğŸ’»      Alvin ZhaoğŸ¨ ğŸ’»      Lazar GugletağŸ¨ ğŸ’»              vmichoğŸ¨ ğŸ’»      Sikandar AliğŸ¨ ğŸ’»      Raja BabuğŸ¨ ğŸ’»      faizajahanzebğŸ’»      Guil_AiTğŸ¨ ğŸ’»      Kushal DasğŸ¨ ğŸ’»      Luis BonillağŸ¨ ğŸ’»              jovan1013ğŸ¨ ğŸ’»      DamianğŸ¨ ğŸ’»      Yash GuptağŸ’»      lolcatnipğŸ¨ ğŸ’»      Ikko AshimineğŸ¨ ğŸ’»      FarukhğŸ¨ ğŸ’»      MoksedulğŸ’» ğŸ¨              Navneet KumarğŸ¨ ğŸ’»      Saqib AlMalikğŸ’»      fahimrahmanğŸ¨ ğŸ’»      vaibhav patilğŸ¨ ğŸ’»      Rahul MadanğŸ¨ ğŸ’»      kartik KaklotarğŸ¨ ğŸ’»      ASAHI OCEANğŸ¨ ğŸ’»              Daniel JungbluthğŸ¨ ğŸ’»      Rajdeep Singh BoranağŸ¨ ğŸ’»      ankitha19ğŸ’»      Linh TranğŸ’»      islamarrğŸ’» ğŸ¨      Mohamed SabithğŸ¨ ğŸ’»      Miguel Angel Cruz AcostağŸ¨ ğŸ’»              Adebayo Ilerioluwa ğŸ¨      MarkusğŸ¨ ğŸ’»      dkonyayevğŸ¨ ğŸ’»      Kevin A MathewğŸ¨ ğŸ’»      David MeloğŸ¨ ğŸ”£      DFW1NğŸ¨ ğŸ’»      Sohaib AyubğŸ¨ ğŸ’»              NavvyğŸ¨ ğŸ’»      bloodiator2ğŸ¨ ğŸ’»      HanjiğŸ¨ ğŸ’»      arthur74ğŸ¨ ğŸ’»      Sri Subathra Devi BğŸ¨ ğŸ’»      Akif AydogmusğŸ¨ ğŸ’»      Umer JavaidğŸ¨ ğŸ’»              Norio UmatağŸ¨ ğŸ’»      Gazi Hasan RahmanğŸ¨ ğŸ’»      Keith NguyenğŸ¨ ğŸ’»      MegalomaniacğŸ¨ ğŸ’»      ShankS3ğŸ¨ ğŸ’»      Farhad AlishovğŸ¨ ğŸ’»      Ronak J VanpariyağŸ¨ ğŸ’»              azrael0learzağŸ¨ ğŸ’»      Pavel RahmanğŸ¨ ğŸ’»      chuabernğŸ¨ ğŸ’»      Rahul TirkeyğŸ¨ ğŸ’»      Ruslan BesğŸ¨ ğŸ’» ğŸ’¡ ğŸš§ ğŸ–‹ ğŸ”£ ğŸš‡      BohdanğŸ¨ ğŸ’»      JuzdzewskiğŸ¨ ğŸ’»              Grigor MinasyanğŸ¨ ğŸ’»      alvintwcğŸ¨ ğŸ’»      Anand NatarajanğŸ¨ ğŸ’»      Kashan AliğŸ¨ ğŸ’»      Thomas MeshailğŸ¨ ğŸ’»      Son PhamğŸ¨      Michael FrenchğŸ’¡              Yash MishrağŸ“–      Miguel RodriguezğŸ¨ ğŸ’»      Philipp BachmannğŸ¨ ğŸ’»      sunnyğŸ¨ ğŸ’»      Siddharth ChatterjeeğŸ¨ ğŸ’»      Michael NaghavipourğŸ¨ ğŸ’»      Sahil GargğŸ¨ ğŸ’»              MicroLionğŸ¨ ğŸ’»      wctwcğŸ¨ ğŸ’»      Rohan SharmağŸ”£      AshishBodlağŸ¨ ğŸ’»      Taras PysarskyiğŸ¨ ğŸ’»      Luqman Bello O.ğŸ¨ ğŸ’»      DyingDownğŸ¨ ğŸ’»              Diego ChapedelaineğŸ¨ ğŸ’»      RichleeğŸ¨ ğŸ’»      Asif HabibğŸ¨ ğŸ’»      Mazharul HossainğŸ¨ ğŸ’»      toniğŸ¨ ğŸ’»      Pragyanshu RaiğŸ¨ ğŸ’»      Matthew EllerğŸ¨ ğŸ’»              AbhiBijuğŸ¨ ğŸ’»      Roman ZhornytskiyğŸ¨ ğŸ’»      Lucas CaminoğŸ¨ ğŸ’»      JoÃ£o Vitor CasarinğŸ¨ ğŸ’»      Evgeniy ShayğŸ¨ ğŸ’»      Ehsan BarkhordarğŸ¨ ğŸ’»      GabrielğŸ¨ ğŸ’»              Shibu MohapatrağŸ¨ ğŸ’»      Pavel KirkovskyğŸ¨ ğŸ’»      Tahir GulğŸ¨ ğŸ’»      imDevSalmanğŸ¨ ğŸ’»      Jordan DonaldsonğŸ¨ ğŸ’»      js-venusğŸ¨ ğŸ’»      Faisal ShaikhğŸ¨ ğŸ’»              ashishbpatilğŸ¨ ğŸ’»      Tri LeğŸ¨ ğŸ’»      tomtreffkeğŸ¨ ğŸ’»      Salah Eddine LalamiğŸ¨ ğŸ’»      Mattias XuğŸ¨ ğŸ’»      Manas GuptağŸ¨ ğŸ’»      wolfsong62ğŸ¨ ğŸ’»              Mehdi MirzaeiğŸ¨ ğŸ’»      Van Ba KhanhğŸ¨ ğŸ’»      Sel EmbeeğŸ¨ ğŸ’»      Suvradip PaulğŸ¨ ğŸ’»      ShariqueğŸ¨      SeabassğŸ¨ ğŸ’»      Penny LiuğŸ¨ ğŸ’»              jatinder bholağŸ¨ ğŸ’»      misterqbitğŸ¨ ğŸ’»      Daniel-VS9ğŸ¨ ğŸ’»      ShruthiğŸ¨ ğŸ’»      beefydogğŸ¨ ğŸ’»      Suraj KumarğŸ¨ ğŸ’»      hrishikeshpsğŸ¨ ğŸ’»              SudarshanğŸ¨ ğŸ’»      DivyanshğŸ’» ğŸ¨      ZyaireğŸ¨ ğŸ’»      Omar BelkadyğŸ¨ ğŸ’»      alexiismuağŸ¨ ğŸ’»      Eduarda AlvesğŸ¨      pycoachğŸ¨ ğŸ’»              RuhulğŸ¨ ğŸ’»      pmoustopoulosğŸ¨ ğŸ’»      Lee Hui TingğŸ’» ğŸ¨      bodi1981ğŸ¨ ğŸ’»      Devaraat JoshiğŸ¨ ğŸ’»      JohnnyğŸ¨ ğŸ’»      rogue-coderğŸ¨ ğŸ’»              viiktrğŸ¨      Lalit MohanğŸ’»      JoÃ£o SousağŸ’»      è¨€è‘‰ä¹‹éˆğŸ’» ğŸ¨      RJLABSğŸ’»      brittney0522ğŸ¨ ğŸ’»      shamğŸ¨ ğŸ’»              Glenn GoossensğŸ’» ğŸ¨      Cyber HawkğŸ¨ ğŸ’» ğŸ–‹ ğŸ’¼      Ankit YadavğŸ¨ ğŸ’»      verbalityğŸ’»      Mohammed SiddiquiğŸ¨ ğŸ’»      AdamKaczor6250ğŸ¨ ğŸ’»      RamÃ³n Martinez NietoğŸ¨ ğŸ’»              Grzegorz DziubakğŸ¨ ğŸ’»      Ayoub BERDEDDOUCHğŸ¨ ğŸ’»      nikola-fadvğŸ¨ ğŸ’»      Akarsh AgrawalğŸ¨ ğŸ’»      Mitra MirshafieeğŸ¨ ğŸ’»      Parker StephensğŸ¨ ğŸ’»      alrenee99ğŸ’»              Karthick VankayalağŸ’»      Iryna ğŸ¨ ğŸ’»      palanugrahğŸ’»      GwinbleindğŸ¨ ğŸ’»      Randy BobandyğŸ¨ ğŸ’»      Bek RozikoffğŸ’»      davnguyeğŸ¨ ğŸ’»              Neel PatelğŸ’»      ehudbeharğŸ¨ ğŸ’»      nicholas-cod3rğŸ¨ ğŸ’»      michaelfrankiğŸ¨      Esther WhiteğŸ¨ ğŸ’»      prathmeshpbğŸ¨ ğŸ’»      Victor LinğŸ¨ ğŸ’»              Christine C. YinğŸ¨ ğŸ’»      GitLearner-beginğŸ¨ ğŸ’»      Mesrop AndreasyanğŸ¨ ğŸ’»      Nathan GarciağŸ¨      commonsw04ğŸ¨ ğŸ’»      Md. Rashad TanjimğŸ¨ ğŸ’»      Ali MalekğŸ’»              PAODLTğŸ¨ ğŸ’»      Nikhil BobadeğŸ¨ ğŸ’»      hyuckjin21ğŸ’»      Itasha ModiğŸ¨ ğŸ’»      Nikitha ReddyğŸ¨ ğŸ’»      Mahshooq ZubairğŸ¨ ğŸ’»      Subham DasğŸ’»              Onkar BirajdarğŸ¨ ğŸ’»      Nick TitomichelakisğŸ¨ ğŸ’»      Christian Leo-PernoldğŸ¨      Matthew MarquiseğŸ¨ ğŸ’»      baronfacğŸ¨ ğŸ’»      Abhishek TilwarğŸ¨ ğŸ’»      DavidsDvmğŸ¨ ğŸ’»              Parth ParikhğŸ¨ ğŸ’»      Hector CastroğŸ¨ ğŸ’»      Rikky ArisendiğŸ¨ ğŸ’»      Ali HamXağŸ¨ ğŸ’»      Frank.wuğŸ¨ ğŸ’»      Jatin KumarğŸ¨ ğŸ’» ğŸ“–      masterHAWK99ğŸ¨ ğŸ’»              Pushp JainğŸ¨ ğŸ’»      Ashutosh RoutğŸ¨ ğŸ’»      Atharva DeshpandeğŸ¨ ğŸ’»      Teodor CiripescuğŸ¨ ğŸ’»      Anmol BansalğŸ¨ ğŸ’»      Nikhil Kumar MacharlağŸ¨ ğŸ’»      DexterğŸ¨ ğŸ’»              AaronğŸ¨ ğŸ’»      Yogita JaswaniğŸ¨ ğŸ’» ğŸ“– ğŸ–‹      StoryDevğŸ¨ ğŸ’»      Mesut DoÄŸansoyğŸ¨ ğŸ’»      Paras DhawanğŸ¨ ğŸ’»      Emanuel ZhupağŸ¨ ğŸ’»      Aaradhyaa717ğŸ¨ ğŸ’»              jaacko-torusğŸ¨ ğŸ’»      mBlackğŸ’»      kalrayashwinğŸ“– ğŸ–‹ ğŸ¨ ğŸ’»      SeraphğŸ’» ğŸ¨      ZhiHong ChuağŸ¨ ğŸ’»      Amsal KhanğŸ¨ ğŸ’» ğŸ“– ğŸ–‹      Raghav RastogiğŸ¨ ğŸ’»              TzilağŸ“–      Shahriar Nasim NafiğŸ“–      AGğŸ¨ ğŸ’»      Mojtaba KamyabiğŸ¨ ğŸ’»      Ahmad AbdulrahmanğŸ¨ ğŸ’»      EclipseğŸ¨ ğŸ’»      Anshu PalğŸ¨ ğŸ’»              DenisğŸ¨ ğŸ’»      mehmet sayinğŸ“–      WebDEVğŸ¨ ğŸ’»      Sam KomesarookğŸ¨ ğŸ’»      Kiran GhimireğŸ¨ ğŸ’»      Joshua DavisğŸ¨ ğŸ’»      Muhammad-Huzaifa-SiddiquiğŸ’»              tobeornottobeadevğŸ¨ ğŸ’»      VAIBHAV SINGHALğŸ¨ ğŸ’»      Keiran PillmanğŸ¨ ğŸ’»      Max DonchenkoğŸ¨ ğŸ’»      sgonsalğŸ¨ ğŸ’»      diksha137ğŸ¨ ğŸ’»      VigneshğŸ¨ ğŸ’»              Gabriel FranÃ§ağŸ¨ ğŸ’»      JosephğŸ¨ ğŸ’»      Bruno RafaelğŸ¨ ğŸ’»      vcamarreğŸ¨ ğŸ’»      thibault kettererğŸ¨ ğŸ’» ğŸš§      VictorGonzalezToledoğŸ¨ ğŸ’»      1911510996ğŸ¨ ğŸ’»              inviduğŸ¨ ğŸ’»      Nurul FurqonğŸ¨ ğŸ’»      David AsbillğŸ¨ ğŸ’»      Niko BirbilisğŸ¨ ğŸ’»      Mugundan KottursureshğŸ¨      agrsachin81ğŸ¨ ğŸ’»      Othmane El AlamiğŸ¨ ğŸ’»              Syed Atif AliğŸ¨ ğŸ’»      lakhanjindamğŸ¨ ğŸ’»      youssef hamdaneğŸ¨ ğŸ’»      starfaerieğŸ¨ ğŸ’»      rodrigo0107ğŸ¨ ğŸ’»      MichaÅ‚ GralakğŸ¨ ğŸ’»      Jewel MahmudğŸ¨ ğŸ’»              cwilson830ğŸ¨ ğŸ’»      buun1030ğŸ¨ ğŸ’»      Reda-ELOUAHABIğŸ¨ ğŸ’»      saad-aksağŸ¨ ğŸ’»      Emdadul HaqueğŸ¨ ğŸ’»      PROCWğŸ¨ ğŸ’»      cccppp1ğŸ¨ ğŸ’»              Joanna BaileğŸ¨ ğŸ’»      Ahmed SaberğŸ¨ ğŸ’»      Masoud KeshavarzğŸ¨ ğŸ’»      mortazavianğŸ¨ ğŸ’»      Aniket PandeyğŸ¨ ğŸ’»      Vijay NirmalğŸ¨ ğŸ’»      Daniel CarvalloğŸ’»              menaechmiğŸ¨ ğŸ’»      azenyxğŸ¨ ğŸ’»      Ahmet Ã–zrahatğŸ¨ ğŸ’»      Abdulrahman AbouzaidğŸ¨ ğŸ’»      jmgnorbecğŸ¨ ğŸ’»      palinko91ğŸ¨ ğŸ’»      Laisson R. SilveirağŸ¨ ğŸ’»              BHARGAVPATEL1244ğŸ¨ ğŸ’»      Candide UğŸ¨ ğŸ’»      Sitansh RajputğŸ¨ ğŸ’»      Houda MouttalibğŸ¨ ğŸ’»      MumuTWğŸ¨ ğŸ’»      Suave BajajğŸ¨ ğŸ’»      Mehdi ParsaeiğŸ¨ ğŸ’»              Dinko OsreckiğŸ¨ ğŸ’»      Dhia DjobbiğŸ¨ ğŸ’»      Mahmoud GalalğŸ¨ ğŸ’»      Anh MinhğŸ¨ ğŸ’»      Suvesh KğŸ¨ ğŸ’»      Petar TodorovğŸ¨ ğŸ’»      Alexander NguyenğŸ¨ ğŸ’»              Morteza JalalvandğŸ¨ ğŸ’»      Claudson MartinsğŸ¨ ğŸ’»      Matt JacobsonğŸ¨ ğŸ’»      Rafael BelokurowsğŸ¨ ğŸ’»       Thomas GamaufğŸ¨ ğŸ’»      Rishabh MahajanğŸ¨ ğŸ’»      rakeshpdgupta23ğŸ¨ ğŸ’»              ShashidharknaikğŸ¨ ğŸ’»      taleleumağŸ¨ ğŸ’»      Florian BÃ¼hlerğŸ¨ ğŸ’»      Raihan Bin WahidğŸ¨ ğŸ’»      MOHAMMED NASSERğŸ¨ ğŸ’»      federicoğŸ¨ ğŸ’»      Andre ViolanteğŸ¨ ğŸ’»              tcunningham98ğŸ¨ ğŸ’»      Jan GrieÃŸerğŸ¨ ğŸ’»      Serkan AlcğŸ¨ ğŸ’» ğŸ–‹      Jez McKeanğŸ¨ ğŸ’»      meisam alifallahiğŸ¨ ğŸ’»      Mehul ThakkarğŸ¨ ğŸ’»      Saksham SoniğŸ¨ ğŸ’»              Pedro PeregrinağŸ¨ ğŸ’»      Mintu ChoudharyğŸ¨ ğŸ’»      lucianmoldovanuğŸ¨ ğŸ’»      John C. ScottğŸ¨ ğŸ’»      Mia D.ğŸ¨ ğŸ’»      EwenBernardğŸ¨ ğŸ’»      M. Reza NasirlooğŸ¨ ğŸ’»              Jay AgrawalğŸ¨ ğŸ’»      DeShayğŸ¨ ğŸ’»      Jay206-ProgrammerğŸ¨ ğŸ’»      ElenderğŸ¨ ğŸ’» ğŸ–‹      Bobby ByrneğŸ¨ ğŸ’»      PirciğŸ¨ ğŸ’»      HasanuzzamanğŸ¨ ğŸ’»              Josh KautzğŸ¨ ğŸ’»      BrofarğŸ¨ ğŸ’»      Mina KaramğŸ¨ ğŸ’»      Duncan O NğŸ¨ ğŸ’»      Sean Tumulak-NguyenğŸ¨ ğŸ’»      Artur TrzeÅ›niewskiğŸ¨ ğŸ’»      JJaammeessMğŸ¨ ğŸ’»              shubham agarwalğŸ¨ ğŸ’»      Michele RighiğŸ¨ ğŸ’»      Panagiotis KontosğŸ¨ ğŸ’»      sumitbathlağŸ¨ ğŸ’»      Deepak MathurğŸ¨ ğŸ’»      Juho NykÃ¤nenğŸ¨ ğŸ’»      Santiago GonzÃ¡lez SiordiağŸ¨ ğŸ’»              SRIJITA MALLICKğŸ¨ ğŸ’»      Samriddhi BğŸ¨ ğŸ’»      Nitzan PapiniğŸ¨ ğŸ’»      Mario SanzğŸ¨ ğŸ’»      Crab^4ğŸ¨ ğŸ’»      PabloğŸ¨ ğŸ’»      Gordon Pham-NguyenğŸ¨ ğŸ’»              KristofferğŸ¨ ğŸ’»      chrisblachğŸ¨ ğŸ’»      GÃ¡borğŸ¨ ğŸ’»      LinağŸ¨ ğŸ’»      Harrison WattsğŸ¨ ğŸ’»      Mario PetriÄkoğŸ¨ ğŸ’»      Ben8120ğŸ¨ ğŸ’»              GiovannağŸ¨ ğŸ’»      Minal AhujağŸ¨ ğŸ’»      mossfarmerğŸ¨ ğŸ’»      ThaC0derDreğŸ¨ ğŸ’»      itwareğŸ¨ ğŸ’»      Michael WalkerğŸ¨ ğŸ’»      Tom Jacob ChirayilğŸ¨ ğŸ’»              Sachin KumarğŸ¨ ğŸ’»      adi-rayğŸ¨ ğŸ’»      Dr-Blank-altğŸ¨ ğŸ’»      Bogdan CazacuğŸ¨ ğŸ’»      Gilson UrbanoğŸ¨ ğŸ’»      NinağŸ¨ ğŸ’»      AnthonyğŸ¨ ğŸ’»              manushimjaniğŸ¨ ğŸ’»      Michael ReyesğŸ¨ ğŸ’»      Rachel KennellyğŸ¨ ğŸ’»      Aakash GargğŸ¨ ğŸ’»      Daniel LivingstonğŸ¨ ğŸ’»      alexrojcoğŸ¨ ğŸ’»      Minh NguyenğŸ¨ ğŸ’»              Mahesh Dattatraya BabarğŸ¨ ğŸ’»      Jin ZihangğŸ¨ ğŸ’»      Bikramjit GangulyğŸ¨ ğŸ’»      QuestionableGuiseğŸ¨ ğŸ’»      liq19chğŸ¨ ğŸ’»      Bruno RochağŸ¨ ğŸ’»      Anand DyavanapalliğŸ’» ğŸ–‹              crucian-afkğŸ¨ ğŸ’»      0xgainzğŸ¨ ğŸ’»      weirdfshğŸ¨ ğŸ’»      Valan Baptist MathuranayagamğŸ¨ ğŸ’»      Paul KaeferğŸ¨ ğŸ’»      Yu-Hsiang WangğŸ¨ ğŸ’»      Javad AdibğŸ¨ ğŸ’»              davidliu0930ğŸ¨ ğŸ’»      Achilleas John YfantisğŸ¨ ğŸ’»      Omkar ShivadekarğŸ¨ ğŸ’» ğŸ–‹ ğŸ›      ToanTranğŸ¨ ğŸ’»      Gautam NaikğŸ¨ ğŸ’»      MarcğŸ¨ ğŸ’»      twix20ğŸ¨ ğŸ’»              Kristian S.ğŸ¨ ğŸ’»      Aleksey KhoroshilovğŸ¨ ğŸ’»      arjunsrsrğŸ¨ ğŸ’»      Ali HaiderğŸ¨ ğŸ’»      Trisha DringğŸ¨ ğŸ’»      Andre MarzuloğŸ¨ ğŸ’»      Krishna ModiğŸ¨ ğŸ’»              Rosemary LiğŸ¨ ğŸ’»      Alex WellerğŸ¨ ğŸ’»      Tam NguyenğŸ¨ ğŸ’»      aquintelaoliveirağŸ¨ ğŸ’»      Norbert BrettğŸ¨ ğŸ’»      rocsogdğŸ¨ ğŸ’»      0nyrğŸ¨ ğŸ’»              rethkevinğŸ¨ ğŸ’»      RickHeadleğŸ¨ ğŸ’»      LeandreğŸ¨ ğŸ’»      Natnael SisayğŸ¨ ğŸ’»      sbbuğŸ¨ ğŸ’»      waelğŸ¨ ğŸ’»      Fabricio Tramontano PiriniğŸ¨ ğŸ’»              Alexander StoyanovğŸ¨ ğŸ’»      Dezx20ğŸ¨ ğŸ’»      southparkkidsğŸ¨ ğŸ’»      bmstarğŸ¨ ğŸ’»      kiagamğŸ¨ ğŸ’»      Juan CastilloğŸ¨ ğŸ’»      FFenneğŸ¨ ğŸ’»              Jose ToledoğŸ¨ ğŸ’»      Pat McGhenğŸ¨ ğŸ’»      Eiko WagenknechtğŸ’» ğŸ–‹ ğŸ”£      Alan ChalmersğŸ¨ ğŸ’»      Jean DidierğŸ¨ ğŸ’»      AndyğŸ¨ ğŸ’»      pestadieuğŸ¨ ğŸ’»              Kanishka ChakrabortyğŸ¨ ğŸ’»      NandhağŸ¨ ğŸ’»      Vahid MafiğŸ¨ ğŸ’» ğŸ”£ ğŸ–‹ ğŸ’¼      Akshay AshokğŸ¨ ğŸ’»      0x08ğŸ¨ ğŸ’»      Sandeep MishrağŸ¨ ğŸ’»      Evann RegnaultğŸ¨ ğŸ’»              Lenny ZeitounğŸ¨ ğŸ’»      Eden BoaronğŸ¨ ğŸ’»      TroyBTCğŸ¨ ğŸ’»      Aby SebastianğŸ¨ ğŸ’»      Matthew DunnğŸ¨ ğŸ’»      ckulloğŸ¨ ğŸ’» ğŸ–‹ ğŸ”£      Mohamed MamdouhğŸ¨ ğŸ’»              Youssef BazinağŸ¨ ğŸ’»      Frederico KÃ¼ckelhausğŸ’»      Nushan KodikarağŸ’»      Zach CooperğŸ’»      RoyğŸ¨ ğŸ’»      Saurav PanchalğŸ¨ ğŸ’»      totallynotdavidğŸ¨ ğŸ’»              goosepirateğŸ¨ ğŸ’» ğŸ’¡ ğŸ’¼      KAUTHğŸ¨ ğŸ’»      Hari Kiran VusirikalağŸ¨ ğŸ’»      Sounak DeyğŸ¨ ğŸ’»      ziağŸ’¼ ğŸ¨ ğŸ’»      Reza DavariğŸ¨ ğŸ’»      AkshayAjaykumarğŸ¨ ğŸ’»              x24870ğŸ¨ ğŸ’»      Ko PhoneğŸ¨ ğŸ’»      Nabstar3ğŸ¨ ğŸ’»      MateuszğŸ¨ ğŸ’»      Yunus Emre EmikğŸ’»      Abhinav SinhağŸ¨ ğŸ’»      Hung NguyenğŸ¨ ğŸ’»              MaselinoğŸ’»      Shuktika MahantyğŸ’»      MikoÅ‚aj GawroÅ„skiğŸ¨ ğŸ’»      Hussein Habibi JuybariğŸ¨ ğŸ’»      Sean-McArthurğŸ¨ ğŸ’»      Osman F BayramğŸ¨ ğŸ’»      Benjamin Thomas BlodgettğŸ¨ ğŸ’»              Chuanlong-ZangğŸ¨ ğŸ’»      julianğŸ¨ ğŸ’»      franciscoğŸ¨ ğŸ’»      aalihhiader9211ğŸ¨ ğŸ’»      Muhammad ZunairğŸ¨ ğŸ’»      LiyağŸ¨ ğŸ’»      BegadTarekğŸ¨ ğŸ’»              etorobotğŸ¨ ğŸ’»      Hussam KhanğŸ¨ ğŸ’»      Saikat ChakrabortyğŸ¨ ğŸ’»      Nicholas QuislerğŸ¨ ğŸ’»      Evang PoulğŸ¨ ğŸ’»      Gregg LindğŸ¨ ğŸ’»      Deepak KumarğŸ¨ ğŸ’»              Callum LeslieğŸ¨ ğŸ’»      Curtis Barnard Jr.ğŸ¨ ğŸ’»      DeepanshukaimğŸ¨ ğŸ’»      Manthan AnkğŸ¨ ğŸ’»      hossein varmazyarğŸ¨ ğŸ’»      Brayan MuÃ±oz V.ğŸ¨ ğŸ’»      Kamil Rasheed SiddiquiğŸ’» ğŸ¨              mutt0-dsğŸ¨ ğŸ’»      egbertjkğŸ¨ ğŸ’»      Majid ZojajiğŸ¨ ğŸ’»      Sean ChenğŸ¨ ğŸ’»      Herbert MilhommeğŸ¨ ğŸ’»      A3ğŸ¨ ğŸ’»      KillianğŸ¨ ğŸ’»              CoakeowğŸ¨ ğŸ’»      à¾…à¼» Ç¬É€Ä§ à¼„à¼†à½‰ğŸ¨ ğŸ’»      Pratik SolankiğŸ¨ ğŸ’»      SunnyğŸ¨ ğŸ’»      ssgeğŸ¨ ğŸ’»      Bernat FrangiğŸ¨ ğŸ’»      Jeevan RupachağŸ¨ ğŸ’»              amirandapğŸ¨ ğŸ’»      Deepakshi MittalğŸ¨ ğŸ’»      Abhijeet ParidağŸ¨ ğŸ’»      Khaled RiyadğŸ¨ ğŸ’»      Pratap paruiğŸ¨ ğŸ’»      Prajit PandayğŸ¨ ğŸ’»      PipeSierrağŸ¨ ğŸ’»              Collins OdenğŸ¨ ğŸ’»      Kshitij DwivediğŸ¨ ğŸ’»      Bernardia Vitri ArumsariğŸ¨ ğŸ’»      Ã–mer Faruk TaÅŸdemirğŸ¨ ğŸ’»      Spencer StithğŸ¨ ğŸ’»      Porsche RodjanasakğŸ¨ ğŸ’»      Shakeel SharifğŸ¨ ğŸ’»              Victoria ChengğŸ¨ ğŸ’»      DenisğŸ¨ ğŸ’»      Anand Prakash TiwariğŸ¨ ğŸ’»      danijeljw-rpcğŸ¨ ğŸ’»      Ahmed H EbrahimğŸ¨ ğŸ’»      Virginia GardnerğŸ¨ ğŸ’»      Jhironsel Diaz A.ğŸ¨ ğŸ’»              Yunus KidemğŸ¨ ğŸ’»      MTğŸ¨ ğŸ’»      Dinesh ZaldekarğŸ¨ ğŸ’»      adiğŸ¨ ğŸ’»      Farhan ShaikhğŸ¨ ğŸ’»      Elvis SalvatierrağŸ¨ ğŸ’»      Kaushik-IyerğŸ¨ ğŸ’»              HocAndresğŸ¨ ğŸ’»      VictorHugoAguilarAguilarğŸ¨ ğŸ’»      Murat Can AbayğŸ¨ ğŸ’»      ChrisğŸ¨ ğŸ’»      Shivam7-1ğŸ¨ ğŸ’»      Paipai13ğŸ¨ ğŸ’»      Shambles-ioğŸ¨ ğŸ’»              Abhishek K MğŸ¨ ğŸ’»      Ezequiel CuevasğŸ¨ ğŸ’»      Plamen IvanovğŸ¨ ğŸ’»      YujiğŸ¨ ğŸ’»      Jean-Philippe LebÅ“ufğŸ¨ ğŸ’» ğŸ”£      NaufanğŸ¨ ğŸ’»      jadnovğŸ¨ ğŸ’»              vaxtangensğŸ¨ ğŸ’»      subashkonar13ğŸ¨ ğŸ’»      Rushi JaviyağŸ¨ ğŸ’»      Mert GÃ¼lğŸ¨ ğŸ’»      LilyğŸ¨ ğŸ’»      KalinoffğŸ¨ ğŸ’»      Joel TonyğŸ¨ ğŸ’»              PeterğŸ¨ ğŸ’»      Roozbeh ZareiğŸ¨ ğŸ’»      ShenğŸ¨ ğŸ’»      Joonsoo.LEEğŸ¨ ğŸ’»      Fede.BregğŸ¨ ğŸ’»      Rui CostağŸ¨ ğŸ’»      JoÃ£o Gustavo BispoğŸ¨ ğŸ’»              Sami-IğŸ¨ ğŸ’»      Tsvetoslav TsvetkovğŸ¨ ğŸ’»      Olabode Olaniyi DavidğŸ¨ ğŸ’»      theRuslanğŸ¨ ğŸ’»      leighbozğŸ¨ ğŸ’»      Frank SossiğŸ¨ ğŸ’»      Tomasz AdamskiğŸ¨ ğŸ’»              Mansoor M. SathirğŸ¨ ğŸ’»      Golamrabbi AzadğŸ¨ ğŸ’»      Nahian AhmedğŸ¨ ğŸ’»      Rafael de Jesus Silva MonteiroğŸ¨ ğŸ’»      Odionyebuchukwu JudeğŸ¨ ğŸ’»      The Nithin BalajiğŸ¨ ğŸ’»      KnackiiğŸ¨ ğŸ’»              vittorio-giattiğŸ¨ ğŸ’»      Guilherme de Carvalho Lima RebouÃ§asğŸ¨ ğŸ’»      aaref shamiğŸ¨ ğŸ’»      Andrey DryupinğŸ¨ ğŸ’»      Muhanned NomanğŸ¨ ğŸ’»      Jan SilvağŸ¨ ğŸ’»      emanuele-emğŸ¨ ğŸ’» ğŸ–‹              Sanjay TMğŸ¨ ğŸ’»      Joe Markberg / code editorğŸ¨ ğŸ’»      Julien QuiaiosğŸ¨ ğŸ’»      Eric Ramirez SantisğŸ¨ ğŸ’»      MğŸ¨ ğŸ’»      MalcatağŸ¨ ğŸ’»      Athul MuralidharanğŸ¨ ğŸ’»              Dariusz OchotağŸ¨ ğŸ’»      CHANDAN CHOUDHURYğŸ¨ ğŸ’»      DeepğŸ¨ ğŸ’»      Ahmet Ä°stemihan Ã–ZTÃœRKğŸ¨ ğŸ’»      TIMğŸ¨ ğŸ’»      jakeg814ğŸ¨ ğŸ’»      LeonidosğŸ¨ ğŸ’»              Abhinandu V NairğŸ¨ ğŸ’»      charafeddine01ğŸ¨ ğŸ’»      JasperğŸ¨ ğŸ’»      Manish GoyalğŸ¨ ğŸ’»      SATYAM_SINGHğŸ¨ ğŸ’»      FourğŸ¨ ğŸ’»      Vaishnavi Amira YadağŸ¨ ğŸ’»              ShriKrushna BhagwatğŸ¨ ğŸ’»      Rohit NandagawaliğŸ¨ ğŸ’»      felipeğŸ¨ ğŸ’» ğŸš§ ğŸ–‹ âœ… ğŸ§‘â€ğŸ«      Saurabh MudgalğŸ¨ ğŸ’»      szenadamğŸ¨ ğŸ’»      Shubhendra SinghğŸ¨ ğŸ’»      Yoosuf SayyidğŸ’» ğŸ¨              GÃ¼ven Ã‡etinerlerğŸ¨ ğŸ’»      Luke JefferiesğŸ¨ ğŸ’»      ChrisğŸ¨ ğŸ’»      LÃºcio AguiarğŸ’»      Enuma029ğŸ’»      yktsang01ğŸ’»      maximumn3rdğŸ¨ ğŸ’»              Jon GalleteroğŸ¨ ğŸ’»      Thaddeus  ThomasğŸ¨ ğŸ’»      Aakash KumarğŸ’» ğŸ¨      Ali MğŸ¨ ğŸ’»      OskyEdzğŸ¨ ğŸ’»      Ravi GuptağŸ¨ ğŸ’»      Rafa RaizerğŸ¨ ğŸ’»              Abdullah Al MuzakiğŸ¨ ğŸ’»      Rahul FaujdarğŸ¨ ğŸ’»      Abhishek VermağŸ¨ ğŸ’»      Ashutosh ShindeğŸ¨ ğŸ’»      Ganesh RaiğŸ¨ ğŸ’»      StefanTrpkovicğŸ¨ ğŸ’»      Erik BlancağŸ¨ ğŸ’»              Vedant MadaneğŸ¨ ğŸ’»      Antra TripathiğŸ¨ ğŸ’»      Ethan KnightsğŸ¨ ğŸ’»      Alexandru BoncutğŸ¨ ğŸ’»      Pablo BandinoplağŸ¨ ğŸ’» ğŸš§ ğŸ–‹      Robz-99ğŸ¨ ğŸ’»      Harpal SinghğŸ¨ ğŸ’»              paulboundy99ğŸ¨ ğŸ’»      Mubashir AhmedğŸ¨ ğŸ’»      Rohan HariğŸ¨ ğŸ’»      Erik Henrique ğŸ¨ ğŸ’»      Leandro MatheusğŸ¨ ğŸ’»      DeepakğŸ¨ ğŸ’»      AlishaSinghğŸ¨ ğŸ’»              Lynn Latt YatiğŸ¨ ğŸ’»      San ShweğŸ¨ ğŸ’»      SKRğŸ¨ ğŸ’»      msbunnyjaguarğŸ¨ ğŸ’»      Mohamad ZabiullağŸ¨ ğŸ’»      Hatim ZahidğŸ¨ ğŸ’»      Rauzan SumarağŸ¨ ğŸ’»              Hosein1358ğŸ¨ ğŸ’»      MohitğŸ¨ ğŸ’»      AliğŸ¨ ğŸ’»      Avinash1765ğŸ¨ ğŸ’»      Sai Teja MadhağŸ¨ ğŸ’»      Monsur Ahmed ShafiqğŸ¨ ğŸ’»      xuxianjin-devğŸ¨ ğŸ’»              chetnağŸ¨ ğŸ’»      Gul ZaibğŸ¨ ğŸ’»      NataliağŸ¨ ğŸ’»      DionÃ­sio BragağŸ¨ ğŸ’»      Pritish RajpurohitğŸ¨ ğŸ’»      incanloveğŸ¨ ğŸ’»      InnocentğŸ¨ ğŸ’»              Devin AlmonorğŸ¨ ğŸ’»      antonyveyreğŸ¨ ğŸ’»      Beltz AnhxtonğŸ¨ ğŸ’»      MehdiğŸ¨ ğŸ’»      Muhammad UsmanğŸ¨ ğŸ’»      Patrick DantasğŸ¨ ğŸ’»      Tak VannakğŸ¨ ğŸ’»              Ramzi RADDAOUIğŸ¨ ğŸ’»      Konstantin-GlukhovğŸ¨ ğŸ’»      ugurobanğŸ¨ ğŸ’»      Humberto AlvesğŸ¨ ğŸ’»      JuangZendratoğŸ¨ ğŸ’»      James OluwaleyeğŸ¨ ğŸ’»      Wasi SadmanğŸ¨ ğŸ’»              Pavle MijatovicğŸ¨ ğŸ’»      Luiz H. S. BispoğŸ¨ ğŸ’»      Ğ¡ÑƒÑ…Ğ°Ñ Ğ”Ñ…Ğ¾Ğ»Ğ·ğŸ¨ ğŸ’»      Alvaro TrujilloğŸ¨ ğŸ’»      Everton ğŸ¨ ğŸ’»      jfrozasğŸ¨ ğŸ’»      Shuaaib BadranğŸ¨ ğŸ’»              Shivam JhağŸ¨ ğŸ’»      Mohamed TayehğŸ¨ ğŸ’»      Makendran GğŸ¨ ğŸ’»      mayank singh tomarğŸ¨ ğŸ’»      hossam sadanyğŸ¨ ğŸ’»      Harshbardhan SinghğŸ’» ğŸ¨      Fawad Jawaid MalikğŸ¨ ğŸ’»              Tina LacatisğŸ¨ ğŸ’»      TeddyCuoreDolceğŸ¨ ğŸ’»      bchooxgğŸ¨ ğŸ’»      Alisha TakkarğŸ¨ ğŸ’»      GianluigiğŸ¨ ğŸ’»      Mehran JavaherianğŸ¨ ğŸ’»      Benjamin Ololade AdedokunğŸ¨ ğŸ’»              Md. Abdul MutalibğŸ¨ ğŸ’»      Aadil Arsh.S.RğŸ¨ ğŸ’»      J. Nathan AllenğŸ¨ ğŸ’»      Kieran KrugğŸ¨ ğŸ’»      Seth AddoğŸ¨ ğŸ’»      Satvik Singh RathoreğŸ¨ ğŸ’»      dangothğŸ¨ ğŸ’»              MaximğŸ¨ ğŸ’»      Phuong-Cat NgoğŸ¨ ğŸ’»      Frenchtoast0ğŸ¨ ğŸ’»      RakshithğŸ¨ ğŸ’»      Vaibhav ArorağŸ¨ ğŸ’»      zghpğŸ¨ ğŸ’»      BedovanğŸ¨ ğŸ’»              chiaramistroğŸ¨ ğŸ’»      him2016ğŸ¨ ğŸ’»      HarshitSachdevağŸ¨ ğŸ’»      Sadaf SaleemğŸ¨ ğŸ’»      Aaroh SrivastavağŸ¨ ğŸ’»      eloygplazağŸ¨ ğŸ’»      Gaurav Kumar VermağŸ¨ ğŸ’»              AndreaCUSğŸ¨ ğŸ’»      SimranğŸ¨ ğŸ’»      Prashant BhapkarğŸ¨ ğŸ’»      mhaendlerğŸ¨ ğŸ’»      Gauri MaheshwariğŸ¨ ğŸ’»      4LajfğŸ¨ ğŸ’»      Tanmoy SenguptağŸ¨ ğŸ’»              Sharad TripathiğŸ¨ ğŸ’»      Niraj ChavanğŸ¨ ğŸ’»      Luisa GualdağŸ¨ ğŸ’»      Monika-Sivakumar-3ğŸ¨ ğŸ’»      harryfensomeğŸ¨ ğŸ’»      Shubham ChoubeyğŸ¨ ğŸ’»      Ashwini PatilğŸ¨ ğŸ’»              cleversonlirağŸ¨ ğŸ’»      NurmukhammedğŸ¨ ğŸ’»      workspace-utkarshğŸ¨ ğŸ’»      Santosh PhadtareğŸ¨ ğŸ’»      Prashant WarghudeğŸ¨ ğŸ’»      Umang DakhğŸ¨ ğŸ’»      Shalini ChavanğŸ¨ ğŸ’»              vinit gurjarğŸ¨ ğŸ’»      Vishal KumarğŸ¨ ğŸ’»      Wonhyeong SeoğŸ¨ ğŸ’»      Achwale Prajwal NamdevraoğŸ¨ ğŸ’»      Ankan BanerjeeğŸ¨ ğŸ’»      bhaumikankanğŸ¨ ğŸ’»      JamesMacroZhangğŸ¨ ğŸ’»              Pedro LopesğŸ¨ ğŸ’»      diağŸ¨ ğŸ’»      tayyabhussain2910ğŸ¨ ğŸ’»      Rajdeep Shrivastava ğŸ¨ ğŸ’»      Mukul KumarğŸ¨ ğŸ’»      Mayank NğŸ¨ ğŸ’»      jdeluccağŸ¨ ğŸ’»              Sneha MittalğŸ¨ ğŸ’»      Sarika KushwahağŸ¨ ğŸ’»      farzad-khbğŸ¨ ğŸ’»      Elijah ShackelfordğŸ¨ ğŸ’»      The-Only-RaminatorğŸ¨ ğŸ’»      Keerthana KasthurilğŸ¨ ğŸ’»      Viachaslau AuchynnikauğŸ¨ ğŸ’»              Mohammad Osman RasooliğŸ¨ ğŸ’»      mvedovatoğŸ¨ ğŸ’»      Sonali RajputğŸ¨ ğŸ’»      Isha DhekğŸ¨ ğŸ’»      Ramshad Cheriyeri PeediyakkalğŸ¨ ğŸ’»      MicahğŸ¨ ğŸ’»      gauravshukla2203ğŸ¨ ğŸ’»              sndmurthyğŸ¨ ğŸ’»      Shivam-SinghğŸ¨ ğŸ’»      M. Ammar KhanğŸ¨ ğŸ’»      chandolakulğŸ¨ ğŸ’»      bhatnagar221ğŸ¨ ğŸ’»      Adrian NieÅ›ciurğŸ¨ ğŸ’»      nezi311ğŸ¨ ğŸ’»              scottajevansğŸ¨ ğŸ’»      Marcelo Antunes Soares FantiniğŸ¨ ğŸ’»      Axel De AcetisğŸ¨ ğŸ’»      Drishti SahğŸ¨ ğŸ’»      VipulDhillonğŸ¨ ğŸ’»      Urmi JanağŸ¨ ğŸ’»      Ayush MokalğŸ¨ ğŸ’»              Damola OlutokeğŸ¨ ğŸ’»      MaxğŸ¨ ğŸ’»      Lakshmi NğŸ¨ ğŸ’»      ArtemRevağŸ¨ ğŸ’»      Ujjwal AggarwalğŸ¨ ğŸ’»      MoğŸ¨ ğŸ’»      BrianğŸ¨ ğŸ’»              chamleyğŸ¨ ğŸ’»      Simone BaptisteğŸ¨ ğŸ’»      Shekhar ThakurğŸ¨ ğŸ’»      SmithğŸ¨ ğŸ’»      codernoob1ğŸ¨ ğŸ’»      lok84ğŸ¨ ğŸ’»      Tobias RiemenschneiderğŸ¨ ğŸ’»              Tharsanan1ğŸ¨ ğŸ’»      ANURAG SINGHğŸ¨ ğŸ’»      Yash SantğŸ¨ ğŸ’»      Krishiv PatelğŸ¨ ğŸ’»      GGGalaxyğŸ¨ ğŸ’»      pardeepdhillon661ğŸ¨ ğŸ’»      anujd64ğŸ¨ ğŸ’»              Pedro PereirağŸ¨ ğŸ’»      Master_SaptakğŸ¨ ğŸ’»      SURANJAN DASğŸ¨ ğŸ’»      Tripura kantğŸ¨ ğŸ’»      shabzkhanğŸ¨ ğŸ’»      Mustafa PoyağŸ¨ ğŸ’»      Roshan JhağŸ¨ ğŸ’»              GuillaumeLarueğŸ¨ ğŸ’»      Tomasz RodakğŸ¨ ğŸ’»      Junil KimğŸ¨ ğŸ’»      Surbhi MayankğŸ¨ ğŸ’»      Nemanja LekicğŸ¨ ğŸ’»      HemantMalokarğŸ¨ ğŸ’»      Felipe M. LÃ³pezğŸ¨ ğŸ’»              bibliofiloğŸ¨ ğŸ’»      GauthamG2ğŸ¨ ğŸ’»      02_tğŸ¨ ğŸ’»      Yusuf Abdul-razaqğŸ¨ ğŸ’»      VladimirğŸ¨ ğŸ’»      Sai Chandra KğŸ¨ ğŸ’»      Soroush BonabğŸ¨ ğŸ’»              Giide0nğŸ¨ ğŸ’»      GGğŸ¨ ğŸ’»      DÃ¡ger ZÃºÃ±igağŸ¨ ğŸ’»      rsk2ğŸ¨ ğŸ’»      Storozhev DJğŸ¨ ğŸ’»      JeevanğŸ¨ ğŸ’»      Andy JohnsonğŸ¨ ğŸ’»              AnÃ­bal PozoğŸ¨ ğŸ’»      Jovane de CastroğŸ¨ ğŸ’»      Muhammad Hamza AmirğŸ¨ ğŸ’»      tharaka-mtsğŸ¨ ğŸ’»      Ali KHYARğŸ¨ ğŸ’»      Caio AraujoğŸ¨ ğŸ’»      Oscar DyremyhrğŸ¨ ğŸ’»              artealityğŸ¨ ğŸ’»      Daniel DrexlmaierğŸ¨ ğŸ’»      Marco MontiğŸ¨ ğŸ’»      mikeycrystalğŸ¨ ğŸ’»      VeljanovskiiğŸ¨ ğŸ’»      Ivan GorbachevğŸ¨ ğŸ’»      Sahil RawatğŸ¨ ğŸ’»              Hasitha SunethğŸ¨ ğŸ’»      Yerko Vera LezamağŸ¨ ğŸ’»      Ivan PenchevğŸ¨ ğŸ’»      Tanver Islam TonmoyğŸ¨ ğŸ’»      Xun CaoğŸ¨ ğŸ’»      Nayan BabariyağŸ¨ ğŸ’»      Priyanshu MauryağŸ¨ ğŸ’»              Dylan TintenfichğŸ¨ ğŸ’»      Ron StraussğŸ¨ ğŸ’»      Mohammed AlBannağŸ¨ ğŸ’»      Mukund MğŸ¨ ğŸ’»      Franklin OhaegbulamğŸ¨ ğŸ’»      Nisarg ShahğŸ¨ ğŸ’»      Unik DahalğŸ¨ ğŸ’»              ReadilyğŸ¨ ğŸ’»      Alexandre PoitevinğŸ¨ ğŸ’»      ScaramirğŸ¨ ğŸ’»      PruthviğŸ¨ ğŸ’»      KalmanqğŸ¨ ğŸ’»      Alfatah NesabğŸ¨ ğŸ’»      arudesaiğŸ¨ ğŸ’»              AdryenneğŸ¨ ğŸ’»      El mehdi oudaoudğŸ¨ ğŸ’»      Jayant GoelğŸ¨ ğŸ’»      TsukiğŸ¨ ğŸ’»      Peter LemanskiğŸ¨ ğŸ’»      Annurag-byteğŸ¨ ğŸ’»      Anthony VuğŸ¨ ğŸ’»              Vitaly NikolaychukğŸ¨ ğŸ’»      NathanğŸ¨ ğŸ’»      Evgenii PetukhovğŸ¨ ğŸ’»      Loris GuerrağŸ¨ ğŸ’»      fakhriaunurğŸ¨ ğŸ’»      Mehdi HYANIğŸ¨ ğŸ’»      Sarvex JatasrağŸ¨ ğŸ’»              santimanuelrğŸ¨ ğŸ’»      Evgeniy RezanovğŸ¨ ğŸ’»      Sonia MğŸ¨ ğŸ’»      Grzegorz KmitağŸ¨ ğŸ’»      Manuel CaritağŸ¨ ğŸ’»      Felipe Cisternas AlvarezğŸ¨ ğŸ’»      Guo CiğŸ¨ ğŸ’»              Marcos SilvağŸ¨ ğŸ’»      KKğŸ¨ ğŸ’»      Shubhanjan MedhiğŸ¨ ğŸ’»      ArthurFerreiraRodriguesğŸ¨ ğŸ’»      PabloHermunğŸ¨ ğŸ’»      disha-baldawağŸ¨ ğŸ’»      StaroMoonğŸ¨ ğŸ’»              Amila T KumarasekarağŸ¨ ğŸ’»      Amoh PrinceğŸ¨ ğŸ’»      AngeloGCğŸ¨ ğŸ’»      Ebube Glory OgbondağŸ¨ ğŸ’»      Prahalad BelavadiğŸ“–      Antoni Sarnowski-TrypkağŸ¨ ğŸ’»      Alberto PasqualettoğŸ¨ ğŸ’»              Amir BabaeiğŸ¨ ğŸ’»      Syed Abdul HannanğŸ¨ ğŸ’»      Srajan RaiğŸ¨ ğŸ’»      Clarence MooreğŸ¨ ğŸ’»      Nguyen Anh TuanğŸ¨ ğŸ’»      dar2dar2ğŸ¨ ğŸ’»      Ameer IbrahimğŸ¨ ğŸ’»              Tiago LugattoğŸ¨ ğŸ’»      raremiroirğŸ¨ ğŸ’»      MoobieğŸ¨ ğŸ’»      AlicanDursunğŸ¨ ğŸ’»      bbalsamğŸ¨ ğŸ’»      LuboÅ¡ HÃ¡jekğŸ¨ ğŸ’»      mrshahzeb7ğŸ¨ ğŸ’»              Wesley SchollğŸ¨ ğŸ’»      Lawrence TurcotteğŸ¨ ğŸ’»      Michael DiPaoloğŸ¨ ğŸ’»      Smart-CodiğŸ¨ ğŸ’»      Vivek KumarğŸ¨ ğŸ’»      Igor MoiseevğŸ¨ ğŸ’»      BÃ¥rd PedersenğŸ¨ ğŸ’»              HOA PHANğŸ¨ ğŸ’»      GaborModrağŸ¨ ğŸ’»      vivek-114ğŸ¨ ğŸ’»      RobinğŸ¨ ğŸ’»      AlexğŸ¨ ğŸ’»      John EhrlingerğŸ¨ ğŸ’»      Roman ZhuravlovğŸ¨ ğŸ’»              Jordan MossğŸ¨ ğŸ’»      RaeShellyğŸ¨ ğŸ’»      gmollardğŸ¨ ğŸ’»      Md Kaif KhanğŸ¨ ğŸ’»      Pablo RomerağŸ¨ ğŸ’»      Erik BustosğŸ¨ ğŸ’»      trogfieldğŸ¨ ğŸ’»              simon-aichhornğŸ¨ ğŸ’»      Tufan GÃœLEÃ‡ğŸ¨ ğŸ’»      UÄŸur Berkecan ÃœnlÃ¼ğŸ¨ ğŸ’»      Revanth NaikğŸ¨ ğŸ’»      Lia PiresğŸ¨ ğŸ’»      Igor MestechkinğŸ¨ ğŸ’»      Anirudh KaranthğŸ¨ ğŸ’»              KBobovskiyğŸ¨ ğŸ’»      zhatiayuağŸ¨ ğŸ’» ğŸ–‹      David CardonağŸ¨ ğŸ’»      Paulo CastilhoğŸ¨ ğŸ’»      Sebastiano PicchiğŸ¨ ğŸ’»      pjotarğŸ¨ ğŸ’»      Rimel CHERIFğŸ’»              Arsal uddinğŸ–‹      Dmitry KasporskyğŸ’»      SoftwareDev1014ğŸ¨ ğŸ’»      @RobvredğŸ¨ ğŸ’»      Kasun ShanakağŸ’»      Ahmad M.ğŸ¨ ğŸ’»      Alex KozinğŸ¨ ğŸ’»              Mandy MeindersmağŸ¨ ğŸ’»      LEGALISE PIRACYğŸ¨ ğŸ’»      Alex LogvinğŸ¨ ğŸ’»      Aria DahlğŸ¨ ğŸ’»      Mustafa ArifogluğŸ¨ ğŸ’»      Yevhen LeshchenkoğŸ¨ ğŸ’»      Anubhav AdhikariğŸ¨ ğŸ’»              Noah TatkoğŸ¨ ğŸ’»      Mohit GadhaviğŸ¨ ğŸ’»      Pedro BasÃ­lioğŸ¨ ğŸ’»      RealSanjeevğŸ¨ ğŸ’»      Akash HazrağŸ¨ ğŸ’»      Christoph DahlenğŸ¨ ğŸ’»      Vincent du PlessisğŸ¨ ğŸ’»              Karen TamrazyanğŸ¨ ğŸ’»      Mirza Younus BaigğŸ¨ ğŸ’»      Ashish KumarğŸ¨ ğŸ’»      Unknown6334ğŸ¨ ğŸ’»      flowazğŸ¨ ğŸ’»      zi-aikrağŸ¨ ğŸ’»      PAYAL PMğŸ¨ ğŸ’»              Lennart LÃ¶scheğŸ¨ ğŸ’»      Yummy-YumsğŸ¨ ğŸ’»      Njuacha Hubert MikulowskiğŸ¨ ğŸ’»      Hussein EsmailğŸ¨ ğŸ’»      Bilgehan BezirğŸ¨ ğŸ’»      Muhammed ShittuğŸ¨ ğŸ’»      ClÃ©ment FERNANDESğŸ¨ ğŸ’»              JaCKoP619ğŸ¨ ğŸ’»      userutf8ğŸ¨ ğŸ’»      Mohamed UbaidğŸ¨ ğŸ’»      Justin YatesğŸ¨ ğŸ’»      mohammad aliğŸ¨ ğŸ’»      Madhav SinghğŸ¨ ğŸ’»      RgbMouse69ğŸ¨ ğŸ’»              Nicholas LeaskğŸ¨ ğŸ’»      parthav0ğŸ¨ ğŸ’»      SigmağŸ¨ ğŸ’»      Evelina BechevağŸ¨ ğŸ’»      Akshit GulyanğŸ¨ ğŸ’»      Arpita JanağŸ¨ ğŸ’»      Praveen KumarğŸ¨ ğŸ’»              Mohammad SamiğŸ¨ ğŸ’»      eddiestefanescuğŸ¨ ğŸ’»      Ramesh YadavğŸ¨ ğŸ’»      Sarthak JoshiğŸ¨ ğŸ’»      Nikhil12300ğŸ¨ ğŸ’»      YevgenğŸ¨ ğŸ’»      LeoğŸ¨ ğŸ’»              laurent bğŸ¨ ğŸ’»      MettchenğŸ¨ ğŸ’»      Ali MahdaviğŸ¨ ğŸ’»      Lucas DondoğŸ¨ ğŸ’»      Siddhesh AgarwalğŸ¨ ğŸ’»      slimerPuncherğŸ¨ ğŸ’»      saritashhğŸ¨ ğŸ’»              Iulian-Valeriu CioatÄƒğŸ¨ ğŸ’»      Szabolcs NagyğŸ¨ ğŸ’»      Jarle KvileğŸ¨ ğŸ’»      åŠ‰è€€å‡ Vic LiuğŸ¨ ğŸ’»      SuryanshğŸ¨ ğŸ’»      Matthew OosthuyseğŸ¨ ğŸ’»      Florin ZamfirğŸ¨ ğŸ’»              MelekğŸ¨ ğŸ’»      moesocioğŸ¨ ğŸ’»      Alan JamesğŸ¨ ğŸ’»      Mai Thanh PhÆ°Æ¡ngğŸ¨ ğŸ’»      Neville DabreğŸ¨ ğŸ’»      MaksymğŸ¨ ğŸ’»      tamanna900ğŸ¨ ğŸ’»              Adithya AwatiğŸ¨ ğŸ’»      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
83,hankcs/HanLP,https://github.com/hankcs/HanLP/blob/master/README.md,Python,"HanLP: Han Language Processing                                                                                   ä¸­æ–‡ |    æ—¥æœ¬èª |    Docs |    ForumThe multilingual NLP library for researchers and companies, built on PyTorch and TensorFlow 2.x, for advancingstate-of-the-art deep learning techniques in both academia and industry. HanLP was designed from day one to beefficient, user-friendly and extendable.Thanks to open-access corpora like Universal Dependencies and OntoNotes, HanLP 2.1 now offers 10 joint tasks on 130languages: tokenization, lemmatization, part-of-speech tagging, token feature extraction, dependency parsing,constituency parsing, semantic role labeling, semantic dependency parsing, abstract meaning representation (AMR)parsing.For end users, HanLP offers light-weighted RESTful APIs and native Python APIs.RESTful APIsTiny packages in several KBs for agile development and mobile applications. Although anonymous users are welcomed, anauth key is suggestedand a free one can be applied here underthe CC BY-NC-SA 4.0 license.  Click to expand tutorials for RESTful APIsPythonpip install hanlp_restfulCreate a client with our API endpoint and your auth.from hanlp_restful import HanLPClientHanLP = HanLPClient('https://hanlp.hankcs.com/api', auth=None, language='mul') # mul: multilingual, zh: ChineseJavaInsert the following dependency into your pom.xml.<dependency>  <groupId>com.hankcs.hanlp.restful</groupId>  <artifactId>hanlp-restful</artifactId>  <version>0.0.15</version></dependency>Create a client with our API endpoint and your auth.HanLPClient HanLP = new HanLPClient(\""https://hanlp.hankcs.com/api\"", null, \""mul\""); // mul: multilingual, zh: ChineseQuick StartNo matter which language you use, the same interface can be used to parse a document.HanLP.parse(    \""In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments. 2021å¹´ã€HanLPv2.1ã¯æ¬¡ä¸–ä»£ã®æœ€å…ˆç«¯å¤šè¨€èªNLPæŠ€è¡“ã‚’æœ¬ç•ªç’°å¢ƒã«å°å…¥ã—ã¾ã™ã€‚2021å¹´ HanLPv2.1ä¸ºç”Ÿäº§ç¯å¢ƒå¸¦æ¥æ¬¡ä¸–ä»£æœ€å…ˆè¿›çš„å¤šè¯­ç§NLPæŠ€æœ¯ã€‚\"")See docs for visualization, annotation guidelines and more details.Native APIspip install hanlpHanLP requires Python 3.6 or later. GPU/TPU is suggested but not mandatory.Quick Startimport hanlpHanLP = hanlp.load(hanlp.pretrained.mtl.UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_XLMR_BASE)print(HanLP(['In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments.',             '2021å¹´ã€HanLPv2.1ã¯æ¬¡ä¸–ä»£ã®æœ€å…ˆç«¯å¤šè¨€èªNLPæŠ€è¡“ã‚’æœ¬ç•ªç’°å¢ƒã«å°å…¥ã—ã¾ã™ã€‚',             '2021å¹´ HanLPv2.1ä¸ºç”Ÿäº§ç¯å¢ƒå¸¦æ¥æ¬¡ä¸–ä»£æœ€å…ˆè¿›çš„å¤šè¯­ç§NLPæŠ€æœ¯ã€‚']))In particular, the Python HanLPClient can also be used as a callable function following the same semantics.See docs for visualization, annotation guidelines and more details.To process Chinese or Japanese, HanLP provides mono-lingual models in each language which significantly outperform themulti-lingual model. See docs for the list of models.Train Your Own ModelsTo write DL models is not hard, the real hard thing is to write a model able to reproduce the scores in papers. Thesnippet below shows how to surpass the state-of-the-art tokenizer in 6 minutes.tokenizer = TransformerTaggingTokenizer()save_dir = 'data/model/cws/sighan2005_pku_bert_base_96.7'tokenizer.fit(    SIGHAN2005_PKU_TRAIN_ALL,    SIGHAN2005_PKU_TEST,  # Conventionally, no devset is used. See Tian et al. (2020).    save_dir,    'bert-base-chinese',    max_seq_len=300,    char_level=True,    hard_constraint=True,    sampler_builder=SortingSamplerBuilder(batch_size=32),    epochs=3,    adam_epsilon=1e-6,    warmup_steps=0.1,    weight_decay=0.01,    word_dropout=0.1,    seed=1660853059,)tokenizer.evaluate(SIGHAN2005_PKU_TEST, save_dir)The result is guaranteed to be 96.73 as the random seed is fixed. Different from some overclaiming papers andprojects, HanLP promises every single digit in our scores is reproducible. Any issues on reproducibility will be treatedand solved as a top-priority fatal bug.PerformanceThe performance of multi-task learning models is shown in the following table.langcorporamodeltokposnerdepconsrlsdplemfeaamrfinecoarsectbpku863udpkumsraontonotesSemEval16DMPASPSDmulUD2.7OntoNotes5small98.62----93.23--74.4279.1076.8570.63-91.1993.6785.3487.7184.51-base98.97----90.32--80.3278.7471.2373.63-92.6096.0481.1985.0882.13-zhopensmall97.25-96.66-----95.0084.5787.6273.4084.57------base97.50-97.07-----96.0487.1189.8477.7887.11------closesmall96.7095.9396.8797.5695.05-96.2295.7476.7984.4488.1375.8174.28------base97.5296.4496.9997.5995.29-96.4895.7277.7785.2988.5776.5273.76------ernie96.9597.2996.7697.6495.22-97.3196.4777.9585.6789.1778.5174.10------Multi-task learning models often under-perform their single-task learning counterparts according to our latestresearch. Similarly, mono-lingual models often outperform multi-lingual models. Therefore, we strongly recommend theuse of a single-task mono-lingual model if you aretargeting at high accuracy instead of faster speed.A state-of-the-art AMR model has been released.CitingIf you use HanLP in your research, please cite this repository.@inproceedings{he-choi-2021-stem,    title = \""The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders\"",    author = \""He, Han and Choi, Jinho D.\"",    booktitle = \""Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\"",    month = nov,    year = \""2021\"",    address = \""Online and Punta Cana, Dominican Republic\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://aclanthology.org/2021.emnlp-main.451\"",    pages = \""5555--5577\"",    abstract = \""Multi-task learning with transformer encoders (MTL) has emerged as a powerful technique to improve performance on closely-related tasks for both accuracy and efficiency while a question still remains whether or not it would perform as well on tasks that are distinct in nature. We first present MTL results on five NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over single-task learning. We then conduct an extensive pruning analysis to show that a certain set of attention heads get claimed by most tasks during MTL, who interfere with one another to fine-tune those heads for their own objectives. Based on this finding, we propose the Stem Cell Hypothesis to reveal the existence of attention heads naturally talented for many tasks that cannot be jointly trained to create adequate embeddings for all of those tasks. Finally, we design novel parameter-free probes to justify our hypothesis and demonstrate how attention heads are transformed across the five tasks during MTL through label analysis.\"",}LicenseCodesHanLP is licensed under Apache License 2.0. You can use HanLP in your commercial products for free. We wouldappreciate it if you add a link to HanLP on your website.ModelsUnless otherwise specified, all models in HanLP are licensedunder  CC BY-NC-SA 4.0.Referenceshttps://hanlp.hankcs.com/docs/references.html"
84,XX-net/XX-Net,https://github.com/XX-net/XX-Net/blob/master/README.md,Python,"ğŸš€ XX-Net (ç¿»å¢™VPN)è¿™æ˜¯ä¸€ä¸ªå¯é çš„ç¿»å¢™ç³»ç»Ÿï¼Œå·²ç»è¿ç»­è¿è¡Œ 8 å¹´ï¼æˆ‘ä»¬ä¸å»ç ”ç©¶å¢™æœ‰ä»€ä¹ˆç¼ºé™·ï¼Œå› ä¸ºæ‰€æœ‰çš„ç¼ºé™·éƒ½ä¼šè¢«æ…¢æ…¢çš„è¡¥ä¸Šã€‚æˆ‘ä»¬çš„ç­–ç•¥æ˜¯åŒ–èº«ä¸ºæ™®é€šæµé‡ï¼Œå®Œå…¨æ— æ³•åŒºåˆ†ï¼Œæœ€ç»ˆéšèº«åœ¨èŒ«èŒ«çš„ç½‘ç»œè¿æ¥ä¸­ã€‚ã€‚ã€‚ğŸ”Œ åŠŸèƒ½ç‰¹æ€§æ”¯æŒå¤šå¹³å°ï¼š Android/iOS/Windows/Mac/Linuxé‡‡ç”¨ç‹¬ç‰¹çš„æ··æ·†ç®—æ³•ï¼Œè®©æ‚¨çš„æµé‡åœ¨ç½‘ç»œä¸­æ— æ³•è¢«è¯†åˆ«å¼€æºç»¿è‰²è½¯ä»¶ï¼Œæ— éœ€å®‰è£…ï¼Œå¯ä»¥æ”¯æŒå¤šå°è®¾å¤‡åŒæ—¶è¿æ¥æ¨¡æ‹ŸChromeæµè§ˆå™¨è¡Œä¸ºï¼Œå®Œå…¨æ— æ³•è¯†åˆ«ï¼Œç¨³å®šç¿»å¢™å†…ç½® ChatGPTï¼Œæ¯ä¸ªå¥—é¤èµ é€ ChatGPT-3.5 ä¸€ç™¾ä¸‡tokenå®˜ç½‘ä¸‹è½½: https://xx-net.comTelegram: https://t.me/xxnetshareTwitter: https://twitter.com/XXNetDevä¸­æ–‡å¸®åŠ©æ–‡æ¡£ Â  Â  Â English Document Â  Â  Â ÙØ§Ø±Ø³ÛŒ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒæœ€æ–°å…¬å‘Šï¼š2023-08-15æ–°ç‰ˆ 5.5.0, æå‡è¿æ¥æ€§èƒ½5.1.0ï¼Œå†…ç½®ChatGPTåŸæ¥æ˜¯4.x.x è€ç‰ˆæœ¬çš„ï¼Œéœ€è¦é‡æ–°ä¸‹è½½æ–°ç‰ˆå®‰è£…ï¼Œä¸èƒ½åº”ç”¨å†…å‡çº§ã€‚æç¤ºï¼šæœ‰é—®é¢˜è¯·å…ˆçœ‹Wikiæ–‡æ¡£æé—® å‰ï¼Œè¯·å…ˆçœ‹æœ€è¿‘è®¨è®ºä¸»é¢˜ ï¼Œé¿å…é‡å¤å‘é—®ã€‚"
85,wangzheng0822/algo,https://github.com/wangzheng0822/algo/blob/master/README.md,Python,æ•°æ®ç»“æ„å’Œç®—æ³•å¿…çŸ¥å¿…ä¼šçš„50ä¸ªä»£ç å®ç°å¾®ä¿¡æœç´¢æˆ‘çš„å…¬ä¼—å·â€œå°äº‰å“¥â€ï¼Œæˆ–è€…å¾®ä¿¡æ‰«æä¸‹é¢äºŒç»´ç å…³æ³¨å…³æ³¨å¾®ä¿¡å…¬ä¼—å·ï¼Œå›å¤â€PDFâ€œè·å–ç‹¬å®¶ç®—æ³•èµ„æ–™ã€‚å‰Googleå·¥ç¨‹å¸ˆï¼Œ10ä¸‡äººè·Ÿç€å­¦çš„ã€Šæ•°æ®ç»“æ„å’Œç®—æ³•ä¹‹ç¾ã€‹ã€Šè®¾è®¡æ¨¡å¼ä¹‹ç¾ã€‹ä¸“æ ä½œè€…æ•°ç»„å®ç°ä¸€ä¸ªæ”¯æŒåŠ¨æ€æ‰©å®¹çš„æ•°ç»„å®ç°ä¸€ä¸ªå¤§å°å›ºå®šçš„æœ‰åºæ•°ç»„ï¼Œæ”¯æŒåŠ¨æ€å¢åˆ æ”¹æ“ä½œå®ç°ä¸¤ä¸ªæœ‰åºæ•°ç»„åˆå¹¶ä¸ºä¸€ä¸ªæœ‰åºæ•°ç»„é“¾è¡¨å®ç°å•é“¾è¡¨ã€å¾ªç¯é“¾è¡¨ã€åŒå‘é“¾è¡¨ï¼Œæ”¯æŒå¢åˆ æ“ä½œå®ç°å•é“¾è¡¨åè½¬å®ç°ä¸¤ä¸ªæœ‰åºçš„é“¾è¡¨åˆå¹¶ä¸ºä¸€ä¸ªæœ‰åºé“¾è¡¨å®ç°æ±‚é“¾è¡¨çš„ä¸­é—´ç»“ç‚¹æ ˆç”¨æ•°ç»„å®ç°ä¸€ä¸ªé¡ºåºæ ˆç”¨é“¾è¡¨å®ç°ä¸€ä¸ªé“¾å¼æ ˆç¼–ç¨‹æ¨¡æ‹Ÿå®ç°ä¸€ä¸ªæµè§ˆå™¨çš„å‰è¿›ã€åé€€åŠŸèƒ½é˜Ÿåˆ—ç”¨æ•°ç»„å®ç°ä¸€ä¸ªé¡ºåºé˜Ÿåˆ—ç”¨é“¾è¡¨å®ç°ä¸€ä¸ªé“¾å¼é˜Ÿåˆ—å®ç°ä¸€ä¸ªå¾ªç¯é˜Ÿåˆ—é€’å½’ç¼–ç¨‹å®ç°æ–æ³¢é‚£å¥‘æ•°åˆ—æ±‚å€¼f(n)=f(n-1)+f(n-2)ç¼–ç¨‹å®ç°æ±‚é˜¶ä¹˜n!ç¼–ç¨‹å®ç°ä¸€ç»„æ•°æ®é›†åˆçš„å…¨æ’åˆ—æ’åºå®ç°å½’å¹¶æ’åºã€å¿«é€Ÿæ’åºã€æ’å…¥æ’åºã€å†’æ³¡æ’åºã€é€‰æ‹©æ’åºç¼–ç¨‹å®ç°O(n)æ—¶é—´å¤æ‚åº¦å†…æ‰¾åˆ°ä¸€ç»„æ•°æ®çš„ç¬¬Kå¤§å…ƒç´ äºŒåˆ†æŸ¥æ‰¾å®ç°ä¸€ä¸ªæœ‰åºæ•°ç»„çš„äºŒåˆ†æŸ¥æ‰¾ç®—æ³•å®ç°æ¨¡ç³ŠäºŒåˆ†æŸ¥æ‰¾ç®—æ³•ï¼ˆæ¯”å¦‚å¤§äºç­‰äºç»™å®šå€¼çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰æ•£åˆ—è¡¨å®ç°ä¸€ä¸ªåŸºäºé“¾è¡¨æ³•è§£å†³å†²çªé—®é¢˜çš„æ•£åˆ—è¡¨å®ç°ä¸€ä¸ªLRUç¼“å­˜æ·˜æ±°ç®—æ³•å­—ç¬¦ä¸²å®ç°ä¸€ä¸ªå­—ç¬¦é›†ï¼ŒåªåŒ…å«aï½zè¿™26ä¸ªè‹±æ–‡å­—æ¯çš„Trieæ ‘å®ç°æœ´ç´ çš„å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•äºŒå‰æ ‘å®ç°ä¸€ä¸ªäºŒå‰æŸ¥æ‰¾æ ‘ï¼Œå¹¶ä¸”æ”¯æŒæ’å…¥ã€åˆ é™¤ã€æŸ¥æ‰¾æ“ä½œå®ç°æŸ¥æ‰¾äºŒå‰æŸ¥æ‰¾æ ‘ä¸­æŸä¸ªèŠ‚ç‚¹çš„åç»§ã€å‰é©±èŠ‚ç‚¹å®ç°äºŒå‰æ ‘å‰ã€ä¸­ã€ååºä»¥åŠæŒ‰å±‚éå†å †å®ç°ä¸€ä¸ªå°é¡¶å †ã€å¤§é¡¶å †ã€ä¼˜å…ˆçº§é˜Ÿåˆ—å®ç°å †æ’åºåˆ©ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—åˆå¹¶Kä¸ªæœ‰åºæ•°ç»„æ±‚ä¸€ç»„åŠ¨æ€æ•°æ®é›†åˆçš„æœ€å¤§Top Kå›¾å®ç°æœ‰å‘å›¾ã€æ— å‘å›¾ã€æœ‰æƒå›¾ã€æ— æƒå›¾çš„é‚»æ¥çŸ©é˜µå’Œé‚»æ¥è¡¨è¡¨ç¤ºæ–¹æ³•å®ç°å›¾çš„æ·±åº¦ä¼˜å…ˆæœç´¢ã€å¹¿åº¦ä¼˜å…ˆæœç´¢å®ç°Dijkstraç®—æ³•ã€A*ç®—æ³•å®ç°æ‹“æ‰‘æ’åºçš„Kahnç®—æ³•ã€DFSç®—æ³•å›æº¯åˆ©ç”¨å›æº¯ç®—æ³•æ±‚è§£å…«çš‡åé—®é¢˜åˆ©ç”¨å›æº¯ç®—æ³•æ±‚è§£0-1èƒŒåŒ…é—®é¢˜åˆ†æ²»åˆ©ç”¨åˆ†æ²»ç®—æ³•æ±‚ä¸€ç»„æ•°æ®çš„é€†åºå¯¹ä¸ªæ•°åŠ¨æ€è§„åˆ’0-1èƒŒåŒ…é—®é¢˜æœ€å°è·¯å¾„å’Œç¼–ç¨‹å®ç°è±æ–‡æ–¯å¦æœ€çŸ­ç¼–è¾‘è·ç¦»ç¼–ç¨‹å®ç°æŸ¥æ‰¾ä¸¤ä¸ªå­—ç¬¦ä¸²çš„æœ€é•¿å…¬å…±å­åºåˆ—ç¼–ç¨‹å®ç°ä¸€ä¸ªæ•°æ®åºåˆ—çš„æœ€é•¿é€’å¢å­åºåˆ—
86,encode/django-rest-framework,https://github.com/encode/django-rest-framework/blob/master/README.md,Python,"Django REST frameworkAwesome web-browsable Web APIs.Full documentation for the project is available at https://www.django-rest-framework.org/.FundingREST framework is a collaboratively funded project. If you useREST framework commercially we strongly encourage you to invest in itscontinued development by signing up for a paid plan.The initial aim is to provide a single full-time position on REST framework.Every single sign-up makes a significant impact towards making that possible.Many thanks to all our wonderful sponsors, and in particular to our premium backers, Sentry, Stream, Spacinov, Retool, bit.io, PostHog, CryptAPI, and FEZTO.OverviewDjango REST framework is a powerful and flexible toolkit for building Web APIs.Some reasons you might want to use REST framework:The Web browsable API is a huge usability win for your developers.Authentication policies including optional packages for OAuth1a and OAuth2.Serialization that supports both ORM and non-ORM data sources.Customizable all the way down - just use regular function-based views if you don't need the more powerful features.Extensive documentation, and great community support.There is a live example API for testing purposes, available here.Below: Screenshot from the browsable APIRequirementsPython 3.6+Django 4.2, 4.1, 4.0, 3.2, 3.1, 3.0We highly recommend and only officially support the latest patch release ofeach Python and Django series.InstallationInstall using pip...pip install djangorestframeworkAdd 'rest_framework' to your INSTALLED_APPS setting.INSTALLED_APPS = [    ...    'rest_framework',]ExampleLet's take a look at a quick example of using REST framework to build a simple model-backed API for accessing users and groups.Startup up a new project like so...pip install djangopip install djangorestframeworkdjango-admin startproject example ../manage.py migrate./manage.py createsuperuserNow edit the example/urls.py module in your project:from django.contrib.auth.models import Userfrom django.urls import include, pathfrom rest_framework import routers, serializers, viewsets# Serializers define the API representation.class UserSerializer(serializers.HyperlinkedModelSerializer):    class Meta:        model = User        fields = ['url', 'username', 'email', 'is_staff']# ViewSets define the view behavior.class UserViewSet(viewsets.ModelViewSet):    queryset = User.objects.all()    serializer_class = UserSerializer# Routers provide a way of automatically determining the URL conf.router = routers.DefaultRouter()router.register(r'users', UserViewSet)# Wire up our API using automatic URL routing.# Additionally, we include login URLs for the browsable API.urlpatterns = [    path('', include(router.urls)),    path('api-auth/', include('rest_framework.urls', namespace='rest_framework')),]We'd also like to configure a couple of settings for our API.Add the following to your settings.py module:INSTALLED_APPS = [    ...  # Make sure to include the default installed apps here.    'rest_framework',]REST_FRAMEWORK = {    # Use Django's standard `django.contrib.auth` permissions,    # or allow read-only access for unauthenticated users.    'DEFAULT_PERMISSION_CLASSES': [        'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly',    ]}That's it, we're done!./manage.py runserverYou can now open the API in your browser at http://127.0.0.1:8000/, and view your new 'users' API. If you use the Login control in the top right corner you'll also be able to add, create and delete users from the system.You can also interact with the API using command line tools such as curl. For example, to list the users endpoint:$ curl -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/[    {        \""url\"": \""http://127.0.0.1:8000/users/1/\"",        \""username\"": \""admin\"",        \""email\"": \""admin@example.com\"",        \""is_staff\"": true,    }]Or to create a new user:$ curl -X POST -d username=new -d email=new@example.com -d is_staff=false -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/{    \""url\"": \""http://127.0.0.1:8000/users/2/\"",    \""username\"": \""new\"",    \""email\"": \""new@example.com\"",    \""is_staff\"": false,}Documentation & SupportFull documentation for the project is available at https://www.django-rest-framework.org/.For questions and support, use the REST framework discussion group, or #restframework on libera.chat IRC.You may also want to follow the author on Twitter.SecurityPlease see the security policy."
