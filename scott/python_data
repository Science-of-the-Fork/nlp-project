,repo_name,url,language,readme_content
0,jackfrued/Python-100-Days,https://github.com/jackfrued/Python-100-Days/blob/master/README.md,Python,"Python - 100天从新手到大师作者：骆昊说明：从项目上线到获得8w+星标以来，一直收到反馈说基础部分（前15天的内容）对新手来说是比较困难的，建议有配套视频进行讲解。最近把基础部分的内容重新制作了一个名为“Python-Core-50-Courses”的项目，用更为简单通俗的方式重写了这部分内容并附带了视频讲解，初学者可以关注下这个新项目。如果需要Python基础视频，可以在“B站”搜索《Python零基础快速上手》，这套视频是我讲课的时候录制的随堂视频，画质尚可、音质一般，但是对初学者应该会有些帮助，欢迎大家留言、评论、发弹幕。学习之后觉得有收获的小伙伴可以“一键三连”来支持UP主（千锋Python）。国内用户如果访问GitHub比较慢的话，可以关注我的知乎号Python-Jack，上面的“从零开始学Python”专栏比较适合初学者，其他的专栏也在持续创作和更新中，欢迎大家关注并点赞评论。创作不易，感谢大家的打赏支持，这些钱不会用于个人消费（例如：购买咖啡），而是通过腾讯公益、美团公益、水滴筹等平台捐赠给需要帮助的人（点击了解捐赠情况）。需要加入QQ学习群的可以扫描下面的二维码，三个群加一个即可，不要重复进群。学习群会为大家提供学习资源和问题解答，如果有Python体验课和行业公开课会提前在群里通知大家，欢迎大家加入。项目“Day80~90”部分目前仍在创作中，因为作者平时也挤不出太多时间来写文档，因此更新的速度比较缓慢，感谢大家的理解。Python应用领域和职业发展分析简单的说，Python是一个“优雅”、“明确”、“简单”的编程语言。学习曲线低，非专业人士也能上手开源系统，拥有强大的生态圈解释型语言，完美的平台可移植性动态类型语言，支持面向对象和函数式编程代码规范程度高，可读性强Python在以下领域都有用武之地。后端开发 - Python / Java / Go / PHPDevOps - Python / Shell / Ruby数据采集 - Python / C++ / Java量化交易 - Python / C++ / R数据科学 - Python / R / Julia / Matlab机器学习 - Python / R / C++ / Julia自动化测试 - Python / Shell作为一名Python开发者，根据个人的喜好和职业规划，可以选择的就业领域也非常多。Python后端开发工程师（服务器、云平台、数据接口）Python运维工程师（自动化运维、SRE、DevOps）Python数据分析师（数据分析、商业智能、数字化运营）Python数据挖掘工程师（机器学习、深度学习、算法专家）Python爬虫工程师Python测试工程师（自动化测试、测试开发）说明：目前，数据分析和数据挖掘是非常热门的方向，因为不管是互联网行业还是传统行业都已经积累了大量的数据，各行各业都需要数据分析师从已有的数据中发现更多的商业价值，从而为企业的决策提供数据的支撑，这就是所谓的数据驱动决策。给初学者的几个建议：Make English as your working language. （让英语成为你的工作语言）Practice makes perfect. （熟能生巧）All experience comes from mistakes. （所有的经验都源于你犯过的错误）Don't be one of the leeches. （不要当伸手党）Either outstanding or out. （要么出众，要么出局）Day01~15 - Python语言基础Day01 - 初识PythonPython简介 - Python的历史 / Python的优缺点 / Python的应用领域搭建编程环境 - Windows环境 / Linux环境 / MacOS环境从终端运行Python程序 - Hello, world / print函数 / 运行程序使用IDLE - 交互式环境(REPL) / 编写多行代码 / 运行程序 / 退出IDLE注释 - 注释的作用 / 单行注释 / 多行注释Day02 - 语言元素程序和进制 - 指令和程序 / 冯诺依曼机 / 二进制和十进制 / 八进制和十六进制变量和类型 - 变量的命名 / 变量的使用 / input函数 / 检查变量类型 / 类型转换数字和字符串 - 整数 / 浮点数 / 复数 / 字符串 / 字符串基本操作 / 字符编码运算符 - 数学运算符 / 赋值运算符 / 比较运算符 / 逻辑运算符 / 身份运算符 / 运算符的优先级应用案例 - 华氏温度转换成摄氏温度 / 输入圆的半径计算周长和面积 / 输入年份判断是否是闰年Day03 - 分支结构分支结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图if语句 - 简单的if / if-else结构 / if-elif-else结构 / 嵌套的if应用案例 - 用户身份验证 / 英制单位与公制单位互换 / 掷骰子决定做什么 / 百分制成绩转等级制 / 分段函数求值 / 输入三条边的长度如果能构成三角形就计算周长和面积Day04 - 循环结构循环结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图while循环 - 基本结构 / break语句 / continue语句for循环 - 基本结构 / range类型 / 循环中的分支结构 / 嵌套的循环 / 提前结束程序应用案例 - 1~100求和 / 判断素数 / 猜数字游戏 / 打印九九表 / 打印三角形图案 / 猴子吃桃 / 百钱百鸡Day05 - 构造程序逻辑经典案例：水仙花数 / 百钱百鸡 / Craps赌博游戏练习题目：斐波那契数列 / 完美数 / 素数Day06 - 函数和模块的使用函数的作用 - 代码的坏味道 / 用函数封装功能模块定义函数 - def关键字 / 函数名 / 参数列表 / return语句 / 调用自定义函数调用函数 - Python内置函数 /  导入模块和函数函数的参数 - 默认参数 / 可变参数 / 关键字参数 / 命名关键字参数函数的返回值 - 没有返回值  / 返回单个值 / 返回多个值作用域问题 - 局部作用域 / 嵌套作用域 / 全局作用域 / 内置作用域 / 和作用域相关的关键字用模块管理函数 - 模块的概念 / 用自定义模块管理函数 / 命名冲突的时候会怎样（同一个模块和不同的模块）Day07 - 字符串和常用数据结构字符串的使用 - 计算长度 / 下标运算 / 切片 / 常用方法列表基本用法 - 定义列表 / 用下表访问元素 / 下标越界 / 添加元素 / 删除元素 / 修改元素 / 切片 / 循环遍历列表常用操作 - 连接 / 复制(复制元素和复制数组) / 长度 / 排序 / 倒转 / 查找生成列表 - 使用range创建数字列表 / 生成表达式 / 生成器元组的使用 - 定义元组 / 使用元组中的值 / 修改元组变量 / 元组和列表转换集合基本用法 - 集合和列表的区别 /  创建集合 / 添加元素 / 删除元素 /  清空集合常用操作 - 交集 / 并集 / 差集 / 对称差 / 子集 / 超集字典的基本用法 - 字典的特点 / 创建字典 / 添加元素 / 删除元素 / 取值 / 清空字典常用操作 - keys方法 / values方法 / items方法 / setdefault方法基础练习 - 跑马灯效果 / 列表找最大元素 / 统计考试成绩的平均分 / Fibonacci数列 / 杨辉三角综合案例 - 双色球选号 / 井字棋Day08 - 面向对象编程基础类和对象 - 什么是类 / 什么是对象 / 面向对象其他相关概念定义类 - 基本结构 / 属性和方法 / 构造器 / 析构器 / __str__方法使用对象 - 创建对象 / 给对象发消息面向对象的四大支柱 - 抽象 / 封装 / 继承 / 多态基础练习 - 定义学生类 / 定义时钟类 / 定义图形类 / 定义汽车类Day09 - 面向对象进阶属性 - 类属性 / 实例属性 / 属性访问器 / 属性修改器 / 属性删除器 / 使用__slots__类中的方法 - 实例方法 / 类方法 / 静态方法运算符重载 - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__类(的对象)之间的关系 - 关联 / 继承 / 依赖继承和多态 - 什么是继承 / 继承的语法 / 调用父类方法 / 方法重写 / 类型判定 / 多重继承 / 菱形继承(钻石继承)和C3算法综合案例 - 工资结算系统 / 图书自动折扣系统 / 自定义分数类Day10 - 图形用户界面和游戏开发使用tkinter开发GUI程序使用pygame三方库开发游戏应用“大球吃小球”游戏Day11 - 文件和异常读文件 - 读取整个文件 / 逐行读取 / 文件路径写文件 - 覆盖写入 / 追加写入 / 文本文件 / 二进制文件异常处理 - 异常机制的重要性 / try-except代码块 / else代码块 / finally代码块 / 内置异常类型 / 异常栈 / raise语句数据持久化 - CSV文件概述 / csv模块的应用 / JSON数据格式 / json模块的应用Day12 - 字符串和正则表达式字符串高级操作 - 转义字符 / 原始字符串 / 多行字符串 / in和not in运算符 / is_xxx方法 / join和split方法 / strip相关方法 / pyperclip模块 / 不变字符串和可变字符串 / StringIO的使用正则表达式入门 - 正则表达式的作用 / 元字符 / 转义 / 量词 / 分组 / 零宽断言 /贪婪匹配与惰性匹配懒惰 / 使用re模块实现正则表达式操作（匹配、搜索、替换、捕获）使用正则表达式 - re模块 / compile函数 / group和groups方法 / match方法 / search方法 / findall和finditer方法 / sub和subn方法 / split方法应用案例 - 使用正则表达式验证输入的字符串Day13 - 进程和线程进程和线程的概念 - 什么是进程 / 什么是线程 / 多线程的应用场景使用进程 - fork函数 / multiprocessing模块 / 进程池 / 进程间通信使用线程 -  threading模块 / Thread类 / RLock类 / Condition类 / 线程池Day14 - 网络编程入门和网络应用开发计算机网络基础 - 计算机网络发展史 / “TCP-IP”模型 / IP地址 / 端口 / 协议 / 其他相关概念网络应用模式 - “客户端-服务器”模式 / “浏览器-服务器”模式基于HTTP协议访问网络资源 - 网络API概述 / 访问URL / requests三方库 / 解析JSON格式数据Python网络编程 - 套接字的概念 / socket模块 /  socket函数 / 创建TCP服务器 / 创建TCP客户端 / 创建UDP服务器 / 创建UDP客户端电子邮件 - SMTP协议 / POP3协议 / IMAP协议 / smtplib模块 / poplib模块 / imaplib模块短信服务 - 调用短信服务网关Day15 - 图像和文档处理用Pillow处理图片 - 图片读写 / 图片合成 / 几何变换 / 色彩转换 / 滤镜效果读写Word文档 - 文本内容的处理 / 段落 / 页眉和页脚 / 样式的处理读写Excel文件 - xlrd / xlwt / openpyxlDay16~Day20 - Python语言进阶 常用数据结构函数的高级用法 - “一等公民” / 高阶函数 / Lambda函数 / 作用域和闭包 / 装饰器面向对象高级知识 - “三大支柱” / 类与类之间的关系 / 垃圾回收 / 魔术属性和方法 / 混入 / 元类 / 面向对象设计原则 / GoF设计模式迭代器和生成器 - 相关魔术方法 / 创建生成器的两种方式 /并发和异步编程 - 多线程 / 多进程 / 异步IO / async和awaitDay21~30 - Web前端入门用HTML标签承载页面内容用CSS渲染页面用JavaScript处理交互式行为jQuery入门和提高Vue.js入门Element的使用Bootstrap的使用Day31~35 - 玩转Linux操作系统操作系统发展史和Linux概述Linux基础命令Linux中的实用程序Linux的文件系统Vim编辑器的应用环境变量和Shell编程软件的安装和服务的配置网络访问和管理其他相关内容Day36~40 - 数据库基础和进阶关系型数据库概述MySQL的安装和使用SQL的使用DDL - 数据定义语言 - create / drop / alterDML - 数据操作语言 - insert / delete / updateDQL - 数据查询语言 - selectDCL - 数据控制语言 - grant / revokeMySQL新特性窗口函数的应用JSON数据类型相关知识数据完整性和一致性视图、函数、过程、触发器事务和锁执行计划和索引范式理论和反范式设计在Python中操作MySQLDay41~55 - 实战DjangoDay41 - Django快速上手Web应用工作机制HTTP请求和响应Django框架概述5分钟快速上手Day42 - 深入模型关系型数据库配置使用ORM完成对模型的CRUD操作管理后台的使用Django模型最佳实践模型定义参考Day43 - 静态资源和Ajax请求加载静态资源Ajax概述用Ajax实现投票功能Day44 - Cookie和Session实现用户跟踪cookie和session的关系Django框架对session的支持视图函数中的cookie读写操作Day45 - 报表和日志通过HttpResponse修改响应头使用StreamingHttpResponse处理大文件使用xlwt生成Excel报表使用reportlab生成PDF报表使用ECharts生成前端图表Day46 - 日志和调试工具栏配置日志配置Django-Debug-Toolbar优化ORM代码Day47 - 中间件的应用什么是中间件Django框架内置的中间件自定义中间件及其应用场景Day48 - 前后端分离开发入门返回JSON格式的数据用Vue.js渲染页面Day49 - RESTful架构和DRF入门Day50 - RESTful架构和DRF进阶Day51 - 使用缓存网站优化第一定律在Django项目中使用Redis提供缓存服务在视图函数中读写缓存使用装饰器实现页面缓存为数据接口提供缓存服务Day52 - 接入三方平台文件上传表单控件和图片文件预览服务器端如何处理上传的文件Day53 - 异步任务和定时任务网站优化第二定律配置消息队列服务在项目中使用Celery实现任务异步化在项目中使用Celery实现定时任务Day54 - 单元测试Day55 - 项目上线Python中的单元测试Django框架对单元测试的支持使用版本控制系统配置和使用uWSGI动静分离和Nginx配置配置HTTPS配置域名解析Day56~60 - 用FastAPI开发数据接口FastAPI五分钟上手请求和响应接入关系型数据库依赖注入中间件异步化虚拟化部署（Docker）项目实战：车辆违章查询项目Day61~65 - 爬虫开发Day61 - 网络数据采集概述网络爬虫的概念及其应用领域网络爬虫的合法性探讨开发网络爬虫的相关工具一个爬虫程序的构成Day62 - 数据抓取和解析使用requests三方库实现数据抓取页面解析的三种方式正则表达式解析XPath解析CSS选择器解析Day63 - Python中的并发编程多线程多进程异步I/ODay64 - 使用Selenium抓取网页动态内容Day65 - 爬虫框架Scrapy简介Day66~80 - 数据分析Day66 - 数据分析概述Day67 - 环境准备Day68 - NumPy的应用-1Day69 - NumPy的应用-2Day70 - Pandas的应用-1Day71 - Pandas的应用-2Day72 - Pandas的应用-3Day73 - Pandas的应用-4Day74 - Pandas的应用-5Day75 - 数据可视化-1Day76 - 数据可视化-2Day77 - 概率统计基础Day78 - 方差分析和参数估计Day79 - 相关和回归Day80 - 数据分析方法论Day81~90 - 机器学习和深度学习Day81 - 机器学习基础Day82 - k最近邻分类Day83 - 决策树Day84 - 贝叶斯分类Day85 - 支持向量机Day86 - K-均值聚类Day87 - 回归分析Day88 - 深度学习入门Day89 - PyTorch概述Day90 - PyTorch实战Day91~100 - 团队项目开发第91天：团队项目开发的问题和解决方案软件过程模型经典过程模型（瀑布模型）可行性分析（研究做还是不做），输出《可行性分析报告》。需求分析（研究做什么），输出《需求规格说明书》和产品界面原型图。概要设计和详细设计，输出概念模型图（ER图）、物理模型图、类图、时序图等。编码 / 测试。上线 / 维护。瀑布模型最大的缺点是无法拥抱需求变化，整套流程结束后才能看到产品，团队士气低落。敏捷开发（Scrum）- 产品所有者、Scrum Master、研发人员 - Sprint产品的Backlog（用户故事、产品原型）。计划会议（评估和预算）。日常开发（站立会议、番茄工作法、结对编程、测试先行、代码重构……）。修复bug（问题描述、重现步骤、测试人员、被指派人）。发布版本。评审会议（Showcase，用户需要参与）。回顾会议（对当前迭代周期做一个总结）。补充：敏捷软件开发宣言个体和互动 高于 流程和工具工作的软件 高于 详尽的文档客户合作 高于 合同谈判响应变化 高于 遵循计划角色：产品所有者（决定做什么，能对需求拍板的人）、团队负责人（解决各种问题，专注如何更好的工作，屏蔽外部对开发团队的影响）、开发团队（项目执行人员，具体指开发人员和测试人员）。准备工作：商业案例和资金、合同、憧憬、初始产品需求、初始发布计划、入股、组建团队。敏捷团队通常人数为8-10人。工作量估算：将开发任务量化，包括原型、Logo设计、UI设计、前端开发等，尽量把每个工作分解到最小任务量，最小任务量标准为工作时间不能超过两天，然后估算总体项目时间。把每个任务都贴在看板上面，看板上分三部分：to do（待完成）、in progress（进行中）和done（已完成）。项目团队组建团队的构成和角色说明：谢谢付祥英女士帮助我绘制了下面这张精美的公司组织架构图。编程规范和代码审查（flake8、pylint）Python中的一些“惯例”（请参考《Python惯例-如何编写Pythonic的代码》）影响代码可读性的原因：代码注释太少或者没有注释代码破坏了语言的最佳实践反模式编程（意大利面代码、复制-黏贴编程、自负编程、……）团队开发工具介绍版本控制：Git、Mercury缺陷管理：Gitlab、Redmine敏捷闭环工具：禅道、JIRA持续集成：Jenkins、Travis-CI请参考《团队项目开发的问题和解决方案》。项目选题和理解业务选题范围设定CMS（用户端）：新闻聚合网站、问答/分享社区、影评/书评网站等。MIS（用户端+管理端）：KMS、KPI考核系统、HRS、CRM系统、供应链系统、仓储管理系统等。App后台（管理端+数据接口）：二手交易类、报刊杂志类、小众电商类、新闻资讯类、旅游类、社交类、阅读类等。其他类型：自身行业背景和工作经验、业务容易理解和把控。需求理解、模块划分和任务分配需求理解：头脑风暴和竞品分析。模块划分：画思维导图（XMind），每个模块是一个枝节点，每个具体的功能是一个叶节点（用动词表述），需要确保每个叶节点无法再生出新节点，确定每个叶子节点的重要性、优先级和工作量。任务分配：由项目负责人根据上面的指标为每个团队成员分配任务。制定项目进度表（每日更新）模块功能人员状态完成工时计划开始实际开始计划结束实际结束备注评论添加评论王大锤正在进行50%42018/8/72018/8/7删除评论王大锤等待0%22018/8/72018/8/7查看评论白元芳正在进行20%42018/8/72018/8/7需要进行代码审查评论投票白元芳等待0%42018/8/82018/8/8OOAD和数据库设计UML（统一建模语言）的类图通过模型创建表（正向工程），例如在Django项目中可以通过下面的命令创建二维表。python manage.py makemigrations apppython manage.py migrate使用PowerDesigner绘制物理模型图。通过数据表创建模型（反向工程），例如在Django项目中可以通过下面的命令生成模型。python manage.py inspectdb > app/models.py第92天：Docker容器详解Docker简介安装Docker使用Docker创建容器（Nginx、MySQL、Redis、Gitlab、Jenkins）构建Docker镜像（Dockerfile的编写和相关指令）容器编排（Docker-compose）集群管理（Kubernetes）第93天：MySQL性能优化第94天：网络API接口设计第95天：[使用Django开发商业项目](./Day91-100/95.使用Django开发商业项\t目.md)项目开发中的公共问题数据库的配置（多数据库、主从复制、数据库路由）缓存的配置（分区缓存、键设置、超时设置、主从复制、故障恢复（哨兵））日志的配置分析和调试（Django-Debug-ToolBar）好用的Python模块（日期计算、图像处理、数据加密、三方API）REST API设计RESTful架构理解RESTful架构RESTful API设计指南RESTful API最佳实践API接口文档的撰写RAP2YAPIdjango-REST-framework的应用项目中的重点难点剖析使用缓存缓解数据库压力 - Redis使用消息队列做解耦合和削峰 - Celery + RabbitMQ第96天：软件测试和自动化测试单元测试测试的种类编写单元测试（unittest、pytest、nose2、tox、ddt、……）测试覆盖率（coverage）Django项目部署部署前的准备工作关键设置（SECRET_KEY / DEBUG / ALLOWED_HOSTS / 缓存 / 数据库）HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECURE日志相关配置Linux常用命令回顾Linux常用服务的安装和配置uWSGI/Gunicorn和Nginx的使用Gunicorn和uWSGI的比较对于不需要大量定制化的简单应用程序，Gunicorn是一个不错的选择，uWSGI的学习曲线比Gunicorn要陡峭得多，Gunicorn的默认参数就已经能够适应大多数应用程序。uWSGI支持异构部署。由于Nginx本身支持uWSGI，在线上一般都将Nginx和uWSGI捆绑在一起部署，而且uWSGI属于功能齐全且高度定制的WSGI中间件。在性能上，Gunicorn和uWSGI其实表现相当。使用虚拟化技术（Docker）部署测试环境和生产环境性能测试AB的使用SQLslap的使用sysbench的使用自动化测试使用Shell和Python进行自动化测试使用Selenium实现自动化测试Selenium IDESelenium WebDriverSelenium Remote Control测试工具Robot Framework介绍第97天：电商网站技术要点剖析第98天：项目部署上线和性能调优MySQL数据库调优Web服务器性能优化Nginx负载均衡配置Keepalived实现高可用代码性能调优多线程异步化静态资源访问优化云存储CDN第99天：面试中的公共问题第100天：Python面试题实录"
1,Significant-Gravitas/Auto-GPT,https://github.com/Significant-Gravitas/Auto-GPT/blob/master/README.md,Python,"Auto-GPT: An Autonomous GPT-4 Experiment💡 Get help - Q&A or Discord 💬🔴 USE stable not master 🔴Download the latest stable release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.The master branch is under heavy development and may often be in a broken state.Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \""thoughts\"", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI. Demo April 16th 2023               AutoGPTDemo_Subs_WithoutFinalScreen.mp4          Demo made by Blake Werlinger🚀 Features🌐 Internet access for searches and information gathering💾 Long-term and short-term memory management🧠 GPT-4 instances for text generation🔗 Access to popular websites and platforms🗃️ File storage and summarization with GPT-3.5🔌 Extensibility with PluginsQuickstartCheck out the wikiGet an OpenAI API KeyDownload the latest releaseFollow the installation instructionsConfigure any additional features you want, or install some pluginsRun the appPlease see the documentation for full setup instructions and configuration options.📖 Documentation⚙️ Setup💻 Usage🔌 PluginsConfiguration🔍 Web Search🧠 Memory🗣️ Voice (TTS)🖼️ Image Generation 💖 Help Fund Auto-GPT's Development 💖If you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help to push the boundaries of fully autonomous AI!Your support is greatly appreciated. Development of this free, open-source project is made possible by all the contributors and sponsors. If you'd like to sponsor this project and have your avatar or company logo appear below click here.                                                                                                                                                                                                                                                                                                                                          ⚠️ LimitationsThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:Not a polished application or product, just an experimentMay not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!Quite expensive to run, so set and monitor your API key limits with OpenAI!🛡 DisclaimerThis project, Auto-GPT, is an experimental application and is provided \""as-is\"" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.The developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.Please note that the use of the GPT-4 language model can be expensive due to its token usage. By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.As an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.By using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.🐦 Connect with Us on TwitterStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.Developer: Follow @siggravitas for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!        "
2,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
3,pallets/flask,https://github.com/pallets/flask/blob/main/README.rst,Python,"FlaskFlask is a lightweight WSGI web application framework. It is designedto make getting started quick and easy, with the ability to scale up tocomplex applications. It began as a simple wrapper around Werkzeugand Jinja and has become one of the most popular Python webapplication frameworks.Flask offers suggestions, but doesn't enforce any dependencies orproject layout. It is up to the developer to choose the tools andlibraries they want to use. There are many extensions provided by thecommunity that make adding new functionality easy.InstallingInstall and update using pip:$ pip install -U FlaskA Simple Example# save this as app.pyfrom flask import Flaskapp = Flask(__name__)@app.route(\""/\"")def hello():    return \""Hello, World!\""$ flask run  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)ContributingFor guidance on setting up a development environment and how to make acontribution to Flask, see the contributing guidelines.DonateThe Pallets organization develops and supports Flask and the librariesit uses. In order to grow the community of contributors and users, andallow the maintainers to devote more time to the projects, pleasedonate today.LinksDocumentation: https://flask.palletsprojects.com/Changes: https://flask.palletsprojects.com/changes/PyPI Releases: https://pypi.org/project/Flask/Source Code: https://github.com/pallets/flask/Issue Tracker: https://github.com/pallets/flask/issues/Chat: https://discord.gg/pallets"
4,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.⚠️ IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!⚠️ IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means you’ve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the project’s direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a project’s website for a “team” page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participants’ behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, “How do I…“ or “What do you think about…“ instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
5,apachecn/ailearning,https://github.com/apachecn/ailearning/blob/master/README.md,Python,"                                AI learning协议：CC BY-NC-SA 4.0一种新技术一旦开始流行，你要么坐上压路机，要么成为铺路石。——Stewart Brand在线阅读在线阅读（v1）QuantLearningApacheCN 中文翻译组 713436582ApacheCN 学习资源注: 广告位合作(物美价廉)，请联系 apachecn@163.com路线图入门只看: 步骤 1 => 2 => 3，你可以当大牛！中级补充 - 资料库: https://github.com/apachecn/ai-roadmap补充算法刷题: https://www.ixigua.com/pseries/6822642486343631363/面试求职: https://www.ixigua.com/pseries/6822563009391493636/机器学习实战: https://www.ixigua.com/pseries/6822816341615968772/NLP教学视频: https://www.ixigua.com/pseries/6828241431295951373/AI常用函数说明: https://github.com/apachecn/AiLearning/tree/master/AI常用函数说明.md1.机器学习 - 基础支持版本VersionSupported3.6.x❌2.7.x✅注意事项:机器学习实战: 仅仅只是学习，请使用 python 2.7.x 版本 （3.6.x 只是修改了部分）基本介绍资料来源: Machine Learning in Action(机器学习实战-个人笔记)统一数据地址: https://github.com/apachecn/data百度云打包地址: apachecn/data#3书籍下载地址: https://github.com/apachecn/data/tree/master/book机器学习下载地址: https://github.com/apachecn/data/tree/master/机器学习深度学习数据地址: https://github.com/apachecn/data/tree/master/深度学习推荐系统数据地址: https://github.com/apachecn/data/tree/master/推荐系统视频网站: 优酷 ／bilibili / Acfun / 网易云课堂，可直接在线播放。（最下方有相应链接）-- 推荐 红色石头: 台湾大学林轩田机器学习笔记-- 推荐 机器学习笔记: https://feisky.xyz/machine-learning学习文档模块章节类型负责人(GitHub)QQ机器学习实战第 1 章: 机器学习基础介绍@毛红动1306014226机器学习实战第 2 章: KNN 近邻算法分类@尤永江279393323机器学习实战第 3 章: 决策树分类@景涛844300439机器学习实战第 4 章: 朴素贝叶斯分类@wnma3mz@分析1003324213244970749机器学习实战第 5 章: Logistic回归分类@微光同尘529925688机器学习实战第 6 章: SVM 支持向量机分类@王德红934969547网上组合内容第 7 章: 集成方法（随机森林和 AdaBoost）分类@片刻529815144机器学习实战第 8 章: 回归回归@微光同尘529925688机器学习实战第 9 章: 树回归回归@微光同尘529925688机器学习实战第 10 章: K-Means 聚类聚类@徐昭清827106588机器学习实战第 11 章: 利用 Apriori 算法进行关联分析频繁项集@刘海飞1049498972机器学习实战第 12 章: FP-growth 高效发现频繁项集频繁项集@程威842725815机器学习实战第 13 章: 利用 PCA 来简化数据工具@廖立娟835670618机器学习实战第 14 章: 利用 SVD 来简化数据工具@张俊皓714974242机器学习实战第 15 章: 大数据与 MapReduce工具@wnma3mz1003324213Ml项目实战第 16 章: 推荐系统（已迁移）项目推荐系统（迁移后地址）第一期的总结2017-04-08: 第一期的总结总结总结529815144网站视频知乎问答-爆炸啦-机器学习该怎么入门？当然我知道，第一句就会被吐槽，因为科班出身的人，不屑的吐了一口唾沫，说傻X，还评论 Andrew Ng 的视频。。我还知道还有一部分人，看 Andrew Ng 的视频就是看不懂，那神秘的数学推导，那迷之微笑的英文版的教学，我何尝又不是这样走过来的？？ 我的心可能比你们都痛，因为我在网上收藏过上10部《机器学习》相关视频，外加国内本土风格的教程: 7月+小象 等等，我都很难去听懂，直到有一天，被一个百度的高级算法分析师推荐说: 《机器学习实战》还不错，通俗易懂，你去试试？？我试了试，还好我的Python基础和调试能力还不错，基本上代码都调试过一遍，很多高大上的 \""理论+推导\""，在我眼中变成了几个 \""加减乘除+循环\""，我想这不就是像我这样的程序员想要的入门教程么？很多程序员说机器学习 TM 太难学了，是的，真 TM 难学，我想最难的是: 没有一本像《机器学习实战》那样的作者愿意以程序员 Coding 角度去给大家讲解！！最近几天，GitHub 涨了 300颗 star，加群的200人， 现在还在不断的增加++，我想大家可能都是感同身受吧！很多想入门新手就是被忽悠着收藏收藏再收藏，但是最后还是什么都没有学到，也就是\""资源收藏家\""，也许新手要的就是 MachineLearning(机器学习) 学习路线图。没错，我可以给你们的一份，因为我们还通过视频记录下来我们的学习过程。水平当然也有限，不过对于新手入门，绝对没问题，如果你还不会，那算我输！！视频怎么看？理论科班出身-建议去学习 Andrew Ng 的视频（Ng 的视频绝对是权威，这个毋庸置疑）编码能力强 - 建议看我们的《机器学习实战-教学版》编码能力弱 - 建议看我们的《机器学习实战-讨论版》，不过在看理论的时候，看 教学版-理论部分；讨论版的废话太多，不过在讲解代码的时候是一行一行讲解的；所以，根据自己的需求，自由的组合。【免费】数学教学视频 - 可汗学院 入门篇@于振梓 推荐: 可汗学院-网易公开课概率统计线性代数可汗学院(概率)可汗学院(统计学)可汗学院(线性代数)机器学习视频 - ApacheCN 教学版AcFunB站优酷网易云课堂【免费】机器/深度学习视频 - 吴恩达机器学习深度学习吴恩达机器学习神经网络和深度学习2.深度学习支持版本VersionSupported3.6.x✅2.7.x❌入门基础反向传递: https://www.cnblogs.com/charlotte77/p/5629865.htmlCNN原理: http://www.cnblogs.com/charlotte77/p/7759802.htmlRNN原理: https://blog.csdn.net/qq_39422642/article/details/78676567LSTM原理: https://blog.csdn.net/weixin_42111770/article/details/80900575Pytorch - 教程-- 待更新TensorFlow 2.0 - 教程-- 待更新目录结构:安装指南Keras 快速入门实战项目 1 电影情感分类实战项目 2 汽车燃油效率实战项目 3 优化 过拟合和欠拟合实战项目 4 古诗词自动生成切分（分词）词性标注命名实体识别句法分析WordNet可以被看作是一个同义词词典词干提取（stemming）与词形还原（lemmatization）https://www.biaodianfu.com/nltk.html/ampTensorFlow 2.0学习网址https://github.com/lyhue1991/eat_tensorflow2_in_30_days3.自然语言处理支持版本VersionSupported3.6.x✅2.7.x❌学习过程中-内心复杂的变化！！！自从学习NLP以后，才发现国内与国外的典型区别:1. 对资源的态度是完全相反的:  1) 国内: 就好像为了名气，举办工作装逼的会议，就是没有干货，全部都是象征性的PPT介绍，不是针对在做的各位  2）国外: 就好像是为了推动nlp进步一样，分享者各种干货资料和具体的实现。（特别是: python自然语言处理）2. 论文的实现:   1) 各种高大上的论文实现，却还是没看到一个像样的GitHub项目！（可能我的搜索能力差了点，一直没找到）  2）国外就不举例了，我看不懂！3. 开源的框架  1）国外的开源框架:  tensorflow/pytorch 文档+教程+视频（官方提供）  2) 国内的开源框架: 额额，还真举例不出来！但是牛逼吹得不比国外差！（MXNet虽然有众多国人参与开发，但不能算是国内开源框架。基于MXNet的动手学深度学习(http://zh.d2l.ai & https://discuss.gluon.ai/t/topic/753)中文教程,已经由沐神(李沐)以及阿斯顿·张讲授录制，公开发布(文档+第一季教程+视频）。)每一次深入都要去翻墙，每一次深入都要Google，每一次看着国内的说: 哈工大、讯飞、中科大、百度、阿里多牛逼，但是资料还是得国外去找！有时候真的挺恨的！真的有点瞧不起自己国内的技术环境！当然谢谢国内很多博客大佬，特别是一些入门的Demo和基本概念。【深入的水平有限，没看懂】【入门须知】必须了解: https://github.com/apachecn/AiLearning/tree/master/nlp【入门教程】强烈推荐: PyTorch 自然语言处理: https://github.com/apachecn/NLP-with-PyTorchPython 自然语言处理 第二版: https://usyiyi.github.io/nlp-py-2e-zh推荐一个liuhuanyong大佬整理的nlp全面知识体系: https://liuhuanyong.github.io开源 - 词向量库集合:https://www.cnblogs.com/Darwin2000/p/5786984.htmlhttps://ai.tencent.com/ailab/nlp/embedding.htmlhttps://blog.csdn.net/xiezj007/article/details/85073890https://github.com/Embedding/Chinese-Word-Vectorshttps://github.com/brightmart/nlp_chinese_corpushttps://github.com/codemayq/chinese_chatbot_corpushttps://github.com/candlewill/Dialog_Corpus1.使用场景 （百度公开课）第一部分 入门介绍1.) 自然语言处理入门介绍第二部分 机器翻译2.) 机器翻译第三部分 篇章分析3.1.) 篇章分析-内容概述3.2.) 篇章分析-内容标签3.3.) 篇章分析-情感分析3.4.) 篇章分析-自动摘要第四部分 UNIT-语言理解与交互技术4.) UNIT-语言理解与交互技术应用领域中文分词:构建DAG图动态规划查找，综合正反向（正向加权反向输出）求得DAG最大概率路径使用了SBME语料训练了一套 HMM + Viterbi 模型，解决未登录词问题1.文本分类（Text Classification）文本分类是指标记句子或文档，例如电子邮件垃圾邮件分类和情感分析。下面是一些很好的初学者文本分类数据集。路透社Newswire主题分类（路透社-21578）。1987年路透社出现的一系列新闻文件，按类别编制索引。另见RCV1，RCV2和TRC2。IMDB电影评论情感分类（斯坦福）。来自网站imdb.com的一系列电影评论及其积极或消极的情绪。新闻组电影评论情感分类（康奈尔）。来自网站imdb.com的一系列电影评论及其积极或消极的情绪。有关更多信息，请参阅帖子:单标签文本分类的数据集。情感分析比赛地址: https://www.kaggle.com/c/word2vec-nlp-tutorial方案一(0.86): WordCount + 朴素 Bayes方案二(0.94): LDA + 分类模型（knn/决策树/逻辑回归/svm/xgboost/随机森林）a) 决策树效果不是很好，这种连续特征不太适合的b) 通过参数调整 200 个topic，信息量保存效果较优（计算主题）方案三(0.72): word2vec + CNN说实话: 没有一个好的机器，是调不出来一个好的结果 (: 逃通过AUC 来评估模型的效果2.语言模型（Language Modeling）语言建模涉及开发一种统计模型，用于预测句子中的下一个单词或一个单词中的下一个单词。它是语音识别和机器翻译等任务中的前置任务。它是语音识别和机器翻译等任务中的前置任务。下面是一些很好的初学者语言建模数据集。古腾堡项目，一系列免费书籍，可以用纯文本检索各种语言。还有更多正式的语料库得到了很好的研究; 例如:布朗大学现代美国英语标准语料库。大量英语单词样本。谷歌10亿字语料库。新词发现中文分词新词发现python3利用互信息和左右信息熵的中文分词新词发现https://github.com/zhanzecheng/Chinese_segment_augment句子相似度识别项目地址: https://www.kaggle.com/c/quora-question-pairs解决方案: word2vec + Bi-GRU文本纠错bi-gram + levenshtein3.图像字幕（Image Captioning）mage字幕是为给定图像生成文本描述的任务。下面是一些很好的初学者图像字幕数据集。上下文中的公共对象（COCO）。包含超过12万张带描述的图像的集合Flickr 8K。从flickr.com获取的8千个描述图像的集合。Flickr 30K。从flickr.com获取的3万个描述图像的集合。欲了解更多，请看帖子:探索图像字幕数据集，2016年4.机器翻译（Machine Translation）机器翻译是将文本从一种语言翻译成另一种语言的任务。下面是一些很好的初学者机器翻译数据集。加拿大第36届议会的协调国会议员。成对的英语和法语句子。欧洲议会诉讼平行语料库1996-2011。句子对一套欧洲语言。有大量标准数据集用于年度机器翻译挑战; 看到:统计机器翻译机器翻译Encoder + Decoder(Attention)参考案例: http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html5.问答系统（Question Answering）问答是一项任务，其中提供了一个句子或文本样本，从中提出问题并且必须回答问题。下面是一些很好的初学者问题回答数据集。斯坦福问题回答数据集（SQuAD）。回答有关维基百科文章的问题。Deepmind问题回答语料库。从每日邮报回答有关新闻文章的问题。亚马逊问答数据。回答有关亚马逊产品的问题。有关更多信息，请参阅帖子:数据集: 我如何获得问答网站的语料库，如Quora或Yahoo Answers或Stack Overflow来分析答案质量？6.语音识别（Speech Recognition）语音识别是将口语的音频转换为人类可读文本的任务。下面是一些很好的初学者语音识别数据集。TIMIT声学 - 语音连续语音语料库。不是免费的，但因其广泛使用而上市。口语美国英语和相关的转录。VoxForge。用于构建用于语音识别的开源数据库的项目。LibriSpeech ASR语料库。从LibriVox收集的大量英语有声读物。7.自动文摘（Document Summarization）文档摘要是创建较大文档的简短有意义描述的任务。下面是一些很好的初学者文档摘要数据集。法律案例报告数据集。收集了4000份法律案件及其摘要。TIPSTER文本摘要评估会议语料库。收集了近200份文件及其摘要。英语新闻文本的AQUAINT语料库。不是免费的，而是广泛使用的。新闻文章的语料库。欲了解更多信息:文档理解会议（DUC）任务。在哪里可以找到用于文本摘要的良好数据集？命名实体识别Bi-LSTM CRF参考案例: http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.htmlCRF推荐文档: https://www.jianshu.com/p/55755fc649b1文本摘要抽取式word2vec + textrankword2vec推荐文档: https://www.zhihu.com/question/44832436/answer/266068967textrank推荐文档: https://blog.csdn.net/BaiHuaXiu123/article/details/77847232Graph图计算【慢慢更新】数据集: https://github.com/apachecn/data/tree/master/graph学习资料: spark graphX实战.pdf 【文件太大不方便提供，自己百度】知识图谱知识图谱，我只认 SimmerChan: 【知识图谱-给AI装个大脑】说实话，我是看这博主老哥写的博客长大的，写的真的是深入浅出。我很喜欢，所以就分享给大家，希望你们也喜欢。进一步阅读如果您希望更深入，本节提供了其他数据集列表。维基百科研究中使用的文本数据集数据集: 计算语言学家和自然语言处理研究人员使用的主要文本语料库是什么？斯坦福统计自然语言处理语料库按字母顺序排列的NLP数据集列表该机构NLTK在DL4J上打开深度学习数据NLP数据集国内开放数据集: https://bosonnlp.com/dev/resource参考比赛收集平台pbharrin/machinelearninginactionML Mastery致谢最近无意收到群友推送的链接，发现得到大佬高度的认可，并在热心的推广。在此感谢:量子位人工智能前沿讲习赞助我们"
6,hankcs/HanLP,https://github.com/hankcs/HanLP/blob/master/README.md,Python,"HanLP: Han Language Processing                                                                                   中文 |    日本語 |    Docs |    ForumThe multilingual NLP library for researchers and companies, built on PyTorch and TensorFlow 2.x, for advancingstate-of-the-art deep learning techniques in both academia and industry. HanLP was designed from day one to beefficient, user-friendly and extendable.Thanks to open-access corpora like Universal Dependencies and OntoNotes, HanLP 2.1 now offers 10 joint tasks on 130languages: tokenization, lemmatization, part-of-speech tagging, token feature extraction, dependency parsing,constituency parsing, semantic role labeling, semantic dependency parsing, abstract meaning representation (AMR)parsing.For end users, HanLP offers light-weighted RESTful APIs and native Python APIs.RESTful APIsTiny packages in several KBs for agile development and mobile applications. Although anonymous users are welcomed, anauth key is suggestedand a free one can be applied here underthe CC BY-NC-SA 4.0 license.  Click to expand tutorials for RESTful APIsPythonpip install hanlp_restfulCreate a client with our API endpoint and your auth.from hanlp_restful import HanLPClientHanLP = HanLPClient('https://hanlp.hankcs.com/api', auth=None, language='mul') # mul: multilingual, zh: ChineseJavaInsert the following dependency into your pom.xml.<dependency>  <groupId>com.hankcs.hanlp.restful</groupId>  <artifactId>hanlp-restful</artifactId>  <version>0.0.15</version></dependency>Create a client with our API endpoint and your auth.HanLPClient HanLP = new HanLPClient(\""https://hanlp.hankcs.com/api\"", null, \""mul\""); // mul: multilingual, zh: ChineseQuick StartNo matter which language you use, the same interface can be used to parse a document.HanLP.parse(    \""In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments. 2021年、HanLPv2.1は次世代の最先端多言語NLP技術を本番環境に導入します。2021年 HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。\"")See docs for visualization, annotation guidelines and more details.Native APIspip install hanlpHanLP requires Python 3.6 or later. GPU/TPU is suggested but not mandatory.Quick Startimport hanlpHanLP = hanlp.load(hanlp.pretrained.mtl.UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_XLMR_BASE)print(HanLP(['In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments.',             '2021年、HanLPv2.1は次世代の最先端多言語NLP技術を本番環境に導入します。',             '2021年 HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。']))In particular, the Python HanLPClient can also be used as a callable function following the same semantics.See docs for visualization, annotation guidelines and more details.To process Chinese or Japanese, HanLP provides mono-lingual models in each language which significantly outperform themulti-lingual model. See docs for the list of models.Train Your Own ModelsTo write DL models is not hard, the real hard thing is to write a model able to reproduce the scores in papers. Thesnippet below shows how to surpass the state-of-the-art tokenizer in 6 minutes.tokenizer = TransformerTaggingTokenizer()save_dir = 'data/model/cws/sighan2005_pku_bert_base_96.7'tokenizer.fit(    SIGHAN2005_PKU_TRAIN_ALL,    SIGHAN2005_PKU_TEST,  # Conventionally, no devset is used. See Tian et al. (2020).    save_dir,    'bert-base-chinese',    max_seq_len=300,    char_level=True,    hard_constraint=True,    sampler_builder=SortingSamplerBuilder(batch_size=32),    epochs=3,    adam_epsilon=1e-6,    warmup_steps=0.1,    weight_decay=0.01,    word_dropout=0.1,    seed=1660853059,)tokenizer.evaluate(SIGHAN2005_PKU_TEST, save_dir)The result is guaranteed to be 96.73 as the random seed is fixed. Different from some overclaiming papers andprojects, HanLP promises every single digit in our scores is reproducible. Any issues on reproducibility will be treatedand solved as a top-priority fatal bug.PerformanceThe performance of multi-task learning models is shown in the following table.langcorporamodeltokposnerdepconsrlsdplemfeaamrfinecoarsectbpku863udpkumsraontonotesSemEval16DMPASPSDmulUD2.7OntoNotes5small98.62----93.23--74.4279.1076.8570.63-91.1993.6785.3487.7184.51-base98.97----90.32--80.3278.7471.2373.63-92.6096.0481.1985.0882.13-zhopensmall97.25-96.66-----95.0084.5787.6273.4084.57------base97.50-97.07-----96.0487.1189.8477.7887.11------closesmall96.7095.9396.8797.5695.05-96.2295.7476.7984.4488.1375.8174.28------base97.5296.4496.9997.5995.29-96.4895.7277.7785.2988.5776.5273.76------ernie96.9597.2996.7697.6495.22-97.3196.4777.9585.6789.1778.5174.10------Multi-task learning models often under-perform their single-task learning counterparts according to our latestresearch. Similarly, mono-lingual models often outperform multi-lingual models. Therefore, we strongly recommend theuse of a single-task mono-lingual model if you aretargeting at high accuracy instead of faster speed.A state-of-the-art AMR model has been released.CitingIf you use HanLP in your research, please cite this repository.@inproceedings{he-choi-2021-stem,    title = \""The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders\"",    author = \""He, Han and Choi, Jinho D.\"",    booktitle = \""Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\"",    month = nov,    year = \""2021\"",    address = \""Online and Punta Cana, Dominican Republic\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://aclanthology.org/2021.emnlp-main.451\"",    pages = \""5555--5577\"",    abstract = \""Multi-task learning with transformer encoders (MTL) has emerged as a powerful technique to improve performance on closely-related tasks for both accuracy and efficiency while a question still remains whether or not it would perform as well on tasks that are distinct in nature. We first present MTL results on five NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over single-task learning. We then conduct an extensive pruning analysis to show that a certain set of attention heads get claimed by most tasks during MTL, who interfere with one another to fine-tune those heads for their own objectives. Based on this finding, we propose the Stem Cell Hypothesis to reveal the existence of attention heads naturally talented for many tasks that cannot be jointly trained to create adequate embeddings for all of those tasks. Finally, we design novel parameter-free probes to justify our hypothesis and demonstrate how attention heads are transformed across the five tasks during MTL through label analysis.\"",}LicenseCodesHanLP is licensed under Apache License 2.0. You can use HanLP in your commercial products for free. We wouldappreciate it if you add a link to HanLP on your website.ModelsUnless otherwise specified, all models in HanLP are licensedunder  CC BY-NC-SA 4.0.Referenceshttps://hanlp.hankcs.com/docs/references.html"
7,vagabond-systems/jpmc-task-1,https://github.com/vagabond-systems/jpmc-task-1/blob/main/README.md,Python,JPMC Task 1Starter repo for task 1 of the JPMC software engineering program
8,langchain-ai/langchain,https://github.com/langchain-ai/langchain/blob/master/README.md,Python,"🦜️🔗 LangChain⚡ Building applications with LLMs through composability ⚡Looking for the JS/TS version? Check out LangChain.js.Production Support: As you move your LangChains into production, we'd love to offer more hands-on support.Fill out this form to share more about what you're building, and our team will get in touch.🚨Breaking Changes for select chains (SQLDatabase) on 7/28/23In an effort to make langchain leaner and safer, we are moving select chains to langchain_experimental.This migration has already started, but we are remaining backwards compatible until 7/28.On that date, we will remove functionality from langchain.Read more about the motivation and the progress here.Read how to migrate your code here.Quick Installpip install langchainorpip install langsmith && conda install langchain -c conda-forge🤔 What is this?Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. However, using these LLMs in isolation is often insufficient for creating a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.This library aims to assist in the development of those types of applications. Common examples of these applications include:❓ Question Answering over specific documentsDocumentationEnd-to-end Example: Question Answering over Notion Database💬 ChatbotsDocumentationEnd-to-end Example: Chat-LangChain🤖 AgentsDocumentationEnd-to-end Example: GPT+WolframAlpha📖 DocumentationPlease see here for full documentation on:Getting started (installation, setting up the environment, simple examples)How-To examples (demos, integrations, helper functions)Reference (full API docs)Resources (high-level explanation of core concepts)🚀 What can this help with?There are six main areas that LangChain is designed to help with.These are, in increasing order of complexity:📃 LLMs and Prompts:This includes prompt management, prompt optimization, a generic interface for all LLMs, and common utilities for working with LLMs.🔗 Chains:Chains go beyond a single LLM call and involve sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.📚 Data Augmented Generation:Data Augmented Generation involves specific types of chains that first interact with an external data source to fetch data for use in the generation step. Examples include summarization of long pieces of text and question/answering over specific data sources.🤖 Agents:Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end-to-end agents.🧠 Memory:Memory refers to persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.🧐 Evaluation:[BETA] Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this.For more information on these concepts, please see our full documentation.💁 ContributingAs an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.For detailed information on how to contribute, see here."
9,XX-net/XX-Net,https://github.com/XX-net/XX-Net/blob/master/README.md,Python,"🚀 XX-Net (翻墙VPN)这是一个可靠的翻墙系统，已经连续运行 8 年！我们不去研究墙有什么缺陷，因为所有的缺陷都会被慢慢的补上。我们的策略是化身为普通流量，完全无法区分，最终隐身在茫茫的网络连接中。。。🔌 功能特性支持多平台： Android/iOS/Windows/Mac/Linux采用独特的混淆算法，让您的流量在网络中无法被识别开源绿色软件，无需安装，可以支持多台设备同时连接模拟Chrome浏览器行为，完全无法识别，稳定翻墙内置 ChatGPT，每个套餐赠送 ChatGPT-3.5 一百万token官网下载: https://xx-net.comTelegram: https://t.me/xxnetshareTwitter: https://twitter.com/XXNetDev中文帮助文档      English Document      فارسی صفحه اصلی最新公告：2023-08-15新版 5.5.0, 提升连接性能5.1.0，内置ChatGPT原来是4.x.x 老版本的，需要重新下载新版安装，不能应用内升级。提示：有问题请先看Wiki文档提问 前，请先看最近讨论主题 ，避免重复发问。"
10,jackfrued/Python-100-Days,https://github.com/jackfrued/Python-100-Days/blob/master/README.md,Python,"Python - 100天从新手到大师作者：骆昊说明：从项目上线到获得8w+星标以来，一直收到反馈说基础部分（前15天的内容）对新手来说是比较困难的，建议有配套视频进行讲解。最近把基础部分的内容重新制作了一个名为“Python-Core-50-Courses”的项目，用更为简单通俗的方式重写了这部分内容并附带了视频讲解，初学者可以关注下这个新项目。如果需要Python基础视频，可以在“B站”搜索《Python零基础快速上手》，这套视频是我讲课的时候录制的随堂视频，画质尚可、音质一般，但是对初学者应该会有些帮助，欢迎大家留言、评论、发弹幕。学习之后觉得有收获的小伙伴可以“一键三连”来支持UP主（千锋Python）。国内用户如果访问GitHub比较慢的话，可以关注我的知乎号Python-Jack，上面的“从零开始学Python”专栏比较适合初学者，其他的专栏也在持续创作和更新中，欢迎大家关注并点赞评论。创作不易，感谢大家的打赏支持，这些钱不会用于个人消费（例如：购买咖啡），而是通过腾讯公益、美团公益、水滴筹等平台捐赠给需要帮助的人（点击了解捐赠情况）。需要加入QQ学习群的可以扫描下面的二维码，三个群加一个即可，不要重复进群。学习群会为大家提供学习资源和问题解答，如果有Python体验课和行业公开课会提前在群里通知大家，欢迎大家加入。项目“Day80~90”部分目前仍在创作中，因为作者平时也挤不出太多时间来写文档，因此更新的速度比较缓慢，感谢大家的理解。Python应用领域和职业发展分析简单的说，Python是一个“优雅”、“明确”、“简单”的编程语言。学习曲线低，非专业人士也能上手开源系统，拥有强大的生态圈解释型语言，完美的平台可移植性动态类型语言，支持面向对象和函数式编程代码规范程度高，可读性强Python在以下领域都有用武之地。后端开发 - Python / Java / Go / PHPDevOps - Python / Shell / Ruby数据采集 - Python / C++ / Java量化交易 - Python / C++ / R数据科学 - Python / R / Julia / Matlab机器学习 - Python / R / C++ / Julia自动化测试 - Python / Shell作为一名Python开发者，根据个人的喜好和职业规划，可以选择的就业领域也非常多。Python后端开发工程师（服务器、云平台、数据接口）Python运维工程师（自动化运维、SRE、DevOps）Python数据分析师（数据分析、商业智能、数字化运营）Python数据挖掘工程师（机器学习、深度学习、算法专家）Python爬虫工程师Python测试工程师（自动化测试、测试开发）说明：目前，数据分析和数据挖掘是非常热门的方向，因为不管是互联网行业还是传统行业都已经积累了大量的数据，各行各业都需要数据分析师从已有的数据中发现更多的商业价值，从而为企业的决策提供数据的支撑，这就是所谓的数据驱动决策。给初学者的几个建议：Make English as your working language. （让英语成为你的工作语言）Practice makes perfect. （熟能生巧）All experience comes from mistakes. （所有的经验都源于你犯过的错误）Don't be one of the leeches. （不要当伸手党）Either outstanding or out. （要么出众，要么出局）Day01~15 - Python语言基础Day01 - 初识PythonPython简介 - Python的历史 / Python的优缺点 / Python的应用领域搭建编程环境 - Windows环境 / Linux环境 / MacOS环境从终端运行Python程序 - Hello, world / print函数 / 运行程序使用IDLE - 交互式环境(REPL) / 编写多行代码 / 运行程序 / 退出IDLE注释 - 注释的作用 / 单行注释 / 多行注释Day02 - 语言元素程序和进制 - 指令和程序 / 冯诺依曼机 / 二进制和十进制 / 八进制和十六进制变量和类型 - 变量的命名 / 变量的使用 / input函数 / 检查变量类型 / 类型转换数字和字符串 - 整数 / 浮点数 / 复数 / 字符串 / 字符串基本操作 / 字符编码运算符 - 数学运算符 / 赋值运算符 / 比较运算符 / 逻辑运算符 / 身份运算符 / 运算符的优先级应用案例 - 华氏温度转换成摄氏温度 / 输入圆的半径计算周长和面积 / 输入年份判断是否是闰年Day03 - 分支结构分支结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图if语句 - 简单的if / if-else结构 / if-elif-else结构 / 嵌套的if应用案例 - 用户身份验证 / 英制单位与公制单位互换 / 掷骰子决定做什么 / 百分制成绩转等级制 / 分段函数求值 / 输入三条边的长度如果能构成三角形就计算周长和面积Day04 - 循环结构循环结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图while循环 - 基本结构 / break语句 / continue语句for循环 - 基本结构 / range类型 / 循环中的分支结构 / 嵌套的循环 / 提前结束程序应用案例 - 1~100求和 / 判断素数 / 猜数字游戏 / 打印九九表 / 打印三角形图案 / 猴子吃桃 / 百钱百鸡Day05 - 构造程序逻辑经典案例：水仙花数 / 百钱百鸡 / Craps赌博游戏练习题目：斐波那契数列 / 完美数 / 素数Day06 - 函数和模块的使用函数的作用 - 代码的坏味道 / 用函数封装功能模块定义函数 - def关键字 / 函数名 / 参数列表 / return语句 / 调用自定义函数调用函数 - Python内置函数 /  导入模块和函数函数的参数 - 默认参数 / 可变参数 / 关键字参数 / 命名关键字参数函数的返回值 - 没有返回值  / 返回单个值 / 返回多个值作用域问题 - 局部作用域 / 嵌套作用域 / 全局作用域 / 内置作用域 / 和作用域相关的关键字用模块管理函数 - 模块的概念 / 用自定义模块管理函数 / 命名冲突的时候会怎样（同一个模块和不同的模块）Day07 - 字符串和常用数据结构字符串的使用 - 计算长度 / 下标运算 / 切片 / 常用方法列表基本用法 - 定义列表 / 用下表访问元素 / 下标越界 / 添加元素 / 删除元素 / 修改元素 / 切片 / 循环遍历列表常用操作 - 连接 / 复制(复制元素和复制数组) / 长度 / 排序 / 倒转 / 查找生成列表 - 使用range创建数字列表 / 生成表达式 / 生成器元组的使用 - 定义元组 / 使用元组中的值 / 修改元组变量 / 元组和列表转换集合基本用法 - 集合和列表的区别 /  创建集合 / 添加元素 / 删除元素 /  清空集合常用操作 - 交集 / 并集 / 差集 / 对称差 / 子集 / 超集字典的基本用法 - 字典的特点 / 创建字典 / 添加元素 / 删除元素 / 取值 / 清空字典常用操作 - keys方法 / values方法 / items方法 / setdefault方法基础练习 - 跑马灯效果 / 列表找最大元素 / 统计考试成绩的平均分 / Fibonacci数列 / 杨辉三角综合案例 - 双色球选号 / 井字棋Day08 - 面向对象编程基础类和对象 - 什么是类 / 什么是对象 / 面向对象其他相关概念定义类 - 基本结构 / 属性和方法 / 构造器 / 析构器 / __str__方法使用对象 - 创建对象 / 给对象发消息面向对象的四大支柱 - 抽象 / 封装 / 继承 / 多态基础练习 - 定义学生类 / 定义时钟类 / 定义图形类 / 定义汽车类Day09 - 面向对象进阶属性 - 类属性 / 实例属性 / 属性访问器 / 属性修改器 / 属性删除器 / 使用__slots__类中的方法 - 实例方法 / 类方法 / 静态方法运算符重载 - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__类(的对象)之间的关系 - 关联 / 继承 / 依赖继承和多态 - 什么是继承 / 继承的语法 / 调用父类方法 / 方法重写 / 类型判定 / 多重继承 / 菱形继承(钻石继承)和C3算法综合案例 - 工资结算系统 / 图书自动折扣系统 / 自定义分数类Day10 - 图形用户界面和游戏开发使用tkinter开发GUI程序使用pygame三方库开发游戏应用“大球吃小球”游戏Day11 - 文件和异常读文件 - 读取整个文件 / 逐行读取 / 文件路径写文件 - 覆盖写入 / 追加写入 / 文本文件 / 二进制文件异常处理 - 异常机制的重要性 / try-except代码块 / else代码块 / finally代码块 / 内置异常类型 / 异常栈 / raise语句数据持久化 - CSV文件概述 / csv模块的应用 / JSON数据格式 / json模块的应用Day12 - 字符串和正则表达式字符串高级操作 - 转义字符 / 原始字符串 / 多行字符串 / in和not in运算符 / is_xxx方法 / join和split方法 / strip相关方法 / pyperclip模块 / 不变字符串和可变字符串 / StringIO的使用正则表达式入门 - 正则表达式的作用 / 元字符 / 转义 / 量词 / 分组 / 零宽断言 /贪婪匹配与惰性匹配懒惰 / 使用re模块实现正则表达式操作（匹配、搜索、替换、捕获）使用正则表达式 - re模块 / compile函数 / group和groups方法 / match方法 / search方法 / findall和finditer方法 / sub和subn方法 / split方法应用案例 - 使用正则表达式验证输入的字符串Day13 - 进程和线程进程和线程的概念 - 什么是进程 / 什么是线程 / 多线程的应用场景使用进程 - fork函数 / multiprocessing模块 / 进程池 / 进程间通信使用线程 -  threading模块 / Thread类 / RLock类 / Condition类 / 线程池Day14 - 网络编程入门和网络应用开发计算机网络基础 - 计算机网络发展史 / “TCP-IP”模型 / IP地址 / 端口 / 协议 / 其他相关概念网络应用模式 - “客户端-服务器”模式 / “浏览器-服务器”模式基于HTTP协议访问网络资源 - 网络API概述 / 访问URL / requests三方库 / 解析JSON格式数据Python网络编程 - 套接字的概念 / socket模块 /  socket函数 / 创建TCP服务器 / 创建TCP客户端 / 创建UDP服务器 / 创建UDP客户端电子邮件 - SMTP协议 / POP3协议 / IMAP协议 / smtplib模块 / poplib模块 / imaplib模块短信服务 - 调用短信服务网关Day15 - 图像和文档处理用Pillow处理图片 - 图片读写 / 图片合成 / 几何变换 / 色彩转换 / 滤镜效果读写Word文档 - 文本内容的处理 / 段落 / 页眉和页脚 / 样式的处理读写Excel文件 - xlrd / xlwt / openpyxlDay16~Day20 - Python语言进阶 常用数据结构函数的高级用法 - “一等公民” / 高阶函数 / Lambda函数 / 作用域和闭包 / 装饰器面向对象高级知识 - “三大支柱” / 类与类之间的关系 / 垃圾回收 / 魔术属性和方法 / 混入 / 元类 / 面向对象设计原则 / GoF设计模式迭代器和生成器 - 相关魔术方法 / 创建生成器的两种方式 /并发和异步编程 - 多线程 / 多进程 / 异步IO / async和awaitDay21~30 - Web前端入门用HTML标签承载页面内容用CSS渲染页面用JavaScript处理交互式行为jQuery入门和提高Vue.js入门Element的使用Bootstrap的使用Day31~35 - 玩转Linux操作系统操作系统发展史和Linux概述Linux基础命令Linux中的实用程序Linux的文件系统Vim编辑器的应用环境变量和Shell编程软件的安装和服务的配置网络访问和管理其他相关内容Day36~40 - 数据库基础和进阶关系型数据库概述MySQL的安装和使用SQL的使用DDL - 数据定义语言 - create / drop / alterDML - 数据操作语言 - insert / delete / updateDQL - 数据查询语言 - selectDCL - 数据控制语言 - grant / revokeMySQL新特性窗口函数的应用JSON数据类型相关知识数据完整性和一致性视图、函数、过程、触发器事务和锁执行计划和索引范式理论和反范式设计在Python中操作MySQLDay41~55 - 实战DjangoDay41 - Django快速上手Web应用工作机制HTTP请求和响应Django框架概述5分钟快速上手Day42 - 深入模型关系型数据库配置使用ORM完成对模型的CRUD操作管理后台的使用Django模型最佳实践模型定义参考Day43 - 静态资源和Ajax请求加载静态资源Ajax概述用Ajax实现投票功能Day44 - Cookie和Session实现用户跟踪cookie和session的关系Django框架对session的支持视图函数中的cookie读写操作Day45 - 报表和日志通过HttpResponse修改响应头使用StreamingHttpResponse处理大文件使用xlwt生成Excel报表使用reportlab生成PDF报表使用ECharts生成前端图表Day46 - 日志和调试工具栏配置日志配置Django-Debug-Toolbar优化ORM代码Day47 - 中间件的应用什么是中间件Django框架内置的中间件自定义中间件及其应用场景Day48 - 前后端分离开发入门返回JSON格式的数据用Vue.js渲染页面Day49 - RESTful架构和DRF入门Day50 - RESTful架构和DRF进阶Day51 - 使用缓存网站优化第一定律在Django项目中使用Redis提供缓存服务在视图函数中读写缓存使用装饰器实现页面缓存为数据接口提供缓存服务Day52 - 接入三方平台文件上传表单控件和图片文件预览服务器端如何处理上传的文件Day53 - 异步任务和定时任务网站优化第二定律配置消息队列服务在项目中使用Celery实现任务异步化在项目中使用Celery实现定时任务Day54 - 单元测试Day55 - 项目上线Python中的单元测试Django框架对单元测试的支持使用版本控制系统配置和使用uWSGI动静分离和Nginx配置配置HTTPS配置域名解析Day56~60 - 用FastAPI开发数据接口FastAPI五分钟上手请求和响应接入关系型数据库依赖注入中间件异步化虚拟化部署（Docker）项目实战：车辆违章查询项目Day61~65 - 爬虫开发Day61 - 网络数据采集概述网络爬虫的概念及其应用领域网络爬虫的合法性探讨开发网络爬虫的相关工具一个爬虫程序的构成Day62 - 数据抓取和解析使用requests三方库实现数据抓取页面解析的三种方式正则表达式解析XPath解析CSS选择器解析Day63 - Python中的并发编程多线程多进程异步I/ODay64 - 使用Selenium抓取网页动态内容Day65 - 爬虫框架Scrapy简介Day66~80 - 数据分析Day66 - 数据分析概述Day67 - 环境准备Day68 - NumPy的应用-1Day69 - NumPy的应用-2Day70 - Pandas的应用-1Day71 - Pandas的应用-2Day72 - Pandas的应用-3Day73 - Pandas的应用-4Day74 - Pandas的应用-5Day75 - 数据可视化-1Day76 - 数据可视化-2Day77 - 概率统计基础Day78 - 方差分析和参数估计Day79 - 相关和回归Day80 - 数据分析方法论Day81~90 - 机器学习和深度学习Day81 - 机器学习基础Day82 - k最近邻分类Day83 - 决策树Day84 - 贝叶斯分类Day85 - 支持向量机Day86 - K-均值聚类Day87 - 回归分析Day88 - 深度学习入门Day89 - PyTorch概述Day90 - PyTorch实战Day91~100 - 团队项目开发第91天：团队项目开发的问题和解决方案软件过程模型经典过程模型（瀑布模型）可行性分析（研究做还是不做），输出《可行性分析报告》。需求分析（研究做什么），输出《需求规格说明书》和产品界面原型图。概要设计和详细设计，输出概念模型图（ER图）、物理模型图、类图、时序图等。编码 / 测试。上线 / 维护。瀑布模型最大的缺点是无法拥抱需求变化，整套流程结束后才能看到产品，团队士气低落。敏捷开发（Scrum）- 产品所有者、Scrum Master、研发人员 - Sprint产品的Backlog（用户故事、产品原型）。计划会议（评估和预算）。日常开发（站立会议、番茄工作法、结对编程、测试先行、代码重构……）。修复bug（问题描述、重现步骤、测试人员、被指派人）。发布版本。评审会议（Showcase，用户需要参与）。回顾会议（对当前迭代周期做一个总结）。补充：敏捷软件开发宣言个体和互动 高于 流程和工具工作的软件 高于 详尽的文档客户合作 高于 合同谈判响应变化 高于 遵循计划角色：产品所有者（决定做什么，能对需求拍板的人）、团队负责人（解决各种问题，专注如何更好的工作，屏蔽外部对开发团队的影响）、开发团队（项目执行人员，具体指开发人员和测试人员）。准备工作：商业案例和资金、合同、憧憬、初始产品需求、初始发布计划、入股、组建团队。敏捷团队通常人数为8-10人。工作量估算：将开发任务量化，包括原型、Logo设计、UI设计、前端开发等，尽量把每个工作分解到最小任务量，最小任务量标准为工作时间不能超过两天，然后估算总体项目时间。把每个任务都贴在看板上面，看板上分三部分：to do（待完成）、in progress（进行中）和done（已完成）。项目团队组建团队的构成和角色说明：谢谢付祥英女士帮助我绘制了下面这张精美的公司组织架构图。编程规范和代码审查（flake8、pylint）Python中的一些“惯例”（请参考《Python惯例-如何编写Pythonic的代码》）影响代码可读性的原因：代码注释太少或者没有注释代码破坏了语言的最佳实践反模式编程（意大利面代码、复制-黏贴编程、自负编程、……）团队开发工具介绍版本控制：Git、Mercury缺陷管理：Gitlab、Redmine敏捷闭环工具：禅道、JIRA持续集成：Jenkins、Travis-CI请参考《团队项目开发的问题和解决方案》。项目选题和理解业务选题范围设定CMS（用户端）：新闻聚合网站、问答/分享社区、影评/书评网站等。MIS（用户端+管理端）：KMS、KPI考核系统、HRS、CRM系统、供应链系统、仓储管理系统等。App后台（管理端+数据接口）：二手交易类、报刊杂志类、小众电商类、新闻资讯类、旅游类、社交类、阅读类等。其他类型：自身行业背景和工作经验、业务容易理解和把控。需求理解、模块划分和任务分配需求理解：头脑风暴和竞品分析。模块划分：画思维导图（XMind），每个模块是一个枝节点，每个具体的功能是一个叶节点（用动词表述），需要确保每个叶节点无法再生出新节点，确定每个叶子节点的重要性、优先级和工作量。任务分配：由项目负责人根据上面的指标为每个团队成员分配任务。制定项目进度表（每日更新）模块功能人员状态完成工时计划开始实际开始计划结束实际结束备注评论添加评论王大锤正在进行50%42018/8/72018/8/7删除评论王大锤等待0%22018/8/72018/8/7查看评论白元芳正在进行20%42018/8/72018/8/7需要进行代码审查评论投票白元芳等待0%42018/8/82018/8/8OOAD和数据库设计UML（统一建模语言）的类图通过模型创建表（正向工程），例如在Django项目中可以通过下面的命令创建二维表。python manage.py makemigrations apppython manage.py migrate使用PowerDesigner绘制物理模型图。通过数据表创建模型（反向工程），例如在Django项目中可以通过下面的命令生成模型。python manage.py inspectdb > app/models.py第92天：Docker容器详解Docker简介安装Docker使用Docker创建容器（Nginx、MySQL、Redis、Gitlab、Jenkins）构建Docker镜像（Dockerfile的编写和相关指令）容器编排（Docker-compose）集群管理（Kubernetes）第93天：MySQL性能优化第94天：网络API接口设计第95天：[使用Django开发商业项目](./Day91-100/95.使用Django开发商业项\t目.md)项目开发中的公共问题数据库的配置（多数据库、主从复制、数据库路由）缓存的配置（分区缓存、键设置、超时设置、主从复制、故障恢复（哨兵））日志的配置分析和调试（Django-Debug-ToolBar）好用的Python模块（日期计算、图像处理、数据加密、三方API）REST API设计RESTful架构理解RESTful架构RESTful API设计指南RESTful API最佳实践API接口文档的撰写RAP2YAPIdjango-REST-framework的应用项目中的重点难点剖析使用缓存缓解数据库压力 - Redis使用消息队列做解耦合和削峰 - Celery + RabbitMQ第96天：软件测试和自动化测试单元测试测试的种类编写单元测试（unittest、pytest、nose2、tox、ddt、……）测试覆盖率（coverage）Django项目部署部署前的准备工作关键设置（SECRET_KEY / DEBUG / ALLOWED_HOSTS / 缓存 / 数据库）HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECURE日志相关配置Linux常用命令回顾Linux常用服务的安装和配置uWSGI/Gunicorn和Nginx的使用Gunicorn和uWSGI的比较对于不需要大量定制化的简单应用程序，Gunicorn是一个不错的选择，uWSGI的学习曲线比Gunicorn要陡峭得多，Gunicorn的默认参数就已经能够适应大多数应用程序。uWSGI支持异构部署。由于Nginx本身支持uWSGI，在线上一般都将Nginx和uWSGI捆绑在一起部署，而且uWSGI属于功能齐全且高度定制的WSGI中间件。在性能上，Gunicorn和uWSGI其实表现相当。使用虚拟化技术（Docker）部署测试环境和生产环境性能测试AB的使用SQLslap的使用sysbench的使用自动化测试使用Shell和Python进行自动化测试使用Selenium实现自动化测试Selenium IDESelenium WebDriverSelenium Remote Control测试工具Robot Framework介绍第97天：电商网站技术要点剖析第98天：项目部署上线和性能调优MySQL数据库调优Web服务器性能优化Nginx负载均衡配置Keepalived实现高可用代码性能调优多线程异步化静态资源访问优化云存储CDN第99天：面试中的公共问题第100天：Python面试题实录"
11,google/it-cert-automation-practice,https://github.com/google/it-cert-automation-practice/blob/master/README.md,Python,Google IT Automation with Python Professional Certificate - Practice filesThis repository contains the practice files used throughout the courses that arepart of the Google IT Automation with Python Professional CertificateThere's a separate folder for each course.
12,Significant-Gravitas/Auto-GPT,https://github.com/Significant-Gravitas/Auto-GPT/blob/master/README.md,Python,"Auto-GPT: An Autonomous GPT-4 Experiment💡 Get help - Q&A or Discord 💬🔴 USE stable not master 🔴Download the latest stable release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.The master branch is under heavy development and may often be in a broken state.Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \""thoughts\"", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI. Demo April 16th 2023               AutoGPTDemo_Subs_WithoutFinalScreen.mp4          Demo made by Blake Werlinger🚀 Features🌐 Internet access for searches and information gathering💾 Long-term and short-term memory management🧠 GPT-4 instances for text generation🔗 Access to popular websites and platforms🗃️ File storage and summarization with GPT-3.5🔌 Extensibility with PluginsQuickstartCheck out the wikiGet an OpenAI API KeyDownload the latest releaseFollow the installation instructionsConfigure any additional features you want, or install some pluginsRun the appPlease see the documentation for full setup instructions and configuration options.📖 Documentation⚙️ Setup💻 Usage🔌 PluginsConfiguration🔍 Web Search🧠 Memory🗣️ Voice (TTS)🖼️ Image Generation 💖 Help Fund Auto-GPT's Development 💖If you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help to push the boundaries of fully autonomous AI!Your support is greatly appreciated. Development of this free, open-source project is made possible by all the contributors and sponsors. If you'd like to sponsor this project and have your avatar or company logo appear below click here.                                                                                                                                                                                                                                                                                                                                          ⚠️ LimitationsThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:Not a polished application or product, just an experimentMay not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!Quite expensive to run, so set and monitor your API key limits with OpenAI!🛡 DisclaimerThis project, Auto-GPT, is an experimental application and is provided \""as-is\"" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.The developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.Please note that the use of the GPT-4 language model can be expensive due to its token usage. By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.As an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.By using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.🐦 Connect with Us on TwitterStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.Developer: Follow @siggravitas for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!        "
13,keras-team/keras,https://github.com/keras-team/keras/blob/master/README.md,Python,"Keras: Deep Learning for humansThis repository hosts the development of the Keras library.Read the documentation at keras.io.About KerasKeras is a deep learning API written in Python,running on top of the machine learning platform TensorFlow.It was developed with a focus on enabling fast experimentation andproviding a delightful developer experience.The purpose of Keras is to give an unfair advantage to any developer looking to ship ML-powered apps.Keras is:Simple -- but not simplistic. Keras reduces developer cognitive loadto free you to focus on the parts of the problem that really matter.Keras focuses on ease of use, debugging speed, code elegance & conciseness,maintainability, and deployability (via TFServing, TFLite, TF.js).Flexible -- Keras adopts the principle of progressive disclosure ofcomplexity: simple workflows should be quick and easy, while arbitrarilyadvanced workflows should be possible via a clear path that builds uponwhat you've already learned.Powerful -- Keras provides industry-strength performance andscalability: it is used by organizations and companies including NASA,YouTube, and Waymo. That's right -- your YouTube recommendations arepowered by Keras, and so is the world's most advanced driverless vehicle.Keras & TensorFlow 2TensorFlow 2 is an end-to-end, open-source machine learning platform.You can think of it as an infrastructure layer fordifferentiable programming.It combines four key abilities:Efficiently executing low-level tensor operations on CPU, GPU, or TPU.Computing the gradient of arbitrary differentiable expressions.Scaling computation to many devices, such as clusters of hundreds of GPUs.Exporting programs (\""graphs\"") to external runtimes such as servers, browsers, mobile and embedded devices.Keras is the high-level API of TensorFlow 2: an approachable, highly-productive interfacefor solving machine learning problems,with a focus on modern deep learning. It provides essential abstractions and building blocks for developingand shipping machine learning solutions with high iteration velocity.Keras empowers engineers and researchers to take full advantage of the scalabilityand cross-platform capabilities of TensorFlow 2: you can run Keras on TPU or on large clusters of GPUs,and you can export your Keras models to run in the browser or on a mobile device.First contact with KerasThe core data structures of Keras are layers and models.The simplest type of model is the Sequential model, a linear stack of layers.For more complex architectures, you should use the Keras functional API,which allows you to build arbitrary graphs of layers or write models entirely from scratch via subclassing.Here is the Sequential model:from tensorflow.keras.models import Sequentialmodel = Sequential()Stacking layers is as easy as .add():from tensorflow.keras.layers import Densemodel.add(Dense(units=64, activation='relu'))model.add(Dense(units=10, activation='softmax'))Once your model looks good, configure its learning process with .compile():model.compile(loss='categorical_crossentropy',              optimizer='sgd',              metrics=['accuracy'])If you need to, you can further configure your optimizer. The Keras philosophy is to keep simple things simple,while allowing the user to be fully in control when they need to be (the ultimate control being the easy extensibility of the source code via subclassing).model.compile(loss=tf.keras.losses.categorical_crossentropy,              optimizer=tf.keras.optimizers.SGD(                  learning_rate=0.01, momentum=0.9, nesterov=True))You can now iterate on your training data in batches:# x_train and y_train are Numpy arrays.model.fit(x_train, y_train, epochs=5, batch_size=32)Evaluate your test loss and metrics in one line:loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)Or generate predictions on new data:classes = model.predict(x_test, batch_size=128)What you just saw is the most elementary way to use Keras.However, Keras is also a highly-flexible framework suitable to iterate on state-of-the-art research ideas.Keras follows the principle of progressive disclosure of complexity: it makes it easy to get started,yet it makes it possible to handle arbitrarily advanced use cases,only requiring incremental learning at each step.In pretty much the same way that you were able to train & evaluate a simple neural network above in a few lines,you can use Keras to quickly develop new training procedures or exotic model architectures.Here's a low-level training loop example, combining Keras functionality with the TensorFlow GradientTape:import tensorflow as tf# Prepare an optimizer.optimizer = tf.keras.optimizers.Adam()# Prepare a loss function.loss_fn = tf.keras.losses.kl_divergence# Iterate over the batches of a dataset.for inputs, targets in dataset:    # Open a GradientTape.    with tf.GradientTape() as tape:        # Forward pass.        predictions = model(inputs)        # Compute the loss value for this batch.        loss_value = loss_fn(targets, predictions)    # Get gradients of loss wrt the weights.    gradients = tape.gradient(loss_value, model.trainable_weights)    # Update the weights of the model.    optimizer.apply_gradients(zip(gradients, model.trainable_weights))For more in-depth tutorials about Keras, you can check out:Introduction to Keras for engineersIntroduction to Keras for researchersDeveloper guidesOther learning resourcesInstallationKeras comes packaged with TensorFlow 2 as tensorflow.keras.To start using Keras, simply install TensorFlow 2.You can then import Keras as follows:from tensorflow import kerasRelease and compatibilityKeras has nightly releases (keras-nightly on PyPI)and stable releases (keras on PyPI).The nightly Keras releases are usually compatible with the corresponding versionof the tf-nightly releases(e.g. keras-nightly==2.7.0.dev2021100607 should beused with tf-nightly==2.7.0.dev2021100607).We don't maintain backward compatibility for nightly releases.For stable releases, each Kerasversion maps to a specific stable version of TensorFlow.The table below shows the compatibility version mappingbetween TensorFlow versions and Keras versions.All the release branches can be found on GitHub.All the release binaries can be found on Pypi.SupportYou can ask questions and join the development discussion:In the TensorFlow forum.On the Keras mailing list.Opening an issueYou can also post bug reports and feature requests (only)in GitHub issues.Opening a PRWe welcome contributions! Before opening a PR, please readour contributor guide,and the API design guideline."
14,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
15,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.⚠️ IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!⚠️ IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means you’ve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the project’s direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a project’s website for a “team” page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participants’ behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, “How do I…“ or “What do you think about…“ instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
16,open-mmlab/mmdetection,https://github.com/open-mmlab/mmdetection/blob/main/README.md,Python,"           OpenMMLab website                  HOT                      OpenMMLab platform                  TRY IT OUT               📘Documentation |🛠️Installation |👀Model Zoo |🆕Update News |🚀Ongoing Projects |🤔Reporting IssuesEnglish | 简体中文                                              IntroductionMMDetection is an open source object detection toolbox based on PyTorch. It isa part of the OpenMMLab project.The main branch works with PyTorch 1.8+.Major featuresModular DesignWe decompose the detection framework into different components and one can easily construct a customized object detection framework by combining different modules.Support of multiple tasks out of boxThe toolbox directly supports multiple detection tasks such as object detection, instance segmentation, panoptic segmentation, and semi-supervised object detection.High efficiencyAll basic bbox and mask operations run on GPUs. The training speed is faster than or comparable to other codebases, including Detectron2, maskrcnn-benchmark and SimpleDet.State of the artThe toolbox stems from the codebase developed by the MMDet team, who won COCO Detection Challenge in 2018, and we keep pushing it forward.The newly released RTMDet also obtains new state-of-the-art results on real-time instance segmentation and rotated object detection tasks and the best parameter-accuracy trade-off on object detection.Apart from MMDetection, we also released MMEngine for model training and MMCV for computer vision research, which are heavily depended on by this toolbox.What's NewHighlightWe are excited to announce our latest work on real-time object recognition tasks, RTMDet, a family of fully convolutional single-stage detectors. RTMDet not only achieves the best parameter-accuracy trade-off on object detection from tiny to extra-large model sizes but also obtains new state-of-the-art performance on instance segmentation and rotated object detection tasks. Details can be found in the technical report. Pre-trained models are here.TaskDatasetAPFPS(TRT FP16 BS1 3090)Object DetectionCOCO52.8322Instance SegmentationCOCO44.6188Rotated Object DetectionDOTA78.9(single-scale)/81.3(multi-scale)121v3.1.0 was released in 30/6/2023:Supports tracking algorithms including multi-object tracking (MOT) algorithms SORT, DeepSORT, StrongSORT, OCSORT, ByteTrack, QDTrack, and video instance segmentation (VIS) algorithm MaskTrackRCNN, Mask2Former-VIS.Support ViTDetSupports inference and evaluation of multimodal algorithms GLIP and XDecoder, and also supports datasets such as COCO semantic segmentation, COCO Caption, ADE20k general segmentation, and RefCOCO. GLIP fine-tuning will be supported in the future.Provides a gradio demo for image type tasks of MMDetection, making it easy for users to experience.InstallationPlease refer to Installation for installation instructions.Getting StartedPlease see Overview for the general introduction of MMDetection.For detailed user guides and advanced guides, please refer to our documentation:User GuidesTrain & TestLearn about ConfigsInference with existing modelsDataset PrepareTest existing models on standard datasetsTrain predefined models on standard datasetsTrain with customized datasetsTrain with customized models and standard datasetsFinetuning ModelsTest Results SubmissionWeight initializationUse a single stage detector as RPNSemi-supervised Object DetectionUseful ToolsAdvanced GuidesBasic ConceptsComponent CustomizationHow toWe also provide object detection colab tutorial  and instance segmentation colab tutorial .To migrate from MMDetection 2.x, please refer to migration.Overview of Benchmark and Model ZooResults and models are available in the model zoo.  Architectures                    Object Detection                    Instance Segmentation                    Panoptic Segmentation                    Other                                        Fast R-CNN (ICCV'2015)            Faster R-CNN (NeurIPS'2015)            RPN (NeurIPS'2015)            SSD (ECCV'2016)            RetinaNet (ICCV'2017)            Cascade R-CNN (CVPR'2018)            YOLOv3 (ArXiv'2018)            CornerNet (ECCV'2018)            Grid R-CNN (CVPR'2019)            Guided Anchoring (CVPR'2019)            FSAF (CVPR'2019)            CenterNet (CVPR'2019)            Libra R-CNN (CVPR'2019)            TridentNet (ICCV'2019)            FCOS (ICCV'2019)            RepPoints (ICCV'2019)            FreeAnchor (NeurIPS'2019)            CascadeRPN (NeurIPS'2019)            Foveabox (TIP'2020)            Double-Head R-CNN (CVPR'2020)            ATSS (CVPR'2020)            NAS-FCOS (CVPR'2020)            CentripetalNet (CVPR'2020)            AutoAssign (ArXiv'2020)            Side-Aware Boundary Localization (ECCV'2020)            Dynamic R-CNN (ECCV'2020)            DETR (ECCV'2020)            PAA (ECCV'2020)            VarifocalNet (CVPR'2021)            Sparse R-CNN (CVPR'2021)            YOLOF (CVPR'2021)            YOLOX (CVPR'2021)            Deformable DETR (ICLR'2021)            TOOD (ICCV'2021)            DDOD (ACM MM'2021)            RTMDet (ArXiv'2022)            Conditional DETR (ICCV'2021)            DAB-DETR (ICLR'2022)            DINO (ICLR'2023)            GLIP (CVPR'2022)            DiffusionDet (ArXiv'2023)            EfficientDet (CVPR'2020)            Detic (ECCV'2022)                                    Mask R-CNN (ICCV'2017)          Cascade Mask R-CNN (CVPR'2018)          Mask Scoring R-CNN (CVPR'2019)          Hybrid Task Cascade (CVPR'2019)          YOLACT (ICCV'2019)          InstaBoost (ICCV'2019)          SOLO (ECCV'2020)          PointRend (CVPR'2020)          DetectoRS (ArXiv'2020)          SOLOv2 (NeurIPS'2020)          SCNet (AAAI'2021)          QueryInst (ICCV'2021)          Mask2Former (ArXiv'2021)          CondInst (ECCV'2020)          SparseInst (CVPR'2022)          RTMDet (ArXiv'2022)          BoxInst (CVPR'2021)                                      Panoptic FPN (CVPR'2019)          MaskFormer (NeurIPS'2021)          Mask2Former (ArXiv'2021)                                      Contrastive Learning                          SwAV (NeurIPS'2020)          MoCo (CVPR'2020)          MoCov2 (ArXiv'2020)                                  Distillation                          Localization Distillation (CVPR'2022)          Label Assignment Distillation (WACV'2022)                          Semi-Supervised Object Detection                          Soft Teacher (ICCV'2021)                                        Components                    Backbones                    Necks                    Loss                    Common                                  VGG (ICLR'2015)        ResNet (CVPR'2016)        ResNeXt (CVPR'2017)        MobileNetV2 (CVPR'2018)        HRNet (CVPR'2019)        Generalized Attention (ICCV'2019)        GCNet (ICCVW'2019)        Res2Net (TPAMI'2020)        RegNet (CVPR'2020)        ResNeSt (ArXiv'2020)        PVT (ICCV'2021)        Swin (CVPR'2021)        PVTv2 (ArXiv'2021)        ResNet strikes back (ArXiv'2021)        EfficientNet (ArXiv'2021)        ConvNeXt (CVPR'2022)        ConvNeXtv2 (ArXiv'2023)                                PAFPN (CVPR'2018)        NAS-FPN (CVPR'2019)        CARAFE (ICCV'2019)        FPG (ArXiv'2020)        GRoIE (ICPR'2020)        DyHead (CVPR'2021)                                    GHM (AAAI'2019)          Generalized Focal Loss (NeurIPS'2020)          Seasaw Loss (CVPR'2021)                                      OHEM (CVPR'2016)          Group Normalization (ECCV'2018)          DCN (ICCV'2017)          DCNv2 (CVPR'2019)          Weight Standardization (ArXiv'2019)          Prime Sample Attention (CVPR'2020)          Strong Baselines (CVPR'2021)          Resnet strikes back (ArXiv'2021)                        Some other methods are also supported in projects using MMDetection.FAQPlease refer to FAQ for frequently asked questions.ContributingWe appreciate all contributions to improve MMDetection. Ongoing projects can be found in out GitHub Projects. Welcome community users to participate in these projects. Please refer to CONTRIBUTING.md for the contributing guideline.AcknowledgementMMDetection is an open source project that is contributed by researchers and engineers from various colleges and companies. We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks.We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new detectors.CitationIf you use this toolbox or benchmark in your research, please cite this project.@article{mmdetection,  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},  journal= {arXiv preprint arXiv:1906.07155},  year={2019}}LicenseThis project is released under the Apache 2.0 license.Projects in OpenMMLabMMEngine: OpenMMLab foundational library for training deep learning models.MMCV: OpenMMLab foundational library for computer vision.MMPreTrain: OpenMMLab pre-training toolbox and benchmark.MMagic: OpenMMLab Advanced, Generative and Intelligent Creation toolbox.MMDetection: OpenMMLab detection toolbox and benchmark.MMDetection3D: OpenMMLab's next-generation platform for general 3D object detection.MMRotate: OpenMMLab rotated object detection toolbox and benchmark.MMYOLO: OpenMMLab YOLO series toolbox and benchmark.MMSegmentation: OpenMMLab semantic segmentation toolbox and benchmark.MMOCR: OpenMMLab text detection, recognition, and understanding toolbox.MMPose: OpenMMLab pose estimation toolbox and benchmark.MMHuman3D: OpenMMLab 3D human parametric model toolbox and benchmark.MMSelfSup: OpenMMLab self-supervised learning toolbox and benchmark.MMRazor: OpenMMLab model compression toolbox and benchmark.MMFewShot: OpenMMLab fewshot learning toolbox and benchmark.MMAction2: OpenMMLab's next-generation action understanding toolbox and benchmark.MMTracking: OpenMMLab video perception toolbox and benchmark.MMFlow: OpenMMLab optical flow toolbox and benchmark.MMEditing: OpenMMLab image and video editing toolbox.MMGeneration: OpenMMLab image and video generative models toolbox.MMDeploy: OpenMMLab model deployment framework.MIM: MIM installs OpenMMLab packages.MMEval: A unified evaluation library for multiple machine learning libraries.Playground: A central hub for gathering and showcasing amazing projects built upon OpenMMLab."
17,hankcs/HanLP,https://github.com/hankcs/HanLP/blob/master/README.md,Python,"HanLP: Han Language Processing                                                                                   中文 |    日本語 |    Docs |    ForumThe multilingual NLP library for researchers and companies, built on PyTorch and TensorFlow 2.x, for advancingstate-of-the-art deep learning techniques in both academia and industry. HanLP was designed from day one to beefficient, user-friendly and extendable.Thanks to open-access corpora like Universal Dependencies and OntoNotes, HanLP 2.1 now offers 10 joint tasks on 130languages: tokenization, lemmatization, part-of-speech tagging, token feature extraction, dependency parsing,constituency parsing, semantic role labeling, semantic dependency parsing, abstract meaning representation (AMR)parsing.For end users, HanLP offers light-weighted RESTful APIs and native Python APIs.RESTful APIsTiny packages in several KBs for agile development and mobile applications. Although anonymous users are welcomed, anauth key is suggestedand a free one can be applied here underthe CC BY-NC-SA 4.0 license.  Click to expand tutorials for RESTful APIsPythonpip install hanlp_restfulCreate a client with our API endpoint and your auth.from hanlp_restful import HanLPClientHanLP = HanLPClient('https://hanlp.hankcs.com/api', auth=None, language='mul') # mul: multilingual, zh: ChineseJavaInsert the following dependency into your pom.xml.<dependency>  <groupId>com.hankcs.hanlp.restful</groupId>  <artifactId>hanlp-restful</artifactId>  <version>0.0.15</version></dependency>Create a client with our API endpoint and your auth.HanLPClient HanLP = new HanLPClient(\""https://hanlp.hankcs.com/api\"", null, \""mul\""); // mul: multilingual, zh: ChineseQuick StartNo matter which language you use, the same interface can be used to parse a document.HanLP.parse(    \""In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments. 2021年、HanLPv2.1は次世代の最先端多言語NLP技術を本番環境に導入します。2021年 HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。\"")See docs for visualization, annotation guidelines and more details.Native APIspip install hanlpHanLP requires Python 3.6 or later. GPU/TPU is suggested but not mandatory.Quick Startimport hanlpHanLP = hanlp.load(hanlp.pretrained.mtl.UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_XLMR_BASE)print(HanLP(['In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments.',             '2021年、HanLPv2.1は次世代の最先端多言語NLP技術を本番環境に導入します。',             '2021年 HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。']))In particular, the Python HanLPClient can also be used as a callable function following the same semantics.See docs for visualization, annotation guidelines and more details.To process Chinese or Japanese, HanLP provides mono-lingual models in each language which significantly outperform themulti-lingual model. See docs for the list of models.Train Your Own ModelsTo write DL models is not hard, the real hard thing is to write a model able to reproduce the scores in papers. Thesnippet below shows how to surpass the state-of-the-art tokenizer in 6 minutes.tokenizer = TransformerTaggingTokenizer()save_dir = 'data/model/cws/sighan2005_pku_bert_base_96.7'tokenizer.fit(    SIGHAN2005_PKU_TRAIN_ALL,    SIGHAN2005_PKU_TEST,  # Conventionally, no devset is used. See Tian et al. (2020).    save_dir,    'bert-base-chinese',    max_seq_len=300,    char_level=True,    hard_constraint=True,    sampler_builder=SortingSamplerBuilder(batch_size=32),    epochs=3,    adam_epsilon=1e-6,    warmup_steps=0.1,    weight_decay=0.01,    word_dropout=0.1,    seed=1660853059,)tokenizer.evaluate(SIGHAN2005_PKU_TEST, save_dir)The result is guaranteed to be 96.73 as the random seed is fixed. Different from some overclaiming papers andprojects, HanLP promises every single digit in our scores is reproducible. Any issues on reproducibility will be treatedand solved as a top-priority fatal bug.PerformanceThe performance of multi-task learning models is shown in the following table.langcorporamodeltokposnerdepconsrlsdplemfeaamrfinecoarsectbpku863udpkumsraontonotesSemEval16DMPASPSDmulUD2.7OntoNotes5small98.62----93.23--74.4279.1076.8570.63-91.1993.6785.3487.7184.51-base98.97----90.32--80.3278.7471.2373.63-92.6096.0481.1985.0882.13-zhopensmall97.25-96.66-----95.0084.5787.6273.4084.57------base97.50-97.07-----96.0487.1189.8477.7887.11------closesmall96.7095.9396.8797.5695.05-96.2295.7476.7984.4488.1375.8174.28------base97.5296.4496.9997.5995.29-96.4895.7277.7785.2988.5776.5273.76------ernie96.9597.2996.7697.6495.22-97.3196.4777.9585.6789.1778.5174.10------Multi-task learning models often under-perform their single-task learning counterparts according to our latestresearch. Similarly, mono-lingual models often outperform multi-lingual models. Therefore, we strongly recommend theuse of a single-task mono-lingual model if you aretargeting at high accuracy instead of faster speed.A state-of-the-art AMR model has been released.CitingIf you use HanLP in your research, please cite this repository.@inproceedings{he-choi-2021-stem,    title = \""The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders\"",    author = \""He, Han and Choi, Jinho D.\"",    booktitle = \""Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\"",    month = nov,    year = \""2021\"",    address = \""Online and Punta Cana, Dominican Republic\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://aclanthology.org/2021.emnlp-main.451\"",    pages = \""5555--5577\"",    abstract = \""Multi-task learning with transformer encoders (MTL) has emerged as a powerful technique to improve performance on closely-related tasks for both accuracy and efficiency while a question still remains whether or not it would perform as well on tasks that are distinct in nature. We first present MTL results on five NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over single-task learning. We then conduct an extensive pruning analysis to show that a certain set of attention heads get claimed by most tasks during MTL, who interfere with one another to fine-tune those heads for their own objectives. Based on this finding, we propose the Stem Cell Hypothesis to reveal the existence of attention heads naturally talented for many tasks that cannot be jointly trained to create adequate embeddings for all of those tasks. Finally, we design novel parameter-free probes to justify our hypothesis and demonstrate how attention heads are transformed across the five tasks during MTL through label analysis.\"",}LicenseCodesHanLP is licensed under Apache License 2.0. You can use HanLP in your commercial products for free. We wouldappreciate it if you add a link to HanLP on your website.ModelsUnless otherwise specified, all models in HanLP are licensedunder  CC BY-NC-SA 4.0.Referenceshttps://hanlp.hankcs.com/docs/references.html"
18,XX-net/XX-Net,https://github.com/XX-net/XX-Net/blob/master/README.md,Python,"🚀 XX-Net (翻墙VPN)这是一个可靠的翻墙系统，已经连续运行 8 年！我们不去研究墙有什么缺陷，因为所有的缺陷都会被慢慢的补上。我们的策略是化身为普通流量，完全无法区分，最终隐身在茫茫的网络连接中。。。🔌 功能特性支持多平台： Android/iOS/Windows/Mac/Linux采用独特的混淆算法，让您的流量在网络中无法被识别开源绿色软件，无需安装，可以支持多台设备同时连接模拟Chrome浏览器行为，完全无法识别，稳定翻墙内置 ChatGPT，每个套餐赠送 ChatGPT-3.5 一百万token官网下载: https://xx-net.comTelegram: https://t.me/xxnetshareTwitter: https://twitter.com/XXNetDev中文帮助文档      English Document      فارسی صفحه اصلی最新公告：2023-08-15新版 5.5.0, 提升连接性能5.1.0，内置ChatGPT原来是4.x.x 老版本的，需要重新下载新版安装，不能应用内升级。提示：有问题请先看Wiki文档提问 前，请先看最近讨论主题 ，避免重复发问。"
19,floodsung/Deep-Learning-Papers-Reading-Roadmap,https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md,Python,"Deep Learning Papers Reading RoadmapIf you are a newcomer to the Deep Learning area, the first question you may have is \""Which paper should I start reading from?\""Here is a reading roadmap of Deep Learning papers!The roadmap is constructed in accordance with the following four guidelines:From outline to detailFrom old to state-of-the-artfrom generic to specific areasfocus on state-of-the-artYou will find many papers that are quite new but really worth reading.I would continue adding papers to this roadmap.1 Deep Learning History and Basics1.0 Book[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. \""Deep learning.\"" An MIT Press book. (2015). [html] (Deep Learning Bible, you can read this book while reading following papers.) ⭐⭐⭐⭐⭐1.1 Survey[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. \""Deep learning.\"" Nature 521.7553 (2015): 436-444. [pdf] (Three Giants' Survey) ⭐⭐⭐⭐⭐1.2 Deep Belief Network(DBN)(Milestone of Deep Learning Eve)[2] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. \""A fast learning algorithm for deep belief nets.\"" Neural computation 18.7 (2006): 1527-1554. [pdf](Deep Learning Eve) ⭐⭐⭐[3] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. \""Reducing the dimensionality of data with neural networks.\"" Science 313.5786 (2006): 504-507. [pdf] (Milestone, Show the promise of deep learning) ⭐⭐⭐1.3 ImageNet Evolution（Deep Learning broke out from here）[4] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \""Imagenet classification with deep convolutional neural networks.\"" Advances in neural information processing systems. 2012. [pdf] (AlexNet, Deep Learning Breakthrough) ⭐⭐⭐⭐⭐[5] Simonyan, Karen, and Andrew Zisserman. \""Very deep convolutional networks for large-scale image recognition.\"" arXiv preprint arXiv:1409.1556 (2014). [pdf] (VGGNet,Neural Networks become very deep!) ⭐⭐⭐[6] Szegedy, Christian, et al. \""Going deeper with convolutions.\"" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [pdf] (GoogLeNet) ⭐⭐⭐[7] He, Kaiming, et al. \""Deep residual learning for image recognition.\"" arXiv preprint arXiv:1512.03385 (2015). [pdf] (ResNet,Very very deep networks, CVPR best paper) ⭐⭐⭐⭐⭐1.4 Speech Recognition Evolution[8] Hinton, Geoffrey, et al. \""Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups.\"" IEEE Signal Processing Magazine 29.6 (2012): 82-97. [pdf] (Breakthrough in speech recognition)⭐⭐⭐⭐[9] Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. \""Speech recognition with deep recurrent neural networks.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (RNN)⭐⭐⭐[10] Graves, Alex, and Navdeep Jaitly. \""Towards End-To-End Speech Recognition with Recurrent Neural Networks.\"" ICML. Vol. 14. 2014. [pdf]⭐⭐⭐[11] Sak, Haşim, et al. \""Fast and accurate recurrent neural network acoustic models for speech recognition.\"" arXiv preprint arXiv:1507.06947 (2015). [pdf] (Google Speech Recognition System) ⭐⭐⭐[12] Amodei, Dario, et al. \""Deep speech 2: End-to-end speech recognition in english and mandarin.\"" arXiv preprint arXiv:1512.02595 (2015). [pdf] (Baidu Speech Recognition System) ⭐⭐⭐⭐[13] W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig \""Achieving Human Parity in Conversational Speech Recognition.\"" arXiv preprint arXiv:1610.05256 (2016). [pdf] (State-of-the-art in speech recognition, Microsoft) ⭐⭐⭐⭐After reading above papers, you will have a basic understanding of the Deep Learning history, the basic architectures of Deep Learning model(including CNN, RNN, LSTM) and how deep learning can be applied to image and speech recognition issues. The following papers will take you in-depth understanding of the Deep Learning method, Deep Learning in different areas of application and the frontiers. I suggest that you can choose the following papers based on your interests and research direction.#2 Deep Learning Method2.1 Model[14] Hinton, Geoffrey E., et al. \""Improving neural networks by preventing co-adaptation of feature detectors.\"" arXiv preprint arXiv:1207.0580 (2012). [pdf] (Dropout) ⭐⭐⭐[15] Srivastava, Nitish, et al. \""Dropout: a simple way to prevent neural networks from overfitting.\"" Journal of Machine Learning Research 15.1 (2014): 1929-1958. [pdf] ⭐⭐⭐[16] Ioffe, Sergey, and Christian Szegedy. \""Batch normalization: Accelerating deep network training by reducing internal covariate shift.\"" arXiv preprint arXiv:1502.03167 (2015). [pdf] (An outstanding Work in 2015) ⭐⭐⭐⭐[17] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \""Layer normalization.\"" arXiv preprint arXiv:1607.06450 (2016). [pdf] (Update of Batch Normalization) ⭐⭐⭐⭐[18] Courbariaux, Matthieu, et al. \""Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or−1.\"" [pdf] (New Model,Fast)  ⭐⭐⭐[19] Jaderberg, Max, et al. \""Decoupled neural interfaces using synthetic gradients.\"" arXiv preprint arXiv:1608.05343 (2016). [pdf] (Innovation of Training Method,Amazing Work) ⭐⭐⭐⭐⭐[20] Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. \""Net2net: Accelerating learning via knowledge transfer.\"" arXiv preprint arXiv:1511.05641 (2015). [pdf] (Modify previously trained network to reduce training epochs) ⭐⭐⭐[21] Wei, Tao, et al. \""Network Morphism.\"" arXiv preprint arXiv:1603.01670 (2016). [pdf] (Modify previously trained network to reduce training epochs) ⭐⭐⭐2.2 Optimization[22] Sutskever, Ilya, et al. \""On the importance of initialization and momentum in deep learning.\"" ICML (3) 28 (2013): 1139-1147. [pdf] (Momentum optimizer) ⭐⭐[23] Kingma, Diederik, and Jimmy Ba. \""Adam: A method for stochastic optimization.\"" arXiv preprint arXiv:1412.6980 (2014). [pdf] (Maybe used most often currently) ⭐⭐⭐[24] Andrychowicz, Marcin, et al. \""Learning to learn by gradient descent by gradient descent.\"" arXiv preprint arXiv:1606.04474 (2016). [pdf] (Neural Optimizer,Amazing Work) ⭐⭐⭐⭐⭐[25] Han, Song, Huizi Mao, and William J. Dally. \""Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding.\"" CoRR, abs/1510.00149 2 (2015). [pdf] (ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup) ⭐⭐⭐⭐⭐[26] Iandola, Forrest N., et al. \""SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size.\"" arXiv preprint arXiv:1602.07360 (2016). [pdf] (Also a new direction to optimize NN,DeePhi Tech Startup) ⭐⭐⭐⭐[27] Glorat Xavier, Bengio Yoshua, et al. \""Understanding the difficulty of training deep forward neural networks.\"" Proceedings of the thirteenth International Conference on Artificial Intelligence and Statistics, PMLR 9:249-256,2010. [pdf] ⭐⭐⭐⭐2.3 Unsupervised Learning / Deep Generative Model[28] Le, Quoc V. \""Building high-level features using large scale unsupervised learning.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (Milestone, Andrew Ng, Google Brain Project, Cat) ⭐⭐⭐⭐[29] Kingma, Diederik P., and Max Welling. \""Auto-encoding variational bayes.\"" arXiv preprint arXiv:1312.6114 (2013). [pdf] (VAE) ⭐⭐⭐⭐[30] Goodfellow, Ian, et al. \""Generative adversarial nets.\"" Advances in Neural Information Processing Systems. 2014. [pdf] (GAN,super cool idea) ⭐⭐⭐⭐⭐[31] Radford, Alec, Luke Metz, and Soumith Chintala. \""Unsupervised representation learning with deep convolutional generative adversarial networks.\"" arXiv preprint arXiv:1511.06434 (2015). [pdf] (DCGAN) ⭐⭐⭐⭐[32] Gregor, Karol, et al. \""DRAW: A recurrent neural network for image generation.\"" arXiv preprint arXiv:1502.04623 (2015). [pdf] (VAE with attention, outstanding work) ⭐⭐⭐⭐⭐[33] Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. \""Pixel recurrent neural networks.\"" arXiv preprint arXiv:1601.06759 (2016). [pdf] (PixelRNN) ⭐⭐⭐⭐[34] Oord, Aaron van den, et al. \""Conditional image generation with PixelCNN decoders.\"" arXiv preprint arXiv:1606.05328 (2016). [pdf] (PixelCNN) ⭐⭐⭐⭐[34] S. Mehri et al., \""SampleRNN: An Unconditional End-to-End Neural Audio Generation Model.\"" arXiv preprint \tarXiv:1612.07837 (2016). [pdf] ⭐⭐⭐⭐⭐2.4 RNN / Sequence-to-Sequence Model[35] Graves, Alex. \""Generating sequences with recurrent neural networks.\"" arXiv preprint arXiv:1308.0850 (2013). [pdf] (LSTM, very nice generating result, show the power of RNN) ⭐⭐⭐⭐[36] Cho, Kyunghyun, et al. \""Learning phrase representations using RNN encoder-decoder for statistical machine translation.\"" arXiv preprint arXiv:1406.1078 (2014). [pdf] (First Seq-to-Seq Paper) ⭐⭐⭐⭐[37] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \""Sequence to sequence learning with neural networks.\"" Advances in neural information processing systems. 2014. [pdf] (Outstanding Work) ⭐⭐⭐⭐⭐[38] Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. \""Neural Machine Translation by Jointly Learning to Align and Translate.\"" arXiv preprint arXiv:1409.0473 (2014). [pdf] ⭐⭐⭐⭐[39] Vinyals, Oriol, and Quoc Le. \""A neural conversational model.\"" arXiv preprint arXiv:1506.05869 (2015). [pdf] (Seq-to-Seq on Chatbot) ⭐⭐⭐2.5 Neural Turing Machine[40] Graves, Alex, Greg Wayne, and Ivo Danihelka. \""Neural turing machines.\"" arXiv preprint arXiv:1410.5401 (2014). [pdf] (Basic Prototype of Future Computer) ⭐⭐⭐⭐⭐[41] Zaremba, Wojciech, and Ilya Sutskever. \""Reinforcement learning neural Turing machines.\"" arXiv preprint arXiv:1505.00521 362 (2015). [pdf] ⭐⭐⭐[42] Weston, Jason, Sumit Chopra, and Antoine Bordes. \""Memory networks.\"" arXiv preprint arXiv:1410.3916 (2014). [pdf] ⭐⭐⭐[43] Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. \""End-to-end memory networks.\"" Advances in neural information processing systems. 2015. [pdf] ⭐⭐⭐⭐[44] Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. \""Pointer networks.\"" Advances in Neural Information Processing Systems. 2015. [pdf] ⭐⭐⭐⭐[45] Graves, Alex, et al. \""Hybrid computing using a neural network with dynamic external memory.\"" Nature (2016). [pdf] (Milestone,combine above papers' ideas) ⭐⭐⭐⭐⭐2.6 Deep Reinforcement Learning[46] Mnih, Volodymyr, et al. \""Playing atari with deep reinforcement learning.\"" arXiv preprint arXiv:1312.5602 (2013). [pdf]) (First Paper named deep reinforcement learning) ⭐⭐⭐⭐[47] Mnih, Volodymyr, et al. \""Human-level control through deep reinforcement learning.\"" Nature 518.7540 (2015): 529-533. [pdf] (Milestone) ⭐⭐⭐⭐⭐[48] Wang, Ziyu, Nando de Freitas, and Marc Lanctot. \""Dueling network architectures for deep reinforcement learning.\"" arXiv preprint arXiv:1511.06581 (2015). [pdf] (ICLR best paper,great idea)  ⭐⭐⭐⭐[49] Mnih, Volodymyr, et al. \""Asynchronous methods for deep reinforcement learning.\"" arXiv preprint arXiv:1602.01783 (2016). [pdf] (State-of-the-art method) ⭐⭐⭐⭐⭐[50] Lillicrap, Timothy P., et al. \""Continuous control with deep reinforcement learning.\"" arXiv preprint arXiv:1509.02971 (2015). [pdf] (DDPG) ⭐⭐⭐⭐[51] Gu, Shixiang, et al. \""Continuous Deep Q-Learning with Model-based Acceleration.\"" arXiv preprint arXiv:1603.00748 (2016). [pdf] (NAF) ⭐⭐⭐⭐[52] Schulman, John, et al. \""Trust region policy optimization.\"" CoRR, abs/1502.05477 (2015). [pdf] (TRPO) ⭐⭐⭐⭐[53] Silver, David, et al. \""Mastering the game of Go with deep neural networks and tree search.\"" Nature 529.7587 (2016): 484-489. [pdf] (AlphaGo) ⭐⭐⭐⭐⭐2.7 Deep Transfer Learning / Lifelong Learning / especially for RL[54] Bengio, Yoshua. \""Deep Learning of Representations for Unsupervised and Transfer Learning.\"" ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [pdf] (A Tutorial) ⭐⭐⭐[55] Silver, Daniel L., Qiang Yang, and Lianghao Li. \""Lifelong Machine Learning Systems: Beyond Learning Algorithms.\"" AAAI Spring Symposium: Lifelong Machine Learning. 2013. [pdf] (A brief discussion about lifelong learning)  ⭐⭐⭐[56] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \""Distilling the knowledge in a neural network.\"" arXiv preprint arXiv:1503.02531 (2015). [pdf] (Godfather's Work) ⭐⭐⭐⭐[57] Rusu, Andrei A., et al. \""Policy distillation.\"" arXiv preprint arXiv:1511.06295 (2015). [pdf] (RL domain) ⭐⭐⭐[58] Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. \""Actor-mimic: Deep multitask and transfer reinforcement learning.\"" arXiv preprint arXiv:1511.06342 (2015). [pdf] (RL domain) ⭐⭐⭐[59] Rusu, Andrei A., et al. \""Progressive neural networks.\"" arXiv preprint arXiv:1606.04671 (2016). [pdf] (Outstanding Work, A novel idea) ⭐⭐⭐⭐⭐2.8 One Shot Deep Learning[60] Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. \""Human-level concept learning through probabilistic program induction.\"" Science 350.6266 (2015): 1332-1338. [pdf] (No Deep Learning,but worth reading) ⭐⭐⭐⭐⭐[61] Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. \""Siamese Neural Networks for One-shot Image Recognition.\""(2015) [pdf] ⭐⭐⭐[62] Santoro, Adam, et al. \""One-shot Learning with Memory-Augmented Neural Networks.\"" arXiv preprint arXiv:1605.06065 (2016). [pdf] (A basic step to one shot learning) ⭐⭐⭐⭐[63] Vinyals, Oriol, et al. \""Matching Networks for One Shot Learning.\"" arXiv preprint arXiv:1606.04080 (2016). [pdf] ⭐⭐⭐[64] Hariharan, Bharath, and Ross Girshick. \""Low-shot visual object recognition.\"" arXiv preprint arXiv:1606.02819 (2016). [pdf] (A step to large data) ⭐⭐⭐⭐3 Applications3.1 NLP(Natural Language Processing)[1] Antoine Bordes, et al. \""Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing.\"" AISTATS(2012) [pdf] ⭐⭐⭐⭐[2] Mikolov, et al. \""Distributed representations of words and phrases and their compositionality.\"" ANIPS(2013): 3111-3119 [pdf] (word2vec) ⭐⭐⭐[3] Sutskever, et al. \""“Sequence to sequence learning with neural networks.\"" ANIPS(2014) [pdf] ⭐⭐⭐[4] Ankit Kumar, et al. \""“Ask Me Anything: Dynamic Memory Networks for Natural Language Processing.\"" arXiv preprint arXiv:1506.07285(2015) [pdf] ⭐⭐⭐⭐[5] Yoon Kim, et al. \""Character-Aware Neural Language Models.\"" NIPS(2015) arXiv preprint arXiv:1508.06615(2015) [pdf] ⭐⭐⭐⭐[6] Jason Weston, et al. \""Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.\"" arXiv preprint arXiv:1502.05698(2015) [pdf] (bAbI tasks) ⭐⭐⭐[7] Karl Moritz Hermann, et al. \""Teaching Machines to Read and Comprehend.\"" arXiv preprint arXiv:1506.03340(2015) [pdf] (CNN/DailyMail cloze style questions) ⭐⭐[8] Alexis Conneau, et al. \""Very Deep Convolutional Networks for Natural Language Processing.\"" arXiv preprint arXiv:1606.01781(2016) [pdf] (state-of-the-art in text classification) ⭐⭐⭐[9] Armand Joulin, et al. \""Bag of Tricks for Efficient Text Classification.\"" arXiv preprint arXiv:1607.01759(2016) [pdf] (slightly worse than state-of-the-art, but a lot faster) ⭐⭐⭐3.2 Object Detection[1] Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. \""Deep neural networks for object detection.\"" Advances in Neural Information Processing Systems. 2013. [pdf] ⭐⭐⭐[2] Girshick, Ross, et al. \""Rich feature hierarchies for accurate object detection and semantic segmentation.\"" Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [pdf] (RCNN) ⭐⭐⭐⭐⭐[3] He, Kaiming, et al. \""Spatial pyramid pooling in deep convolutional networks for visual recognition.\"" European Conference on Computer Vision. Springer International Publishing, 2014. [pdf] (SPPNet) ⭐⭐⭐⭐[4] Girshick, Ross. \""Fast r-cnn.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] ⭐⭐⭐⭐[5] Ren, Shaoqing, et al. \""Faster R-CNN: Towards real-time object detection with region proposal networks.\"" Advances in neural information processing systems. 2015. [pdf] ⭐⭐⭐⭐[6] Redmon, Joseph, et al. \""You only look once: Unified, real-time object detection.\"" arXiv preprint arXiv:1506.02640 (2015). [pdf] (YOLO,Oustanding Work, really practical) ⭐⭐⭐⭐⭐[7] Liu, Wei, et al. \""SSD: Single Shot MultiBox Detector.\"" arXiv preprint arXiv:1512.02325 (2015). [pdf] ⭐⭐⭐[8] Dai, Jifeng, et al. \""R-FCN: Object Detection viaRegion-based Fully Convolutional Networks.\"" arXiv preprint arXiv:1605.06409 (2016). [pdf] ⭐⭐⭐⭐[9] He, Gkioxari, et al. \""Mask R-CNN\"" arXiv preprint arXiv:1703.06870 (2017). [pdf] ⭐⭐⭐⭐[10] Bochkovskiy, Alexey, et al. \""YOLOv4: Optimal Speed and Accuracy of Object Detection.\""  arXiv preprint arXiv:2004.10934 (2020). [pdf] ⭐⭐⭐⭐[11] Tan, Mingxing, et al. “EfficientDet: Scalable and Efficient Object Detection.\"" arXiv preprint arXiv:1911.09070 (2019). [pdf] ⭐⭐⭐⭐⭐3.3 Visual Tracking[1] Wang, Naiyan, and Dit-Yan Yeung. \""Learning a deep compact image representation for visual tracking.\"" Advances in neural information processing systems. 2013. [pdf] (First Paper to do visual tracking using Deep Learning,DLT Tracker) ⭐⭐⭐[2] Wang, Naiyan, et al. \""Transferring rich feature hierarchies for robust visual tracking.\"" arXiv preprint arXiv:1501.04587 (2015). [pdf] (SO-DLT) ⭐⭐⭐⭐[3] Wang, Lijun, et al. \""Visual tracking with fully convolutional networks.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] (FCNT) ⭐⭐⭐⭐[4] Held, David, Sebastian Thrun, and Silvio Savarese. \""Learning to Track at 100 FPS with Deep Regression Networks.\"" arXiv preprint arXiv:1604.01802 (2016). [pdf] (GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods) ⭐⭐⭐⭐[5] Bertinetto, Luca, et al. \""Fully-Convolutional Siamese Networks for Object Tracking.\"" arXiv preprint arXiv:1606.09549 (2016). [pdf] (SiameseFC,New state-of-the-art for real-time object tracking) ⭐⭐⭐⭐[6] Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. \""Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking.\"" ECCV (2016) [pdf] (C-COT) ⭐⭐⭐⭐[7] Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. \""Modeling and Propagating CNNs in a Tree Structure for Visual Tracking.\"" arXiv preprint arXiv:1608.07242 (2016). [pdf] (VOT2016 Winner,TCNN) ⭐⭐⭐⭐3.4 Image Caption[1] Farhadi,Ali,etal. \""Every picture tells a story: Generating sentences from images\"". In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. [pdf] ⭐⭐⭐[2] Kulkarni, Girish, et al. \""Baby talk: Understanding and generating image descriptions\"". In Proceedings of the 24th CVPR, 2011. [pdf]⭐⭐⭐⭐[3] Vinyals, Oriol, et al. \""Show and tell: A neural image caption generator\"". In arXiv preprint arXiv:1411.4555, 2014. [pdf]⭐⭐⭐[4] Donahue, Jeff, et al. \""Long-term recurrent convolutional networks for visual recognition and description\"". In arXiv preprint arXiv:1411.4389 ,2014. [pdf][5] Karpathy, Andrej, and Li Fei-Fei. \""Deep visual-semantic alignments for generating image descriptions\"". In arXiv preprint arXiv:1412.2306, 2014. [pdf]⭐⭐⭐⭐⭐[6] Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. \""Deep fragment embeddings for bidirectional image sentence mapping\"". In Advances in neural information processing systems, 2014. [pdf]⭐⭐⭐⭐[7] Fang, Hao, et al. \""From captions to visual concepts and back\"". In arXiv preprint arXiv:1411.4952, 2014. [pdf]⭐⭐⭐⭐⭐[8] Chen, Xinlei, and C. Lawrence Zitnick. \""Learning a recurrent visual representation for image caption generation\"". In arXiv preprint arXiv:1411.5654, 2014. [pdf]⭐⭐⭐⭐[9] Mao, Junhua, et al. \""Deep captioning with multimodal recurrent neural networks (m-rnn)\"". In arXiv preprint arXiv:1412.6632, 2014. [pdf]⭐⭐⭐[10] Xu, Kelvin, et al. \""Show, attend and tell: Neural image caption generation with visual attention\"". In arXiv preprint arXiv:1502.03044, 2015. [pdf]⭐⭐⭐⭐⭐3.5 Machine TranslationSome milestone papers are listed in RNN / Seq-to-Seq topic.[1] Luong, Minh-Thang, et al. \""Addressing the rare word problem in neural machine translation.\"" arXiv preprint arXiv:1410.8206 (2014). [pdf] ⭐⭐⭐⭐[2] Sennrich, et al. \""Neural Machine Translation of Rare Words with Subword Units\"". In arXiv preprint arXiv:1508.07909, 2015. [pdf]⭐⭐⭐[3] Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. \""Effective approaches to attention-based neural machine translation.\"" arXiv preprint arXiv:1508.04025 (2015). [pdf] ⭐⭐⭐⭐[4] Chung, et al. \""A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation\"". In arXiv preprint arXiv:1603.06147, 2016. [pdf]⭐⭐[5] Lee, et al. \""Fully Character-Level Neural Machine Translation without Explicit Segmentation\"". In arXiv preprint arXiv:1610.03017, 2016. [pdf]⭐⭐⭐⭐⭐[6] Wu, Schuster, Chen, Le, et al. \""Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\"". In arXiv preprint arXiv:1609.08144v2, 2016. [pdf] (Milestone) ⭐⭐⭐⭐3.6 Robotics[1] Koutník, Jan, et al. \""Evolving large-scale neural networks for vision-based reinforcement learning.\"" Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [pdf] ⭐⭐⭐[2] Levine, Sergey, et al. \""End-to-end training of deep visuomotor policies.\"" Journal of Machine Learning Research 17.39 (2016): 1-40. [pdf] ⭐⭐⭐⭐⭐[3] Pinto, Lerrel, and Abhinav Gupta. \""Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours.\"" arXiv preprint arXiv:1509.06825 (2015). [pdf] ⭐⭐⭐[4] Levine, Sergey, et al. \""Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection.\"" arXiv preprint arXiv:1603.02199 (2016). [pdf] ⭐⭐⭐⭐[5] Zhu, Yuke, et al. \""Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning.\"" arXiv preprint arXiv:1609.05143 (2016). [pdf] ⭐⭐⭐⭐[6] Yahya, Ali, et al. \""Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search.\"" arXiv preprint arXiv:1610.00673 (2016). [pdf] ⭐⭐⭐⭐[7] Gu, Shixiang, et al. \""Deep Reinforcement Learning for Robotic Manipulation.\"" arXiv preprint arXiv:1610.00633 (2016). [pdf] ⭐⭐⭐⭐[8] A Rusu, M Vecerik, Thomas Rothörl, N Heess, R Pascanu, R Hadsell.\""Sim-to-Real Robot Learning from Pixels with Progressive Nets.\"" arXiv preprint arXiv:1610.04286 (2016). [pdf] ⭐⭐⭐⭐[9] Mirowski, Piotr, et al. \""Learning to navigate in complex environments.\"" arXiv preprint arXiv:1611.03673 (2016). [pdf] ⭐⭐⭐⭐3.7 Art[1] Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). \""Inceptionism: Going Deeper into Neural Networks\"". Google Research. [html] (Deep Dream)⭐⭐⭐⭐[2] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. \""A neural algorithm of artistic style.\"" arXiv preprint arXiv:1508.06576 (2015). [pdf] (Outstanding Work, most successful method currently) ⭐⭐⭐⭐⭐[3] Zhu, Jun-Yan, et al. \""Generative Visual Manipulation on the Natural Image Manifold.\"" European Conference on Computer Vision. Springer International Publishing, 2016. [pdf] (iGAN) ⭐⭐⭐⭐[4] Champandard, Alex J. \""Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks.\"" arXiv preprint arXiv:1603.01768 (2016). [pdf] (Neural Doodle) ⭐⭐⭐⭐[5] Zhang, Richard, Phillip Isola, and Alexei A. Efros. \""Colorful Image Colorization.\"" arXiv preprint arXiv:1603.08511 (2016). [pdf] ⭐⭐⭐⭐[6] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. \""Perceptual losses for real-time style transfer and super-resolution.\"" arXiv preprint arXiv:1603.08155 (2016). [pdf] ⭐⭐⭐⭐[7] Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. \""A learned representation for artistic style.\"" arXiv preprint arXiv:1610.07629 (2016). [pdf] ⭐⭐⭐⭐[8] Gatys, Leon and Ecker, et al.\""Controlling Perceptual Factors in Neural Style Transfer.\"" arXiv preprint arXiv:1611.07865 (2016). [pdf] (control style transfer over spatial location,colour information and across spatial scale)⭐⭐⭐⭐[9] Ulyanov, Dmitry and Lebedev, Vadim, et al. \""Texture Networks: Feed-forward Synthesis of Textures and Stylized Images.\"" arXiv preprint arXiv:1603.03417(2016). [pdf] (texture generation and style transfer) ⭐⭐⭐⭐[10] Yijun Li, Ming-Yu Liu ,Xueting Li, Ming-Hsuan Yang,Jan Kautz (NVIDIA). \""A Closed-form Solution to Photorealistic Image Stylization.\"" arXiv preprint arXiv:1802.06474(2018). [pdf] (Very fast and ultra realistic style transfer) ⭐⭐⭐⭐3.8 Object Segmentation[1] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation.” in CVPR, 2015. [pdf] ⭐⭐⭐⭐⭐[2] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. \""Semantic image segmentation with deep convolutional nets and fully connected crfs.\"" In ICLR, 2015. [pdf] ⭐⭐⭐⭐⭐[3] Pinheiro, P.O., Collobert, R., Dollar, P. \""Learning to segment object candidates.\"" In: NIPS. 2015. [pdf] ⭐⭐⭐⭐[4] Dai, J., He, K., Sun, J. \""Instance-aware semantic segmentation via multi-task network cascades.\"" in CVPR. 2016 [pdf] ⭐⭐⭐[5] Dai, J., He, K., Sun, J. \""Instance-sensitive Fully Convolutional Networks.\"" arXiv preprint arXiv:1603.08678 (2016). [pdf] ⭐⭐⭐"
20,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
21,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        简体中文 |        繁體中文 |        한국어 |        Español |        日本語 |        हिन्दी        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    🤗 Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:📝 Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.🖼️ Images, for tasks like image classification, object detection, and segmentation.🗣️ Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.🤗 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install 🤗 Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, 🤗 Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.🤗 Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by 🤗 Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: 🤗 Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from École polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Suárez*, Yoann Dupont, Laurent Romary, Éric Villemonte de la Clergerie, Djamé Seddah and Benoît Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of Göttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo Lüddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Hervé Jégou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp Krähenbühl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Hervé Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by René Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre Défossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, Loïc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Benoît Crabbé, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey Öhman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo García del Río, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Hervé Jégou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by Jörg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre Défossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noah’s Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.Nyströmformer (from the University of Wisconsin - Madison) released with the paper Nyströmformer: A Nyström-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier Hénaff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, João Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, Łukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Dollár.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault Févry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of Würzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, Paweł Krzysztof Nowak, Thomas Müller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Lučić, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper ​XLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the 🤗 Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by 🤗 TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by 🤗 Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the 🤗 Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
22,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answers⚠️ DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]🙏 PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!🎉 AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.❓ Need help?Open new issue🔥 Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accounting❗needs updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustrator❗needs updating  7674Adobe-InDesign❗needs updating  4240Adobe-Lightroom❗needs updating  2020Adobe-Photoshop❗needs updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effects❗needs updating  2413Agile Methodologies❗needs updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCAD❗needs updating  7775@djayorAutodesk Fusion 360❗needs updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambda❗needs updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++❗needs updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurity❗needs updating10196Django7171@PROCW.NET Framework6359@declarckEclipse❗needs updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSON❗needs updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excel❗needs updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Project❗needs updating4443Microsoft Word❗needs updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooks❗needs updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revit❗needs updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePoint❗needs updating5338Sketchup22SOLIDWORKS❗needs updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnity❗needs updating4746@uno-sebastianVisual Basic for Applications (VBA)❗needs updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors ✨Thanks goes to these wonderful people (emoji key):            Evgenii💻 🖋      Sergei Stadnik💻 🔍 🤔 📖      Santhosh💻      Jacob Dsa💻 🖋      Aaron Meese💻 🖋      arqarq💻 🖋      Amit Yadav💻 🖋              Javokhir Nazarov💻 🖋      saurav kumar🖋      Chetan🖋      Amir Hossein Shekari🎨 🖋 💻      SergDaut🎨      Nilotpal Pramanik🎨 💻 🖋 💼 📖 🔣 💡      Abhishek Kumar🎨              Monu Gupta🎨      KARTIKEYA GUPTA💻 🖋      kenkyusha💻 🖋      juandavidtowers💻 🖋      cyber-netics💻 🖋      jtrisw💻 🖋      Renato Regalado💻 🖋              Matthew💻 🖋      Jan S.💻 🖋      Manoli💻 🖋      Faraz tanveer💻 🖋      mohnishkarri💻 🖋 🎨      andyzhu💻 🖋      Vishal Kushwah💻 🖋              Yurii Yakymenko💻 🖋      Swetabh Suman💻 🖋      AJAY DANDGE💻 🖋      Mehmet Yesin🎨      Lok Chun Wai🎨      Adria de Juan🎨      GL-Man🎨              Jheel Patel🎨      Sameer Waskar🎨      Alexander Andrews🎨      Alexander Maxwell🎨      Slava🎨      Mayur Khatri🎨      Mascantosh💻 🖋 📢 🤔              Kivanc Enes🎨      Ritika Das🎨      Zer07793🎨      Andrew Cheung🎨      Sadha🎨      tainenko🎨 💻      github-star-coder🎨              Danilo Oliveira🎨      lordeko🎨      Shubham Kumar🎨 💻      testtree🎨      Cheryl Murphy🎨 💻      Bipin Thomas🎨      Abdulrahman Hisham🎨              Dakshitha Dissanayaka🎨      BADR KACIMI🎨      Alex Wang🎨      Maxim🎨      GordonGrant🎨 💻      Ephrem Demelash🎨      JonOrcutt🎨              topdev10🎨      cookwellwebsite🎨      xren935🎨      Nemo Frenkel🎨      MD SAIF ALAM🎨      Boris López Araya🎨      Larry Chiem🎨              Muhammad Bilal Ilyas🎨      AliMilani🎨 💻      Suraj Sahani🎨      FlyingSquirrel🎨      Erick Tijero🎨      Jaskaran Kukreja🎨      MichaelL🎨              MagicLegend🎨      Dereck Bearsong🎨      Pappu Kumar Pashi🎨      Venkata Kishore Tavva🎨      Rafat Touqir Rafsun🎨      Snehesh Dutta🎨      Timo Körner🎨 💻              alexxxan🎨      GGJason🎨      LeeAnna Ewing🎨 🤔      kamal Jyotwal🎨      Bob-Johns🎨 💻 🖋      yunussalmanlyit🎨 💻      chilcot🎨 💻              Jacky Li💻 🖋 🎨      Sarthak Trivedi🎨      Ayush Aggarwal🎨 💻      Nic Ballarini🎨      Luigi Zambetti🎨 💻      govindhaswin🎨      Addy Roy💻 🎨              Akshat Tamrakar🎨 💻      Sai Bhargava Ramu🎨      Gurkan💻      Spencer Hayes-Laverdiere💻      Aniket Soni💻      tanmay5792💻      Dina Taklit💻 🎨 🖋              Dushyant Singh💻      Ravi Prakash Singh💻      Nihal Joshi💻      Guy Klages💻      Arvind🎨 💻      mujeeb91💻      joserca🎨 💻              Prateek Agrawal💻      Teoh Tze Chuin(サラ)💻 🎨      Jayant Jain💻      Ayush Sahu💻      Hridya Krishna R💻 🎨      Rahul Bali💻 🎨      S.ZHeng🎨 💻 💼              Shriya Madan🎨 💻      mahalrupi🎨      Lucas Lermagne🎨      Jeff Deutsch🎨 💻      Betoxx1🎨      Wingman4l7🎨      Martin Espericueta🎨              Mh-Tahir🎨      Zdravko Šplajt🎨 💻      Ms3105🎨 💻 🖋      Ambika Sidhesware💻      mundoguero💻      Darkus24🖋      Sou-786🖋 🎨              Banurekha🖋      ShiraStarL🎨      Ilya Komarov🎨      DemigodMs🖋 📖      Mekha Hridya🎨 🔍      Andrey Safonov🎨 🔍      Tommaso🎨 💻              Jessica Salbert💻 🎨      JAYANTH DOLAI💻 🎨      silverstroom💻 🎨 💼      Furkan Sayım💻 🎨      Sukumar Chandrasekaran🎨      Yejin Park🎨 💻      Ali Nooshabadi🎨 💻              imitavor🎨 💻      Salih Kilicli🎨 💻      Marcelo Meneses🎨 💻      Anton Krekotun🎨 🚧 🖋 💻 📖 💼      Arnav Sarma💻 💡 🎨      meghatiku💻 🎨      Anshu Trivedi🎨              Taylor Dorsett💻 🖋 🎨      Havit Rovik💻      pushpapune💻 🎨      Ramtin Radfar🎨 🤔 💼 💵 💻 🖋 💬      Abdulmajeed Isa💻 🎨      vikassaxena02🎨      RobTables🎨 💻 💼              Daniel🎨 💻 💼 🔍      Zahid Ali💻 🎨      Chad Chai💻 🎨      Marco Biedermann💻 🎨 💼 🤔      Srinidhi Murthy🎨      Miao Cai💻 🎨      Dionicio Diaz🎨 💻              Mir Monoarul Alam🎨      Shawn Ohn💻 🎨      Amanbolat Balabekov🎨 💻      black-mamba-code💻      Jian-forks🎨 💻      shivani patel🎨      Akash Chowrasia🎨              yairg98🎨      Jay Gajjar🎨      coolerbooler💻      Md Zinnatul Islam Morol🎨      shresthashok550🎨 📖      Alan Pallath📖      Adrian Wong💻              vsDizzy💻 🎨      Frex Cuadillera🎨 💻      ashish570💻 🎨      ruchpeanuts💻 🎨      Artmasque🎨 💻      Amirhossein Mojiri Foroushani🎨      for💻 🎨              Luke🎨 💻      Hector Espinoza🎨      Adrián Buenfil🎨 💻      Amit Kumar🎨      schoppfe🎨 💻      Sofiyal C🎨 💻      spitlisk💻 🎨              PRAVIN SHARMA🎨      NIDZAAA1🎨 💻      John Mai🎨 💻      kimsoyeong🎨      Dona Ghosh💻      Ryan Hill🎨 💻      j42z🎨 💻              Ashish Sangale🎨 💻      Derek Yang🎨 💻      mohsinmsm🎨 💻      Gokulkrish2302💻      Bhaavishek💻 🎨      Louis Liao🎨      sengc92🎨 💻              Alex Marvin🎨      Balkrishna Bhatt🎨 💻      Evaldas Lavrinovičius🎨 💻      Adam Erchegyi🎨 💻      Truman Hung🎨 💻      rzamora11🎨      gaurav0224🎨              Lee GyeongJun🎨      Mirek🎨 💻      surajm245🎨      ArisLaode🎨 💻      RaviDhoriya🎨 💻      sarai-84🎨 💻      Vishnu🎨 💻              Muhammad Minhaj💻      Chandrika Deb🎨 💻      Gitgit101-bit💻 🎨      Hedi Sellami💻 🎨      saurabhvaish93💻 🎨      Nikola Begovic💻 🎨      Wang💻 🎨              Manuel Eusebio de Paz Carmona🎨      Basim Al-Jawahery🎨 💻      RAJA AHMED🎨 💻      Abhik Lodh💻      Md. Pial Ahamed💻 🎨      Hassan Shahzad💻 🎨      Christian Sosa Gago💻              Hasnain Rasheed💻 🎨      T-Radford💻      dahiyashish💻 🎨      RahulSharma468💻 🎨      Jumpod Plekhongthu💻 🎨      Thomas Young-Audet💻 🎨      VinayagamBabu💻 🎨              Deniz Koç💻 🎨      Azhar Khan💻 🎨 🖋 📖 🔣 🚧      Jacob Short💻 🎨      Uchimura85💻 🎨      Leo Nugraha💻 🎨 📖      Mujtaba Mehdi📖 🖋      Jim-ds💻 🎨              Sreehari K💻 🎨      Florian Martinez💻 🎨      Aaron💻 🎨      apoage🎨      Ignacio Guillermo Martinez 💻 🎨      AirlineDog🎨 💻      Mekel🎨 💻              hmosharrof🎨 💻      Ben Emamian💻 🎨      babeshark💻 🎨      Leonardo Jaques💻 🎨      Stefanos Apkarian💻 🎨      Ayhan Albayrak💻 🎨      KidusMT💻 🎨              hectormarroquin20💻 🎨      Edelweiss35💻 🎨      MihaiD💻 🎨      AnveshReddyAnnem💻 🎨      Hyunjae Park💻 🎨      Rajiv Albino💻 🎨      Atishay💻              Yusuf Naheem🎨      Windu🎨 💻      Superv1sor💻 🎨      Karine (:🎨 💻      Eduard Pech🎨 💻      jjeshwani🎨 💻      Steve🎨 💻              Aleigh Ohslund💻      Abhinav Suman🎨 💻      Hamza Ehtesham Farooq🎨 💻      IamNotPeterPan💻 💵 🎨      Cetger🎨      pkonopacki🎨      Yang Yang🎨 💻              Muhammad Shoaib Sarwar💻      Murilo Henrique💻 🎨      emilianoalvz🎨 💻      Sumana Saha🎨 💻      Yurii17K🎨 💻      Rupesh Bhandari🎨 💻      salmos3718💻              John Baker🎨 💻      SanjaySathiraju🎨 💻      Donat Kabashi🎨      Arul Prasad J🎨 💻      Qi Chen🎨 💻      Maksym Dmyterko🎨 💻      ilovepullrequests💻              Samira Maleki🎨 💻      NIKITA MAHOVIYA💻      jesuisdev.Net🎨 💻      Ashraf Nazar🎨      Naveed Ahmad🎨      Ajmain Naqib🎨 💻      Avinash Tingre💻 🎨              nicktids🎨      Keith Dinh💻 🎨      André Ferreira💻 🎨      eliottkespi💻 🎨      praveenpno💻 🎨      vitowidigdo💻 🎨      Devesh Pratap Singh💻 🎨              Dario Rodriguez💻 🎨      charmander_didi💻 🎨      PHBasin💻 🎨      Ritvik Singh Chauhan💻 🎨      Riya P Mathew💻 🎨      Stephanie Cherubin💻 🎨      BenitesGui💻 🎨              FarikBear💻 🎨      Dmytro Havrilov💻 🎨      Parvesh Monu💻 🎨      Dipen Panchasara💻 🎨      gudata🎨 💻      gawadeditor💻 🎨      Kirill Taletski🎨 💻              Saajan🎨 💻      Kushagra S🎨 💻      Oanh Le🎨 💻      Frane Medvidović🎨 💻      Yorman🎨 💻      Bill Chan🎨 💻      Pratik Lomte🎨 💻              LOC LAM🎨 💻      TUSAR RANJAN MAHAPATRA💻      BhargavKanjarla💻      Karel De Smet💻 🎨      sidisan🎨      ygnzayarphyo🎨 💻      svansteelandt💻              Kebechet🎨      Daniel Selvan D🎨 💻      Mahdi Razavi🎨 💻      Niklas Tiede💻 🎨      narutubaderddin💻 🎨      dylandhood💻      Dheeraj Gupta💻              Pieter Claerhout💻 🎨      Shivam Agnihotri💻      RanjithReddy-Narra💻      Nikita Wadhwani🎨 💻      rsholokh💻 🎨      Ayaan Hossain💻 🎨      Rajesh Swarna💻              Deniz Etkar🎨 💻      pro335💻 🎨      Jakub Radzik💻 🎨      Hamza Khanzada💻      ARNON🎨      Vikram Singh💻      Shoxruxbek💻 🎨              Amit Khatri💻 🎨      Wali Ullah🎨 💻      Amit11794💻 🎨      metis-macys-66898💻 🎨      Faisal Maqbool🎨 💻      Kumar Neeraj💻 🎨      Maurizio Marini🎨 💻              Saket Kothari🎨 💻      Szymon Zborowski🎨 💻      iks3000🎨 💻      Ehsan Seyedi🎨 💻      vanekbr🎨 💻      Princy_M🎨 💻      Shijie Zhou🎨 💻              lakshyamcs16🎨 💻      Filippo Facco🎨 💻      mendel5🎨 💻      Patryk🎨 💻      VishwaSangani🎨 💻      Alvin Zhao🎨 💻      Lazar Gugleta🎨 💻              vmicho🎨 💻      Sikandar Ali🎨 💻      Raja Babu🎨 💻      faizajahanzeb💻      Guil_AiT🎨 💻      Kushal Das🎨 💻      Luis Bonilla🎨 💻              jovan1013🎨 💻      Damian🎨 💻      Yash Gupta💻      lolcatnip🎨 💻      Ikko Ashimine🎨 💻      Farukh🎨 💻      Moksedul💻 🎨              Navneet Kumar🎨 💻      Saqib AlMalik💻      fahimrahman🎨 💻      vaibhav patil🎨 💻      Rahul Madan🎨 💻      kartik Kaklotar🎨 💻      ASAHI OCEAN🎨 💻              Daniel Jungbluth🎨 💻      Rajdeep Singh Borana🎨 💻      ankitha19💻      Linh Tran💻      islamarr💻 🎨      Mohamed Sabith🎨 💻      Miguel Angel Cruz Acosta🎨 💻              Adebayo Ilerioluwa 🎨      Markus🎨 💻      dkonyayev🎨 💻      Kevin A Mathew🎨 💻      David Melo🎨 🔣      DFW1N🎨 💻      Sohaib Ayub🎨 💻              Navvy🎨 💻      bloodiator2🎨 💻      Hanji🎨 💻      arthur74🎨 💻      Sri Subathra Devi B🎨 💻      Akif Aydogmus🎨 💻      Umer Javaid🎨 💻              Norio Umata🎨 💻      Gazi Hasan Rahman🎨 💻      Keith Nguyen🎨 💻      Megalomaniac🎨 💻      ShankS3🎨 💻      Farhad Alishov🎨 💻      Ronak J Vanpariya🎨 💻              azrael0learza🎨 💻      Pavel Rahman🎨 💻      chuabern🎨 💻      Rahul Tirkey🎨 💻      Ruslan Bes🎨 💻 💡 🚧 🖋 🔣 🚇      Bohdan🎨 💻      Juzdzewski🎨 💻              Grigor Minasyan🎨 💻      alvintwc🎨 💻      Anand Natarajan🎨 💻      Kashan Ali🎨 💻      Thomas Meshail🎨 💻      Son Pham🎨      Michael French💡              Yash Mishra📖      Miguel Rodriguez🎨 💻      Philipp Bachmann🎨 💻      sunny🎨 💻      Siddharth Chatterjee🎨 💻      Michael Naghavipour🎨 💻      Sahil Garg🎨 💻              MicroLion🎨 💻      wctwc🎨 💻      Rohan Sharma🔣      AshishBodla🎨 💻      Taras Pysarskyi🎨 💻      Luqman Bello O.🎨 💻      DyingDown🎨 💻              Diego Chapedelaine🎨 💻      Richlee🎨 💻      Asif Habib🎨 💻      Mazharul Hossain🎨 💻      toni🎨 💻      Pragyanshu Rai🎨 💻      Matthew Eller🎨 💻              AbhiBiju🎨 💻      Roman Zhornytskiy🎨 💻      Lucas Camino🎨 💻      João Vitor Casarin🎨 💻      Evgeniy Shay🎨 💻      Ehsan Barkhordar🎨 💻      Gabriel🎨 💻              Shibu Mohapatra🎨 💻      Pavel Kirkovsky🎨 💻      Tahir Gul🎨 💻      imDevSalman🎨 💻      Jordan Donaldson🎨 💻      js-venus🎨 💻      Faisal Shaikh🎨 💻              ashishbpatil🎨 💻      Tri Le🎨 💻      tomtreffke🎨 💻      Salah Eddine Lalami🎨 💻      Mattias Xu🎨 💻      Manas Gupta🎨 💻      wolfsong62🎨 💻              Mehdi Mirzaei🎨 💻      Van Ba Khanh🎨 💻      Sel Embee🎨 💻      Suvradip Paul🎨 💻      Sharique🎨      Seabass🎨 💻      Penny Liu🎨 💻              jatinder bhola🎨 💻      misterqbit🎨 💻      Daniel-VS9🎨 💻      Shruthi🎨 💻      beefydog🎨 💻      Suraj Kumar🎨 💻      hrishikeshps🎨 💻              Sudarshan🎨 💻      Divyansh💻 🎨      Zyaire🎨 💻      Omar Belkady🎨 💻      alexiismua🎨 💻      Eduarda Alves🎨      pycoach🎨 💻              Ruhul🎨 💻      pmoustopoulos🎨 💻      Lee Hui Ting💻 🎨      bodi1981🎨 💻      Devaraat Joshi🎨 💻      Johnny🎨 💻      rogue-coder🎨 💻              viiktr🎨      Lalit Mohan💻      João Sousa💻      言葉之靈💻 🎨      RJLABS💻      brittney0522🎨 💻      sham🎨 💻              Glenn Goossens💻 🎨      Cyber Hawk🎨 💻 🖋 💼      Ankit Yadav🎨 💻      verbality💻      Mohammed Siddiqui🎨 💻      AdamKaczor6250🎨 💻      Ramón Martinez Nieto🎨 💻              Grzegorz Dziubak🎨 💻      Ayoub BERDEDDOUCH🎨 💻      nikola-fadv🎨 💻      Akarsh Agrawal🎨 💻      Mitra Mirshafiee🎨 💻      Parker Stephens🎨 💻      alrenee99💻              Karthick Vankayala💻      Iryna 🎨 💻      palanugrah💻      Gwinbleind🎨 💻      Randy Bobandy🎨 💻      Bek Rozikoff💻      davnguye🎨 💻              Neel Patel💻      ehudbehar🎨 💻      nicholas-cod3r🎨 💻      michaelfranki🎨      Esther White🎨 💻      prathmeshpb🎨 💻      Victor Lin🎨 💻              Christine C. Yin🎨 💻      GitLearner-begin🎨 💻      Mesrop Andreasyan🎨 💻      Nathan Garcia🎨      commonsw04🎨 💻      Md. Rashad Tanjim🎨 💻      Ali Malek💻              PAODLT🎨 💻      Nikhil Bobade🎨 💻      hyuckjin21💻      Itasha Modi🎨 💻      Nikitha Reddy🎨 💻      Mahshooq Zubair🎨 💻      Subham Das💻              Onkar Birajdar🎨 💻      Nick Titomichelakis🎨 💻      Christian Leo-Pernold🎨      Matthew Marquise🎨 💻      baronfac🎨 💻      Abhishek Tilwar🎨 💻      DavidsDvm🎨 💻              Parth Parikh🎨 💻      Hector Castro🎨 💻      Rikky Arisendi🎨 💻      Ali HamXa🎨 💻      Frank.wu🎨 💻      Jatin Kumar🎨 💻 📖      masterHAWK99🎨 💻              Pushp Jain🎨 💻      Ashutosh Rout🎨 💻      Atharva Deshpande🎨 💻      Teodor Ciripescu🎨 💻      Anmol Bansal🎨 💻      Nikhil Kumar Macharla🎨 💻      Dexter🎨 💻              Aaron🎨 💻      Yogita Jaswani🎨 💻 📖 🖋      StoryDev🎨 💻      Mesut Doğansoy🎨 💻      Paras Dhawan🎨 💻      Emanuel Zhupa🎨 💻      Aaradhyaa717🎨 💻              jaacko-torus🎨 💻      mBlack💻      kalrayashwin📖 🖋 🎨 💻      Seraph💻 🎨      ZhiHong Chua🎨 💻      Amsal Khan🎨 💻 📖 🖋      Raghav Rastogi🎨 💻              Tzila📖      Shahriar Nasim Nafi📖      AG🎨 💻      Mojtaba Kamyabi🎨 💻      Ahmad Abdulrahman🎨 💻      Eclipse🎨 💻      Anshu Pal🎨 💻              Denis🎨 💻      mehmet sayin📖      WebDEV🎨 💻      Sam Komesarook🎨 💻      Kiran Ghimire🎨 💻      Joshua Davis🎨 💻      Muhammad-Huzaifa-Siddiqui💻              tobeornottobeadev🎨 💻      VAIBHAV SINGHAL🎨 💻      Keiran Pillman🎨 💻      Max Donchenko🎨 💻      sgonsal🎨 💻      diksha137🎨 💻      Vignesh🎨 💻              Gabriel França🎨 💻      Joseph🎨 💻      Bruno Rafael🎨 💻      vcamarre🎨 💻      thibault ketterer🎨 💻 🚧      VictorGonzalezToledo🎨 💻      1911510996🎨 💻              invidu🎨 💻      Nurul Furqon🎨 💻      David Asbill🎨 💻      Niko Birbilis🎨 💻      Mugundan Kottursuresh🎨      agrsachin81🎨 💻      Othmane El Alami🎨 💻              Syed Atif Ali🎨 💻      lakhanjindam🎨 💻      youssef hamdane🎨 💻      starfaerie🎨 💻      rodrigo0107🎨 💻      Michał Gralak🎨 💻      Jewel Mahmud🎨 💻              cwilson830🎨 💻      buun1030🎨 💻      Reda-ELOUAHABI🎨 💻      saad-aksa🎨 💻      Emdadul Haque🎨 💻      PROCW🎨 💻      cccppp1🎨 💻              Joanna Baile🎨 💻      Ahmed Saber🎨 💻      Masoud Keshavarz🎨 💻      mortazavian🎨 💻      Aniket Pandey🎨 💻      Vijay Nirmal🎨 💻      Daniel Carvallo💻              menaechmi🎨 💻      azenyx🎨 💻      Ahmet Özrahat🎨 💻      Abdulrahman Abouzaid🎨 💻      jmgnorbec🎨 💻      palinko91🎨 💻      Laisson R. Silveira🎨 💻              BHARGAVPATEL1244🎨 💻      Candide U🎨 💻      Sitansh Rajput🎨 💻      Houda Mouttalib🎨 💻      MumuTW🎨 💻      Suave Bajaj🎨 💻      Mehdi Parsaei🎨 💻              Dinko Osrecki🎨 💻      Dhia Djobbi🎨 💻      Mahmoud Galal🎨 💻      Anh Minh🎨 💻      Suvesh K🎨 💻      Petar Todorov🎨 💻      Alexander Nguyen🎨 💻              Morteza Jalalvand🎨 💻      Claudson Martins🎨 💻      Matt Jacobson🎨 💻      Rafael Belokurows🎨 💻       Thomas Gamauf🎨 💻      Rishabh Mahajan🎨 💻      rakeshpdgupta23🎨 💻              Shashidharknaik🎨 💻      taleleuma🎨 💻      Florian Bühler🎨 💻      Raihan Bin Wahid🎨 💻      MOHAMMED NASSER🎨 💻      federico🎨 💻      Andre Violante🎨 💻              tcunningham98🎨 💻      Jan Grießer🎨 💻      Serkan Alc🎨 💻 🖋      Jez McKean🎨 💻      meisam alifallahi🎨 💻      Mehul Thakkar🎨 💻      Saksham Soni🎨 💻              Pedro Peregrina🎨 💻      Mintu Choudhary🎨 💻      lucianmoldovanu🎨 💻      John C. Scott🎨 💻      Mia D.🎨 💻      EwenBernard🎨 💻      M. Reza Nasirloo🎨 💻              Jay Agrawal🎨 💻      DeShay🎨 💻      Jay206-Programmer🎨 💻      Elender🎨 💻 🖋      Bobby Byrne🎨 💻      Pirci🎨 💻      Hasanuzzaman🎨 💻              Josh Kautz🎨 💻      Brofar🎨 💻      Mina Karam🎨 💻      Duncan O N🎨 💻      Sean Tumulak-Nguyen🎨 💻      Artur Trześniewski🎨 💻      JJaammeessM🎨 💻              shubham agarwal🎨 💻      Michele Righi🎨 💻      Panagiotis Kontos🎨 💻      sumitbathla🎨 💻      Deepak Mathur🎨 💻      Juho Nykänen🎨 💻      Santiago González Siordia🎨 💻              SRIJITA MALLICK🎨 💻      Samriddhi B🎨 💻      Nitzan Papini🎨 💻      Mario Sanz🎨 💻      Crab^4🎨 💻      Pablo🎨 💻      Gordon Pham-Nguyen🎨 💻              Kristoffer🎨 💻      chrisblach🎨 💻      Gábor🎨 💻      Lina🎨 💻      Harrison Watts🎨 💻      Mario Petričko🎨 💻      Ben8120🎨 💻              Giovanna🎨 💻      Minal Ahuja🎨 💻      mossfarmer🎨 💻      ThaC0derDre🎨 💻      itware🎨 💻      Michael Walker🎨 💻      Tom Jacob Chirayil🎨 💻              Sachin Kumar🎨 💻      adi-ray🎨 💻      Dr-Blank-alt🎨 💻      Bogdan Cazacu🎨 💻      Gilson Urbano🎨 💻      Nina🎨 💻      Anthony🎨 💻              manushimjani🎨 💻      Michael Reyes🎨 💻      Rachel Kennelly🎨 💻      Aakash Garg🎨 💻      Daniel Livingston🎨 💻      alexrojco🎨 💻      Minh Nguyen🎨 💻              Mahesh Dattatraya Babar🎨 💻      Jin Zihang🎨 💻      Bikramjit Ganguly🎨 💻      QuestionableGuise🎨 💻      liq19ch🎨 💻      Bruno Rocha🎨 💻      Anand Dyavanapalli💻 🖋              crucian-afk🎨 💻      0xgainz🎨 💻      weirdfsh🎨 💻      Valan Baptist Mathuranayagam🎨 💻      Paul Kaefer🎨 💻      Yu-Hsiang Wang🎨 💻      Javad Adib🎨 💻              davidliu0930🎨 💻      Achilleas John Yfantis🎨 💻      Omkar Shivadekar🎨 💻 🖋 🐛      ToanTran🎨 💻      Gautam Naik🎨 💻      Marc🎨 💻      twix20🎨 💻              Kristian S.🎨 💻      Aleksey Khoroshilov🎨 💻      arjunsrsr🎨 💻      Ali Haider🎨 💻      Trisha Dring🎨 💻      Andre Marzulo🎨 💻      Krishna Modi🎨 💻              Rosemary Li🎨 💻      Alex Weller🎨 💻      Tam Nguyen🎨 💻      aquintelaoliveira🎨 💻      Norbert Brett🎨 💻      rocsogd🎨 💻      0nyr🎨 💻              rethkevin🎨 💻      RickHeadle🎨 💻      Leandre🎨 💻      Natnael Sisay🎨 💻      sbbu🎨 💻      wael🎨 💻      Fabricio Tramontano Pirini🎨 💻              Alexander Stoyanov🎨 💻      Dezx20🎨 💻      southparkkids🎨 💻      bmstar🎨 💻      kiagam🎨 💻      Juan Castillo🎨 💻      FFenne🎨 💻              Jose Toledo🎨 💻      Pat McGhen🎨 💻      Eiko Wagenknecht💻 🖋 🔣      Alan Chalmers🎨 💻      Jean Didier🎨 💻      Andy🎨 💻      pestadieu🎨 💻              Kanishka Chakraborty🎨 💻      Nandha🎨 💻      Vahid Mafi🎨 💻 🔣 🖋 💼      Akshay Ashok🎨 💻      0x08🎨 💻      Sandeep Mishra🎨 💻      Evann Regnault🎨 💻              Lenny Zeitoun🎨 💻      Eden Boaron🎨 💻      TroyBTC🎨 💻      Aby Sebastian🎨 💻      Matthew Dunn🎨 💻      ckullo🎨 💻 🖋 🔣      Mohamed Mamdouh🎨 💻              Youssef Bazina🎨 💻      Frederico Kückelhaus💻      Nushan Kodikara💻      Zach Cooper💻      Roy🎨 💻      Saurav Panchal🎨 💻      totallynotdavid🎨 💻              goosepirate🎨 💻 💡 💼      KAUTH🎨 💻      Hari Kiran Vusirikala🎨 💻      Sounak Dey🎨 💻      zia💼 🎨 💻      Reza Davari🎨 💻      AkshayAjaykumar🎨 💻              x24870🎨 💻      Ko Phone🎨 💻      Nabstar3🎨 💻      Mateusz🎨 💻      Yunus Emre Emik💻      Abhinav Sinha🎨 💻      Hung Nguyen🎨 💻              Maselino💻      Shuktika Mahanty💻      Mikołaj Gawroński🎨 💻      Hussein Habibi Juybari🎨 💻      Sean-McArthur🎨 💻      Osman F Bayram🎨 💻      Benjamin Thomas Blodgett🎨 💻              Chuanlong-Zang🎨 💻      julian🎨 💻      francisco🎨 💻      aalihhiader9211🎨 💻      Muhammad Zunair🎨 💻      Liya🎨 💻      BegadTarek🎨 💻              etorobot🎨 💻      Hussam Khan🎨 💻      Saikat Chakraborty🎨 💻      Nicholas Quisler🎨 💻      Evang Poul🎨 💻      Gregg Lind🎨 💻      Deepak Kumar🎨 💻              Callum Leslie🎨 💻      Curtis Barnard Jr.🎨 💻      Deepanshukaim🎨 💻      Manthan Ank🎨 💻      hossein varmazyar🎨 💻      Brayan Muñoz V.🎨 💻      Kamil Rasheed Siddiqui💻 🎨              mutt0-ds🎨 💻      egbertjk🎨 💻      Majid Zojaji🎨 💻      Sean Chen🎨 💻      Herbert Milhomme🎨 💻      A3🎨 💻      Killian🎨 💻              Coakeow🎨 💻      ྅༻ Ǭɀħ ༄༆ཉ🎨 💻      Pratik Solanki🎨 💻      Sunny🎨 💻      ssge🎨 💻      Bernat Frangi🎨 💻      Jeevan Rupacha🎨 💻              amirandap🎨 💻      Deepakshi Mittal🎨 💻      Abhijeet Parida🎨 💻      Khaled Riyad🎨 💻      Pratap parui🎨 💻      Prajit Panday🎨 💻      PipeSierra🎨 💻              Collins Oden🎨 💻      Kshitij Dwivedi🎨 💻      Bernardia Vitri Arumsari🎨 💻      Ömer Faruk Taşdemir🎨 💻      Spencer Stith🎨 💻      Porsche Rodjanasak🎨 💻      Shakeel Sharif🎨 💻              Victoria Cheng🎨 💻      Denis🎨 💻      Anand Prakash Tiwari🎨 💻      danijeljw-rpc🎨 💻      Ahmed H Ebrahim🎨 💻      Virginia Gardner🎨 💻      Jhironsel Diaz A.🎨 💻              Yunus Kidem🎨 💻      MT🎨 💻      Dinesh Zaldekar🎨 💻      adi🎨 💻      Farhan Shaikh🎨 💻      Elvis Salvatierra🎨 💻      Kaushik-Iyer🎨 💻              HocAndres🎨 💻      VictorHugoAguilarAguilar🎨 💻      Murat Can Abay🎨 💻      Chris🎨 💻      Shivam7-1🎨 💻      Paipai13🎨 💻      Shambles-io🎨 💻              Abhishek K M🎨 💻      Ezequiel Cuevas🎨 💻      Plamen Ivanov🎨 💻      Yuji🎨 💻      Jean-Philippe Lebœuf🎨 💻 🔣      Naufan🎨 💻      jadnov🎨 💻              vaxtangens🎨 💻      subashkonar13🎨 💻      Rushi Javiya🎨 💻      Mert Gül🎨 💻      Lily🎨 💻      Kalinoff🎨 💻      Joel Tony🎨 💻              Peter🎨 💻      Roozbeh Zarei🎨 💻      Shen🎨 💻      Joonsoo.LEE🎨 💻      Fede.Breg🎨 💻      Rui Costa🎨 💻      João Gustavo Bispo🎨 💻              Sami-I🎨 💻      Tsvetoslav Tsvetkov🎨 💻      Olabode Olaniyi David🎨 💻      theRuslan🎨 💻      leighboz🎨 💻      Frank Sossi🎨 💻      Tomasz Adamski🎨 💻              Mansoor M. Sathir🎨 💻      Golamrabbi Azad🎨 💻      Nahian Ahmed🎨 💻      Rafael de Jesus Silva Monteiro🎨 💻      Odionyebuchukwu Jude🎨 💻      The Nithin Balaji🎨 💻      Knackii🎨 💻              vittorio-giatti🎨 💻      Guilherme de Carvalho Lima Rebouças🎨 💻      aaref shami🎨 💻      Andrey Dryupin🎨 💻      Muhanned Noman🎨 💻      Jan Silva🎨 💻      emanuele-em🎨 💻 🖋              Sanjay TM🎨 💻      Joe Markberg / code editor🎨 💻      Julien Quiaios🎨 💻      Eric Ramirez Santis🎨 💻      M🎨 💻      Malcata🎨 💻      Athul Muralidharan🎨 💻              Dariusz Ochota🎨 💻      CHANDAN CHOUDHURY🎨 💻      Deep🎨 💻      Ahmet İstemihan ÖZTÜRK🎨 💻      TIM🎨 💻      jakeg814🎨 💻      Leonidos🎨 💻              Abhinandu V Nair🎨 💻      charafeddine01🎨 💻      Jasper🎨 💻      Manish Goyal🎨 💻      SATYAM_SINGH🎨 💻      Four🎨 💻      Vaishnavi Amira Yada🎨 💻              ShriKrushna Bhagwat🎨 💻      Rohit Nandagawali🎨 💻      felipe🎨 💻 🚧 🖋 ✅ 🧑‍🏫      Saurabh Mudgal🎨 💻      szenadam🎨 💻      Shubhendra Singh🎨 💻      Yoosuf Sayyid💻 🎨              Güven Çetinerler🎨 💻      Luke Jefferies🎨 💻      Chris🎨 💻      Lúcio Aguiar💻      Enuma029💻      yktsang01💻      maximumn3rd🎨 💻              Jon Galletero🎨 💻      Thaddeus  Thomas🎨 💻      Aakash Kumar💻 🎨      Ali M🎨 💻      OskyEdz🎨 💻      Ravi Gupta🎨 💻      Rafa Raizer🎨 💻              Abdullah Al Muzaki🎨 💻      Rahul Faujdar🎨 💻      Abhishek Verma🎨 💻      Ashutosh Shinde🎨 💻      Ganesh Rai🎨 💻      StefanTrpkovic🎨 💻      Erik Blanca🎨 💻              Vedant Madane🎨 💻      Antra Tripathi🎨 💻      Ethan Knights🎨 💻      Alexandru Boncut🎨 💻      Pablo Bandinopla🎨 💻 🚧 🖋      Robz-99🎨 💻      Harpal Singh🎨 💻              paulboundy99🎨 💻      Mubashir Ahmed🎨 💻      Rohan Hari🎨 💻      Erik Henrique 🎨 💻      Leandro Matheus🎨 💻      Deepak🎨 💻      AlishaSingh🎨 💻              Lynn Latt Yati🎨 💻      San Shwe🎨 💻      SKR🎨 💻      msbunnyjaguar🎨 💻      Mohamad Zabiulla🎨 💻      Hatim Zahid🎨 💻      Rauzan Sumara🎨 💻              Hosein1358🎨 💻      Mohit🎨 💻      Ali🎨 💻      Avinash1765🎨 💻      Sai Teja Madha🎨 💻      Monsur Ahmed Shafiq🎨 💻      xuxianjin-dev🎨 💻              chetna🎨 💻      Gul Zaib🎨 💻      Natalia🎨 💻      Dionísio Braga🎨 💻      Pritish Rajpurohit🎨 💻      incanlove🎨 💻      Innocent🎨 💻              Devin Almonor🎨 💻      antonyveyre🎨 💻      Beltz Anhxton🎨 💻      Mehdi🎨 💻      Muhammad Usman🎨 💻      Patrick Dantas🎨 💻      Tak Vannak🎨 💻              Ramzi RADDAOUI🎨 💻      Konstantin-Glukhov🎨 💻      uguroban🎨 💻      Humberto Alves🎨 💻      JuangZendrato🎨 💻      James Oluwaleye🎨 💻      Wasi Sadman🎨 💻              Pavle Mijatovic🎨 💻      Luiz H. S. Bispo🎨 💻      Сухас Дхолз🎨 💻      Alvaro Trujillo🎨 💻      Everton 🎨 💻      jfrozas🎨 💻      Shuaaib Badran🎨 💻              Shivam Jha🎨 💻      Mohamed Tayeh🎨 💻      Makendran G🎨 💻      mayank singh tomar🎨 💻      hossam sadany🎨 💻      Harshbardhan Singh💻 🎨      Fawad Jawaid Malik🎨 💻              Tina Lacatis🎨 💻      TeddyCuoreDolce🎨 💻      bchooxg🎨 💻      Alisha Takkar🎨 💻      Gianluigi🎨 💻      Mehran Javaherian🎨 💻      Benjamin Ololade Adedokun🎨 💻              Md. Abdul Mutalib🎨 💻      Aadil Arsh.S.R🎨 💻      J. Nathan Allen🎨 💻      Kieran Krug🎨 💻      Seth Addo🎨 💻      Satvik Singh Rathore🎨 💻      dangoth🎨 💻              Maxim🎨 💻      Phuong-Cat Ngo🎨 💻      Frenchtoast0🎨 💻      Rakshith🎨 💻      Vaibhav Arora🎨 💻      zghp🎨 💻      Bedovan🎨 💻              chiaramistro🎨 💻      him2016🎨 💻      HarshitSachdeva🎨 💻      Sadaf Saleem🎨 💻      Aaroh Srivastava🎨 💻      eloygplaza🎨 💻      Gaurav Kumar Verma🎨 💻              AndreaCUS🎨 💻      Simran🎨 💻      Prashant Bhapkar🎨 💻      mhaendler🎨 💻      Gauri Maheshwari🎨 💻      4Lajf🎨 💻      Tanmoy Sengupta🎨 💻              Sharad Tripathi🎨 💻      Niraj Chavan🎨 💻      Luisa Gualda🎨 💻      Monika-Sivakumar-3🎨 💻      harryfensome🎨 💻      Shubham Choubey🎨 💻      Ashwini Patil🎨 💻              cleversonlira🎨 💻      Nurmukhammed🎨 💻      workspace-utkarsh🎨 💻      Santosh Phadtare🎨 💻      Prashant Warghude🎨 💻      Umang Dakh🎨 💻      Shalini Chavan🎨 💻              vinit gurjar🎨 💻      Vishal Kumar🎨 💻      Wonhyeong Seo🎨 💻      Achwale Prajwal Namdevrao🎨 💻      Ankan Banerjee🎨 💻      bhaumikankan🎨 💻      JamesMacroZhang🎨 💻              Pedro Lopes🎨 💻      dia🎨 💻      tayyabhussain2910🎨 💻      Rajdeep Shrivastava 🎨 💻      Mukul Kumar🎨 💻      Mayank N🎨 💻      jdelucca🎨 💻              Sneha Mittal🎨 💻      Sarika Kushwaha🎨 💻      farzad-khb🎨 💻      Elijah Shackelford🎨 💻      The-Only-Raminator🎨 💻      Keerthana Kasthuril🎨 💻      Viachaslau Auchynnikau🎨 💻              Mohammad Osman Rasooli🎨 💻      mvedovato🎨 💻      Sonali Rajput🎨 💻      Isha Dhek🎨 💻      Ramshad Cheriyeri Peediyakkal🎨 💻      Micah🎨 💻      gauravshukla2203🎨 💻              sndmurthy🎨 💻      Shivam-Singh🎨 💻      M. Ammar Khan🎨 💻      chandolakul🎨 💻      bhatnagar221🎨 💻      Adrian Nieściur🎨 💻      nezi311🎨 💻              scottajevans🎨 💻      Marcelo Antunes Soares Fantini🎨 💻      Axel De Acetis🎨 💻      Drishti Sah🎨 💻      VipulDhillon🎨 💻      Urmi Jana🎨 💻      Ayush Mokal🎨 💻              Damola Olutoke🎨 💻      Max🎨 💻      Lakshmi N🎨 💻      ArtemReva🎨 💻      Ujjwal Aggarwal🎨 💻      Mo🎨 💻      Brian🎨 💻              chamley🎨 💻      Simone Baptiste🎨 💻      Shekhar Thakur🎨 💻      Smith🎨 💻      codernoob1🎨 💻      lok84🎨 💻      Tobias Riemenschneider🎨 💻              Tharsanan1🎨 💻      ANURAG SINGH🎨 💻      Yash Sant🎨 💻      Krishiv Patel🎨 💻      GGGalaxy🎨 💻      pardeepdhillon661🎨 💻      anujd64🎨 💻              Pedro Pereira🎨 💻      Master_Saptak🎨 💻      SURANJAN DAS🎨 💻      Tripura kant🎨 💻      shabzkhan🎨 💻      Mustafa Poya🎨 💻      Roshan Jha🎨 💻              GuillaumeLarue🎨 💻      Tomasz Rodak🎨 💻      Junil Kim🎨 💻      Surbhi Mayank🎨 💻      Nemanja Lekic🎨 💻      HemantMalokar🎨 💻      Felipe M. López🎨 💻              bibliofilo🎨 💻      GauthamG2🎨 💻      02_t🎨 💻      Yusuf Abdul-razaq🎨 💻      Vladimir🎨 💻      Sai Chandra K🎨 💻      Soroush Bonab🎨 💻              Giide0n🎨 💻      GG🎨 💻      Dáger Zúñiga🎨 💻      rsk2🎨 💻      Storozhev DJ🎨 💻      Jeevan🎨 💻      Andy Johnson🎨 💻              Aníbal Pozo🎨 💻      Jovane de Castro🎨 💻      Muhammad Hamza Amir🎨 💻      tharaka-mts🎨 💻      Ali KHYAR🎨 💻      Caio Araujo🎨 💻      Oscar Dyremyhr🎨 💻              arteality🎨 💻      Daniel Drexlmaier🎨 💻      Marco Monti🎨 💻      mikeycrystal🎨 💻      Veljanovskii🎨 💻      Ivan Gorbachev🎨 💻      Sahil Rawat🎨 💻              Hasitha Suneth🎨 💻      Yerko Vera Lezama🎨 💻      Ivan Penchev🎨 💻      Tanver Islam Tonmoy🎨 💻      Xun Cao🎨 💻      Nayan Babariya🎨 💻      Priyanshu Maurya🎨 💻              Dylan Tintenfich🎨 💻      Ron Strauss🎨 💻      Mohammed AlBanna🎨 💻      Mukund M🎨 💻      Franklin Ohaegbulam🎨 💻      Nisarg Shah🎨 💻      Unik Dahal🎨 💻              Readily🎨 💻      Alexandre Poitevin🎨 💻      Scaramir🎨 💻      Pruthvi🎨 💻      Kalmanq🎨 💻      Alfatah Nesab🎨 💻      arudesai🎨 💻              Adryenne🎨 💻      El mehdi oudaoud🎨 💻      Jayant Goel🎨 💻      Tsuki🎨 💻      Peter Lemanski🎨 💻      Annurag-byte🎨 💻      Anthony Vu🎨 💻              Vitaly Nikolaychuk🎨 💻      Nathan🎨 💻      Evgenii Petukhov🎨 💻      Loris Guerra🎨 💻      fakhriaunur🎨 💻      Mehdi HYANI🎨 💻      Sarvex Jatasra🎨 💻              santimanuelr🎨 💻      Evgeniy Rezanov🎨 💻      Sonia M🎨 💻      Grzegorz Kmita🎨 💻      Manuel Carita🎨 💻      Felipe Cisternas Alvarez🎨 💻      Guo Ci🎨 💻              Marcos Silva🎨 💻      KK🎨 💻      Shubhanjan Medhi🎨 💻      ArthurFerreiraRodrigues🎨 💻      PabloHermun🎨 💻      disha-baldawa🎨 💻      StaroMoon🎨 💻              Amila T Kumarasekara🎨 💻      Amoh Prince🎨 💻      AngeloGC🎨 💻      Ebube Glory Ogbonda🎨 💻      Prahalad Belavadi📖      Antoni Sarnowski-Trypka🎨 💻      Alberto Pasqualetto🎨 💻              Amir Babaei🎨 💻      Syed Abdul Hannan🎨 💻      Srajan Rai🎨 💻      Clarence Moore🎨 💻      Nguyen Anh Tuan🎨 💻      dar2dar2🎨 💻      Ameer Ibrahim🎨 💻              Tiago Lugatto🎨 💻      raremiroir🎨 💻      Moobie🎨 💻      AlicanDursun🎨 💻      bbalsam🎨 💻      Luboš Hájek🎨 💻      mrshahzeb7🎨 💻              Wesley Scholl🎨 💻      Lawrence Turcotte🎨 💻      Michael DiPaolo🎨 💻      Smart-Codi🎨 💻      Vivek Kumar🎨 💻      Igor Moiseev🎨 💻      Bård Pedersen🎨 💻              HOA PHAN🎨 💻      GaborModra🎨 💻      vivek-114🎨 💻      Robin🎨 💻      Alex🎨 💻      John Ehrlinger🎨 💻      Roman Zhuravlov🎨 💻              Jordan Moss🎨 💻      RaeShelly🎨 💻      gmollard🎨 💻      Md Kaif Khan🎨 💻      Pablo Romera🎨 💻      Erik Bustos🎨 💻      trogfield🎨 💻              simon-aichhorn🎨 💻      Tufan GÜLEÇ🎨 💻      Uğur Berkecan Ünlü🎨 💻      Revanth Naik🎨 💻      Lia Pires🎨 💻      Igor Mestechkin🎨 💻      Anirudh Karanth🎨 💻              KBobovskiy🎨 💻      zhatiayua🎨 💻 🖋      David Cardona🎨 💻      Paulo Castilho🎨 💻      Sebastiano Picchi🎨 💻      pjotar🎨 💻      Rimel CHERIF💻              Arsal uddin🖋      Dmitry Kasporsky💻      SoftwareDev1014🎨 💻      @Robvred🎨 💻      Kasun Shanaka💻      Ahmad M.🎨 💻      Alex Kozin🎨 💻              Mandy Meindersma🎨 💻      LEGALISE PIRACY🎨 💻      Alex Logvin🎨 💻      Aria Dahl🎨 💻      Mustafa Arifoglu🎨 💻      Yevhen Leshchenko🎨 💻      Anubhav Adhikari🎨 💻              Noah Tatko🎨 💻      Mohit Gadhavi🎨 💻      Pedro Basílio🎨 💻      RealSanjeev🎨 💻      Akash Hazra🎨 💻      Christoph Dahlen🎨 💻      Vincent du Plessis🎨 💻              Karen Tamrazyan🎨 💻      Mirza Younus Baig🎨 💻      Ashish Kumar🎨 💻      Unknown6334🎨 💻      flowaz🎨 💻      zi-aikra🎨 💻      PAYAL PM🎨 💻              Lennart Lösche🎨 💻      Yummy-Yums🎨 💻      Njuacha Hubert Mikulowski🎨 💻      Hussein Esmail🎨 💻      Bilgehan Bezir🎨 💻      Muhammed Shittu🎨 💻      Clément FERNANDES🎨 💻              JaCKoP619🎨 💻      userutf8🎨 💻      Mohamed Ubaid🎨 💻      Justin Yates🎨 💻      mohammad ali🎨 💻      Madhav Singh🎨 💻      RgbMouse69🎨 💻              Nicholas Leask🎨 💻      parthav0🎨 💻      Sigma🎨 💻      Evelina Becheva🎨 💻      Akshit Gulyan🎨 💻      Arpita Jana🎨 💻      Praveen Kumar🎨 💻              Mohammad Sami🎨 💻      eddiestefanescu🎨 💻      Ramesh Yadav🎨 💻      Sarthak Joshi🎨 💻      Nikhil12300🎨 💻      Yevgen🎨 💻      Leo🎨 💻              laurent b🎨 💻      Mettchen🎨 💻      Ali Mahdavi🎨 💻      Lucas Dondo🎨 💻      Siddhesh Agarwal🎨 💻      slimerPuncher🎨 💻      saritashh🎨 💻              Iulian-Valeriu Cioată🎨 💻      Szabolcs Nagy🎨 💻      Jarle Kvile🎨 💻      劉耀升 Vic Liu🎨 💻      Suryansh🎨 💻      Matthew Oosthuyse🎨 💻      Florin Zamfir🎨 💻              Melek🎨 💻      moesocio🎨 💻      Alan James🎨 💻      Mai Thanh Phương🎨 💻      Neville Dabre🎨 💻      Maksym🎨 💻      tamanna900🎨 💻              Adithya Awati🎨 💻      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
23,wangzheng0822/algo,https://github.com/wangzheng0822/algo/blob/master/README.md,Python,数据结构和算法必知必会的50个代码实现微信搜索我的公众号“小争哥”，或者微信扫描下面二维码关注关注微信公众号，回复”PDF“获取独家算法资料。前Google工程师，10万人跟着学的《数据结构和算法之美》《设计模式之美》专栏作者数组实现一个支持动态扩容的数组实现一个大小固定的有序数组，支持动态增删改操作实现两个有序数组合并为一个有序数组链表实现单链表、循环链表、双向链表，支持增删操作实现单链表反转实现两个有序的链表合并为一个有序链表实现求链表的中间结点栈用数组实现一个顺序栈用链表实现一个链式栈编程模拟实现一个浏览器的前进、后退功能队列用数组实现一个顺序队列用链表实现一个链式队列实现一个循环队列递归编程实现斐波那契数列求值f(n)=f(n-1)+f(n-2)编程实现求阶乘n!编程实现一组数据集合的全排列排序实现归并排序、快速排序、插入排序、冒泡排序、选择排序编程实现O(n)时间复杂度内找到一组数据的第K大元素二分查找实现一个有序数组的二分查找算法实现模糊二分查找算法（比如大于等于给定值的第一个元素）散列表实现一个基于链表法解决冲突问题的散列表实现一个LRU缓存淘汰算法字符串实现一个字符集，只包含a～z这26个英文字母的Trie树实现朴素的字符串匹配算法二叉树实现一个二叉查找树，并且支持插入、删除、查找操作实现查找二叉查找树中某个节点的后继、前驱节点实现二叉树前、中、后序以及按层遍历堆实现一个小顶堆、大顶堆、优先级队列实现堆排序利用优先级队列合并K个有序数组求一组动态数据集合的最大Top K图实现有向图、无向图、有权图、无权图的邻接矩阵和邻接表表示方法实现图的深度优先搜索、广度优先搜索实现Dijkstra算法、A*算法实现拓扑排序的Kahn算法、DFS算法回溯利用回溯算法求解八皇后问题利用回溯算法求解0-1背包问题分治利用分治算法求一组数据的逆序对个数动态规划0-1背包问题最小路径和编程实现莱文斯坦最短编辑距离编程实现查找两个字符串的最长公共子序列编程实现一个数据序列的最长递增子序列
24,encode/django-rest-framework,https://github.com/encode/django-rest-framework/blob/master/README.md,Python,"Django REST frameworkAwesome web-browsable Web APIs.Full documentation for the project is available at https://www.django-rest-framework.org/.FundingREST framework is a collaboratively funded project. If you useREST framework commercially we strongly encourage you to invest in itscontinued development by signing up for a paid plan.The initial aim is to provide a single full-time position on REST framework.Every single sign-up makes a significant impact towards making that possible.Many thanks to all our wonderful sponsors, and in particular to our premium backers, Sentry, Stream, Spacinov, Retool, bit.io, PostHog, CryptAPI, and FEZTO.OverviewDjango REST framework is a powerful and flexible toolkit for building Web APIs.Some reasons you might want to use REST framework:The Web browsable API is a huge usability win for your developers.Authentication policies including optional packages for OAuth1a and OAuth2.Serialization that supports both ORM and non-ORM data sources.Customizable all the way down - just use regular function-based views if you don't need the more powerful features.Extensive documentation, and great community support.There is a live example API for testing purposes, available here.Below: Screenshot from the browsable APIRequirementsPython 3.6+Django 4.2, 4.1, 4.0, 3.2, 3.1, 3.0We highly recommend and only officially support the latest patch release ofeach Python and Django series.InstallationInstall using pip...pip install djangorestframeworkAdd 'rest_framework' to your INSTALLED_APPS setting.INSTALLED_APPS = [    ...    'rest_framework',]ExampleLet's take a look at a quick example of using REST framework to build a simple model-backed API for accessing users and groups.Startup up a new project like so...pip install djangopip install djangorestframeworkdjango-admin startproject example ../manage.py migrate./manage.py createsuperuserNow edit the example/urls.py module in your project:from django.contrib.auth.models import Userfrom django.urls import include, pathfrom rest_framework import routers, serializers, viewsets# Serializers define the API representation.class UserSerializer(serializers.HyperlinkedModelSerializer):    class Meta:        model = User        fields = ['url', 'username', 'email', 'is_staff']# ViewSets define the view behavior.class UserViewSet(viewsets.ModelViewSet):    queryset = User.objects.all()    serializer_class = UserSerializer# Routers provide a way of automatically determining the URL conf.router = routers.DefaultRouter()router.register(r'users', UserViewSet)# Wire up our API using automatic URL routing.# Additionally, we include login URLs for the browsable API.urlpatterns = [    path('', include(router.urls)),    path('api-auth/', include('rest_framework.urls', namespace='rest_framework')),]We'd also like to configure a couple of settings for our API.Add the following to your settings.py module:INSTALLED_APPS = [    ...  # Make sure to include the default installed apps here.    'rest_framework',]REST_FRAMEWORK = {    # Use Django's standard `django.contrib.auth` permissions,    # or allow read-only access for unauthenticated users.    'DEFAULT_PERMISSION_CLASSES': [        'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly',    ]}That's it, we're done!./manage.py runserverYou can now open the API in your browser at http://127.0.0.1:8000/, and view your new 'users' API. If you use the Login control in the top right corner you'll also be able to add, create and delete users from the system.You can also interact with the API using command line tools such as curl. For example, to list the users endpoint:$ curl -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/[    {        \""url\"": \""http://127.0.0.1:8000/users/1/\"",        \""username\"": \""admin\"",        \""email\"": \""admin@example.com\"",        \""is_staff\"": true,    }]Or to create a new user:$ curl -X POST -d username=new -d email=new@example.com -d is_staff=false -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/{    \""url\"": \""http://127.0.0.1:8000/users/2/\"",    \""username\"": \""new\"",    \""email\"": \""new@example.com\"",    \""is_staff\"": false,}Documentation & SupportFull documentation for the project is available at https://www.django-rest-framework.org/.For questions and support, use the REST framework discussion group, or #restframework on libera.chat IRC.You may also want to follow the author on Twitter.SecurityPlease see the security policy."
25,saltstack/salt,https://github.com/saltstack/salt/blob/master/README.rst,Python,"Latest Salt DocumentationOpen an issue (bug report, feature request, etc.)Salt is the world's fastest, most intelligent and scalable automationengine.About SaltBuilt on Python, Salt is an event-driven automation tool and framework todeploy, configure, and manage complex IT systems. Use Salt to automate commoninfrastructure administration tasks and ensure that all the components of yourinfrastructure are operating in a consistent desired state.Salt has many possible uses, including configuration management, which involves:Managing operating system deployment and configuration.Installing and configuring software applications and services.Managing servers, virtual machines, containers, databases, web servers,network devices, and more.Ensuring consistent configuration and preventing configuration drift.Salt is ideal for configuration management because it is pluggable,customizable, and plays well with many existing technologies. Salt enables youto deploy and manage applications that use any tech stack running on nearly anyoperating system,including different types of network devices such as switches and routers from avariety of vendors.In addition to configuration management Salt can also:Automate and orchestrate routine IT processes, such as common required tasksfor scheduled server downtimes or upgrading operating systems or applications.Create self-aware, self-healing systems that can automatically respond tooutages, common administration problems, or other important events.About our sponsorsSalt powers VMware's VMware Aria Automation Config(previously vRealize Automation SaltStack Config / SaltStack Enterprise), and can be foundunder the hood of products from Juniper, Cisco, Cloudflare, Nutanix, SUSE, andTieto, to name a few.The original sponsor of our community, SaltStack, was acquired by VMware in 2020.The Salt Project remains an open source ecosystem that VMware supports andcontributes to. VMware ensures the code integrity and quality of the Saltmodules by acting as the official sponsor and manager of the Salt project. Manyof the core Salt Project contributors are also VMware employees. This teamcarefully reviews and enhances the Salt modules to ensure speed, quality, andsecurity.Download and install SaltSalt is tested and packaged to run on CentOS, Debian, RHEL, Ubuntu, MacOS,Windows, and more. Download Salt and get started now. Seesupported operating systemsfor more information.To download and install Salt, see:* The Salt install guide* Salt Project repositoryTechnical supportReport bugs or problems using Salt by opening an issue: https://github.com/saltstack/salt/issuesTo join our community forum where you can exchange ideas, best practices,discuss technical support questions, and talk to project maintainers, join ourSlack workspace: Salt Project Community SlackSalt Project documentationInstallation instructions, tutorials, in-depth API and module documentation:The Salt install guideThe Salt user guideLatest Salt documentationSalt's contributing guideSecurity advisoriesKeep an eye on the Salt ProjectSecurity Announcementslanding page. Salt Project recommends subscribing to theSalt Project Security RSS feedto receive notification when new information is available regarding securityannouncements.Other channels to receive security announcements include theSalt Community mailing listand the Salt Project Community Slack.Responsibly reporting security vulnerabilitiesWhen reporting security vulnerabilities for Salt or other SaltStack projects,refer to the SECURITY.md file found in this repository.Join our communitySalt is built by the Salt Project community, which includes more than 3,000contributors working in roles just like yours. This well-known and trustedcommunity works together to improve the underlying technology and extend Salt bycreating a variety of execution and state modules to accomplish the most commontasks or solve the most important problems that people in your role are likelyto face.If you want to help extend Salt or solve a problem with Salt, you can join ourcommunity and contribute today.Please be sure to review ourCode of Conduct.Also, check out some of our community resources including:Salt Project Community WikiSalt Project Community SlackSalt Project: IRC on LiberaChatSalt Project YouTube channelSalt Project Twitch channelThere are lots of ways to get involved in our community. Every month, there arearound a dozen opportunities to meet with other contributors and the Salt Coreteam and collaborate in real time. The best way to keep track is by subscribingto the Salt Project Community Events Calendar on the mainhttps://saltproject.io website.If you have additional questions, email us at saltproject@vmware.com or reach outdirectly to the Community Manager, Jimmy Chunga via Slack. We'd be glad tohave you join our community!LicenseSalt is licensed under the Apache 2.0 license. Pleasesee theLICENSE file for thefull text of the Apache license, followed by a full summary of the licensingused by external modules.A complete list of attributions and dependencies can be found here:salt/DEPENDENCIES.md"
26,openai/gpt-2,https://github.com/openai/gpt-2/blob/master/README.md,Python,"Status: Archive (code is provided as-is, no updates expected)gpt-2Code and models from the paper \""Language Models are Unsupervised Multitask Learners\"".You can read about GPT-2 and its staged release in our original blog post, 6 month follow-up post, and final post.We have also released a dataset for researchers to study their behaviors.* Note that our original parameter counts were wrong due to an error (in our previous blog posts and paper).  Thus you may have seen small referred to as 117M and medium referred to as 345M.UsageThis repository is meant to be a starting point for researchers and engineers to experiment with GPT-2.For basic information, see our model card.Some caveatsGPT-2 models' robustness and worst case behaviors are not well-understood.  As with any machine-learned model, carefully evaluate GPT-2 for your use case, especially if used without fine-tuning or in safety-critical applications where reliability is important.The dataset our GPT-2 models were trained on contains many texts with biases and factual inaccuracies, and thus GPT-2 models are likely to be biased and inaccurate as well.To avoid having samples mistaken as human-written, we recommend clearly labeling samples as synthetic before wide dissemination.  Our models are often incoherent or inaccurate in subtle ways, which takes more than a quick read for a human to notice.Work with usPlease let us know if you’re doing interesting research with or working on applications of GPT-2!  We’re especially interested in hearing from and potentially working with those who are studyingPotential malicious use cases and defenses against them (e.g. the detectability of synthetic text)The extent of problematic content (e.g. bias) being baked into the models and effective mitigationsDevelopmentSee DEVELOPERS.mdContributorsSee CONTRIBUTORS.mdCitationPlease use the following bibtex entry:@article{radford2019language,  title={Language Models are Unsupervised Multitask Learners},  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},  year={2019}}Future workWe may release code for evaluating the models on various benchmarks.We are still considering release of the larger models.LicenseModified MIT"
27,jumpserver/jumpserver,https://github.com/jumpserver/jumpserver/blob/dev/README.md,Python,"  广受欢迎的开源堡垒机            JumpServer v3.0 正式发布。        9 年时间，倾情投入，用心做好一款开源堡垒机。JumpServer 是广受欢迎的开源堡垒机，是符合 4A 规范的专业运维安全审计系统。JumpServer 堡垒机帮助企业以更安全的方式管控和登录各种类型的资产，包括：SSH: Linux / Unix / 网络设备 等；Windows: Web 方式连接 / 原生 RDP 连接；数据库: MySQL / MariaDB / PostgreSQL / Oracle / SQLServer / ClickHouse 等；NoSQL: Redis / MongoDB 等；GPT: ChatGPT 等;云服务: Kubernetes / VMware vSphere 等;Web 站点: 各类系统的 Web 管理后台；应用: 通过 Remote App 连接各类应用。产品特色开源: 零门槛，线上快速获取和安装；无插件: 仅需浏览器，极致的 Web Terminal 使用体验；分布式: 支持分布式部署和横向扩展，轻松支持大规模并发访问；多云支持: 一套系统，同时管理不同云上面的资产；多租户: 一套系统，多个子公司或部门同时使用；云端存储: 审计录像云端存储，永不丢失；UI 展示在线体验环境地址：https://demo.jumpserver.org/⚠️ 注意该环境仅作体验目的使用，我们会定时清理、重置数据！请勿修改体验环境用户的密码！请勿在环境中添加业务生产环境地址、用户名密码等敏感信息！快速开始快速入门产品文档在线学习知识库案例研究腾讯海外游戏：基于JumpServer构建游戏安全运营能力万华化学：通过JumpServer管理全球化分布式IT资产，并且实现与云管平台的联动雪花啤酒：JumpServer堡垒机使用体会顺丰科技：JumpServer 堡垒机护航顺丰科技超大规模资产安全运维沐瞳游戏：通过JumpServer管控多项目分布式资产携程：JumpServer 堡垒机部署与运营实战大智慧：JumpServer 堡垒机让“大智慧”的混合 IT 运维更智慧小红书：JumpServer 堡垒机大规模资产跨版本迁移之路中手游：JumpServer堡垒机助力中手游提升多云环境下安全运维能力中通快递：JumpServer主机安全运维实践东方明珠：JumpServer高效管控异构化、分布式云端资产江苏农信：JumpServer堡垒机助力行业云安全运维社区交流如果您在使用过程中有任何疑问或对建议，欢迎提交 GitHub Issue。您也可以到我们的 社区论坛 当中进行交流沟通。参与贡献欢迎提交 PR 参与贡献。 参考 CONTRIBUTING.md组件项目项目状态描述LinaJumpServer Web UI 项目LunaJumpServer Web Terminal 项目KoKoJumpServer 字符协议 Connector 项目LionJumpServer 图形协议 Connector 项目，依赖 Apache GuacamoleRazorJumpServer RDP 代理 Connector 项目TinkerJumpServer 远程应用 Connector 项目MagnusJumpServer 数据库代理 Connector 项目ChenJumpServer Web DB 项目，替代原来的 OmniDBKaelJumpServer 连接 GPT 资产的组件项目WispJumpServer 各系统终端组件和 Core Api 通信的组件项目ClientsJumpServer 客户端 项目InstallerJumpServer 安装包 项目安全说明JumpServer是一款安全产品，请参考 基本安全建议进行安装部署。如果您发现安全相关问题，请直接联系我们：邮箱：support@fit2cloud.com电话：400-052-0755License & CopyrightCopyright (c) 2014-2023 飞致云 FIT2CLOUD, All rights reserved.Licensed under The GNU General Public License version 3 (GPLv3)  (the \""License\""); you may not use this file except incompliance with the License. You may obtain a copy of the License athttps://www.gnu.org/licenses/gpl-3.0.htmlUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \""AS IS\"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specificlanguage governing permissions and limitations under the License."
28,celery/celery,https://github.com/celery/celery/blob/main/README.rst,Python,"        Version:5.3.1 (emerald-rush)Web:https://docs.celeryq.dev/en/stable/index.htmlDownload:https://pypi.org/project/celery/Source:https://github.com/celery/celery/Keywords:task, queue, job, async, rabbitmq, amqp, redis,python, distributed, actorsDonationsThis project relies on your generous donations.If you are using Celery to create a commercial product, please consider becoming our backer or our sponsor to ensure Celery's future.For enterpriseAvailable as part of the Tidelift Subscription.The maintainers of celery and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more.What's a Task Queue?Task queues are used as a mechanism to distribute work across threads ormachines.A task queue's input is a unit of work, called a task, dedicated workerprocesses then constantly monitor the queue for new work to perform.Celery communicates via messages, usually using a brokerto mediate between clients and workers. To initiate a task a client puts amessage on the queue, the broker then delivers the message to a worker.A Celery system can consist of multiple workers and brokers, giving wayto high availability and horizontal scaling.Celery is written in Python, but the protocol can be implemented in anylanguage. In addition to Python there's node-celery for Node.js,a PHP client, gocelery, gopher-celery for Go, and rusty-celery for Rust.Language interoperability can also be achieved by using webhooksin such a way that the client enqueues an URL to be requested by a worker.What do I need?Celery version 5.3.1 runs on:Python (3.8, 3.9, 3.10, 3.11)PyPy3.8+ (v7.3.11+)This is the version of celery which will support Python 3.8 or newer.If you're running an older version of Python, you need to be runningan older version of Celery:Python 3.7: Celery 5.2 or earlier.Python 3.6: Celery 5.1 or earlier.Python 2.7: Celery 4.x series.Python 2.6: Celery series 3.1 or earlier.Python 2.5: Celery series 3.0 or earlier.Python 2.4: Celery series 2.2 or earlier.Celery is a project with minimal funding,so we don't support Microsoft Windows but it should be working.Please don't open any issues related to that platform.Celery is usually used with a message broker to send and receive messages.The RabbitMQ, Redis transports are feature complete,but there's also experimental support for a myriad of other solutions, includingusing SQLite for local development.Celery can run on a single machine, on multiple machines, or evenacross datacenters.Get StartedIf this is the first time you're trying to use Celery, or you'renew to Celery v5.3.1 coming from previous versions then you should read ourgetting started tutorials:First steps with CeleryTutorial teaching you the bare minimum needed to get started with Celery.Next stepsA more complete overview, showing more features.You can also get started with Celery by using a hosted broker transport CloudAMQP. The largest hosting provider of RabbitMQ is a proud sponsor of Celery.Celery is...SimpleCelery is easy to use and maintain, and does not need configuration files.It has an active, friendly community you can talk to for support,like at our mailing-list, or the IRC channel.Here's one of the simplest applications you can make:from celery import Celeryapp = Celery('hello', broker='amqp://guest@localhost//')@app.taskdef hello():    return 'hello world'Highly AvailableWorkers and clients will automatically retry in the eventof connection loss or failure, and some brokers supportHA in way of Primary/Primary or Primary/Replica replication.FastA single Celery process can process millions of tasks a minute,with sub-millisecond round-trip latency (using RabbitMQ,py-librabbitmq, and optimized settings).FlexibleAlmost every part of Celery can be extended or used on its own,Custom pool implementations, serializers, compression schemes, logging,schedulers, consumers, producers, broker transports, and much more.It supports...Message TransportsRabbitMQ, Redis, Amazon SQSConcurrencyPrefork, Eventlet, gevent, single threaded (solo)Result StoresAMQP, RedismemcachedSQLAlchemy, Django ORMApache Cassandra, IronCache, ElasticsearchSerializationpickle, json, yaml, msgpack.zlib, bzip2 compression.Cryptographic message signing.Framework IntegrationCelery is easy to integrate with web frameworks, some of which even haveintegration packages:Djangonot neededPyramidpyramid_celeryPylonscelery-pylonsFlasknot neededweb2pyweb2py-celeryTornadotornado-celeryThe integration packages aren't strictly necessary, but they can makedevelopment easier, and sometimes they add important hooks like closingdatabase connections at fork.DocumentationThe latest documentation is hosted at Read The Docs, containing user guides,tutorials, and an API reference.最新的中文文档托管在 https://www.celerycn.io/ 中，包含用户指南、教程、API接口等。InstallationYou can install Celery either via the Python Package Index (PyPI)or from source.To install using pip:$ pip install -U CeleryBundlesCelery also defines a group of bundles that can be usedto install Celery and the dependencies for a given feature.You can specify these in your requirements or on the pipcommand-line by using brackets. Multiple bundles can be specified byseparating them by commas.$ pip install \""celery[redis]\""$ pip install \""celery[redis,auth,msgpack]\""The following bundles are available:Serializerscelery[auth]:for using the auth security serializer.celery[msgpack]:for using the msgpack serializer.celery[yaml]:for using the yaml serializer.Concurrencycelery[eventlet]:for using the eventlet pool.celery[gevent]:for using the gevent pool.Transports and Backendscelery[amqp]:for using the RabbitMQ amqp python library.celery[redis]:for using Redis as a message transport or as a result backend.celery[sqs]:for using Amazon SQS as a message transport.celery[tblib]:for using the task_remote_tracebacks feature.celery[memcache]:for using Memcached as a result backend (using pylibmc)celery[pymemcache]:for using Memcached as a result backend (pure-Python implementation).celery[cassandra]:for using Apache Cassandra/Astra DB as a result backend with the DataStax driver.celery[azureblockblob]:for using Azure Storage as a result backend (using azure-storage)celery[s3]:for using S3 Storage as a result backend.celery[couchbase]:for using Couchbase as a result backend.celery[arangodb]:for using ArangoDB as a result backend.celery[elasticsearch]:for using Elasticsearch as a result backend.celery[riak]:for using Riak as a result backend.celery[cosmosdbsql]:for using Azure Cosmos DB as a result backend (using pydocumentdb)celery[zookeeper]:for using Zookeeper as a message transport.celery[sqlalchemy]:for using SQLAlchemy as a result backend (supported).celery[pyro]:for using the Pyro4 message transport (experimental).celery[slmq]:for using the SoftLayer Message Queue transport (experimental).celery[consul]:for using the Consul.io Key/Value store as a message transport or result backend (experimental).celery[django]:specifies the lowest version possible for Django support.You should probably not use this in your requirements, it's herefor informational purposes only.Downloading and installing from sourceDownload the latest version of Celery from PyPI:https://pypi.org/project/celery/You can install it by doing the following:$ tar xvfz celery-0.0.0.tar.gz$ cd celery-0.0.0$ python setup.py build# python setup.py installThe last command must be executed as a privileged user ifyou aren't currently using a virtualenv.Using the development versionWith pipThe Celery development version also requires the developmentversions of kombu, amqp, billiard, and vine.You can install the latest snapshot of these using the followingpip commands:$ pip install https://github.com/celery/celery/zipball/main#egg=celery$ pip install https://github.com/celery/billiard/zipball/main#egg=billiard$ pip install https://github.com/celery/py-amqp/zipball/main#egg=amqp$ pip install https://github.com/celery/kombu/zipball/main#egg=kombu$ pip install https://github.com/celery/vine/zipball/main#egg=vineWith gitPlease see the Contributing section.Getting HelpMailing listFor discussions about the usage, development, and future of Celery,please join the celery-users mailing list.IRCCome chat with us on IRC. The #celery channel is located at theLibera Chat network.Bug trackerIf you have any suggestions, bug reports, or annoyances please report themto our issue tracker at https://github.com/celery/celery/issues/Wikihttps://github.com/celery/celery/wikiCreditsContributorsThis project exists thanks to all the people who contribute. Development ofcelery happens at GitHub: https://github.com/celery/celeryYou're highly encouraged to participate in the developmentof celery. If you don't like GitHub (for some reason) you're welcometo send regular patches.Be sure to also read the Contributing to Celery section in thedocumentation.BackersThank you to all our backers! 🙏 [Become a backer]SponsorsSupport this project by becoming a sponsor. Your logo will show up here with alink to your website. [Become a sponsor]LicenseThis software is licensed under the New BSD License. See the LICENSEfile in the top distribution directory for the full license text."
29,donnemartin/system-design-primer,https://github.com/donnemartin/system-design-primer/blob/master/README-ja.md,Python,"English ∙ 日本語 ∙ 简体中文 ∙ 繁體中文 | العَرَبِيَّة‎ ∙ বাংলা ∙ Português do Brasil ∙ Deutsch ∙ ελληνικά ∙ עברית ∙ Italiano ∙ 한국어 ∙ فارسی ∙ Polski ∙ русский язык ∙ Español ∙ ภาษาไทย ∙ Türkçe ∙ tiếng Việt ∙ Français | Add Translationシステム設計入門    動機・目的大規模システムのシステム設計を学ぶシステム設計面接課題に備える大規模システムの設計を学ぶスケーラブルなシステムのシステム設計を学ぶことは、より良いエンジニアになることに資するでしょう。システム設計はとても広範なトピックを含みます。システム設計原理については インターネット上には膨大な量の文献が散らばっています。このリポジトリは大規模システム構築に必要な知識を学ぶことができる 文献リストを体系的にまとめたもの です。オープンソースコミュニティから学ぶこのプロジェクトは、これからもずっと更新されていくオープンソースプロジェクトの初期段階にすぎません。Contributions は大歓迎です！システム設計面接課題に備えるコード技術面接に加えて、システム設計に関する知識は、多くのテック企業における 技術採用面接プロセス で 必要不可欠な要素 です。システム設計面接での頻出質問に備え、自分の解答と模範解答:ディスカッション、コードそして図表などを比較して学びましょう。面接準備に役立つその他のトピック:学習指針システム設計面接課題にどのように準備するかシステム設計課題例 とその解答オブジェクト指向設計課題例、 とその解答その他のシステム設計面接課題例暗記カード    このAnki用フラッシュカードデッキ は、間隔反復を活用して、システム設計のキーコンセプトの学習を支援します。システム設計デッキシステム設計練習課題デッキオブジェクト指向練習課題デッキ外出先や移動中の勉強に役立つでしょう。コーディング技術課題用の問題: 練習用インタラクティブアプリケーションコード技術面接用の問題を探している場合はこちら    姉妹リポジトリの Interactive Coding Challengesも見てみてください。追加の暗記デッキカードも入っています。Coding deckコントリビュートコミュニティから学ぶプルリクエスト等の貢献は積極的にお願いします:エラー修正セクション内容改善新規セクション追加翻訳する現在、内容の改善が必要な作業中のコンテンツはこちらです。コントリビュートの前にContributing Guidelinesを読みましょう。システム設計目次賛否も含めた様々なシステム設計の各トピックの概要。 全てはトレードオフの関係にあります。それぞれのセクションはより学びを深めるような他の文献へのリンクが貼られています。    システム設計トピック: まずはここからStep 1: スケーラビリティに関する動画を見るStep 2: スケーラビリティに関する記事を読む次のステップパフォーマンス vs スケーラビリティレイテンシー vs スループット可用性 vs 一貫性CAP理論CP - 一貫性(consistency)と分割性(partition)耐性AP - 可用性(availability)と分割性(partition)耐性一貫性 パターン弱い一貫性結果整合性強い一貫性可用性 パターンフェイルオーバーレプリケーションドメインネームシステム(DNS)コンテンツデリバリーネットワーク(CDN)プッシュCDNプルCDNロードバランサーアクティブ/パッシブ構成アクティブ/アクティブ構成Layer 4 ロードバランシングLayer 7 ロードバランシング水平スケーリングリバースプロキシ (WEBサーバー)ロードバランサー vs リバースプロキシアプリケーションレイヤーマイクロサービスサービスディスカバリーデータベースリレーショナルデータベースマネジメントシステム (RDBMS)マスター/スレーブ レプリケーションマスター/マスター レプリケーションフェデレーションシャーディングデノーマライゼーションSQL チューニングNoSQLキー/バリューストアドキュメントストアワイドカラムストアグラフ データベースSQL or NoSQLキャッシュクライアントキャッシングCDNキャッシングWebサーバーキャッシングデータベースキャッシングアプリケーションキャッシングデータベースクエリレベルでキャッシングするオブジェクトレベルでキャッシングするいつキャッシュを更新するのかキャッシュアサイドライトスルーライトビハインド (ライトバック)リフレッシュアヘッド非同期処理メッセージキュータスクキューバックプレッシャー通信伝送制御プロトコル (TCP)ユーザデータグラムプロトコル (UDP)遠隔手続呼出 (RPC)Representational state transfer (REST)セキュリティ補遺2の乗数表全てのプログラマーが知るべきレイテンシー値他のシステム設計面接例題実世界でのアーキテクチャ各企業のアーキテクチャ企業のエンジニアブログ作業中クレジット連絡情報ライセンス学習指針学習スパンに応じてみるべきトピックス (short, medium, long)Q: 面接のためには、ここにあるものすべてをやらないといけないのでしょうか？A: いえ、ここにあるすべてをやる必要はありません。面接で何を聞かれるかは以下の条件によって変わってきます:どれだけの技術経験があるかあなたの技術背景が何であるかどのポジションのために面接を受けているかどの企業の面接を受けているか運より経験のある候補者は一般的にシステム設計についてより深い知識を有していることを要求されるでしょう。システムアーキテクトやチームリーダーは各メンバーの持つような知識よりは深い見識を持っているべきでしょう。一流テック企業では複数回の設計面接を課されることが多いです。まずは広く始めて、そこからいくつかの分野に絞って深めていくのがいいでしょう。様々なシステム設計のトピックについて少しずつ知っておくことはいいことです。以下の学習ガイドを自分の学習に当てられる時間、技術経験、どの職位、どの会社に応募しているかなどを加味して自分用に調整して使うといいでしょう。短期間 - 幅広く システム設計トピックを学ぶ。いくつかの 面接課題を解くことで対策する。中期間 - 幅広く そして それなりに深くシステム設計トピックを学ぶ。多くの 面接課題を解くことで対策する。長期間 - 幅広く そして もっと深くシステム設計トピックを学ぶ。ほぼ全ての 面接課題を解くことで対策する。短期間中期間長期間システム設計トピック を読み、システム動作機序について広く知る👍👍👍次のリンク先のいくつかのページを読んで 各企業のエンジニアリングブログ 応募する会社について知る👍👍👍次のリンク先のいくつかのページを読む 実世界でのアーキテクチャ👍👍👍復習する システム設計面接課題にどのように準備するか👍👍👍とりあえず一周する システム設計課題例SomeManyMostとりあえず一周する オブジェクト指向設計問題と解答SomeManyMost復習する その他システム設計面接での質問例SomeManyMostシステム設計面接にどのようにして臨めばいいかシステム設計面接試験問題にどのように取り組むかシステム設計面接は open-ended conversation(Yes/Noでは答えられない口頭質問)です。 自分で会話を組み立てることを求められます。以下のステップに従って議論を組み立てることができるでしょう。この過程を確かなものにするために、次のセクションシステム設計課題例とその解答 を以下の指針に従って読み込むといいでしょう。ステップ 1: そのシステム使用例の概要、制約、推計値等を聞き出し、まとめるシステム仕様の要求事項を聞き出し、問題箇所を特定しましょう。使用例と制約を明確にするための質問を投げかけましょう。要求する推計値についても議論しておきましょう。誰がそのサービスを使うのか？どのように使うのか？何人のユーザーがいるのか？システムはどのような機能を果たすのか？システムへの入力と出力は？どれだけの容量のデータを捌く必要があるのか？一秒間に何リクエストの送信が想定されるか？読み書き比率の推定値はいくら程度か？ステップ 2: より高レベルのシステム設計を組み立てる重要なコンポーネントを全て考慮した高レベルのシステム設計概要を組み立てる。主要なコンポーネントと接続をスケッチして書き出す考えの裏付けをするステップ 3: 核となるコンポーネントを設計するそれぞれの主要なコンポーネントについての詳細を学ぶ。例えば、url短縮サービスの設計を問われた際には次のようにするといいでしょう:元のURLのハッシュ化したものを作り、それを保存するMD5 と Base62ハッシュ衝突SQL もしくは NoSQLデータベーススキーマハッシュ化されたURLを元のURLに再翻訳するデータベース参照API & オブジェクト指向の設計ステップ 4: システム設計のスケール与えられた制約条件からボトルネックとなりそうなところを割り出し、明確化する。  例えば、スケーラビリティの問題解決のために以下の要素を考慮する必要があるだろうか？ロードバランサー水平スケーリングキャッシングデータベースシャーディング取りうる解決策とそのトレードオフについて議論をしよう。全てのことはトレードオフの関係にある。ボトルネックについてはスケーラブルなシステム設計の原理を読むといいでしょう。ちょっとした暗算問題ちょっとした推計値を手計算ですることを求められることもあるかもしれません。補遺の以下の項目が役に立つでしょう:チラ裏計算でシステム設計する2の乗数表全てのプログラマーが知っておくべきレイテンシの参考値文献とその他の参考資料以下のリンク先ページを見てどのような質問を投げかけられるか概要を頭に入れておきましょう:システム設計面接で成功するには？システム設計面接アーキテクチャ、システム設計面接への導入システム設計課題例とその解答頻出のシステム設計面接課題と参考解答、コード及びダイアグラム解答は solutions/ フォルダ以下にリンクが貼られている問題Pastebin.com (もしくは Bit.ly) を設計する解答Twitterタイムライン (もしくはFacebookフィード)を設計するTwitter検索(もしくはFacebook検索)機能を設計する解答ウェブクローラーを設計する解答Mint.comを設計する解答SNSサービスのデータ構造を設計する解答検索エンジンのキー/バリュー構造を設計する解答Amazonのカテゴリ毎の売り上げランキングを設計する解答AWS上で100万人規模のユーザーを捌くサービスを設計する解答システム設計問題を追加するContributePastebin.com (もしくは Bit.ly) を設計する問題と解答を見るTwitterタイムライン&検索 (もしくはFacebookフィード&検索)を設計する問題と解答を見るウェブクローラーの設計問題と解答を見るMint.comの設計問題と解答を見るSNSサービスのデータ構造を設計する問題と解答を見る検索エンジンのキー/バリュー構造を設計する問題と解答を見るAmazonのカテゴリ毎の売り上げランキングを設計する問題と解答を見るAWS上で100万人規模のユーザーを捌くサービスを設計する問題と解答を見るオブジェクト指向設計問題と解答頻出のオブジェクト指向システム設計面接課題と参考解答、コード及びダイアグラム解答は solutions/ フォルダ以下にリンクが貼られている備考: このセクションは作業中です問題ハッシュマップの設計解答LRUキャッシュの設計解答コールセンターの設計解答カードのデッキの設計解答駐車場の設計解答チャットサーバーの設計解答円形配列の設計Contributeオブジェクト指向システム設計問題を追加するContributeシステム設計トピックス: まずはここからシステム設計の勉強は初めて？まず初めに、よく使われる設計原理について、それらが何であるか、どのように用いられるか、長所短所について基本的な知識を得る必要がありますステップ 1: スケーラビリティに関する動画を観て復習するHarvardでのスケーラビリティの講義ここで触れられているトピックス:垂直スケーリング水平スケーリングキャッシングロードバランシングデータベースレプリケーションデータベースパーティションステップ 2: スケーラビリティに関する資料を読んで復習するスケーラビリティここで触れられているトピックス:クローンデータベースキャッシュ非同期次のステップ次に、ハイレベルでのトレードオフについてみていく:パフォーマンス vs スケーラビリティレイテンシ vs スループット可用性 vs 一貫性全てはトレードオフの関係にあるというのを肝に命じておきましょう。それから、より深い内容、DNSやCDNそしてロードバランサーなどについて学習を進めていきましょう。パフォーマンス vs スケーラビリティリソースが追加されるのにつれて パフォーマンス が向上する場合そのサービスは スケーラブル であると言えるでしょう。一般的に、パフォーマンスを向上させるというのはすなわち計算処理を増やすことを意味しますが、データセットが増えた時などより大きな処理を捌けるようになることでもあります。1パフォーマンスvsスケーラビリティをとらえる他の考え方:パフォーマンス での問題を抱えている時、あなたのシステムは一人のユーザーにとって遅いと言えるでしょう。スケーラビリティ での問題を抱えているとき、一人のユーザーにとっては速いですが、多くのリクエストがある時には遅くなってしまうでしょう。その他の参考資料、ページスケーラビリティについてスケーラビリティ、可用性、安定性、パターンレイテンシー vs スループットレイテンシー とはなにがしかの動作を行う、もしくは結果を算出するのに要する時間スループット とはそのような動作や結果算出が単位時間に行われる回数一般的に、 最大限のスループット を 許容範囲内のレイテンシー で実現することを目指すのが普通だ。その他の参考資料、ページレイテンシー vs スループットを理解する可用性 vs 一貫性CAP 理論      Source: CAP theorem revisited分散型コンピュータシステムにおいては下の三つのうち二つまでしか同時に保証することはできない。:一貫性 - 全ての読み込みは最新の書き込みもしくはエラーを受け取る可用性 - 受け取る情報が最新のものだという保証はないが、全てのリクエストはレスポンスを必ず受け取る分断耐性 - ネットワーク問題によって順不同の分断が起きてもシステムが動作を続けるネットワークは信頼できないので、分断耐性は必ず保証しなければなりません。つまりソフトウェアシステムとしてのトレードオフは、一貫性を取るか、可用性を取るかを考えなければなりません。CP - 一貫性と分断耐性(consistency and partition tolerance)分断されたノードからのレスポンスを待ち続けているとタイムアウトエラーに陥る可能性があります。CPはあなたのサービスがアトミックな読み書き（不可分操作）を必要とする際にはいい選択肢でしょう。AP - 可用性と分断耐性(availability and partition tolerance)レスポンスはノード上にあるデータで最新のものを返します。つまり、最新版のデータが返されるとは限りません。分断が解消された後も、書き込みが反映されるのには時間がかかります。結果整合性　を求めるサービスの際にはAPを採用するのがいいでしょう。もしくは、外部エラーに関わらずシステムが稼働する必要がある際にも同様です。その他の参考資料、ページCAP 理論を振り返る平易な英語でのCAP 理論のイントロCAP FAQ一貫性パターン同じデータの複製が複数ある状態では、クライアントが一貫したデータ表示を受け取るために、どのようにそれらを同期すればいいのかという課題があります。 CAP 理論 における一貫性の定義を思い出してみましょう。全ての読み取りは最新の書き込みデータもしくはエラーを受け取るはずです。弱い一貫性書き込み後の読み取りでは、その最新の書き込みを読めたり読めなかったりする。ベストエフォート型のアプローチに基づく。このアプローチはmemcachedなどのシステムに見られます。弱い一貫性はリアルタイム性が必要なユースケース、例えばVoIP、ビデオチャット、リアルタイムマルチプレイヤーゲームなどと相性がいいでしょう。例えば、電話に出ているときに数秒間音声が受け取れなくなったとしたら、その後に接続が回復してもその接続が切断されていた間に話されていたことは聞き取れないというような感じです。結果整合性書き込みの後、読み取りは最終的にはその結果を読み取ることができる(ミリ秒ほど遅れてというのが一般的です)。データは非同期的に複製されます。このアプローチはDNSやメールシステムなどに採用されています。結果整合性は多くのリクエストを捌くサービスと相性がいいでしょう。強い一貫性書き込みの後、読み取りはそれを必ず読むことができます。データは同期的に複製されます。このアプローチはファイルシステムやRDBMSなどで採用されています。トランザクションを扱うサービスでは強い一貫性が必要でしょう。その他の参考資料、ページデータセンター間でのトランザクション可用性パターン高い可用性を担保するには主に次の二つのパターンがあります: フェイルオーバー と レプリケーション です。フェイルオーバーアクティブ・パッシブアクティブ・パッシブフェイルオーバーにおいては、周期信号はアクティブもしくはスタンバイ中のパッシブなサーバーに送られます。周期信号が中断された時には、パッシブだったサーバーがアクティブサーバーのIPアドレスを引き継いでサービスを再開します。起動までのダウンタイムはパッシブサーバーが「ホット」なスタンバイ状態にあるか、「コールド」なスタンバイ状態にあるかで変わります。アクティブなサーバーのみがトラフィックを捌きます。アクティブ・パッシブフェイルオーバーはマスター・スレーブフェイルオーバーと呼ばれることもあります。アクティブ・アクティブアクティブアクティブ構成では両方のサーバーがトラフィックを捌くことで負荷を分散します。これらのサーバーがパブリックなものの場合、DNSは両方のサーバーのパブリックIPを知っている必要があります。もし、プライベートなものな場合、アプリケーションロジックが両方のサーバーの情報について知っている必要があります。アクティブ・アクティブなフェイルオーバーはマスター・マスターフェイルオーバーと呼ばれることもあります。短所: フェイルオーバーフェイルオーバーではより多くのハードウェアを要し、複雑さが増します。最新の書き込みがパッシブサーバーに複製される前にアクティブが落ちると、データ欠損が起きる潜在可能性があります。レプリケーションマスター・スレーブ　と　マスター・マスターこのトピックは データベース セクションにおいてより詳細に解説されています:マスター・スレーブ レプリケーションマスター・マスター レプリケーションドメインネームシステム      Source: DNS security presentationドメインネームシステム (DNS) は www.example.com などのドメインネームをIPアドレスへと翻訳します。DNSは少数のオーソライズされたサーバーが上位に位置する階層的構造です。あなたのルーターもしくはISPは検索をする際にどのDNSサーバーに接続するかという情報を提供します。低い階層のDNSサーバーはその経路マップをキャッシュします。ただ、この情報は伝搬遅延によって陳腐化する可能性があります。DNSの結果はあなたのブラウザもしくはOSに一定期間（time to live (TTL)に設定された期間）キャッシュされます。NS record (name server) - あなたのドメイン・サブドメインでのDNSサーバーを特定します。MX record (mail exchange) - メッセージを受け取るメールサーバーを特定します。A record (address) - IPアドレスに名前をつけます。CNAME (canonical) - 他の名前もしくは　CNAME (example.com を www.example.com) もしくは A recordへと名前を指し示す。CloudFlare や Route 53 などのサービスはマネージドDNSサービスを提供しています。いくつかのDNSサービスでは様々な手法を使ってトラフィックを捌くことができます:加重ラウンドロビントラフィックがメンテナンス中のサーバーに行くのを防ぎます様々なクラスターサイズに応じて調整しますA/B テストレイテンシーベース地理ベース欠点: DNS上記で示されているようなキャッシングによって緩和されているとはいえ、DNSサーバーへの接続には少し遅延が生じる。DNSサーバーは、政府、ISP企業,そして大企業に管理されているが、それらの管理は複雑である。DNSサービスはDDoS attackの例で、IPアドレスなしにユーザーがTwitterなどにアクセスできなくなったように、攻撃を受ける可能性がある。その他の参考資料、ページDNS アーキテクチャWikipediaDNS 記事コンテンツデリバリーネットワーク(Content delivery network)      Source: Why use a CDNコンテンツデリバリーネットワーク(CDN)は世界中に配置されたプロキシサーバーのネットワークがユーザーに一番地理的に近いサーバーからコンテンツを配信するシステムのことです。AmazonのCloudFrontなどは例外的にダイナミックなコンテンツも配信しますが、一般的に、HTML/CSS/JS、写真、そして動画などの静的ファイルがCDNを通じて配信されます。そのサイトのDNSがクライアントにどのサーバーと交信するかという情報を伝えます。CDNを用いてコンテンツを配信することで以下の二つの理由でパフォーマンスが劇的に向上します:ユーザーは近くにあるデータセンターから受信できるバックエンドサーバーはCDNが処理してくれるリクエストに関しては処理する必要がなくなりますプッシュCDNプッシュCDNではサーバーデータに更新があった時には必ず、新しいコンテンツを受け取る方式です。コンテンツを用意し、CDNに直接アップロードし、URLをCDNを指すように指定するところまで、全て自分で責任を負う形です。コンテンツがいつ期限切れになるのか更新されるのかを設定することができます。コンテンツは新規作成時、更新時のみアップロードされることでトラフィックは最小化される一方、ストレージは最大限消費されてしまいます。トラフィックの少ない、もしくは頻繁にはコンテンツが更新されないサイトの場合にはプッシュCDNと相性がいいでしょう。コンテンツは定期的に再びプルされるのではなく、CDNに一度のみ配置されます。プルCDNプルCDNでは一人目のユーザーがリクエストした時に、新しいコンテンツをサービスのサーバーから取得します。コンテンツは自分のサーバーに保存して、CDNを指すURLを書き換えます。結果として、CDNにコンテンツがキャッシュされるまではリクエスト処理が遅くなります。time-to-live (TTL) はコンテンツがどれだけの期間キャッシュされるかを規定します。プルCDNはCDN 上でのストレージスペースを最小化しますが、有効期限が切れたファイルが更新前にプルされてしまうことで冗長なトラフィックに繋がってしまう可能性があります。大規模なトラフィックのあるサイトではプルCDNが相性がいいでしょう。というのも、トラフィックの大部分は最近リクエストされ、CDNに残っているコンテンツにアクセスするものであることが多いからです。欠点: CDNCDNのコストはトラフィック量によって変わります。もちろん、CDNを使わない場合のコストと比較するべきでしょう。TTLが切れる前にコンテンツが更新されると陳腐化する恐れがあります。CDNでは静的コンテンツがCDNを指すようにURLを更新する必要があります。その他の参考資料、ページグローバルに分散されたコンテンツデリバリーネットワークプッシュCDNとプルCDNの違いWikipediaロードバランサー      Source: Scalable system design patternsロードバランサーは入力されるクライアントのリクエストをアプリケーションサーバーやデータベースへと分散させる。どのケースでもロードバランサーはサーバー等計算リソースからのレスポンスを適切なクライアントに返す。ロードバランサーは以下のことに効果的です:リクエストが状態の良くないサーバーに行くのを防ぐリクエストを過剰に送るのを防ぐ特定箇所の欠陥でサービスが落ちることを防ぐロードバランサーは (費用の高い) ハードウェアもしくはHAProxyなどのソフトウェアで実現できる。他の利点としては:SSL termination - 入力されるリクエストを解読する、また、サーバーレスポンスを暗号化することでバックエンドのサーバーがこのコストが高くつきがちな処理を請け負わなくていいように肩代わりします。X.509 certificates をそれぞれのサーバーにインストールする必要をなくしますセッション管理 - クッキーを取り扱うウェブアプリがセッション情報を保持していない時などに、特定のクライアントのリクエストを同じインスタンスへと流します。障害に対応するために、アクティブ・パッシブ もしくは アクティブ・アクティブ モードのどちらにおいても、複数のロードバランサーを配置するのが一般的です。ロードバランサーは以下のような種々のメトリックを用いてトラフィックルーティングを行うことができます:ランダムLeast loadedセッション/クッキーラウンドロビンもしくは加重ラウンドロビンLayer 4Layer 7Layer 4 ロードバランシングLayer 4 ロードバランサーは トランスポートレイヤー を参照してどのようにリクエストを配分するか判断します。一般的に、トランスポートレイヤーとしては、ソース、送信先IPアドレス、ヘッダーに記述されたポート番号が含まれますが、パケットの中身のコンテンツは含みません。 Layer 4 ロードバランサーはネットワークパケットを上流サーバーへ届け、上流サーバーから配信することでネットワークアドレス変換 Network Address Translation (NAT) を実現します。Layer 7 ロードバランシングLayer 7 ロードバランサーは アプリケーションレイヤー を参照してどのようにリクエストを配分するか判断します。ヘッダー、メッセージ、クッキーなどのコンテンツのことです。Layer 7 ロードバランサーはネットワークトラフィックの終端を受け持ち メッセージを読み込み、ロードバランシングの判断をし、選択したサーバーとの接続を繋ぎます。例えば layer 7 ロードバランサーは動画のトラフィックを直接、そのデータをホストしているサーバーにつなぐと同時に、決済処理などのより繊細なトラフィックをセキュリティ強化されたサーバーに流すということもできる。柔軟性とのトレードオフになりますが、 layer 4 ロードバランサーではLayer 7ロードバランサーよりも所要時間、計算リソースを少なく済ませることができます。ただし、昨今の汎用ハードウェアではパフォーマンスは最小限のみしか発揮できないでしょう。水平スケーリングロードバランサーでは水平スケーリングによってパフォーマンスと可用性を向上させることができます。手頃な汎用マシンを追加することによってスケールアウトさせる方が、一つのサーバーをより高価なマシンにスケールアップする（垂直スケーリング）より費用対効果も高くなり、結果的に可用性も高くなります。また、汎用ハードウェアを扱える人材を雇う方が、特化型の商用ハードウェアを扱える人材を雇うよりも簡単でしょう。欠点: 水平スケーリング水平的にスケーリングしていくと、複雑さが増す上に、サーバーのクローニングが必要になる。サーバーはステートレスである必要がある: ユーザーに関連するセッションや、プロフィール写真などのデータを持ってはいけないセッションは一元的なデータベース (SQL、 NoSQL)などのデータストアにストアされるか キャッシュ (Redis、 Memcached)に残す必要があります。キャッシュやデータベースなどの下流サーバーは上流サーバーがスケールアウトするにつれてより多くの同時接続を保たなければなりません。欠点: ロードバランサーロードバランサーはリソースが不足していたり、設定が適切でない場合、システム全体のボトルネックになる可能性があります。単一障害点を除こうとしてロードバランサーを導入した結果、複雑さが増してしまうことになります。ロードバランサーが一つだけだとそこが単一障害点になってしまいます。一方で、ロードバランサーを複数にすると、さらに複雑さが増してしまいます。その他の参考資料、ページNGINX アーキテクチャHAProxy アーキテクチャガイドスケーラビリティWikipediaLayer 4 ロードバランシングLayer 7 ロードバランシングELB listener configリバースプロキシ(webサーバー)      Source: Wikipedia  リバースプロキシサーバーは内部サービスをまとめて外部に統一されたインターフェースを提供するウェブサーバーです。クライアントからのリクエストはそれに対応するサーバーに送られて、その後レスポンスをリバースプロキシがクライアントに返します。他には以下のような利点があります:より堅牢なセキュリティ - バックエンドサーバーの情報を隠したり、IPアドレスをブラックリスト化したり、クライアントごとの接続数を制限したりできます。スケーラビリティや柔軟性が増します - クライアントはリバースプロキシのIPしか見ないので、裏でサーバーをスケールしたり、設定を変えやすくなります。SSL termination - 入力されるリクエストを解読し、サーバーのレスポンスを暗号化することでサーバーがこのコストのかかりうる処理をしなくて済むようになります。X.509 証明書 を各サーバーにインストールする必要がなくなります。圧縮 - サーバーレスポンスを圧縮できますキャッシング - キャッシュされたリクエストに対して、レスポンスを返します静的コンテンツ - 静的コンテンツを直接送信することができます。HTML/CSS/JS写真動画などなどロードバランサー vs リバースプロキシ複数のサーバーがある時にはロードバランサーをデプロイすると役に立つでしょう。 しばしば、ロードバランサーは同じ機能を果たすサーバー群へのトラフィックを捌きます。リバースプロキシでは、上記に述べたような利点を、単一のウェブサーバーやアプリケーションレイヤーに対しても示すことができます。NGINX や HAProxy などの技術はlayer 7 リバースプロキシとロードバランサーの両方をサポートします。欠点: リバースプロキシリバースプロキシを導入するとシステムの複雑性が増します。単一のリバースプロキシは単一障害点になりえます。一方で、複数のリバースプロキシを導入すると(例: フェイルオーバー) 複雑性はより増します。その他の参考資料、ページリバースプロキシ vs ロードバランサーNGINX アーキテクチャHAProxy アーキテクチャ ガイドWikipediaアプリケーション層      Source: Intro to architecting systems for scaleウェブレイヤーをアプリケーション層 (プラットフォーム層とも言われる) と分離することでそれぞれの層を独立にスケール、設定することができるようになります。新しいAPIをアプリケーション層に追加する際に、不必要にウェブサーバーを追加する必要がなくなります。単一責任の原則 では、小さい自律的なサービスが協調して動くように提唱しています。小さいサービスの小さいチームが急成長のためにより積極的な計画を立てられるようにするためです。アプリケーション層は非同期処理もサポートします。マイクロサービス独立してデプロイできる、小規模なモジュール様式であるマイクロサービスもこの議論に関係してくる技術でしょう。それぞれのサービスは独自のプロセスを処理し、明確で軽量なメカニズムで通信して、その目的とする機能を実現します。1例えばPinterestでは以下のようなマイクロサービスに分かれています。ユーザープロフィール、フォロワー、フィード、検索、写真アップロードなどです。サービスディスカバリーConsul、 Etcd、 Zookeeper などのシステムでは、登録されているサービスの名前、アドレス、ポートの情報を監視することで、サービス同士が互いを見つけやすくしています。サービスの完全性の確認には Health checks が便利で、これには HTTP エンドポイントがよく使われます。 Consul と Etcd のいずれも組み込みの key-value store を持っており、設定データや共有データなどのデータを保存しておくことに使われます。欠点: アプリケーション層アーキテクチャ、運用、そしてプロセスを考慮すると、緩く結び付けられたアプリケーション層を追加するには、モノリシックなシステムとは異なるアプローチが必要です。マイクロサービスはデプロイと運用の点から見ると複雑性が増すことになります。その他の参考資料、ページスケールするシステムアーキテクチャを設計するためのイントロシステム設計インタビューを紐解くサービス指向アーキテクチャZookeeperのイントロダクションマイクロサービスを作るために知っておきたいことデータベース      Source: Scaling up to your first 10 million usersリレーショナルデータベースマネジメントシステム (RDBMS)SQLなどのリレーショナルデータベースはテーブルに整理されたデータの集合である。ACID はリレーショナルデータベースにおけるトランザクションのプロパティの集合である不可分性 - それぞれのトランザクションはあるかないかのいずれかである一貫性 - どんなトランザクションもデータベースをある確かな状態から次の状態に遷移させる。独立性 - 同時にトランザクションを処理することは、連続的にトランザクションを処理するのと同じ結果をもたらす。永続性 - トランザクションが処理されたら、そのように保存されるリレーショナルデータベースをスケールさせるためにはたくさんの技術がある: マスター・スレーブ レプリケーション、 マスター・マスター レプリケーション、 federation、 シャーディング、 非正規化、 そして SQL チューニングマスタースレーブ レプリケーションマスターデータベースが読み取りと書き込みを処理し、書き込みを一つ以上のスレーブデータベースに複製します。スレーブデータベースは読み取りのみを処理します。スレーブデータベースは木構造のように追加のスレーブにデータを複製することもできます。マスターデータベースがオフラインになった場合には、いずれかのスレーブがマスターに昇格するか、新しいマスターデータベースが追加されるまでは読み取り専用モードで稼働します。      Source: Scalability, availability, stability, patterns欠点: マスタースレーブ レプリケーションスレーブをマスターに昇格させるには追加のロジックが必要になる。マスタースレーブ レプリケーション、マスターマスター レプリケーションの 両方 の欠点は欠点: レプリケーションを参照マスターマスター レプリケーションいずれのマスターも読み取り書き込みの両方に対応する。書き込みに関してはそれぞれ協調する。いずれかのマスターが落ちても、システム全体としては読み書き両方に対応したまま運用できる。      Source: Scalability, availability, stability, patterns欠点: マスターマスター レプリケーションロードバランサーを導入するか、アプリケーションロジックを変更することでどこに書き込むかを指定しなければならない。大体のマスターマスターシステムは、一貫性が緩い（ACID原理を守っていない）もしくは、同期する時間がかかるために書き込みのレイテンシーが増加してしまっている。書き込みノードが追加され、レイテンシーが増加するにつれ書き込みの衝突の可能性が増える。マスタースレーブ レプリケーション、マスターマスター レプリケーションの 両方 の欠点は欠点: レプリケーション を参照欠点: レプリケーション新しいデータ書き込みを複製する前にマスターが落ちた場合にはそのデータが失われてしまう可能性がある。書き込みは読み取りレプリカにおいてリプレイされる。書き込みが多い場合、複製ノードが書き込みの処理のみで行き詰まって、読み取りの処理を満足に行えない可能性がある。読み取りスレーブノードの数が多ければ多いほど、複製しなければならない数も増え、複製時間が伸びてしまいます。システムによっては、マスターへの書き込みはマルチスレッドで並列処理できる一方、スレーブへの複製は単一スレッドで連続的に処理しなければならない場合があります。レプリケーションでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: レプリケーションスケーラビリティ、 可用性、 スタビリティ パターンマルチマスター レプリケーションFederation      Source: Scaling up to your first 10 million usersフェデレーション (もしくは機能分割化とも言う) はデータベースを機能ごとに分割する。例えば、モノリシックな単一データベースの代わりに、データベースを フォーラム、 ユーザー、 プロダクト のように三つにすることで、データベース一つあたりの書き込み・読み取りのトラフィックが減り、その結果レプリケーションのラグも短くなります。データベースが小さくなることで、メモリーに収まるデータが増えます。キャッシュの局所性が高まるため、キャッシュヒット率も上がります。単一の中央マスターで書き込みを直列化したりしないため、並列で書き込みを処理することができ、スループットの向上が期待できます。欠点: federation大規模な処理やテーブルを要するスキーマの場合、フェデレーションは効果的とは言えないでしょう。どのデータベースに読み書きをするのかを指定するアプリケーションロジックを更新しなければなりません。server linkで二つのデータベースからのデータを連結するのはより複雑になるでしょう。フェデレーションでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: federationScaling up to your first 10 million usersシャーディング      Source: Scalability, availability, stability, patternsシャーディングでは異なるデータベースにそれぞれがデータのサブセット断片のみを持つようにデータを分割します。ユーザーデータベースを例にとると、ユーザー数が増えるにつれてクラスターにはより多くの断片が加えられることになります。federationの利点に似ていて、シャーディングでは読み書きのトラフィックを減らし、レプリケーションを減らし、キャッシュヒットを増やすことができます。インデックスサイズも減らすことができます。一般的にはインデックスサイズを減らすと、パフォーマンスが向上しクエリ速度が速くなります。なにがしかのデータを複製する機能がなければデータロスにつながりますが、もし、一つのシャードが落ちても、他のシャードが動いていることになります。フェデレーションと同じく、単一の中央マスターが書き込みの処理をしなくても、並列で書き込みを処理することができ、スループットの向上が期待できます。ユーザーテーブルをシャードする一般的な方法は、ユーザーのラストネームイニシャルでシャードするか、ユーザーの地理的配置でシャードするなどです。欠点: シャーディングシャードに対応するようにアプリケーションロジックを変更しなければなりません。結果としてSQLクエリが複雑になります。シャードではデータ配分がいびつになってしまう可能性があります。例えば、標準ユーザーの集合を持つシャードがある場合、そのシャードが他のシャードよりも重い負荷を負うことになります。リバランシングをすると複雑性がより増します。consistent hashing に基づいたシャーディングでは、通信データを削減することもできます。複数のシャードからのデータを連結するのはより複雑です。シャーディングでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: シャーディングシャードの登場シャードデータベースアーキテクチャConsistent hashing非正規化非正規化では、書き込みのパフォーマンスをいくらか犠牲にして読み込みのパフォーマンスを向上させようとします。計算的に重いテーブルの結合などをせずに、複数のテーブルに冗長なデータのコピーが書き込まれるのを許容します。いくつかのRDBMS例えば、PostgreSQL やOracleはこの冗長な情報を取り扱い、一貫性を保つためのmaterialized views という機能をサポートしています。フェデレーション や シャーディングなどのテクニックによってそれぞれのデータセンターに分配されたデータを合一させることはとても複雑な作業です。非正規化によってそのような複雑な処理をしなくて済むようになります。多くのシステムで、100対1あるいは1000対1くらいになるくらい読み取りの方が、書き込みのトラフィックよりも多いことでしょう。読み込みを行うために、複雑なデータベースのジョイン処理が含まれるものは計算的に高価につきますし、ディスクの処理時間で膨大な時間を費消してしまうことになります。欠点: 非正規化データが複製される。冗長なデータの複製が同期されるように制約が存在し、そのことでデータベース全体の設計が複雑化する。非正規化されたデータベースは過大な書き込みを処理しなければならない場合、正規化されているそれよりもパフォーマンスにおいて劣る可能性がある。その他の参考資料、ページ: 非正規化DenormalizationSQLチューニングSQLチューニングは広範な知識を必要とする分野で多くの 本 が書かれています。ボトルネックを明らかにし、シミュレートする上で、 ベンチマーク を定め、 プロファイル することはとても重要です。ベンチマーク - abなどのツールを用いて、高負荷の状況をシミュレーションしてみましょう。プロファイル - slow query log などのツールを用いて、パフォーマンス状況の確認をしましょう。ベンチマークとプロファイルをとることで以下のような効率化の選択肢をとることになるでしょう。スキーマを絞るMySQLはアクセス速度向上のため、ディスク上の連続したブロックへデータを格納しています。長さの決まったフィールドに対しては VARCHAR よりも CHAR を使うようにしましょう。CHAR の方が効率的に速くランダムにデータにアクセスできます。 一方、 VARCHAR では次のデータに移る前にデータの末尾を検知しなければならないために速度が犠牲になります。ブログの投稿など、大きなテキストには TEXT を使いましょう。 TEXT ではブーリアン型の検索も可能です。 TEXT フィールドには、テキストブロックが配置されている、ディスク上の場所へのポインターが保存されます。2の32乗や40億以下を超えない程度の大きな数には INT を使いましょう。通貨に関しては小数点表示上のエラーを避けるために DECIMAL を使いましょう。大きな BLOBS を保存するのは避けましょう。どこからそのオブジェクトを取ってくることができるかの情報を保存しましょう。VARCHAR(255) は8ビットで数えられる最大の文字数です。一部のDBMSでは、1バイトの利用効率を最大化するためにこの文字数がよく使われます。検索性能向上のため 、可能であれば NOT NULL 制約を設定しましょう。インデックスを効果的に用いるクエリ(SELECT、 GROUP BY、 ORDER BY、 JOIN) の対象となる列にインデックスを使うことで速度を向上できるかもしれません。インデックスは通常、平衡探索木であるB木の形で表されます。B木によりデータは常にソートされた状態になります。また検索、順次アクセス、挿入、削除を対数時間で行えます。インデックスを配置することはデータをメモリーに残すことにつながりより容量を必要とします。インデックスの更新も必要になるため書き込みも遅くなります。大量のデータをロードする際には、インデックスを切ってからデータをロードして再びインデックスをビルドした方が速いことがあります。高負荷なジョインを避けるパフォーマンス上必要なところには非正規化を適用するテーブルのパーティションテーブルを分割し、ホットスポットを独立したテーブルに分離してメモリーに乗せられるようにする。クエリキャッシュを調整する場合によってはクエリキャッシュ がパフォーマンス問題 を引き起こす可能性があるその他の参考資料、ページ: SQLチューニングMySQLクエリを最適化するためのTipsVARCHAR(255)をやたらよく見かけるのはなんで？null値はどのようにパフォーマンスに影響するのか？Slow query logNoSQLNoSQL は key-value store、 document-store、 wide column store、 もしくは graph databaseによって表現されるデータアイテムの集合です。データは一般的に正規化されておらず、アプリケーション側でジョインが行われます。大部分のNoSQLは真のACIDトランザクションを持たず、 結果整合性 的な振る舞いの方を好みます。BASE はしばしばNoSQLデータベースのプロパティを説明するために用いられます。CAP Theorem と対照的に、BASEは一貫性よりも可用性を優先します。Basically available - システムは可用性を保証します。Soft state - システムの状態は入力がなくても時間経過とともに変化する可能性があります。結果整合性 - システム全体は時間経過とともにその間に入力がないという前提のもと、一貫性が達成されます。SQLか？NoSQLか？ を選択するのに加えて、どのタイプのNoSQLがどの使用例に最も適するかを理解するのはとても有益です。このセクションでは キーバリューストア、 ドキュメントストア、 ワイドカラムストア、 と グラフデータベース について触れていきます。キーバリューストア概要: ハッシュテーブルキーバリューストアでは一般的にO(1)の読み書きができ、それらはメモリないしSSDで裏付けられています。データストアはキーを 辞書的順序 で保持することでキーの効率的な取得を可能にしています。キーバリューストアではメタデータを値とともに保持することが可能です。キーバリューストアはハイパフォーマンスな挙動が可能で、単純なデータモデルやインメモリーキャッシュレイヤーなどのデータが急速に変わる場合などに使われます。単純な処理のみに機能が制限されているので、追加の処理機能が必要な場合にはその複雑性はアプリケーション層に載せることになります。キーバリューストアはもっと複雑なドキュメントストアや、グラフデータベースなどの基本です。その他の参考資料、ページ: キーバリューストアキーバリューデータベースキーバリューストアの欠点Redisアーキテクチャメムキャッシュアーキテクチャドキュメントストア概要: ドキュメントがバリューとして保存されたキーバリューストアドキュメントストアはオブジェクトに関する全ての情報を持つドキュメント(XML、 JSON、 binaryなど)を中心に据えたシステムです。ドキュメントストアでは、ドキュメント自身の内部構造に基づいた、APIもしくはクエリ言語を提供します。 メモ：多くのキーバリューストアでは、値のメタデータを扱う機能を含んでいますが、そのことによって二つドキュメントストアとの境界線が曖昧になってしまっています。以上のことを実現するために、ドキュメントはコレクション、タグ、メタデータやディレクトリなどとして整理されています。ドキュメント同士はまとめてグループにできるものの、それぞれで全く異なるフィールドを持つ可能性があります。MongoDB や CouchDB などのドキュメントストアも、複雑なクエリを処理するためのSQLのような言語を提供しています。DynamoDB はキーバリューとドキュメントの両方をサポートしています。ドキュメントストアは高い柔軟性を担保するので、頻繁に変化するデータを扱う時に用いられます。その他の参考資料、ページ:  ドキュメントストアドキュメント指向 データベースMongoDB アーキテクチャCouchDB アーキテクチャElasticsearch アーキテクチャワイドカラムストア      Source: SQL & NoSQL, a brief history概要: ネストされたマップ カラムファミリー<行キー、 カラム<ColKey、 Value、 Timestamp>>ワイドカラムストアのデータの基本単位はカラム（ネーム・バリューのペア）です。それぞれのカラムはカラムファミリーとして（SQLテーブルのように）グループ化することができます。スーパーカラムファミリーはカラムファミリーの集合です。それぞれのカラムには行キーでアクセスすることができます。同じ行キーを持つカラムは同じ行として認識されます。それぞれの値は、バージョン管理とコンフリクトが起きた時のために、タイムスタンプを含みます。GoogleはBigtableを初のワイドカラムストアとして発表しました。それがオープンソースでHadoopなどでよく使われるHBase やFacebookによるCassandra などのプロジェクトに影響を与えました。BigTable、HBaseやCassandraなどのストアはキーを辞書形式で保持することで選択したキーレンジでのデータ取得を効率的にします。ワイドカラムストアは高い可用性とスケーラビリティを担保します。これらはとても大規模なデータセットを扱うことによく使われます。その他の参考資料、ページ:  ワイドカラムストアSQL & NoSQL簡単に歴史をさらうBigtable アーキテクチャHBase アーキテクチャCassandra アーキテクチャグラフデータベース      Source: Graph database概要: グラフグラフデータベースでは、それぞれのノードがレコードで、それぞれのアークは二つのノードを繋ぐ関係性として定義されます。グラフデータベースは多数の外部キーや多対多などの複雑な関係性を表すのに最適です。グラフデータベースはSNSなどのサービスの複雑な関係性モデルなどについて高いパフォーマンスを発揮します。比較的新しく、まだ一般的には用いられていないので、開発ツールやリソースを探すのが他の方法に比べて難しいかもしれません。多くのグラフはREST APIsを通じてのみアクセスできます。その他の参考資料、ページ:  グラフGraphデータベースNeo4jFlockDBその他の参考資料、ページ:  NoSQL基本用語の説明NoSQLデータベースについて調査と選択ガイドスケーラビリティNoSQLのイントロダクションNoSQLパターンSQLか？NoSQLか？      Source: Transitioning from RDBMS to NoSQLSQL を選ぶ理由:構造化されたデータ厳格なスキーマリレーショナルデータ複雑なジョインをする必要性トランザクションスケールする際のパターンが明確なとき開発者の数、コミュニティ、コード等がより充実しているインデックスによるデータ探索はとても速いNoSQL を選ぶ理由:準構造化されたデータダイナミックないし、フレキシブルなスキーマノンリレーショナルなデータ複雑なジョインをする必要がないデータの多くのTB (もしくは PB) を保存する集中的、大規模なデータ負荷に耐えられるIOPSについては極めて高いスループットを示すNoSQLに適するサンプルデータ:急激なクリックストリームやログデータの収集リーダーボードやスコアリングデータショッピングカートなどの一時的情報頻繁にアクセスされる ('ホットな') テーブルメタデータやルックアップテーブルその他の参考資料、ページ:  　SQLもしくはNoSQL最初の1000万ユーザーにスケールアップするためにSQLとNoSQLの違いキャッシュ      Source: Scalable system design patternsキャッシュはページの読み込み時間を削減し、サーバーやデータベースへの負荷を低減することができます。このモデルでは、実際の処理を保存するために、ディスパッチャーがまず以前にリクエストが送信されたかどうかを確認し、直前の結果を受け取ります。データベースはそのパーティションに渡って統合された読み取り書き込みの分配を要求しますが、人気アイテムはその分配を歪めてシステム全体のボトルネックになってしまうことがあります。データベースの前にキャッシュを差し込むことでこのように、均一でない負荷やトラフィックの急激な増加を吸収することができます。クライアントキャッシングキャッシュはOSやブラウザーなどのクライアントサイド、サーバーサイド もしくは独立のキャッシュレイヤーに設置することができます。CDNキャッシングCDN もキャッシュの一つとして考えることができます。Webサーバーキャッシングリバースプロキシ や Varnish などのキャッシュは静的そして動的なコンテンツを直接配信することができます。 webサーバーもリクエストをキャッシュしてアプリケーションサーバーに接続することなしにレスポンスを返すことができます。データベースキャッシングデータベースは普通、一般的な使用状況に適するようなキャッシングの設定を初期状態で持っています。この設定を特定の仕様に合わせて調整することでパフォーマンスを向上させることができます。アプリケーションキャッシングメムキャッシュなどのIn-memoryキャッシュやRedisはアプリケーションとデータストレージの間のキーバリューストアです。データはRAMで保持されるため、データがディスクで保存される一般的なデータベースよりもだいぶ速いです。RAM容量はディスクよりも限られているので、least recently used (LRU)などのcache invalidation アルゴリズムが 'コールド' なエントリを弾き、'ホット' なデータをRAMに保存します。Redisはさらに以下のような機能を備えています:パージステンス設定ソート済みセット、リストなどの組み込みデータ構造キャッシュには様々なレベルのものがありますが、いずれも大きく二つのカテゴリーのいずれかに分類することができます: データベースクエリ と オブジェクト です:行レベルクエリレベルFully-formed serializable objectsFully-rendered HTML一般的に、ファイルベースキャッシングはクローンを作り出してオートスケーリングを難しくしてしまうので避けるべきです。データベースクエリレベルでのキャッシングデータベースをクエリする際には必ずクエリをキーとしてハッシュして結果をキャッシュに保存しましょう。この手法はキャッシュ期限切れ問題に悩むことになります:複雑なクエリによりキャッシュされた結果を削除することが困難テーブルセルなどのデータ断片が変化した時に、その変化したセルを含むかもしれない全てのキャッシュされたクエリを削除する必要がある。オブジェクトレベルでのキャッシングデータをアプリケーションコードでそうするように、オブジェクトとして捉えてみましょう。アプリケーションに、データベースからのデータセットをクラスインスタンスやデータ構造として組み立てさせます。:そのデータが変更されたら、オブジェクトをキャッシュから削除すること非同期処理を許容します: ワーカーがキャッシュされたオブジェクトの中で最新のものを集めてきます何をキャッシュするか:ユーザーのセッション完全にレンダーされたウェブページアクテビティストリームユーザーグラフデータいつキャッシュを更新するかキャッシュに保存できる容量は限られているため、自分のケースではどのキャッシュ手法が一番いいかは検討する必要があります。キャッシュアサイド      Source: From cache to in-memory data gridアプリケーションはストレージへの読み書きの処理をします。キャッシュはストレージとは直接やりとりをしません。アプリケーションは以下のことをします:キャッシュの中のエントリを参照しますが、結果としてキャッシュミスになりますデータベースからエントリを取得しますエントリをキャッシュに追加しますエントリを返しますdef get_user(self, user_id):    user = cache.get(\""user.{0}\"", user_id)    if user is None:        user = db.query(\""SELECT * FROM users WHERE user_id = {0}\"", user_id)        if user is not None:            key = \""user.{0}\"".format(user_id)            cache.set(key, json.dumps(user))    return userMemcached は通常このように使われる。その後のキャッシュデータ読み込みは速いです。キャッシュアサイドはレージーローディングであるとも言われます。リクエストされたデータのみがキャッシュされ、リクエストされていないデータでキャッシュが溢れるのを防止します。欠点: キャッシュアサイド各キャッシュミスは三つのトリップを呼び出すことになり、体感できるほどの遅延が起きてしまいます。データベースのデータが更新されるとキャッシュデータは古いものになってしまいます。time-to-live (TTL)を設定することでキャッシュエントリの更新を強制的に行う、もしくはライトスルーを採用することでこの問題は緩和できます。ノードが落ちると、新規の空のノードで代替されることでレイテンシーが増加することになります。ライトスルー      Source: Scalability, availability, stability, patternsアプリケーションはキャッシュをメインのデータストアとして使い、そこにデータの読み書きを行います。一方、キャッシュはデータベースへの読み書きを担当します。アプリケーションはキャッシュにあるエントリを追加・更新しますキャッシュは同期的にデータストアに書き込みを行いますエントリを返しますアプリケーションコード:set_user(12345, {\""foo\"":\""bar\""})キャッシュコード:def set_user(user_id, values):    user = db.query(\""UPDATE Users WHERE id = {0}\"", user_id, values)    cache.set(user_id, user)ライトスルーは書き込み処理のせいで全体としては遅いオペレーションですが、書き込まれたばかりのデータに関する読み込みは速いです。ユーザー側は一般的にデータ更新時の方が読み込み時よりもレイテンシーに許容的です。キャッシュ内のデータは最新版で保たれます。欠点: ライトスルーノードが落ちたこと、もしくはスケーリングによって新しいノードが作成された時に、新しいノードはデータベース内のエントリーが更新されるまではエントリーをキャッシュしません。キャッシュアサイドとライトスルーを併用することでこの問題を緩和できます。書き込まれたデータの大部分は一度も読み込まれることはありません。このデータはTTLによって圧縮することができます。ライトビハインド (ライトバック)      Source: Scalability, availability, stability, patternsライトビハインドではアプリケーションは以下のことをします:キャッシュのエントリーを追加・更新しますデータストアへの書き込みを非同期的に行うことで、書き込みパフォーマンスを向上させます。欠点: ライトビハインドキャッシュがデータストア内のコンテンツにヒットする前にキャッシュが落ちるとデータ欠損が起きる可能性があります。キャッシュアサイドやライトスルーよりも実装が複雑になります。リフレッシュアヘッド      Source: From cache to in-memory data grid期限切れよりも前に、直近でアクセスされた全てのキャッシュエントリを自動的に更新するように設定することができます。もしどのアイテムが将来必要になるのかを正確に予測することができるのならば、リードスルーよりもレイテンシーを削減することができます。欠点: リフレッシュアヘッドどのアイテムが必要になるかの予測が正確でない場合にはリフレッシュアヘッドがない方がレイテンシーは良いという結果になってしまいます。欠点: キャッシュcache invalidationなどを用いて、データベースなどの真のデータとキャッシュの間の一貫性を保つ必要があります。Redisやmemcachedを追加することでアプリケーション構成を変更する必要があります。Cache invalidationも難しいですがそれに加えて、いつキャッシュを更新するかという複雑な問題にも悩まされることになります。その他の参考資料、ページFrom cache to in-memory data gridスケーラブルなシステムデザインパターンスケールできるシステムを設計するためのイントロダクションスケーラビリティ、可用性、安定性、パターンスケーラビリティAWS ElastiCacheのストラテジーWikipedia非同期処理      Source: Intro to architecting systems for scale非同期のワークフローはもし、連続的に行われるとリクエスト時間を圧迫してしまうような重い処理を別で処理する手法です。また、定期的にデータを集合させるなどの時間がかかるような処理を前もって処理しておくことにも役立ちます。メッセージキューメッセージキューはメッセージを受け取り、保存し、配信します。もし、処理がインラインで行うには遅すぎる場合、以下のようなワークフローでメッセージキューを用いるといいでしょう:アプリケーションはジョブをキューに配信し、ユーザーにジョブステータスを伝えます。ワーカーがジョブキューから受け取って、処理を行い、終了したらそのシグナルを返します。ユーザーの処理が止まることはなく、ジョブはバックグラウンドで処理されます。この間に、クライアントはオプションとして、タスクが完了したかのように見せるために小規模の処理を行います。例えば、ツイートを投稿するときに、ツイートはすぐにあなたのタイムラインに反映されたように見えますが、そのツイートが実際に全てのフォロワーに配信されるまでにはもう少し時間がかかっているでしょう。Redis はシンプルなメッセージ仲介としてはいいですが、メッセージが失われてしまう可能性があります。RabbitMQ はよく使われていますが、'AMQP'プロトコルに対応して、自前のノードを立てる必要があります。Amazon SQS という選択肢もありますが、レイテンシーが高く、メッセージが重複して配信されてしまう可能性があります。タスクキュータスクキューはタスクとその関連するデータを受け取り、処理した上でその結果を返します。スケジュール管理をできるほか、バックグラウンドでとても重いジョブをこなすこともできます。Celery はスケジューリングとpythonのサポートがあります。バックプレッシャーもし、キューが拡大しすぎると、メモリーよりもキューの方が大きくなりキャッシュミスが起こり、ディスク読み出しにつながり、パフォーマンスが低下することにつながります。バックプレッシャーはキューサイズを制限することで回避することができ、高いスループットを確保しキューにすでにあるジョブについてのレスポンス時間を短縮できます。キューがいっぱいになると、クライアントはサーバービジーもしくはHTTP 503をレスポンスとして受け取りまた後で時間をおいてアクセスするようにメッセージを受け取ります。クライアントはexponential backoffなどによって後ほど再度時間を置いてリクエストすることができます。欠点: 非同期処理キューを用いることで遅延が起こり、複雑さも増すため、あまり重くない計算処理やリアルタイムワークフローにおいては同期処理の方がいいでしょう。その他の参考資料、ページIt's all a numbers gameオーバーロードした時にバックプレッシャーを適用するLittle's lawメッセージキューとタスクキューの違いとは？通信      Source: OSI 7 layer modelHypertext transfer protocol (HTTP)HTTP はクライアントとサーバー間でのデータをエンコードして転送するための手法です。リクエスト・レスポンスに関わるプロトコルです。クライアントがリクエストをサーバーに投げ、サーバーがリクエストに関係するコンテンツと完了ステータス情報をレスポンスとして返します。HTTPは自己完結するので、間にロードバランサー、キャッシュ、エンクリプション、圧縮などのどんな中間ルーターが入っても動くようにできています。基本的なHTTPリクエストはHTTP動詞(メソッド)とリソース(エンドポイント)で成り立っています。以下がよくあるHTTP動詞です。:動詞詳細冪等性*セーフキャッシュできるかGETリソースを読み取るYesYesYesPOSTリソースを作成するもしくはデータを処理するトリガーNoNoYes レスポンスが新しい情報を含む場合PUTリソースを作成もしくは入れ替えるYesNoNoPATCHリソースを部分的に更新するNoNoYes レスポンスが新しい情報を含む場合DELETEリソースを削除するYesNoNo何度呼んでも同じ結果が返ってくることHTTPはTCP や UDP などの低級プロトコルに依存しているアプリケーションレイヤーのプロトコルである。その他の参考資料、ページ: HTTPHTTPってなに?HTTP と TCPの違いPUT と PATCHの違い伝送制御プロトコル (TCP)      Source: How to make a multiplayer gameTCPはIP networkの上で成り立つ接続プロトコルです。接続はhandshakeによって開始、解除されます。全ての送信されたパケットは欠損なしで送信先に送信された順番で到達するように以下の方法で保証されています:シーケンス番号とchecksum fieldsが全てのパケットに用意されているAcknowledgementパケットと自動再送信もし送信者が正しいレスポンスを受け取らなかったとき、パケットを再送信します。複数のタイムアウトがあったとき、接続は解除されます。TCP はフロー制御 と 輻輳制御も実装しています。これらの機能によって速度は低下し、一般的にUDPよりも非効率な転送手段になっています。ハイスループットを実現するために、ウェブサーバーはかなり大きな数のTCP接続を開いておくことがあり、そのことでメモリー使用が圧迫されます。ウェブサーバスレッドと例えばmemcached サーバーの間で多数のコネクションを保っておくことは高くつくかもしれません。可能なところではUDPに切り替えるだけでなくコネクションプーリングなども役立つかもしれません。TCPは高い依存性を要し、時間制約が厳しくないものに適しているでしょう。ウェブサーバー、データベース情報、SMTP、FTPやSSHなどの例に適用されます。以下の時にUDPよりもTCPを使うといいでしょう:全てのデータが欠損することなしに届いてほしいネットワークスループットの最適な自動推測をしてオペレーションしたいユーザデータグラムプロトコル (UDP)      Source: How to make a multiplayer gameUDPはコネクションレスです。データグラム（パケットのようなもの）はデータグラムレベルでの保証しかされません。データグラムは順不同で受け取り先に到着したりそもそも着かなかったりします。UDPは輻輳制御をサポートしません。TCPにおいてはサポートされているこれらの保証がないため、UDPは一般的に、TCPよりも効率的です。UDPはサブネット上のすべての機器にデータグラムを送信することができます。これはDHCP において役に立ちます。というのも、クライアントはまだIPアドレスを取得していないので、IPアドレスを必要とするTCPによるストリームができないからです。UDPは信頼性の面では劣りますが、VoIP、ビデオチャット、ストリーミングや同時通信マルチプレイヤーゲームなどのリアルタイム性が重視される時にはとても効果的です。TCPよりもUDPを使うのは:レイテンシーを最低限に抑えたい時データ欠損よりも、データ遅延を重視するときエラー修正を自前で実装したいときその他の参考資料、ページ: TCP と UDPゲームプログラミングのためのネットワークTCP と UDP プロトコルの主な違いTCP と UDPの違いTransmission control protocolUser datagram protocolFacebookのメムキャッシュスケーリング遠隔手続呼出 (RPC)      Source: Crack the system design interviewRPCではクライアントがリモートサーバーなどの異なるアドレス空間でプロシージャーが処理されるようにします。プロシージャーはローカルでのコールのように、クライアントからサーバーにどのように通信するかという詳細を省いた状態でコードが書かれます。リモートのコールは普通、ローカルのコールよりも遅く、信頼性に欠けるため、RPCコールをローカルコールと区別させておくことが好ましいでしょう。人気のRPCフレームワークは以下です。Protobuf、 Thrift、AvroRPC は リクエストレスポンスプロトコル:クライアントプログラム - クライアントスタブプロシージャーを呼び出します。パラメータはローカルでのプロシージャーコールのようにスタックへとプッシュされていきます。クライアントスタブプロシージャー - プロシージャIDとアーギュメントをパックしてリクエストメッセージにします。クライアント通信モジュール - OSがクライアントからサーバーへとメッセージを送ります。サーバー通信モジュール - OSが受け取ったパケットをサーバースタブプロシージャーに受け渡します。サーバースタブプロシージャー -  結果を展開し、プロシージャーIDにマッチするサーバープロシージャーを呼び出し、結果を返します。サーバーレスポンスは上記のステップを逆順で繰り返します。Sample RPC calls:GET /someoperation?data=anIdPOST /anotheroperation{  \""data\"":\""anId\"";  \""anotherdata\"": \""another value\""}RPCは振る舞いを公開することに焦点を当てています。RPCは内部通信パフォーマンスを理由として使われることが多いです。というのも、使用する状況に合わせてネイティブコールを自作することができるからです。ネイティブライブラリー (aka SDK) を呼ぶのは以下の時:ターゲットのプラットフォームを知っている時ロジックがどのようにアクセスされるのかを管理したいときライブラリー外でエラーがどのようにコントロールされるかを管理したい時パフォーマンスとエンドユーザーエクスペリエンスが最優先の時REST プロトコルに従うHTTP APIはパブリックAPIにおいてよく用いられます。欠点: RPCRPCクライアントとはサービス実装により厳密に左右されることになります。新しいオペレーション、使用例があるたびに新しくAPIが定義されなければなりません。RPCをデバッグするのは難しい可能性があります。既存のテクノロジーをそのまま使ってサービスを構築することはできないかもしれません。例えば、SquidなどのサーバーにRPCコールが正しくキャッシュ されるように追加で骨を折る必要があるかもしれません。Representational state transfer (REST)RESTは、クライアントがサーバーによってマネージされるリソースに対して処理を行うクライアント・サーバーモデルを支持するアーキテキチャスタイルです。サーバーは操作できるもしくは新しいリソースレプレゼンテーションを受け取ることができるようなリソースやアクションのレプレゼンテーションを提供します。すべての通信はステートレスでキャッシュ可能でなければなりません。RESTful なインターフェースには次の四つの特徴があります:特徴的なリソース (URI in HTTP) - どのオペレーションであっても同じURIを使う。HTTP動詞によって変わる (Verbs in HTTP) - 動詞、ヘッダー、ボディを使う自己説明的なエラーメッセージ (status response in HTTP) - ステータスコードを使い、新しく作ったりしないこと。HATEOAS (HTML interface for HTTP) - 自分のwebサービスがブラウザで完全にアクセスできること。サンプル REST コール:GET /someresources/anIdPUT /someresources/anId{\""anotherdata\"": \""another value\""}RESTはデータを公開することに焦点を当てています。クライアントとサーバーのカップリングを最小限にするもので、パブリックAPIなどによく用いられます。RESTはURI、 representation through headers、そして、GET、POST、PUT、 DELETE、PATCHなどのHTTP動詞等のよりジェネリックで統一されたメソッドを用います。ステートレスであるのでRESTは水平スケーリングやパーティショニングに最適です。欠点: RESTRESTはデータ公開に焦点を当てているので、リソースが自然に整理されていなかったり、シンプルなヒエラルキーで表せられない時にはよい選択肢とは言えないかもしれません。例えば、とあるイベントのセットにマッチするすべての更新情報を返すと言った処理は簡単にはパスで表現することができません。RESTでは、URIパス、クエリパラメータ、そして場合によってはリクエストボディなどによって実装されることが多いでしょう。RESTは少数の動詞に依存しています(GET、POST、PUT、DELETE、そして PATCH) が時には使いたい事例に合わないことがあります。例えば、期限の切れたドキュメントをアーカイブに移したい場合などはこれらの動詞の中には綺麗にはフィットしません。ネストされたヒエラルキーの中にあるリソースをとってくるのはシングルビューを描画するのにクライアントとサーバー間で数回やりとりしなければなりません。例として、ブログエントリーのコンテンツとそれに対するコメントを表示する場合などです。様々なネットワーク環境で動作する可能性が考えられるモバイルアプリケーションにおいてはこのような複数のやり取りは好ましくありません。時が経つにつれて、APIレスポンスにより多くのフィールドが与えられて、古いクライアントはすでにいらないものも含めてすべてのデータフィールドを受け取ることになります。そのことで、ペイロードが大きくなりすぎて、レイテンシーも拡大することになります。RPCとREST比較OperationRPCRESTサインアップPOST /signupPOST /personsリザインPOST /resign{\""personid\"": \""1234\""}DELETE /persons/1234Person読み込みGET /readPerson?personid=1234GET /persons/1234Personのアイテムリスト読み込みGET /readUsersItemsList?personid=1234GET /persons/1234/itemsPersonのアイテムへのアイテム追加POST /addItemToUsersItemsList{\""personid\"": \""1234\"";\""itemid\"": \""456\""}POST /persons/1234/items{\""itemid\"": \""456\""}アイテム更新POST /modifyItem{\""itemid\"": \""456\"";\""key\"": \""value\""}PUT /items/456{\""key\"": \""value\""}アイテム削除POST /removeItem{\""itemid\"": \""456\""}DELETE /items/456  Source: Do you really know why you prefer REST over RPCその他の参考資料、ページ: REST と RPCDo you really know why you prefer REST over RPCWhen are RPC-ish approaches more appropriate than REST?REST vs JSON-RPCDebunking the myths of RPC and RESTWhat are the drawbacks of using RESTCrack the system design interviewThriftWhy REST for internal use and not RPCセキュリティこのセクションは更新が必要です。contributingしてください！セキュリティは幅広いトピックです。十分な経験、セキュリティ分野のバックグラウンドがなくても、セキュリティの知識を要する職に応募するのでない限り、基本以上のことを知る必要はないでしょう。情報伝達、保存における暗号化XSS や SQL injectionを防ぐために、全てのユーザー入力もしくはユーザーに露出される入力パラメーターをサニタイズするSQL injectionを防ぐためにパラメータ化されたクエリを用いる。least privilegeの原理を用いるその他の参考資料、ページ:開発者のためのセキュリティガイドOWASP top ten補遺暗算で、推計値を求める必要があることも時にはあります。例えば、ディスクから100枚イメージ分のサムネイルを作る時間を求めたり、その時にどれだけディスクメモリーが消費されるかなどの値です。2の乗数表 と 全てのプログラマーが知るべきレイテンシー値 は良い参考になるでしょう。2の乗数表乗数           厳密な値         約        Bytes---------------------------------------------------------------7                             1288                             25610                           1024   1 thousand           1 KB16                         65,536                       64 KB20                      1,048,576   1 million            1 MB30                  1,073,741,824   1 billion            1 GB32                  4,294,967,296                        4 GB40              1,099,511,627,776   1 trillion           1 TBその他の参考資料、ページ:2の乗数表全てのプログラマーが知るべきレイテンシー値Latency Comparison Numbers--------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy            10,000   ns       10 usSend 1 KB bytes over 1 Gbps network     10,000   ns       10 usRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSDRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSDSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 msNotes-----1 ns = 10^-9 seconds1 us = 10^-6 seconds = 1,000 ns1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns上記表に基づいた役に立つ数値:ディスクからの連続読み取り速度 30 MB/s1 Gbps Ethernetからの連続読み取り速度　100 MB/sSSDからの連続読み取り速度 1 GB/smain memoryからの連続読み取り速度 4 GB/s1秒で地球6-7周できる1秒でデータセンターと2000周やりとりできるレイテンシーの視覚的表その他の参考資料、ページ:全てのプログラマーが知るべきレイテンシー値 - 1全てのプログラマーが知るべきレイテンシー値 - 2Designs, lessons, and advice from building large distributed systemsSoftware Engineering Advice from Building Large-Scale Distributed Systems他のシステム設計面接例題頻出のシステム設計面接課題とその解答へのリンク質問解答Dropboxのようなファイル同期サービスを設計するyoutube.comGoogleのような検索エンジンの設計queue.acm.orgstackexchange.comardendertat.comstanford.eduGoogleのようなスケーラブルなwebクローラーの設計quora.comGoogle docsの設計code.google.comneil.fraser.nameRedisのようなキーバリューストアの設計slideshare.netMemcachedのようなキャッシュシステムの設計slideshare.netAmazonのようなレコメンデーションシステムの設計hulu.comijcai13.orgBitlyのようなURL短縮サービスの設計n00tc0d3r.blogspot.comWhatsAppのようなチャットアプリの設計highscalability.comInstagramのような写真共有サービスの設計highscalability.comhighscalability.comFacebookニュースフィードの設計quora.comquora.comslideshare.netFacebookタイムラインの設計facebook.comhighscalability.comFacebookチャットの設計erlang-factory.comfacebook.comFacebookのようなgraph検索の設計facebook.comfacebook.comfacebook.comCloudFlareのようなCDNの設計cmu.eduTwitterのトレンド機能の設計michael-noll.comsnikolov .wordpress.comランダムID発行システムの設計blog.twitter.comgithub.com一定のインターバル時間での上位k件を返すucsb.eduwpi.edu複数のデータセンターからデータを配信するサービスの設計highscalability.comオンラインの複数プレイヤーカードゲームの設計indieflashblog.combuildnewgames.comガーベッジコレクションシステムの設計stuffwithstuff.comwashington.eduシステム設計例題を追加するContribute実世界のアーキテクチャ世の中のシステムがどのように設計されているかについての記事      Source: Twitter timelines at scale以下の記事の重箱の隅をつつくような細かい詳細にこだわらないこと。むしろ共通の原理、技術、パターンを探ることそれぞれのコンポーネントでどんな問題が解決され、コンポーネントはどこでうまく使えもしくは使えないかを知ること学んだことを復習すること種類システム参考ページデータ処理MapReduce - Googleの分散データ処理システムresearch.google.comデータ処理Spark - Databricksの分散データ処理システムslideshare.netデータ処理Storm - Twitterの分散データ処理システムslideshare.netデータストアBigtable - Googleのカラム指向分散データベースharvard.eduデータストアHBase - Bigtableのオープンソース実装slideshare.netデータストアCassandra - Facebookのカラム指向分散データベースslideshare.netデータストアDynamoDB - Amazonのドキュメント指向分散データベースharvard.eduデータストアMongoDB - ドキュメント指向分散データベースslideshare.netデータストアSpanner - Googleのグローバル分散データベースresearch.google.comデータストアMemcached - 分散メモリーキャッシングシステムslideshare.netデータストアRedis - 永続性とバリュータイプを兼ね備えた分散メモリーキャッシングシステムslideshare.netファイルシステムGoogle File System (GFS) - 分散ファイルシステムresearch.google.comファイルシステムHadoop File System (HDFS) - GFSのオープンソース実装apache.orgMiscChubby - 疎結合の分散システムをロックするGoogleのサービスresearch.google.comMiscDapper - 分散システムを追跡するインフラresearch.google.comMiscKafka - LinkedInによるPub/subメッセージキューslideshare.netMiscZookeeper - 同期を可能にする中央集権インフラとサービスslideshare.netアーキテクチャを追加するContribute各企業のアーキテクチャ企業参考ページAmazonAmazon architectureCinchcastProducing 1,500 hours of audio every dayDataSiftRealtime datamining At 120,000 tweets per secondDropBoxHow we've scaled DropboxESPNOperating At 100,000 duh nuh nuhs per secondGoogleGoogle architectureInstagram14 million users, terabytes of photosWhat powers InstagramJustin.tvJustin.Tv's live video broadcasting architectureFacebookScaling memcached at FacebookTAO: Facebook’s distributed data store for the social graphFacebook’s photo storageFlickrFlickr architectureMailboxFrom 0 to one million users in 6 weeksPinterestFrom 0 To 10s of billions of page views a month18 million visitors, 10x growth, 12 employeesPlayfish50 million monthly users and growingPlentyOfFishPlentyOfFish architectureSalesforceHow they handle 1.3 billion transactions a dayStack OverflowStack Overflow architectureTripAdvisor40M visitors, 200M dynamic page views, 30TB dataTumblr15 billion page views a monthTwitterMaking Twitter 10000 percent fasterStoring 250 million tweets a day using MySQL150M active users, 300K QPS, a 22 MB/S firehoseTimelines at scaleBig and small data at TwitterOperations at Twitter: scaling beyond 100 million usersUberHow Uber scales their real-time market platformWhatsAppThe WhatsApp architecture Facebook bought for $19 billionYouTubeYouTube scalabilityYouTube architecture企業のエンジニアブログ面接を受ける企業のアーキテクチャ投げられる質問は同じ分野から来ることもあるでしょうAirbnb EngineeringAtlassian DevelopersAutodesk EngineeringAWS BlogBitly Engineering BlogBox BlogsCloudera Developer BlogDropbox Tech BlogEngineering at QuoraEbay Tech BlogEvernote Tech BlogEtsy Code as CraftFacebook EngineeringFlickr CodeFoursquare Engineering BlogGitHub Engineering BlogGoogle Research BlogGroupon Engineering BlogHeroku Engineering BlogHubspot Engineering BlogHigh ScalabilityInstagram EngineeringIntel Software BlogJane Street Tech BlogLinkedIn EngineeringMicrosoft EngineeringMicrosoft Python EngineeringNetflix Tech BlogPaypal Developer BlogPinterest Engineering BlogQuora EngineeringReddit BlogSalesforce Engineering BlogSlack Engineering BlogSpotify LabsTwilio Engineering BlogTwitter EngineeringUber Engineering BlogYahoo Engineering BlogYelp Engineering BlogZynga Engineering Blogその他の参考資料、ページ:kilimchoi/engineering-blogsここにあるリストは比較的小規模なものにとどめ、kilimchoi/engineering-blogsにより詳細に記すことで重複しないようにしておくことにする。エンジニアブログへのリンクを追加する場合はここではなく、engineering-blogsレボジトリに追加することを検討してください。進行中の作業セクションの追加や、進行中の作業を手伝っていただける場合はこちら!MapReduceによる分散コンピューティングConsistent hashingScatter gatherContributeクレジットクレジット及び、参照ページは適時このリポジトリ内に記載してありますSpecial thanks to:Hired in techCracking the coding interviewHigh scalabilitycheckcheckzz/system-design-interviewshashank88/system_designmmcgrana/services-engineeringSystem design cheat sheetA distributed systems reading listCracking the system design interviewContact infoFeel free to contact me to discuss any issues, questions, or comments.My contact info can be found on my GitHub page.LicenseI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2017 Donne MartinCreative Commons Attribution 4.0 International License (CC BY 4.0)http://creativecommons.org/licenses/by/4.0/"
30,AUTOMATIC1111/stable-diffusion-webui,https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/README.md,Python,"Stable Diffusion web UIA browser interface based on Gradio library for Stable Diffusion.FeaturesDetailed feature showcase with images:Original txt2img and img2img modesOne click install and run script (but you still must install python and git)OutpaintingInpaintingColor SketchPrompt MatrixStable Diffusion UpscaleAttention, specify parts of text that the model should pay more attention toa man in a ((tuxedo)) - will pay more attention to tuxedoa man in a (tuxedo:1.21) - alternative syntaxselect text and press Ctrl+Up or Ctrl+Down (or Command+Up or Command+Down if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)Loopback, run img2img processing multiple timesX/Y/Z plot, a way to draw a 3 dimensional plot of images with different parametersTextual Inversionhave as many embeddings as you want and use any names you like for themuse multiple embeddings with different numbers of vectors per tokenworks with half precision floating point numberstrain embeddings on 8GB (also reports of 6GB working)Extras tab with:GFPGAN, neural network that fixes facesCodeFormer, face restoration tool as an alternative to GFPGANRealESRGAN, neural network upscalerESRGAN, neural network upscaler with a lot of third party modelsSwinIR and Swin2SR (see here), neural network upscalersLDSR, Latent diffusion super resolution upscalingResizing aspect ratio optionsSampling method selectionAdjust sampler eta values (noise multiplier)More advanced noise setting optionsInterrupt processing at any time4GB video card support (also reports of 2GB working)Correct seeds for batchesLive prompt token length validationGeneration parametersparameters you used to generate images are saved with that imagein PNG chunks for PNG, in EXIF for JPEGcan drag the image to PNG info tab to restore generation parameters and automatically copy them into UIcan be disabled in settingsdrag and drop an image/text-parameters to promptboxRead Generation Parameters Button, loads parameters in promptbox to UISettings pageRunning arbitrary python code from UI (must run with --allow-code to enable)Mouseover hints for most UI elementsPossible to change defaults/mix/max/step values for UI elements via text configTiling support, a checkbox to create images that can be tiled like texturesProgress bar and live image generation previewCan use a separate neural network to produce previews with almost none VRAM or compute requirementNegative prompt, an extra text field that allows you to list what you don't want to see in generated imageStyles, a way to save part of prompt and easily apply them via dropdown laterVariations, a way to generate same image but with tiny differencesSeed resizing, a way to generate same image but at slightly different resolutionCLIP interrogator, a button that tries to guess prompt from an imagePrompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midwayBatch Processing, process a group of files using img2imgImg2img Alternative, reverse Euler method of cross attention controlHighres Fix, a convenience option to produce high resolution pictures in one click without usual distortionsReloading checkpoints on the flyCheckpoint Merger, a tab that allows you to merge up to 3 checkpoints into oneCustom scripts with many extensions from communityComposable-Diffusion, a way to use multiple prompts at onceseparate prompts using uppercase ANDalso supports weights for prompts: a cat :1.2 AND a dog AND a penguin :2.2No token limit for prompts (original stable diffusion lets you use up to 75 tokens)DeepDanbooru integration, creates danbooru style tags for anime promptsxformers, major speed increase for select cards: (add --xformers to commandline args)via extension: History tab: view, direct and delete images conveniently within the UIGenerate forever optionTraining tabhypernetworks and embeddings optionsPreprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)Clip skipHypernetworksLoras (same as Hypernetworks but more pretty)A sparate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your promptCan select to load a different VAE from settings screenEstimated completion time in progress barAPISupport for dedicated inpainting model by RunwayMLvia extension: Aesthetic Gradients, a way to generate images with a specific aesthetic by using clip images embeds (implementation of https://github.com/vicgalle/stable-diffusion-aesthetic-gradients)Stable Diffusion 2.0 support - see wiki for instructionsAlt-Diffusion support - see wiki for instructionsNow without any bad letters!Load checkpoints in safetensors formatEased resolution restriction: generated image's domension must be a multiple of 8 rather than 64Now with a license!Reorder elements in the UI from settings screenInstallation and RunningMake sure the required dependencies are met and follow the instructions available for both NVidia (recommended) and AMD GPUs.Alternatively, use online services (like Google Colab):List of Online ServicesInstallation on Windows 10/11 with NVidia-GPUs using release packageDownload sd.webui.zip from v1.0.0-pre and extract it's contents.Run update.bat.Run run.bat.For more details see Install-and-Run-on-NVidia-GPUsAutomatic Installation on WindowsInstall Python 3.10.6 (Newer version of Python does not support torch), checking \""Add Python to PATH\"".Install git.Download the stable-diffusion-webui repository, for example by running git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git.Run webui-user.bat from Windows Explorer as normal, non-administrator, user.Automatic Installation on LinuxInstall the dependencies:# Debian-based:sudo apt install wget git python3 python3-venv# Red Hat-based:sudo dnf install wget git python3# Arch-based:sudo pacman -S wget git python3Navigate to the directory you would like the webui to be installed and execute the following command:bash <(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)Run webui.sh.Check webui-user.sh for options.Installation on Apple SiliconFind the instructions here.ContributingHere's how to add code to this repo: ContributingDocumentationThe documentation was moved from this README over to the project's wiki.For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) crawlable wiki.CreditsLicenses for borrowed code can be found in Settings -> Licenses screen, and also in html/licenses.html file.Stable Diffusion - https://github.com/CompVis/stable-diffusion, https://github.com/CompVis/taming-transformersk-diffusion - https://github.com/crowsonkb/k-diffusion.gitGFPGAN - https://github.com/TencentARC/GFPGAN.gitCodeFormer - https://github.com/sczhou/CodeFormerESRGAN - https://github.com/xinntao/ESRGANSwinIR - https://github.com/JingyunLiang/SwinIRSwin2SR - https://github.com/mv-lab/swin2srLDSR - https://github.com/Hafiidz/latent-diffusionMiDaS - https://github.com/isl-org/MiDaSIdeas for optimizations - https://github.com/basujindal/stable-diffusionCross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)Sub-quadratic Cross Attention layer optimization - Alex Birch (Birch-san/diffusers#1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we're not using his code, but we are using his ideas).Idea for SD upscale - https://github.com/jquesnelle/txt2imghdNoise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-botCLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogatorIdea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorchxformers - https://github.com/facebookresearch/xformersDeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooruSampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pixSecurity advice - RyotaKUniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPCTAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesdLyCORIS - KohakuBlueleafInitial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.(You)"
31,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
32,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.⚠️ IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!⚠️ IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means you’ve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the project’s direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a project’s website for a “team” page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participants’ behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, “How do I…“ or “What do you think about…“ instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
33,geekcomputers/Python,https://github.com/geekcomputers/Python/blob/master/README.md,Python,"My Python Eggs 🐍 😄I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in Notepad++ 🗒️Feel free to explore the scripts and use them for your learning and automation needs!List of Scripts:batch_file_rename.py - Batch rename a group of files in a specified directory, changing their extensions.create_dir_if_not_there.py - Check if a directory exists in the user's home directory. Create it if it doesn't exist.Fast Youtube Downloader - Download YouTube videos quickly with parallel threads using aria2c.Google Image Downloader - Query a given term and retrieve images from the Google Image database.dir_test.py - Test if the directory testdir exists. If not, create it.env_check.py - Check if all the required environment variables are set.blackjack.py - Casino Blackjack-21 game in Python.fileinfo.py - Show file information for a given file.folder_size.py - Scan the current directory and all subdirectories and display their sizes.logs.py - Search for all *.log files in a directory, zip them using the specified program, and date stamp them.move_files_over_x_days.py - Move all files over a specified age (in days) from the source directory to the destination directory.nslookup_check.py - Open the file server_list.txt and perform nslookup for each server to check the DNS entry.osinfo.py - Display information about the operating system on which the script is running.ping_servers.py - Ping the servers associated with the specified application group.ping_subnet.py - Scan the final range of a given IP subnet for available addresses.powerdown_startup.py - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.puttylogs.py - Zip all the logs in the given directory.script_count.py - Scan the scripts directory and count the different types of scripts.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.script_listing.py - List all files in a given directory and its subdirectories.testlines.py - Open a file and print out 100 lines of the set line variable.tweeter.py - Tweet text or a picture from the terminal.serial_scanner.py - List available serial ports in use on Linux and Windows systems.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.CountMillionCharacter.py and CountMillionCharacter2.0 - Get character count of a text file.xkcd_downloader.py - Download the latest XKCD comic and place them in a new folder called \""comics\"".timymodule.py - An alternative to Python's 'timeit' module and easier to use.calculator.py - Implement a calculator using Python's eval() function.Google_News.py - Use BeautifulSoup to provide latest news headlines along with news links.cricket_live_score - Use BeautifulSoup to provide live cricket scores.youtube.py - Take a song name as input and fetch the YouTube URL of the best matching song and play it.site_health.py - Check the health of a remote server.SimpleStopWatch.py - Simple stop watch implementation using Python's time module.Changemac.py - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).whatsapp-monitor.py - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.whatsapp-chat-analyzer.py - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.JARVIS.py - Control Windows programs with your voice.Images Downloader - Download images from webpages on Unix-based systems.space_invader.py.py - Classical 2D space invader game to recall your childhood memories.Test Case Generator - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.Note: The content in this repository belongs to the respective authors and creators. I'm just providing a formatted README.md for better presentation."
34,floodsung/Deep-Learning-Papers-Reading-Roadmap,https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md,Python,"Deep Learning Papers Reading RoadmapIf you are a newcomer to the Deep Learning area, the first question you may have is \""Which paper should I start reading from?\""Here is a reading roadmap of Deep Learning papers!The roadmap is constructed in accordance with the following four guidelines:From outline to detailFrom old to state-of-the-artfrom generic to specific areasfocus on state-of-the-artYou will find many papers that are quite new but really worth reading.I would continue adding papers to this roadmap.1 Deep Learning History and Basics1.0 Book[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. \""Deep learning.\"" An MIT Press book. (2015). [html] (Deep Learning Bible, you can read this book while reading following papers.) ⭐⭐⭐⭐⭐1.1 Survey[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. \""Deep learning.\"" Nature 521.7553 (2015): 436-444. [pdf] (Three Giants' Survey) ⭐⭐⭐⭐⭐1.2 Deep Belief Network(DBN)(Milestone of Deep Learning Eve)[2] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. \""A fast learning algorithm for deep belief nets.\"" Neural computation 18.7 (2006): 1527-1554. [pdf](Deep Learning Eve) ⭐⭐⭐[3] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. \""Reducing the dimensionality of data with neural networks.\"" Science 313.5786 (2006): 504-507. [pdf] (Milestone, Show the promise of deep learning) ⭐⭐⭐1.3 ImageNet Evolution（Deep Learning broke out from here）[4] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \""Imagenet classification with deep convolutional neural networks.\"" Advances in neural information processing systems. 2012. [pdf] (AlexNet, Deep Learning Breakthrough) ⭐⭐⭐⭐⭐[5] Simonyan, Karen, and Andrew Zisserman. \""Very deep convolutional networks for large-scale image recognition.\"" arXiv preprint arXiv:1409.1556 (2014). [pdf] (VGGNet,Neural Networks become very deep!) ⭐⭐⭐[6] Szegedy, Christian, et al. \""Going deeper with convolutions.\"" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [pdf] (GoogLeNet) ⭐⭐⭐[7] He, Kaiming, et al. \""Deep residual learning for image recognition.\"" arXiv preprint arXiv:1512.03385 (2015). [pdf] (ResNet,Very very deep networks, CVPR best paper) ⭐⭐⭐⭐⭐1.4 Speech Recognition Evolution[8] Hinton, Geoffrey, et al. \""Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups.\"" IEEE Signal Processing Magazine 29.6 (2012): 82-97. [pdf] (Breakthrough in speech recognition)⭐⭐⭐⭐[9] Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. \""Speech recognition with deep recurrent neural networks.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (RNN)⭐⭐⭐[10] Graves, Alex, and Navdeep Jaitly. \""Towards End-To-End Speech Recognition with Recurrent Neural Networks.\"" ICML. Vol. 14. 2014. [pdf]⭐⭐⭐[11] Sak, Haşim, et al. \""Fast and accurate recurrent neural network acoustic models for speech recognition.\"" arXiv preprint arXiv:1507.06947 (2015). [pdf] (Google Speech Recognition System) ⭐⭐⭐[12] Amodei, Dario, et al. \""Deep speech 2: End-to-end speech recognition in english and mandarin.\"" arXiv preprint arXiv:1512.02595 (2015). [pdf] (Baidu Speech Recognition System) ⭐⭐⭐⭐[13] W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig \""Achieving Human Parity in Conversational Speech Recognition.\"" arXiv preprint arXiv:1610.05256 (2016). [pdf] (State-of-the-art in speech recognition, Microsoft) ⭐⭐⭐⭐After reading above papers, you will have a basic understanding of the Deep Learning history, the basic architectures of Deep Learning model(including CNN, RNN, LSTM) and how deep learning can be applied to image and speech recognition issues. The following papers will take you in-depth understanding of the Deep Learning method, Deep Learning in different areas of application and the frontiers. I suggest that you can choose the following papers based on your interests and research direction.#2 Deep Learning Method2.1 Model[14] Hinton, Geoffrey E., et al. \""Improving neural networks by preventing co-adaptation of feature detectors.\"" arXiv preprint arXiv:1207.0580 (2012). [pdf] (Dropout) ⭐⭐⭐[15] Srivastava, Nitish, et al. \""Dropout: a simple way to prevent neural networks from overfitting.\"" Journal of Machine Learning Research 15.1 (2014): 1929-1958. [pdf] ⭐⭐⭐[16] Ioffe, Sergey, and Christian Szegedy. \""Batch normalization: Accelerating deep network training by reducing internal covariate shift.\"" arXiv preprint arXiv:1502.03167 (2015). [pdf] (An outstanding Work in 2015) ⭐⭐⭐⭐[17] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \""Layer normalization.\"" arXiv preprint arXiv:1607.06450 (2016). [pdf] (Update of Batch Normalization) ⭐⭐⭐⭐[18] Courbariaux, Matthieu, et al. \""Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or−1.\"" [pdf] (New Model,Fast)  ⭐⭐⭐[19] Jaderberg, Max, et al. \""Decoupled neural interfaces using synthetic gradients.\"" arXiv preprint arXiv:1608.05343 (2016). [pdf] (Innovation of Training Method,Amazing Work) ⭐⭐⭐⭐⭐[20] Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. \""Net2net: Accelerating learning via knowledge transfer.\"" arXiv preprint arXiv:1511.05641 (2015). [pdf] (Modify previously trained network to reduce training epochs) ⭐⭐⭐[21] Wei, Tao, et al. \""Network Morphism.\"" arXiv preprint arXiv:1603.01670 (2016). [pdf] (Modify previously trained network to reduce training epochs) ⭐⭐⭐2.2 Optimization[22] Sutskever, Ilya, et al. \""On the importance of initialization and momentum in deep learning.\"" ICML (3) 28 (2013): 1139-1147. [pdf] (Momentum optimizer) ⭐⭐[23] Kingma, Diederik, and Jimmy Ba. \""Adam: A method for stochastic optimization.\"" arXiv preprint arXiv:1412.6980 (2014). [pdf] (Maybe used most often currently) ⭐⭐⭐[24] Andrychowicz, Marcin, et al. \""Learning to learn by gradient descent by gradient descent.\"" arXiv preprint arXiv:1606.04474 (2016). [pdf] (Neural Optimizer,Amazing Work) ⭐⭐⭐⭐⭐[25] Han, Song, Huizi Mao, and William J. Dally. \""Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding.\"" CoRR, abs/1510.00149 2 (2015). [pdf] (ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup) ⭐⭐⭐⭐⭐[26] Iandola, Forrest N., et al. \""SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size.\"" arXiv preprint arXiv:1602.07360 (2016). [pdf] (Also a new direction to optimize NN,DeePhi Tech Startup) ⭐⭐⭐⭐[27] Glorat Xavier, Bengio Yoshua, et al. \""Understanding the difficulty of training deep forward neural networks.\"" Proceedings of the thirteenth International Conference on Artificial Intelligence and Statistics, PMLR 9:249-256,2010. [pdf] ⭐⭐⭐⭐2.3 Unsupervised Learning / Deep Generative Model[28] Le, Quoc V. \""Building high-level features using large scale unsupervised learning.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (Milestone, Andrew Ng, Google Brain Project, Cat) ⭐⭐⭐⭐[29] Kingma, Diederik P., and Max Welling. \""Auto-encoding variational bayes.\"" arXiv preprint arXiv:1312.6114 (2013). [pdf] (VAE) ⭐⭐⭐⭐[30] Goodfellow, Ian, et al. \""Generative adversarial nets.\"" Advances in Neural Information Processing Systems. 2014. [pdf] (GAN,super cool idea) ⭐⭐⭐⭐⭐[31] Radford, Alec, Luke Metz, and Soumith Chintala. \""Unsupervised representation learning with deep convolutional generative adversarial networks.\"" arXiv preprint arXiv:1511.06434 (2015). [pdf] (DCGAN) ⭐⭐⭐⭐[32] Gregor, Karol, et al. \""DRAW: A recurrent neural network for image generation.\"" arXiv preprint arXiv:1502.04623 (2015). [pdf] (VAE with attention, outstanding work) ⭐⭐⭐⭐⭐[33] Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. \""Pixel recurrent neural networks.\"" arXiv preprint arXiv:1601.06759 (2016). [pdf] (PixelRNN) ⭐⭐⭐⭐[34] Oord, Aaron van den, et al. \""Conditional image generation with PixelCNN decoders.\"" arXiv preprint arXiv:1606.05328 (2016). [pdf] (PixelCNN) ⭐⭐⭐⭐[34] S. Mehri et al., \""SampleRNN: An Unconditional End-to-End Neural Audio Generation Model.\"" arXiv preprint \tarXiv:1612.07837 (2016). [pdf] ⭐⭐⭐⭐⭐2.4 RNN / Sequence-to-Sequence Model[35] Graves, Alex. \""Generating sequences with recurrent neural networks.\"" arXiv preprint arXiv:1308.0850 (2013). [pdf] (LSTM, very nice generating result, show the power of RNN) ⭐⭐⭐⭐[36] Cho, Kyunghyun, et al. \""Learning phrase representations using RNN encoder-decoder for statistical machine translation.\"" arXiv preprint arXiv:1406.1078 (2014). [pdf] (First Seq-to-Seq Paper) ⭐⭐⭐⭐[37] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \""Sequence to sequence learning with neural networks.\"" Advances in neural information processing systems. 2014. [pdf] (Outstanding Work) ⭐⭐⭐⭐⭐[38] Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. \""Neural Machine Translation by Jointly Learning to Align and Translate.\"" arXiv preprint arXiv:1409.0473 (2014). [pdf] ⭐⭐⭐⭐[39] Vinyals, Oriol, and Quoc Le. \""A neural conversational model.\"" arXiv preprint arXiv:1506.05869 (2015). [pdf] (Seq-to-Seq on Chatbot) ⭐⭐⭐2.5 Neural Turing Machine[40] Graves, Alex, Greg Wayne, and Ivo Danihelka. \""Neural turing machines.\"" arXiv preprint arXiv:1410.5401 (2014). [pdf] (Basic Prototype of Future Computer) ⭐⭐⭐⭐⭐[41] Zaremba, Wojciech, and Ilya Sutskever. \""Reinforcement learning neural Turing machines.\"" arXiv preprint arXiv:1505.00521 362 (2015). [pdf] ⭐⭐⭐[42] Weston, Jason, Sumit Chopra, and Antoine Bordes. \""Memory networks.\"" arXiv preprint arXiv:1410.3916 (2014). [pdf] ⭐⭐⭐[43] Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. \""End-to-end memory networks.\"" Advances in neural information processing systems. 2015. [pdf] ⭐⭐⭐⭐[44] Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. \""Pointer networks.\"" Advances in Neural Information Processing Systems. 2015. [pdf] ⭐⭐⭐⭐[45] Graves, Alex, et al. \""Hybrid computing using a neural network with dynamic external memory.\"" Nature (2016). [pdf] (Milestone,combine above papers' ideas) ⭐⭐⭐⭐⭐2.6 Deep Reinforcement Learning[46] Mnih, Volodymyr, et al. \""Playing atari with deep reinforcement learning.\"" arXiv preprint arXiv:1312.5602 (2013). [pdf]) (First Paper named deep reinforcement learning) ⭐⭐⭐⭐[47] Mnih, Volodymyr, et al. \""Human-level control through deep reinforcement learning.\"" Nature 518.7540 (2015): 529-533. [pdf] (Milestone) ⭐⭐⭐⭐⭐[48] Wang, Ziyu, Nando de Freitas, and Marc Lanctot. \""Dueling network architectures for deep reinforcement learning.\"" arXiv preprint arXiv:1511.06581 (2015). [pdf] (ICLR best paper,great idea)  ⭐⭐⭐⭐[49] Mnih, Volodymyr, et al. \""Asynchronous methods for deep reinforcement learning.\"" arXiv preprint arXiv:1602.01783 (2016). [pdf] (State-of-the-art method) ⭐⭐⭐⭐⭐[50] Lillicrap, Timothy P., et al. \""Continuous control with deep reinforcement learning.\"" arXiv preprint arXiv:1509.02971 (2015). [pdf] (DDPG) ⭐⭐⭐⭐[51] Gu, Shixiang, et al. \""Continuous Deep Q-Learning with Model-based Acceleration.\"" arXiv preprint arXiv:1603.00748 (2016). [pdf] (NAF) ⭐⭐⭐⭐[52] Schulman, John, et al. \""Trust region policy optimization.\"" CoRR, abs/1502.05477 (2015). [pdf] (TRPO) ⭐⭐⭐⭐[53] Silver, David, et al. \""Mastering the game of Go with deep neural networks and tree search.\"" Nature 529.7587 (2016): 484-489. [pdf] (AlphaGo) ⭐⭐⭐⭐⭐2.7 Deep Transfer Learning / Lifelong Learning / especially for RL[54] Bengio, Yoshua. \""Deep Learning of Representations for Unsupervised and Transfer Learning.\"" ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [pdf] (A Tutorial) ⭐⭐⭐[55] Silver, Daniel L., Qiang Yang, and Lianghao Li. \""Lifelong Machine Learning Systems: Beyond Learning Algorithms.\"" AAAI Spring Symposium: Lifelong Machine Learning. 2013. [pdf] (A brief discussion about lifelong learning)  ⭐⭐⭐[56] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \""Distilling the knowledge in a neural network.\"" arXiv preprint arXiv:1503.02531 (2015). [pdf] (Godfather's Work) ⭐⭐⭐⭐[57] Rusu, Andrei A., et al. \""Policy distillation.\"" arXiv preprint arXiv:1511.06295 (2015). [pdf] (RL domain) ⭐⭐⭐[58] Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. \""Actor-mimic: Deep multitask and transfer reinforcement learning.\"" arXiv preprint arXiv:1511.06342 (2015). [pdf] (RL domain) ⭐⭐⭐[59] Rusu, Andrei A., et al. \""Progressive neural networks.\"" arXiv preprint arXiv:1606.04671 (2016). [pdf] (Outstanding Work, A novel idea) ⭐⭐⭐⭐⭐2.8 One Shot Deep Learning[60] Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. \""Human-level concept learning through probabilistic program induction.\"" Science 350.6266 (2015): 1332-1338. [pdf] (No Deep Learning,but worth reading) ⭐⭐⭐⭐⭐[61] Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. \""Siamese Neural Networks for One-shot Image Recognition.\""(2015) [pdf] ⭐⭐⭐[62] Santoro, Adam, et al. \""One-shot Learning with Memory-Augmented Neural Networks.\"" arXiv preprint arXiv:1605.06065 (2016). [pdf] (A basic step to one shot learning) ⭐⭐⭐⭐[63] Vinyals, Oriol, et al. \""Matching Networks for One Shot Learning.\"" arXiv preprint arXiv:1606.04080 (2016). [pdf] ⭐⭐⭐[64] Hariharan, Bharath, and Ross Girshick. \""Low-shot visual object recognition.\"" arXiv preprint arXiv:1606.02819 (2016). [pdf] (A step to large data) ⭐⭐⭐⭐3 Applications3.1 NLP(Natural Language Processing)[1] Antoine Bordes, et al. \""Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing.\"" AISTATS(2012) [pdf] ⭐⭐⭐⭐[2] Mikolov, et al. \""Distributed representations of words and phrases and their compositionality.\"" ANIPS(2013): 3111-3119 [pdf] (word2vec) ⭐⭐⭐[3] Sutskever, et al. \""“Sequence to sequence learning with neural networks.\"" ANIPS(2014) [pdf] ⭐⭐⭐[4] Ankit Kumar, et al. \""“Ask Me Anything: Dynamic Memory Networks for Natural Language Processing.\"" arXiv preprint arXiv:1506.07285(2015) [pdf] ⭐⭐⭐⭐[5] Yoon Kim, et al. \""Character-Aware Neural Language Models.\"" NIPS(2015) arXiv preprint arXiv:1508.06615(2015) [pdf] ⭐⭐⭐⭐[6] Jason Weston, et al. \""Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.\"" arXiv preprint arXiv:1502.05698(2015) [pdf] (bAbI tasks) ⭐⭐⭐[7] Karl Moritz Hermann, et al. \""Teaching Machines to Read and Comprehend.\"" arXiv preprint arXiv:1506.03340(2015) [pdf] (CNN/DailyMail cloze style questions) ⭐⭐[8] Alexis Conneau, et al. \""Very Deep Convolutional Networks for Natural Language Processing.\"" arXiv preprint arXiv:1606.01781(2016) [pdf] (state-of-the-art in text classification) ⭐⭐⭐[9] Armand Joulin, et al. \""Bag of Tricks for Efficient Text Classification.\"" arXiv preprint arXiv:1607.01759(2016) [pdf] (slightly worse than state-of-the-art, but a lot faster) ⭐⭐⭐3.2 Object Detection[1] Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. \""Deep neural networks for object detection.\"" Advances in Neural Information Processing Systems. 2013. [pdf] ⭐⭐⭐[2] Girshick, Ross, et al. \""Rich feature hierarchies for accurate object detection and semantic segmentation.\"" Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [pdf] (RCNN) ⭐⭐⭐⭐⭐[3] He, Kaiming, et al. \""Spatial pyramid pooling in deep convolutional networks for visual recognition.\"" European Conference on Computer Vision. Springer International Publishing, 2014. [pdf] (SPPNet) ⭐⭐⭐⭐[4] Girshick, Ross. \""Fast r-cnn.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] ⭐⭐⭐⭐[5] Ren, Shaoqing, et al. \""Faster R-CNN: Towards real-time object detection with region proposal networks.\"" Advances in neural information processing systems. 2015. [pdf] ⭐⭐⭐⭐[6] Redmon, Joseph, et al. \""You only look once: Unified, real-time object detection.\"" arXiv preprint arXiv:1506.02640 (2015). [pdf] (YOLO,Oustanding Work, really practical) ⭐⭐⭐⭐⭐[7] Liu, Wei, et al. \""SSD: Single Shot MultiBox Detector.\"" arXiv preprint arXiv:1512.02325 (2015). [pdf] ⭐⭐⭐[8] Dai, Jifeng, et al. \""R-FCN: Object Detection viaRegion-based Fully Convolutional Networks.\"" arXiv preprint arXiv:1605.06409 (2016). [pdf] ⭐⭐⭐⭐[9] He, Gkioxari, et al. \""Mask R-CNN\"" arXiv preprint arXiv:1703.06870 (2017). [pdf] ⭐⭐⭐⭐[10] Bochkovskiy, Alexey, et al. \""YOLOv4: Optimal Speed and Accuracy of Object Detection.\""  arXiv preprint arXiv:2004.10934 (2020). [pdf] ⭐⭐⭐⭐[11] Tan, Mingxing, et al. “EfficientDet: Scalable and Efficient Object Detection.\"" arXiv preprint arXiv:1911.09070 (2019). [pdf] ⭐⭐⭐⭐⭐3.3 Visual Tracking[1] Wang, Naiyan, and Dit-Yan Yeung. \""Learning a deep compact image representation for visual tracking.\"" Advances in neural information processing systems. 2013. [pdf] (First Paper to do visual tracking using Deep Learning,DLT Tracker) ⭐⭐⭐[2] Wang, Naiyan, et al. \""Transferring rich feature hierarchies for robust visual tracking.\"" arXiv preprint arXiv:1501.04587 (2015). [pdf] (SO-DLT) ⭐⭐⭐⭐[3] Wang, Lijun, et al. \""Visual tracking with fully convolutional networks.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] (FCNT) ⭐⭐⭐⭐[4] Held, David, Sebastian Thrun, and Silvio Savarese. \""Learning to Track at 100 FPS with Deep Regression Networks.\"" arXiv preprint arXiv:1604.01802 (2016). [pdf] (GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods) ⭐⭐⭐⭐[5] Bertinetto, Luca, et al. \""Fully-Convolutional Siamese Networks for Object Tracking.\"" arXiv preprint arXiv:1606.09549 (2016). [pdf] (SiameseFC,New state-of-the-art for real-time object tracking) ⭐⭐⭐⭐[6] Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. \""Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking.\"" ECCV (2016) [pdf] (C-COT) ⭐⭐⭐⭐[7] Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. \""Modeling and Propagating CNNs in a Tree Structure for Visual Tracking.\"" arXiv preprint arXiv:1608.07242 (2016). [pdf] (VOT2016 Winner,TCNN) ⭐⭐⭐⭐3.4 Image Caption[1] Farhadi,Ali,etal. \""Every picture tells a story: Generating sentences from images\"". In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. [pdf] ⭐⭐⭐[2] Kulkarni, Girish, et al. \""Baby talk: Understanding and generating image descriptions\"". In Proceedings of the 24th CVPR, 2011. [pdf]⭐⭐⭐⭐[3] Vinyals, Oriol, et al. \""Show and tell: A neural image caption generator\"". In arXiv preprint arXiv:1411.4555, 2014. [pdf]⭐⭐⭐[4] Donahue, Jeff, et al. \""Long-term recurrent convolutional networks for visual recognition and description\"". In arXiv preprint arXiv:1411.4389 ,2014. [pdf][5] Karpathy, Andrej, and Li Fei-Fei. \""Deep visual-semantic alignments for generating image descriptions\"". In arXiv preprint arXiv:1412.2306, 2014. [pdf]⭐⭐⭐⭐⭐[6] Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. \""Deep fragment embeddings for bidirectional image sentence mapping\"". In Advances in neural information processing systems, 2014. [pdf]⭐⭐⭐⭐[7] Fang, Hao, et al. \""From captions to visual concepts and back\"". In arXiv preprint arXiv:1411.4952, 2014. [pdf]⭐⭐⭐⭐⭐[8] Chen, Xinlei, and C. Lawrence Zitnick. \""Learning a recurrent visual representation for image caption generation\"". In arXiv preprint arXiv:1411.5654, 2014. [pdf]⭐⭐⭐⭐[9] Mao, Junhua, et al. \""Deep captioning with multimodal recurrent neural networks (m-rnn)\"". In arXiv preprint arXiv:1412.6632, 2014. [pdf]⭐⭐⭐[10] Xu, Kelvin, et al. \""Show, attend and tell: Neural image caption generation with visual attention\"". In arXiv preprint arXiv:1502.03044, 2015. [pdf]⭐⭐⭐⭐⭐3.5 Machine TranslationSome milestone papers are listed in RNN / Seq-to-Seq topic.[1] Luong, Minh-Thang, et al. \""Addressing the rare word problem in neural machine translation.\"" arXiv preprint arXiv:1410.8206 (2014). [pdf] ⭐⭐⭐⭐[2] Sennrich, et al. \""Neural Machine Translation of Rare Words with Subword Units\"". In arXiv preprint arXiv:1508.07909, 2015. [pdf]⭐⭐⭐[3] Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. \""Effective approaches to attention-based neural machine translation.\"" arXiv preprint arXiv:1508.04025 (2015). [pdf] ⭐⭐⭐⭐[4] Chung, et al. \""A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation\"". In arXiv preprint arXiv:1603.06147, 2016. [pdf]⭐⭐[5] Lee, et al. \""Fully Character-Level Neural Machine Translation without Explicit Segmentation\"". In arXiv preprint arXiv:1610.03017, 2016. [pdf]⭐⭐⭐⭐⭐[6] Wu, Schuster, Chen, Le, et al. \""Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\"". In arXiv preprint arXiv:1609.08144v2, 2016. [pdf] (Milestone) ⭐⭐⭐⭐3.6 Robotics[1] Koutník, Jan, et al. \""Evolving large-scale neural networks for vision-based reinforcement learning.\"" Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [pdf] ⭐⭐⭐[2] Levine, Sergey, et al. \""End-to-end training of deep visuomotor policies.\"" Journal of Machine Learning Research 17.39 (2016): 1-40. [pdf] ⭐⭐⭐⭐⭐[3] Pinto, Lerrel, and Abhinav Gupta. \""Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours.\"" arXiv preprint arXiv:1509.06825 (2015). [pdf] ⭐⭐⭐[4] Levine, Sergey, et al. \""Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection.\"" arXiv preprint arXiv:1603.02199 (2016). [pdf] ⭐⭐⭐⭐[5] Zhu, Yuke, et al. \""Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning.\"" arXiv preprint arXiv:1609.05143 (2016). [pdf] ⭐⭐⭐⭐[6] Yahya, Ali, et al. \""Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search.\"" arXiv preprint arXiv:1610.00673 (2016). [pdf] ⭐⭐⭐⭐[7] Gu, Shixiang, et al. \""Deep Reinforcement Learning for Robotic Manipulation.\"" arXiv preprint arXiv:1610.00633 (2016). [pdf] ⭐⭐⭐⭐[8] A Rusu, M Vecerik, Thomas Rothörl, N Heess, R Pascanu, R Hadsell.\""Sim-to-Real Robot Learning from Pixels with Progressive Nets.\"" arXiv preprint arXiv:1610.04286 (2016). [pdf] ⭐⭐⭐⭐[9] Mirowski, Piotr, et al. \""Learning to navigate in complex environments.\"" arXiv preprint arXiv:1611.03673 (2016). [pdf] ⭐⭐⭐⭐3.7 Art[1] Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). \""Inceptionism: Going Deeper into Neural Networks\"". Google Research. [html] (Deep Dream)⭐⭐⭐⭐[2] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. \""A neural algorithm of artistic style.\"" arXiv preprint arXiv:1508.06576 (2015). [pdf] (Outstanding Work, most successful method currently) ⭐⭐⭐⭐⭐[3] Zhu, Jun-Yan, et al. \""Generative Visual Manipulation on the Natural Image Manifold.\"" European Conference on Computer Vision. Springer International Publishing, 2016. [pdf] (iGAN) ⭐⭐⭐⭐[4] Champandard, Alex J. \""Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks.\"" arXiv preprint arXiv:1603.01768 (2016). [pdf] (Neural Doodle) ⭐⭐⭐⭐[5] Zhang, Richard, Phillip Isola, and Alexei A. Efros. \""Colorful Image Colorization.\"" arXiv preprint arXiv:1603.08511 (2016). [pdf] ⭐⭐⭐⭐[6] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. \""Perceptual losses for real-time style transfer and super-resolution.\"" arXiv preprint arXiv:1603.08155 (2016). [pdf] ⭐⭐⭐⭐[7] Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. \""A learned representation for artistic style.\"" arXiv preprint arXiv:1610.07629 (2016). [pdf] ⭐⭐⭐⭐[8] Gatys, Leon and Ecker, et al.\""Controlling Perceptual Factors in Neural Style Transfer.\"" arXiv preprint arXiv:1611.07865 (2016). [pdf] (control style transfer over spatial location,colour information and across spatial scale)⭐⭐⭐⭐[9] Ulyanov, Dmitry and Lebedev, Vadim, et al. \""Texture Networks: Feed-forward Synthesis of Textures and Stylized Images.\"" arXiv preprint arXiv:1603.03417(2016). [pdf] (texture generation and style transfer) ⭐⭐⭐⭐[10] Yijun Li, Ming-Yu Liu ,Xueting Li, Ming-Hsuan Yang,Jan Kautz (NVIDIA). \""A Closed-form Solution to Photorealistic Image Stylization.\"" arXiv preprint arXiv:1802.06474(2018). [pdf] (Very fast and ultra realistic style transfer) ⭐⭐⭐⭐3.8 Object Segmentation[1] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation.” in CVPR, 2015. [pdf] ⭐⭐⭐⭐⭐[2] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. \""Semantic image segmentation with deep convolutional nets and fully connected crfs.\"" In ICLR, 2015. [pdf] ⭐⭐⭐⭐⭐[3] Pinheiro, P.O., Collobert, R., Dollar, P. \""Learning to segment object candidates.\"" In: NIPS. 2015. [pdf] ⭐⭐⭐⭐[4] Dai, J., He, K., Sun, J. \""Instance-aware semantic segmentation via multi-task network cascades.\"" in CVPR. 2016 [pdf] ⭐⭐⭐[5] Dai, J., He, K., Sun, J. \""Instance-sensitive Fully Convolutional Networks.\"" arXiv preprint arXiv:1603.08678 (2016). [pdf] ⭐⭐⭐"
35,AntonOsika/gpt-engineer,https://github.com/AntonOsika/gpt-engineer/blob/main/README.md,Python,"GPT EngineerSpecify what you want it to build, the AI asks for clarification, and then builds it.GPT Engineer is made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt.DemoProject philosophySimple to get valueFlexible and easy to add new own \""AI steps\"". See steps.py.Incrementally build towards a user experience of:high level promptinggiving feedback to the AI that it will remember over timeFast handovers back and forth between AI and humanSimplicity, all computation is \""resumable\"" and persisted to the filesystemUsageChoose either stable or development.For stable release:python -m pip install gpt-engineerFor development:git clone https://github.com/AntonOsika/gpt-engineer.gitcd gpt-engineerpython -m pip install -e .(or: make install && source venv/bin/activate for a venv)API KeyEither just:export OPENAI_API_KEY=[your api key]Or:Create a copy of .env.template named .envAdd your OPENAI_API_KEY in .envCheck the Windows README for windows usage.RunningCreate an empty folder. If inside the repo, you can run:cp -r projects/example/ projects/my-new-projectFill in the prompt file in your new foldergpt-engineer projects/my-new-project(Note, gpt-engineer --help lets you see all available options. For example --steps use_feedback lets you improve/fix code in a project)By running gpt-engineer you agree to our terms.ResultsCheck the generated files in projects/my-new-project/workspaceAlternativesYou can check Docker instructions to use Docker, or simplydo everything in your browser:FeaturesYou can specify the \""identity\"" of the AI agent by editing the files in the preprompts folder.Editing the preprompts, and evolving how you write the project prompt, is how you make the agent remember things between projects.Each step in steps.py will have its communication history with GPT4 stored in the logs folder, and can be rerun with scripts/rerun_edited_message_logs.py.VisionThe gpt-engineer community is building the open platform for devs to tinker with and build their personal code-generation toolbox.If you are interested in contributing to this, we would be interested in having you.If you want to see our broader ambitions, check out the roadmap, and joindiscordto get input on how you can contribute to it.We are currently looking for more maintainers and community organizers. Email anton.osika@gmail.com if you are interested in an official role.Example              Demo.mov          "
36,fxsjy/jieba,https://github.com/fxsjy/jieba/blob/master/README.md,Python,"jieba“结巴”中文分词：做最好的 Python 中文分词组件\""Jieba\"" (Chinese for \""to stutter\"") Chinese text segmentation: built to be the best Python Chinese word segmentation module.Scroll down for English documentation.特点支持四种分词模式：精确模式，试图将句子最精确地切开，适合文本分析；全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。paddle模式，利用PaddlePaddle深度学习框架，训练序列标注（双向GRU）网络模型实现分词。同时支持词性标注。paddle模式使用需安装paddlepaddle-tiny，pip install paddlepaddle-tiny==1.6.1。目前paddle模式支持jieba v0.40及以上版本。jieba v0.40以下版本，请升级jieba，pip install jieba --upgrade 。PaddlePaddle官网支持繁体分词支持自定义词典MIT 授权协议安装说明代码对 Python 2/3 均兼容全自动安装：easy_install jieba 或者 pip install jieba / pip3 install jieba半自动安装：先下载 http://pypi.python.org/pypi/jieba/ ，解压后运行 python setup.py install手动安装：将 jieba 目录放置于当前目录或者 site-packages 目录通过 import jieba 来引用如果需要使用paddle模式下的分词和词性标注功能，请先安装paddlepaddle-tiny，pip install paddlepaddle-tiny==1.6.1。算法基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法主要功能分词jieba.cut 方法接受四个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型；use_paddle 参数用来控制是否使用paddle模式下的分词模式，paddle模式采用延迟加载方式，通过enable_paddle接口安装paddlepaddle-tiny，并且import相关代码；jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用jieba.lcut 以及 jieba.lcut_for_search 直接返回 listjieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。代码示例# encoding=utf-8import jiebajieba.enable_paddle()# 启动paddle模式。 0.40版之后开始支持，早期版本不支持strs=[\""我来到北京清华大学\"",\""乒乓球拍卖完了\"",\""中国科学技术大学\""]for str in strs:    seg_list = jieba.cut(str,use_paddle=True) # 使用paddle模式    print(\""Paddle Mode: \"" + '/'.join(list(seg_list)))seg_list = jieba.cut(\""我来到北京清华大学\"", cut_all=True)print(\""Full Mode: \"" + \""/ \"".join(seg_list))  # 全模式seg_list = jieba.cut(\""我来到北京清华大学\"", cut_all=False)print(\""Default Mode: \"" + \""/ \"".join(seg_list))  # 精确模式seg_list = jieba.cut(\""他来到了网易杭研大厦\"")  # 默认是精确模式print(\"", \"".join(seg_list))seg_list = jieba.cut_for_search(\""小明硕士毕业于中国科学院计算所，后在日本京都大学深造\"")  # 搜索引擎模式print(\"", \"".join(seg_list))输出:【全模式】: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学【精确模式】: 我/ 来到/ 北京/ 清华大学【新词识别】：他, 来到, 了, 网易, 杭研, 大厦    (此处，“杭研”并没有在词典中，但是也被Viterbi算法识别出来了)【搜索引擎模式】： 小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造添加自定义词典载入词典开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率用法： jieba.load_userdict(file_name) # file_name 为文件类对象或自定义词典的路径词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。词频省略时使用自动计算的能保证分出该词的词频。例如：创新办 3 i云计算 5凱特琳 nz台中更改分词器（默认为 jieba.dt）的 tmp_dir 和 cache_file 属性，可分别指定缓存文件所在的文件夹及其文件名，用于受限的文件系统。范例：自定义词典：https://github.com/fxsjy/jieba/blob/master/test/userdict.txt用法示例：https://github.com/fxsjy/jieba/blob/master/test/test_userdict.py之前： 李小福 / 是 / 创新 / 办 / 主任 / 也 / 是 / 云 / 计算 / 方面 / 的 / 专家 /加载自定义词库后：　李小福 / 是 / 创新办 / 主任 / 也 / 是 / 云计算 / 方面 / 的 / 专家 /调整词典使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。代码示例：>>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))如果/放到/post/中将/出错/。>>> jieba.suggest_freq(('中', '将'), True)494>>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))如果/放到/post/中/将/出错/。>>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))「/台/中/」/正确/应该/不会/被/切开>>> jieba.suggest_freq('台中', True)69>>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))「/台中/」/正确/应该/不会/被/切开\""通过用户自定义词典来增强歧义纠错能力\"" --- #14关键词提取基于 TF-IDF 算法的关键词抽取import jieba.analysejieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())sentence 为待提取的文本topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20withWeight 为是否一并返回关键词权重值，默认值为 FalseallowPOS 仅包括指定词性的词，默认值为空，即不筛选jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件代码示例 （关键词提取）https://github.com/fxsjy/jieba/blob/master/test/extract_tags.py关键词提取所使用逆向文件频率（IDF）文本语料库可以切换成自定义语料库的路径用法： jieba.analyse.set_idf_path(file_name) # file_name为自定义语料库的路径自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py关键词提取所使用停止词（Stop Words）文本语料库可以切换成自定义语料库的路径用法： jieba.analyse.set_stop_words(file_name) # file_name为自定义语料库的路径自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py关键词一并返回关键词权重值示例用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.py基于 TextRank 算法的关键词抽取jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) 直接使用，接口相同，注意默认过滤词性。jieba.analyse.TextRank() 新建自定义 TextRank 实例算法论文： TextRank: Bringing Order into Texts基本思想:将待抽取关键词的文本进行分词以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图计算图中节点的PageRank，注意是无向带权图使用示例:见 test/demo.py词性标注jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer 参数可指定内部使用的 jieba.Tokenizer 分词器。jieba.posseg.dt 为默认词性标注分词器。标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。除了jieba默认分词模式，提供paddle模式下的词性标注功能。paddle模式采用延迟加载方式，通过enable_paddle()安装paddlepaddle-tiny，并且import相关代码；用法示例>>> import jieba>>> import jieba.posseg as pseg>>> words = pseg.cut(\""我爱北京天安门\"") #jieba默认模式>>> jieba.enable_paddle() #启动paddle模式。 0.40版之后开始支持，早期版本不支持>>> words = pseg.cut(\""我爱北京天安门\"",use_paddle=True) #paddle模式>>> for word, flag in words:...    print('%s %s' % (word, flag))...我 r爱 v北京 ns天安门 nspaddle模式词性标注对应表如下：paddle模式词性和专名类别标签集合如下表，其中词性标签 24 个（小写字母），专名类别标签 4 个（大写字母）。标签含义标签含义标签含义标签含义n普通名词f方位名词s处所名词t时间nr人名ns地名nt机构名nw作品名nz其他专名v普通动词vd动副词vn名动词a形容词ad副形词an名形词d副词m数量词q量词r代词p介词c连词u助词xc其他虚词w标点符号PER人名LOC地名ORG机构名TIME时间并行分词原理：将目标文本按行分隔后，把各行文本分配到多个 Python 进程并行分词，然后归并结果，从而获得分词速度的可观提升基于 python 自带的 multiprocessing 模块，目前暂不支持 Windows用法：jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数jieba.disable_parallel() # 关闭并行分词模式例子：https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.py实验结果：在 4 核 3.4GHz Linux 机器上，对金庸全集进行精确分词，获得了 1MB/s 的速度，是单进程版的 3.3 倍。注意：并行分词仅支持默认分词器 jieba.dt 和 jieba.posseg.dt。Tokenize：返回词语在原文的起止位置注意，输入参数只接受 unicode默认模式result = jieba.tokenize(u'永和服装饰品有限公司')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word 永和                start: 0                end:2word 服装                start: 2                end:4word 饰品                start: 4                end:6word 有限公司            start: 6                end:10搜索模式result = jieba.tokenize(u'永和服装饰品有限公司', mode='search')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word 永和                start: 0                end:2word 服装                start: 2                end:4word 饰品                start: 4                end:6word 有限                start: 6                end:8word 公司                start: 8                end:10word 有限公司            start: 6                end:10ChineseAnalyzer for Whoosh 搜索引擎引用： from jieba.analyse import ChineseAnalyzer用法示例：https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py命令行分词使用示例：python -m jieba news.txt > cut_result.txt命令行选项（翻译）：使用: python -m jieba [options] filename结巴命令行界面。固定参数:  filename              输入文件可选参数:  -h, --help            显示此帮助信息并退出  -d [DELIM], --delimiter [DELIM]                        使用 DELIM 分隔词语，而不是用默认的' / '。                        若不指定 DELIM，则使用一个空格分隔。  -p [DELIM], --pos [DELIM]                        启用词性标注；如果指定 DELIM，词语和词性之间                        用它分隔，否则用 _ 分隔  -D DICT, --dict DICT  使用 DICT 代替默认词典  -u USER_DICT, --user-dict USER_DICT                        使用 USER_DICT 作为附加词典，与默认词典或自定义词典配合使用  -a, --cut-all         全模式分词（不支持词性标注）  -n, --no-hmm          不使用隐含马尔可夫模型  -q, --quiet           不输出载入信息到 STDERR  -V, --version         显示版本信息并退出如果没有指定文件名，则使用标准输入。--help 选项输出：$> python -m jieba --helpJieba command line interface.positional arguments:  filename              input fileoptional arguments:  -h, --help            show this help message and exit  -d [DELIM], --delimiter [DELIM]                        use DELIM instead of ' / ' for word delimiter; or a                        space if it is used without DELIM  -p [DELIM], --pos [DELIM]                        enable POS tagging; if DELIM is specified, use DELIM                        instead of '_' for POS delimiter  -D DICT, --dict DICT  use DICT as dictionary  -u USER_DICT, --user-dict USER_DICT                        use USER_DICT together with the default dictionary or                        DICT (if specified)  -a, --cut-all         full pattern cutting (ignored with POS tagging)  -n, --no-hmm          don't use the Hidden Markov Model  -q, --quiet           don't print loading messages to stderr  -V, --version         show program's version number and exitIf no filename specified, use STDIN instead.延迟加载机制jieba 采用延迟加载，import jieba 和 jieba.Tokenizer() 不会立即触发词典的加载，一旦有必要才开始加载词典构建前缀字典。如果你想手工初始 jieba，也可以手动初始化。import jiebajieba.initialize()  # 手动初始化（可选）在 0.28 之前的版本是不能指定主词典的路径的，有了延迟加载机制后，你可以改变主词典的路径:jieba.set_dictionary('data/dict.txt.big')例子： https://github.com/fxsjy/jieba/blob/master/test/test_change_dictpath.py其他词典占用内存较小的词典文件https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.small支持繁体分词更好的词典文件https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big下载你所需要的词典，然后覆盖 jieba/dict.txt 即可；或者用 jieba.set_dictionary('data/dict.txt.big')其他语言实现结巴分词 Java 版本作者：piaolingxue地址：https://github.com/huaban/jieba-analysis结巴分词 C++ 版本作者：yanyiwu地址：https://github.com/yanyiwu/cppjieba结巴分词 Rust 版本作者：messense, MnO2地址：https://github.com/messense/jieba-rs结巴分词 Node.js 版本作者：yanyiwu地址：https://github.com/yanyiwu/nodejieba结巴分词 Erlang 版本作者：falood地址：https://github.com/falood/exjieba结巴分词 R 版本作者：qinwf地址：https://github.com/qinwf/jiebaR结巴分词 iOS 版本作者：yanyiwu地址：https://github.com/yanyiwu/iosjieba结巴分词 PHP 版本作者：fukuball地址：https://github.com/fukuball/jieba-php结巴分词 .NET(C#) 版本作者：anderscui地址：https://github.com/anderscui/jieba.NET/结巴分词 Go 版本作者: wangbin 地址: https://github.com/wangbin/jiebago作者: yanyiwu 地址: https://github.com/yanyiwu/gojieba结巴分词Android版本作者   Dongliang.W  地址：https://github.com/452896915/jieba-android友情链接https://github.com/baidu/lac   百度中文词法分析（分词+词性+专名）系统https://github.com/baidu/AnyQ  百度FAQ自动问答系统https://github.com/baidu/Senta 百度情感识别系统系统集成Solr: https://github.com/sing1ee/jieba-solr分词速度1.5 MB / Second in Full Mode400 KB / Second in Default Mode测试环境: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHz；《围城》.txt常见问题1. 模型的数据是如何生成的？详见： #72. “台中”总是被切成“台 中”？（以及类似情况）P(台中) ＜ P(台)×P(中)，“台中”词频不够导致其成词概率较低解决方法：强制调高词频jieba.add_word('台中') 或者 jieba.suggest_freq('台中', True)3. “今天天气 不错”应该被切成“今天 天气 不错”？（以及类似情况）解决方法：强制调低词频jieba.suggest_freq(('今天', '天气'), True)或者直接删除该词 jieba.del_word('今天天气')4. 切出了词典中没有的词语，效果不理想？解决方法：关闭新词发现jieba.cut('丰田太省了', HMM=False)jieba.cut('我们中出了一个叛徒', HMM=False)更多问题请点击：https://github.com/fxsjy/jieba/issues?sort=updated&state=closed修订历史https://github.com/fxsjy/jieba/blob/master/Changelogjieba\""Jieba\"" (Chinese for \""to stutter\"") Chinese text segmentation: built to be the best Python Chinese word segmentation module.FeaturesSupport three types of segmentation mode:Accurate Mode attempts to cut the sentence into the most accurate segmentations, which is suitable for text analysis.Full Mode gets all the possible words from the sentence. Fast but not accurate.Search Engine Mode, based on the Accurate Mode, attempts to cut long words into several short words, which can raise the recall rate. Suitable for search engines.Supports Traditional ChineseSupports customized dictionariesMIT LicenseOnline demohttp://jiebademo.ap01.aws.af.cm/(Powered by Appfog)UsageFully automatic installation: easy_install jieba or pip install jiebaSemi-automatic installation: Download http://pypi.python.org/pypi/jieba/ , run python setup.py install after extracting.Manual installation: place the jieba directory in the current directory or python site-packages directory.import jieba.AlgorithmBased on a prefix dictionary structure to achieve efficient word graph scanning. Build a directed acyclic graph (DAG) for all possible word combinations.Use dynamic programming to find the most probable combination based on the word frequency.For unknown words, a HMM-based model is used with the Viterbi algorithm.Main FunctionsCutThe jieba.cut function accepts three input parameters: the first parameter is the string to be cut; the second parameter is cut_all, controlling the cut mode; the third parameter is to control whether to use the Hidden Markov Model.jieba.cut_for_search accepts two parameter: the string to be cut; whether to use the Hidden Markov Model. This will cut the sentence into short words suitable for search engines.The input string can be an unicode/str object, or a str/bytes object which is encoded in UTF-8 or GBK. Note that using GBK encoding is not recommended because it may be unexpectly decoded as UTF-8.jieba.cut and jieba.cut_for_search returns an generator, from which you can use a for loop to get the segmentation result (in unicode).jieba.lcut and jieba.lcut_for_search returns a list.jieba.Tokenizer(dictionary=DEFAULT_DICT) creates a new customized Tokenizer, which enables you to use different dictionaries at the same time. jieba.dt is the default Tokenizer, to which almost all global functions are mapped.Code example: segmentation#encoding=utf-8import jiebaseg_list = jieba.cut(\""我来到北京清华大学\"", cut_all=True)print(\""Full Mode: \"" + \""/ \"".join(seg_list))  # 全模式seg_list = jieba.cut(\""我来到北京清华大学\"", cut_all=False)print(\""Default Mode: \"" + \""/ \"".join(seg_list))  # 默认模式seg_list = jieba.cut(\""他来到了网易杭研大厦\"")print(\"", \"".join(seg_list))seg_list = jieba.cut_for_search(\""小明硕士毕业于中国科学院计算所，后在日本京都大学深造\"")  # 搜索引擎模式print(\"", \"".join(seg_list))Output:[Full Mode]: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学[Accurate Mode]: 我/ 来到/ 北京/ 清华大学[Unknown Words Recognize] 他, 来到, 了, 网易, 杭研, 大厦    (In this case, \""杭研\"" is not in the dictionary, but is identified by the Viterbi algorithm)[Search Engine Mode]： 小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造Add a custom dictionaryLoad dictionaryDevelopers can specify their own custom dictionary to be included in the jieba default dictionary. Jieba is able to identify new words, but you can add your own new words can ensure a higher accuracy.Usage： jieba.load_userdict(file_name) # file_name is a file-like object or the path of the custom dictionaryThe dictionary format is the same as that of dict.txt: one word per line; each line is divided into three parts separated by a space: word, word frequency, POS tag. If file_name is a path or a file opened in binary mode, the dictionary must be UTF-8 encoded.The word frequency and POS tag can be omitted respectively. The word frequency will be filled with a suitable value if omitted.For example:创新办 3 i云计算 5凱特琳 nz台中Change a Tokenizer's tmp_dir and cache_file to specify the path of the cache file, for using on a restricted file system.Example:  云计算 5  李小福 2  创新办 3  [Before]： 李小福 / 是 / 创新 / 办 / 主任 / 也 / 是 / 云 / 计算 / 方面 / 的 / 专家 /  [After]：　李小福 / 是 / 创新办 / 主任 / 也 / 是 / 云计算 / 方面 / 的 / 专家 /Modify dictionaryUse add_word(word, freq=None, tag=None) and del_word(word) to modify the dictionary dynamically in programs.Use suggest_freq(segment, tune=True) to adjust the frequency of a single word so that it can (or cannot) be segmented.Note that HMM may affect the final result.Example:>>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))如果/放到/post/中将/出错/。>>> jieba.suggest_freq(('中', '将'), True)494>>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))如果/放到/post/中/将/出错/。>>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))「/台/中/」/正确/应该/不会/被/切开>>> jieba.suggest_freq('台中', True)69>>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))「/台中/」/正确/应该/不会/被/切开Keyword Extractionimport jieba.analysejieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())sentence: the text to be extractedtopK: return how many keywords with the highest TF/IDF weights. The default value is 20withWeight: whether return TF/IDF weights with the keywords. The default value is FalseallowPOS: filter words with which POSs are included. Empty for no filtering.jieba.analyse.TFIDF(idf_path=None) creates a new TFIDF instance, idf_path specifies IDF file path.Example (keyword extraction)https://github.com/fxsjy/jieba/blob/master/test/extract_tags.pyDevelopers can specify their own custom IDF corpus in jieba keyword extractionUsage： jieba.analyse.set_idf_path(file_name) # file_name is the path for the custom corpusCustom Corpus Sample：https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.bigSample Code：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.pyDevelopers can specify their own custom stop words corpus in jieba keyword extractionUsage： jieba.analyse.set_stop_words(file_name) # file_name is the path for the custom corpusCustom Corpus Sample：https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txtSample Code：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.pyThere's also a TextRank implementation available.Use: jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))Note that it filters POS by default.jieba.analyse.TextRank() creates a new TextRank instance.Part of Speech Taggingjieba.posseg.POSTokenizer(tokenizer=None) creates a new customized Tokenizer. tokenizer specifies the jieba.Tokenizer to internally use. jieba.posseg.dt is the default POSTokenizer.Tags the POS of each word after segmentation, using labels compatible with ictclas.Example:>>> import jieba.posseg as pseg>>> words = pseg.cut(\""我爱北京天安门\"")>>> for w in words:...    print('%s %s' % (w.word, w.flag))...我 r爱 v北京 ns天安门 nsParallel ProcessingPrinciple: Split target text by line, assign the lines into multiple Python processes, and then merge the results, which is considerably faster.Based on the multiprocessing module of Python.Usage:jieba.enable_parallel(4) # Enable parallel processing. The parameter is the number of processes.jieba.disable_parallel() # Disable parallel processing.Example:https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.pyResult: On a four-core 3.4GHz Linux machine, do accurate word segmentation on Complete Works of Jin Yong, and the speed reaches 1MB/s, which is 3.3 times faster than the single-process version.Note that parallel processing supports only default tokenizers, jieba.dt and jieba.posseg.dt.Tokenize: return words with positionThe input must be unicodeDefault moderesult = jieba.tokenize(u'永和服装饰品有限公司')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word 永和                start: 0                end:2word 服装                start: 2                end:4word 饰品                start: 4                end:6word 有限公司            start: 6                end:10Search moderesult = jieba.tokenize(u'永和服装饰品有限公司',mode='search')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word 永和                start: 0                end:2word 服装                start: 2                end:4word 饰品                start: 4                end:6word 有限                start: 6                end:8word 公司                start: 8                end:10word 有限公司            start: 6                end:10ChineseAnalyzer for Whooshfrom jieba.analyse import ChineseAnalyzerExample: https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.pyCommand Line Interface$> python -m jieba --helpJieba command line interface.positional arguments:  filename              input fileoptional arguments:  -h, --help            show this help message and exit  -d [DELIM], --delimiter [DELIM]                        use DELIM instead of ' / ' for word delimiter; or a                        space if it is used without DELIM  -p [DELIM], --pos [DELIM]                        enable POS tagging; if DELIM is specified, use DELIM                        instead of '_' for POS delimiter  -D DICT, --dict DICT  use DICT as dictionary  -u USER_DICT, --user-dict USER_DICT                        use USER_DICT together with the default dictionary or                        DICT (if specified)  -a, --cut-all         full pattern cutting (ignored with POS tagging)  -n, --no-hmm          don't use the Hidden Markov Model  -q, --quiet           don't print loading messages to stderr  -V, --version         show program's version number and exitIf no filename specified, use STDIN instead.InitializationBy default, Jieba don't build the prefix dictionary unless it's necessary. This takes 1-3 seconds, after which it is not initialized again. If you want to initialize Jieba manually, you can call:import jiebajieba.initialize()  # (optional)You can also specify the dictionary (not supported before version 0.28) :jieba.set_dictionary('data/dict.txt.big')Using Other DictionariesIt is possible to use your own dictionary with Jieba, and there are also two dictionaries ready for download:A smaller dictionary for a smaller memory footprint:https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.smallThere is also a bigger dictionary that has better support for traditional Chinese (繁體):https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.bigBy default, an in-between dictionary is used, called dict.txt and included in the distribution.In either case, download the file you want, and then call jieba.set_dictionary('data/dict.txt.big') or just replace the existing dict.txt.Segmentation speed1.5 MB / Second in Full Mode400 KB / Second in Default ModeTest Env: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHz；《围城》.txt"
37,PaddlePaddle/PaddleOCR,https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/README.md,Python,"English | 简体中文 | हिन्दी | 日本語 | 한국인 | Pу́сский язы́к                             简介PaddleOCR旨在打造一套丰富、领先、且实用的OCR工具库，助力开发者训练出更好的模型，并应用落地。        📣 近期更新🔥2023.8.7 发布 PaddleOCR release/2.7发布PP-OCRv4，提供mobile和server两种模型PP-OCRv4-mobile：速度可比情况下，中文场景效果相比于PP-OCRv3再提升4.5%，英文场景提升10%，80语种多语言模型平均识别准确率提升8%以上PP-OCRv4-server：发布了目前精度最高的OCR模型，中英文场景上检测模型精度提升4.9%， 识别模型精度提升2%可参考快速开始 一行命令快速使用，同时也可在飞桨AI套件(PaddleX)中的通用OCR产业方案中低代码完成模型训练、推理、高性能部署全流程发布PP-ChatOCR ,使用融合PP-OCR模型和文心大模型的通用场景关键信息抽取全新方案🔨2022.11 新增实现4种前沿算法：文本检测 DRRG,  文本识别 RFL, 文本超分Text Telescope，公式识别CAN2022.10 优化JS版PP-OCRv3模型：模型大小仅4.3M，预测速度提升8倍，配套web demo开箱即用💥 直播回放：PaddleOCR研发团队详解PP-StructureV2优化策略。微信扫描下方二维码，关注公众号并填写问卷后进入官方交流群，获取直播回放链接与20G重磅OCR学习大礼包（内含PDF转Word应用程序、10种垂类模型、《动手学OCR》电子书等）🔥2022.8.24 发布 PaddleOCR release/2.6发布PP-StructureV2，系统功能性能全面升级，适配中文场景，新增支持版面复原，支持一行命令完成PDF转Word；版面分析模型优化：模型存储减少95%，速度提升11倍，平均CPU耗时仅需41ms；表格识别模型优化：设计3大优化策略，预测耗时不变情况下，模型精度提升6%；关键信息抽取模型优化：设计视觉无关模型结构，语义实体识别精度提升2.8%，关系抽取精度提升9.1%。🔥2022.8 发布 OCR场景应用集合：包含数码管、液晶屏、车牌、高精度SVTR模型、手写体识别等9个垂类模型，覆盖通用，制造、金融、交通行业的主要OCR垂类应用。更多🌟 特性支持多种OCR相关前沿算法，在此基础上打造产业级特色模型PP-OCR、PP-Structure和PP-ChatOCR，并打通数据生产、模型训练、压缩、预测部署全流程。    上述内容的使用方法建议从文档教程中的快速开始体验⚡ 快速开始在线网站体验：PP-OCRv4 在线体验地址：https://aistudio.baidu.com/aistudio/projectdetail/6611435PP-ChatOCR 在线体验地址：https://aistudio.baidu.com/aistudio/projectdetail/6488689一行命令快速使用：快速开始（中英文/多语言/文档分析）飞桨AI套件（PaddleX）中训练、推理、高性能部署全流程体验：PP-OCRv4：https://aistudio.baidu.com/aistudio/modelsdetail?modelId=286PP-ChatOCR：https://aistudio.baidu.com/aistudio/modelsdetail?modelId=332移动端demo体验：安装包DEMO下载地址(基于EasyEdge和Paddle-Lite, 支持iOS和Android系统)📖 技术交流合作飞桨AI套件(PaddleX)提供了飞桨模型训压推一站式全流程高效率开发平台，其使命是助力AI技术快速落地，愿景是使人人成为AI Developer！PaddleX 目前覆盖图像分类、目标检测、图像分割、3D、OCR和时序预测等领域方向，已内置了36种基础单模型，例如RT-DETR、PP-YOLOE、PP-HGNet、PP-LCNet、PP-LiteSeg等；集成了12种实用的产业方案，例如PP-OCRv4、PP-ChatOCR、PP-ShiTu、PP-TS、车载路面垃圾检测、野生动物违禁制品识别等。PaddleX 提供了“工具箱”和“开发者”两种AI开发模式。工具箱模式可以无代码调优关键超参，开发者模式可以低代码进行单模型训压推和多模型串联推理，同时支持云端和本地端。PaddleX 还支持联创开发，利润分成！目前 PaddleX 正在快速迭代，欢迎广大的个人开发者和企业开发者参与进来，共创繁荣的 AI 技术生态！微信扫描下面二维码添加运营同学，并回复【paddlex】，运营同学会邀请您加入官方交流群，获得更高效的问题答疑。飞桨AI套件【PaddleX】技术交流群二维码📚《动手学OCR》电子书《动手学OCR》电子书🚀 开源共建👫 加入社区：感谢大家长久以来对 PaddleOCR 的支持和关注，与广大开发者共同构建一个专业、和谐、相互帮助的开源社区是 PaddleOCR 的目标。我们非常欢迎各位开发者参与到飞桨社区的开源建设中，加入开源、共建飞桨。为感谢社区开发者在 PaddleOCR release2.7 中做出的代码贡献，我们将为贡献者制作与邮寄开源贡献证书，烦请填写问卷提供必要的邮寄信息。🤩 社区活动：飞桨开源社区长期运营与发布各类丰富的活动与开发任务，在 PaddleOCR 社区，你可以关注以下社区活动，并选择自己感兴趣的内容参与开源共建：🎁 飞桨套件快乐开源常规赛 | 传送门：OCR 社区常规赛升级版，以建设更好用的 OCR 套件为目标，包括但不限于学术前沿模型训练与推理、打磨优化 OCR 工具与应用项目开发等，任何有利于社区意见流动和问题解决的行为都热切希望大家的参与。让我们共同成长为飞桨套件的重要 Contributor 🎉🎉🎉。💡 新需求征集 | 传送门：你在日常研究和实践深度学习过程中，有哪些你期望的 feature 亟待实现？请按照格式描述你想实现的 feature 和你提出的初步实现思路，我们会定期沟通与讨论这些需求，并将其纳入未来的版本规划中。💬 PP-SIG 技术研讨会 | 传送门：PP-SIG 是飞桨社区开发者由于相同的兴趣汇聚在一起形成的虚拟组织，通过定期召开技术研讨会的方式，分享行业前沿动态、探讨社区需求与技术开发细节、发起社区联合贡献任务。PaddleOCR 希望可以通过 AI 的力量助力任何一位有梦想的开发者实现自己的想法，享受创造价值带来的愉悦。📑 项目合作：如果你有企业中明确的 OCR 垂类应用需求，我们推荐你使用训压推一站式全流程高效率开发平台 PaddleX，助力 AI 技术快速落地。PaddleX 还支持联创开发，利润分成！欢迎广大的个人开发者和企业开发者参与进来，共创繁荣的 AI 技术生态！🛠️ PP-OCR系列模型列表（更新中）模型简介模型名称推荐场景检测模型方向分类器识别模型中英文超轻量PP-OCRv4模型（15.8M）ch_PP-OCRv4_xx移动端&服务器端推理模型 / 训练模型推理模型 / 训练模型推理模型 / 训练模型中英文超轻量PP-OCRv3模型（16.2M）ch_PP-OCRv3_xx移动端&服务器端推理模型 / 训练模型推理模型 / 训练模型推理模型 / 训练模型英文超轻量PP-OCRv3模型（13.4M）en_PP-OCRv3_xx移动端&服务器端推理模型 / 训练模型推理模型 / 训练模型推理模型 / 训练模型超轻量OCR系列更多模型下载（包括多语言），可以参考PP-OCR系列模型下载，文档分析相关模型参考PP-Structure系列模型下载PaddleOCR场景应用模型行业类别亮点文档说明模型下载制造数码管识别数码管数据合成、漏识别调优光功率计数码管字符识别下载链接金融通用表单识别多模态通用表单结构化提取多模态表单识别下载链接交通车牌识别多角度图像处理、轻量模型、端侧部署轻量级车牌识别下载链接更多制造、金融、交通行业的主要OCR垂类应用模型（如电表、液晶屏、高精度SVTR模型等），可参考场景应用模型下载📖 文档教程运行环境准备PP-OCR文本检测识别🔥快速开始模型库模型训练文本检测文本识别文本方向分类器模型压缩模型量化模型裁剪知识蒸馏推理部署基于Python预测引擎推理基于C++预测引擎推理服务化部署端侧部署Paddle2ONNX模型转化与预测云上飞桨部署工具BenchmarkPP-Structure文档分析🔥快速开始模型库模型训练版面分析表格识别关键信息提取推理部署基于Python预测引擎推理基于C++预测引擎推理服务化部署前沿算法与模型🚀文本检测算法文本识别算法端到端OCR算法表格识别算法关键信息抽取算法使用PaddleOCR架构添加新算法场景应用数据标注与合成半自动标注工具PPOCRLabel数据合成工具Style-Text其它数据标注工具其它数据合成工具数据集通用中英文OCR数据集手写中文OCR数据集垂类多语言OCR数据集版面分析数据集表格识别数据集关键信息提取数据集代码组织结构效果展示《动手学OCR》电子书📚开源社区FAQ通用问题PaddleOCR实战问题参考文献许可证书👀 效果展示 morePP-OCRv3 中文模型            PP-OCRv3 英文模型        PP-OCRv3 多语言模型        PP-Structure 文档分析版面分析+表格识别    SER（语义实体识别）            RE（关系提取）            许可证书本项目的发布受Apache 2.0 license许可认证。"
38,lazyprogrammer/machine_learning_examples,https://github.com/lazyprogrammer/machine_learning_examples/blob/master/README.md,Python,"machine_learning_examplesA collection of machine learning examples and tutorials.Find associated tutorials at https://lazyprogrammer.meFind associated courses at https://deeplearningcourses.comPlease note that not all code from all courses will be found in this repository. Some newer code examples (e.g. most of Tensorflow 2.0) were done in Google Colab. Therefore, you should check the instructions given in the lectures for the course you are taking.How to I find the code for a particular course?The code for each course is separated by folder. You can determine which folder corresponds with which course by watching the \""Where to get the code\"" lecture inside the course (usually Lecture 2 or 3).Remember: one folder = one course.Why you should not fork this repoI've noticed that many people have out-of-date forks. Thus, I recommend not forking this repository if you take one of my courses. I am constantly updating my courses, and your fork will soon become out-of-date. You should clone the repository instead to make it easy to get updates (i.e. just \""git pull\"" randomly and frequently).Where is the code for your latest courses?Beginning with Tensorflow 2, I started to use Google Colab. For those courses, unless otherwise noted, the code will be on Google Colab. Links to the notebooks are provided in the course. See the lecture \""Where to get the code\"" for further details.VIP Course LinksData Science: Transformers for Natural Language Processinghttps://deeplearningcourses.com/c/data-science-transformers-nlpMachine Learning: Natural Language Processing in Python (V2)https://deeplearningcourses.com/c/natural-language-processing-in-pythonTime Series Analysis, Forecasting, and Machine Learninghttps://deeplearningcourses.com/c/time-series-analysisFinancial Engineering and Artificial Intelligence in Pythonhttps://deeplearningcourses.com/c/ai-financePyTorch: Deep Learning and Artificial Intelligencehttps://deeplearningcourses.com/c/pytorch-deep-learningTensorflow 2.0: Deep Learning and Artificial Intelligence (VIP Version)https://deeplearningcourses.com/c/deep-learning-tensorflow-2Deep Learning Courses ExclusivesData Science: Bayesian Linear Regression in Pythonhttps://deeplearningcourses.com/c/bayesian-linear-regression-in-pythonData Science: Bayesian Classification in Pythonhttps://deeplearningcourses.com/c/bayesian-classification-in-pythonClassical Statistical Inference and A/B Testing in Pythonhttps://deeplearningcourses.com/c/statistical-inference-in-pythonLinear Programming for Linear Regression in Pythonhttps://deeplearningcourses.com/c/linear-programming-pythonMATLAB for Students, Engineers, and Professionals in STEMhttps://deeplearningcourses.com/c/matlabOther Course LinksFinancial Analysis: Build a ChatGPT Pairs Trading Bothttps://deeplearningcourses.com/c/chatgpt-pairs-tradingMath 0-1: Calculus for Data Science & Machine Learninghttps://deeplearningcourses.com/c/calculus-data-scienceData Science & Machine Learning: Naive Bayes in Pythonhttps://deeplearningcourses.com/c/data-science-machine-learning-naive-bayes-in-pythonCutting-Edge AI: Deep Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/cutting-edge-artificial-intelligenceRecommender Systems and Deep Learning in Pythonhttps://deeplearningcourses.com/c/recommender-systemsMachine Learning and AI: Support Vector Machines in Pythonhttps://deeplearningcourses.com/c/support-vector-machines-in-pythonDeep Learning: Advanced Computer Visionhttps://deeplearningcourses.com/c/advanced-computer-visionDeep Learning: Advanced NLP and RNNshttps://deeplearningcourses.com/c/deep-learning-advanced-nlpDeep Learning: GANs and Variational Autoencodershttps://deeplearningcourses.com/c/deep-learning-gans-and-variational-autoencodersAdvanced AI: Deep Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/deep-reinforcement-learning-in-pythonArtificial Intelligence: Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-pythonNatural Language Processing with Deep Learning in Pythonhttps://deeplearningcourses.com/c/natural-language-processing-with-deep-learning-in-pythonDeep Learning: Recurrent Neural Networks in Pythonhttps://deeplearningcourses.com/c/deep-learning-recurrent-neural-networks-in-pythonUnsupervised Machine Learning: Hidden Markov Models in Pythonhttps://deeplearningcourses.com/c/unsupervised-machine-learning-hidden-markov-models-in-pythonDeep Learning Prerequisites: The Numpy Stack in Pythonhttps://deeplearningcourses.com/c/deep-learning-prerequisites-the-numpy-stack-in-pythonDeep Learning Prerequisites: Linear Regression in Pythonhttps://deeplearningcourses.com/c/data-science-linear-regression-in-pythonDeep Learning Prerequisites: Logistic Regression in Pythonhttps://deeplearningcourses.com/c/data-science-logistic-regression-in-pythonData Science: Deep Learning and Neural Networks in Pythonhttps://deeplearningcourses.com/c/data-science-deep-learning-in-pythonCluster Analysis and Unsupervised Machine Learning in Pythonhttps://deeplearningcourses.com/c/cluster-analysis-unsupervised-machine-learning-pythonData Science: Supervised Machine Learning in Pythonhttps://deeplearningcourses.com/c/data-science-supervised-machine-learning-in-pythonBayesian Machine Learning in Python: A/B Testinghttps://deeplearningcourses.com/c/bayesian-machine-learning-in-python-ab-testingData Science: Natural Language Processing in Pythonhttps://deeplearningcourses.com/c/data-science-natural-language-processing-in-pythonModern Deep Learning in Pythonhttps://deeplearningcourses.com/c/data-science-deep-learning-in-theano-tensorflowEnsemble Machine Learning in Python: Random Forest and AdaBoosthttps://deeplearningcourses.com/c/machine-learning-in-python-random-forest-adaboostDeep Learning: Convolutional Neural Networks in Pythonhttps://deeplearningcourses.com/c/deep-learning-convolutional-neural-networks-theano-tensorflowUnsupervised Deep Learning in Pythonhttps://deeplearningcourses.com/c/unsupervised-deep-learning-in-python"
39,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
40,donnemartin/system-design-primer,https://github.com/donnemartin/system-design-primer/blob/master/README-ja.md,Python,"English ∙ 日本語 ∙ 简体中文 ∙ 繁體中文 | العَرَبِيَّة‎ ∙ বাংলা ∙ Português do Brasil ∙ Deutsch ∙ ελληνικά ∙ עברית ∙ Italiano ∙ 한국어 ∙ فارسی ∙ Polski ∙ русский язык ∙ Español ∙ ภาษาไทย ∙ Türkçe ∙ tiếng Việt ∙ Français | Add Translationシステム設計入門    動機・目的大規模システムのシステム設計を学ぶシステム設計面接課題に備える大規模システムの設計を学ぶスケーラブルなシステムのシステム設計を学ぶことは、より良いエンジニアになることに資するでしょう。システム設計はとても広範なトピックを含みます。システム設計原理については インターネット上には膨大な量の文献が散らばっています。このリポジトリは大規模システム構築に必要な知識を学ぶことができる 文献リストを体系的にまとめたもの です。オープンソースコミュニティから学ぶこのプロジェクトは、これからもずっと更新されていくオープンソースプロジェクトの初期段階にすぎません。Contributions は大歓迎です！システム設計面接課題に備えるコード技術面接に加えて、システム設計に関する知識は、多くのテック企業における 技術採用面接プロセス で 必要不可欠な要素 です。システム設計面接での頻出質問に備え、自分の解答と模範解答:ディスカッション、コードそして図表などを比較して学びましょう。面接準備に役立つその他のトピック:学習指針システム設計面接課題にどのように準備するかシステム設計課題例 とその解答オブジェクト指向設計課題例、 とその解答その他のシステム設計面接課題例暗記カード    このAnki用フラッシュカードデッキ は、間隔反復を活用して、システム設計のキーコンセプトの学習を支援します。システム設計デッキシステム設計練習課題デッキオブジェクト指向練習課題デッキ外出先や移動中の勉強に役立つでしょう。コーディング技術課題用の問題: 練習用インタラクティブアプリケーションコード技術面接用の問題を探している場合はこちら    姉妹リポジトリの Interactive Coding Challengesも見てみてください。追加の暗記デッキカードも入っています。Coding deckコントリビュートコミュニティから学ぶプルリクエスト等の貢献は積極的にお願いします:エラー修正セクション内容改善新規セクション追加翻訳する現在、内容の改善が必要な作業中のコンテンツはこちらです。コントリビュートの前にContributing Guidelinesを読みましょう。システム設計目次賛否も含めた様々なシステム設計の各トピックの概要。 全てはトレードオフの関係にあります。それぞれのセクションはより学びを深めるような他の文献へのリンクが貼られています。    システム設計トピック: まずはここからStep 1: スケーラビリティに関する動画を見るStep 2: スケーラビリティに関する記事を読む次のステップパフォーマンス vs スケーラビリティレイテンシー vs スループット可用性 vs 一貫性CAP理論CP - 一貫性(consistency)と分割性(partition)耐性AP - 可用性(availability)と分割性(partition)耐性一貫性 パターン弱い一貫性結果整合性強い一貫性可用性 パターンフェイルオーバーレプリケーションドメインネームシステム(DNS)コンテンツデリバリーネットワーク(CDN)プッシュCDNプルCDNロードバランサーアクティブ/パッシブ構成アクティブ/アクティブ構成Layer 4 ロードバランシングLayer 7 ロードバランシング水平スケーリングリバースプロキシ (WEBサーバー)ロードバランサー vs リバースプロキシアプリケーションレイヤーマイクロサービスサービスディスカバリーデータベースリレーショナルデータベースマネジメントシステム (RDBMS)マスター/スレーブ レプリケーションマスター/マスター レプリケーションフェデレーションシャーディングデノーマライゼーションSQL チューニングNoSQLキー/バリューストアドキュメントストアワイドカラムストアグラフ データベースSQL or NoSQLキャッシュクライアントキャッシングCDNキャッシングWebサーバーキャッシングデータベースキャッシングアプリケーションキャッシングデータベースクエリレベルでキャッシングするオブジェクトレベルでキャッシングするいつキャッシュを更新するのかキャッシュアサイドライトスルーライトビハインド (ライトバック)リフレッシュアヘッド非同期処理メッセージキュータスクキューバックプレッシャー通信伝送制御プロトコル (TCP)ユーザデータグラムプロトコル (UDP)遠隔手続呼出 (RPC)Representational state transfer (REST)セキュリティ補遺2の乗数表全てのプログラマーが知るべきレイテンシー値他のシステム設計面接例題実世界でのアーキテクチャ各企業のアーキテクチャ企業のエンジニアブログ作業中クレジット連絡情報ライセンス学習指針学習スパンに応じてみるべきトピックス (short, medium, long)Q: 面接のためには、ここにあるものすべてをやらないといけないのでしょうか？A: いえ、ここにあるすべてをやる必要はありません。面接で何を聞かれるかは以下の条件によって変わってきます:どれだけの技術経験があるかあなたの技術背景が何であるかどのポジションのために面接を受けているかどの企業の面接を受けているか運より経験のある候補者は一般的にシステム設計についてより深い知識を有していることを要求されるでしょう。システムアーキテクトやチームリーダーは各メンバーの持つような知識よりは深い見識を持っているべきでしょう。一流テック企業では複数回の設計面接を課されることが多いです。まずは広く始めて、そこからいくつかの分野に絞って深めていくのがいいでしょう。様々なシステム設計のトピックについて少しずつ知っておくことはいいことです。以下の学習ガイドを自分の学習に当てられる時間、技術経験、どの職位、どの会社に応募しているかなどを加味して自分用に調整して使うといいでしょう。短期間 - 幅広く システム設計トピックを学ぶ。いくつかの 面接課題を解くことで対策する。中期間 - 幅広く そして それなりに深くシステム設計トピックを学ぶ。多くの 面接課題を解くことで対策する。長期間 - 幅広く そして もっと深くシステム設計トピックを学ぶ。ほぼ全ての 面接課題を解くことで対策する。短期間中期間長期間システム設計トピック を読み、システム動作機序について広く知る👍👍👍次のリンク先のいくつかのページを読んで 各企業のエンジニアリングブログ 応募する会社について知る👍👍👍次のリンク先のいくつかのページを読む 実世界でのアーキテクチャ👍👍👍復習する システム設計面接課題にどのように準備するか👍👍👍とりあえず一周する システム設計課題例SomeManyMostとりあえず一周する オブジェクト指向設計問題と解答SomeManyMost復習する その他システム設計面接での質問例SomeManyMostシステム設計面接にどのようにして臨めばいいかシステム設計面接試験問題にどのように取り組むかシステム設計面接は open-ended conversation(Yes/Noでは答えられない口頭質問)です。 自分で会話を組み立てることを求められます。以下のステップに従って議論を組み立てることができるでしょう。この過程を確かなものにするために、次のセクションシステム設計課題例とその解答 を以下の指針に従って読み込むといいでしょう。ステップ 1: そのシステム使用例の概要、制約、推計値等を聞き出し、まとめるシステム仕様の要求事項を聞き出し、問題箇所を特定しましょう。使用例と制約を明確にするための質問を投げかけましょう。要求する推計値についても議論しておきましょう。誰がそのサービスを使うのか？どのように使うのか？何人のユーザーがいるのか？システムはどのような機能を果たすのか？システムへの入力と出力は？どれだけの容量のデータを捌く必要があるのか？一秒間に何リクエストの送信が想定されるか？読み書き比率の推定値はいくら程度か？ステップ 2: より高レベルのシステム設計を組み立てる重要なコンポーネントを全て考慮した高レベルのシステム設計概要を組み立てる。主要なコンポーネントと接続をスケッチして書き出す考えの裏付けをするステップ 3: 核となるコンポーネントを設計するそれぞれの主要なコンポーネントについての詳細を学ぶ。例えば、url短縮サービスの設計を問われた際には次のようにするといいでしょう:元のURLのハッシュ化したものを作り、それを保存するMD5 と Base62ハッシュ衝突SQL もしくは NoSQLデータベーススキーマハッシュ化されたURLを元のURLに再翻訳するデータベース参照API & オブジェクト指向の設計ステップ 4: システム設計のスケール与えられた制約条件からボトルネックとなりそうなところを割り出し、明確化する。  例えば、スケーラビリティの問題解決のために以下の要素を考慮する必要があるだろうか？ロードバランサー水平スケーリングキャッシングデータベースシャーディング取りうる解決策とそのトレードオフについて議論をしよう。全てのことはトレードオフの関係にある。ボトルネックについてはスケーラブルなシステム設計の原理を読むといいでしょう。ちょっとした暗算問題ちょっとした推計値を手計算ですることを求められることもあるかもしれません。補遺の以下の項目が役に立つでしょう:チラ裏計算でシステム設計する2の乗数表全てのプログラマーが知っておくべきレイテンシの参考値文献とその他の参考資料以下のリンク先ページを見てどのような質問を投げかけられるか概要を頭に入れておきましょう:システム設計面接で成功するには？システム設計面接アーキテクチャ、システム設計面接への導入システム設計課題例とその解答頻出のシステム設計面接課題と参考解答、コード及びダイアグラム解答は solutions/ フォルダ以下にリンクが貼られている問題Pastebin.com (もしくは Bit.ly) を設計する解答Twitterタイムライン (もしくはFacebookフィード)を設計するTwitter検索(もしくはFacebook検索)機能を設計する解答ウェブクローラーを設計する解答Mint.comを設計する解答SNSサービスのデータ構造を設計する解答検索エンジンのキー/バリュー構造を設計する解答Amazonのカテゴリ毎の売り上げランキングを設計する解答AWS上で100万人規模のユーザーを捌くサービスを設計する解答システム設計問題を追加するContributePastebin.com (もしくは Bit.ly) を設計する問題と解答を見るTwitterタイムライン&検索 (もしくはFacebookフィード&検索)を設計する問題と解答を見るウェブクローラーの設計問題と解答を見るMint.comの設計問題と解答を見るSNSサービスのデータ構造を設計する問題と解答を見る検索エンジンのキー/バリュー構造を設計する問題と解答を見るAmazonのカテゴリ毎の売り上げランキングを設計する問題と解答を見るAWS上で100万人規模のユーザーを捌くサービスを設計する問題と解答を見るオブジェクト指向設計問題と解答頻出のオブジェクト指向システム設計面接課題と参考解答、コード及びダイアグラム解答は solutions/ フォルダ以下にリンクが貼られている備考: このセクションは作業中です問題ハッシュマップの設計解答LRUキャッシュの設計解答コールセンターの設計解答カードのデッキの設計解答駐車場の設計解答チャットサーバーの設計解答円形配列の設計Contributeオブジェクト指向システム設計問題を追加するContributeシステム設計トピックス: まずはここからシステム設計の勉強は初めて？まず初めに、よく使われる設計原理について、それらが何であるか、どのように用いられるか、長所短所について基本的な知識を得る必要がありますステップ 1: スケーラビリティに関する動画を観て復習するHarvardでのスケーラビリティの講義ここで触れられているトピックス:垂直スケーリング水平スケーリングキャッシングロードバランシングデータベースレプリケーションデータベースパーティションステップ 2: スケーラビリティに関する資料を読んで復習するスケーラビリティここで触れられているトピックス:クローンデータベースキャッシュ非同期次のステップ次に、ハイレベルでのトレードオフについてみていく:パフォーマンス vs スケーラビリティレイテンシ vs スループット可用性 vs 一貫性全てはトレードオフの関係にあるというのを肝に命じておきましょう。それから、より深い内容、DNSやCDNそしてロードバランサーなどについて学習を進めていきましょう。パフォーマンス vs スケーラビリティリソースが追加されるのにつれて パフォーマンス が向上する場合そのサービスは スケーラブル であると言えるでしょう。一般的に、パフォーマンスを向上させるというのはすなわち計算処理を増やすことを意味しますが、データセットが増えた時などより大きな処理を捌けるようになることでもあります。1パフォーマンスvsスケーラビリティをとらえる他の考え方:パフォーマンス での問題を抱えている時、あなたのシステムは一人のユーザーにとって遅いと言えるでしょう。スケーラビリティ での問題を抱えているとき、一人のユーザーにとっては速いですが、多くのリクエストがある時には遅くなってしまうでしょう。その他の参考資料、ページスケーラビリティについてスケーラビリティ、可用性、安定性、パターンレイテンシー vs スループットレイテンシー とはなにがしかの動作を行う、もしくは結果を算出するのに要する時間スループット とはそのような動作や結果算出が単位時間に行われる回数一般的に、 最大限のスループット を 許容範囲内のレイテンシー で実現することを目指すのが普通だ。その他の参考資料、ページレイテンシー vs スループットを理解する可用性 vs 一貫性CAP 理論      Source: CAP theorem revisited分散型コンピュータシステムにおいては下の三つのうち二つまでしか同時に保証することはできない。:一貫性 - 全ての読み込みは最新の書き込みもしくはエラーを受け取る可用性 - 受け取る情報が最新のものだという保証はないが、全てのリクエストはレスポンスを必ず受け取る分断耐性 - ネットワーク問題によって順不同の分断が起きてもシステムが動作を続けるネットワークは信頼できないので、分断耐性は必ず保証しなければなりません。つまりソフトウェアシステムとしてのトレードオフは、一貫性を取るか、可用性を取るかを考えなければなりません。CP - 一貫性と分断耐性(consistency and partition tolerance)分断されたノードからのレスポンスを待ち続けているとタイムアウトエラーに陥る可能性があります。CPはあなたのサービスがアトミックな読み書き（不可分操作）を必要とする際にはいい選択肢でしょう。AP - 可用性と分断耐性(availability and partition tolerance)レスポンスはノード上にあるデータで最新のものを返します。つまり、最新版のデータが返されるとは限りません。分断が解消された後も、書き込みが反映されるのには時間がかかります。結果整合性　を求めるサービスの際にはAPを採用するのがいいでしょう。もしくは、外部エラーに関わらずシステムが稼働する必要がある際にも同様です。その他の参考資料、ページCAP 理論を振り返る平易な英語でのCAP 理論のイントロCAP FAQ一貫性パターン同じデータの複製が複数ある状態では、クライアントが一貫したデータ表示を受け取るために、どのようにそれらを同期すればいいのかという課題があります。 CAP 理論 における一貫性の定義を思い出してみましょう。全ての読み取りは最新の書き込みデータもしくはエラーを受け取るはずです。弱い一貫性書き込み後の読み取りでは、その最新の書き込みを読めたり読めなかったりする。ベストエフォート型のアプローチに基づく。このアプローチはmemcachedなどのシステムに見られます。弱い一貫性はリアルタイム性が必要なユースケース、例えばVoIP、ビデオチャット、リアルタイムマルチプレイヤーゲームなどと相性がいいでしょう。例えば、電話に出ているときに数秒間音声が受け取れなくなったとしたら、その後に接続が回復してもその接続が切断されていた間に話されていたことは聞き取れないというような感じです。結果整合性書き込みの後、読み取りは最終的にはその結果を読み取ることができる(ミリ秒ほど遅れてというのが一般的です)。データは非同期的に複製されます。このアプローチはDNSやメールシステムなどに採用されています。結果整合性は多くのリクエストを捌くサービスと相性がいいでしょう。強い一貫性書き込みの後、読み取りはそれを必ず読むことができます。データは同期的に複製されます。このアプローチはファイルシステムやRDBMSなどで採用されています。トランザクションを扱うサービスでは強い一貫性が必要でしょう。その他の参考資料、ページデータセンター間でのトランザクション可用性パターン高い可用性を担保するには主に次の二つのパターンがあります: フェイルオーバー と レプリケーション です。フェイルオーバーアクティブ・パッシブアクティブ・パッシブフェイルオーバーにおいては、周期信号はアクティブもしくはスタンバイ中のパッシブなサーバーに送られます。周期信号が中断された時には、パッシブだったサーバーがアクティブサーバーのIPアドレスを引き継いでサービスを再開します。起動までのダウンタイムはパッシブサーバーが「ホット」なスタンバイ状態にあるか、「コールド」なスタンバイ状態にあるかで変わります。アクティブなサーバーのみがトラフィックを捌きます。アクティブ・パッシブフェイルオーバーはマスター・スレーブフェイルオーバーと呼ばれることもあります。アクティブ・アクティブアクティブアクティブ構成では両方のサーバーがトラフィックを捌くことで負荷を分散します。これらのサーバーがパブリックなものの場合、DNSは両方のサーバーのパブリックIPを知っている必要があります。もし、プライベートなものな場合、アプリケーションロジックが両方のサーバーの情報について知っている必要があります。アクティブ・アクティブなフェイルオーバーはマスター・マスターフェイルオーバーと呼ばれることもあります。短所: フェイルオーバーフェイルオーバーではより多くのハードウェアを要し、複雑さが増します。最新の書き込みがパッシブサーバーに複製される前にアクティブが落ちると、データ欠損が起きる潜在可能性があります。レプリケーションマスター・スレーブ　と　マスター・マスターこのトピックは データベース セクションにおいてより詳細に解説されています:マスター・スレーブ レプリケーションマスター・マスター レプリケーションドメインネームシステム      Source: DNS security presentationドメインネームシステム (DNS) は www.example.com などのドメインネームをIPアドレスへと翻訳します。DNSは少数のオーソライズされたサーバーが上位に位置する階層的構造です。あなたのルーターもしくはISPは検索をする際にどのDNSサーバーに接続するかという情報を提供します。低い階層のDNSサーバーはその経路マップをキャッシュします。ただ、この情報は伝搬遅延によって陳腐化する可能性があります。DNSの結果はあなたのブラウザもしくはOSに一定期間（time to live (TTL)に設定された期間）キャッシュされます。NS record (name server) - あなたのドメイン・サブドメインでのDNSサーバーを特定します。MX record (mail exchange) - メッセージを受け取るメールサーバーを特定します。A record (address) - IPアドレスに名前をつけます。CNAME (canonical) - 他の名前もしくは　CNAME (example.com を www.example.com) もしくは A recordへと名前を指し示す。CloudFlare や Route 53 などのサービスはマネージドDNSサービスを提供しています。いくつかのDNSサービスでは様々な手法を使ってトラフィックを捌くことができます:加重ラウンドロビントラフィックがメンテナンス中のサーバーに行くのを防ぎます様々なクラスターサイズに応じて調整しますA/B テストレイテンシーベース地理ベース欠点: DNS上記で示されているようなキャッシングによって緩和されているとはいえ、DNSサーバーへの接続には少し遅延が生じる。DNSサーバーは、政府、ISP企業,そして大企業に管理されているが、それらの管理は複雑である。DNSサービスはDDoS attackの例で、IPアドレスなしにユーザーがTwitterなどにアクセスできなくなったように、攻撃を受ける可能性がある。その他の参考資料、ページDNS アーキテクチャWikipediaDNS 記事コンテンツデリバリーネットワーク(Content delivery network)      Source: Why use a CDNコンテンツデリバリーネットワーク(CDN)は世界中に配置されたプロキシサーバーのネットワークがユーザーに一番地理的に近いサーバーからコンテンツを配信するシステムのことです。AmazonのCloudFrontなどは例外的にダイナミックなコンテンツも配信しますが、一般的に、HTML/CSS/JS、写真、そして動画などの静的ファイルがCDNを通じて配信されます。そのサイトのDNSがクライアントにどのサーバーと交信するかという情報を伝えます。CDNを用いてコンテンツを配信することで以下の二つの理由でパフォーマンスが劇的に向上します:ユーザーは近くにあるデータセンターから受信できるバックエンドサーバーはCDNが処理してくれるリクエストに関しては処理する必要がなくなりますプッシュCDNプッシュCDNではサーバーデータに更新があった時には必ず、新しいコンテンツを受け取る方式です。コンテンツを用意し、CDNに直接アップロードし、URLをCDNを指すように指定するところまで、全て自分で責任を負う形です。コンテンツがいつ期限切れになるのか更新されるのかを設定することができます。コンテンツは新規作成時、更新時のみアップロードされることでトラフィックは最小化される一方、ストレージは最大限消費されてしまいます。トラフィックの少ない、もしくは頻繁にはコンテンツが更新されないサイトの場合にはプッシュCDNと相性がいいでしょう。コンテンツは定期的に再びプルされるのではなく、CDNに一度のみ配置されます。プルCDNプルCDNでは一人目のユーザーがリクエストした時に、新しいコンテンツをサービスのサーバーから取得します。コンテンツは自分のサーバーに保存して、CDNを指すURLを書き換えます。結果として、CDNにコンテンツがキャッシュされるまではリクエスト処理が遅くなります。time-to-live (TTL) はコンテンツがどれだけの期間キャッシュされるかを規定します。プルCDNはCDN 上でのストレージスペースを最小化しますが、有効期限が切れたファイルが更新前にプルされてしまうことで冗長なトラフィックに繋がってしまう可能性があります。大規模なトラフィックのあるサイトではプルCDNが相性がいいでしょう。というのも、トラフィックの大部分は最近リクエストされ、CDNに残っているコンテンツにアクセスするものであることが多いからです。欠点: CDNCDNのコストはトラフィック量によって変わります。もちろん、CDNを使わない場合のコストと比較するべきでしょう。TTLが切れる前にコンテンツが更新されると陳腐化する恐れがあります。CDNでは静的コンテンツがCDNを指すようにURLを更新する必要があります。その他の参考資料、ページグローバルに分散されたコンテンツデリバリーネットワークプッシュCDNとプルCDNの違いWikipediaロードバランサー      Source: Scalable system design patternsロードバランサーは入力されるクライアントのリクエストをアプリケーションサーバーやデータベースへと分散させる。どのケースでもロードバランサーはサーバー等計算リソースからのレスポンスを適切なクライアントに返す。ロードバランサーは以下のことに効果的です:リクエストが状態の良くないサーバーに行くのを防ぐリクエストを過剰に送るのを防ぐ特定箇所の欠陥でサービスが落ちることを防ぐロードバランサーは (費用の高い) ハードウェアもしくはHAProxyなどのソフトウェアで実現できる。他の利点としては:SSL termination - 入力されるリクエストを解読する、また、サーバーレスポンスを暗号化することでバックエンドのサーバーがこのコストが高くつきがちな処理を請け負わなくていいように肩代わりします。X.509 certificates をそれぞれのサーバーにインストールする必要をなくしますセッション管理 - クッキーを取り扱うウェブアプリがセッション情報を保持していない時などに、特定のクライアントのリクエストを同じインスタンスへと流します。障害に対応するために、アクティブ・パッシブ もしくは アクティブ・アクティブ モードのどちらにおいても、複数のロードバランサーを配置するのが一般的です。ロードバランサーは以下のような種々のメトリックを用いてトラフィックルーティングを行うことができます:ランダムLeast loadedセッション/クッキーラウンドロビンもしくは加重ラウンドロビンLayer 4Layer 7Layer 4 ロードバランシングLayer 4 ロードバランサーは トランスポートレイヤー を参照してどのようにリクエストを配分するか判断します。一般的に、トランスポートレイヤーとしては、ソース、送信先IPアドレス、ヘッダーに記述されたポート番号が含まれますが、パケットの中身のコンテンツは含みません。 Layer 4 ロードバランサーはネットワークパケットを上流サーバーへ届け、上流サーバーから配信することでネットワークアドレス変換 Network Address Translation (NAT) を実現します。Layer 7 ロードバランシングLayer 7 ロードバランサーは アプリケーションレイヤー を参照してどのようにリクエストを配分するか判断します。ヘッダー、メッセージ、クッキーなどのコンテンツのことです。Layer 7 ロードバランサーはネットワークトラフィックの終端を受け持ち メッセージを読み込み、ロードバランシングの判断をし、選択したサーバーとの接続を繋ぎます。例えば layer 7 ロードバランサーは動画のトラフィックを直接、そのデータをホストしているサーバーにつなぐと同時に、決済処理などのより繊細なトラフィックをセキュリティ強化されたサーバーに流すということもできる。柔軟性とのトレードオフになりますが、 layer 4 ロードバランサーではLayer 7ロードバランサーよりも所要時間、計算リソースを少なく済ませることができます。ただし、昨今の汎用ハードウェアではパフォーマンスは最小限のみしか発揮できないでしょう。水平スケーリングロードバランサーでは水平スケーリングによってパフォーマンスと可用性を向上させることができます。手頃な汎用マシンを追加することによってスケールアウトさせる方が、一つのサーバーをより高価なマシンにスケールアップする（垂直スケーリング）より費用対効果も高くなり、結果的に可用性も高くなります。また、汎用ハードウェアを扱える人材を雇う方が、特化型の商用ハードウェアを扱える人材を雇うよりも簡単でしょう。欠点: 水平スケーリング水平的にスケーリングしていくと、複雑さが増す上に、サーバーのクローニングが必要になる。サーバーはステートレスである必要がある: ユーザーに関連するセッションや、プロフィール写真などのデータを持ってはいけないセッションは一元的なデータベース (SQL、 NoSQL)などのデータストアにストアされるか キャッシュ (Redis、 Memcached)に残す必要があります。キャッシュやデータベースなどの下流サーバーは上流サーバーがスケールアウトするにつれてより多くの同時接続を保たなければなりません。欠点: ロードバランサーロードバランサーはリソースが不足していたり、設定が適切でない場合、システム全体のボトルネックになる可能性があります。単一障害点を除こうとしてロードバランサーを導入した結果、複雑さが増してしまうことになります。ロードバランサーが一つだけだとそこが単一障害点になってしまいます。一方で、ロードバランサーを複数にすると、さらに複雑さが増してしまいます。その他の参考資料、ページNGINX アーキテクチャHAProxy アーキテクチャガイドスケーラビリティWikipediaLayer 4 ロードバランシングLayer 7 ロードバランシングELB listener configリバースプロキシ(webサーバー)      Source: Wikipedia  リバースプロキシサーバーは内部サービスをまとめて外部に統一されたインターフェースを提供するウェブサーバーです。クライアントからのリクエストはそれに対応するサーバーに送られて、その後レスポンスをリバースプロキシがクライアントに返します。他には以下のような利点があります:より堅牢なセキュリティ - バックエンドサーバーの情報を隠したり、IPアドレスをブラックリスト化したり、クライアントごとの接続数を制限したりできます。スケーラビリティや柔軟性が増します - クライアントはリバースプロキシのIPしか見ないので、裏でサーバーをスケールしたり、設定を変えやすくなります。SSL termination - 入力されるリクエストを解読し、サーバーのレスポンスを暗号化することでサーバーがこのコストのかかりうる処理をしなくて済むようになります。X.509 証明書 を各サーバーにインストールする必要がなくなります。圧縮 - サーバーレスポンスを圧縮できますキャッシング - キャッシュされたリクエストに対して、レスポンスを返します静的コンテンツ - 静的コンテンツを直接送信することができます。HTML/CSS/JS写真動画などなどロードバランサー vs リバースプロキシ複数のサーバーがある時にはロードバランサーをデプロイすると役に立つでしょう。 しばしば、ロードバランサーは同じ機能を果たすサーバー群へのトラフィックを捌きます。リバースプロキシでは、上記に述べたような利点を、単一のウェブサーバーやアプリケーションレイヤーに対しても示すことができます。NGINX や HAProxy などの技術はlayer 7 リバースプロキシとロードバランサーの両方をサポートします。欠点: リバースプロキシリバースプロキシを導入するとシステムの複雑性が増します。単一のリバースプロキシは単一障害点になりえます。一方で、複数のリバースプロキシを導入すると(例: フェイルオーバー) 複雑性はより増します。その他の参考資料、ページリバースプロキシ vs ロードバランサーNGINX アーキテクチャHAProxy アーキテクチャ ガイドWikipediaアプリケーション層      Source: Intro to architecting systems for scaleウェブレイヤーをアプリケーション層 (プラットフォーム層とも言われる) と分離することでそれぞれの層を独立にスケール、設定することができるようになります。新しいAPIをアプリケーション層に追加する際に、不必要にウェブサーバーを追加する必要がなくなります。単一責任の原則 では、小さい自律的なサービスが協調して動くように提唱しています。小さいサービスの小さいチームが急成長のためにより積極的な計画を立てられるようにするためです。アプリケーション層は非同期処理もサポートします。マイクロサービス独立してデプロイできる、小規模なモジュール様式であるマイクロサービスもこの議論に関係してくる技術でしょう。それぞれのサービスは独自のプロセスを処理し、明確で軽量なメカニズムで通信して、その目的とする機能を実現します。1例えばPinterestでは以下のようなマイクロサービスに分かれています。ユーザープロフィール、フォロワー、フィード、検索、写真アップロードなどです。サービスディスカバリーConsul、 Etcd、 Zookeeper などのシステムでは、登録されているサービスの名前、アドレス、ポートの情報を監視することで、サービス同士が互いを見つけやすくしています。サービスの完全性の確認には Health checks が便利で、これには HTTP エンドポイントがよく使われます。 Consul と Etcd のいずれも組み込みの key-value store を持っており、設定データや共有データなどのデータを保存しておくことに使われます。欠点: アプリケーション層アーキテクチャ、運用、そしてプロセスを考慮すると、緩く結び付けられたアプリケーション層を追加するには、モノリシックなシステムとは異なるアプローチが必要です。マイクロサービスはデプロイと運用の点から見ると複雑性が増すことになります。その他の参考資料、ページスケールするシステムアーキテクチャを設計するためのイントロシステム設計インタビューを紐解くサービス指向アーキテクチャZookeeperのイントロダクションマイクロサービスを作るために知っておきたいことデータベース      Source: Scaling up to your first 10 million usersリレーショナルデータベースマネジメントシステム (RDBMS)SQLなどのリレーショナルデータベースはテーブルに整理されたデータの集合である。ACID はリレーショナルデータベースにおけるトランザクションのプロパティの集合である不可分性 - それぞれのトランザクションはあるかないかのいずれかである一貫性 - どんなトランザクションもデータベースをある確かな状態から次の状態に遷移させる。独立性 - 同時にトランザクションを処理することは、連続的にトランザクションを処理するのと同じ結果をもたらす。永続性 - トランザクションが処理されたら、そのように保存されるリレーショナルデータベースをスケールさせるためにはたくさんの技術がある: マスター・スレーブ レプリケーション、 マスター・マスター レプリケーション、 federation、 シャーディング、 非正規化、 そして SQL チューニングマスタースレーブ レプリケーションマスターデータベースが読み取りと書き込みを処理し、書き込みを一つ以上のスレーブデータベースに複製します。スレーブデータベースは読み取りのみを処理します。スレーブデータベースは木構造のように追加のスレーブにデータを複製することもできます。マスターデータベースがオフラインになった場合には、いずれかのスレーブがマスターに昇格するか、新しいマスターデータベースが追加されるまでは読み取り専用モードで稼働します。      Source: Scalability, availability, stability, patterns欠点: マスタースレーブ レプリケーションスレーブをマスターに昇格させるには追加のロジックが必要になる。マスタースレーブ レプリケーション、マスターマスター レプリケーションの 両方 の欠点は欠点: レプリケーションを参照マスターマスター レプリケーションいずれのマスターも読み取り書き込みの両方に対応する。書き込みに関してはそれぞれ協調する。いずれかのマスターが落ちても、システム全体としては読み書き両方に対応したまま運用できる。      Source: Scalability, availability, stability, patterns欠点: マスターマスター レプリケーションロードバランサーを導入するか、アプリケーションロジックを変更することでどこに書き込むかを指定しなければならない。大体のマスターマスターシステムは、一貫性が緩い（ACID原理を守っていない）もしくは、同期する時間がかかるために書き込みのレイテンシーが増加してしまっている。書き込みノードが追加され、レイテンシーが増加するにつれ書き込みの衝突の可能性が増える。マスタースレーブ レプリケーション、マスターマスター レプリケーションの 両方 の欠点は欠点: レプリケーション を参照欠点: レプリケーション新しいデータ書き込みを複製する前にマスターが落ちた場合にはそのデータが失われてしまう可能性がある。書き込みは読み取りレプリカにおいてリプレイされる。書き込みが多い場合、複製ノードが書き込みの処理のみで行き詰まって、読み取りの処理を満足に行えない可能性がある。読み取りスレーブノードの数が多ければ多いほど、複製しなければならない数も増え、複製時間が伸びてしまいます。システムによっては、マスターへの書き込みはマルチスレッドで並列処理できる一方、スレーブへの複製は単一スレッドで連続的に処理しなければならない場合があります。レプリケーションでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: レプリケーションスケーラビリティ、 可用性、 スタビリティ パターンマルチマスター レプリケーションFederation      Source: Scaling up to your first 10 million usersフェデレーション (もしくは機能分割化とも言う) はデータベースを機能ごとに分割する。例えば、モノリシックな単一データベースの代わりに、データベースを フォーラム、 ユーザー、 プロダクト のように三つにすることで、データベース一つあたりの書き込み・読み取りのトラフィックが減り、その結果レプリケーションのラグも短くなります。データベースが小さくなることで、メモリーに収まるデータが増えます。キャッシュの局所性が高まるため、キャッシュヒット率も上がります。単一の中央マスターで書き込みを直列化したりしないため、並列で書き込みを処理することができ、スループットの向上が期待できます。欠点: federation大規模な処理やテーブルを要するスキーマの場合、フェデレーションは効果的とは言えないでしょう。どのデータベースに読み書きをするのかを指定するアプリケーションロジックを更新しなければなりません。server linkで二つのデータベースからのデータを連結するのはより複雑になるでしょう。フェデレーションでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: federationScaling up to your first 10 million usersシャーディング      Source: Scalability, availability, stability, patternsシャーディングでは異なるデータベースにそれぞれがデータのサブセット断片のみを持つようにデータを分割します。ユーザーデータベースを例にとると、ユーザー数が増えるにつれてクラスターにはより多くの断片が加えられることになります。federationの利点に似ていて、シャーディングでは読み書きのトラフィックを減らし、レプリケーションを減らし、キャッシュヒットを増やすことができます。インデックスサイズも減らすことができます。一般的にはインデックスサイズを減らすと、パフォーマンスが向上しクエリ速度が速くなります。なにがしかのデータを複製する機能がなければデータロスにつながりますが、もし、一つのシャードが落ちても、他のシャードが動いていることになります。フェデレーションと同じく、単一の中央マスターが書き込みの処理をしなくても、並列で書き込みを処理することができ、スループットの向上が期待できます。ユーザーテーブルをシャードする一般的な方法は、ユーザーのラストネームイニシャルでシャードするか、ユーザーの地理的配置でシャードするなどです。欠点: シャーディングシャードに対応するようにアプリケーションロジックを変更しなければなりません。結果としてSQLクエリが複雑になります。シャードではデータ配分がいびつになってしまう可能性があります。例えば、標準ユーザーの集合を持つシャードがある場合、そのシャードが他のシャードよりも重い負荷を負うことになります。リバランシングをすると複雑性がより増します。consistent hashing に基づいたシャーディングでは、通信データを削減することもできます。複数のシャードからのデータを連結するのはより複雑です。シャーディングでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: シャーディングシャードの登場シャードデータベースアーキテクチャConsistent hashing非正規化非正規化では、書き込みのパフォーマンスをいくらか犠牲にして読み込みのパフォーマンスを向上させようとします。計算的に重いテーブルの結合などをせずに、複数のテーブルに冗長なデータのコピーが書き込まれるのを許容します。いくつかのRDBMS例えば、PostgreSQL やOracleはこの冗長な情報を取り扱い、一貫性を保つためのmaterialized views という機能をサポートしています。フェデレーション や シャーディングなどのテクニックによってそれぞれのデータセンターに分配されたデータを合一させることはとても複雑な作業です。非正規化によってそのような複雑な処理をしなくて済むようになります。多くのシステムで、100対1あるいは1000対1くらいになるくらい読み取りの方が、書き込みのトラフィックよりも多いことでしょう。読み込みを行うために、複雑なデータベースのジョイン処理が含まれるものは計算的に高価につきますし、ディスクの処理時間で膨大な時間を費消してしまうことになります。欠点: 非正規化データが複製される。冗長なデータの複製が同期されるように制約が存在し、そのことでデータベース全体の設計が複雑化する。非正規化されたデータベースは過大な書き込みを処理しなければならない場合、正規化されているそれよりもパフォーマンスにおいて劣る可能性がある。その他の参考資料、ページ: 非正規化DenormalizationSQLチューニングSQLチューニングは広範な知識を必要とする分野で多くの 本 が書かれています。ボトルネックを明らかにし、シミュレートする上で、 ベンチマーク を定め、 プロファイル することはとても重要です。ベンチマーク - abなどのツールを用いて、高負荷の状況をシミュレーションしてみましょう。プロファイル - slow query log などのツールを用いて、パフォーマンス状況の確認をしましょう。ベンチマークとプロファイルをとることで以下のような効率化の選択肢をとることになるでしょう。スキーマを絞るMySQLはアクセス速度向上のため、ディスク上の連続したブロックへデータを格納しています。長さの決まったフィールドに対しては VARCHAR よりも CHAR を使うようにしましょう。CHAR の方が効率的に速くランダムにデータにアクセスできます。 一方、 VARCHAR では次のデータに移る前にデータの末尾を検知しなければならないために速度が犠牲になります。ブログの投稿など、大きなテキストには TEXT を使いましょう。 TEXT ではブーリアン型の検索も可能です。 TEXT フィールドには、テキストブロックが配置されている、ディスク上の場所へのポインターが保存されます。2の32乗や40億以下を超えない程度の大きな数には INT を使いましょう。通貨に関しては小数点表示上のエラーを避けるために DECIMAL を使いましょう。大きな BLOBS を保存するのは避けましょう。どこからそのオブジェクトを取ってくることができるかの情報を保存しましょう。VARCHAR(255) は8ビットで数えられる最大の文字数です。一部のDBMSでは、1バイトの利用効率を最大化するためにこの文字数がよく使われます。検索性能向上のため 、可能であれば NOT NULL 制約を設定しましょう。インデックスを効果的に用いるクエリ(SELECT、 GROUP BY、 ORDER BY、 JOIN) の対象となる列にインデックスを使うことで速度を向上できるかもしれません。インデックスは通常、平衡探索木であるB木の形で表されます。B木によりデータは常にソートされた状態になります。また検索、順次アクセス、挿入、削除を対数時間で行えます。インデックスを配置することはデータをメモリーに残すことにつながりより容量を必要とします。インデックスの更新も必要になるため書き込みも遅くなります。大量のデータをロードする際には、インデックスを切ってからデータをロードして再びインデックスをビルドした方が速いことがあります。高負荷なジョインを避けるパフォーマンス上必要なところには非正規化を適用するテーブルのパーティションテーブルを分割し、ホットスポットを独立したテーブルに分離してメモリーに乗せられるようにする。クエリキャッシュを調整する場合によってはクエリキャッシュ がパフォーマンス問題 を引き起こす可能性があるその他の参考資料、ページ: SQLチューニングMySQLクエリを最適化するためのTipsVARCHAR(255)をやたらよく見かけるのはなんで？null値はどのようにパフォーマンスに影響するのか？Slow query logNoSQLNoSQL は key-value store、 document-store、 wide column store、 もしくは graph databaseによって表現されるデータアイテムの集合です。データは一般的に正規化されておらず、アプリケーション側でジョインが行われます。大部分のNoSQLは真のACIDトランザクションを持たず、 結果整合性 的な振る舞いの方を好みます。BASE はしばしばNoSQLデータベースのプロパティを説明するために用いられます。CAP Theorem と対照的に、BASEは一貫性よりも可用性を優先します。Basically available - システムは可用性を保証します。Soft state - システムの状態は入力がなくても時間経過とともに変化する可能性があります。結果整合性 - システム全体は時間経過とともにその間に入力がないという前提のもと、一貫性が達成されます。SQLか？NoSQLか？ を選択するのに加えて、どのタイプのNoSQLがどの使用例に最も適するかを理解するのはとても有益です。このセクションでは キーバリューストア、 ドキュメントストア、 ワイドカラムストア、 と グラフデータベース について触れていきます。キーバリューストア概要: ハッシュテーブルキーバリューストアでは一般的にO(1)の読み書きができ、それらはメモリないしSSDで裏付けられています。データストアはキーを 辞書的順序 で保持することでキーの効率的な取得を可能にしています。キーバリューストアではメタデータを値とともに保持することが可能です。キーバリューストアはハイパフォーマンスな挙動が可能で、単純なデータモデルやインメモリーキャッシュレイヤーなどのデータが急速に変わる場合などに使われます。単純な処理のみに機能が制限されているので、追加の処理機能が必要な場合にはその複雑性はアプリケーション層に載せることになります。キーバリューストアはもっと複雑なドキュメントストアや、グラフデータベースなどの基本です。その他の参考資料、ページ: キーバリューストアキーバリューデータベースキーバリューストアの欠点Redisアーキテクチャメムキャッシュアーキテクチャドキュメントストア概要: ドキュメントがバリューとして保存されたキーバリューストアドキュメントストアはオブジェクトに関する全ての情報を持つドキュメント(XML、 JSON、 binaryなど)を中心に据えたシステムです。ドキュメントストアでは、ドキュメント自身の内部構造に基づいた、APIもしくはクエリ言語を提供します。 メモ：多くのキーバリューストアでは、値のメタデータを扱う機能を含んでいますが、そのことによって二つドキュメントストアとの境界線が曖昧になってしまっています。以上のことを実現するために、ドキュメントはコレクション、タグ、メタデータやディレクトリなどとして整理されています。ドキュメント同士はまとめてグループにできるものの、それぞれで全く異なるフィールドを持つ可能性があります。MongoDB や CouchDB などのドキュメントストアも、複雑なクエリを処理するためのSQLのような言語を提供しています。DynamoDB はキーバリューとドキュメントの両方をサポートしています。ドキュメントストアは高い柔軟性を担保するので、頻繁に変化するデータを扱う時に用いられます。その他の参考資料、ページ:  ドキュメントストアドキュメント指向 データベースMongoDB アーキテクチャCouchDB アーキテクチャElasticsearch アーキテクチャワイドカラムストア      Source: SQL & NoSQL, a brief history概要: ネストされたマップ カラムファミリー<行キー、 カラム<ColKey、 Value、 Timestamp>>ワイドカラムストアのデータの基本単位はカラム（ネーム・バリューのペア）です。それぞれのカラムはカラムファミリーとして（SQLテーブルのように）グループ化することができます。スーパーカラムファミリーはカラムファミリーの集合です。それぞれのカラムには行キーでアクセスすることができます。同じ行キーを持つカラムは同じ行として認識されます。それぞれの値は、バージョン管理とコンフリクトが起きた時のために、タイムスタンプを含みます。GoogleはBigtableを初のワイドカラムストアとして発表しました。それがオープンソースでHadoopなどでよく使われるHBase やFacebookによるCassandra などのプロジェクトに影響を与えました。BigTable、HBaseやCassandraなどのストアはキーを辞書形式で保持することで選択したキーレンジでのデータ取得を効率的にします。ワイドカラムストアは高い可用性とスケーラビリティを担保します。これらはとても大規模なデータセットを扱うことによく使われます。その他の参考資料、ページ:  ワイドカラムストアSQL & NoSQL簡単に歴史をさらうBigtable アーキテクチャHBase アーキテクチャCassandra アーキテクチャグラフデータベース      Source: Graph database概要: グラフグラフデータベースでは、それぞれのノードがレコードで、それぞれのアークは二つのノードを繋ぐ関係性として定義されます。グラフデータベースは多数の外部キーや多対多などの複雑な関係性を表すのに最適です。グラフデータベースはSNSなどのサービスの複雑な関係性モデルなどについて高いパフォーマンスを発揮します。比較的新しく、まだ一般的には用いられていないので、開発ツールやリソースを探すのが他の方法に比べて難しいかもしれません。多くのグラフはREST APIsを通じてのみアクセスできます。その他の参考資料、ページ:  グラフGraphデータベースNeo4jFlockDBその他の参考資料、ページ:  NoSQL基本用語の説明NoSQLデータベースについて調査と選択ガイドスケーラビリティNoSQLのイントロダクションNoSQLパターンSQLか？NoSQLか？      Source: Transitioning from RDBMS to NoSQLSQL を選ぶ理由:構造化されたデータ厳格なスキーマリレーショナルデータ複雑なジョインをする必要性トランザクションスケールする際のパターンが明確なとき開発者の数、コミュニティ、コード等がより充実しているインデックスによるデータ探索はとても速いNoSQL を選ぶ理由:準構造化されたデータダイナミックないし、フレキシブルなスキーマノンリレーショナルなデータ複雑なジョインをする必要がないデータの多くのTB (もしくは PB) を保存する集中的、大規模なデータ負荷に耐えられるIOPSについては極めて高いスループットを示すNoSQLに適するサンプルデータ:急激なクリックストリームやログデータの収集リーダーボードやスコアリングデータショッピングカートなどの一時的情報頻繁にアクセスされる ('ホットな') テーブルメタデータやルックアップテーブルその他の参考資料、ページ:  　SQLもしくはNoSQL最初の1000万ユーザーにスケールアップするためにSQLとNoSQLの違いキャッシュ      Source: Scalable system design patternsキャッシュはページの読み込み時間を削減し、サーバーやデータベースへの負荷を低減することができます。このモデルでは、実際の処理を保存するために、ディスパッチャーがまず以前にリクエストが送信されたかどうかを確認し、直前の結果を受け取ります。データベースはそのパーティションに渡って統合された読み取り書き込みの分配を要求しますが、人気アイテムはその分配を歪めてシステム全体のボトルネックになってしまうことがあります。データベースの前にキャッシュを差し込むことでこのように、均一でない負荷やトラフィックの急激な増加を吸収することができます。クライアントキャッシングキャッシュはOSやブラウザーなどのクライアントサイド、サーバーサイド もしくは独立のキャッシュレイヤーに設置することができます。CDNキャッシングCDN もキャッシュの一つとして考えることができます。Webサーバーキャッシングリバースプロキシ や Varnish などのキャッシュは静的そして動的なコンテンツを直接配信することができます。 webサーバーもリクエストをキャッシュしてアプリケーションサーバーに接続することなしにレスポンスを返すことができます。データベースキャッシングデータベースは普通、一般的な使用状況に適するようなキャッシングの設定を初期状態で持っています。この設定を特定の仕様に合わせて調整することでパフォーマンスを向上させることができます。アプリケーションキャッシングメムキャッシュなどのIn-memoryキャッシュやRedisはアプリケーションとデータストレージの間のキーバリューストアです。データはRAMで保持されるため、データがディスクで保存される一般的なデータベースよりもだいぶ速いです。RAM容量はディスクよりも限られているので、least recently used (LRU)などのcache invalidation アルゴリズムが 'コールド' なエントリを弾き、'ホット' なデータをRAMに保存します。Redisはさらに以下のような機能を備えています:パージステンス設定ソート済みセット、リストなどの組み込みデータ構造キャッシュには様々なレベルのものがありますが、いずれも大きく二つのカテゴリーのいずれかに分類することができます: データベースクエリ と オブジェクト です:行レベルクエリレベルFully-formed serializable objectsFully-rendered HTML一般的に、ファイルベースキャッシングはクローンを作り出してオートスケーリングを難しくしてしまうので避けるべきです。データベースクエリレベルでのキャッシングデータベースをクエリする際には必ずクエリをキーとしてハッシュして結果をキャッシュに保存しましょう。この手法はキャッシュ期限切れ問題に悩むことになります:複雑なクエリによりキャッシュされた結果を削除することが困難テーブルセルなどのデータ断片が変化した時に、その変化したセルを含むかもしれない全てのキャッシュされたクエリを削除する必要がある。オブジェクトレベルでのキャッシングデータをアプリケーションコードでそうするように、オブジェクトとして捉えてみましょう。アプリケーションに、データベースからのデータセットをクラスインスタンスやデータ構造として組み立てさせます。:そのデータが変更されたら、オブジェクトをキャッシュから削除すること非同期処理を許容します: ワーカーがキャッシュされたオブジェクトの中で最新のものを集めてきます何をキャッシュするか:ユーザーのセッション完全にレンダーされたウェブページアクテビティストリームユーザーグラフデータいつキャッシュを更新するかキャッシュに保存できる容量は限られているため、自分のケースではどのキャッシュ手法が一番いいかは検討する必要があります。キャッシュアサイド      Source: From cache to in-memory data gridアプリケーションはストレージへの読み書きの処理をします。キャッシュはストレージとは直接やりとりをしません。アプリケーションは以下のことをします:キャッシュの中のエントリを参照しますが、結果としてキャッシュミスになりますデータベースからエントリを取得しますエントリをキャッシュに追加しますエントリを返しますdef get_user(self, user_id):    user = cache.get(\""user.{0}\"", user_id)    if user is None:        user = db.query(\""SELECT * FROM users WHERE user_id = {0}\"", user_id)        if user is not None:            key = \""user.{0}\"".format(user_id)            cache.set(key, json.dumps(user))    return userMemcached は通常このように使われる。その後のキャッシュデータ読み込みは速いです。キャッシュアサイドはレージーローディングであるとも言われます。リクエストされたデータのみがキャッシュされ、リクエストされていないデータでキャッシュが溢れるのを防止します。欠点: キャッシュアサイド各キャッシュミスは三つのトリップを呼び出すことになり、体感できるほどの遅延が起きてしまいます。データベースのデータが更新されるとキャッシュデータは古いものになってしまいます。time-to-live (TTL)を設定することでキャッシュエントリの更新を強制的に行う、もしくはライトスルーを採用することでこの問題は緩和できます。ノードが落ちると、新規の空のノードで代替されることでレイテンシーが増加することになります。ライトスルー      Source: Scalability, availability, stability, patternsアプリケーションはキャッシュをメインのデータストアとして使い、そこにデータの読み書きを行います。一方、キャッシュはデータベースへの読み書きを担当します。アプリケーションはキャッシュにあるエントリを追加・更新しますキャッシュは同期的にデータストアに書き込みを行いますエントリを返しますアプリケーションコード:set_user(12345, {\""foo\"":\""bar\""})キャッシュコード:def set_user(user_id, values):    user = db.query(\""UPDATE Users WHERE id = {0}\"", user_id, values)    cache.set(user_id, user)ライトスルーは書き込み処理のせいで全体としては遅いオペレーションですが、書き込まれたばかりのデータに関する読み込みは速いです。ユーザー側は一般的にデータ更新時の方が読み込み時よりもレイテンシーに許容的です。キャッシュ内のデータは最新版で保たれます。欠点: ライトスルーノードが落ちたこと、もしくはスケーリングによって新しいノードが作成された時に、新しいノードはデータベース内のエントリーが更新されるまではエントリーをキャッシュしません。キャッシュアサイドとライトスルーを併用することでこの問題を緩和できます。書き込まれたデータの大部分は一度も読み込まれることはありません。このデータはTTLによって圧縮することができます。ライトビハインド (ライトバック)      Source: Scalability, availability, stability, patternsライトビハインドではアプリケーションは以下のことをします:キャッシュのエントリーを追加・更新しますデータストアへの書き込みを非同期的に行うことで、書き込みパフォーマンスを向上させます。欠点: ライトビハインドキャッシュがデータストア内のコンテンツにヒットする前にキャッシュが落ちるとデータ欠損が起きる可能性があります。キャッシュアサイドやライトスルーよりも実装が複雑になります。リフレッシュアヘッド      Source: From cache to in-memory data grid期限切れよりも前に、直近でアクセスされた全てのキャッシュエントリを自動的に更新するように設定することができます。もしどのアイテムが将来必要になるのかを正確に予測することができるのならば、リードスルーよりもレイテンシーを削減することができます。欠点: リフレッシュアヘッドどのアイテムが必要になるかの予測が正確でない場合にはリフレッシュアヘッドがない方がレイテンシーは良いという結果になってしまいます。欠点: キャッシュcache invalidationなどを用いて、データベースなどの真のデータとキャッシュの間の一貫性を保つ必要があります。Redisやmemcachedを追加することでアプリケーション構成を変更する必要があります。Cache invalidationも難しいですがそれに加えて、いつキャッシュを更新するかという複雑な問題にも悩まされることになります。その他の参考資料、ページFrom cache to in-memory data gridスケーラブルなシステムデザインパターンスケールできるシステムを設計するためのイントロダクションスケーラビリティ、可用性、安定性、パターンスケーラビリティAWS ElastiCacheのストラテジーWikipedia非同期処理      Source: Intro to architecting systems for scale非同期のワークフローはもし、連続的に行われるとリクエスト時間を圧迫してしまうような重い処理を別で処理する手法です。また、定期的にデータを集合させるなどの時間がかかるような処理を前もって処理しておくことにも役立ちます。メッセージキューメッセージキューはメッセージを受け取り、保存し、配信します。もし、処理がインラインで行うには遅すぎる場合、以下のようなワークフローでメッセージキューを用いるといいでしょう:アプリケーションはジョブをキューに配信し、ユーザーにジョブステータスを伝えます。ワーカーがジョブキューから受け取って、処理を行い、終了したらそのシグナルを返します。ユーザーの処理が止まることはなく、ジョブはバックグラウンドで処理されます。この間に、クライアントはオプションとして、タスクが完了したかのように見せるために小規模の処理を行います。例えば、ツイートを投稿するときに、ツイートはすぐにあなたのタイムラインに反映されたように見えますが、そのツイートが実際に全てのフォロワーに配信されるまでにはもう少し時間がかかっているでしょう。Redis はシンプルなメッセージ仲介としてはいいですが、メッセージが失われてしまう可能性があります。RabbitMQ はよく使われていますが、'AMQP'プロトコルに対応して、自前のノードを立てる必要があります。Amazon SQS という選択肢もありますが、レイテンシーが高く、メッセージが重複して配信されてしまう可能性があります。タスクキュータスクキューはタスクとその関連するデータを受け取り、処理した上でその結果を返します。スケジュール管理をできるほか、バックグラウンドでとても重いジョブをこなすこともできます。Celery はスケジューリングとpythonのサポートがあります。バックプレッシャーもし、キューが拡大しすぎると、メモリーよりもキューの方が大きくなりキャッシュミスが起こり、ディスク読み出しにつながり、パフォーマンスが低下することにつながります。バックプレッシャーはキューサイズを制限することで回避することができ、高いスループットを確保しキューにすでにあるジョブについてのレスポンス時間を短縮できます。キューがいっぱいになると、クライアントはサーバービジーもしくはHTTP 503をレスポンスとして受け取りまた後で時間をおいてアクセスするようにメッセージを受け取ります。クライアントはexponential backoffなどによって後ほど再度時間を置いてリクエストすることができます。欠点: 非同期処理キューを用いることで遅延が起こり、複雑さも増すため、あまり重くない計算処理やリアルタイムワークフローにおいては同期処理の方がいいでしょう。その他の参考資料、ページIt's all a numbers gameオーバーロードした時にバックプレッシャーを適用するLittle's lawメッセージキューとタスクキューの違いとは？通信      Source: OSI 7 layer modelHypertext transfer protocol (HTTP)HTTP はクライアントとサーバー間でのデータをエンコードして転送するための手法です。リクエスト・レスポンスに関わるプロトコルです。クライアントがリクエストをサーバーに投げ、サーバーがリクエストに関係するコンテンツと完了ステータス情報をレスポンスとして返します。HTTPは自己完結するので、間にロードバランサー、キャッシュ、エンクリプション、圧縮などのどんな中間ルーターが入っても動くようにできています。基本的なHTTPリクエストはHTTP動詞(メソッド)とリソース(エンドポイント)で成り立っています。以下がよくあるHTTP動詞です。:動詞詳細冪等性*セーフキャッシュできるかGETリソースを読み取るYesYesYesPOSTリソースを作成するもしくはデータを処理するトリガーNoNoYes レスポンスが新しい情報を含む場合PUTリソースを作成もしくは入れ替えるYesNoNoPATCHリソースを部分的に更新するNoNoYes レスポンスが新しい情報を含む場合DELETEリソースを削除するYesNoNo何度呼んでも同じ結果が返ってくることHTTPはTCP や UDP などの低級プロトコルに依存しているアプリケーションレイヤーのプロトコルである。その他の参考資料、ページ: HTTPHTTPってなに?HTTP と TCPの違いPUT と PATCHの違い伝送制御プロトコル (TCP)      Source: How to make a multiplayer gameTCPはIP networkの上で成り立つ接続プロトコルです。接続はhandshakeによって開始、解除されます。全ての送信されたパケットは欠損なしで送信先に送信された順番で到達するように以下の方法で保証されています:シーケンス番号とchecksum fieldsが全てのパケットに用意されているAcknowledgementパケットと自動再送信もし送信者が正しいレスポンスを受け取らなかったとき、パケットを再送信します。複数のタイムアウトがあったとき、接続は解除されます。TCP はフロー制御 と 輻輳制御も実装しています。これらの機能によって速度は低下し、一般的にUDPよりも非効率な転送手段になっています。ハイスループットを実現するために、ウェブサーバーはかなり大きな数のTCP接続を開いておくことがあり、そのことでメモリー使用が圧迫されます。ウェブサーバスレッドと例えばmemcached サーバーの間で多数のコネクションを保っておくことは高くつくかもしれません。可能なところではUDPに切り替えるだけでなくコネクションプーリングなども役立つかもしれません。TCPは高い依存性を要し、時間制約が厳しくないものに適しているでしょう。ウェブサーバー、データベース情報、SMTP、FTPやSSHなどの例に適用されます。以下の時にUDPよりもTCPを使うといいでしょう:全てのデータが欠損することなしに届いてほしいネットワークスループットの最適な自動推測をしてオペレーションしたいユーザデータグラムプロトコル (UDP)      Source: How to make a multiplayer gameUDPはコネクションレスです。データグラム（パケットのようなもの）はデータグラムレベルでの保証しかされません。データグラムは順不同で受け取り先に到着したりそもそも着かなかったりします。UDPは輻輳制御をサポートしません。TCPにおいてはサポートされているこれらの保証がないため、UDPは一般的に、TCPよりも効率的です。UDPはサブネット上のすべての機器にデータグラムを送信することができます。これはDHCP において役に立ちます。というのも、クライアントはまだIPアドレスを取得していないので、IPアドレスを必要とするTCPによるストリームができないからです。UDPは信頼性の面では劣りますが、VoIP、ビデオチャット、ストリーミングや同時通信マルチプレイヤーゲームなどのリアルタイム性が重視される時にはとても効果的です。TCPよりもUDPを使うのは:レイテンシーを最低限に抑えたい時データ欠損よりも、データ遅延を重視するときエラー修正を自前で実装したいときその他の参考資料、ページ: TCP と UDPゲームプログラミングのためのネットワークTCP と UDP プロトコルの主な違いTCP と UDPの違いTransmission control protocolUser datagram protocolFacebookのメムキャッシュスケーリング遠隔手続呼出 (RPC)      Source: Crack the system design interviewRPCではクライアントがリモートサーバーなどの異なるアドレス空間でプロシージャーが処理されるようにします。プロシージャーはローカルでのコールのように、クライアントからサーバーにどのように通信するかという詳細を省いた状態でコードが書かれます。リモートのコールは普通、ローカルのコールよりも遅く、信頼性に欠けるため、RPCコールをローカルコールと区別させておくことが好ましいでしょう。人気のRPCフレームワークは以下です。Protobuf、 Thrift、AvroRPC は リクエストレスポンスプロトコル:クライアントプログラム - クライアントスタブプロシージャーを呼び出します。パラメータはローカルでのプロシージャーコールのようにスタックへとプッシュされていきます。クライアントスタブプロシージャー - プロシージャIDとアーギュメントをパックしてリクエストメッセージにします。クライアント通信モジュール - OSがクライアントからサーバーへとメッセージを送ります。サーバー通信モジュール - OSが受け取ったパケットをサーバースタブプロシージャーに受け渡します。サーバースタブプロシージャー -  結果を展開し、プロシージャーIDにマッチするサーバープロシージャーを呼び出し、結果を返します。サーバーレスポンスは上記のステップを逆順で繰り返します。Sample RPC calls:GET /someoperation?data=anIdPOST /anotheroperation{  \""data\"":\""anId\"";  \""anotherdata\"": \""another value\""}RPCは振る舞いを公開することに焦点を当てています。RPCは内部通信パフォーマンスを理由として使われることが多いです。というのも、使用する状況に合わせてネイティブコールを自作することができるからです。ネイティブライブラリー (aka SDK) を呼ぶのは以下の時:ターゲットのプラットフォームを知っている時ロジックがどのようにアクセスされるのかを管理したいときライブラリー外でエラーがどのようにコントロールされるかを管理したい時パフォーマンスとエンドユーザーエクスペリエンスが最優先の時REST プロトコルに従うHTTP APIはパブリックAPIにおいてよく用いられます。欠点: RPCRPCクライアントとはサービス実装により厳密に左右されることになります。新しいオペレーション、使用例があるたびに新しくAPIが定義されなければなりません。RPCをデバッグするのは難しい可能性があります。既存のテクノロジーをそのまま使ってサービスを構築することはできないかもしれません。例えば、SquidなどのサーバーにRPCコールが正しくキャッシュ されるように追加で骨を折る必要があるかもしれません。Representational state transfer (REST)RESTは、クライアントがサーバーによってマネージされるリソースに対して処理を行うクライアント・サーバーモデルを支持するアーキテキチャスタイルです。サーバーは操作できるもしくは新しいリソースレプレゼンテーションを受け取ることができるようなリソースやアクションのレプレゼンテーションを提供します。すべての通信はステートレスでキャッシュ可能でなければなりません。RESTful なインターフェースには次の四つの特徴があります:特徴的なリソース (URI in HTTP) - どのオペレーションであっても同じURIを使う。HTTP動詞によって変わる (Verbs in HTTP) - 動詞、ヘッダー、ボディを使う自己説明的なエラーメッセージ (status response in HTTP) - ステータスコードを使い、新しく作ったりしないこと。HATEOAS (HTML interface for HTTP) - 自分のwebサービスがブラウザで完全にアクセスできること。サンプル REST コール:GET /someresources/anIdPUT /someresources/anId{\""anotherdata\"": \""another value\""}RESTはデータを公開することに焦点を当てています。クライアントとサーバーのカップリングを最小限にするもので、パブリックAPIなどによく用いられます。RESTはURI、 representation through headers、そして、GET、POST、PUT、 DELETE、PATCHなどのHTTP動詞等のよりジェネリックで統一されたメソッドを用います。ステートレスであるのでRESTは水平スケーリングやパーティショニングに最適です。欠点: RESTRESTはデータ公開に焦点を当てているので、リソースが自然に整理されていなかったり、シンプルなヒエラルキーで表せられない時にはよい選択肢とは言えないかもしれません。例えば、とあるイベントのセットにマッチするすべての更新情報を返すと言った処理は簡単にはパスで表現することができません。RESTでは、URIパス、クエリパラメータ、そして場合によってはリクエストボディなどによって実装されることが多いでしょう。RESTは少数の動詞に依存しています(GET、POST、PUT、DELETE、そして PATCH) が時には使いたい事例に合わないことがあります。例えば、期限の切れたドキュメントをアーカイブに移したい場合などはこれらの動詞の中には綺麗にはフィットしません。ネストされたヒエラルキーの中にあるリソースをとってくるのはシングルビューを描画するのにクライアントとサーバー間で数回やりとりしなければなりません。例として、ブログエントリーのコンテンツとそれに対するコメントを表示する場合などです。様々なネットワーク環境で動作する可能性が考えられるモバイルアプリケーションにおいてはこのような複数のやり取りは好ましくありません。時が経つにつれて、APIレスポンスにより多くのフィールドが与えられて、古いクライアントはすでにいらないものも含めてすべてのデータフィールドを受け取ることになります。そのことで、ペイロードが大きくなりすぎて、レイテンシーも拡大することになります。RPCとREST比較OperationRPCRESTサインアップPOST /signupPOST /personsリザインPOST /resign{\""personid\"": \""1234\""}DELETE /persons/1234Person読み込みGET /readPerson?personid=1234GET /persons/1234Personのアイテムリスト読み込みGET /readUsersItemsList?personid=1234GET /persons/1234/itemsPersonのアイテムへのアイテム追加POST /addItemToUsersItemsList{\""personid\"": \""1234\"";\""itemid\"": \""456\""}POST /persons/1234/items{\""itemid\"": \""456\""}アイテム更新POST /modifyItem{\""itemid\"": \""456\"";\""key\"": \""value\""}PUT /items/456{\""key\"": \""value\""}アイテム削除POST /removeItem{\""itemid\"": \""456\""}DELETE /items/456  Source: Do you really know why you prefer REST over RPCその他の参考資料、ページ: REST と RPCDo you really know why you prefer REST over RPCWhen are RPC-ish approaches more appropriate than REST?REST vs JSON-RPCDebunking the myths of RPC and RESTWhat are the drawbacks of using RESTCrack the system design interviewThriftWhy REST for internal use and not RPCセキュリティこのセクションは更新が必要です。contributingしてください！セキュリティは幅広いトピックです。十分な経験、セキュリティ分野のバックグラウンドがなくても、セキュリティの知識を要する職に応募するのでない限り、基本以上のことを知る必要はないでしょう。情報伝達、保存における暗号化XSS や SQL injectionを防ぐために、全てのユーザー入力もしくはユーザーに露出される入力パラメーターをサニタイズするSQL injectionを防ぐためにパラメータ化されたクエリを用いる。least privilegeの原理を用いるその他の参考資料、ページ:開発者のためのセキュリティガイドOWASP top ten補遺暗算で、推計値を求める必要があることも時にはあります。例えば、ディスクから100枚イメージ分のサムネイルを作る時間を求めたり、その時にどれだけディスクメモリーが消費されるかなどの値です。2の乗数表 と 全てのプログラマーが知るべきレイテンシー値 は良い参考になるでしょう。2の乗数表乗数           厳密な値         約        Bytes---------------------------------------------------------------7                             1288                             25610                           1024   1 thousand           1 KB16                         65,536                       64 KB20                      1,048,576   1 million            1 MB30                  1,073,741,824   1 billion            1 GB32                  4,294,967,296                        4 GB40              1,099,511,627,776   1 trillion           1 TBその他の参考資料、ページ:2の乗数表全てのプログラマーが知るべきレイテンシー値Latency Comparison Numbers--------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy            10,000   ns       10 usSend 1 KB bytes over 1 Gbps network     10,000   ns       10 usRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSDRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSDSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 msNotes-----1 ns = 10^-9 seconds1 us = 10^-6 seconds = 1,000 ns1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns上記表に基づいた役に立つ数値:ディスクからの連続読み取り速度 30 MB/s1 Gbps Ethernetからの連続読み取り速度　100 MB/sSSDからの連続読み取り速度 1 GB/smain memoryからの連続読み取り速度 4 GB/s1秒で地球6-7周できる1秒でデータセンターと2000周やりとりできるレイテンシーの視覚的表その他の参考資料、ページ:全てのプログラマーが知るべきレイテンシー値 - 1全てのプログラマーが知るべきレイテンシー値 - 2Designs, lessons, and advice from building large distributed systemsSoftware Engineering Advice from Building Large-Scale Distributed Systems他のシステム設計面接例題頻出のシステム設計面接課題とその解答へのリンク質問解答Dropboxのようなファイル同期サービスを設計するyoutube.comGoogleのような検索エンジンの設計queue.acm.orgstackexchange.comardendertat.comstanford.eduGoogleのようなスケーラブルなwebクローラーの設計quora.comGoogle docsの設計code.google.comneil.fraser.nameRedisのようなキーバリューストアの設計slideshare.netMemcachedのようなキャッシュシステムの設計slideshare.netAmazonのようなレコメンデーションシステムの設計hulu.comijcai13.orgBitlyのようなURL短縮サービスの設計n00tc0d3r.blogspot.comWhatsAppのようなチャットアプリの設計highscalability.comInstagramのような写真共有サービスの設計highscalability.comhighscalability.comFacebookニュースフィードの設計quora.comquora.comslideshare.netFacebookタイムラインの設計facebook.comhighscalability.comFacebookチャットの設計erlang-factory.comfacebook.comFacebookのようなgraph検索の設計facebook.comfacebook.comfacebook.comCloudFlareのようなCDNの設計cmu.eduTwitterのトレンド機能の設計michael-noll.comsnikolov .wordpress.comランダムID発行システムの設計blog.twitter.comgithub.com一定のインターバル時間での上位k件を返すucsb.eduwpi.edu複数のデータセンターからデータを配信するサービスの設計highscalability.comオンラインの複数プレイヤーカードゲームの設計indieflashblog.combuildnewgames.comガーベッジコレクションシステムの設計stuffwithstuff.comwashington.eduシステム設計例題を追加するContribute実世界のアーキテクチャ世の中のシステムがどのように設計されているかについての記事      Source: Twitter timelines at scale以下の記事の重箱の隅をつつくような細かい詳細にこだわらないこと。むしろ共通の原理、技術、パターンを探ることそれぞれのコンポーネントでどんな問題が解決され、コンポーネントはどこでうまく使えもしくは使えないかを知ること学んだことを復習すること種類システム参考ページデータ処理MapReduce - Googleの分散データ処理システムresearch.google.comデータ処理Spark - Databricksの分散データ処理システムslideshare.netデータ処理Storm - Twitterの分散データ処理システムslideshare.netデータストアBigtable - Googleのカラム指向分散データベースharvard.eduデータストアHBase - Bigtableのオープンソース実装slideshare.netデータストアCassandra - Facebookのカラム指向分散データベースslideshare.netデータストアDynamoDB - Amazonのドキュメント指向分散データベースharvard.eduデータストアMongoDB - ドキュメント指向分散データベースslideshare.netデータストアSpanner - Googleのグローバル分散データベースresearch.google.comデータストアMemcached - 分散メモリーキャッシングシステムslideshare.netデータストアRedis - 永続性とバリュータイプを兼ね備えた分散メモリーキャッシングシステムslideshare.netファイルシステムGoogle File System (GFS) - 分散ファイルシステムresearch.google.comファイルシステムHadoop File System (HDFS) - GFSのオープンソース実装apache.orgMiscChubby - 疎結合の分散システムをロックするGoogleのサービスresearch.google.comMiscDapper - 分散システムを追跡するインフラresearch.google.comMiscKafka - LinkedInによるPub/subメッセージキューslideshare.netMiscZookeeper - 同期を可能にする中央集権インフラとサービスslideshare.netアーキテクチャを追加するContribute各企業のアーキテクチャ企業参考ページAmazonAmazon architectureCinchcastProducing 1,500 hours of audio every dayDataSiftRealtime datamining At 120,000 tweets per secondDropBoxHow we've scaled DropboxESPNOperating At 100,000 duh nuh nuhs per secondGoogleGoogle architectureInstagram14 million users, terabytes of photosWhat powers InstagramJustin.tvJustin.Tv's live video broadcasting architectureFacebookScaling memcached at FacebookTAO: Facebook’s distributed data store for the social graphFacebook’s photo storageFlickrFlickr architectureMailboxFrom 0 to one million users in 6 weeksPinterestFrom 0 To 10s of billions of page views a month18 million visitors, 10x growth, 12 employeesPlayfish50 million monthly users and growingPlentyOfFishPlentyOfFish architectureSalesforceHow they handle 1.3 billion transactions a dayStack OverflowStack Overflow architectureTripAdvisor40M visitors, 200M dynamic page views, 30TB dataTumblr15 billion page views a monthTwitterMaking Twitter 10000 percent fasterStoring 250 million tweets a day using MySQL150M active users, 300K QPS, a 22 MB/S firehoseTimelines at scaleBig and small data at TwitterOperations at Twitter: scaling beyond 100 million usersUberHow Uber scales their real-time market platformWhatsAppThe WhatsApp architecture Facebook bought for $19 billionYouTubeYouTube scalabilityYouTube architecture企業のエンジニアブログ面接を受ける企業のアーキテクチャ投げられる質問は同じ分野から来ることもあるでしょうAirbnb EngineeringAtlassian DevelopersAutodesk EngineeringAWS BlogBitly Engineering BlogBox BlogsCloudera Developer BlogDropbox Tech BlogEngineering at QuoraEbay Tech BlogEvernote Tech BlogEtsy Code as CraftFacebook EngineeringFlickr CodeFoursquare Engineering BlogGitHub Engineering BlogGoogle Research BlogGroupon Engineering BlogHeroku Engineering BlogHubspot Engineering BlogHigh ScalabilityInstagram EngineeringIntel Software BlogJane Street Tech BlogLinkedIn EngineeringMicrosoft EngineeringMicrosoft Python EngineeringNetflix Tech BlogPaypal Developer BlogPinterest Engineering BlogQuora EngineeringReddit BlogSalesforce Engineering BlogSlack Engineering BlogSpotify LabsTwilio Engineering BlogTwitter EngineeringUber Engineering BlogYahoo Engineering BlogYelp Engineering BlogZynga Engineering Blogその他の参考資料、ページ:kilimchoi/engineering-blogsここにあるリストは比較的小規模なものにとどめ、kilimchoi/engineering-blogsにより詳細に記すことで重複しないようにしておくことにする。エンジニアブログへのリンクを追加する場合はここではなく、engineering-blogsレボジトリに追加することを検討してください。進行中の作業セクションの追加や、進行中の作業を手伝っていただける場合はこちら!MapReduceによる分散コンピューティングConsistent hashingScatter gatherContributeクレジットクレジット及び、参照ページは適時このリポジトリ内に記載してありますSpecial thanks to:Hired in techCracking the coding interviewHigh scalabilitycheckcheckzz/system-design-interviewshashank88/system_designmmcgrana/services-engineeringSystem design cheat sheetA distributed systems reading listCracking the system design interviewContact infoFeel free to contact me to discuss any issues, questions, or comments.My contact info can be found on my GitHub page.LicenseI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2017 Donne MartinCreative Commons Attribution 4.0 International License (CC BY 4.0)http://creativecommons.org/licenses/by/4.0/"
41,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        简体中文 |        繁體中文 |        한국어 |        Español |        日本語 |        हिन्दी        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    🤗 Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:📝 Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.🖼️ Images, for tasks like image classification, object detection, and segmentation.🗣️ Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.🤗 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install 🤗 Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, 🤗 Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.🤗 Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by 🤗 Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: 🤗 Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from École polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Suárez*, Yoann Dupont, Laurent Romary, Éric Villemonte de la Clergerie, Djamé Seddah and Benoît Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of Göttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo Lüddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Hervé Jégou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp Krähenbühl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Hervé Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by René Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre Défossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, Loïc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Benoît Crabbé, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey Öhman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo García del Río, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Hervé Jégou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by Jörg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre Défossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noah’s Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.Nyströmformer (from the University of Wisconsin - Madison) released with the paper Nyströmformer: A Nyström-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier Hénaff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, João Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, Łukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Dollár.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault Févry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of Würzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, Paweł Krzysztof Nowak, Thomas Müller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Lučić, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper ​XLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the 🤗 Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by 🤗 TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by 🤗 Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the 🤗 Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
42,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answers⚠️ DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]🙏 PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!🎉 AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.❓ Need help?Open new issue🔥 Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accounting❗needs updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustrator❗needs updating  7674Adobe-InDesign❗needs updating  4240Adobe-Lightroom❗needs updating  2020Adobe-Photoshop❗needs updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effects❗needs updating  2413Agile Methodologies❗needs updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCAD❗needs updating  7775@djayorAutodesk Fusion 360❗needs updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambda❗needs updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++❗needs updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurity❗needs updating10196Django7171@PROCW.NET Framework6359@declarckEclipse❗needs updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSON❗needs updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excel❗needs updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Project❗needs updating4443Microsoft Word❗needs updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooks❗needs updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revit❗needs updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePoint❗needs updating5338Sketchup22SOLIDWORKS❗needs updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnity❗needs updating4746@uno-sebastianVisual Basic for Applications (VBA)❗needs updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors ✨Thanks goes to these wonderful people (emoji key):            Evgenii💻 🖋      Sergei Stadnik💻 🔍 🤔 📖      Santhosh💻      Jacob Dsa💻 🖋      Aaron Meese💻 🖋      arqarq💻 🖋      Amit Yadav💻 🖋              Javokhir Nazarov💻 🖋      saurav kumar🖋      Chetan🖋      Amir Hossein Shekari🎨 🖋 💻      SergDaut🎨      Nilotpal Pramanik🎨 💻 🖋 💼 📖 🔣 💡      Abhishek Kumar🎨              Monu Gupta🎨      KARTIKEYA GUPTA💻 🖋      kenkyusha💻 🖋      juandavidtowers💻 🖋      cyber-netics💻 🖋      jtrisw💻 🖋      Renato Regalado💻 🖋              Matthew💻 🖋      Jan S.💻 🖋      Manoli💻 🖋      Faraz tanveer💻 🖋      mohnishkarri💻 🖋 🎨      andyzhu💻 🖋      Vishal Kushwah💻 🖋              Yurii Yakymenko💻 🖋      Swetabh Suman💻 🖋      AJAY DANDGE💻 🖋      Mehmet Yesin🎨      Lok Chun Wai🎨      Adria de Juan🎨      GL-Man🎨              Jheel Patel🎨      Sameer Waskar🎨      Alexander Andrews🎨      Alexander Maxwell🎨      Slava🎨      Mayur Khatri🎨      Mascantosh💻 🖋 📢 🤔              Kivanc Enes🎨      Ritika Das🎨      Zer07793🎨      Andrew Cheung🎨      Sadha🎨      tainenko🎨 💻      github-star-coder🎨              Danilo Oliveira🎨      lordeko🎨      Shubham Kumar🎨 💻      testtree🎨      Cheryl Murphy🎨 💻      Bipin Thomas🎨      Abdulrahman Hisham🎨              Dakshitha Dissanayaka🎨      BADR KACIMI🎨      Alex Wang🎨      Maxim🎨      GordonGrant🎨 💻      Ephrem Demelash🎨      JonOrcutt🎨              topdev10🎨      cookwellwebsite🎨      xren935🎨      Nemo Frenkel🎨      MD SAIF ALAM🎨      Boris López Araya🎨      Larry Chiem🎨              Muhammad Bilal Ilyas🎨      AliMilani🎨 💻      Suraj Sahani🎨      FlyingSquirrel🎨      Erick Tijero🎨      Jaskaran Kukreja🎨      MichaelL🎨              MagicLegend🎨      Dereck Bearsong🎨      Pappu Kumar Pashi🎨      Venkata Kishore Tavva🎨      Rafat Touqir Rafsun🎨      Snehesh Dutta🎨      Timo Körner🎨 💻              alexxxan🎨      GGJason🎨      LeeAnna Ewing🎨 🤔      kamal Jyotwal🎨      Bob-Johns🎨 💻 🖋      yunussalmanlyit🎨 💻      chilcot🎨 💻              Jacky Li💻 🖋 🎨      Sarthak Trivedi🎨      Ayush Aggarwal🎨 💻      Nic Ballarini🎨      Luigi Zambetti🎨 💻      govindhaswin🎨      Addy Roy💻 🎨              Akshat Tamrakar🎨 💻      Sai Bhargava Ramu🎨      Gurkan💻      Spencer Hayes-Laverdiere💻      Aniket Soni💻      tanmay5792💻      Dina Taklit💻 🎨 🖋              Dushyant Singh💻      Ravi Prakash Singh💻      Nihal Joshi💻      Guy Klages💻      Arvind🎨 💻      mujeeb91💻      joserca🎨 💻              Prateek Agrawal💻      Teoh Tze Chuin(サラ)💻 🎨      Jayant Jain💻      Ayush Sahu💻      Hridya Krishna R💻 🎨      Rahul Bali💻 🎨      S.ZHeng🎨 💻 💼              Shriya Madan🎨 💻      mahalrupi🎨      Lucas Lermagne🎨      Jeff Deutsch🎨 💻      Betoxx1🎨      Wingman4l7🎨      Martin Espericueta🎨              Mh-Tahir🎨      Zdravko Šplajt🎨 💻      Ms3105🎨 💻 🖋      Ambika Sidhesware💻      mundoguero💻      Darkus24🖋      Sou-786🖋 🎨              Banurekha🖋      ShiraStarL🎨      Ilya Komarov🎨      DemigodMs🖋 📖      Mekha Hridya🎨 🔍      Andrey Safonov🎨 🔍      Tommaso🎨 💻              Jessica Salbert💻 🎨      JAYANTH DOLAI💻 🎨      silverstroom💻 🎨 💼      Furkan Sayım💻 🎨      Sukumar Chandrasekaran🎨      Yejin Park🎨 💻      Ali Nooshabadi🎨 💻              imitavor🎨 💻      Salih Kilicli🎨 💻      Marcelo Meneses🎨 💻      Anton Krekotun🎨 🚧 🖋 💻 📖 💼      Arnav Sarma💻 💡 🎨      meghatiku💻 🎨      Anshu Trivedi🎨              Taylor Dorsett💻 🖋 🎨      Havit Rovik💻      pushpapune💻 🎨      Ramtin Radfar🎨 🤔 💼 💵 💻 🖋 💬      Abdulmajeed Isa💻 🎨      vikassaxena02🎨      RobTables🎨 💻 💼              Daniel🎨 💻 💼 🔍      Zahid Ali💻 🎨      Chad Chai💻 🎨      Marco Biedermann💻 🎨 💼 🤔      Srinidhi Murthy🎨      Miao Cai💻 🎨      Dionicio Diaz🎨 💻              Mir Monoarul Alam🎨      Shawn Ohn💻 🎨      Amanbolat Balabekov🎨 💻      black-mamba-code💻      Jian-forks🎨 💻      shivani patel🎨      Akash Chowrasia🎨              yairg98🎨      Jay Gajjar🎨      coolerbooler💻      Md Zinnatul Islam Morol🎨      shresthashok550🎨 📖      Alan Pallath📖      Adrian Wong💻              vsDizzy💻 🎨      Frex Cuadillera🎨 💻      ashish570💻 🎨      ruchpeanuts💻 🎨      Artmasque🎨 💻      Amirhossein Mojiri Foroushani🎨      for💻 🎨              Luke🎨 💻      Hector Espinoza🎨      Adrián Buenfil🎨 💻      Amit Kumar🎨      schoppfe🎨 💻      Sofiyal C🎨 💻      spitlisk💻 🎨              PRAVIN SHARMA🎨      NIDZAAA1🎨 💻      John Mai🎨 💻      kimsoyeong🎨      Dona Ghosh💻      Ryan Hill🎨 💻      j42z🎨 💻              Ashish Sangale🎨 💻      Derek Yang🎨 💻      mohsinmsm🎨 💻      Gokulkrish2302💻      Bhaavishek💻 🎨      Louis Liao🎨      sengc92🎨 💻              Alex Marvin🎨      Balkrishna Bhatt🎨 💻      Evaldas Lavrinovičius🎨 💻      Adam Erchegyi🎨 💻      Truman Hung🎨 💻      rzamora11🎨      gaurav0224🎨              Lee GyeongJun🎨      Mirek🎨 💻      surajm245🎨      ArisLaode🎨 💻      RaviDhoriya🎨 💻      sarai-84🎨 💻      Vishnu🎨 💻              Muhammad Minhaj💻      Chandrika Deb🎨 💻      Gitgit101-bit💻 🎨      Hedi Sellami💻 🎨      saurabhvaish93💻 🎨      Nikola Begovic💻 🎨      Wang💻 🎨              Manuel Eusebio de Paz Carmona🎨      Basim Al-Jawahery🎨 💻      RAJA AHMED🎨 💻      Abhik Lodh💻      Md. Pial Ahamed💻 🎨      Hassan Shahzad💻 🎨      Christian Sosa Gago💻              Hasnain Rasheed💻 🎨      T-Radford💻      dahiyashish💻 🎨      RahulSharma468💻 🎨      Jumpod Plekhongthu💻 🎨      Thomas Young-Audet💻 🎨      VinayagamBabu💻 🎨              Deniz Koç💻 🎨      Azhar Khan💻 🎨 🖋 📖 🔣 🚧      Jacob Short💻 🎨      Uchimura85💻 🎨      Leo Nugraha💻 🎨 📖      Mujtaba Mehdi📖 🖋      Jim-ds💻 🎨              Sreehari K💻 🎨      Florian Martinez💻 🎨      Aaron💻 🎨      apoage🎨      Ignacio Guillermo Martinez 💻 🎨      AirlineDog🎨 💻      Mekel🎨 💻              hmosharrof🎨 💻      Ben Emamian💻 🎨      babeshark💻 🎨      Leonardo Jaques💻 🎨      Stefanos Apkarian💻 🎨      Ayhan Albayrak💻 🎨      KidusMT💻 🎨              hectormarroquin20💻 🎨      Edelweiss35💻 🎨      MihaiD💻 🎨      AnveshReddyAnnem💻 🎨      Hyunjae Park💻 🎨      Rajiv Albino💻 🎨      Atishay💻              Yusuf Naheem🎨      Windu🎨 💻      Superv1sor💻 🎨      Karine (:🎨 💻      Eduard Pech🎨 💻      jjeshwani🎨 💻      Steve🎨 💻              Aleigh Ohslund💻      Abhinav Suman🎨 💻      Hamza Ehtesham Farooq🎨 💻      IamNotPeterPan💻 💵 🎨      Cetger🎨      pkonopacki🎨      Yang Yang🎨 💻              Muhammad Shoaib Sarwar💻      Murilo Henrique💻 🎨      emilianoalvz🎨 💻      Sumana Saha🎨 💻      Yurii17K🎨 💻      Rupesh Bhandari🎨 💻      salmos3718💻              John Baker🎨 💻      SanjaySathiraju🎨 💻      Donat Kabashi🎨      Arul Prasad J🎨 💻      Qi Chen🎨 💻      Maksym Dmyterko🎨 💻      ilovepullrequests💻              Samira Maleki🎨 💻      NIKITA MAHOVIYA💻      jesuisdev.Net🎨 💻      Ashraf Nazar🎨      Naveed Ahmad🎨      Ajmain Naqib🎨 💻      Avinash Tingre💻 🎨              nicktids🎨      Keith Dinh💻 🎨      André Ferreira💻 🎨      eliottkespi💻 🎨      praveenpno💻 🎨      vitowidigdo💻 🎨      Devesh Pratap Singh💻 🎨              Dario Rodriguez💻 🎨      charmander_didi💻 🎨      PHBasin💻 🎨      Ritvik Singh Chauhan💻 🎨      Riya P Mathew💻 🎨      Stephanie Cherubin💻 🎨      BenitesGui💻 🎨              FarikBear💻 🎨      Dmytro Havrilov💻 🎨      Parvesh Monu💻 🎨      Dipen Panchasara💻 🎨      gudata🎨 💻      gawadeditor💻 🎨      Kirill Taletski🎨 💻              Saajan🎨 💻      Kushagra S🎨 💻      Oanh Le🎨 💻      Frane Medvidović🎨 💻      Yorman🎨 💻      Bill Chan🎨 💻      Pratik Lomte🎨 💻              LOC LAM🎨 💻      TUSAR RANJAN MAHAPATRA💻      BhargavKanjarla💻      Karel De Smet💻 🎨      sidisan🎨      ygnzayarphyo🎨 💻      svansteelandt💻              Kebechet🎨      Daniel Selvan D🎨 💻      Mahdi Razavi🎨 💻      Niklas Tiede💻 🎨      narutubaderddin💻 🎨      dylandhood💻      Dheeraj Gupta💻              Pieter Claerhout💻 🎨      Shivam Agnihotri💻      RanjithReddy-Narra💻      Nikita Wadhwani🎨 💻      rsholokh💻 🎨      Ayaan Hossain💻 🎨      Rajesh Swarna💻              Deniz Etkar🎨 💻      pro335💻 🎨      Jakub Radzik💻 🎨      Hamza Khanzada💻      ARNON🎨      Vikram Singh💻      Shoxruxbek💻 🎨              Amit Khatri💻 🎨      Wali Ullah🎨 💻      Amit11794💻 🎨      metis-macys-66898💻 🎨      Faisal Maqbool🎨 💻      Kumar Neeraj💻 🎨      Maurizio Marini🎨 💻              Saket Kothari🎨 💻      Szymon Zborowski🎨 💻      iks3000🎨 💻      Ehsan Seyedi🎨 💻      vanekbr🎨 💻      Princy_M🎨 💻      Shijie Zhou🎨 💻              lakshyamcs16🎨 💻      Filippo Facco🎨 💻      mendel5🎨 💻      Patryk🎨 💻      VishwaSangani🎨 💻      Alvin Zhao🎨 💻      Lazar Gugleta🎨 💻              vmicho🎨 💻      Sikandar Ali🎨 💻      Raja Babu🎨 💻      faizajahanzeb💻      Guil_AiT🎨 💻      Kushal Das🎨 💻      Luis Bonilla🎨 💻              jovan1013🎨 💻      Damian🎨 💻      Yash Gupta💻      lolcatnip🎨 💻      Ikko Ashimine🎨 💻      Farukh🎨 💻      Moksedul💻 🎨              Navneet Kumar🎨 💻      Saqib AlMalik💻      fahimrahman🎨 💻      vaibhav patil🎨 💻      Rahul Madan🎨 💻      kartik Kaklotar🎨 💻      ASAHI OCEAN🎨 💻              Daniel Jungbluth🎨 💻      Rajdeep Singh Borana🎨 💻      ankitha19💻      Linh Tran💻      islamarr💻 🎨      Mohamed Sabith🎨 💻      Miguel Angel Cruz Acosta🎨 💻              Adebayo Ilerioluwa 🎨      Markus🎨 💻      dkonyayev🎨 💻      Kevin A Mathew🎨 💻      David Melo🎨 🔣      DFW1N🎨 💻      Sohaib Ayub🎨 💻              Navvy🎨 💻      bloodiator2🎨 💻      Hanji🎨 💻      arthur74🎨 💻      Sri Subathra Devi B🎨 💻      Akif Aydogmus🎨 💻      Umer Javaid🎨 💻              Norio Umata🎨 💻      Gazi Hasan Rahman🎨 💻      Keith Nguyen🎨 💻      Megalomaniac🎨 💻      ShankS3🎨 💻      Farhad Alishov🎨 💻      Ronak J Vanpariya🎨 💻              azrael0learza🎨 💻      Pavel Rahman🎨 💻      chuabern🎨 💻      Rahul Tirkey🎨 💻      Ruslan Bes🎨 💻 💡 🚧 🖋 🔣 🚇      Bohdan🎨 💻      Juzdzewski🎨 💻              Grigor Minasyan🎨 💻      alvintwc🎨 💻      Anand Natarajan🎨 💻      Kashan Ali🎨 💻      Thomas Meshail🎨 💻      Son Pham🎨      Michael French💡              Yash Mishra📖      Miguel Rodriguez🎨 💻      Philipp Bachmann🎨 💻      sunny🎨 💻      Siddharth Chatterjee🎨 💻      Michael Naghavipour🎨 💻      Sahil Garg🎨 💻              MicroLion🎨 💻      wctwc🎨 💻      Rohan Sharma🔣      AshishBodla🎨 💻      Taras Pysarskyi🎨 💻      Luqman Bello O.🎨 💻      DyingDown🎨 💻              Diego Chapedelaine🎨 💻      Richlee🎨 💻      Asif Habib🎨 💻      Mazharul Hossain🎨 💻      toni🎨 💻      Pragyanshu Rai🎨 💻      Matthew Eller🎨 💻              AbhiBiju🎨 💻      Roman Zhornytskiy🎨 💻      Lucas Camino🎨 💻      João Vitor Casarin🎨 💻      Evgeniy Shay🎨 💻      Ehsan Barkhordar🎨 💻      Gabriel🎨 💻              Shibu Mohapatra🎨 💻      Pavel Kirkovsky🎨 💻      Tahir Gul🎨 💻      imDevSalman🎨 💻      Jordan Donaldson🎨 💻      js-venus🎨 💻      Faisal Shaikh🎨 💻              ashishbpatil🎨 💻      Tri Le🎨 💻      tomtreffke🎨 💻      Salah Eddine Lalami🎨 💻      Mattias Xu🎨 💻      Manas Gupta🎨 💻      wolfsong62🎨 💻              Mehdi Mirzaei🎨 💻      Van Ba Khanh🎨 💻      Sel Embee🎨 💻      Suvradip Paul🎨 💻      Sharique🎨      Seabass🎨 💻      Penny Liu🎨 💻              jatinder bhola🎨 💻      misterqbit🎨 💻      Daniel-VS9🎨 💻      Shruthi🎨 💻      beefydog🎨 💻      Suraj Kumar🎨 💻      hrishikeshps🎨 💻              Sudarshan🎨 💻      Divyansh💻 🎨      Zyaire🎨 💻      Omar Belkady🎨 💻      alexiismua🎨 💻      Eduarda Alves🎨      pycoach🎨 💻              Ruhul🎨 💻      pmoustopoulos🎨 💻      Lee Hui Ting💻 🎨      bodi1981🎨 💻      Devaraat Joshi🎨 💻      Johnny🎨 💻      rogue-coder🎨 💻              viiktr🎨      Lalit Mohan💻      João Sousa💻      言葉之靈💻 🎨      RJLABS💻      brittney0522🎨 💻      sham🎨 💻              Glenn Goossens💻 🎨      Cyber Hawk🎨 💻 🖋 💼      Ankit Yadav🎨 💻      verbality💻      Mohammed Siddiqui🎨 💻      AdamKaczor6250🎨 💻      Ramón Martinez Nieto🎨 💻              Grzegorz Dziubak🎨 💻      Ayoub BERDEDDOUCH🎨 💻      nikola-fadv🎨 💻      Akarsh Agrawal🎨 💻      Mitra Mirshafiee🎨 💻      Parker Stephens🎨 💻      alrenee99💻              Karthick Vankayala💻      Iryna 🎨 💻      palanugrah💻      Gwinbleind🎨 💻      Randy Bobandy🎨 💻      Bek Rozikoff💻      davnguye🎨 💻              Neel Patel💻      ehudbehar🎨 💻      nicholas-cod3r🎨 💻      michaelfranki🎨      Esther White🎨 💻      prathmeshpb🎨 💻      Victor Lin🎨 💻              Christine C. Yin🎨 💻      GitLearner-begin🎨 💻      Mesrop Andreasyan🎨 💻      Nathan Garcia🎨      commonsw04🎨 💻      Md. Rashad Tanjim🎨 💻      Ali Malek💻              PAODLT🎨 💻      Nikhil Bobade🎨 💻      hyuckjin21💻      Itasha Modi🎨 💻      Nikitha Reddy🎨 💻      Mahshooq Zubair🎨 💻      Subham Das💻              Onkar Birajdar🎨 💻      Nick Titomichelakis🎨 💻      Christian Leo-Pernold🎨      Matthew Marquise🎨 💻      baronfac🎨 💻      Abhishek Tilwar🎨 💻      DavidsDvm🎨 💻              Parth Parikh🎨 💻      Hector Castro🎨 💻      Rikky Arisendi🎨 💻      Ali HamXa🎨 💻      Frank.wu🎨 💻      Jatin Kumar🎨 💻 📖      masterHAWK99🎨 💻              Pushp Jain🎨 💻      Ashutosh Rout🎨 💻      Atharva Deshpande🎨 💻      Teodor Ciripescu🎨 💻      Anmol Bansal🎨 💻      Nikhil Kumar Macharla🎨 💻      Dexter🎨 💻              Aaron🎨 💻      Yogita Jaswani🎨 💻 📖 🖋      StoryDev🎨 💻      Mesut Doğansoy🎨 💻      Paras Dhawan🎨 💻      Emanuel Zhupa🎨 💻      Aaradhyaa717🎨 💻              jaacko-torus🎨 💻      mBlack💻      kalrayashwin📖 🖋 🎨 💻      Seraph💻 🎨      ZhiHong Chua🎨 💻      Amsal Khan🎨 💻 📖 🖋      Raghav Rastogi🎨 💻              Tzila📖      Shahriar Nasim Nafi📖      AG🎨 💻      Mojtaba Kamyabi🎨 💻      Ahmad Abdulrahman🎨 💻      Eclipse🎨 💻      Anshu Pal🎨 💻              Denis🎨 💻      mehmet sayin📖      WebDEV🎨 💻      Sam Komesarook🎨 💻      Kiran Ghimire🎨 💻      Joshua Davis🎨 💻      Muhammad-Huzaifa-Siddiqui💻              tobeornottobeadev🎨 💻      VAIBHAV SINGHAL🎨 💻      Keiran Pillman🎨 💻      Max Donchenko🎨 💻      sgonsal🎨 💻      diksha137🎨 💻      Vignesh🎨 💻              Gabriel França🎨 💻      Joseph🎨 💻      Bruno Rafael🎨 💻      vcamarre🎨 💻      thibault ketterer🎨 💻 🚧      VictorGonzalezToledo🎨 💻      1911510996🎨 💻              invidu🎨 💻      Nurul Furqon🎨 💻      David Asbill🎨 💻      Niko Birbilis🎨 💻      Mugundan Kottursuresh🎨      agrsachin81🎨 💻      Othmane El Alami🎨 💻              Syed Atif Ali🎨 💻      lakhanjindam🎨 💻      youssef hamdane🎨 💻      starfaerie🎨 💻      rodrigo0107🎨 💻      Michał Gralak🎨 💻      Jewel Mahmud🎨 💻              cwilson830🎨 💻      buun1030🎨 💻      Reda-ELOUAHABI🎨 💻      saad-aksa🎨 💻      Emdadul Haque🎨 💻      PROCW🎨 💻      cccppp1🎨 💻              Joanna Baile🎨 💻      Ahmed Saber🎨 💻      Masoud Keshavarz🎨 💻      mortazavian🎨 💻      Aniket Pandey🎨 💻      Vijay Nirmal🎨 💻      Daniel Carvallo💻              menaechmi🎨 💻      azenyx🎨 💻      Ahmet Özrahat🎨 💻      Abdulrahman Abouzaid🎨 💻      jmgnorbec🎨 💻      palinko91🎨 💻      Laisson R. Silveira🎨 💻              BHARGAVPATEL1244🎨 💻      Candide U🎨 💻      Sitansh Rajput🎨 💻      Houda Mouttalib🎨 💻      MumuTW🎨 💻      Suave Bajaj🎨 💻      Mehdi Parsaei🎨 💻              Dinko Osrecki🎨 💻      Dhia Djobbi🎨 💻      Mahmoud Galal🎨 💻      Anh Minh🎨 💻      Suvesh K🎨 💻      Petar Todorov🎨 💻      Alexander Nguyen🎨 💻              Morteza Jalalvand🎨 💻      Claudson Martins🎨 💻      Matt Jacobson🎨 💻      Rafael Belokurows🎨 💻       Thomas Gamauf🎨 💻      Rishabh Mahajan🎨 💻      rakeshpdgupta23🎨 💻              Shashidharknaik🎨 💻      taleleuma🎨 💻      Florian Bühler🎨 💻      Raihan Bin Wahid🎨 💻      MOHAMMED NASSER🎨 💻      federico🎨 💻      Andre Violante🎨 💻              tcunningham98🎨 💻      Jan Grießer🎨 💻      Serkan Alc🎨 💻 🖋      Jez McKean🎨 💻      meisam alifallahi🎨 💻      Mehul Thakkar🎨 💻      Saksham Soni🎨 💻              Pedro Peregrina🎨 💻      Mintu Choudhary🎨 💻      lucianmoldovanu🎨 💻      John C. Scott🎨 💻      Mia D.🎨 💻      EwenBernard🎨 💻      M. Reza Nasirloo🎨 💻              Jay Agrawal🎨 💻      DeShay🎨 💻      Jay206-Programmer🎨 💻      Elender🎨 💻 🖋      Bobby Byrne🎨 💻      Pirci🎨 💻      Hasanuzzaman🎨 💻              Josh Kautz🎨 💻      Brofar🎨 💻      Mina Karam🎨 💻      Duncan O N🎨 💻      Sean Tumulak-Nguyen🎨 💻      Artur Trześniewski🎨 💻      JJaammeessM🎨 💻              shubham agarwal🎨 💻      Michele Righi🎨 💻      Panagiotis Kontos🎨 💻      sumitbathla🎨 💻      Deepak Mathur🎨 💻      Juho Nykänen🎨 💻      Santiago González Siordia🎨 💻              SRIJITA MALLICK🎨 💻      Samriddhi B🎨 💻      Nitzan Papini🎨 💻      Mario Sanz🎨 💻      Crab^4🎨 💻      Pablo🎨 💻      Gordon Pham-Nguyen🎨 💻              Kristoffer🎨 💻      chrisblach🎨 💻      Gábor🎨 💻      Lina🎨 💻      Harrison Watts🎨 💻      Mario Petričko🎨 💻      Ben8120🎨 💻              Giovanna🎨 💻      Minal Ahuja🎨 💻      mossfarmer🎨 💻      ThaC0derDre🎨 💻      itware🎨 💻      Michael Walker🎨 💻      Tom Jacob Chirayil🎨 💻              Sachin Kumar🎨 💻      adi-ray🎨 💻      Dr-Blank-alt🎨 💻      Bogdan Cazacu🎨 💻      Gilson Urbano🎨 💻      Nina🎨 💻      Anthony🎨 💻              manushimjani🎨 💻      Michael Reyes🎨 💻      Rachel Kennelly🎨 💻      Aakash Garg🎨 💻      Daniel Livingston🎨 💻      alexrojco🎨 💻      Minh Nguyen🎨 💻              Mahesh Dattatraya Babar🎨 💻      Jin Zihang🎨 💻      Bikramjit Ganguly🎨 💻      QuestionableGuise🎨 💻      liq19ch🎨 💻      Bruno Rocha🎨 💻      Anand Dyavanapalli💻 🖋              crucian-afk🎨 💻      0xgainz🎨 💻      weirdfsh🎨 💻      Valan Baptist Mathuranayagam🎨 💻      Paul Kaefer🎨 💻      Yu-Hsiang Wang🎨 💻      Javad Adib🎨 💻              davidliu0930🎨 💻      Achilleas John Yfantis🎨 💻      Omkar Shivadekar🎨 💻 🖋 🐛      ToanTran🎨 💻      Gautam Naik🎨 💻      Marc🎨 💻      twix20🎨 💻              Kristian S.🎨 💻      Aleksey Khoroshilov🎨 💻      arjunsrsr🎨 💻      Ali Haider🎨 💻      Trisha Dring🎨 💻      Andre Marzulo🎨 💻      Krishna Modi🎨 💻              Rosemary Li🎨 💻      Alex Weller🎨 💻      Tam Nguyen🎨 💻      aquintelaoliveira🎨 💻      Norbert Brett🎨 💻      rocsogd🎨 💻      0nyr🎨 💻              rethkevin🎨 💻      RickHeadle🎨 💻      Leandre🎨 💻      Natnael Sisay🎨 💻      sbbu🎨 💻      wael🎨 💻      Fabricio Tramontano Pirini🎨 💻              Alexander Stoyanov🎨 💻      Dezx20🎨 💻      southparkkids🎨 💻      bmstar🎨 💻      kiagam🎨 💻      Juan Castillo🎨 💻      FFenne🎨 💻              Jose Toledo🎨 💻      Pat McGhen🎨 💻      Eiko Wagenknecht💻 🖋 🔣      Alan Chalmers🎨 💻      Jean Didier🎨 💻      Andy🎨 💻      pestadieu🎨 💻              Kanishka Chakraborty🎨 💻      Nandha🎨 💻      Vahid Mafi🎨 💻 🔣 🖋 💼      Akshay Ashok🎨 💻      0x08🎨 💻      Sandeep Mishra🎨 💻      Evann Regnault🎨 💻              Lenny Zeitoun🎨 💻      Eden Boaron🎨 💻      TroyBTC🎨 💻      Aby Sebastian🎨 💻      Matthew Dunn🎨 💻      ckullo🎨 💻 🖋 🔣      Mohamed Mamdouh🎨 💻              Youssef Bazina🎨 💻      Frederico Kückelhaus💻      Nushan Kodikara💻      Zach Cooper💻      Roy🎨 💻      Saurav Panchal🎨 💻      totallynotdavid🎨 💻              goosepirate🎨 💻 💡 💼      KAUTH🎨 💻      Hari Kiran Vusirikala🎨 💻      Sounak Dey🎨 💻      zia💼 🎨 💻      Reza Davari🎨 💻      AkshayAjaykumar🎨 💻              x24870🎨 💻      Ko Phone🎨 💻      Nabstar3🎨 💻      Mateusz🎨 💻      Yunus Emre Emik💻      Abhinav Sinha🎨 💻      Hung Nguyen🎨 💻              Maselino💻      Shuktika Mahanty💻      Mikołaj Gawroński🎨 💻      Hussein Habibi Juybari🎨 💻      Sean-McArthur🎨 💻      Osman F Bayram🎨 💻      Benjamin Thomas Blodgett🎨 💻              Chuanlong-Zang🎨 💻      julian🎨 💻      francisco🎨 💻      aalihhiader9211🎨 💻      Muhammad Zunair🎨 💻      Liya🎨 💻      BegadTarek🎨 💻              etorobot🎨 💻      Hussam Khan🎨 💻      Saikat Chakraborty🎨 💻      Nicholas Quisler🎨 💻      Evang Poul🎨 💻      Gregg Lind🎨 💻      Deepak Kumar🎨 💻              Callum Leslie🎨 💻      Curtis Barnard Jr.🎨 💻      Deepanshukaim🎨 💻      Manthan Ank🎨 💻      hossein varmazyar🎨 💻      Brayan Muñoz V.🎨 💻      Kamil Rasheed Siddiqui💻 🎨              mutt0-ds🎨 💻      egbertjk🎨 💻      Majid Zojaji🎨 💻      Sean Chen🎨 💻      Herbert Milhomme🎨 💻      A3🎨 💻      Killian🎨 💻              Coakeow🎨 💻      ྅༻ Ǭɀħ ༄༆ཉ🎨 💻      Pratik Solanki🎨 💻      Sunny🎨 💻      ssge🎨 💻      Bernat Frangi🎨 💻      Jeevan Rupacha🎨 💻              amirandap🎨 💻      Deepakshi Mittal🎨 💻      Abhijeet Parida🎨 💻      Khaled Riyad🎨 💻      Pratap parui🎨 💻      Prajit Panday🎨 💻      PipeSierra🎨 💻              Collins Oden🎨 💻      Kshitij Dwivedi🎨 💻      Bernardia Vitri Arumsari🎨 💻      Ömer Faruk Taşdemir🎨 💻      Spencer Stith🎨 💻      Porsche Rodjanasak🎨 💻      Shakeel Sharif🎨 💻              Victoria Cheng🎨 💻      Denis🎨 💻      Anand Prakash Tiwari🎨 💻      danijeljw-rpc🎨 💻      Ahmed H Ebrahim🎨 💻      Virginia Gardner🎨 💻      Jhironsel Diaz A.🎨 💻              Yunus Kidem🎨 💻      MT🎨 💻      Dinesh Zaldekar🎨 💻      adi🎨 💻      Farhan Shaikh🎨 💻      Elvis Salvatierra🎨 💻      Kaushik-Iyer🎨 💻              HocAndres🎨 💻      VictorHugoAguilarAguilar🎨 💻      Murat Can Abay🎨 💻      Chris🎨 💻      Shivam7-1🎨 💻      Paipai13🎨 💻      Shambles-io🎨 💻              Abhishek K M🎨 💻      Ezequiel Cuevas🎨 💻      Plamen Ivanov🎨 💻      Yuji🎨 💻      Jean-Philippe Lebœuf🎨 💻 🔣      Naufan🎨 💻      jadnov🎨 💻              vaxtangens🎨 💻      subashkonar13🎨 💻      Rushi Javiya🎨 💻      Mert Gül🎨 💻      Lily🎨 💻      Kalinoff🎨 💻      Joel Tony🎨 💻              Peter🎨 💻      Roozbeh Zarei🎨 💻      Shen🎨 💻      Joonsoo.LEE🎨 💻      Fede.Breg🎨 💻      Rui Costa🎨 💻      João Gustavo Bispo🎨 💻              Sami-I🎨 💻      Tsvetoslav Tsvetkov🎨 💻      Olabode Olaniyi David🎨 💻      theRuslan🎨 💻      leighboz🎨 💻      Frank Sossi🎨 💻      Tomasz Adamski🎨 💻              Mansoor M. Sathir🎨 💻      Golamrabbi Azad🎨 💻      Nahian Ahmed🎨 💻      Rafael de Jesus Silva Monteiro🎨 💻      Odionyebuchukwu Jude🎨 💻      The Nithin Balaji🎨 💻      Knackii🎨 💻              vittorio-giatti🎨 💻      Guilherme de Carvalho Lima Rebouças🎨 💻      aaref shami🎨 💻      Andrey Dryupin🎨 💻      Muhanned Noman🎨 💻      Jan Silva🎨 💻      emanuele-em🎨 💻 🖋              Sanjay TM🎨 💻      Joe Markberg / code editor🎨 💻      Julien Quiaios🎨 💻      Eric Ramirez Santis🎨 💻      M🎨 💻      Malcata🎨 💻      Athul Muralidharan🎨 💻              Dariusz Ochota🎨 💻      CHANDAN CHOUDHURY🎨 💻      Deep🎨 💻      Ahmet İstemihan ÖZTÜRK🎨 💻      TIM🎨 💻      jakeg814🎨 💻      Leonidos🎨 💻              Abhinandu V Nair🎨 💻      charafeddine01🎨 💻      Jasper🎨 💻      Manish Goyal🎨 💻      SATYAM_SINGH🎨 💻      Four🎨 💻      Vaishnavi Amira Yada🎨 💻              ShriKrushna Bhagwat🎨 💻      Rohit Nandagawali🎨 💻      felipe🎨 💻 🚧 🖋 ✅ 🧑‍🏫      Saurabh Mudgal🎨 💻      szenadam🎨 💻      Shubhendra Singh🎨 💻      Yoosuf Sayyid💻 🎨              Güven Çetinerler🎨 💻      Luke Jefferies🎨 💻      Chris🎨 💻      Lúcio Aguiar💻      Enuma029💻      yktsang01💻      maximumn3rd🎨 💻              Jon Galletero🎨 💻      Thaddeus  Thomas🎨 💻      Aakash Kumar💻 🎨      Ali M🎨 💻      OskyEdz🎨 💻      Ravi Gupta🎨 💻      Rafa Raizer🎨 💻              Abdullah Al Muzaki🎨 💻      Rahul Faujdar🎨 💻      Abhishek Verma🎨 💻      Ashutosh Shinde🎨 💻      Ganesh Rai🎨 💻      StefanTrpkovic🎨 💻      Erik Blanca🎨 💻              Vedant Madane🎨 💻      Antra Tripathi🎨 💻      Ethan Knights🎨 💻      Alexandru Boncut🎨 💻      Pablo Bandinopla🎨 💻 🚧 🖋      Robz-99🎨 💻      Harpal Singh🎨 💻              paulboundy99🎨 💻      Mubashir Ahmed🎨 💻      Rohan Hari🎨 💻      Erik Henrique 🎨 💻      Leandro Matheus🎨 💻      Deepak🎨 💻      AlishaSingh🎨 💻              Lynn Latt Yati🎨 💻      San Shwe🎨 💻      SKR🎨 💻      msbunnyjaguar🎨 💻      Mohamad Zabiulla🎨 💻      Hatim Zahid🎨 💻      Rauzan Sumara🎨 💻              Hosein1358🎨 💻      Mohit🎨 💻      Ali🎨 💻      Avinash1765🎨 💻      Sai Teja Madha🎨 💻      Monsur Ahmed Shafiq🎨 💻      xuxianjin-dev🎨 💻              chetna🎨 💻      Gul Zaib🎨 💻      Natalia🎨 💻      Dionísio Braga🎨 💻      Pritish Rajpurohit🎨 💻      incanlove🎨 💻      Innocent🎨 💻              Devin Almonor🎨 💻      antonyveyre🎨 💻      Beltz Anhxton🎨 💻      Mehdi🎨 💻      Muhammad Usman🎨 💻      Patrick Dantas🎨 💻      Tak Vannak🎨 💻              Ramzi RADDAOUI🎨 💻      Konstantin-Glukhov🎨 💻      uguroban🎨 💻      Humberto Alves🎨 💻      JuangZendrato🎨 💻      James Oluwaleye🎨 💻      Wasi Sadman🎨 💻              Pavle Mijatovic🎨 💻      Luiz H. S. Bispo🎨 💻      Сухас Дхолз🎨 💻      Alvaro Trujillo🎨 💻      Everton 🎨 💻      jfrozas🎨 💻      Shuaaib Badran🎨 💻              Shivam Jha🎨 💻      Mohamed Tayeh🎨 💻      Makendran G🎨 💻      mayank singh tomar🎨 💻      hossam sadany🎨 💻      Harshbardhan Singh💻 🎨      Fawad Jawaid Malik🎨 💻              Tina Lacatis🎨 💻      TeddyCuoreDolce🎨 💻      bchooxg🎨 💻      Alisha Takkar🎨 💻      Gianluigi🎨 💻      Mehran Javaherian🎨 💻      Benjamin Ololade Adedokun🎨 💻              Md. Abdul Mutalib🎨 💻      Aadil Arsh.S.R🎨 💻      J. Nathan Allen🎨 💻      Kieran Krug🎨 💻      Seth Addo🎨 💻      Satvik Singh Rathore🎨 💻      dangoth🎨 💻              Maxim🎨 💻      Phuong-Cat Ngo🎨 💻      Frenchtoast0🎨 💻      Rakshith🎨 💻      Vaibhav Arora🎨 💻      zghp🎨 💻      Bedovan🎨 💻              chiaramistro🎨 💻      him2016🎨 💻      HarshitSachdeva🎨 💻      Sadaf Saleem🎨 💻      Aaroh Srivastava🎨 💻      eloygplaza🎨 💻      Gaurav Kumar Verma🎨 💻              AndreaCUS🎨 💻      Simran🎨 💻      Prashant Bhapkar🎨 💻      mhaendler🎨 💻      Gauri Maheshwari🎨 💻      4Lajf🎨 💻      Tanmoy Sengupta🎨 💻              Sharad Tripathi🎨 💻      Niraj Chavan🎨 💻      Luisa Gualda🎨 💻      Monika-Sivakumar-3🎨 💻      harryfensome🎨 💻      Shubham Choubey🎨 💻      Ashwini Patil🎨 💻              cleversonlira🎨 💻      Nurmukhammed🎨 💻      workspace-utkarsh🎨 💻      Santosh Phadtare🎨 💻      Prashant Warghude🎨 💻      Umang Dakh🎨 💻      Shalini Chavan🎨 💻              vinit gurjar🎨 💻      Vishal Kumar🎨 💻      Wonhyeong Seo🎨 💻      Achwale Prajwal Namdevrao🎨 💻      Ankan Banerjee🎨 💻      bhaumikankan🎨 💻      JamesMacroZhang🎨 💻              Pedro Lopes🎨 💻      dia🎨 💻      tayyabhussain2910🎨 💻      Rajdeep Shrivastava 🎨 💻      Mukul Kumar🎨 💻      Mayank N🎨 💻      jdelucca🎨 💻              Sneha Mittal🎨 💻      Sarika Kushwaha🎨 💻      farzad-khb🎨 💻      Elijah Shackelford🎨 💻      The-Only-Raminator🎨 💻      Keerthana Kasthuril🎨 💻      Viachaslau Auchynnikau🎨 💻              Mohammad Osman Rasooli🎨 💻      mvedovato🎨 💻      Sonali Rajput🎨 💻      Isha Dhek🎨 💻      Ramshad Cheriyeri Peediyakkal🎨 💻      Micah🎨 💻      gauravshukla2203🎨 💻              sndmurthy🎨 💻      Shivam-Singh🎨 💻      M. Ammar Khan🎨 💻      chandolakul🎨 💻      bhatnagar221🎨 💻      Adrian Nieściur🎨 💻      nezi311🎨 💻              scottajevans🎨 💻      Marcelo Antunes Soares Fantini🎨 💻      Axel De Acetis🎨 💻      Drishti Sah🎨 💻      VipulDhillon🎨 💻      Urmi Jana🎨 💻      Ayush Mokal🎨 💻              Damola Olutoke🎨 💻      Max🎨 💻      Lakshmi N🎨 💻      ArtemReva🎨 💻      Ujjwal Aggarwal🎨 💻      Mo🎨 💻      Brian🎨 💻              chamley🎨 💻      Simone Baptiste🎨 💻      Shekhar Thakur🎨 💻      Smith🎨 💻      codernoob1🎨 💻      lok84🎨 💻      Tobias Riemenschneider🎨 💻              Tharsanan1🎨 💻      ANURAG SINGH🎨 💻      Yash Sant🎨 💻      Krishiv Patel🎨 💻      GGGalaxy🎨 💻      pardeepdhillon661🎨 💻      anujd64🎨 💻              Pedro Pereira🎨 💻      Master_Saptak🎨 💻      SURANJAN DAS🎨 💻      Tripura kant🎨 💻      shabzkhan🎨 💻      Mustafa Poya🎨 💻      Roshan Jha🎨 💻              GuillaumeLarue🎨 💻      Tomasz Rodak🎨 💻      Junil Kim🎨 💻      Surbhi Mayank🎨 💻      Nemanja Lekic🎨 💻      HemantMalokar🎨 💻      Felipe M. López🎨 💻              bibliofilo🎨 💻      GauthamG2🎨 💻      02_t🎨 💻      Yusuf Abdul-razaq🎨 💻      Vladimir🎨 💻      Sai Chandra K🎨 💻      Soroush Bonab🎨 💻              Giide0n🎨 💻      GG🎨 💻      Dáger Zúñiga🎨 💻      rsk2🎨 💻      Storozhev DJ🎨 💻      Jeevan🎨 💻      Andy Johnson🎨 💻              Aníbal Pozo🎨 💻      Jovane de Castro🎨 💻      Muhammad Hamza Amir🎨 💻      tharaka-mts🎨 💻      Ali KHYAR🎨 💻      Caio Araujo🎨 💻      Oscar Dyremyhr🎨 💻              arteality🎨 💻      Daniel Drexlmaier🎨 💻      Marco Monti🎨 💻      mikeycrystal🎨 💻      Veljanovskii🎨 💻      Ivan Gorbachev🎨 💻      Sahil Rawat🎨 💻              Hasitha Suneth🎨 💻      Yerko Vera Lezama🎨 💻      Ivan Penchev🎨 💻      Tanver Islam Tonmoy🎨 💻      Xun Cao🎨 💻      Nayan Babariya🎨 💻      Priyanshu Maurya🎨 💻              Dylan Tintenfich🎨 💻      Ron Strauss🎨 💻      Mohammed AlBanna🎨 💻      Mukund M🎨 💻      Franklin Ohaegbulam🎨 💻      Nisarg Shah🎨 💻      Unik Dahal🎨 💻              Readily🎨 💻      Alexandre Poitevin🎨 💻      Scaramir🎨 💻      Pruthvi🎨 💻      Kalmanq🎨 💻      Alfatah Nesab🎨 💻      arudesai🎨 💻              Adryenne🎨 💻      El mehdi oudaoud🎨 💻      Jayant Goel🎨 💻      Tsuki🎨 💻      Peter Lemanski🎨 💻      Annurag-byte🎨 💻      Anthony Vu🎨 💻              Vitaly Nikolaychuk🎨 💻      Nathan🎨 💻      Evgenii Petukhov🎨 💻      Loris Guerra🎨 💻      fakhriaunur🎨 💻      Mehdi HYANI🎨 💻      Sarvex Jatasra🎨 💻              santimanuelr🎨 💻      Evgeniy Rezanov🎨 💻      Sonia M🎨 💻      Grzegorz Kmita🎨 💻      Manuel Carita🎨 💻      Felipe Cisternas Alvarez🎨 💻      Guo Ci🎨 💻              Marcos Silva🎨 💻      KK🎨 💻      Shubhanjan Medhi🎨 💻      ArthurFerreiraRodrigues🎨 💻      PabloHermun🎨 💻      disha-baldawa🎨 💻      StaroMoon🎨 💻              Amila T Kumarasekara🎨 💻      Amoh Prince🎨 💻      AngeloGC🎨 💻      Ebube Glory Ogbonda🎨 💻      Prahalad Belavadi📖      Antoni Sarnowski-Trypka🎨 💻      Alberto Pasqualetto🎨 💻              Amir Babaei🎨 💻      Syed Abdul Hannan🎨 💻      Srajan Rai🎨 💻      Clarence Moore🎨 💻      Nguyen Anh Tuan🎨 💻      dar2dar2🎨 💻      Ameer Ibrahim🎨 💻              Tiago Lugatto🎨 💻      raremiroir🎨 💻      Moobie🎨 💻      AlicanDursun🎨 💻      bbalsam🎨 💻      Luboš Hájek🎨 💻      mrshahzeb7🎨 💻              Wesley Scholl🎨 💻      Lawrence Turcotte🎨 💻      Michael DiPaolo🎨 💻      Smart-Codi🎨 💻      Vivek Kumar🎨 💻      Igor Moiseev🎨 💻      Bård Pedersen🎨 💻              HOA PHAN🎨 💻      GaborModra🎨 💻      vivek-114🎨 💻      Robin🎨 💻      Alex🎨 💻      John Ehrlinger🎨 💻      Roman Zhuravlov🎨 💻              Jordan Moss🎨 💻      RaeShelly🎨 💻      gmollard🎨 💻      Md Kaif Khan🎨 💻      Pablo Romera🎨 💻      Erik Bustos🎨 💻      trogfield🎨 💻              simon-aichhorn🎨 💻      Tufan GÜLEÇ🎨 💻      Uğur Berkecan Ünlü🎨 💻      Revanth Naik🎨 💻      Lia Pires🎨 💻      Igor Mestechkin🎨 💻      Anirudh Karanth🎨 💻              KBobovskiy🎨 💻      zhatiayua🎨 💻 🖋      David Cardona🎨 💻      Paulo Castilho🎨 💻      Sebastiano Picchi🎨 💻      pjotar🎨 💻      Rimel CHERIF💻              Arsal uddin🖋      Dmitry Kasporsky💻      SoftwareDev1014🎨 💻      @Robvred🎨 💻      Kasun Shanaka💻      Ahmad M.🎨 💻      Alex Kozin🎨 💻              Mandy Meindersma🎨 💻      LEGALISE PIRACY🎨 💻      Alex Logvin🎨 💻      Aria Dahl🎨 💻      Mustafa Arifoglu🎨 💻      Yevhen Leshchenko🎨 💻      Anubhav Adhikari🎨 💻              Noah Tatko🎨 💻      Mohit Gadhavi🎨 💻      Pedro Basílio🎨 💻      RealSanjeev🎨 💻      Akash Hazra🎨 💻      Christoph Dahlen🎨 💻      Vincent du Plessis🎨 💻              Karen Tamrazyan🎨 💻      Mirza Younus Baig🎨 💻      Ashish Kumar🎨 💻      Unknown6334🎨 💻      flowaz🎨 💻      zi-aikra🎨 💻      PAYAL PM🎨 💻              Lennart Lösche🎨 💻      Yummy-Yums🎨 💻      Njuacha Hubert Mikulowski🎨 💻      Hussein Esmail🎨 💻      Bilgehan Bezir🎨 💻      Muhammed Shittu🎨 💻      Clément FERNANDES🎨 💻              JaCKoP619🎨 💻      userutf8🎨 💻      Mohamed Ubaid🎨 💻      Justin Yates🎨 💻      mohammad ali🎨 💻      Madhav Singh🎨 💻      RgbMouse69🎨 💻              Nicholas Leask🎨 💻      parthav0🎨 💻      Sigma🎨 💻      Evelina Becheva🎨 💻      Akshit Gulyan🎨 💻      Arpita Jana🎨 💻      Praveen Kumar🎨 💻              Mohammad Sami🎨 💻      eddiestefanescu🎨 💻      Ramesh Yadav🎨 💻      Sarthak Joshi🎨 💻      Nikhil12300🎨 💻      Yevgen🎨 💻      Leo🎨 💻              laurent b🎨 💻      Mettchen🎨 💻      Ali Mahdavi🎨 💻      Lucas Dondo🎨 💻      Siddhesh Agarwal🎨 💻      slimerPuncher🎨 💻      saritashh🎨 💻              Iulian-Valeriu Cioată🎨 💻      Szabolcs Nagy🎨 💻      Jarle Kvile🎨 💻      劉耀升 Vic Liu🎨 💻      Suryansh🎨 💻      Matthew Oosthuyse🎨 💻      Florin Zamfir🎨 💻              Melek🎨 💻      moesocio🎨 💻      Alan James🎨 💻      Mai Thanh Phương🎨 💻      Neville Dabre🎨 💻      Maksym🎨 💻      tamanna900🎨 💻              Adithya Awati🎨 💻      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
43,geekcomputers/Python,https://github.com/geekcomputers/Python/blob/master/README.md,Python,"My Python Eggs 🐍 😄I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in Notepad++ 🗒️Feel free to explore the scripts and use them for your learning and automation needs!List of Scripts:batch_file_rename.py - Batch rename a group of files in a specified directory, changing their extensions.create_dir_if_not_there.py - Check if a directory exists in the user's home directory. Create it if it doesn't exist.Fast Youtube Downloader - Download YouTube videos quickly with parallel threads using aria2c.Google Image Downloader - Query a given term and retrieve images from the Google Image database.dir_test.py - Test if the directory testdir exists. If not, create it.env_check.py - Check if all the required environment variables are set.blackjack.py - Casino Blackjack-21 game in Python.fileinfo.py - Show file information for a given file.folder_size.py - Scan the current directory and all subdirectories and display their sizes.logs.py - Search for all *.log files in a directory, zip them using the specified program, and date stamp them.move_files_over_x_days.py - Move all files over a specified age (in days) from the source directory to the destination directory.nslookup_check.py - Open the file server_list.txt and perform nslookup for each server to check the DNS entry.osinfo.py - Display information about the operating system on which the script is running.ping_servers.py - Ping the servers associated with the specified application group.ping_subnet.py - Scan the final range of a given IP subnet for available addresses.powerdown_startup.py - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.puttylogs.py - Zip all the logs in the given directory.script_count.py - Scan the scripts directory and count the different types of scripts.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.script_listing.py - List all files in a given directory and its subdirectories.testlines.py - Open a file and print out 100 lines of the set line variable.tweeter.py - Tweet text or a picture from the terminal.serial_scanner.py - List available serial ports in use on Linux and Windows systems.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.CountMillionCharacter.py and CountMillionCharacter2.0 - Get character count of a text file.xkcd_downloader.py - Download the latest XKCD comic and place them in a new folder called \""comics\"".timymodule.py - An alternative to Python's 'timeit' module and easier to use.calculator.py - Implement a calculator using Python's eval() function.Google_News.py - Use BeautifulSoup to provide latest news headlines along with news links.cricket_live_score - Use BeautifulSoup to provide live cricket scores.youtube.py - Take a song name as input and fetch the YouTube URL of the best matching song and play it.site_health.py - Check the health of a remote server.SimpleStopWatch.py - Simple stop watch implementation using Python's time module.Changemac.py - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).whatsapp-monitor.py - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.whatsapp-chat-analyzer.py - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.JARVIS.py - Control Windows programs with your voice.Images Downloader - Download images from webpages on Unix-based systems.space_invader.py.py - Classical 2D space invader game to recall your childhood memories.Test Case Generator - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.Note: The content in this repository belongs to the respective authors and creators. I'm just providing a formatted README.md for better presentation."
44,wangzheng0822/algo,https://github.com/wangzheng0822/algo/blob/master/README.md,Python,数据结构和算法必知必会的50个代码实现微信搜索我的公众号“小争哥”，或者微信扫描下面二维码关注关注微信公众号，回复”PDF“获取独家算法资料。前Google工程师，10万人跟着学的《数据结构和算法之美》《设计模式之美》专栏作者数组实现一个支持动态扩容的数组实现一个大小固定的有序数组，支持动态增删改操作实现两个有序数组合并为一个有序数组链表实现单链表、循环链表、双向链表，支持增删操作实现单链表反转实现两个有序的链表合并为一个有序链表实现求链表的中间结点栈用数组实现一个顺序栈用链表实现一个链式栈编程模拟实现一个浏览器的前进、后退功能队列用数组实现一个顺序队列用链表实现一个链式队列实现一个循环队列递归编程实现斐波那契数列求值f(n)=f(n-1)+f(n-2)编程实现求阶乘n!编程实现一组数据集合的全排列排序实现归并排序、快速排序、插入排序、冒泡排序、选择排序编程实现O(n)时间复杂度内找到一组数据的第K大元素二分查找实现一个有序数组的二分查找算法实现模糊二分查找算法（比如大于等于给定值的第一个元素）散列表实现一个基于链表法解决冲突问题的散列表实现一个LRU缓存淘汰算法字符串实现一个字符集，只包含a～z这26个英文字母的Trie树实现朴素的字符串匹配算法二叉树实现一个二叉查找树，并且支持插入、删除、查找操作实现查找二叉查找树中某个节点的后继、前驱节点实现二叉树前、中、后序以及按层遍历堆实现一个小顶堆、大顶堆、优先级队列实现堆排序利用优先级队列合并K个有序数组求一组动态数据集合的最大Top K图实现有向图、无向图、有权图、无权图的邻接矩阵和邻接表表示方法实现图的深度优先搜索、广度优先搜索实现Dijkstra算法、A*算法实现拓扑排序的Kahn算法、DFS算法回溯利用回溯算法求解八皇后问题利用回溯算法求解0-1背包问题分治利用分治算法求一组数据的逆序对个数动态规划0-1背包问题最小路径和编程实现莱文斯坦最短编辑距离编程实现查找两个字符串的最长公共子序列编程实现一个数据序列的最长递增子序列
45,encode/django-rest-framework,https://github.com/encode/django-rest-framework/blob/master/README.md,Python,"Django REST frameworkAwesome web-browsable Web APIs.Full documentation for the project is available at https://www.django-rest-framework.org/.FundingREST framework is a collaboratively funded project. If you useREST framework commercially we strongly encourage you to invest in itscontinued development by signing up for a paid plan.The initial aim is to provide a single full-time position on REST framework.Every single sign-up makes a significant impact towards making that possible.Many thanks to all our wonderful sponsors, and in particular to our premium backers, Sentry, Stream, Spacinov, Retool, bit.io, PostHog, CryptAPI, and FEZTO.OverviewDjango REST framework is a powerful and flexible toolkit for building Web APIs.Some reasons you might want to use REST framework:The Web browsable API is a huge usability win for your developers.Authentication policies including optional packages for OAuth1a and OAuth2.Serialization that supports both ORM and non-ORM data sources.Customizable all the way down - just use regular function-based views if you don't need the more powerful features.Extensive documentation, and great community support.There is a live example API for testing purposes, available here.Below: Screenshot from the browsable APIRequirementsPython 3.6+Django 4.2, 4.1, 4.0, 3.2, 3.1, 3.0We highly recommend and only officially support the latest patch release ofeach Python and Django series.InstallationInstall using pip...pip install djangorestframeworkAdd 'rest_framework' to your INSTALLED_APPS setting.INSTALLED_APPS = [    ...    'rest_framework',]ExampleLet's take a look at a quick example of using REST framework to build a simple model-backed API for accessing users and groups.Startup up a new project like so...pip install djangopip install djangorestframeworkdjango-admin startproject example ../manage.py migrate./manage.py createsuperuserNow edit the example/urls.py module in your project:from django.contrib.auth.models import Userfrom django.urls import include, pathfrom rest_framework import routers, serializers, viewsets# Serializers define the API representation.class UserSerializer(serializers.HyperlinkedModelSerializer):    class Meta:        model = User        fields = ['url', 'username', 'email', 'is_staff']# ViewSets define the view behavior.class UserViewSet(viewsets.ModelViewSet):    queryset = User.objects.all()    serializer_class = UserSerializer# Routers provide a way of automatically determining the URL conf.router = routers.DefaultRouter()router.register(r'users', UserViewSet)# Wire up our API using automatic URL routing.# Additionally, we include login URLs for the browsable API.urlpatterns = [    path('', include(router.urls)),    path('api-auth/', include('rest_framework.urls', namespace='rest_framework')),]We'd also like to configure a couple of settings for our API.Add the following to your settings.py module:INSTALLED_APPS = [    ...  # Make sure to include the default installed apps here.    'rest_framework',]REST_FRAMEWORK = {    # Use Django's standard `django.contrib.auth` permissions,    # or allow read-only access for unauthenticated users.    'DEFAULT_PERMISSION_CLASSES': [        'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly',    ]}That's it, we're done!./manage.py runserverYou can now open the API in your browser at http://127.0.0.1:8000/, and view your new 'users' API. If you use the Login control in the top right corner you'll also be able to add, create and delete users from the system.You can also interact with the API using command line tools such as curl. For example, to list the users endpoint:$ curl -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/[    {        \""url\"": \""http://127.0.0.1:8000/users/1/\"",        \""username\"": \""admin\"",        \""email\"": \""admin@example.com\"",        \""is_staff\"": true,    }]Or to create a new user:$ curl -X POST -d username=new -d email=new@example.com -d is_staff=false -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/{    \""url\"": \""http://127.0.0.1:8000/users/2/\"",    \""username\"": \""new\"",    \""email\"": \""new@example.com\"",    \""is_staff\"": false,}Documentation & SupportFull documentation for the project is available at https://www.django-rest-framework.org/.For questions and support, use the REST framework discussion group, or #restframework on libera.chat IRC.You may also want to follow the author on Twitter.SecurityPlease see the security policy."
46,facebookresearch/Detectron,https://github.com/facebookresearch/Detectron/blob/main/README.md,Python,"Detectron is deprecated. Please see detectron2, a ground-up rewrite of Detectron in PyTorch.DetectronDetectron is Facebook AI Research's software system that implements state-of-the-art object detection algorithms, including Mask R-CNN. It is written in Python and powered by the Caffe2 deep learning framework.At FAIR, Detectron has enabled numerous research projects, including: Feature Pyramid Networks for Object Detection, Mask R-CNN, Detecting and Recognizing Human-Object Interactions, Focal Loss for Dense Object Detection, Non-local Neural Networks, Learning to Segment Every Thing, Data Distillation: Towards Omni-Supervised Learning, DensePose: Dense Human Pose Estimation In The Wild, and Group Normalization.    Example Mask R-CNN output.IntroductionThe goal of Detectron is to provide a high-quality, high-performancecodebase for object detection research. It is designed to be flexible in orderto support rapid implementation and evaluation of novel research. Detectronincludes implementations of the following object detection algorithms:Mask R-CNN -- Marr Prize at ICCV 2017RetinaNet -- Best Student Paper Award at ICCV 2017Faster R-CNNRPNFast R-CNNR-FCNusing the following backbone network architectures:ResNeXt{50,101,152}ResNet{50,101,152}Feature Pyramid Networks (with ResNet/ResNeXt)VGG16Additional backbone architectures may be easily implemented. For more details about these models, please see References below.Update4/2018: Support Group Normalization - see GN/README.mdLicenseDetectron is released under the Apache 2.0 license. See the NOTICE file for additional details.Citing DetectronIf you use Detectron in your research or wish to refer to the baseline results published in the Model Zoo, please use the following BibTeX entry.@misc{Detectron2018,  author =       {Ross Girshick and Ilija Radosavovic and Georgia Gkioxari and                  Piotr Doll\\'{a}r and Kaiming He},  title =        {Detectron},  howpublished = {\\url{https://github.com/facebookresearch/detectron}},  year =         {2018}}Model Zoo and BaselinesWe provide a large set of baseline results and trained models available for download in the Detectron Model Zoo.InstallationPlease find installation instructions for Caffe2 and Detectron in INSTALL.md.Quick Start: Using DetectronAfter installation, please see GETTING_STARTED.md for brief tutorials covering inference and training with Detectron.Getting HelpTo start, please check the troubleshooting section of our installation instructions as well as our FAQ. If you couldn't find help there, try searching our GitHub issues. We intend the issues page to be a forum in which the community collectively troubleshoots problems.If bugs are found, we appreciate pull requests (including adding Q&A's to FAQ.md and improving our installation instructions and troubleshooting documents). Please see CONTRIBUTING.md for more information about contributing to Detectron.ReferencesData Distillation: Towards Omni-Supervised Learning.Ilija Radosavovic, Piotr Dollár, Ross Girshick, Georgia Gkioxari, and Kaiming He.Tech report, arXiv, Dec. 2017.Learning to Segment Every Thing.Ronghang Hu, Piotr Dollár, Kaiming He, Trevor Darrell, and Ross Girshick.Tech report, arXiv, Nov. 2017.Non-Local Neural Networks.Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.Tech report, arXiv, Nov. 2017.Mask R-CNN.Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.IEEE International Conference on Computer Vision (ICCV), 2017.Focal Loss for Dense Object Detection.Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár.IEEE International Conference on Computer Vision (ICCV), 2017.Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour.Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.Tech report, arXiv, June 2017.Detecting and Recognizing Human-Object Interactions.Georgia Gkioxari, Ross Girshick, Piotr Dollár, and Kaiming He.Tech report, arXiv, Apr. 2017.Feature Pyramid Networks for Object Detection.Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.Aggregated Residual Transformations for Deep Neural Networks.Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.R-FCN: Object Detection via Region-based Fully Convolutional Networks.Jifeng Dai, Yi Li, Kaiming He, and Jian Sun.Conference on Neural Information Processing Systems (NIPS), 2016.Deep Residual Learning for Image Recognition.Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.Faster R-CNN: Towards Real-Time Object Detection with Region Proposal NetworksShaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.Conference on Neural Information Processing Systems (NIPS), 2015.Fast R-CNN.Ross Girshick.IEEE International Conference on Computer Vision (ICCV), 2015."
47,saltstack/salt,https://github.com/saltstack/salt/blob/master/README.rst,Python,"Latest Salt DocumentationOpen an issue (bug report, feature request, etc.)Salt is the world's fastest, most intelligent and scalable automationengine.About SaltBuilt on Python, Salt is an event-driven automation tool and framework todeploy, configure, and manage complex IT systems. Use Salt to automate commoninfrastructure administration tasks and ensure that all the components of yourinfrastructure are operating in a consistent desired state.Salt has many possible uses, including configuration management, which involves:Managing operating system deployment and configuration.Installing and configuring software applications and services.Managing servers, virtual machines, containers, databases, web servers,network devices, and more.Ensuring consistent configuration and preventing configuration drift.Salt is ideal for configuration management because it is pluggable,customizable, and plays well with many existing technologies. Salt enables youto deploy and manage applications that use any tech stack running on nearly anyoperating system,including different types of network devices such as switches and routers from avariety of vendors.In addition to configuration management Salt can also:Automate and orchestrate routine IT processes, such as common required tasksfor scheduled server downtimes or upgrading operating systems or applications.Create self-aware, self-healing systems that can automatically respond tooutages, common administration problems, or other important events.About our sponsorsSalt powers VMware's VMware Aria Automation Config(previously vRealize Automation SaltStack Config / SaltStack Enterprise), and can be foundunder the hood of products from Juniper, Cisco, Cloudflare, Nutanix, SUSE, andTieto, to name a few.The original sponsor of our community, SaltStack, was acquired by VMware in 2020.The Salt Project remains an open source ecosystem that VMware supports andcontributes to. VMware ensures the code integrity and quality of the Saltmodules by acting as the official sponsor and manager of the Salt project. Manyof the core Salt Project contributors are also VMware employees. This teamcarefully reviews and enhances the Salt modules to ensure speed, quality, andsecurity.Download and install SaltSalt is tested and packaged to run on CentOS, Debian, RHEL, Ubuntu, MacOS,Windows, and more. Download Salt and get started now. Seesupported operating systemsfor more information.To download and install Salt, see:* The Salt install guide* Salt Project repositoryTechnical supportReport bugs or problems using Salt by opening an issue: https://github.com/saltstack/salt/issuesTo join our community forum where you can exchange ideas, best practices,discuss technical support questions, and talk to project maintainers, join ourSlack workspace: Salt Project Community SlackSalt Project documentationInstallation instructions, tutorials, in-depth API and module documentation:The Salt install guideThe Salt user guideLatest Salt documentationSalt's contributing guideSecurity advisoriesKeep an eye on the Salt ProjectSecurity Announcementslanding page. Salt Project recommends subscribing to theSalt Project Security RSS feedto receive notification when new information is available regarding securityannouncements.Other channels to receive security announcements include theSalt Community mailing listand the Salt Project Community Slack.Responsibly reporting security vulnerabilitiesWhen reporting security vulnerabilities for Salt or other SaltStack projects,refer to the SECURITY.md file found in this repository.Join our communitySalt is built by the Salt Project community, which includes more than 3,000contributors working in roles just like yours. This well-known and trustedcommunity works together to improve the underlying technology and extend Salt bycreating a variety of execution and state modules to accomplish the most commontasks or solve the most important problems that people in your role are likelyto face.If you want to help extend Salt or solve a problem with Salt, you can join ourcommunity and contribute today.Please be sure to review ourCode of Conduct.Also, check out some of our community resources including:Salt Project Community WikiSalt Project Community SlackSalt Project: IRC on LiberaChatSalt Project YouTube channelSalt Project Twitch channelThere are lots of ways to get involved in our community. Every month, there arearound a dozen opportunities to meet with other contributors and the Salt Coreteam and collaborate in real time. The best way to keep track is by subscribingto the Salt Project Community Events Calendar on the mainhttps://saltproject.io website.If you have additional questions, email us at saltproject@vmware.com or reach outdirectly to the Community Manager, Jimmy Chunga via Slack. We'd be glad tohave you join our community!LicenseSalt is licensed under the Apache 2.0 license. Pleasesee theLICENSE file for thefull text of the Apache license, followed by a full summary of the licensingused by external modules.A complete list of attributions and dependencies can be found here:salt/DEPENDENCIES.md"
48,donnemartin/system-design-primer,https://github.com/donnemartin/system-design-primer/blob/master/README-ja.md,Python,"English ∙ 日本語 ∙ 简体中文 ∙ 繁體中文 | العَرَبِيَّة‎ ∙ বাংলা ∙ Português do Brasil ∙ Deutsch ∙ ελληνικά ∙ עברית ∙ Italiano ∙ 한국어 ∙ فارسی ∙ Polski ∙ русский язык ∙ Español ∙ ภาษาไทย ∙ Türkçe ∙ tiếng Việt ∙ Français | Add Translationシステム設計入門    動機・目的大規模システムのシステム設計を学ぶシステム設計面接課題に備える大規模システムの設計を学ぶスケーラブルなシステムのシステム設計を学ぶことは、より良いエンジニアになることに資するでしょう。システム設計はとても広範なトピックを含みます。システム設計原理については インターネット上には膨大な量の文献が散らばっています。このリポジトリは大規模システム構築に必要な知識を学ぶことができる 文献リストを体系的にまとめたもの です。オープンソースコミュニティから学ぶこのプロジェクトは、これからもずっと更新されていくオープンソースプロジェクトの初期段階にすぎません。Contributions は大歓迎です！システム設計面接課題に備えるコード技術面接に加えて、システム設計に関する知識は、多くのテック企業における 技術採用面接プロセス で 必要不可欠な要素 です。システム設計面接での頻出質問に備え、自分の解答と模範解答:ディスカッション、コードそして図表などを比較して学びましょう。面接準備に役立つその他のトピック:学習指針システム設計面接課題にどのように準備するかシステム設計課題例 とその解答オブジェクト指向設計課題例、 とその解答その他のシステム設計面接課題例暗記カード    このAnki用フラッシュカードデッキ は、間隔反復を活用して、システム設計のキーコンセプトの学習を支援します。システム設計デッキシステム設計練習課題デッキオブジェクト指向練習課題デッキ外出先や移動中の勉強に役立つでしょう。コーディング技術課題用の問題: 練習用インタラクティブアプリケーションコード技術面接用の問題を探している場合はこちら    姉妹リポジトリの Interactive Coding Challengesも見てみてください。追加の暗記デッキカードも入っています。Coding deckコントリビュートコミュニティから学ぶプルリクエスト等の貢献は積極的にお願いします:エラー修正セクション内容改善新規セクション追加翻訳する現在、内容の改善が必要な作業中のコンテンツはこちらです。コントリビュートの前にContributing Guidelinesを読みましょう。システム設計目次賛否も含めた様々なシステム設計の各トピックの概要。 全てはトレードオフの関係にあります。それぞれのセクションはより学びを深めるような他の文献へのリンクが貼られています。    システム設計トピック: まずはここからStep 1: スケーラビリティに関する動画を見るStep 2: スケーラビリティに関する記事を読む次のステップパフォーマンス vs スケーラビリティレイテンシー vs スループット可用性 vs 一貫性CAP理論CP - 一貫性(consistency)と分割性(partition)耐性AP - 可用性(availability)と分割性(partition)耐性一貫性 パターン弱い一貫性結果整合性強い一貫性可用性 パターンフェイルオーバーレプリケーションドメインネームシステム(DNS)コンテンツデリバリーネットワーク(CDN)プッシュCDNプルCDNロードバランサーアクティブ/パッシブ構成アクティブ/アクティブ構成Layer 4 ロードバランシングLayer 7 ロードバランシング水平スケーリングリバースプロキシ (WEBサーバー)ロードバランサー vs リバースプロキシアプリケーションレイヤーマイクロサービスサービスディスカバリーデータベースリレーショナルデータベースマネジメントシステム (RDBMS)マスター/スレーブ レプリケーションマスター/マスター レプリケーションフェデレーションシャーディングデノーマライゼーションSQL チューニングNoSQLキー/バリューストアドキュメントストアワイドカラムストアグラフ データベースSQL or NoSQLキャッシュクライアントキャッシングCDNキャッシングWebサーバーキャッシングデータベースキャッシングアプリケーションキャッシングデータベースクエリレベルでキャッシングするオブジェクトレベルでキャッシングするいつキャッシュを更新するのかキャッシュアサイドライトスルーライトビハインド (ライトバック)リフレッシュアヘッド非同期処理メッセージキュータスクキューバックプレッシャー通信伝送制御プロトコル (TCP)ユーザデータグラムプロトコル (UDP)遠隔手続呼出 (RPC)Representational state transfer (REST)セキュリティ補遺2の乗数表全てのプログラマーが知るべきレイテンシー値他のシステム設計面接例題実世界でのアーキテクチャ各企業のアーキテクチャ企業のエンジニアブログ作業中クレジット連絡情報ライセンス学習指針学習スパンに応じてみるべきトピックス (short, medium, long)Q: 面接のためには、ここにあるものすべてをやらないといけないのでしょうか？A: いえ、ここにあるすべてをやる必要はありません。面接で何を聞かれるかは以下の条件によって変わってきます:どれだけの技術経験があるかあなたの技術背景が何であるかどのポジションのために面接を受けているかどの企業の面接を受けているか運より経験のある候補者は一般的にシステム設計についてより深い知識を有していることを要求されるでしょう。システムアーキテクトやチームリーダーは各メンバーの持つような知識よりは深い見識を持っているべきでしょう。一流テック企業では複数回の設計面接を課されることが多いです。まずは広く始めて、そこからいくつかの分野に絞って深めていくのがいいでしょう。様々なシステム設計のトピックについて少しずつ知っておくことはいいことです。以下の学習ガイドを自分の学習に当てられる時間、技術経験、どの職位、どの会社に応募しているかなどを加味して自分用に調整して使うといいでしょう。短期間 - 幅広く システム設計トピックを学ぶ。いくつかの 面接課題を解くことで対策する。中期間 - 幅広く そして それなりに深くシステム設計トピックを学ぶ。多くの 面接課題を解くことで対策する。長期間 - 幅広く そして もっと深くシステム設計トピックを学ぶ。ほぼ全ての 面接課題を解くことで対策する。短期間中期間長期間システム設計トピック を読み、システム動作機序について広く知る👍👍👍次のリンク先のいくつかのページを読んで 各企業のエンジニアリングブログ 応募する会社について知る👍👍👍次のリンク先のいくつかのページを読む 実世界でのアーキテクチャ👍👍👍復習する システム設計面接課題にどのように準備するか👍👍👍とりあえず一周する システム設計課題例SomeManyMostとりあえず一周する オブジェクト指向設計問題と解答SomeManyMost復習する その他システム設計面接での質問例SomeManyMostシステム設計面接にどのようにして臨めばいいかシステム設計面接試験問題にどのように取り組むかシステム設計面接は open-ended conversation(Yes/Noでは答えられない口頭質問)です。 自分で会話を組み立てることを求められます。以下のステップに従って議論を組み立てることができるでしょう。この過程を確かなものにするために、次のセクションシステム設計課題例とその解答 を以下の指針に従って読み込むといいでしょう。ステップ 1: そのシステム使用例の概要、制約、推計値等を聞き出し、まとめるシステム仕様の要求事項を聞き出し、問題箇所を特定しましょう。使用例と制約を明確にするための質問を投げかけましょう。要求する推計値についても議論しておきましょう。誰がそのサービスを使うのか？どのように使うのか？何人のユーザーがいるのか？システムはどのような機能を果たすのか？システムへの入力と出力は？どれだけの容量のデータを捌く必要があるのか？一秒間に何リクエストの送信が想定されるか？読み書き比率の推定値はいくら程度か？ステップ 2: より高レベルのシステム設計を組み立てる重要なコンポーネントを全て考慮した高レベルのシステム設計概要を組み立てる。主要なコンポーネントと接続をスケッチして書き出す考えの裏付けをするステップ 3: 核となるコンポーネントを設計するそれぞれの主要なコンポーネントについての詳細を学ぶ。例えば、url短縮サービスの設計を問われた際には次のようにするといいでしょう:元のURLのハッシュ化したものを作り、それを保存するMD5 と Base62ハッシュ衝突SQL もしくは NoSQLデータベーススキーマハッシュ化されたURLを元のURLに再翻訳するデータベース参照API & オブジェクト指向の設計ステップ 4: システム設計のスケール与えられた制約条件からボトルネックとなりそうなところを割り出し、明確化する。  例えば、スケーラビリティの問題解決のために以下の要素を考慮する必要があるだろうか？ロードバランサー水平スケーリングキャッシングデータベースシャーディング取りうる解決策とそのトレードオフについて議論をしよう。全てのことはトレードオフの関係にある。ボトルネックについてはスケーラブルなシステム設計の原理を読むといいでしょう。ちょっとした暗算問題ちょっとした推計値を手計算ですることを求められることもあるかもしれません。補遺の以下の項目が役に立つでしょう:チラ裏計算でシステム設計する2の乗数表全てのプログラマーが知っておくべきレイテンシの参考値文献とその他の参考資料以下のリンク先ページを見てどのような質問を投げかけられるか概要を頭に入れておきましょう:システム設計面接で成功するには？システム設計面接アーキテクチャ、システム設計面接への導入システム設計課題例とその解答頻出のシステム設計面接課題と参考解答、コード及びダイアグラム解答は solutions/ フォルダ以下にリンクが貼られている問題Pastebin.com (もしくは Bit.ly) を設計する解答Twitterタイムライン (もしくはFacebookフィード)を設計するTwitter検索(もしくはFacebook検索)機能を設計する解答ウェブクローラーを設計する解答Mint.comを設計する解答SNSサービスのデータ構造を設計する解答検索エンジンのキー/バリュー構造を設計する解答Amazonのカテゴリ毎の売り上げランキングを設計する解答AWS上で100万人規模のユーザーを捌くサービスを設計する解答システム設計問題を追加するContributePastebin.com (もしくは Bit.ly) を設計する問題と解答を見るTwitterタイムライン&検索 (もしくはFacebookフィード&検索)を設計する問題と解答を見るウェブクローラーの設計問題と解答を見るMint.comの設計問題と解答を見るSNSサービスのデータ構造を設計する問題と解答を見る検索エンジンのキー/バリュー構造を設計する問題と解答を見るAmazonのカテゴリ毎の売り上げランキングを設計する問題と解答を見るAWS上で100万人規模のユーザーを捌くサービスを設計する問題と解答を見るオブジェクト指向設計問題と解答頻出のオブジェクト指向システム設計面接課題と参考解答、コード及びダイアグラム解答は solutions/ フォルダ以下にリンクが貼られている備考: このセクションは作業中です問題ハッシュマップの設計解答LRUキャッシュの設計解答コールセンターの設計解答カードのデッキの設計解答駐車場の設計解答チャットサーバーの設計解答円形配列の設計Contributeオブジェクト指向システム設計問題を追加するContributeシステム設計トピックス: まずはここからシステム設計の勉強は初めて？まず初めに、よく使われる設計原理について、それらが何であるか、どのように用いられるか、長所短所について基本的な知識を得る必要がありますステップ 1: スケーラビリティに関する動画を観て復習するHarvardでのスケーラビリティの講義ここで触れられているトピックス:垂直スケーリング水平スケーリングキャッシングロードバランシングデータベースレプリケーションデータベースパーティションステップ 2: スケーラビリティに関する資料を読んで復習するスケーラビリティここで触れられているトピックス:クローンデータベースキャッシュ非同期次のステップ次に、ハイレベルでのトレードオフについてみていく:パフォーマンス vs スケーラビリティレイテンシ vs スループット可用性 vs 一貫性全てはトレードオフの関係にあるというのを肝に命じておきましょう。それから、より深い内容、DNSやCDNそしてロードバランサーなどについて学習を進めていきましょう。パフォーマンス vs スケーラビリティリソースが追加されるのにつれて パフォーマンス が向上する場合そのサービスは スケーラブル であると言えるでしょう。一般的に、パフォーマンスを向上させるというのはすなわち計算処理を増やすことを意味しますが、データセットが増えた時などより大きな処理を捌けるようになることでもあります。1パフォーマンスvsスケーラビリティをとらえる他の考え方:パフォーマンス での問題を抱えている時、あなたのシステムは一人のユーザーにとって遅いと言えるでしょう。スケーラビリティ での問題を抱えているとき、一人のユーザーにとっては速いですが、多くのリクエストがある時には遅くなってしまうでしょう。その他の参考資料、ページスケーラビリティについてスケーラビリティ、可用性、安定性、パターンレイテンシー vs スループットレイテンシー とはなにがしかの動作を行う、もしくは結果を算出するのに要する時間スループット とはそのような動作や結果算出が単位時間に行われる回数一般的に、 最大限のスループット を 許容範囲内のレイテンシー で実現することを目指すのが普通だ。その他の参考資料、ページレイテンシー vs スループットを理解する可用性 vs 一貫性CAP 理論      Source: CAP theorem revisited分散型コンピュータシステムにおいては下の三つのうち二つまでしか同時に保証することはできない。:一貫性 - 全ての読み込みは最新の書き込みもしくはエラーを受け取る可用性 - 受け取る情報が最新のものだという保証はないが、全てのリクエストはレスポンスを必ず受け取る分断耐性 - ネットワーク問題によって順不同の分断が起きてもシステムが動作を続けるネットワークは信頼できないので、分断耐性は必ず保証しなければなりません。つまりソフトウェアシステムとしてのトレードオフは、一貫性を取るか、可用性を取るかを考えなければなりません。CP - 一貫性と分断耐性(consistency and partition tolerance)分断されたノードからのレスポンスを待ち続けているとタイムアウトエラーに陥る可能性があります。CPはあなたのサービスがアトミックな読み書き（不可分操作）を必要とする際にはいい選択肢でしょう。AP - 可用性と分断耐性(availability and partition tolerance)レスポンスはノード上にあるデータで最新のものを返します。つまり、最新版のデータが返されるとは限りません。分断が解消された後も、書き込みが反映されるのには時間がかかります。結果整合性　を求めるサービスの際にはAPを採用するのがいいでしょう。もしくは、外部エラーに関わらずシステムが稼働する必要がある際にも同様です。その他の参考資料、ページCAP 理論を振り返る平易な英語でのCAP 理論のイントロCAP FAQ一貫性パターン同じデータの複製が複数ある状態では、クライアントが一貫したデータ表示を受け取るために、どのようにそれらを同期すればいいのかという課題があります。 CAP 理論 における一貫性の定義を思い出してみましょう。全ての読み取りは最新の書き込みデータもしくはエラーを受け取るはずです。弱い一貫性書き込み後の読み取りでは、その最新の書き込みを読めたり読めなかったりする。ベストエフォート型のアプローチに基づく。このアプローチはmemcachedなどのシステムに見られます。弱い一貫性はリアルタイム性が必要なユースケース、例えばVoIP、ビデオチャット、リアルタイムマルチプレイヤーゲームなどと相性がいいでしょう。例えば、電話に出ているときに数秒間音声が受け取れなくなったとしたら、その後に接続が回復してもその接続が切断されていた間に話されていたことは聞き取れないというような感じです。結果整合性書き込みの後、読み取りは最終的にはその結果を読み取ることができる(ミリ秒ほど遅れてというのが一般的です)。データは非同期的に複製されます。このアプローチはDNSやメールシステムなどに採用されています。結果整合性は多くのリクエストを捌くサービスと相性がいいでしょう。強い一貫性書き込みの後、読み取りはそれを必ず読むことができます。データは同期的に複製されます。このアプローチはファイルシステムやRDBMSなどで採用されています。トランザクションを扱うサービスでは強い一貫性が必要でしょう。その他の参考資料、ページデータセンター間でのトランザクション可用性パターン高い可用性を担保するには主に次の二つのパターンがあります: フェイルオーバー と レプリケーション です。フェイルオーバーアクティブ・パッシブアクティブ・パッシブフェイルオーバーにおいては、周期信号はアクティブもしくはスタンバイ中のパッシブなサーバーに送られます。周期信号が中断された時には、パッシブだったサーバーがアクティブサーバーのIPアドレスを引き継いでサービスを再開します。起動までのダウンタイムはパッシブサーバーが「ホット」なスタンバイ状態にあるか、「コールド」なスタンバイ状態にあるかで変わります。アクティブなサーバーのみがトラフィックを捌きます。アクティブ・パッシブフェイルオーバーはマスター・スレーブフェイルオーバーと呼ばれることもあります。アクティブ・アクティブアクティブアクティブ構成では両方のサーバーがトラフィックを捌くことで負荷を分散します。これらのサーバーがパブリックなものの場合、DNSは両方のサーバーのパブリックIPを知っている必要があります。もし、プライベートなものな場合、アプリケーションロジックが両方のサーバーの情報について知っている必要があります。アクティブ・アクティブなフェイルオーバーはマスター・マスターフェイルオーバーと呼ばれることもあります。短所: フェイルオーバーフェイルオーバーではより多くのハードウェアを要し、複雑さが増します。最新の書き込みがパッシブサーバーに複製される前にアクティブが落ちると、データ欠損が起きる潜在可能性があります。レプリケーションマスター・スレーブ　と　マスター・マスターこのトピックは データベース セクションにおいてより詳細に解説されています:マスター・スレーブ レプリケーションマスター・マスター レプリケーションドメインネームシステム      Source: DNS security presentationドメインネームシステム (DNS) は www.example.com などのドメインネームをIPアドレスへと翻訳します。DNSは少数のオーソライズされたサーバーが上位に位置する階層的構造です。あなたのルーターもしくはISPは検索をする際にどのDNSサーバーに接続するかという情報を提供します。低い階層のDNSサーバーはその経路マップをキャッシュします。ただ、この情報は伝搬遅延によって陳腐化する可能性があります。DNSの結果はあなたのブラウザもしくはOSに一定期間（time to live (TTL)に設定された期間）キャッシュされます。NS record (name server) - あなたのドメイン・サブドメインでのDNSサーバーを特定します。MX record (mail exchange) - メッセージを受け取るメールサーバーを特定します。A record (address) - IPアドレスに名前をつけます。CNAME (canonical) - 他の名前もしくは　CNAME (example.com を www.example.com) もしくは A recordへと名前を指し示す。CloudFlare や Route 53 などのサービスはマネージドDNSサービスを提供しています。いくつかのDNSサービスでは様々な手法を使ってトラフィックを捌くことができます:加重ラウンドロビントラフィックがメンテナンス中のサーバーに行くのを防ぎます様々なクラスターサイズに応じて調整しますA/B テストレイテンシーベース地理ベース欠点: DNS上記で示されているようなキャッシングによって緩和されているとはいえ、DNSサーバーへの接続には少し遅延が生じる。DNSサーバーは、政府、ISP企業,そして大企業に管理されているが、それらの管理は複雑である。DNSサービスはDDoS attackの例で、IPアドレスなしにユーザーがTwitterなどにアクセスできなくなったように、攻撃を受ける可能性がある。その他の参考資料、ページDNS アーキテクチャWikipediaDNS 記事コンテンツデリバリーネットワーク(Content delivery network)      Source: Why use a CDNコンテンツデリバリーネットワーク(CDN)は世界中に配置されたプロキシサーバーのネットワークがユーザーに一番地理的に近いサーバーからコンテンツを配信するシステムのことです。AmazonのCloudFrontなどは例外的にダイナミックなコンテンツも配信しますが、一般的に、HTML/CSS/JS、写真、そして動画などの静的ファイルがCDNを通じて配信されます。そのサイトのDNSがクライアントにどのサーバーと交信するかという情報を伝えます。CDNを用いてコンテンツを配信することで以下の二つの理由でパフォーマンスが劇的に向上します:ユーザーは近くにあるデータセンターから受信できるバックエンドサーバーはCDNが処理してくれるリクエストに関しては処理する必要がなくなりますプッシュCDNプッシュCDNではサーバーデータに更新があった時には必ず、新しいコンテンツを受け取る方式です。コンテンツを用意し、CDNに直接アップロードし、URLをCDNを指すように指定するところまで、全て自分で責任を負う形です。コンテンツがいつ期限切れになるのか更新されるのかを設定することができます。コンテンツは新規作成時、更新時のみアップロードされることでトラフィックは最小化される一方、ストレージは最大限消費されてしまいます。トラフィックの少ない、もしくは頻繁にはコンテンツが更新されないサイトの場合にはプッシュCDNと相性がいいでしょう。コンテンツは定期的に再びプルされるのではなく、CDNに一度のみ配置されます。プルCDNプルCDNでは一人目のユーザーがリクエストした時に、新しいコンテンツをサービスのサーバーから取得します。コンテンツは自分のサーバーに保存して、CDNを指すURLを書き換えます。結果として、CDNにコンテンツがキャッシュされるまではリクエスト処理が遅くなります。time-to-live (TTL) はコンテンツがどれだけの期間キャッシュされるかを規定します。プルCDNはCDN 上でのストレージスペースを最小化しますが、有効期限が切れたファイルが更新前にプルされてしまうことで冗長なトラフィックに繋がってしまう可能性があります。大規模なトラフィックのあるサイトではプルCDNが相性がいいでしょう。というのも、トラフィックの大部分は最近リクエストされ、CDNに残っているコンテンツにアクセスするものであることが多いからです。欠点: CDNCDNのコストはトラフィック量によって変わります。もちろん、CDNを使わない場合のコストと比較するべきでしょう。TTLが切れる前にコンテンツが更新されると陳腐化する恐れがあります。CDNでは静的コンテンツがCDNを指すようにURLを更新する必要があります。その他の参考資料、ページグローバルに分散されたコンテンツデリバリーネットワークプッシュCDNとプルCDNの違いWikipediaロードバランサー      Source: Scalable system design patternsロードバランサーは入力されるクライアントのリクエストをアプリケーションサーバーやデータベースへと分散させる。どのケースでもロードバランサーはサーバー等計算リソースからのレスポンスを適切なクライアントに返す。ロードバランサーは以下のことに効果的です:リクエストが状態の良くないサーバーに行くのを防ぐリクエストを過剰に送るのを防ぐ特定箇所の欠陥でサービスが落ちることを防ぐロードバランサーは (費用の高い) ハードウェアもしくはHAProxyなどのソフトウェアで実現できる。他の利点としては:SSL termination - 入力されるリクエストを解読する、また、サーバーレスポンスを暗号化することでバックエンドのサーバーがこのコストが高くつきがちな処理を請け負わなくていいように肩代わりします。X.509 certificates をそれぞれのサーバーにインストールする必要をなくしますセッション管理 - クッキーを取り扱うウェブアプリがセッション情報を保持していない時などに、特定のクライアントのリクエストを同じインスタンスへと流します。障害に対応するために、アクティブ・パッシブ もしくは アクティブ・アクティブ モードのどちらにおいても、複数のロードバランサーを配置するのが一般的です。ロードバランサーは以下のような種々のメトリックを用いてトラフィックルーティングを行うことができます:ランダムLeast loadedセッション/クッキーラウンドロビンもしくは加重ラウンドロビンLayer 4Layer 7Layer 4 ロードバランシングLayer 4 ロードバランサーは トランスポートレイヤー を参照してどのようにリクエストを配分するか判断します。一般的に、トランスポートレイヤーとしては、ソース、送信先IPアドレス、ヘッダーに記述されたポート番号が含まれますが、パケットの中身のコンテンツは含みません。 Layer 4 ロードバランサーはネットワークパケットを上流サーバーへ届け、上流サーバーから配信することでネットワークアドレス変換 Network Address Translation (NAT) を実現します。Layer 7 ロードバランシングLayer 7 ロードバランサーは アプリケーションレイヤー を参照してどのようにリクエストを配分するか判断します。ヘッダー、メッセージ、クッキーなどのコンテンツのことです。Layer 7 ロードバランサーはネットワークトラフィックの終端を受け持ち メッセージを読み込み、ロードバランシングの判断をし、選択したサーバーとの接続を繋ぎます。例えば layer 7 ロードバランサーは動画のトラフィックを直接、そのデータをホストしているサーバーにつなぐと同時に、決済処理などのより繊細なトラフィックをセキュリティ強化されたサーバーに流すということもできる。柔軟性とのトレードオフになりますが、 layer 4 ロードバランサーではLayer 7ロードバランサーよりも所要時間、計算リソースを少なく済ませることができます。ただし、昨今の汎用ハードウェアではパフォーマンスは最小限のみしか発揮できないでしょう。水平スケーリングロードバランサーでは水平スケーリングによってパフォーマンスと可用性を向上させることができます。手頃な汎用マシンを追加することによってスケールアウトさせる方が、一つのサーバーをより高価なマシンにスケールアップする（垂直スケーリング）より費用対効果も高くなり、結果的に可用性も高くなります。また、汎用ハードウェアを扱える人材を雇う方が、特化型の商用ハードウェアを扱える人材を雇うよりも簡単でしょう。欠点: 水平スケーリング水平的にスケーリングしていくと、複雑さが増す上に、サーバーのクローニングが必要になる。サーバーはステートレスである必要がある: ユーザーに関連するセッションや、プロフィール写真などのデータを持ってはいけないセッションは一元的なデータベース (SQL、 NoSQL)などのデータストアにストアされるか キャッシュ (Redis、 Memcached)に残す必要があります。キャッシュやデータベースなどの下流サーバーは上流サーバーがスケールアウトするにつれてより多くの同時接続を保たなければなりません。欠点: ロードバランサーロードバランサーはリソースが不足していたり、設定が適切でない場合、システム全体のボトルネックになる可能性があります。単一障害点を除こうとしてロードバランサーを導入した結果、複雑さが増してしまうことになります。ロードバランサーが一つだけだとそこが単一障害点になってしまいます。一方で、ロードバランサーを複数にすると、さらに複雑さが増してしまいます。その他の参考資料、ページNGINX アーキテクチャHAProxy アーキテクチャガイドスケーラビリティWikipediaLayer 4 ロードバランシングLayer 7 ロードバランシングELB listener configリバースプロキシ(webサーバー)      Source: Wikipedia  リバースプロキシサーバーは内部サービスをまとめて外部に統一されたインターフェースを提供するウェブサーバーです。クライアントからのリクエストはそれに対応するサーバーに送られて、その後レスポンスをリバースプロキシがクライアントに返します。他には以下のような利点があります:より堅牢なセキュリティ - バックエンドサーバーの情報を隠したり、IPアドレスをブラックリスト化したり、クライアントごとの接続数を制限したりできます。スケーラビリティや柔軟性が増します - クライアントはリバースプロキシのIPしか見ないので、裏でサーバーをスケールしたり、設定を変えやすくなります。SSL termination - 入力されるリクエストを解読し、サーバーのレスポンスを暗号化することでサーバーがこのコストのかかりうる処理をしなくて済むようになります。X.509 証明書 を各サーバーにインストールする必要がなくなります。圧縮 - サーバーレスポンスを圧縮できますキャッシング - キャッシュされたリクエストに対して、レスポンスを返します静的コンテンツ - 静的コンテンツを直接送信することができます。HTML/CSS/JS写真動画などなどロードバランサー vs リバースプロキシ複数のサーバーがある時にはロードバランサーをデプロイすると役に立つでしょう。 しばしば、ロードバランサーは同じ機能を果たすサーバー群へのトラフィックを捌きます。リバースプロキシでは、上記に述べたような利点を、単一のウェブサーバーやアプリケーションレイヤーに対しても示すことができます。NGINX や HAProxy などの技術はlayer 7 リバースプロキシとロードバランサーの両方をサポートします。欠点: リバースプロキシリバースプロキシを導入するとシステムの複雑性が増します。単一のリバースプロキシは単一障害点になりえます。一方で、複数のリバースプロキシを導入すると(例: フェイルオーバー) 複雑性はより増します。その他の参考資料、ページリバースプロキシ vs ロードバランサーNGINX アーキテクチャHAProxy アーキテクチャ ガイドWikipediaアプリケーション層      Source: Intro to architecting systems for scaleウェブレイヤーをアプリケーション層 (プラットフォーム層とも言われる) と分離することでそれぞれの層を独立にスケール、設定することができるようになります。新しいAPIをアプリケーション層に追加する際に、不必要にウェブサーバーを追加する必要がなくなります。単一責任の原則 では、小さい自律的なサービスが協調して動くように提唱しています。小さいサービスの小さいチームが急成長のためにより積極的な計画を立てられるようにするためです。アプリケーション層は非同期処理もサポートします。マイクロサービス独立してデプロイできる、小規模なモジュール様式であるマイクロサービスもこの議論に関係してくる技術でしょう。それぞれのサービスは独自のプロセスを処理し、明確で軽量なメカニズムで通信して、その目的とする機能を実現します。1例えばPinterestでは以下のようなマイクロサービスに分かれています。ユーザープロフィール、フォロワー、フィード、検索、写真アップロードなどです。サービスディスカバリーConsul、 Etcd、 Zookeeper などのシステムでは、登録されているサービスの名前、アドレス、ポートの情報を監視することで、サービス同士が互いを見つけやすくしています。サービスの完全性の確認には Health checks が便利で、これには HTTP エンドポイントがよく使われます。 Consul と Etcd のいずれも組み込みの key-value store を持っており、設定データや共有データなどのデータを保存しておくことに使われます。欠点: アプリケーション層アーキテクチャ、運用、そしてプロセスを考慮すると、緩く結び付けられたアプリケーション層を追加するには、モノリシックなシステムとは異なるアプローチが必要です。マイクロサービスはデプロイと運用の点から見ると複雑性が増すことになります。その他の参考資料、ページスケールするシステムアーキテクチャを設計するためのイントロシステム設計インタビューを紐解くサービス指向アーキテクチャZookeeperのイントロダクションマイクロサービスを作るために知っておきたいことデータベース      Source: Scaling up to your first 10 million usersリレーショナルデータベースマネジメントシステム (RDBMS)SQLなどのリレーショナルデータベースはテーブルに整理されたデータの集合である。ACID はリレーショナルデータベースにおけるトランザクションのプロパティの集合である不可分性 - それぞれのトランザクションはあるかないかのいずれかである一貫性 - どんなトランザクションもデータベースをある確かな状態から次の状態に遷移させる。独立性 - 同時にトランザクションを処理することは、連続的にトランザクションを処理するのと同じ結果をもたらす。永続性 - トランザクションが処理されたら、そのように保存されるリレーショナルデータベースをスケールさせるためにはたくさんの技術がある: マスター・スレーブ レプリケーション、 マスター・マスター レプリケーション、 federation、 シャーディング、 非正規化、 そして SQL チューニングマスタースレーブ レプリケーションマスターデータベースが読み取りと書き込みを処理し、書き込みを一つ以上のスレーブデータベースに複製します。スレーブデータベースは読み取りのみを処理します。スレーブデータベースは木構造のように追加のスレーブにデータを複製することもできます。マスターデータベースがオフラインになった場合には、いずれかのスレーブがマスターに昇格するか、新しいマスターデータベースが追加されるまでは読み取り専用モードで稼働します。      Source: Scalability, availability, stability, patterns欠点: マスタースレーブ レプリケーションスレーブをマスターに昇格させるには追加のロジックが必要になる。マスタースレーブ レプリケーション、マスターマスター レプリケーションの 両方 の欠点は欠点: レプリケーションを参照マスターマスター レプリケーションいずれのマスターも読み取り書き込みの両方に対応する。書き込みに関してはそれぞれ協調する。いずれかのマスターが落ちても、システム全体としては読み書き両方に対応したまま運用できる。      Source: Scalability, availability, stability, patterns欠点: マスターマスター レプリケーションロードバランサーを導入するか、アプリケーションロジックを変更することでどこに書き込むかを指定しなければならない。大体のマスターマスターシステムは、一貫性が緩い（ACID原理を守っていない）もしくは、同期する時間がかかるために書き込みのレイテンシーが増加してしまっている。書き込みノードが追加され、レイテンシーが増加するにつれ書き込みの衝突の可能性が増える。マスタースレーブ レプリケーション、マスターマスター レプリケーションの 両方 の欠点は欠点: レプリケーション を参照欠点: レプリケーション新しいデータ書き込みを複製する前にマスターが落ちた場合にはそのデータが失われてしまう可能性がある。書き込みは読み取りレプリカにおいてリプレイされる。書き込みが多い場合、複製ノードが書き込みの処理のみで行き詰まって、読み取りの処理を満足に行えない可能性がある。読み取りスレーブノードの数が多ければ多いほど、複製しなければならない数も増え、複製時間が伸びてしまいます。システムによっては、マスターへの書き込みはマルチスレッドで並列処理できる一方、スレーブへの複製は単一スレッドで連続的に処理しなければならない場合があります。レプリケーションでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: レプリケーションスケーラビリティ、 可用性、 スタビリティ パターンマルチマスター レプリケーションFederation      Source: Scaling up to your first 10 million usersフェデレーション (もしくは機能分割化とも言う) はデータベースを機能ごとに分割する。例えば、モノリシックな単一データベースの代わりに、データベースを フォーラム、 ユーザー、 プロダクト のように三つにすることで、データベース一つあたりの書き込み・読み取りのトラフィックが減り、その結果レプリケーションのラグも短くなります。データベースが小さくなることで、メモリーに収まるデータが増えます。キャッシュの局所性が高まるため、キャッシュヒット率も上がります。単一の中央マスターで書き込みを直列化したりしないため、並列で書き込みを処理することができ、スループットの向上が期待できます。欠点: federation大規模な処理やテーブルを要するスキーマの場合、フェデレーションは効果的とは言えないでしょう。どのデータベースに読み書きをするのかを指定するアプリケーションロジックを更新しなければなりません。server linkで二つのデータベースからのデータを連結するのはより複雑になるでしょう。フェデレーションでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: federationScaling up to your first 10 million usersシャーディング      Source: Scalability, availability, stability, patternsシャーディングでは異なるデータベースにそれぞれがデータのサブセット断片のみを持つようにデータを分割します。ユーザーデータベースを例にとると、ユーザー数が増えるにつれてクラスターにはより多くの断片が加えられることになります。federationの利点に似ていて、シャーディングでは読み書きのトラフィックを減らし、レプリケーションを減らし、キャッシュヒットを増やすことができます。インデックスサイズも減らすことができます。一般的にはインデックスサイズを減らすと、パフォーマンスが向上しクエリ速度が速くなります。なにがしかのデータを複製する機能がなければデータロスにつながりますが、もし、一つのシャードが落ちても、他のシャードが動いていることになります。フェデレーションと同じく、単一の中央マスターが書き込みの処理をしなくても、並列で書き込みを処理することができ、スループットの向上が期待できます。ユーザーテーブルをシャードする一般的な方法は、ユーザーのラストネームイニシャルでシャードするか、ユーザーの地理的配置でシャードするなどです。欠点: シャーディングシャードに対応するようにアプリケーションロジックを変更しなければなりません。結果としてSQLクエリが複雑になります。シャードではデータ配分がいびつになってしまう可能性があります。例えば、標準ユーザーの集合を持つシャードがある場合、そのシャードが他のシャードよりも重い負荷を負うことになります。リバランシングをすると複雑性がより増します。consistent hashing に基づいたシャーディングでは、通信データを削減することもできます。複数のシャードからのデータを連結するのはより複雑です。シャーディングでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: シャーディングシャードの登場シャードデータベースアーキテクチャConsistent hashing非正規化非正規化では、書き込みのパフォーマンスをいくらか犠牲にして読み込みのパフォーマンスを向上させようとします。計算的に重いテーブルの結合などをせずに、複数のテーブルに冗長なデータのコピーが書き込まれるのを許容します。いくつかのRDBMS例えば、PostgreSQL やOracleはこの冗長な情報を取り扱い、一貫性を保つためのmaterialized views という機能をサポートしています。フェデレーション や シャーディングなどのテクニックによってそれぞれのデータセンターに分配されたデータを合一させることはとても複雑な作業です。非正規化によってそのような複雑な処理をしなくて済むようになります。多くのシステムで、100対1あるいは1000対1くらいになるくらい読み取りの方が、書き込みのトラフィックよりも多いことでしょう。読み込みを行うために、複雑なデータベースのジョイン処理が含まれるものは計算的に高価につきますし、ディスクの処理時間で膨大な時間を費消してしまうことになります。欠点: 非正規化データが複製される。冗長なデータの複製が同期されるように制約が存在し、そのことでデータベース全体の設計が複雑化する。非正規化されたデータベースは過大な書き込みを処理しなければならない場合、正規化されているそれよりもパフォーマンスにおいて劣る可能性がある。その他の参考資料、ページ: 非正規化DenormalizationSQLチューニングSQLチューニングは広範な知識を必要とする分野で多くの 本 が書かれています。ボトルネックを明らかにし、シミュレートする上で、 ベンチマーク を定め、 プロファイル することはとても重要です。ベンチマーク - abなどのツールを用いて、高負荷の状況をシミュレーションしてみましょう。プロファイル - slow query log などのツールを用いて、パフォーマンス状況の確認をしましょう。ベンチマークとプロファイルをとることで以下のような効率化の選択肢をとることになるでしょう。スキーマを絞るMySQLはアクセス速度向上のため、ディスク上の連続したブロックへデータを格納しています。長さの決まったフィールドに対しては VARCHAR よりも CHAR を使うようにしましょう。CHAR の方が効率的に速くランダムにデータにアクセスできます。 一方、 VARCHAR では次のデータに移る前にデータの末尾を検知しなければならないために速度が犠牲になります。ブログの投稿など、大きなテキストには TEXT を使いましょう。 TEXT ではブーリアン型の検索も可能です。 TEXT フィールドには、テキストブロックが配置されている、ディスク上の場所へのポインターが保存されます。2の32乗や40億以下を超えない程度の大きな数には INT を使いましょう。通貨に関しては小数点表示上のエラーを避けるために DECIMAL を使いましょう。大きな BLOBS を保存するのは避けましょう。どこからそのオブジェクトを取ってくることができるかの情報を保存しましょう。VARCHAR(255) は8ビットで数えられる最大の文字数です。一部のDBMSでは、1バイトの利用効率を最大化するためにこの文字数がよく使われます。検索性能向上のため 、可能であれば NOT NULL 制約を設定しましょう。インデックスを効果的に用いるクエリ(SELECT、 GROUP BY、 ORDER BY、 JOIN) の対象となる列にインデックスを使うことで速度を向上できるかもしれません。インデックスは通常、平衡探索木であるB木の形で表されます。B木によりデータは常にソートされた状態になります。また検索、順次アクセス、挿入、削除を対数時間で行えます。インデックスを配置することはデータをメモリーに残すことにつながりより容量を必要とします。インデックスの更新も必要になるため書き込みも遅くなります。大量のデータをロードする際には、インデックスを切ってからデータをロードして再びインデックスをビルドした方が速いことがあります。高負荷なジョインを避けるパフォーマンス上必要なところには非正規化を適用するテーブルのパーティションテーブルを分割し、ホットスポットを独立したテーブルに分離してメモリーに乗せられるようにする。クエリキャッシュを調整する場合によってはクエリキャッシュ がパフォーマンス問題 を引き起こす可能性があるその他の参考資料、ページ: SQLチューニングMySQLクエリを最適化するためのTipsVARCHAR(255)をやたらよく見かけるのはなんで？null値はどのようにパフォーマンスに影響するのか？Slow query logNoSQLNoSQL は key-value store、 document-store、 wide column store、 もしくは graph databaseによって表現されるデータアイテムの集合です。データは一般的に正規化されておらず、アプリケーション側でジョインが行われます。大部分のNoSQLは真のACIDトランザクションを持たず、 結果整合性 的な振る舞いの方を好みます。BASE はしばしばNoSQLデータベースのプロパティを説明するために用いられます。CAP Theorem と対照的に、BASEは一貫性よりも可用性を優先します。Basically available - システムは可用性を保証します。Soft state - システムの状態は入力がなくても時間経過とともに変化する可能性があります。結果整合性 - システム全体は時間経過とともにその間に入力がないという前提のもと、一貫性が達成されます。SQLか？NoSQLか？ を選択するのに加えて、どのタイプのNoSQLがどの使用例に最も適するかを理解するのはとても有益です。このセクションでは キーバリューストア、 ドキュメントストア、 ワイドカラムストア、 と グラフデータベース について触れていきます。キーバリューストア概要: ハッシュテーブルキーバリューストアでは一般的にO(1)の読み書きができ、それらはメモリないしSSDで裏付けられています。データストアはキーを 辞書的順序 で保持することでキーの効率的な取得を可能にしています。キーバリューストアではメタデータを値とともに保持することが可能です。キーバリューストアはハイパフォーマンスな挙動が可能で、単純なデータモデルやインメモリーキャッシュレイヤーなどのデータが急速に変わる場合などに使われます。単純な処理のみに機能が制限されているので、追加の処理機能が必要な場合にはその複雑性はアプリケーション層に載せることになります。キーバリューストアはもっと複雑なドキュメントストアや、グラフデータベースなどの基本です。その他の参考資料、ページ: キーバリューストアキーバリューデータベースキーバリューストアの欠点Redisアーキテクチャメムキャッシュアーキテクチャドキュメントストア概要: ドキュメントがバリューとして保存されたキーバリューストアドキュメントストアはオブジェクトに関する全ての情報を持つドキュメント(XML、 JSON、 binaryなど)を中心に据えたシステムです。ドキュメントストアでは、ドキュメント自身の内部構造に基づいた、APIもしくはクエリ言語を提供します。 メモ：多くのキーバリューストアでは、値のメタデータを扱う機能を含んでいますが、そのことによって二つドキュメントストアとの境界線が曖昧になってしまっています。以上のことを実現するために、ドキュメントはコレクション、タグ、メタデータやディレクトリなどとして整理されています。ドキュメント同士はまとめてグループにできるものの、それぞれで全く異なるフィールドを持つ可能性があります。MongoDB や CouchDB などのドキュメントストアも、複雑なクエリを処理するためのSQLのような言語を提供しています。DynamoDB はキーバリューとドキュメントの両方をサポートしています。ドキュメントストアは高い柔軟性を担保するので、頻繁に変化するデータを扱う時に用いられます。その他の参考資料、ページ:  ドキュメントストアドキュメント指向 データベースMongoDB アーキテクチャCouchDB アーキテクチャElasticsearch アーキテクチャワイドカラムストア      Source: SQL & NoSQL, a brief history概要: ネストされたマップ カラムファミリー<行キー、 カラム<ColKey、 Value、 Timestamp>>ワイドカラムストアのデータの基本単位はカラム（ネーム・バリューのペア）です。それぞれのカラムはカラムファミリーとして（SQLテーブルのように）グループ化することができます。スーパーカラムファミリーはカラムファミリーの集合です。それぞれのカラムには行キーでアクセスすることができます。同じ行キーを持つカラムは同じ行として認識されます。それぞれの値は、バージョン管理とコンフリクトが起きた時のために、タイムスタンプを含みます。GoogleはBigtableを初のワイドカラムストアとして発表しました。それがオープンソースでHadoopなどでよく使われるHBase やFacebookによるCassandra などのプロジェクトに影響を与えました。BigTable、HBaseやCassandraなどのストアはキーを辞書形式で保持することで選択したキーレンジでのデータ取得を効率的にします。ワイドカラムストアは高い可用性とスケーラビリティを担保します。これらはとても大規模なデータセットを扱うことによく使われます。その他の参考資料、ページ:  ワイドカラムストアSQL & NoSQL簡単に歴史をさらうBigtable アーキテクチャHBase アーキテクチャCassandra アーキテクチャグラフデータベース      Source: Graph database概要: グラフグラフデータベースでは、それぞれのノードがレコードで、それぞれのアークは二つのノードを繋ぐ関係性として定義されます。グラフデータベースは多数の外部キーや多対多などの複雑な関係性を表すのに最適です。グラフデータベースはSNSなどのサービスの複雑な関係性モデルなどについて高いパフォーマンスを発揮します。比較的新しく、まだ一般的には用いられていないので、開発ツールやリソースを探すのが他の方法に比べて難しいかもしれません。多くのグラフはREST APIsを通じてのみアクセスできます。その他の参考資料、ページ:  グラフGraphデータベースNeo4jFlockDBその他の参考資料、ページ:  NoSQL基本用語の説明NoSQLデータベースについて調査と選択ガイドスケーラビリティNoSQLのイントロダクションNoSQLパターンSQLか？NoSQLか？      Source: Transitioning from RDBMS to NoSQLSQL を選ぶ理由:構造化されたデータ厳格なスキーマリレーショナルデータ複雑なジョインをする必要性トランザクションスケールする際のパターンが明確なとき開発者の数、コミュニティ、コード等がより充実しているインデックスによるデータ探索はとても速いNoSQL を選ぶ理由:準構造化されたデータダイナミックないし、フレキシブルなスキーマノンリレーショナルなデータ複雑なジョインをする必要がないデータの多くのTB (もしくは PB) を保存する集中的、大規模なデータ負荷に耐えられるIOPSについては極めて高いスループットを示すNoSQLに適するサンプルデータ:急激なクリックストリームやログデータの収集リーダーボードやスコアリングデータショッピングカートなどの一時的情報頻繁にアクセスされる ('ホットな') テーブルメタデータやルックアップテーブルその他の参考資料、ページ:  　SQLもしくはNoSQL最初の1000万ユーザーにスケールアップするためにSQLとNoSQLの違いキャッシュ      Source: Scalable system design patternsキャッシュはページの読み込み時間を削減し、サーバーやデータベースへの負荷を低減することができます。このモデルでは、実際の処理を保存するために、ディスパッチャーがまず以前にリクエストが送信されたかどうかを確認し、直前の結果を受け取ります。データベースはそのパーティションに渡って統合された読み取り書き込みの分配を要求しますが、人気アイテムはその分配を歪めてシステム全体のボトルネックになってしまうことがあります。データベースの前にキャッシュを差し込むことでこのように、均一でない負荷やトラフィックの急激な増加を吸収することができます。クライアントキャッシングキャッシュはOSやブラウザーなどのクライアントサイド、サーバーサイド もしくは独立のキャッシュレイヤーに設置することができます。CDNキャッシングCDN もキャッシュの一つとして考えることができます。Webサーバーキャッシングリバースプロキシ や Varnish などのキャッシュは静的そして動的なコンテンツを直接配信することができます。 webサーバーもリクエストをキャッシュしてアプリケーションサーバーに接続することなしにレスポンスを返すことができます。データベースキャッシングデータベースは普通、一般的な使用状況に適するようなキャッシングの設定を初期状態で持っています。この設定を特定の仕様に合わせて調整することでパフォーマンスを向上させることができます。アプリケーションキャッシングメムキャッシュなどのIn-memoryキャッシュやRedisはアプリケーションとデータストレージの間のキーバリューストアです。データはRAMで保持されるため、データがディスクで保存される一般的なデータベースよりもだいぶ速いです。RAM容量はディスクよりも限られているので、least recently used (LRU)などのcache invalidation アルゴリズムが 'コールド' なエントリを弾き、'ホット' なデータをRAMに保存します。Redisはさらに以下のような機能を備えています:パージステンス設定ソート済みセット、リストなどの組み込みデータ構造キャッシュには様々なレベルのものがありますが、いずれも大きく二つのカテゴリーのいずれかに分類することができます: データベースクエリ と オブジェクト です:行レベルクエリレベルFully-formed serializable objectsFully-rendered HTML一般的に、ファイルベースキャッシングはクローンを作り出してオートスケーリングを難しくしてしまうので避けるべきです。データベースクエリレベルでのキャッシングデータベースをクエリする際には必ずクエリをキーとしてハッシュして結果をキャッシュに保存しましょう。この手法はキャッシュ期限切れ問題に悩むことになります:複雑なクエリによりキャッシュされた結果を削除することが困難テーブルセルなどのデータ断片が変化した時に、その変化したセルを含むかもしれない全てのキャッシュされたクエリを削除する必要がある。オブジェクトレベルでのキャッシングデータをアプリケーションコードでそうするように、オブジェクトとして捉えてみましょう。アプリケーションに、データベースからのデータセットをクラスインスタンスやデータ構造として組み立てさせます。:そのデータが変更されたら、オブジェクトをキャッシュから削除すること非同期処理を許容します: ワーカーがキャッシュされたオブジェクトの中で最新のものを集めてきます何をキャッシュするか:ユーザーのセッション完全にレンダーされたウェブページアクテビティストリームユーザーグラフデータいつキャッシュを更新するかキャッシュに保存できる容量は限られているため、自分のケースではどのキャッシュ手法が一番いいかは検討する必要があります。キャッシュアサイド      Source: From cache to in-memory data gridアプリケーションはストレージへの読み書きの処理をします。キャッシュはストレージとは直接やりとりをしません。アプリケーションは以下のことをします:キャッシュの中のエントリを参照しますが、結果としてキャッシュミスになりますデータベースからエントリを取得しますエントリをキャッシュに追加しますエントリを返しますdef get_user(self, user_id):    user = cache.get(\""user.{0}\"", user_id)    if user is None:        user = db.query(\""SELECT * FROM users WHERE user_id = {0}\"", user_id)        if user is not None:            key = \""user.{0}\"".format(user_id)            cache.set(key, json.dumps(user))    return userMemcached は通常このように使われる。その後のキャッシュデータ読み込みは速いです。キャッシュアサイドはレージーローディングであるとも言われます。リクエストされたデータのみがキャッシュされ、リクエストされていないデータでキャッシュが溢れるのを防止します。欠点: キャッシュアサイド各キャッシュミスは三つのトリップを呼び出すことになり、体感できるほどの遅延が起きてしまいます。データベースのデータが更新されるとキャッシュデータは古いものになってしまいます。time-to-live (TTL)を設定することでキャッシュエントリの更新を強制的に行う、もしくはライトスルーを採用することでこの問題は緩和できます。ノードが落ちると、新規の空のノードで代替されることでレイテンシーが増加することになります。ライトスルー      Source: Scalability, availability, stability, patternsアプリケーションはキャッシュをメインのデータストアとして使い、そこにデータの読み書きを行います。一方、キャッシュはデータベースへの読み書きを担当します。アプリケーションはキャッシュにあるエントリを追加・更新しますキャッシュは同期的にデータストアに書き込みを行いますエントリを返しますアプリケーションコード:set_user(12345, {\""foo\"":\""bar\""})キャッシュコード:def set_user(user_id, values):    user = db.query(\""UPDATE Users WHERE id = {0}\"", user_id, values)    cache.set(user_id, user)ライトスルーは書き込み処理のせいで全体としては遅いオペレーションですが、書き込まれたばかりのデータに関する読み込みは速いです。ユーザー側は一般的にデータ更新時の方が読み込み時よりもレイテンシーに許容的です。キャッシュ内のデータは最新版で保たれます。欠点: ライトスルーノードが落ちたこと、もしくはスケーリングによって新しいノードが作成された時に、新しいノードはデータベース内のエントリーが更新されるまではエントリーをキャッシュしません。キャッシュアサイドとライトスルーを併用することでこの問題を緩和できます。書き込まれたデータの大部分は一度も読み込まれることはありません。このデータはTTLによって圧縮することができます。ライトビハインド (ライトバック)      Source: Scalability, availability, stability, patternsライトビハインドではアプリケーションは以下のことをします:キャッシュのエントリーを追加・更新しますデータストアへの書き込みを非同期的に行うことで、書き込みパフォーマンスを向上させます。欠点: ライトビハインドキャッシュがデータストア内のコンテンツにヒットする前にキャッシュが落ちるとデータ欠損が起きる可能性があります。キャッシュアサイドやライトスルーよりも実装が複雑になります。リフレッシュアヘッド      Source: From cache to in-memory data grid期限切れよりも前に、直近でアクセスされた全てのキャッシュエントリを自動的に更新するように設定することができます。もしどのアイテムが将来必要になるのかを正確に予測することができるのならば、リードスルーよりもレイテンシーを削減することができます。欠点: リフレッシュアヘッドどのアイテムが必要になるかの予測が正確でない場合にはリフレッシュアヘッドがない方がレイテンシーは良いという結果になってしまいます。欠点: キャッシュcache invalidationなどを用いて、データベースなどの真のデータとキャッシュの間の一貫性を保つ必要があります。Redisやmemcachedを追加することでアプリケーション構成を変更する必要があります。Cache invalidationも難しいですがそれに加えて、いつキャッシュを更新するかという複雑な問題にも悩まされることになります。その他の参考資料、ページFrom cache to in-memory data gridスケーラブルなシステムデザインパターンスケールできるシステムを設計するためのイントロダクションスケーラビリティ、可用性、安定性、パターンスケーラビリティAWS ElastiCacheのストラテジーWikipedia非同期処理      Source: Intro to architecting systems for scale非同期のワークフローはもし、連続的に行われるとリクエスト時間を圧迫してしまうような重い処理を別で処理する手法です。また、定期的にデータを集合させるなどの時間がかかるような処理を前もって処理しておくことにも役立ちます。メッセージキューメッセージキューはメッセージを受け取り、保存し、配信します。もし、処理がインラインで行うには遅すぎる場合、以下のようなワークフローでメッセージキューを用いるといいでしょう:アプリケーションはジョブをキューに配信し、ユーザーにジョブステータスを伝えます。ワーカーがジョブキューから受け取って、処理を行い、終了したらそのシグナルを返します。ユーザーの処理が止まることはなく、ジョブはバックグラウンドで処理されます。この間に、クライアントはオプションとして、タスクが完了したかのように見せるために小規模の処理を行います。例えば、ツイートを投稿するときに、ツイートはすぐにあなたのタイムラインに反映されたように見えますが、そのツイートが実際に全てのフォロワーに配信されるまでにはもう少し時間がかかっているでしょう。Redis はシンプルなメッセージ仲介としてはいいですが、メッセージが失われてしまう可能性があります。RabbitMQ はよく使われていますが、'AMQP'プロトコルに対応して、自前のノードを立てる必要があります。Amazon SQS という選択肢もありますが、レイテンシーが高く、メッセージが重複して配信されてしまう可能性があります。タスクキュータスクキューはタスクとその関連するデータを受け取り、処理した上でその結果を返します。スケジュール管理をできるほか、バックグラウンドでとても重いジョブをこなすこともできます。Celery はスケジューリングとpythonのサポートがあります。バックプレッシャーもし、キューが拡大しすぎると、メモリーよりもキューの方が大きくなりキャッシュミスが起こり、ディスク読み出しにつながり、パフォーマンスが低下することにつながります。バックプレッシャーはキューサイズを制限することで回避することができ、高いスループットを確保しキューにすでにあるジョブについてのレスポンス時間を短縮できます。キューがいっぱいになると、クライアントはサーバービジーもしくはHTTP 503をレスポンスとして受け取りまた後で時間をおいてアクセスするようにメッセージを受け取ります。クライアントはexponential backoffなどによって後ほど再度時間を置いてリクエストすることができます。欠点: 非同期処理キューを用いることで遅延が起こり、複雑さも増すため、あまり重くない計算処理やリアルタイムワークフローにおいては同期処理の方がいいでしょう。その他の参考資料、ページIt's all a numbers gameオーバーロードした時にバックプレッシャーを適用するLittle's lawメッセージキューとタスクキューの違いとは？通信      Source: OSI 7 layer modelHypertext transfer protocol (HTTP)HTTP はクライアントとサーバー間でのデータをエンコードして転送するための手法です。リクエスト・レスポンスに関わるプロトコルです。クライアントがリクエストをサーバーに投げ、サーバーがリクエストに関係するコンテンツと完了ステータス情報をレスポンスとして返します。HTTPは自己完結するので、間にロードバランサー、キャッシュ、エンクリプション、圧縮などのどんな中間ルーターが入っても動くようにできています。基本的なHTTPリクエストはHTTP動詞(メソッド)とリソース(エンドポイント)で成り立っています。以下がよくあるHTTP動詞です。:動詞詳細冪等性*セーフキャッシュできるかGETリソースを読み取るYesYesYesPOSTリソースを作成するもしくはデータを処理するトリガーNoNoYes レスポンスが新しい情報を含む場合PUTリソースを作成もしくは入れ替えるYesNoNoPATCHリソースを部分的に更新するNoNoYes レスポンスが新しい情報を含む場合DELETEリソースを削除するYesNoNo何度呼んでも同じ結果が返ってくることHTTPはTCP や UDP などの低級プロトコルに依存しているアプリケーションレイヤーのプロトコルである。その他の参考資料、ページ: HTTPHTTPってなに?HTTP と TCPの違いPUT と PATCHの違い伝送制御プロトコル (TCP)      Source: How to make a multiplayer gameTCPはIP networkの上で成り立つ接続プロトコルです。接続はhandshakeによって開始、解除されます。全ての送信されたパケットは欠損なしで送信先に送信された順番で到達するように以下の方法で保証されています:シーケンス番号とchecksum fieldsが全てのパケットに用意されているAcknowledgementパケットと自動再送信もし送信者が正しいレスポンスを受け取らなかったとき、パケットを再送信します。複数のタイムアウトがあったとき、接続は解除されます。TCP はフロー制御 と 輻輳制御も実装しています。これらの機能によって速度は低下し、一般的にUDPよりも非効率な転送手段になっています。ハイスループットを実現するために、ウェブサーバーはかなり大きな数のTCP接続を開いておくことがあり、そのことでメモリー使用が圧迫されます。ウェブサーバスレッドと例えばmemcached サーバーの間で多数のコネクションを保っておくことは高くつくかもしれません。可能なところではUDPに切り替えるだけでなくコネクションプーリングなども役立つかもしれません。TCPは高い依存性を要し、時間制約が厳しくないものに適しているでしょう。ウェブサーバー、データベース情報、SMTP、FTPやSSHなどの例に適用されます。以下の時にUDPよりもTCPを使うといいでしょう:全てのデータが欠損することなしに届いてほしいネットワークスループットの最適な自動推測をしてオペレーションしたいユーザデータグラムプロトコル (UDP)      Source: How to make a multiplayer gameUDPはコネクションレスです。データグラム（パケットのようなもの）はデータグラムレベルでの保証しかされません。データグラムは順不同で受け取り先に到着したりそもそも着かなかったりします。UDPは輻輳制御をサポートしません。TCPにおいてはサポートされているこれらの保証がないため、UDPは一般的に、TCPよりも効率的です。UDPはサブネット上のすべての機器にデータグラムを送信することができます。これはDHCP において役に立ちます。というのも、クライアントはまだIPアドレスを取得していないので、IPアドレスを必要とするTCPによるストリームができないからです。UDPは信頼性の面では劣りますが、VoIP、ビデオチャット、ストリーミングや同時通信マルチプレイヤーゲームなどのリアルタイム性が重視される時にはとても効果的です。TCPよりもUDPを使うのは:レイテンシーを最低限に抑えたい時データ欠損よりも、データ遅延を重視するときエラー修正を自前で実装したいときその他の参考資料、ページ: TCP と UDPゲームプログラミングのためのネットワークTCP と UDP プロトコルの主な違いTCP と UDPの違いTransmission control protocolUser datagram protocolFacebookのメムキャッシュスケーリング遠隔手続呼出 (RPC)      Source: Crack the system design interviewRPCではクライアントがリモートサーバーなどの異なるアドレス空間でプロシージャーが処理されるようにします。プロシージャーはローカルでのコールのように、クライアントからサーバーにどのように通信するかという詳細を省いた状態でコードが書かれます。リモートのコールは普通、ローカルのコールよりも遅く、信頼性に欠けるため、RPCコールをローカルコールと区別させておくことが好ましいでしょう。人気のRPCフレームワークは以下です。Protobuf、 Thrift、AvroRPC は リクエストレスポンスプロトコル:クライアントプログラム - クライアントスタブプロシージャーを呼び出します。パラメータはローカルでのプロシージャーコールのようにスタックへとプッシュされていきます。クライアントスタブプロシージャー - プロシージャIDとアーギュメントをパックしてリクエストメッセージにします。クライアント通信モジュール - OSがクライアントからサーバーへとメッセージを送ります。サーバー通信モジュール - OSが受け取ったパケットをサーバースタブプロシージャーに受け渡します。サーバースタブプロシージャー -  結果を展開し、プロシージャーIDにマッチするサーバープロシージャーを呼び出し、結果を返します。サーバーレスポンスは上記のステップを逆順で繰り返します。Sample RPC calls:GET /someoperation?data=anIdPOST /anotheroperation{  \""data\"":\""anId\"";  \""anotherdata\"": \""another value\""}RPCは振る舞いを公開することに焦点を当てています。RPCは内部通信パフォーマンスを理由として使われることが多いです。というのも、使用する状況に合わせてネイティブコールを自作することができるからです。ネイティブライブラリー (aka SDK) を呼ぶのは以下の時:ターゲットのプラットフォームを知っている時ロジックがどのようにアクセスされるのかを管理したいときライブラリー外でエラーがどのようにコントロールされるかを管理したい時パフォーマンスとエンドユーザーエクスペリエンスが最優先の時REST プロトコルに従うHTTP APIはパブリックAPIにおいてよく用いられます。欠点: RPCRPCクライアントとはサービス実装により厳密に左右されることになります。新しいオペレーション、使用例があるたびに新しくAPIが定義されなければなりません。RPCをデバッグするのは難しい可能性があります。既存のテクノロジーをそのまま使ってサービスを構築することはできないかもしれません。例えば、SquidなどのサーバーにRPCコールが正しくキャッシュ されるように追加で骨を折る必要があるかもしれません。Representational state transfer (REST)RESTは、クライアントがサーバーによってマネージされるリソースに対して処理を行うクライアント・サーバーモデルを支持するアーキテキチャスタイルです。サーバーは操作できるもしくは新しいリソースレプレゼンテーションを受け取ることができるようなリソースやアクションのレプレゼンテーションを提供します。すべての通信はステートレスでキャッシュ可能でなければなりません。RESTful なインターフェースには次の四つの特徴があります:特徴的なリソース (URI in HTTP) - どのオペレーションであっても同じURIを使う。HTTP動詞によって変わる (Verbs in HTTP) - 動詞、ヘッダー、ボディを使う自己説明的なエラーメッセージ (status response in HTTP) - ステータスコードを使い、新しく作ったりしないこと。HATEOAS (HTML interface for HTTP) - 自分のwebサービスがブラウザで完全にアクセスできること。サンプル REST コール:GET /someresources/anIdPUT /someresources/anId{\""anotherdata\"": \""another value\""}RESTはデータを公開することに焦点を当てています。クライアントとサーバーのカップリングを最小限にするもので、パブリックAPIなどによく用いられます。RESTはURI、 representation through headers、そして、GET、POST、PUT、 DELETE、PATCHなどのHTTP動詞等のよりジェネリックで統一されたメソッドを用います。ステートレスであるのでRESTは水平スケーリングやパーティショニングに最適です。欠点: RESTRESTはデータ公開に焦点を当てているので、リソースが自然に整理されていなかったり、シンプルなヒエラルキーで表せられない時にはよい選択肢とは言えないかもしれません。例えば、とあるイベントのセットにマッチするすべての更新情報を返すと言った処理は簡単にはパスで表現することができません。RESTでは、URIパス、クエリパラメータ、そして場合によってはリクエストボディなどによって実装されることが多いでしょう。RESTは少数の動詞に依存しています(GET、POST、PUT、DELETE、そして PATCH) が時には使いたい事例に合わないことがあります。例えば、期限の切れたドキュメントをアーカイブに移したい場合などはこれらの動詞の中には綺麗にはフィットしません。ネストされたヒエラルキーの中にあるリソースをとってくるのはシングルビューを描画するのにクライアントとサーバー間で数回やりとりしなければなりません。例として、ブログエントリーのコンテンツとそれに対するコメントを表示する場合などです。様々なネットワーク環境で動作する可能性が考えられるモバイルアプリケーションにおいてはこのような複数のやり取りは好ましくありません。時が経つにつれて、APIレスポンスにより多くのフィールドが与えられて、古いクライアントはすでにいらないものも含めてすべてのデータフィールドを受け取ることになります。そのことで、ペイロードが大きくなりすぎて、レイテンシーも拡大することになります。RPCとREST比較OperationRPCRESTサインアップPOST /signupPOST /personsリザインPOST /resign{\""personid\"": \""1234\""}DELETE /persons/1234Person読み込みGET /readPerson?personid=1234GET /persons/1234Personのアイテムリスト読み込みGET /readUsersItemsList?personid=1234GET /persons/1234/itemsPersonのアイテムへのアイテム追加POST /addItemToUsersItemsList{\""personid\"": \""1234\"";\""itemid\"": \""456\""}POST /persons/1234/items{\""itemid\"": \""456\""}アイテム更新POST /modifyItem{\""itemid\"": \""456\"";\""key\"": \""value\""}PUT /items/456{\""key\"": \""value\""}アイテム削除POST /removeItem{\""itemid\"": \""456\""}DELETE /items/456  Source: Do you really know why you prefer REST over RPCその他の参考資料、ページ: REST と RPCDo you really know why you prefer REST over RPCWhen are RPC-ish approaches more appropriate than REST?REST vs JSON-RPCDebunking the myths of RPC and RESTWhat are the drawbacks of using RESTCrack the system design interviewThriftWhy REST for internal use and not RPCセキュリティこのセクションは更新が必要です。contributingしてください！セキュリティは幅広いトピックです。十分な経験、セキュリティ分野のバックグラウンドがなくても、セキュリティの知識を要する職に応募するのでない限り、基本以上のことを知る必要はないでしょう。情報伝達、保存における暗号化XSS や SQL injectionを防ぐために、全てのユーザー入力もしくはユーザーに露出される入力パラメーターをサニタイズするSQL injectionを防ぐためにパラメータ化されたクエリを用いる。least privilegeの原理を用いるその他の参考資料、ページ:開発者のためのセキュリティガイドOWASP top ten補遺暗算で、推計値を求める必要があることも時にはあります。例えば、ディスクから100枚イメージ分のサムネイルを作る時間を求めたり、その時にどれだけディスクメモリーが消費されるかなどの値です。2の乗数表 と 全てのプログラマーが知るべきレイテンシー値 は良い参考になるでしょう。2の乗数表乗数           厳密な値         約        Bytes---------------------------------------------------------------7                             1288                             25610                           1024   1 thousand           1 KB16                         65,536                       64 KB20                      1,048,576   1 million            1 MB30                  1,073,741,824   1 billion            1 GB32                  4,294,967,296                        4 GB40              1,099,511,627,776   1 trillion           1 TBその他の参考資料、ページ:2の乗数表全てのプログラマーが知るべきレイテンシー値Latency Comparison Numbers--------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy            10,000   ns       10 usSend 1 KB bytes over 1 Gbps network     10,000   ns       10 usRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSDRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSDSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 msNotes-----1 ns = 10^-9 seconds1 us = 10^-6 seconds = 1,000 ns1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns上記表に基づいた役に立つ数値:ディスクからの連続読み取り速度 30 MB/s1 Gbps Ethernetからの連続読み取り速度　100 MB/sSSDからの連続読み取り速度 1 GB/smain memoryからの連続読み取り速度 4 GB/s1秒で地球6-7周できる1秒でデータセンターと2000周やりとりできるレイテンシーの視覚的表その他の参考資料、ページ:全てのプログラマーが知るべきレイテンシー値 - 1全てのプログラマーが知るべきレイテンシー値 - 2Designs, lessons, and advice from building large distributed systemsSoftware Engineering Advice from Building Large-Scale Distributed Systems他のシステム設計面接例題頻出のシステム設計面接課題とその解答へのリンク質問解答Dropboxのようなファイル同期サービスを設計するyoutube.comGoogleのような検索エンジンの設計queue.acm.orgstackexchange.comardendertat.comstanford.eduGoogleのようなスケーラブルなwebクローラーの設計quora.comGoogle docsの設計code.google.comneil.fraser.nameRedisのようなキーバリューストアの設計slideshare.netMemcachedのようなキャッシュシステムの設計slideshare.netAmazonのようなレコメンデーションシステムの設計hulu.comijcai13.orgBitlyのようなURL短縮サービスの設計n00tc0d3r.blogspot.comWhatsAppのようなチャットアプリの設計highscalability.comInstagramのような写真共有サービスの設計highscalability.comhighscalability.comFacebookニュースフィードの設計quora.comquora.comslideshare.netFacebookタイムラインの設計facebook.comhighscalability.comFacebookチャットの設計erlang-factory.comfacebook.comFacebookのようなgraph検索の設計facebook.comfacebook.comfacebook.comCloudFlareのようなCDNの設計cmu.eduTwitterのトレンド機能の設計michael-noll.comsnikolov .wordpress.comランダムID発行システムの設計blog.twitter.comgithub.com一定のインターバル時間での上位k件を返すucsb.eduwpi.edu複数のデータセンターからデータを配信するサービスの設計highscalability.comオンラインの複数プレイヤーカードゲームの設計indieflashblog.combuildnewgames.comガーベッジコレクションシステムの設計stuffwithstuff.comwashington.eduシステム設計例題を追加するContribute実世界のアーキテクチャ世の中のシステムがどのように設計されているかについての記事      Source: Twitter timelines at scale以下の記事の重箱の隅をつつくような細かい詳細にこだわらないこと。むしろ共通の原理、技術、パターンを探ることそれぞれのコンポーネントでどんな問題が解決され、コンポーネントはどこでうまく使えもしくは使えないかを知ること学んだことを復習すること種類システム参考ページデータ処理MapReduce - Googleの分散データ処理システムresearch.google.comデータ処理Spark - Databricksの分散データ処理システムslideshare.netデータ処理Storm - Twitterの分散データ処理システムslideshare.netデータストアBigtable - Googleのカラム指向分散データベースharvard.eduデータストアHBase - Bigtableのオープンソース実装slideshare.netデータストアCassandra - Facebookのカラム指向分散データベースslideshare.netデータストアDynamoDB - Amazonのドキュメント指向分散データベースharvard.eduデータストアMongoDB - ドキュメント指向分散データベースslideshare.netデータストアSpanner - Googleのグローバル分散データベースresearch.google.comデータストアMemcached - 分散メモリーキャッシングシステムslideshare.netデータストアRedis - 永続性とバリュータイプを兼ね備えた分散メモリーキャッシングシステムslideshare.netファイルシステムGoogle File System (GFS) - 分散ファイルシステムresearch.google.comファイルシステムHadoop File System (HDFS) - GFSのオープンソース実装apache.orgMiscChubby - 疎結合の分散システムをロックするGoogleのサービスresearch.google.comMiscDapper - 分散システムを追跡するインフラresearch.google.comMiscKafka - LinkedInによるPub/subメッセージキューslideshare.netMiscZookeeper - 同期を可能にする中央集権インフラとサービスslideshare.netアーキテクチャを追加するContribute各企業のアーキテクチャ企業参考ページAmazonAmazon architectureCinchcastProducing 1,500 hours of audio every dayDataSiftRealtime datamining At 120,000 tweets per secondDropBoxHow we've scaled DropboxESPNOperating At 100,000 duh nuh nuhs per secondGoogleGoogle architectureInstagram14 million users, terabytes of photosWhat powers InstagramJustin.tvJustin.Tv's live video broadcasting architectureFacebookScaling memcached at FacebookTAO: Facebook’s distributed data store for the social graphFacebook’s photo storageFlickrFlickr architectureMailboxFrom 0 to one million users in 6 weeksPinterestFrom 0 To 10s of billions of page views a month18 million visitors, 10x growth, 12 employeesPlayfish50 million monthly users and growingPlentyOfFishPlentyOfFish architectureSalesforceHow they handle 1.3 billion transactions a dayStack OverflowStack Overflow architectureTripAdvisor40M visitors, 200M dynamic page views, 30TB dataTumblr15 billion page views a monthTwitterMaking Twitter 10000 percent fasterStoring 250 million tweets a day using MySQL150M active users, 300K QPS, a 22 MB/S firehoseTimelines at scaleBig and small data at TwitterOperations at Twitter: scaling beyond 100 million usersUberHow Uber scales their real-time market platformWhatsAppThe WhatsApp architecture Facebook bought for $19 billionYouTubeYouTube scalabilityYouTube architecture企業のエンジニアブログ面接を受ける企業のアーキテクチャ投げられる質問は同じ分野から来ることもあるでしょうAirbnb EngineeringAtlassian DevelopersAutodesk EngineeringAWS BlogBitly Engineering BlogBox BlogsCloudera Developer BlogDropbox Tech BlogEngineering at QuoraEbay Tech BlogEvernote Tech BlogEtsy Code as CraftFacebook EngineeringFlickr CodeFoursquare Engineering BlogGitHub Engineering BlogGoogle Research BlogGroupon Engineering BlogHeroku Engineering BlogHubspot Engineering BlogHigh ScalabilityInstagram EngineeringIntel Software BlogJane Street Tech BlogLinkedIn EngineeringMicrosoft EngineeringMicrosoft Python EngineeringNetflix Tech BlogPaypal Developer BlogPinterest Engineering BlogQuora EngineeringReddit BlogSalesforce Engineering BlogSlack Engineering BlogSpotify LabsTwilio Engineering BlogTwitter EngineeringUber Engineering BlogYahoo Engineering BlogYelp Engineering BlogZynga Engineering Blogその他の参考資料、ページ:kilimchoi/engineering-blogsここにあるリストは比較的小規模なものにとどめ、kilimchoi/engineering-blogsにより詳細に記すことで重複しないようにしておくことにする。エンジニアブログへのリンクを追加する場合はここではなく、engineering-blogsレボジトリに追加することを検討してください。進行中の作業セクションの追加や、進行中の作業を手伝っていただける場合はこちら!MapReduceによる分散コンピューティングConsistent hashingScatter gatherContributeクレジットクレジット及び、参照ページは適時このリポジトリ内に記載してありますSpecial thanks to:Hired in techCracking the coding interviewHigh scalabilitycheckcheckzz/system-design-interviewshashank88/system_designmmcgrana/services-engineeringSystem design cheat sheetA distributed systems reading listCracking the system design interviewContact infoFeel free to contact me to discuss any issues, questions, or comments.My contact info can be found on my GitHub page.LicenseI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2017 Donne MartinCreative Commons Attribution 4.0 International License (CC BY 4.0)http://creativecommons.org/licenses/by/4.0/"
49,AUTOMATIC1111/stable-diffusion-webui,https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/README.md,Python,"Stable Diffusion web UIA browser interface based on Gradio library for Stable Diffusion.FeaturesDetailed feature showcase with images:Original txt2img and img2img modesOne click install and run script (but you still must install python and git)OutpaintingInpaintingColor SketchPrompt MatrixStable Diffusion UpscaleAttention, specify parts of text that the model should pay more attention toa man in a ((tuxedo)) - will pay more attention to tuxedoa man in a (tuxedo:1.21) - alternative syntaxselect text and press Ctrl+Up or Ctrl+Down (or Command+Up or Command+Down if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)Loopback, run img2img processing multiple timesX/Y/Z plot, a way to draw a 3 dimensional plot of images with different parametersTextual Inversionhave as many embeddings as you want and use any names you like for themuse multiple embeddings with different numbers of vectors per tokenworks with half precision floating point numberstrain embeddings on 8GB (also reports of 6GB working)Extras tab with:GFPGAN, neural network that fixes facesCodeFormer, face restoration tool as an alternative to GFPGANRealESRGAN, neural network upscalerESRGAN, neural network upscaler with a lot of third party modelsSwinIR and Swin2SR (see here), neural network upscalersLDSR, Latent diffusion super resolution upscalingResizing aspect ratio optionsSampling method selectionAdjust sampler eta values (noise multiplier)More advanced noise setting optionsInterrupt processing at any time4GB video card support (also reports of 2GB working)Correct seeds for batchesLive prompt token length validationGeneration parametersparameters you used to generate images are saved with that imagein PNG chunks for PNG, in EXIF for JPEGcan drag the image to PNG info tab to restore generation parameters and automatically copy them into UIcan be disabled in settingsdrag and drop an image/text-parameters to promptboxRead Generation Parameters Button, loads parameters in promptbox to UISettings pageRunning arbitrary python code from UI (must run with --allow-code to enable)Mouseover hints for most UI elementsPossible to change defaults/mix/max/step values for UI elements via text configTiling support, a checkbox to create images that can be tiled like texturesProgress bar and live image generation previewCan use a separate neural network to produce previews with almost none VRAM or compute requirementNegative prompt, an extra text field that allows you to list what you don't want to see in generated imageStyles, a way to save part of prompt and easily apply them via dropdown laterVariations, a way to generate same image but with tiny differencesSeed resizing, a way to generate same image but at slightly different resolutionCLIP interrogator, a button that tries to guess prompt from an imagePrompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midwayBatch Processing, process a group of files using img2imgImg2img Alternative, reverse Euler method of cross attention controlHighres Fix, a convenience option to produce high resolution pictures in one click without usual distortionsReloading checkpoints on the flyCheckpoint Merger, a tab that allows you to merge up to 3 checkpoints into oneCustom scripts with many extensions from communityComposable-Diffusion, a way to use multiple prompts at onceseparate prompts using uppercase ANDalso supports weights for prompts: a cat :1.2 AND a dog AND a penguin :2.2No token limit for prompts (original stable diffusion lets you use up to 75 tokens)DeepDanbooru integration, creates danbooru style tags for anime promptsxformers, major speed increase for select cards: (add --xformers to commandline args)via extension: History tab: view, direct and delete images conveniently within the UIGenerate forever optionTraining tabhypernetworks and embeddings optionsPreprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)Clip skipHypernetworksLoras (same as Hypernetworks but more pretty)A sparate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your promptCan select to load a different VAE from settings screenEstimated completion time in progress barAPISupport for dedicated inpainting model by RunwayMLvia extension: Aesthetic Gradients, a way to generate images with a specific aesthetic by using clip images embeds (implementation of https://github.com/vicgalle/stable-diffusion-aesthetic-gradients)Stable Diffusion 2.0 support - see wiki for instructionsAlt-Diffusion support - see wiki for instructionsNow without any bad letters!Load checkpoints in safetensors formatEased resolution restriction: generated image's domension must be a multiple of 8 rather than 64Now with a license!Reorder elements in the UI from settings screenInstallation and RunningMake sure the required dependencies are met and follow the instructions available for both NVidia (recommended) and AMD GPUs.Alternatively, use online services (like Google Colab):List of Online ServicesInstallation on Windows 10/11 with NVidia-GPUs using release packageDownload sd.webui.zip from v1.0.0-pre and extract it's contents.Run update.bat.Run run.bat.For more details see Install-and-Run-on-NVidia-GPUsAutomatic Installation on WindowsInstall Python 3.10.6 (Newer version of Python does not support torch), checking \""Add Python to PATH\"".Install git.Download the stable-diffusion-webui repository, for example by running git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git.Run webui-user.bat from Windows Explorer as normal, non-administrator, user.Automatic Installation on LinuxInstall the dependencies:# Debian-based:sudo apt install wget git python3 python3-venv# Red Hat-based:sudo dnf install wget git python3# Arch-based:sudo pacman -S wget git python3Navigate to the directory you would like the webui to be installed and execute the following command:bash <(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)Run webui.sh.Check webui-user.sh for options.Installation on Apple SiliconFind the instructions here.ContributingHere's how to add code to this repo: ContributingDocumentationThe documentation was moved from this README over to the project's wiki.For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) crawlable wiki.CreditsLicenses for borrowed code can be found in Settings -> Licenses screen, and also in html/licenses.html file.Stable Diffusion - https://github.com/CompVis/stable-diffusion, https://github.com/CompVis/taming-transformersk-diffusion - https://github.com/crowsonkb/k-diffusion.gitGFPGAN - https://github.com/TencentARC/GFPGAN.gitCodeFormer - https://github.com/sczhou/CodeFormerESRGAN - https://github.com/xinntao/ESRGANSwinIR - https://github.com/JingyunLiang/SwinIRSwin2SR - https://github.com/mv-lab/swin2srLDSR - https://github.com/Hafiidz/latent-diffusionMiDaS - https://github.com/isl-org/MiDaSIdeas for optimizations - https://github.com/basujindal/stable-diffusionCross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)Sub-quadratic Cross Attention layer optimization - Alex Birch (Birch-san/diffusers#1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we're not using his code, but we are using his ideas).Idea for SD upscale - https://github.com/jquesnelle/txt2imghdNoise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-botCLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogatorIdea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorchxformers - https://github.com/facebookresearch/xformersDeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooruSampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pixSecurity advice - RyotaKUniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPCTAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesdLyCORIS - KohakuBlueleafInitial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.(You)"
50,geekcomputers/Python,https://github.com/geekcomputers/Python/blob/master/README.md,Python,"My Python Eggs 🐍 😄I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in Notepad++ 🗒️Feel free to explore the scripts and use them for your learning and automation needs!List of Scripts:batch_file_rename.py - Batch rename a group of files in a specified directory, changing their extensions.create_dir_if_not_there.py - Check if a directory exists in the user's home directory. Create it if it doesn't exist.Fast Youtube Downloader - Download YouTube videos quickly with parallel threads using aria2c.Google Image Downloader - Query a given term and retrieve images from the Google Image database.dir_test.py - Test if the directory testdir exists. If not, create it.env_check.py - Check if all the required environment variables are set.blackjack.py - Casino Blackjack-21 game in Python.fileinfo.py - Show file information for a given file.folder_size.py - Scan the current directory and all subdirectories and display their sizes.logs.py - Search for all *.log files in a directory, zip them using the specified program, and date stamp them.move_files_over_x_days.py - Move all files over a specified age (in days) from the source directory to the destination directory.nslookup_check.py - Open the file server_list.txt and perform nslookup for each server to check the DNS entry.osinfo.py - Display information about the operating system on which the script is running.ping_servers.py - Ping the servers associated with the specified application group.ping_subnet.py - Scan the final range of a given IP subnet for available addresses.powerdown_startup.py - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.puttylogs.py - Zip all the logs in the given directory.script_count.py - Scan the scripts directory and count the different types of scripts.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.script_listing.py - List all files in a given directory and its subdirectories.testlines.py - Open a file and print out 100 lines of the set line variable.tweeter.py - Tweet text or a picture from the terminal.serial_scanner.py - List available serial ports in use on Linux and Windows systems.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.CountMillionCharacter.py and CountMillionCharacter2.0 - Get character count of a text file.xkcd_downloader.py - Download the latest XKCD comic and place them in a new folder called \""comics\"".timymodule.py - An alternative to Python's 'timeit' module and easier to use.calculator.py - Implement a calculator using Python's eval() function.Google_News.py - Use BeautifulSoup to provide latest news headlines along with news links.cricket_live_score - Use BeautifulSoup to provide live cricket scores.youtube.py - Take a song name as input and fetch the YouTube URL of the best matching song and play it.site_health.py - Check the health of a remote server.SimpleStopWatch.py - Simple stop watch implementation using Python's time module.Changemac.py - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).whatsapp-monitor.py - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.whatsapp-chat-analyzer.py - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.JARVIS.py - Control Windows programs with your voice.Images Downloader - Download images from webpages on Unix-based systems.space_invader.py.py - Classical 2D space invader game to recall your childhood memories.Test Case Generator - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.Note: The content in this repository belongs to the respective authors and creators. I'm just providing a formatted README.md for better presentation."
51,AntonOsika/gpt-engineer,https://github.com/AntonOsika/gpt-engineer/blob/main/README.md,Python,"GPT EngineerSpecify what you want it to build, the AI asks for clarification, and then builds it.GPT Engineer is made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt.DemoProject philosophySimple to get valueFlexible and easy to add new own \""AI steps\"". See steps.py.Incrementally build towards a user experience of:high level promptinggiving feedback to the AI that it will remember over timeFast handovers back and forth between AI and humanSimplicity, all computation is \""resumable\"" and persisted to the filesystemUsageChoose either stable or development.For stable release:python -m pip install gpt-engineerFor development:git clone https://github.com/AntonOsika/gpt-engineer.gitcd gpt-engineerpython -m pip install -e .(or: make install && source venv/bin/activate for a venv)API KeyEither just:export OPENAI_API_KEY=[your api key]Or:Create a copy of .env.template named .envAdd your OPENAI_API_KEY in .envCheck the Windows README for windows usage.RunningCreate an empty folder. If inside the repo, you can run:cp -r projects/example/ projects/my-new-projectFill in the prompt file in your new foldergpt-engineer projects/my-new-project(Note, gpt-engineer --help lets you see all available options. For example --steps use_feedback lets you improve/fix code in a project)By running gpt-engineer you agree to our terms.ResultsCheck the generated files in projects/my-new-project/workspaceAlternativesYou can check Docker instructions to use Docker, or simplydo everything in your browser:FeaturesYou can specify the \""identity\"" of the AI agent by editing the files in the preprompts folder.Editing the preprompts, and evolving how you write the project prompt, is how you make the agent remember things between projects.Each step in steps.py will have its communication history with GPT4 stored in the logs folder, and can be rerun with scripts/rerun_edited_message_logs.py.VisionThe gpt-engineer community is building the open platform for devs to tinker with and build their personal code-generation toolbox.If you are interested in contributing to this, we would be interested in having you.If you want to see our broader ambitions, check out the roadmap, and joindiscordto get input on how you can contribute to it.We are currently looking for more maintainers and community organizers. Email anton.osika@gmail.com if you are interested in an official role.Example              Demo.mov          "
52,facebookresearch/Detectron,https://github.com/facebookresearch/Detectron/blob/main/README.md,Python,"Detectron is deprecated. Please see detectron2, a ground-up rewrite of Detectron in PyTorch.DetectronDetectron is Facebook AI Research's software system that implements state-of-the-art object detection algorithms, including Mask R-CNN. It is written in Python and powered by the Caffe2 deep learning framework.At FAIR, Detectron has enabled numerous research projects, including: Feature Pyramid Networks for Object Detection, Mask R-CNN, Detecting and Recognizing Human-Object Interactions, Focal Loss for Dense Object Detection, Non-local Neural Networks, Learning to Segment Every Thing, Data Distillation: Towards Omni-Supervised Learning, DensePose: Dense Human Pose Estimation In The Wild, and Group Normalization.    Example Mask R-CNN output.IntroductionThe goal of Detectron is to provide a high-quality, high-performancecodebase for object detection research. It is designed to be flexible in orderto support rapid implementation and evaluation of novel research. Detectronincludes implementations of the following object detection algorithms:Mask R-CNN -- Marr Prize at ICCV 2017RetinaNet -- Best Student Paper Award at ICCV 2017Faster R-CNNRPNFast R-CNNR-FCNusing the following backbone network architectures:ResNeXt{50,101,152}ResNet{50,101,152}Feature Pyramid Networks (with ResNet/ResNeXt)VGG16Additional backbone architectures may be easily implemented. For more details about these models, please see References below.Update4/2018: Support Group Normalization - see GN/README.mdLicenseDetectron is released under the Apache 2.0 license. See the NOTICE file for additional details.Citing DetectronIf you use Detectron in your research or wish to refer to the baseline results published in the Model Zoo, please use the following BibTeX entry.@misc{Detectron2018,  author =       {Ross Girshick and Ilija Radosavovic and Georgia Gkioxari and                  Piotr Doll\\'{a}r and Kaiming He},  title =        {Detectron},  howpublished = {\\url{https://github.com/facebookresearch/detectron}},  year =         {2018}}Model Zoo and BaselinesWe provide a large set of baseline results and trained models available for download in the Detectron Model Zoo.InstallationPlease find installation instructions for Caffe2 and Detectron in INSTALL.md.Quick Start: Using DetectronAfter installation, please see GETTING_STARTED.md for brief tutorials covering inference and training with Detectron.Getting HelpTo start, please check the troubleshooting section of our installation instructions as well as our FAQ. If you couldn't find help there, try searching our GitHub issues. We intend the issues page to be a forum in which the community collectively troubleshoots problems.If bugs are found, we appreciate pull requests (including adding Q&A's to FAQ.md and improving our installation instructions and troubleshooting documents). Please see CONTRIBUTING.md for more information about contributing to Detectron.ReferencesData Distillation: Towards Omni-Supervised Learning.Ilija Radosavovic, Piotr Dollár, Ross Girshick, Georgia Gkioxari, and Kaiming He.Tech report, arXiv, Dec. 2017.Learning to Segment Every Thing.Ronghang Hu, Piotr Dollár, Kaiming He, Trevor Darrell, and Ross Girshick.Tech report, arXiv, Nov. 2017.Non-Local Neural Networks.Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.Tech report, arXiv, Nov. 2017.Mask R-CNN.Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.IEEE International Conference on Computer Vision (ICCV), 2017.Focal Loss for Dense Object Detection.Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár.IEEE International Conference on Computer Vision (ICCV), 2017.Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour.Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.Tech report, arXiv, June 2017.Detecting and Recognizing Human-Object Interactions.Georgia Gkioxari, Ross Girshick, Piotr Dollár, and Kaiming He.Tech report, arXiv, Apr. 2017.Feature Pyramid Networks for Object Detection.Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.Aggregated Residual Transformations for Deep Neural Networks.Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.R-FCN: Object Detection via Region-based Fully Convolutional Networks.Jifeng Dai, Yi Li, Kaiming He, and Jian Sun.Conference on Neural Information Processing Systems (NIPS), 2016.Deep Residual Learning for Image Recognition.Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.Faster R-CNN: Towards Real-Time Object Detection with Region Proposal NetworksShaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.Conference on Neural Information Processing Systems (NIPS), 2015.Fast R-CNN.Ross Girshick.IEEE International Conference on Computer Vision (ICCV), 2015."
53,Jack-Cherish/Machine-Learning,https://github.com/Jack-Cherish/Machine-Learning/blob/master/README-eng.md,Python,"Machine-Learning中文（简体）Rome was not built in a dayBlogMachine-Learning in Practice (Detailed Comments + Training Datasets), Keep updating!Welcome to my[CSDN Column]Follow me on[Zhihu Column]QQ Group for Communication[328127489]My Website: http://cuijiahua.com/Article DebutDebut articles on my website and forward on orther platforms, click here to get the latest development: http://cuijiahua.com/Chapt. 2: K-Nearest Neighbors AlgorithmArticlePersonal WebsiteCSDNZhihuPython3  study notes (I): K-Nearest Neighbors Algorithm (Gorgeous and Splendid Tutorial)Personal WebsiteCSDNZhihuCode1. Entry Level k-NN2. Miss Helen Dating History3. Digits RecognitionChapt. 3: Decision TreeArticlePersonal WebsiteCSDNZhihuPython3  study notes (II): Decision Tree (Basic Concepts): Let's Start from DatingPersonal WebsiteCSDNZhihuPython3  study notes (III): Decision Tree (In Practice): I'm Looking for a Pair of Contact LensesPersonal WebsiteCSDNZhihuCode1. Loan Prediction2. Contact LensesChapt. 4: Navie BayesArticlePersonal WebsiteCSDNZhihuPython3 Python3  study notes (IV): Navie Bayes (Basic Concepts): Comment FilterPersonal WebsiteCSDNZhihuPython3 Python3  study notes (V): Navie Bayes (In Practice): Catalogues of Sina NewsPersonal WebsiteCSDNZhihuCode1. Comment Filter2. Spam Filter3. News CataloguesChapt. 5: Logistic RegressionArticlePersonal WebsiteCSDNZhihuPython3  study notes (VI): Logistic Regression (Basic Concepts): Gradient Ascent AlgorithmPersonal WebsiteCSDNZhihuPython3  study notes (VII): Logistic Regression (In Practice): Prediction of Horse MortalityPersonal WebsiteCSDNZhihuCode1. Entry Level Exercise for Logistic Regression2. Improved Random Gradient Ascent Algorithm3. Prediction of Horse MortalityChapt. 6: SVM (Support Vector Machine)ArticlePersonal WebsiteCSDNZhihuPython3  study notes (VIII): SVM (Basic Concepts): a Handcraft on Linear SVMPersonal WebsiteCSDNZhihuPython3  study notes (IX): SVM (In Practice): Another Handcraft on Nonlinear SVMPersonal WebsiteCSDNZhihuCode1. Simplified SMO Alogrithm2. Complete SMO Alogrithm3. Nonlinear SVM Alogrithm4. Sklearn SVCChapt. 7: AdaBoostArticlePersonal WebsiteCSDNZhihuPython3  study notes (X): Classifier Sharpener -- AdaBoostPersonal WebsiteCSDNZhihuCode1. Training Process of AdaBoost Based On Decision Stump2. AdaBoost on Hard Datasets3. Implement AdaBoost by sklearn4. ROC Curve PlotChapt. 8: Linear RegressionArticlePersonal WebsiteCSDNZhihuPython3  study notes (XI):Personal WebsiteCSDNZhihuPython3  study notes (XII):Personal WebsitenonoCode1. Linear Regression(Ordinary LR + Locally Weighted LR)2. Predicting the Age of Abalones(Ormers)3. Stepwise Regression4. Predicting the Price of Second Hand LegoChapt. 9: Regression TreeArticlePersonal WebsiteCSDNZhihuPython3  study notes (XIII): Regression Tree (Basic Concepts): CART Alogrithm and PruningPersonal WebsitenonoCode1. Regression Tree"
54,jenkins-docs/simple-python-pyinstaller-app,https://github.com/jenkins-docs/simple-python-pyinstaller-app/blob/master/README.md,Python,"simple-python-pyinstaller-appThis repository is for theBuild a Python app with PyInstallertutorial in the Jenkins User Documentation.The repository contains a simple Python application which is a command line tool \""add2vals\"" that outputs the addition of two values. If at least one of thevalues is a string, \""add2vals\"" treats both values as a string and insteadconcatenates the values. The \""add2\"" function in the \""calc\"" library (which\""add2vals\"" imports) is accompanied by a set of unit tests. These are tested with pytest to check that this function works as expected and the results are savedto a JUnit XML report.The delivery of the \""add2vals\"" tool through PyInstaller converts this tool intoa standalone executable file for Linux, which you can download through Jenkinsand execute at the command line on Linux machines without Python.The jenkins directory contains an example of the Jenkinsfile (i.e. Pipeline)you'll be creating yourself during the tutorial."
55,Turonk/character_creation_module,https://github.com/Turonk/character_creation_module/blob/main/README.md,Python,character_creation_moduleМодуль создания персонажа для RPG игры
56,yandex-praktikum/calc_and_win,https://github.com/yandex-praktikum/calc_and_win/blob/master/README.md,Python,"calc_and_winРепозиторий игры \""Рассчитай и победи!\"""
57,huggingface/pytorch-image-models,https://github.com/huggingface/pytorch-image-models/blob/main/README.md,Python,"PyTorch Image ModelsSponsorsWhat's NewIntroductionModelsFeaturesResultsGetting Started (Documentation)Train, Validation, Inference ScriptsAwesome PyTorch ResourcesLicensesCitingSponsorsThanks to the following for hardware support:TPU Research Cloud (TRC) (https://sites.research.google/trc/about/)Nvidia (https://www.nvidia.com/en-us/)And a big thanks to all GitHub sponsors who helped with some of my costs before I joined Hugging Face.What's New❗Updates after Oct 10, 2022 are available in version >= 0.9❗Many changes since the last 0.6.x stable releases. They were previewed in 0.8.x dev releases but not everyone transitioned.timm.models.layers moved to timm.layers:from timm.models.layers import name will still work via deprecation mapping (but please transition to timm.layers).import timm.models.layers.module or from timm.models.layers.module import name needs to be changed now.Builder, helper, non-model modules in timm.models have a _ prefix added, ie timm.models.helpers -> timm.models._helpers, there are temporary deprecation mapping files but those will be removed.All models now support architecture.pretrained_tag naming (ex resnet50.rsb_a1).The pretrained_tag is the specific weight variant (different head) for the architecture.Using only architecture defaults to the first weights in the default_cfgs for that model architecture.In adding pretrained tags, many model names that existed to differentiate were renamed to use the tag  (ex: vit_base_patch16_224_in21k -> vit_base_patch16_224.augreg_in21k). There are deprecation mappings for these.A number of models had their checkpoints remaped to match architecture changes needed to better support features_only=True, there are checkpoint_filter_fn methods in any model module that was remapped. These can be passed to timm.models.load_checkpoint(..., filter_fn=timm.models.swin_transformer_v2.checkpoint_filter_fn) to remap your existing checkpoint.The Hugging Face Hub (https://huggingface.co/timm) is now the primary source for timm weights. Model cards include link to papers, original source, license.Previous 0.6.x can be cloned from 0.6.x branch or installed via pip with version.Aug 3, 2023Add GluonCV weights for HRNet w18_small and w18_small_v2. Converted by SeeFunFix selecsls* model naming regressionPatch and position embedding for ViT/EVA works for bfloat16/float16 weights on load (or activations for on-the-fly resize)v0.9.5 release prepJuly 27, 2023Added timm trained seresnextaa201d_32x8d.sw_in12k_ft_in1k_384 weights (and .sw_in12k pretrain) with 87.3% top-1 on ImageNet-1k, best ImageNet ResNet family model I'm aware of.RepViT model and weights (https://arxiv.org/abs/2307.09283) added by wangaoI-JEPA ViT feature weights (no classifier) added by SeeFunSAM-ViT (segment anything) feature weights (no classifier) added by SeeFunAdd support for alternative feat extraction methods and -ve indices to EfficientNetAdd NAdamW optimizerMisc fixesMay 11, 2023timm 0.9 released, transition from 0.8.xdev releasesMay 10, 2023Hugging Face Hub downloading is now default, 1132 models on https://huggingface.co/timm, 1163 weights in timmDINOv2 vit feature backbone weights added thanks to Leng YueFB MAE vit feature backbone weights addedOpenCLIP DataComp-XL L/14 feat backbone weights addedMetaFormer (poolformer-v2, caformer, convformer, updated poolformer (v1)) w/ weights added by Fredo GuanExperimental get_intermediate_layers function on vit/deit models for grabbing hidden states (inspired by DINO impl). This is WIP and may change significantly... feedback welcome.Model creation throws error if pretrained=True and no weights exist (instead of continuing with random initialization)Fix regression with inception / nasnet TF sourced weights with 1001 classes in original classifiersbitsandbytes (https://github.com/TimDettmers/bitsandbytes) optimizers added to factory, use bnb prefix, ie bnbadam8bitMisc cleanup and fixesFinal testing before switching to a 0.9 and bringing timm out of pre-release stateApril 27, 202397% of timm models uploaded to HF Hub and almost all updated to support multi-weight pretrained configsMinor cleanup and refactoring of another batch of models as multi-weight added. More fused_attn (F.sdpa) and features_only support, and torchscript fixes.April 21, 2023Gradient accumulation support added to train script and tested (--grad-accum-steps), thanks Taeksang KimMore weights on HF Hub (cspnet, cait, volo, xcit, tresnet, hardcorenas, densenet, dpn, vovnet, xception_aligned)Added --head-init-scale and --head-init-bias to train.py to scale classiifer head and set fixed bias for fine-tuneRemove all InplaceABN (inplace_abn) use, replaced use in tresnet with standard BatchNorm (modified weights accordingly).April 12, 2023Add ONNX export script, validate script, helpers that I've had kicking around for along time. Tweak 'same' padding for better export w/ recent ONNX + pytorch.Refactor dropout args for vit and vit-like models, separate drop_rate into drop_rate (classifier dropout), proj_drop_rate (block mlp / out projections), pos_drop_rate (position embedding drop), attn_drop_rate (attention dropout). Also add patch dropout (FLIP) to vit and eva models.fused F.scaled_dot_product_attention support to more vit models, add env var (TIMM_FUSED_ATTN) to control, and config interface to enable/disableAdd EVA-CLIP backbones w/ image tower weights, all the way up to 4B param 'enormous' model, and 336x336 OpenAI ViT mode that was missed.April 5, 2023ALL ResNet models pushed to Hugging Face Hub with multi-weight supportAll past timm trained weights added with recipe based tags to differentiateAll ResNet strikes back A1/A2/A3 (seed 0) and R50 example B/C1/C2/D weights availableAdd torchvision v2 recipe weights to existing torchvision originalsSee comparison table in https://huggingface.co/timm/seresnextaa101d_32x8d.sw_in12k_ft_in1k_288#model-comparisonNew ImageNet-12k + ImageNet-1k fine-tunes available for a few anti-aliased ResNet modelsresnetaa50d.sw_in12k_ft_in1k - 81.7 @ 224, 82.6 @ 288resnetaa101d.sw_in12k_ft_in1k - 83.5 @ 224, 84.1 @ 288seresnextaa101d_32x8d.sw_in12k_ft_in1k - 86.0 @ 224, 86.5 @ 288seresnextaa101d_32x8d.sw_in12k_ft_in1k_288 - 86.5 @ 288, 86.7 @ 320March 31, 2023Add first ConvNext-XXLarge CLIP -> IN-1k fine-tune and IN-12k intermediate fine-tunes for convnext-base/large CLIP models.modeltop1top5img_sizeparam_countgmacsmactsconvnext_xxlarge.clip_laion2b_soup_ft_in1k88.61298.704256846.47198.09124.45convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_38488.31298.578384200.13101.11126.74convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_32087.96898.47320200.1370.2188.02convnext_base.clip_laion2b_augreg_ft_in12k_in1k_38487.13898.21238488.5945.2184.49convnext_base.clip_laion2b_augreg_ft_in12k_in1k86.34497.9725688.5920.0937.55Add EVA-02 MIM pretrained and fine-tuned weights, push to HF hub and update model cards for all EVA models. First model over 90% top-1 (99% top-5)! Check out the original code & weights at https://github.com/baaivision/EVA for more details on their work blending MIM, CLIP w/ many model, dataset, and train recipe tweaks.modeltop1top5param_countimg_sizeeva02_large_patch14_448.mim_m38m_ft_in22k_in1k90.05499.042305.08448eva02_large_patch14_448.mim_in22k_ft_in22k_in1k89.94699.01305.08448eva_giant_patch14_560.m30m_ft_in22k_in1k89.79298.9921014.45560eva02_large_patch14_448.mim_in22k_ft_in1k89.62698.954305.08448eva02_large_patch14_448.mim_m38m_ft_in1k89.5798.918305.08448eva_giant_patch14_336.m30m_ft_in22k_in1k89.5698.9561013.01336eva_giant_patch14_336.clip_ft_in1k89.46698.821013.01336eva_large_patch14_336.in22k_ft_in22k_in1k89.21498.854304.53336eva_giant_patch14_224.clip_ft_in1k88.88298.6781012.56224eva02_base_patch14_448.mim_in22k_ft_in22k_in1k88.69298.72287.12448eva_large_patch14_336.in22k_ft_in1k88.65298.722304.53336eva_large_patch14_196.in22k_ft_in22k_in1k88.59298.656304.14196eva02_base_patch14_448.mim_in22k_ft_in1k88.2398.56487.12448eva_large_patch14_196.in22k_ft_in1k87.93498.504304.14196eva02_small_patch14_336.mim_in22k_ft_in1k85.7497.61422.13336eva02_tiny_patch14_336.mim_in22k_ft_in1k80.65895.5245.76336Multi-weight and HF hub for DeiT and MLP-Mixer based modelsMarch 22, 2023More weights pushed to HF hub along with multi-weight support, including: regnet.py, rexnet.py, byobnet.py, resnetv2.py, swin_transformer.py, swin_transformer_v2.py, swin_transformer_v2_cr.pySwin Transformer models support feature extraction (NCHW feat maps for swinv2_cr_*, and NHWC for all others) and spatial embedding outputs.FocalNet (from https://github.com/microsoft/FocalNet) models and weights added with significant refactoring, feature extraction, no fixed resolution / sizing constraintRegNet weights increased with HF hub push, SWAG, SEER, and torchvision v2 weights. SEER is pretty poor wrt to performance for model size, but possibly useful.More ImageNet-12k pretrained and 1k fine-tuned timm weights:rexnetr_200.sw_in12k_ft_in1k - 82.6 @ 224, 83.2 @ 288rexnetr_300.sw_in12k_ft_in1k - 84.0 @ 224, 84.5 @ 288regnety_120.sw_in12k_ft_in1k - 85.0 @ 224, 85.4 @ 288regnety_160.lion_in12k_ft_in1k - 85.6 @ 224, 86.0 @ 288regnety_160.sw_in12k_ft_in1k - 85.6 @ 224, 86.0 @ 288  (compare to SWAG PT + 1k FT this is same BUT much lower res, blows SEER FT away)Model name deprecation + remapping functionality added (a milestone for bringing 0.8.x out of pre-release). Mappings being added...Minor bug fixes and improvements.Feb 26, 2023Add ConvNeXt-XXLarge CLIP pretrained image tower weights for fine-tune & features (fine-tuning TBD) -- see model cardUpdate convnext_xxlarge default LayerNorm eps to 1e-5 (for CLIP weights, improved stability)0.8.15dev0Feb 20, 2023Add 320x320 convnext_large_mlp.clip_laion2b_ft_320 and convnext_lage_mlp.clip_laion2b_ft_soup_320 CLIP image tower weights for features & fine-tune0.8.13dev0 pypi release for latest changes w/ move to huggingface orgFeb 16, 2023safetensor checkpoint support addedAdd ideas from 'Scaling Vision Transformers to 22 B. Params' (https://arxiv.org/abs/2302.05442) -- qk norm, RmsNorm, parallel blockAdd F.scaled_dot_product_attention support (PyTorch 2.0 only) to vit_*, vit_relpos*, coatnet / maxxvit (to start)Lion optimizer (w/ multi-tensor option) added (https://arxiv.org/abs/2302.06675)gradient checkpointing works with features_only=TrueFeb 7, 2023New inference benchmark numbers added in results folder.Add convnext LAION CLIP trained weights and initial set of in1k fine-tunesconvnext_base.clip_laion2b_augreg_ft_in1k - 86.2% @ 256x256convnext_base.clip_laiona_augreg_ft_in1k_384 - 86.5% @ 384x384convnext_large_mlp.clip_laion2b_augreg_ft_in1k - 87.3% @ 256x256convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384 - 87.9% @ 384x384Add DaViT models. Supports features_only=True. Adapted from https://github.com/dingmyu/davit by Fredo.Use a common NormMlpClassifierHead across MaxViT, ConvNeXt, DaViTAdd EfficientFormer-V2 model, update EfficientFormer, and refactor LeViT (closely related architectures). Weights on HF hub.New EfficientFormer-V2 arch, significant refactor from original at (https://github.com/snap-research/EfficientFormer). Supports features_only=True.Minor updates to EfficientFormer.Refactor LeViT models to stages, add features_only=True support to new conv variants, weight remap required.Move ImageNet meta-data (synsets, indices) from /results to timm/data/_info.Add ImageNetInfo / DatasetInfo classes to provide labelling for various ImageNet classifier layouts in timmUpdate inference.py to use, try: python inference.py /folder/to/images --model convnext_small.in12k --label-type detail --topk 5Ready for 0.8.10 pypi pre-release (final testing).Jan 20, 2023Add two convnext 12k -> 1k fine-tunes at 384x384convnext_tiny.in12k_ft_in1k_384 - 85.1 @ 384convnext_small.in12k_ft_in1k_384 - 86.2 @ 384Push all MaxxViT weights to HF hub, and add new ImageNet-12k -> 1k fine-tunes for rw base MaxViT and CoAtNet 1/2 modelsmodeltop1top5samples / secParams (M)GMACAct (M)maxvit_xlarge_tf_512.in21k_ft_in1k88.5398.6421.76475.77534.141413.22maxvit_xlarge_tf_384.in21k_ft_in1k88.3298.5442.53475.32292.78668.76maxvit_base_tf_512.in21k_ft_in1k88.2098.5350.87119.88138.02703.99maxvit_large_tf_512.in21k_ft_in1k88.0498.4036.42212.33244.75942.15maxvit_large_tf_384.in21k_ft_in1k87.9898.5671.75212.03132.55445.84maxvit_base_tf_384.in21k_ft_in1k87.9298.54104.71119.6573.80332.90maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k87.8198.37106.55116.1470.97318.95maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k87.4798.37149.49116.0972.98213.74coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k87.3998.31160.8073.8847.69209.43maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k86.8998.02375.86116.1423.1592.64maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k86.6498.02501.03116.0924.2062.77maxvit_base_tf_512.in1k86.6097.9250.75119.88138.02703.99coatnet_2_rw_224.sw_in12k_ft_in1k86.5797.89631.8873.8715.0949.22maxvit_large_tf_512.in1k86.5297.8836.04212.33244.75942.15coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k86.4997.90620.5873.8815.1854.78maxvit_base_tf_384.in1k86.2997.80101.09119.6573.80332.90maxvit_large_tf_384.in1k86.2397.6970.56212.03132.55445.84maxvit_small_tf_512.in1k86.1097.7688.6369.1367.26383.77maxvit_tiny_tf_512.in1k85.6797.58144.2531.0533.49257.59maxvit_small_tf_384.in1k85.5497.46188.3569.0235.87183.65maxvit_tiny_tf_384.in1k85.1197.38293.4630.9817.53123.42maxvit_large_tf_224.in1k84.9396.97247.71211.7943.68127.35coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k84.9096.961025.4541.728.1140.13maxvit_base_tf_224.in1k84.8596.99358.25119.4724.0495.01maxxvit_rmlp_small_rw_256.sw_in1k84.6397.06575.5366.0114.6758.38coatnet_rmlp_2_rw_224.sw_in1k84.6196.74625.8173.8815.1854.78maxvit_rmlp_small_rw_224.sw_in1k84.4996.76693.8264.9010.7549.30maxvit_small_tf_224.in1k84.4396.83647.9668.9311.6653.17maxvit_rmlp_tiny_rw_256.sw_in1k84.2396.78807.2129.156.7746.92coatnet_1_rw_224.sw_in1k83.6296.38989.5941.728.0434.60maxvit_tiny_rw_224.sw_in1k83.5096.501100.5329.065.1133.11maxvit_tiny_tf_224.in1k83.4196.591004.9430.925.6035.78coatnet_rmlp_1_rw_224.sw_in1k83.3696.451093.0341.697.8535.47maxxvitv2_nano_rw_256.sw_in1k83.1196.331276.8823.706.2623.05maxxvit_rmlp_nano_rw_256.sw_in1k83.0396.341341.2416.784.3726.05maxvit_rmlp_nano_rw_256.sw_in1k82.9696.261283.2415.504.4731.92maxvit_nano_rw_256.sw_in1k82.9396.231218.1715.454.4630.28coatnet_bn_0_rw_224.sw_in1k82.3996.191600.1427.444.6722.04coatnet_0_rw_224.sw_in1k82.3995.841831.2127.444.4318.73coatnet_rmlp_nano_rw_224.sw_in1k82.0595.872109.0915.152.6220.34coatnext_nano_rw_224.sw_in1k81.9595.922525.5214.702.4712.80coatnet_nano_rw_224.sw_in1k81.7095.642344.5215.142.4115.41maxvit_rmlp_pico_rw_256.sw_in1k80.5395.211594.717.521.8524.86Jan 11, 2023Update ConvNeXt ImageNet-12k pretrain series w/ two new fine-tuned weights (and pre FT .in12k tags)convnext_nano.in12k_ft_in1k - 82.3 @ 224, 82.9 @ 288  (previously released)convnext_tiny.in12k_ft_in1k - 84.2 @ 224, 84.5 @ 288convnext_small.in12k_ft_in1k - 85.2 @ 224, 85.3 @ 288Jan 6, 2023Finally got around to adding --model-kwargs and --opt-kwargs to scripts to pass through rare args directly to model classes from cmd linetrain.py /imagenet --model resnet50 --amp --model-kwargs output_stride=16 act_layer=silutrain.py /imagenet --model vit_base_patch16_clip_224 --img-size 240 --amp --model-kwargs img_size=240 patch_size=12Cleanup some popular models to better support arg passthrough / merge with model configs, more to go.Jan 5, 2023ConvNeXt-V2 models and weights added to existing convnext.pyPaper: ConvNeXt V2: Co-designing and Scaling ConvNets with Masked AutoencodersReference impl: https://github.com/facebookresearch/ConvNeXt-V2 (NOTE: weights currently CC-BY-NC)Dec 23, 2022 🎄☃Add FlexiViT models and weights from https://github.com/google-research/big_vision (check out paper at https://arxiv.org/abs/2212.08013)NOTE currently resizing is static on model creation, on-the-fly dynamic / train patch size sampling is a WIPMany more models updated to multi-weight and downloadable via HF hub now (convnext, efficientnet, mobilenet, vision_transformer*, beit)More model pretrained tag and adjustments, some model names changed (working on deprecation translations, consider main branch DEV branch right now, use 0.6.x for stable use)More ImageNet-12k (subset of 22k) pretrain models popping up:efficientnet_b5.in12k_ft_in1k - 85.9 @ 448x448vit_medium_patch16_gap_384.in12k_ft_in1k - 85.5 @ 384x384vit_medium_patch16_gap_256.in12k_ft_in1k - 84.5 @ 256x256convnext_nano.in12k_ft_in1k - 82.9 @ 288x288Dec 8, 2022Add 'EVA l' to vision_transformer.py, MAE style ViT-L/14 MIM pretrain w/ EVA-CLIP targets, FT on ImageNet-1k (w/ ImageNet-22k intermediate for some)original source: https://github.com/baaivision/EVAmodeltop1param_countgmacmactshubeva_large_patch14_336.in22k_ft_in22k_in1k89.2304.5191.1270.2linkeva_large_patch14_336.in22k_ft_in1k88.7304.5191.1270.2linkeva_large_patch14_196.in22k_ft_in22k_in1k88.6304.161.663.5linkeva_large_patch14_196.in22k_ft_in1k87.9304.161.663.5linkDec 6, 2022Add 'EVA g', BEiT style ViT-g/14 model weights w/ both MIM pretrain and CLIP pretrain to beit.py.original source: https://github.com/baaivision/EVApaper: https://arxiv.org/abs/2211.07636modeltop1param_countgmacmactshubeva_giant_patch14_560.m30m_ft_in22k_in1k89.81014.41906.82577.2linkeva_giant_patch14_336.m30m_ft_in22k_in1k89.61013620.6550.7linkeva_giant_patch14_336.clip_ft_in1k89.41013620.6550.7linkeva_giant_patch14_224.clip_ft_in1k89.11012.6267.2192.6linkDec 5, 2022Pre-release (0.8.0dev0) of multi-weight support (model_arch.pretrained_tag). Install with pip install --pre timmvision_transformer, maxvit, convnext are the first three model impl w/ supportmodel names are changing with this (previous _21k, etc. fn will merge), still sorting out deprecation handlingbugs are likely, but I need feedback so please try it outif stability is needed, please use 0.6.x pypi releases or clone from 0.6.x branchSupport for PyTorch 2.0 compile is added in train/validate/inference/benchmark, use --torchcompile argumentInference script allows more control over output, select k for top-class index + prob json, csv or parquet outputAdd a full set of fine-tuned CLIP image tower weights from both LAION-2B and original OpenAI CLIP modelsmodeltop1param_countgmacmactshubvit_huge_patch14_clip_336.laion2b_ft_in12k_in1k88.6632.5391407.5linkvit_large_patch14_clip_336.openai_ft_in12k_in1k88.3304.5191.1270.2linkvit_huge_patch14_clip_224.laion2b_ft_in12k_in1k88.2632167.4139.4linkvit_large_patch14_clip_336.laion2b_ft_in12k_in1k88.2304.5191.1270.2linkvit_large_patch14_clip_224.openai_ft_in12k_in1k88.2304.281.188.8linkvit_large_patch14_clip_224.laion2b_ft_in12k_in1k87.9304.281.188.8linkvit_large_patch14_clip_224.openai_ft_in1k87.9304.281.188.8linkvit_large_patch14_clip_336.laion2b_ft_in1k87.9304.5191.1270.2linkvit_huge_patch14_clip_224.laion2b_ft_in1k87.6632167.4139.4linkvit_large_patch14_clip_224.laion2b_ft_in1k87.3304.281.188.8linkvit_base_patch16_clip_384.laion2b_ft_in12k_in1k87.286.955.5101.6linkvit_base_patch16_clip_384.openai_ft_in12k_in1k8786.955.5101.6linkvit_base_patch16_clip_384.laion2b_ft_in1k86.686.955.5101.6linkvit_base_patch16_clip_384.openai_ft_in1k86.286.955.5101.6linkvit_base_patch16_clip_224.laion2b_ft_in12k_in1k86.286.617.623.9linkvit_base_patch16_clip_224.openai_ft_in12k_in1k85.986.617.623.9linkvit_base_patch32_clip_448.laion2b_ft_in12k_in1k85.888.317.923.9linkvit_base_patch16_clip_224.laion2b_ft_in1k85.586.617.623.9linkvit_base_patch32_clip_384.laion2b_ft_in12k_in1k85.488.313.116.5linkvit_base_patch16_clip_224.openai_ft_in1k85.386.617.623.9linkvit_base_patch32_clip_384.openai_ft_in12k_in1k85.288.313.116.5linkvit_base_patch32_clip_224.laion2b_ft_in12k_in1k83.388.24.45linkvit_base_patch32_clip_224.laion2b_ft_in1k82.688.24.45linkvit_base_patch32_clip_224.openai_ft_in1k81.988.24.45linkPort of MaxViT Tensorflow Weights from official impl at https://github.com/google-research/maxvitThere was larger than expected drops for the upscaled 384/512 in21k fine-tune weights, possible detail missing, but the 21k FT did seem sensitive to small preprocessingmodeltop1param_countgmacmactshubmaxvit_xlarge_tf_512.in21k_ft_in1k88.5475.8534.11413.2linkmaxvit_xlarge_tf_384.in21k_ft_in1k88.3475.3292.8668.8linkmaxvit_base_tf_512.in21k_ft_in1k88.2119.9138704linkmaxvit_large_tf_512.in21k_ft_in1k88212.3244.8942.2linkmaxvit_large_tf_384.in21k_ft_in1k88212132.6445.8linkmaxvit_base_tf_384.in21k_ft_in1k87.9119.673.8332.9linkmaxvit_base_tf_512.in1k86.6119.9138704linkmaxvit_large_tf_512.in1k86.5212.3244.8942.2linkmaxvit_base_tf_384.in1k86.3119.673.8332.9linkmaxvit_large_tf_384.in1k86.2212132.6445.8linkmaxvit_small_tf_512.in1k86.169.167.3383.8linkmaxvit_tiny_tf_512.in1k85.73133.5257.6linkmaxvit_small_tf_384.in1k85.56935.9183.6linkmaxvit_tiny_tf_384.in1k85.13117.5123.4linkmaxvit_large_tf_224.in1k84.9211.843.7127.4linkmaxvit_base_tf_224.in1k84.9119.52495linkmaxvit_small_tf_224.in1k84.468.911.753.2linkmaxvit_tiny_tf_224.in1k83.430.95.635.8linkOct 15, 2022Train and validation script enhancementsNon-GPU (ie CPU) device supportSLURM compatibility for train scriptHF datasets support (via ReaderHfds)TFDS/WDS dataloading improvements (sample padding/wrap for distributed use fixed wrt sample count estimate)in_chans !=3 support for scripts / loaderAdan optimizerCan enable per-step LR scheduling via argsDataset 'parsers' renamed to 'readers', more descriptive of purposeAMP args changed, APEX via --amp-impl apex, bfloat16 supportedf via --amp-dtype bfloat16main branch switched to 0.7.x version, 0.6x forked for stable release of weight only addsmaster -> main branch renameOct 10, 2022More weights in maxxvit series, incl first ConvNeXt block based coatnext and maxxvit experiments:coatnext_nano_rw_224 - 82.0 @ 224 (G) -- (uses ConvNeXt conv block, no BatchNorm)maxxvit_rmlp_nano_rw_256 - 83.0 @ 256, 83.7 @ 320  (G) (uses ConvNeXt conv block, no BN)maxvit_rmlp_small_rw_224 - 84.5 @ 224, 85.1 @ 320 (G)maxxvit_rmlp_small_rw_256 - 84.6 @ 256, 84.9 @ 288 (G) -- could be trained better, hparams need tuning (uses ConvNeXt block, no BN)coatnet_rmlp_2_rw_224 - 84.6 @ 224, 85 @ 320  (T)NOTE: official MaxVit weights (in1k) have been released at https://github.com/google-research/maxvit -- some extra work is needed to port and adapt since my impl was created independently of theirs and has a few small differences + the whole TF same padding fun.Sept 23, 2022LAION-2B CLIP image towers supported as pretrained backbones for fine-tune or features (no classifier)vit_base_patch32_224_clip_laion2bvit_large_patch14_224_clip_laion2bvit_huge_patch14_224_clip_laion2bvit_giant_patch14_224_clip_laion2bSept 7, 2022Hugging Face timm docs home now exists, look for more here in the futureAdd BEiT-v2 weights for base and large 224x224 models from https://github.com/microsoft/unilm/tree/master/beit2Add more weights in maxxvit series incl a pico (7.5M params, 1.9 GMACs), two tiny variants:maxvit_rmlp_pico_rw_256 - 80.5 @ 256, 81.3 @ 320  (T)maxvit_tiny_rw_224 - 83.5 @ 224 (G)maxvit_rmlp_tiny_rw_256 - 84.2 @ 256, 84.8 @ 320 (T)Aug 29, 2022MaxVit window size scales with img_size by default. Add new RelPosMlp MaxViT weight that leverages this:maxvit_rmlp_nano_rw_256 - 83.0 @ 256, 83.6 @ 320  (T)Aug 26, 2022CoAtNet (https://arxiv.org/abs/2106.04803) and MaxVit (https://arxiv.org/abs/2204.01697) timm original modelsboth found in maxxvit.py model def, contains numerous experiments outside scope of original papersan unfinished Tensorflow version from MaxVit authors can be found https://github.com/google-research/maxvitInitial CoAtNet and MaxVit timm pretrained weights (working on more):coatnet_nano_rw_224 - 81.7 @ 224  (T)coatnet_rmlp_nano_rw_224 - 82.0 @ 224, 82.8 @ 320 (T)coatnet_0_rw_224 - 82.4  (T)  -- NOTE timm '0' coatnets have 2 more 3rd stage blockscoatnet_bn_0_rw_224 - 82.4  (T)maxvit_nano_rw_256 - 82.9 @ 256  (T)coatnet_rmlp_1_rw_224 - 83.4 @ 224, 84 @ 320  (T)coatnet_1_rw_224 - 83.6 @ 224 (G)(T) = TPU trained with bits_and_tpu branch training code, (G) = GPU trainedGCVit (weights adapted from https://github.com/NVlabs/GCVit, code 100% timm re-write for license purposes)MViT-V2 (multi-scale vit, adapted from https://github.com/facebookresearch/mvit)EfficientFormer (adapted from https://github.com/snap-research/EfficientFormer)PyramidVisionTransformer-V2 (adapted from https://github.com/whai362/PVT)'Fast Norm' support for LayerNorm and GroupNorm that avoids float32 upcast w/ AMP (uses APEX LN if available for further boost)Aug 15, 2022ConvNeXt atto weights addedconvnext_atto - 75.7 @ 224, 77.0 @ 288convnext_atto_ols - 75.9  @ 224, 77.2 @ 288Aug 5, 2022More custom ConvNeXt smaller model defs with weightsconvnext_femto - 77.5 @ 224, 78.7 @ 288convnext_femto_ols - 77.9  @ 224, 78.9 @ 288convnext_pico - 79.5 @ 224, 80.4 @ 288convnext_pico_ols - 79.5 @ 224, 80.5 @ 288convnext_nano_ols - 80.9 @ 224, 81.6 @ 288Updated EdgeNeXt to improve ONNX export, add new base variant and weights from original (https://github.com/mmaaz60/EdgeNeXt)July 28, 2022Add freshly minted DeiT-III Medium (width=512, depth=12, num_heads=8) model weights. Thanks Hugo Touvron!July 27, 2022All runtime benchmark and validation result csv files are finally up-to-date!A few more weights & model defs added:darknetaa53 -  79.8 @ 256, 80.5 @ 288convnext_nano - 80.8 @ 224, 81.5 @ 288cs3sedarknet_l - 81.2 @ 256, 81.8 @ 288cs3darknet_x - 81.8 @ 256, 82.2 @ 288cs3sedarknet_x - 82.2 @ 256, 82.7 @ 288cs3edgenet_x - 82.2 @ 256, 82.7 @ 288cs3se_edgenet_x - 82.8 @ 256, 83.5 @ 320cs3* weights above all trained on TPU w/ bits_and_tpu branch. Thanks to TRC program!Add output_stride=8 and 16 support to ConvNeXt (dilation)deit3 models not being able to resize pos_emb fixedVersion 0.6.7 PyPi release (/w above bug fixes and new weighs since 0.6.5)July 8, 2022More models, more fixesOfficial research models (w/ weights) added:EdgeNeXt from (https://github.com/mmaaz60/EdgeNeXt)MobileViT-V2 from (https://github.com/apple/ml-cvnets)DeiT III (Revenge of the ViT) from (https://github.com/facebookresearch/deit)My own models:Small ResNet defs added by request with 1 block repeats for both basic and bottleneck (resnet10 and resnet14)CspNet refactored with dataclass config, simplified CrossStage3 (cs3) option. These are closer to YOLO-v5+ backbone defs.More relative position vit fiddling. Two srelpos (shared relative position) models trained, and a medium w/ class token.Add an alternate downsample mode to EdgeNeXt and train a small model. Better than original small, but not their new USI trained weights.My own model weight results (all ImageNet-1k training)resnet10t - 66.5 @ 176, 68.3 @ 224resnet14t - 71.3 @ 176, 72.3 @ 224resnetaa50 - 80.6 @ 224 , 81.6 @ 288darknet53 -  80.0 @ 256, 80.5 @ 288cs3darknet_m - 77.0 @ 256, 77.6 @ 288cs3darknet_focus_m - 76.7 @ 256, 77.3 @ 288cs3darknet_l - 80.4 @ 256, 80.9 @ 288cs3darknet_focus_l - 80.3 @ 256, 80.9 @ 288vit_srelpos_small_patch16_224 - 81.1 @ 224, 82.1 @ 320vit_srelpos_medium_patch16_224 - 82.3 @ 224, 83.1 @ 320vit_relpos_small_patch16_cls_224 - 82.6 @ 224, 83.6 @ 320edgnext_small_rw - 79.6 @ 224, 80.4 @ 320cs3, darknet, and vit_*relpos weights above all trained on TPU thanks to TRC program! Rest trained on overheating GPUs.Hugging Face Hub support fixes verified, demo notebook TBAPretrained weights / configs can be loaded externally (ie from local disk) w/ support for head adaptation.Add support to change image extensions scanned by timm datasets/readers. See (#1274 (comment))Default ConvNeXt LayerNorm impl to use F.layer_norm(x.permute(0, 2, 3, 1), ...).permute(0, 3, 1, 2) via LayerNorm2d in all cases.a bit slower than previous custom impl on some hardware (ie Ampere w/ CL), but overall fewer regressions across wider HW / PyTorch version ranges.previous impl exists as LayerNormExp2d in models/layers/norm.pyNumerous bug fixesCurrently testing for imminent PyPi 0.6.x releaseLeViT pretraining of larger models still a WIP, they don't train well / easily without distillation. Time to add distill support (finally)?ImageNet-22k weight training + finetune ongoing, work on multi-weight support (slowly) chugging along (there are a LOT of weights, sigh) ...May 13, 2022Official Swin-V2 models and weights added from (https://github.com/microsoft/Swin-Transformer). Cleaned up to support torchscript.Some refactoring for existing timm Swin-V2-CR impl, will likely do a bit more to bring parts closer to official and decide whether to merge some aspects.More Vision Transformer relative position / residual post-norm experiments (all trained on TPU thanks to TRC program)vit_relpos_small_patch16_224 - 81.5 @ 224, 82.5 @ 320 -- rel pos, layer scale, no class token, avg poolvit_relpos_medium_patch16_rpn_224 - 82.3 @ 224, 83.1 @ 320 -- rel pos + res-post-norm, no class token, avg poolvit_relpos_medium_patch16_224 - 82.5 @ 224, 83.3 @ 320 -- rel pos, layer scale, no class token, avg poolvit_relpos_base_patch16_gapcls_224 - 82.8 @ 224, 83.9 @ 320 -- rel pos, layer scale, class token, avg pool (by mistake)Bring 512 dim, 8-head 'medium' ViT model variant back to life (after using in a pre DeiT 'small' model for first ViT impl back in 2020)Add ViT relative position support for switching btw existing impl and some additions in official Swin-V2 impl for future trialsSequencer2D impl (https://arxiv.org/abs/2205.01972), added via PR from author (https://github.com/okojoalg)May 2, 2022Vision Transformer experiments adding Relative Position (Swin-V2 log-coord) (vision_transformer_relpos.py) and Residual Post-Norm branches (from Swin-V2) (vision_transformer*.py)vit_relpos_base_patch32_plus_rpn_256 - 79.5 @ 256, 80.6 @ 320 -- rel pos + extended width + res-post-norm, no class token, avg poolvit_relpos_base_patch16_224 - 82.5 @ 224, 83.6 @ 320 -- rel pos, layer scale, no class token, avg poolvit_base_patch16_rpn_224 - 82.3 @ 224 -- rel pos + res-post-norm, no class token, avg poolVision Transformer refactor to remove representation layer that was only used in initial vit and rarely used since with newer pretrain (ie How to Train Your ViT)vit_* models support removal of class token, use of global average pool, use of fc_norm (ala beit, mae).April 22, 2022timm models are now officially supported in fast.ai! Just in time for the new Practical Deep Learning course. timmdocs documentation link updated to timm.fast.ai.Two more model weights added in the TPU trained series. Some In22k pretrain still in progress.seresnext101d_32x8d - 83.69 @ 224, 84.35 @ 288seresnextaa101d_32x8d (anti-aliased w/ AvgPool2d) - 83.85 @ 224, 84.57 @ 288March 23, 2022Add ParallelBlock and LayerScale option to base vit models to support model configs in Three things everyone should know about ViTconvnext_tiny_hnf (head norm first) weights trained with (close to) A2 recipe, 82.2% top-1, could do better with more epochs.March 21, 2022Merge norm_norm_norm. IMPORTANT this update for a coming 0.6.x release will likely de-stabilize the master branch for a while. Branch 0.5.x or a previous 0.5.x release can be used if stability is required.Significant weights update (all TPU trained) as described in this releaseregnety_040 - 82.3 @ 224, 82.96 @ 288regnety_064 - 83.0 @ 224, 83.65 @ 288regnety_080 - 83.17 @ 224, 83.86 @ 288regnetv_040 - 82.44 @ 224, 83.18 @ 288   (timm pre-act)regnetv_064 - 83.1 @ 224, 83.71 @ 288   (timm pre-act)regnetz_040 - 83.67 @ 256, 84.25 @ 320regnetz_040h - 83.77 @ 256, 84.5 @ 320 (w/ extra fc in head)resnetv2_50d_gn - 80.8 @ 224, 81.96 @ 288 (pre-act GroupNorm)resnetv2_50d_evos 80.77 @ 224, 82.04 @ 288 (pre-act EvoNormS)regnetz_c16_evos  - 81.9 @ 256, 82.64 @ 320 (EvoNormS)regnetz_d8_evos  - 83.42 @ 256, 84.04 @ 320 (EvoNormS)xception41p - 82 @ 299   (timm pre-act)xception65 -  83.17 @ 299xception65p -  83.14 @ 299   (timm pre-act)resnext101_64x4d - 82.46 @ 224, 83.16 @ 288seresnext101_32x8d - 83.57 @ 224, 84.270 @ 288resnetrs200 - 83.85 @ 256, 84.44 @ 320HuggingFace hub support fixed w/ initial groundwork for allowing alternative 'config sources' for pretrained model definitions and weights (generic local file / remote url support soon)SwinTransformer-V2 implementation added. Submitted by Christoph Reich. Training experiments and model changes by myself are ongoing so expect compat breaks.Swin-S3 (AutoFormerV2) models / weights added from https://github.com/microsoft/Cream/tree/main/AutoFormerV2MobileViT models w/ weights adapted from https://github.com/apple/ml-cvnetsPoolFormer models w/ weights adapted from https://github.com/sail-sg/poolformerVOLO models w/ weights adapted from https://github.com/sail-sg/voloSignificant work experimenting with non-BatchNorm norm layers such as EvoNorm, FilterResponseNorm, GroupNorm, etcEnhance support for alternate norm + act ('NormAct') layers added to a number of models, esp EfficientNet/MobileNetV3, RegNet, and aligned XceptionGrouped conv support added to EfficientNet familyAdd 'group matching' API to all models to allow grouping model parameters for application of 'layer-wise' LR decay, lr scale added to LR schedulerGradient checkpointing support added to many modelsforward_head(x, pre_logits=False) fn added to all models to allow separate calls of forward_features + forward_headAll vision transformer and vision MLP models update to return non-pooled / non-token selected features from foward_features, for consistency with CNN models, token selection or pooling now applied in forward_headFeb 2, 2022Chris Hughes posted an exhaustive run through of timm on his blog yesterday. Well worth a read. Getting Started with PyTorch Image Models (timm): A Practitioner’s GuideI'm currently prepping to merge the norm_norm_norm branch back to master (ver 0.6.x) in next week or so.The changes are more extensive than usual and may destabilize and break some model API use (aiming for full backwards compat). So, beware pip install git+https://github.com/rwightman/pytorch-image-models installs!0.5.x releases and a 0.5.x branch will remain stable with a cherry pick or two until dust clears. Recommend sticking to pypi install for a bit if you want stable.Jan 14, 2022Version 0.5.4 w/ release to be pushed to pypi. It's been a while since last pypi update and riskier changes will be merged to main branch soon....Add ConvNeXT models /w weights from official impl (https://github.com/facebookresearch/ConvNeXt), a few perf tweaks, compatible with timm featuresTried training a few small (~1.8-3M param) / mobile optimized models, a few are good so far, more on the way...mnasnet_small - 65.6 top-1mobilenetv2_050 - 65.9lcnet_100/075/050 - 72.1 / 68.8 / 63.1semnasnet_075 - 73fbnetv3_b/d/g - 79.1 / 79.7 / 82.0TinyNet models added by rsomani95LCNet added via MobileNetV3 architectureIntroductionPyTorch Image Models (timm) is a collection of image models, layers, utilities, optimizers, schedulers, data-loaders / augmentations, and reference training / validation scripts that aim to pull together a wide variety of SOTA models with ability to reproduce ImageNet training results.The work of many others is present here. I've tried to make sure all source material is acknowledged via links to github, arxiv papers, etc in the README, documentation, and code docstrings. Please let me know if I missed anything.ModelsAll model architecture families include variants with pretrained weights. There are specific model variants without any weights, it is NOT a bug. Help training new or better weights is always appreciated.Aggregating Nested Transformers - https://arxiv.org/abs/2105.12723BEiT - https://arxiv.org/abs/2106.08254Big Transfer ResNetV2 (BiT) - https://arxiv.org/abs/1912.11370Bottleneck Transformers - https://arxiv.org/abs/2101.11605CaiT (Class-Attention in Image Transformers) - https://arxiv.org/abs/2103.17239CoaT (Co-Scale Conv-Attentional Image Transformers) - https://arxiv.org/abs/2104.06399CoAtNet (Convolution and Attention) - https://arxiv.org/abs/2106.04803ConvNeXt - https://arxiv.org/abs/2201.03545ConvNeXt-V2 - http://arxiv.org/abs/2301.00808ConViT (Soft Convolutional Inductive Biases Vision Transformers)- https://arxiv.org/abs/2103.10697CspNet (Cross-Stage Partial Networks) - https://arxiv.org/abs/1911.11929DeiT - https://arxiv.org/abs/2012.12877DeiT-III - https://arxiv.org/pdf/2204.07118.pdfDenseNet - https://arxiv.org/abs/1608.06993DLA - https://arxiv.org/abs/1707.06484DPN (Dual-Path Network) - https://arxiv.org/abs/1707.01629EdgeNeXt - https://arxiv.org/abs/2206.10589EfficientFormer - https://arxiv.org/abs/2206.01191EfficientNet (MBConvNet Family)EfficientNet NoisyStudent (B0-B7, L2) - https://arxiv.org/abs/1911.04252EfficientNet AdvProp (B0-B8) - https://arxiv.org/abs/1911.09665EfficientNet (B0-B7) - https://arxiv.org/abs/1905.11946EfficientNet-EdgeTPU (S, M, L) - https://ai.googleblog.com/2019/08/efficientnet-edgetpu-creating.htmlEfficientNet V2 - https://arxiv.org/abs/2104.00298FBNet-C - https://arxiv.org/abs/1812.03443MixNet - https://arxiv.org/abs/1907.09595MNASNet B1, A1 (Squeeze-Excite), and Small - https://arxiv.org/abs/1807.11626MobileNet-V2 - https://arxiv.org/abs/1801.04381Single-Path NAS - https://arxiv.org/abs/1904.02877TinyNet - https://arxiv.org/abs/2010.14819EVA - https://arxiv.org/abs/2211.07636EVA-02 - https://arxiv.org/abs/2303.11331FlexiViT - https://arxiv.org/abs/2212.08013FocalNet (Focal Modulation Networks) - https://arxiv.org/abs/2203.11926GCViT (Global Context Vision Transformer) - https://arxiv.org/abs/2206.09959GhostNet - https://arxiv.org/abs/1911.11907gMLP - https://arxiv.org/abs/2105.08050GPU-Efficient Networks - https://arxiv.org/abs/2006.14090Halo Nets - https://arxiv.org/abs/2103.12731HRNet - https://arxiv.org/abs/1908.07919Inception-V3 - https://arxiv.org/abs/1512.00567Inception-ResNet-V2 and Inception-V4 - https://arxiv.org/abs/1602.07261Lambda Networks - https://arxiv.org/abs/2102.08602LeViT (Vision Transformer in ConvNet's Clothing) - https://arxiv.org/abs/2104.01136MaxViT (Multi-Axis Vision Transformer) - https://arxiv.org/abs/2204.01697MLP-Mixer - https://arxiv.org/abs/2105.01601MobileNet-V3 (MBConvNet w/ Efficient Head) - https://arxiv.org/abs/1905.02244FBNet-V3 - https://arxiv.org/abs/2006.02049HardCoRe-NAS - https://arxiv.org/abs/2102.11646LCNet - https://arxiv.org/abs/2109.15099MobileViT - https://arxiv.org/abs/2110.02178MobileViT-V2 - https://arxiv.org/abs/2206.02680MViT-V2 (Improved Multiscale Vision Transformer) - https://arxiv.org/abs/2112.01526NASNet-A - https://arxiv.org/abs/1707.07012NesT - https://arxiv.org/abs/2105.12723NFNet-F - https://arxiv.org/abs/2102.06171NF-RegNet / NF-ResNet - https://arxiv.org/abs/2101.08692PNasNet - https://arxiv.org/abs/1712.00559PoolFormer (MetaFormer) - https://arxiv.org/abs/2111.11418Pooling-based Vision Transformer (PiT) - https://arxiv.org/abs/2103.16302PVT-V2 (Improved Pyramid Vision Transformer) - https://arxiv.org/abs/2106.13797RegNet - https://arxiv.org/abs/2003.13678RegNetZ - https://arxiv.org/abs/2103.06877RepVGG - https://arxiv.org/abs/2101.03697ResMLP - https://arxiv.org/abs/2105.03404ResNet/ResNeXtResNet (v1b/v1.5) - https://arxiv.org/abs/1512.03385ResNeXt - https://arxiv.org/abs/1611.05431'Bag of Tricks' / Gluon C, D, E, S variations - https://arxiv.org/abs/1812.01187Weakly-supervised (WSL) Instagram pretrained / ImageNet tuned ResNeXt101 - https://arxiv.org/abs/1805.00932Semi-supervised (SSL) / Semi-weakly Supervised (SWSL) ResNet/ResNeXts - https://arxiv.org/abs/1905.00546ECA-Net (ECAResNet) - https://arxiv.org/abs/1910.03151v4Squeeze-and-Excitation Networks (SEResNet) - https://arxiv.org/abs/1709.01507ResNet-RS - https://arxiv.org/abs/2103.07579Res2Net - https://arxiv.org/abs/1904.01169ResNeSt - https://arxiv.org/abs/2004.08955ReXNet - https://arxiv.org/abs/2007.00992SelecSLS - https://arxiv.org/abs/1907.00837Selective Kernel Networks - https://arxiv.org/abs/1903.06586Sequencer2D - https://arxiv.org/abs/2205.01972Swin S3 (AutoFormerV2) - https://arxiv.org/abs/2111.14725Swin Transformer - https://arxiv.org/abs/2103.14030Swin Transformer V2 - https://arxiv.org/abs/2111.09883Transformer-iN-Transformer (TNT) - https://arxiv.org/abs/2103.00112TResNet - https://arxiv.org/abs/2003.13630Twins (Spatial Attention in Vision Transformers) - https://arxiv.org/pdf/2104.13840.pdfVisformer - https://arxiv.org/abs/2104.12533Vision Transformer - https://arxiv.org/abs/2010.11929VOLO (Vision Outlooker) - https://arxiv.org/abs/2106.13112VovNet V2 and V1 - https://arxiv.org/abs/1911.06667Xception - https://arxiv.org/abs/1610.02357Xception (Modified Aligned, Gluon) - https://arxiv.org/abs/1802.02611Xception (Modified Aligned, TF) - https://arxiv.org/abs/1802.02611XCiT (Cross-Covariance Image Transformers) - https://arxiv.org/abs/2106.09681FeaturesSeveral (less common) features that I often utilize in my projects are included. Many of their additions are the reason why I maintain my own set of models, instead of using others' via PIP:All models have a common default configuration interface and API foraccessing/changing the classifier - get_classifier and reset_classifierdoing a forward pass on just the features - forward_features (see documentation)these makes it easy to write consistent network wrappers that work with any of the modelsAll models support multi-scale feature map extraction (feature pyramids) via create_model (see documentation)create_model(name, features_only=True, out_indices=..., output_stride=...)out_indices creation arg specifies which feature maps to return, these indices are 0 based and generally correspond to the C(i + 1) feature level.output_stride creation arg controls output stride of the network by using dilated convolutions. Most networks are stride 32 by default. Not all networks support this.feature map channel counts, reduction level (stride) can be queried AFTER model creation via the .feature_info memberAll models have a consistent pretrained weight loader that adapts last linear if necessary, and from 3 to 1 channel input if desiredHigh performance reference training, validation, and inference scripts that work in several process/GPU modes:NVIDIA DDP w/ a single GPU per process, multiple processes with APEX present (AMP mixed-precision optional)PyTorch DistributedDataParallel w/ multi-gpu, single process (AMP disabled as it crashes when enabled)PyTorch w/ single GPU single process (AMP optional)A dynamic global pool implementation that allows selecting from average pooling, max pooling, average + max, or concat([average, max]) at model creation. All global pooling is adaptive average by default and compatible with pretrained weights.A 'Test Time Pool' wrapper that can wrap any of the included models and usually provides improved performance doing inference with input images larger than the training size. Idea adapted from original DPN implementation when I ported (https://github.com/cypw/DPNs)Learning rate schedulersIdeas adopted fromAllenNLP schedulersFAIRseq lr_schedulerSGDR: Stochastic Gradient Descent with Warm Restarts (https://arxiv.org/abs/1608.03983)Schedulers include step, cosine w/ restarts, tanh w/ restarts, plateauOptimizers:rmsprop_tf adapted from PyTorch RMSProp by myself. Reproduces much improved Tensorflow RMSProp behaviour.radam by Liyuan Liu (https://arxiv.org/abs/1908.03265)novograd by Masashi Kimura (https://arxiv.org/abs/1905.11286)lookahead adapted from impl by Liam (https://arxiv.org/abs/1907.08610)fused<name> optimizers by name with NVIDIA Apex installedadamp and sgdp by Naver ClovAI (https://arxiv.org/abs/2006.08217)adafactor adapted from FAIRSeq impl (https://arxiv.org/abs/1804.04235)adahessian by David Samuel (https://arxiv.org/abs/2006.00719)Random Erasing from Zhun Zhong  (https://arxiv.org/abs/1708.04896)Mixup (https://arxiv.org/abs/1710.09412)CutMix (https://arxiv.org/abs/1905.04899)AutoAugment (https://arxiv.org/abs/1805.09501) and RandAugment (https://arxiv.org/abs/1909.13719) ImageNet configurations modeled after impl for EfficientNet training (https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/autoaugment.py)AugMix w/ JSD loss (https://arxiv.org/abs/1912.02781), JSD w/ clean + augmented mixing support works with AutoAugment and RandAugment as wellSplitBachNorm - allows splitting batch norm layers between clean and augmented (auxiliary batch norm) dataDropPath aka \""Stochastic Depth\"" (https://arxiv.org/abs/1603.09382)DropBlock (https://arxiv.org/abs/1810.12890)Blur Pooling (https://arxiv.org/abs/1904.11486)Space-to-Depth by mrT23 (https://arxiv.org/abs/1801.04590) -- original paper?Adaptive Gradient Clipping (https://arxiv.org/abs/2102.06171, https://github.com/deepmind/deepmind-research/tree/master/nfnets)An extensive selection of channel and/or spatial attention modules:Bottleneck Transformer - https://arxiv.org/abs/2101.11605CBAM - https://arxiv.org/abs/1807.06521Effective Squeeze-Excitation (ESE) - https://arxiv.org/abs/1911.06667Efficient Channel Attention (ECA) - https://arxiv.org/abs/1910.03151Gather-Excite (GE) - https://arxiv.org/abs/1810.12348Global Context (GC) - https://arxiv.org/abs/1904.11492Halo - https://arxiv.org/abs/2103.12731Involution - https://arxiv.org/abs/2103.06255Lambda Layer - https://arxiv.org/abs/2102.08602Non-Local (NL) -  https://arxiv.org/abs/1711.07971Squeeze-and-Excitation (SE) - https://arxiv.org/abs/1709.01507Selective Kernel (SK) - (https://arxiv.org/abs/1903.06586Split (SPLAT) - https://arxiv.org/abs/2004.08955Shifted Window (SWIN) - https://arxiv.org/abs/2103.14030ResultsModel validation results can be found in the results tablesGetting Started (Documentation)The official documentation can be found at https://huggingface.co/docs/hub/timm. Documentation contributions are welcome.Getting Started with PyTorch Image Models (timm): A Practitioner’s Guide by Chris Hughes is an extensive blog post covering many aspects of timm in detail.timmdocs is an alternate set of documentation for timm. A big thanks to Aman Arora for his efforts creating timmdocs.paperswithcode is a good resource for browsing the models within timm.Train, Validation, Inference ScriptsThe root folder of the repository contains reference train, validation, and inference scripts that work with the included models and other features of this repository. They are adaptable for other datasets and use cases with a little hacking. See documentation.Awesome PyTorch ResourcesOne of the greatest assets of PyTorch is the community and their contributions. A few of my favourite resources that pair well with the models and components here are listed below.Object Detection, Instance and Semantic SegmentationDetectron2 - https://github.com/facebookresearch/detectron2Segmentation Models (Semantic) - https://github.com/qubvel/segmentation_models.pytorchEfficientDet (Obj Det, Semantic soon) - https://github.com/rwightman/efficientdet-pytorchComputer Vision / Image AugmentationAlbumentations - https://github.com/albumentations-team/albumentationsKornia - https://github.com/kornia/korniaKnowledge DistillationRepDistiller - https://github.com/HobbitLong/RepDistillertorchdistill - https://github.com/yoshitomo-matsubara/torchdistillMetric LearningPyTorch Metric Learning - https://github.com/KevinMusgrave/pytorch-metric-learningTraining / Frameworksfastai - https://github.com/fastai/fastaiLicensesCodeThe code here is licensed Apache 2.0. I've taken care to make sure any third party code included or adapted has compatible (permissive) licenses such as MIT, BSD, etc. I've made an effort to avoid any GPL / LGPL conflicts. That said, it is your responsibility to ensure you comply with licenses here and conditions of any dependent licenses. Where applicable, I've linked the sources/references for various components in docstrings. If you think I've missed anything please create an issue.Pretrained WeightsSo far all of the pretrained weights available here are pretrained on ImageNet with a select few that have some additional pretraining (see extra note below). ImageNet was released for non-commercial research purposes only (https://image-net.org/download). It's not clear what the implications of that are for the use of pretrained weights from that dataset. Any models I have trained with ImageNet are done for research purposes and one should assume that the original dataset license applies to the weights. It's best to seek legal advice if you intend to use the pretrained weights in a commercial product.Pretrained on more than ImageNetSeveral weights included or references here were pretrained with proprietary datasets that I do not have access to. These include the Facebook WSL, SSL, SWSL ResNe(Xt) and the Google Noisy Student EfficientNet models. The Facebook models have an explicit non-commercial license (CC-BY-NC 4.0, https://github.com/facebookresearch/semi-supervised-ImageNet1K-models, https://github.com/facebookresearch/WSL-Images). The Google models do not appear to have any restriction beyond the Apache 2.0 license (and ImageNet concerns). In either case, you should contact Facebook or Google with any questions.CitingBibTeX@misc{rw2019timm,  author = {Ross Wightman},  title = {PyTorch Image Models},  year = {2019},  publisher = {GitHub},  journal = {GitHub repository},  doi = {10.5281/zenodo.4414861},  howpublished = {\\url{https://github.com/rwightman/pytorch-image-models}}}Latest DOI"
58,donnemartin/system-design-primer,https://github.com/donnemartin/system-design-primer/blob/master/README-ja.md,Python,"English ∙ 日本語 ∙ 简体中文 ∙ 繁體中文 | العَرَبِيَّة‎ ∙ বাংলা ∙ Português do Brasil ∙ Deutsch ∙ ελληνικά ∙ עברית ∙ Italiano ∙ 한국어 ∙ فارسی ∙ Polski ∙ русский язык ∙ Español ∙ ภาษาไทย ∙ Türkçe ∙ tiếng Việt ∙ Français | Add Translationシステム設計入門    動機・目的大規模システムのシステム設計を学ぶシステム設計面接課題に備える大規模システムの設計を学ぶスケーラブルなシステムのシステム設計を学ぶことは、より良いエンジニアになることに資するでしょう。システム設計はとても広範なトピックを含みます。システム設計原理については インターネット上には膨大な量の文献が散らばっています。このリポジトリは大規模システム構築に必要な知識を学ぶことができる 文献リストを体系的にまとめたもの です。オープンソースコミュニティから学ぶこのプロジェクトは、これからもずっと更新されていくオープンソースプロジェクトの初期段階にすぎません。Contributions は大歓迎です！システム設計面接課題に備えるコード技術面接に加えて、システム設計に関する知識は、多くのテック企業における 技術採用面接プロセス で 必要不可欠な要素 です。システム設計面接での頻出質問に備え、自分の解答と模範解答:ディスカッション、コードそして図表などを比較して学びましょう。面接準備に役立つその他のトピック:学習指針システム設計面接課題にどのように準備するかシステム設計課題例 とその解答オブジェクト指向設計課題例、 とその解答その他のシステム設計面接課題例暗記カード    このAnki用フラッシュカードデッキ は、間隔反復を活用して、システム設計のキーコンセプトの学習を支援します。システム設計デッキシステム設計練習課題デッキオブジェクト指向練習課題デッキ外出先や移動中の勉強に役立つでしょう。コーディング技術課題用の問題: 練習用インタラクティブアプリケーションコード技術面接用の問題を探している場合はこちら    姉妹リポジトリの Interactive Coding Challengesも見てみてください。追加の暗記デッキカードも入っています。Coding deckコントリビュートコミュニティから学ぶプルリクエスト等の貢献は積極的にお願いします:エラー修正セクション内容改善新規セクション追加翻訳する現在、内容の改善が必要な作業中のコンテンツはこちらです。コントリビュートの前にContributing Guidelinesを読みましょう。システム設計目次賛否も含めた様々なシステム設計の各トピックの概要。 全てはトレードオフの関係にあります。それぞれのセクションはより学びを深めるような他の文献へのリンクが貼られています。    システム設計トピック: まずはここからStep 1: スケーラビリティに関する動画を見るStep 2: スケーラビリティに関する記事を読む次のステップパフォーマンス vs スケーラビリティレイテンシー vs スループット可用性 vs 一貫性CAP理論CP - 一貫性(consistency)と分割性(partition)耐性AP - 可用性(availability)と分割性(partition)耐性一貫性 パターン弱い一貫性結果整合性強い一貫性可用性 パターンフェイルオーバーレプリケーションドメインネームシステム(DNS)コンテンツデリバリーネットワーク(CDN)プッシュCDNプルCDNロードバランサーアクティブ/パッシブ構成アクティブ/アクティブ構成Layer 4 ロードバランシングLayer 7 ロードバランシング水平スケーリングリバースプロキシ (WEBサーバー)ロードバランサー vs リバースプロキシアプリケーションレイヤーマイクロサービスサービスディスカバリーデータベースリレーショナルデータベースマネジメントシステム (RDBMS)マスター/スレーブ レプリケーションマスター/マスター レプリケーションフェデレーションシャーディングデノーマライゼーションSQL チューニングNoSQLキー/バリューストアドキュメントストアワイドカラムストアグラフ データベースSQL or NoSQLキャッシュクライアントキャッシングCDNキャッシングWebサーバーキャッシングデータベースキャッシングアプリケーションキャッシングデータベースクエリレベルでキャッシングするオブジェクトレベルでキャッシングするいつキャッシュを更新するのかキャッシュアサイドライトスルーライトビハインド (ライトバック)リフレッシュアヘッド非同期処理メッセージキュータスクキューバックプレッシャー通信伝送制御プロトコル (TCP)ユーザデータグラムプロトコル (UDP)遠隔手続呼出 (RPC)Representational state transfer (REST)セキュリティ補遺2の乗数表全てのプログラマーが知るべきレイテンシー値他のシステム設計面接例題実世界でのアーキテクチャ各企業のアーキテクチャ企業のエンジニアブログ作業中クレジット連絡情報ライセンス学習指針学習スパンに応じてみるべきトピックス (short, medium, long)Q: 面接のためには、ここにあるものすべてをやらないといけないのでしょうか？A: いえ、ここにあるすべてをやる必要はありません。面接で何を聞かれるかは以下の条件によって変わってきます:どれだけの技術経験があるかあなたの技術背景が何であるかどのポジションのために面接を受けているかどの企業の面接を受けているか運より経験のある候補者は一般的にシステム設計についてより深い知識を有していることを要求されるでしょう。システムアーキテクトやチームリーダーは各メンバーの持つような知識よりは深い見識を持っているべきでしょう。一流テック企業では複数回の設計面接を課されることが多いです。まずは広く始めて、そこからいくつかの分野に絞って深めていくのがいいでしょう。様々なシステム設計のトピックについて少しずつ知っておくことはいいことです。以下の学習ガイドを自分の学習に当てられる時間、技術経験、どの職位、どの会社に応募しているかなどを加味して自分用に調整して使うといいでしょう。短期間 - 幅広く システム設計トピックを学ぶ。いくつかの 面接課題を解くことで対策する。中期間 - 幅広く そして それなりに深くシステム設計トピックを学ぶ。多くの 面接課題を解くことで対策する。長期間 - 幅広く そして もっと深くシステム設計トピックを学ぶ。ほぼ全ての 面接課題を解くことで対策する。短期間中期間長期間システム設計トピック を読み、システム動作機序について広く知る👍👍👍次のリンク先のいくつかのページを読んで 各企業のエンジニアリングブログ 応募する会社について知る👍👍👍次のリンク先のいくつかのページを読む 実世界でのアーキテクチャ👍👍👍復習する システム設計面接課題にどのように準備するか👍👍👍とりあえず一周する システム設計課題例SomeManyMostとりあえず一周する オブジェクト指向設計問題と解答SomeManyMost復習する その他システム設計面接での質問例SomeManyMostシステム設計面接にどのようにして臨めばいいかシステム設計面接試験問題にどのように取り組むかシステム設計面接は open-ended conversation(Yes/Noでは答えられない口頭質問)です。 自分で会話を組み立てることを求められます。以下のステップに従って議論を組み立てることができるでしょう。この過程を確かなものにするために、次のセクションシステム設計課題例とその解答 を以下の指針に従って読み込むといいでしょう。ステップ 1: そのシステム使用例の概要、制約、推計値等を聞き出し、まとめるシステム仕様の要求事項を聞き出し、問題箇所を特定しましょう。使用例と制約を明確にするための質問を投げかけましょう。要求する推計値についても議論しておきましょう。誰がそのサービスを使うのか？どのように使うのか？何人のユーザーがいるのか？システムはどのような機能を果たすのか？システムへの入力と出力は？どれだけの容量のデータを捌く必要があるのか？一秒間に何リクエストの送信が想定されるか？読み書き比率の推定値はいくら程度か？ステップ 2: より高レベルのシステム設計を組み立てる重要なコンポーネントを全て考慮した高レベルのシステム設計概要を組み立てる。主要なコンポーネントと接続をスケッチして書き出す考えの裏付けをするステップ 3: 核となるコンポーネントを設計するそれぞれの主要なコンポーネントについての詳細を学ぶ。例えば、url短縮サービスの設計を問われた際には次のようにするといいでしょう:元のURLのハッシュ化したものを作り、それを保存するMD5 と Base62ハッシュ衝突SQL もしくは NoSQLデータベーススキーマハッシュ化されたURLを元のURLに再翻訳するデータベース参照API & オブジェクト指向の設計ステップ 4: システム設計のスケール与えられた制約条件からボトルネックとなりそうなところを割り出し、明確化する。  例えば、スケーラビリティの問題解決のために以下の要素を考慮する必要があるだろうか？ロードバランサー水平スケーリングキャッシングデータベースシャーディング取りうる解決策とそのトレードオフについて議論をしよう。全てのことはトレードオフの関係にある。ボトルネックについてはスケーラブルなシステム設計の原理を読むといいでしょう。ちょっとした暗算問題ちょっとした推計値を手計算ですることを求められることもあるかもしれません。補遺の以下の項目が役に立つでしょう:チラ裏計算でシステム設計する2の乗数表全てのプログラマーが知っておくべきレイテンシの参考値文献とその他の参考資料以下のリンク先ページを見てどのような質問を投げかけられるか概要を頭に入れておきましょう:システム設計面接で成功するには？システム設計面接アーキテクチャ、システム設計面接への導入システム設計課題例とその解答頻出のシステム設計面接課題と参考解答、コード及びダイアグラム解答は solutions/ フォルダ以下にリンクが貼られている問題Pastebin.com (もしくは Bit.ly) を設計する解答Twitterタイムライン (もしくはFacebookフィード)を設計するTwitter検索(もしくはFacebook検索)機能を設計する解答ウェブクローラーを設計する解答Mint.comを設計する解答SNSサービスのデータ構造を設計する解答検索エンジンのキー/バリュー構造を設計する解答Amazonのカテゴリ毎の売り上げランキングを設計する解答AWS上で100万人規模のユーザーを捌くサービスを設計する解答システム設計問題を追加するContributePastebin.com (もしくは Bit.ly) を設計する問題と解答を見るTwitterタイムライン&検索 (もしくはFacebookフィード&検索)を設計する問題と解答を見るウェブクローラーの設計問題と解答を見るMint.comの設計問題と解答を見るSNSサービスのデータ構造を設計する問題と解答を見る検索エンジンのキー/バリュー構造を設計する問題と解答を見るAmazonのカテゴリ毎の売り上げランキングを設計する問題と解答を見るAWS上で100万人規模のユーザーを捌くサービスを設計する問題と解答を見るオブジェクト指向設計問題と解答頻出のオブジェクト指向システム設計面接課題と参考解答、コード及びダイアグラム解答は solutions/ フォルダ以下にリンクが貼られている備考: このセクションは作業中です問題ハッシュマップの設計解答LRUキャッシュの設計解答コールセンターの設計解答カードのデッキの設計解答駐車場の設計解答チャットサーバーの設計解答円形配列の設計Contributeオブジェクト指向システム設計問題を追加するContributeシステム設計トピックス: まずはここからシステム設計の勉強は初めて？まず初めに、よく使われる設計原理について、それらが何であるか、どのように用いられるか、長所短所について基本的な知識を得る必要がありますステップ 1: スケーラビリティに関する動画を観て復習するHarvardでのスケーラビリティの講義ここで触れられているトピックス:垂直スケーリング水平スケーリングキャッシングロードバランシングデータベースレプリケーションデータベースパーティションステップ 2: スケーラビリティに関する資料を読んで復習するスケーラビリティここで触れられているトピックス:クローンデータベースキャッシュ非同期次のステップ次に、ハイレベルでのトレードオフについてみていく:パフォーマンス vs スケーラビリティレイテンシ vs スループット可用性 vs 一貫性全てはトレードオフの関係にあるというのを肝に命じておきましょう。それから、より深い内容、DNSやCDNそしてロードバランサーなどについて学習を進めていきましょう。パフォーマンス vs スケーラビリティリソースが追加されるのにつれて パフォーマンス が向上する場合そのサービスは スケーラブル であると言えるでしょう。一般的に、パフォーマンスを向上させるというのはすなわち計算処理を増やすことを意味しますが、データセットが増えた時などより大きな処理を捌けるようになることでもあります。1パフォーマンスvsスケーラビリティをとらえる他の考え方:パフォーマンス での問題を抱えている時、あなたのシステムは一人のユーザーにとって遅いと言えるでしょう。スケーラビリティ での問題を抱えているとき、一人のユーザーにとっては速いですが、多くのリクエストがある時には遅くなってしまうでしょう。その他の参考資料、ページスケーラビリティについてスケーラビリティ、可用性、安定性、パターンレイテンシー vs スループットレイテンシー とはなにがしかの動作を行う、もしくは結果を算出するのに要する時間スループット とはそのような動作や結果算出が単位時間に行われる回数一般的に、 最大限のスループット を 許容範囲内のレイテンシー で実現することを目指すのが普通だ。その他の参考資料、ページレイテンシー vs スループットを理解する可用性 vs 一貫性CAP 理論      Source: CAP theorem revisited分散型コンピュータシステムにおいては下の三つのうち二つまでしか同時に保証することはできない。:一貫性 - 全ての読み込みは最新の書き込みもしくはエラーを受け取る可用性 - 受け取る情報が最新のものだという保証はないが、全てのリクエストはレスポンスを必ず受け取る分断耐性 - ネットワーク問題によって順不同の分断が起きてもシステムが動作を続けるネットワークは信頼できないので、分断耐性は必ず保証しなければなりません。つまりソフトウェアシステムとしてのトレードオフは、一貫性を取るか、可用性を取るかを考えなければなりません。CP - 一貫性と分断耐性(consistency and partition tolerance)分断されたノードからのレスポンスを待ち続けているとタイムアウトエラーに陥る可能性があります。CPはあなたのサービスがアトミックな読み書き（不可分操作）を必要とする際にはいい選択肢でしょう。AP - 可用性と分断耐性(availability and partition tolerance)レスポンスはノード上にあるデータで最新のものを返します。つまり、最新版のデータが返されるとは限りません。分断が解消された後も、書き込みが反映されるのには時間がかかります。結果整合性　を求めるサービスの際にはAPを採用するのがいいでしょう。もしくは、外部エラーに関わらずシステムが稼働する必要がある際にも同様です。その他の参考資料、ページCAP 理論を振り返る平易な英語でのCAP 理論のイントロCAP FAQ一貫性パターン同じデータの複製が複数ある状態では、クライアントが一貫したデータ表示を受け取るために、どのようにそれらを同期すればいいのかという課題があります。 CAP 理論 における一貫性の定義を思い出してみましょう。全ての読み取りは最新の書き込みデータもしくはエラーを受け取るはずです。弱い一貫性書き込み後の読み取りでは、その最新の書き込みを読めたり読めなかったりする。ベストエフォート型のアプローチに基づく。このアプローチはmemcachedなどのシステムに見られます。弱い一貫性はリアルタイム性が必要なユースケース、例えばVoIP、ビデオチャット、リアルタイムマルチプレイヤーゲームなどと相性がいいでしょう。例えば、電話に出ているときに数秒間音声が受け取れなくなったとしたら、その後に接続が回復してもその接続が切断されていた間に話されていたことは聞き取れないというような感じです。結果整合性書き込みの後、読み取りは最終的にはその結果を読み取ることができる(ミリ秒ほど遅れてというのが一般的です)。データは非同期的に複製されます。このアプローチはDNSやメールシステムなどに採用されています。結果整合性は多くのリクエストを捌くサービスと相性がいいでしょう。強い一貫性書き込みの後、読み取りはそれを必ず読むことができます。データは同期的に複製されます。このアプローチはファイルシステムやRDBMSなどで採用されています。トランザクションを扱うサービスでは強い一貫性が必要でしょう。その他の参考資料、ページデータセンター間でのトランザクション可用性パターン高い可用性を担保するには主に次の二つのパターンがあります: フェイルオーバー と レプリケーション です。フェイルオーバーアクティブ・パッシブアクティブ・パッシブフェイルオーバーにおいては、周期信号はアクティブもしくはスタンバイ中のパッシブなサーバーに送られます。周期信号が中断された時には、パッシブだったサーバーがアクティブサーバーのIPアドレスを引き継いでサービスを再開します。起動までのダウンタイムはパッシブサーバーが「ホット」なスタンバイ状態にあるか、「コールド」なスタンバイ状態にあるかで変わります。アクティブなサーバーのみがトラフィックを捌きます。アクティブ・パッシブフェイルオーバーはマスター・スレーブフェイルオーバーと呼ばれることもあります。アクティブ・アクティブアクティブアクティブ構成では両方のサーバーがトラフィックを捌くことで負荷を分散します。これらのサーバーがパブリックなものの場合、DNSは両方のサーバーのパブリックIPを知っている必要があります。もし、プライベートなものな場合、アプリケーションロジックが両方のサーバーの情報について知っている必要があります。アクティブ・アクティブなフェイルオーバーはマスター・マスターフェイルオーバーと呼ばれることもあります。短所: フェイルオーバーフェイルオーバーではより多くのハードウェアを要し、複雑さが増します。最新の書き込みがパッシブサーバーに複製される前にアクティブが落ちると、データ欠損が起きる潜在可能性があります。レプリケーションマスター・スレーブ　と　マスター・マスターこのトピックは データベース セクションにおいてより詳細に解説されています:マスター・スレーブ レプリケーションマスター・マスター レプリケーションドメインネームシステム      Source: DNS security presentationドメインネームシステム (DNS) は www.example.com などのドメインネームをIPアドレスへと翻訳します。DNSは少数のオーソライズされたサーバーが上位に位置する階層的構造です。あなたのルーターもしくはISPは検索をする際にどのDNSサーバーに接続するかという情報を提供します。低い階層のDNSサーバーはその経路マップをキャッシュします。ただ、この情報は伝搬遅延によって陳腐化する可能性があります。DNSの結果はあなたのブラウザもしくはOSに一定期間（time to live (TTL)に設定された期間）キャッシュされます。NS record (name server) - あなたのドメイン・サブドメインでのDNSサーバーを特定します。MX record (mail exchange) - メッセージを受け取るメールサーバーを特定します。A record (address) - IPアドレスに名前をつけます。CNAME (canonical) - 他の名前もしくは　CNAME (example.com を www.example.com) もしくは A recordへと名前を指し示す。CloudFlare や Route 53 などのサービスはマネージドDNSサービスを提供しています。いくつかのDNSサービスでは様々な手法を使ってトラフィックを捌くことができます:加重ラウンドロビントラフィックがメンテナンス中のサーバーに行くのを防ぎます様々なクラスターサイズに応じて調整しますA/B テストレイテンシーベース地理ベース欠点: DNS上記で示されているようなキャッシングによって緩和されているとはいえ、DNSサーバーへの接続には少し遅延が生じる。DNSサーバーは、政府、ISP企業,そして大企業に管理されているが、それらの管理は複雑である。DNSサービスはDDoS attackの例で、IPアドレスなしにユーザーがTwitterなどにアクセスできなくなったように、攻撃を受ける可能性がある。その他の参考資料、ページDNS アーキテクチャWikipediaDNS 記事コンテンツデリバリーネットワーク(Content delivery network)      Source: Why use a CDNコンテンツデリバリーネットワーク(CDN)は世界中に配置されたプロキシサーバーのネットワークがユーザーに一番地理的に近いサーバーからコンテンツを配信するシステムのことです。AmazonのCloudFrontなどは例外的にダイナミックなコンテンツも配信しますが、一般的に、HTML/CSS/JS、写真、そして動画などの静的ファイルがCDNを通じて配信されます。そのサイトのDNSがクライアントにどのサーバーと交信するかという情報を伝えます。CDNを用いてコンテンツを配信することで以下の二つの理由でパフォーマンスが劇的に向上します:ユーザーは近くにあるデータセンターから受信できるバックエンドサーバーはCDNが処理してくれるリクエストに関しては処理する必要がなくなりますプッシュCDNプッシュCDNではサーバーデータに更新があった時には必ず、新しいコンテンツを受け取る方式です。コンテンツを用意し、CDNに直接アップロードし、URLをCDNを指すように指定するところまで、全て自分で責任を負う形です。コンテンツがいつ期限切れになるのか更新されるのかを設定することができます。コンテンツは新規作成時、更新時のみアップロードされることでトラフィックは最小化される一方、ストレージは最大限消費されてしまいます。トラフィックの少ない、もしくは頻繁にはコンテンツが更新されないサイトの場合にはプッシュCDNと相性がいいでしょう。コンテンツは定期的に再びプルされるのではなく、CDNに一度のみ配置されます。プルCDNプルCDNでは一人目のユーザーがリクエストした時に、新しいコンテンツをサービスのサーバーから取得します。コンテンツは自分のサーバーに保存して、CDNを指すURLを書き換えます。結果として、CDNにコンテンツがキャッシュされるまではリクエスト処理が遅くなります。time-to-live (TTL) はコンテンツがどれだけの期間キャッシュされるかを規定します。プルCDNはCDN 上でのストレージスペースを最小化しますが、有効期限が切れたファイルが更新前にプルされてしまうことで冗長なトラフィックに繋がってしまう可能性があります。大規模なトラフィックのあるサイトではプルCDNが相性がいいでしょう。というのも、トラフィックの大部分は最近リクエストされ、CDNに残っているコンテンツにアクセスするものであることが多いからです。欠点: CDNCDNのコストはトラフィック量によって変わります。もちろん、CDNを使わない場合のコストと比較するべきでしょう。TTLが切れる前にコンテンツが更新されると陳腐化する恐れがあります。CDNでは静的コンテンツがCDNを指すようにURLを更新する必要があります。その他の参考資料、ページグローバルに分散されたコンテンツデリバリーネットワークプッシュCDNとプルCDNの違いWikipediaロードバランサー      Source: Scalable system design patternsロードバランサーは入力されるクライアントのリクエストをアプリケーションサーバーやデータベースへと分散させる。どのケースでもロードバランサーはサーバー等計算リソースからのレスポンスを適切なクライアントに返す。ロードバランサーは以下のことに効果的です:リクエストが状態の良くないサーバーに行くのを防ぐリクエストを過剰に送るのを防ぐ特定箇所の欠陥でサービスが落ちることを防ぐロードバランサーは (費用の高い) ハードウェアもしくはHAProxyなどのソフトウェアで実現できる。他の利点としては:SSL termination - 入力されるリクエストを解読する、また、サーバーレスポンスを暗号化することでバックエンドのサーバーがこのコストが高くつきがちな処理を請け負わなくていいように肩代わりします。X.509 certificates をそれぞれのサーバーにインストールする必要をなくしますセッション管理 - クッキーを取り扱うウェブアプリがセッション情報を保持していない時などに、特定のクライアントのリクエストを同じインスタンスへと流します。障害に対応するために、アクティブ・パッシブ もしくは アクティブ・アクティブ モードのどちらにおいても、複数のロードバランサーを配置するのが一般的です。ロードバランサーは以下のような種々のメトリックを用いてトラフィックルーティングを行うことができます:ランダムLeast loadedセッション/クッキーラウンドロビンもしくは加重ラウンドロビンLayer 4Layer 7Layer 4 ロードバランシングLayer 4 ロードバランサーは トランスポートレイヤー を参照してどのようにリクエストを配分するか判断します。一般的に、トランスポートレイヤーとしては、ソース、送信先IPアドレス、ヘッダーに記述されたポート番号が含まれますが、パケットの中身のコンテンツは含みません。 Layer 4 ロードバランサーはネットワークパケットを上流サーバーへ届け、上流サーバーから配信することでネットワークアドレス変換 Network Address Translation (NAT) を実現します。Layer 7 ロードバランシングLayer 7 ロードバランサーは アプリケーションレイヤー を参照してどのようにリクエストを配分するか判断します。ヘッダー、メッセージ、クッキーなどのコンテンツのことです。Layer 7 ロードバランサーはネットワークトラフィックの終端を受け持ち メッセージを読み込み、ロードバランシングの判断をし、選択したサーバーとの接続を繋ぎます。例えば layer 7 ロードバランサーは動画のトラフィックを直接、そのデータをホストしているサーバーにつなぐと同時に、決済処理などのより繊細なトラフィックをセキュリティ強化されたサーバーに流すということもできる。柔軟性とのトレードオフになりますが、 layer 4 ロードバランサーではLayer 7ロードバランサーよりも所要時間、計算リソースを少なく済ませることができます。ただし、昨今の汎用ハードウェアではパフォーマンスは最小限のみしか発揮できないでしょう。水平スケーリングロードバランサーでは水平スケーリングによってパフォーマンスと可用性を向上させることができます。手頃な汎用マシンを追加することによってスケールアウトさせる方が、一つのサーバーをより高価なマシンにスケールアップする（垂直スケーリング）より費用対効果も高くなり、結果的に可用性も高くなります。また、汎用ハードウェアを扱える人材を雇う方が、特化型の商用ハードウェアを扱える人材を雇うよりも簡単でしょう。欠点: 水平スケーリング水平的にスケーリングしていくと、複雑さが増す上に、サーバーのクローニングが必要になる。サーバーはステートレスである必要がある: ユーザーに関連するセッションや、プロフィール写真などのデータを持ってはいけないセッションは一元的なデータベース (SQL、 NoSQL)などのデータストアにストアされるか キャッシュ (Redis、 Memcached)に残す必要があります。キャッシュやデータベースなどの下流サーバーは上流サーバーがスケールアウトするにつれてより多くの同時接続を保たなければなりません。欠点: ロードバランサーロードバランサーはリソースが不足していたり、設定が適切でない場合、システム全体のボトルネックになる可能性があります。単一障害点を除こうとしてロードバランサーを導入した結果、複雑さが増してしまうことになります。ロードバランサーが一つだけだとそこが単一障害点になってしまいます。一方で、ロードバランサーを複数にすると、さらに複雑さが増してしまいます。その他の参考資料、ページNGINX アーキテクチャHAProxy アーキテクチャガイドスケーラビリティWikipediaLayer 4 ロードバランシングLayer 7 ロードバランシングELB listener configリバースプロキシ(webサーバー)      Source: Wikipedia  リバースプロキシサーバーは内部サービスをまとめて外部に統一されたインターフェースを提供するウェブサーバーです。クライアントからのリクエストはそれに対応するサーバーに送られて、その後レスポンスをリバースプロキシがクライアントに返します。他には以下のような利点があります:より堅牢なセキュリティ - バックエンドサーバーの情報を隠したり、IPアドレスをブラックリスト化したり、クライアントごとの接続数を制限したりできます。スケーラビリティや柔軟性が増します - クライアントはリバースプロキシのIPしか見ないので、裏でサーバーをスケールしたり、設定を変えやすくなります。SSL termination - 入力されるリクエストを解読し、サーバーのレスポンスを暗号化することでサーバーがこのコストのかかりうる処理をしなくて済むようになります。X.509 証明書 を各サーバーにインストールする必要がなくなります。圧縮 - サーバーレスポンスを圧縮できますキャッシング - キャッシュされたリクエストに対して、レスポンスを返します静的コンテンツ - 静的コンテンツを直接送信することができます。HTML/CSS/JS写真動画などなどロードバランサー vs リバースプロキシ複数のサーバーがある時にはロードバランサーをデプロイすると役に立つでしょう。 しばしば、ロードバランサーは同じ機能を果たすサーバー群へのトラフィックを捌きます。リバースプロキシでは、上記に述べたような利点を、単一のウェブサーバーやアプリケーションレイヤーに対しても示すことができます。NGINX や HAProxy などの技術はlayer 7 リバースプロキシとロードバランサーの両方をサポートします。欠点: リバースプロキシリバースプロキシを導入するとシステムの複雑性が増します。単一のリバースプロキシは単一障害点になりえます。一方で、複数のリバースプロキシを導入すると(例: フェイルオーバー) 複雑性はより増します。その他の参考資料、ページリバースプロキシ vs ロードバランサーNGINX アーキテクチャHAProxy アーキテクチャ ガイドWikipediaアプリケーション層      Source: Intro to architecting systems for scaleウェブレイヤーをアプリケーション層 (プラットフォーム層とも言われる) と分離することでそれぞれの層を独立にスケール、設定することができるようになります。新しいAPIをアプリケーション層に追加する際に、不必要にウェブサーバーを追加する必要がなくなります。単一責任の原則 では、小さい自律的なサービスが協調して動くように提唱しています。小さいサービスの小さいチームが急成長のためにより積極的な計画を立てられるようにするためです。アプリケーション層は非同期処理もサポートします。マイクロサービス独立してデプロイできる、小規模なモジュール様式であるマイクロサービスもこの議論に関係してくる技術でしょう。それぞれのサービスは独自のプロセスを処理し、明確で軽量なメカニズムで通信して、その目的とする機能を実現します。1例えばPinterestでは以下のようなマイクロサービスに分かれています。ユーザープロフィール、フォロワー、フィード、検索、写真アップロードなどです。サービスディスカバリーConsul、 Etcd、 Zookeeper などのシステムでは、登録されているサービスの名前、アドレス、ポートの情報を監視することで、サービス同士が互いを見つけやすくしています。サービスの完全性の確認には Health checks が便利で、これには HTTP エンドポイントがよく使われます。 Consul と Etcd のいずれも組み込みの key-value store を持っており、設定データや共有データなどのデータを保存しておくことに使われます。欠点: アプリケーション層アーキテクチャ、運用、そしてプロセスを考慮すると、緩く結び付けられたアプリケーション層を追加するには、モノリシックなシステムとは異なるアプローチが必要です。マイクロサービスはデプロイと運用の点から見ると複雑性が増すことになります。その他の参考資料、ページスケールするシステムアーキテクチャを設計するためのイントロシステム設計インタビューを紐解くサービス指向アーキテクチャZookeeperのイントロダクションマイクロサービスを作るために知っておきたいことデータベース      Source: Scaling up to your first 10 million usersリレーショナルデータベースマネジメントシステム (RDBMS)SQLなどのリレーショナルデータベースはテーブルに整理されたデータの集合である。ACID はリレーショナルデータベースにおけるトランザクションのプロパティの集合である不可分性 - それぞれのトランザクションはあるかないかのいずれかである一貫性 - どんなトランザクションもデータベースをある確かな状態から次の状態に遷移させる。独立性 - 同時にトランザクションを処理することは、連続的にトランザクションを処理するのと同じ結果をもたらす。永続性 - トランザクションが処理されたら、そのように保存されるリレーショナルデータベースをスケールさせるためにはたくさんの技術がある: マスター・スレーブ レプリケーション、 マスター・マスター レプリケーション、 federation、 シャーディング、 非正規化、 そして SQL チューニングマスタースレーブ レプリケーションマスターデータベースが読み取りと書き込みを処理し、書き込みを一つ以上のスレーブデータベースに複製します。スレーブデータベースは読み取りのみを処理します。スレーブデータベースは木構造のように追加のスレーブにデータを複製することもできます。マスターデータベースがオフラインになった場合には、いずれかのスレーブがマスターに昇格するか、新しいマスターデータベースが追加されるまでは読み取り専用モードで稼働します。      Source: Scalability, availability, stability, patterns欠点: マスタースレーブ レプリケーションスレーブをマスターに昇格させるには追加のロジックが必要になる。マスタースレーブ レプリケーション、マスターマスター レプリケーションの 両方 の欠点は欠点: レプリケーションを参照マスターマスター レプリケーションいずれのマスターも読み取り書き込みの両方に対応する。書き込みに関してはそれぞれ協調する。いずれかのマスターが落ちても、システム全体としては読み書き両方に対応したまま運用できる。      Source: Scalability, availability, stability, patterns欠点: マスターマスター レプリケーションロードバランサーを導入するか、アプリケーションロジックを変更することでどこに書き込むかを指定しなければならない。大体のマスターマスターシステムは、一貫性が緩い（ACID原理を守っていない）もしくは、同期する時間がかかるために書き込みのレイテンシーが増加してしまっている。書き込みノードが追加され、レイテンシーが増加するにつれ書き込みの衝突の可能性が増える。マスタースレーブ レプリケーション、マスターマスター レプリケーションの 両方 の欠点は欠点: レプリケーション を参照欠点: レプリケーション新しいデータ書き込みを複製する前にマスターが落ちた場合にはそのデータが失われてしまう可能性がある。書き込みは読み取りレプリカにおいてリプレイされる。書き込みが多い場合、複製ノードが書き込みの処理のみで行き詰まって、読み取りの処理を満足に行えない可能性がある。読み取りスレーブノードの数が多ければ多いほど、複製しなければならない数も増え、複製時間が伸びてしまいます。システムによっては、マスターへの書き込みはマルチスレッドで並列処理できる一方、スレーブへの複製は単一スレッドで連続的に処理しなければならない場合があります。レプリケーションでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: レプリケーションスケーラビリティ、 可用性、 スタビリティ パターンマルチマスター レプリケーションFederation      Source: Scaling up to your first 10 million usersフェデレーション (もしくは機能分割化とも言う) はデータベースを機能ごとに分割する。例えば、モノリシックな単一データベースの代わりに、データベースを フォーラム、 ユーザー、 プロダクト のように三つにすることで、データベース一つあたりの書き込み・読み取りのトラフィックが減り、その結果レプリケーションのラグも短くなります。データベースが小さくなることで、メモリーに収まるデータが増えます。キャッシュの局所性が高まるため、キャッシュヒット率も上がります。単一の中央マスターで書き込みを直列化したりしないため、並列で書き込みを処理することができ、スループットの向上が期待できます。欠点: federation大規模な処理やテーブルを要するスキーマの場合、フェデレーションは効果的とは言えないでしょう。どのデータベースに読み書きをするのかを指定するアプリケーションロジックを更新しなければなりません。server linkで二つのデータベースからのデータを連結するのはより複雑になるでしょう。フェデレーションでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: federationScaling up to your first 10 million usersシャーディング      Source: Scalability, availability, stability, patternsシャーディングでは異なるデータベースにそれぞれがデータのサブセット断片のみを持つようにデータを分割します。ユーザーデータベースを例にとると、ユーザー数が増えるにつれてクラスターにはより多くの断片が加えられることになります。federationの利点に似ていて、シャーディングでは読み書きのトラフィックを減らし、レプリケーションを減らし、キャッシュヒットを増やすことができます。インデックスサイズも減らすことができます。一般的にはインデックスサイズを減らすと、パフォーマンスが向上しクエリ速度が速くなります。なにがしかのデータを複製する機能がなければデータロスにつながりますが、もし、一つのシャードが落ちても、他のシャードが動いていることになります。フェデレーションと同じく、単一の中央マスターが書き込みの処理をしなくても、並列で書き込みを処理することができ、スループットの向上が期待できます。ユーザーテーブルをシャードする一般的な方法は、ユーザーのラストネームイニシャルでシャードするか、ユーザーの地理的配置でシャードするなどです。欠点: シャーディングシャードに対応するようにアプリケーションロジックを変更しなければなりません。結果としてSQLクエリが複雑になります。シャードではデータ配分がいびつになってしまう可能性があります。例えば、標準ユーザーの集合を持つシャードがある場合、そのシャードが他のシャードよりも重い負荷を負うことになります。リバランシングをすると複雑性がより増します。consistent hashing に基づいたシャーディングでは、通信データを削減することもできます。複数のシャードからのデータを連結するのはより複雑です。シャーディングでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: シャーディングシャードの登場シャードデータベースアーキテクチャConsistent hashing非正規化非正規化では、書き込みのパフォーマンスをいくらか犠牲にして読み込みのパフォーマンスを向上させようとします。計算的に重いテーブルの結合などをせずに、複数のテーブルに冗長なデータのコピーが書き込まれるのを許容します。いくつかのRDBMS例えば、PostgreSQL やOracleはこの冗長な情報を取り扱い、一貫性を保つためのmaterialized views という機能をサポートしています。フェデレーション や シャーディングなどのテクニックによってそれぞれのデータセンターに分配されたデータを合一させることはとても複雑な作業です。非正規化によってそのような複雑な処理をしなくて済むようになります。多くのシステムで、100対1あるいは1000対1くらいになるくらい読み取りの方が、書き込みのトラフィックよりも多いことでしょう。読み込みを行うために、複雑なデータベースのジョイン処理が含まれるものは計算的に高価につきますし、ディスクの処理時間で膨大な時間を費消してしまうことになります。欠点: 非正規化データが複製される。冗長なデータの複製が同期されるように制約が存在し、そのことでデータベース全体の設計が複雑化する。非正規化されたデータベースは過大な書き込みを処理しなければならない場合、正規化されているそれよりもパフォーマンスにおいて劣る可能性がある。その他の参考資料、ページ: 非正規化DenormalizationSQLチューニングSQLチューニングは広範な知識を必要とする分野で多くの 本 が書かれています。ボトルネックを明らかにし、シミュレートする上で、 ベンチマーク を定め、 プロファイル することはとても重要です。ベンチマーク - abなどのツールを用いて、高負荷の状況をシミュレーションしてみましょう。プロファイル - slow query log などのツールを用いて、パフォーマンス状況の確認をしましょう。ベンチマークとプロファイルをとることで以下のような効率化の選択肢をとることになるでしょう。スキーマを絞るMySQLはアクセス速度向上のため、ディスク上の連続したブロックへデータを格納しています。長さの決まったフィールドに対しては VARCHAR よりも CHAR を使うようにしましょう。CHAR の方が効率的に速くランダムにデータにアクセスできます。 一方、 VARCHAR では次のデータに移る前にデータの末尾を検知しなければならないために速度が犠牲になります。ブログの投稿など、大きなテキストには TEXT を使いましょう。 TEXT ではブーリアン型の検索も可能です。 TEXT フィールドには、テキストブロックが配置されている、ディスク上の場所へのポインターが保存されます。2の32乗や40億以下を超えない程度の大きな数には INT を使いましょう。通貨に関しては小数点表示上のエラーを避けるために DECIMAL を使いましょう。大きな BLOBS を保存するのは避けましょう。どこからそのオブジェクトを取ってくることができるかの情報を保存しましょう。VARCHAR(255) は8ビットで数えられる最大の文字数です。一部のDBMSでは、1バイトの利用効率を最大化するためにこの文字数がよく使われます。検索性能向上のため 、可能であれば NOT NULL 制約を設定しましょう。インデックスを効果的に用いるクエリ(SELECT、 GROUP BY、 ORDER BY、 JOIN) の対象となる列にインデックスを使うことで速度を向上できるかもしれません。インデックスは通常、平衡探索木であるB木の形で表されます。B木によりデータは常にソートされた状態になります。また検索、順次アクセス、挿入、削除を対数時間で行えます。インデックスを配置することはデータをメモリーに残すことにつながりより容量を必要とします。インデックスの更新も必要になるため書き込みも遅くなります。大量のデータをロードする際には、インデックスを切ってからデータをロードして再びインデックスをビルドした方が速いことがあります。高負荷なジョインを避けるパフォーマンス上必要なところには非正規化を適用するテーブルのパーティションテーブルを分割し、ホットスポットを独立したテーブルに分離してメモリーに乗せられるようにする。クエリキャッシュを調整する場合によってはクエリキャッシュ がパフォーマンス問題 を引き起こす可能性があるその他の参考資料、ページ: SQLチューニングMySQLクエリを最適化するためのTipsVARCHAR(255)をやたらよく見かけるのはなんで？null値はどのようにパフォーマンスに影響するのか？Slow query logNoSQLNoSQL は key-value store、 document-store、 wide column store、 もしくは graph databaseによって表現されるデータアイテムの集合です。データは一般的に正規化されておらず、アプリケーション側でジョインが行われます。大部分のNoSQLは真のACIDトランザクションを持たず、 結果整合性 的な振る舞いの方を好みます。BASE はしばしばNoSQLデータベースのプロパティを説明するために用いられます。CAP Theorem と対照的に、BASEは一貫性よりも可用性を優先します。Basically available - システムは可用性を保証します。Soft state - システムの状態は入力がなくても時間経過とともに変化する可能性があります。結果整合性 - システム全体は時間経過とともにその間に入力がないという前提のもと、一貫性が達成されます。SQLか？NoSQLか？ を選択するのに加えて、どのタイプのNoSQLがどの使用例に最も適するかを理解するのはとても有益です。このセクションでは キーバリューストア、 ドキュメントストア、 ワイドカラムストア、 と グラフデータベース について触れていきます。キーバリューストア概要: ハッシュテーブルキーバリューストアでは一般的にO(1)の読み書きができ、それらはメモリないしSSDで裏付けられています。データストアはキーを 辞書的順序 で保持することでキーの効率的な取得を可能にしています。キーバリューストアではメタデータを値とともに保持することが可能です。キーバリューストアはハイパフォーマンスな挙動が可能で、単純なデータモデルやインメモリーキャッシュレイヤーなどのデータが急速に変わる場合などに使われます。単純な処理のみに機能が制限されているので、追加の処理機能が必要な場合にはその複雑性はアプリケーション層に載せることになります。キーバリューストアはもっと複雑なドキュメントストアや、グラフデータベースなどの基本です。その他の参考資料、ページ: キーバリューストアキーバリューデータベースキーバリューストアの欠点Redisアーキテクチャメムキャッシュアーキテクチャドキュメントストア概要: ドキュメントがバリューとして保存されたキーバリューストアドキュメントストアはオブジェクトに関する全ての情報を持つドキュメント(XML、 JSON、 binaryなど)を中心に据えたシステムです。ドキュメントストアでは、ドキュメント自身の内部構造に基づいた、APIもしくはクエリ言語を提供します。 メモ：多くのキーバリューストアでは、値のメタデータを扱う機能を含んでいますが、そのことによって二つドキュメントストアとの境界線が曖昧になってしまっています。以上のことを実現するために、ドキュメントはコレクション、タグ、メタデータやディレクトリなどとして整理されています。ドキュメント同士はまとめてグループにできるものの、それぞれで全く異なるフィールドを持つ可能性があります。MongoDB や CouchDB などのドキュメントストアも、複雑なクエリを処理するためのSQLのような言語を提供しています。DynamoDB はキーバリューとドキュメントの両方をサポートしています。ドキュメントストアは高い柔軟性を担保するので、頻繁に変化するデータを扱う時に用いられます。その他の参考資料、ページ:  ドキュメントストアドキュメント指向 データベースMongoDB アーキテクチャCouchDB アーキテクチャElasticsearch アーキテクチャワイドカラムストア      Source: SQL & NoSQL, a brief history概要: ネストされたマップ カラムファミリー<行キー、 カラム<ColKey、 Value、 Timestamp>>ワイドカラムストアのデータの基本単位はカラム（ネーム・バリューのペア）です。それぞれのカラムはカラムファミリーとして（SQLテーブルのように）グループ化することができます。スーパーカラムファミリーはカラムファミリーの集合です。それぞれのカラムには行キーでアクセスすることができます。同じ行キーを持つカラムは同じ行として認識されます。それぞれの値は、バージョン管理とコンフリクトが起きた時のために、タイムスタンプを含みます。GoogleはBigtableを初のワイドカラムストアとして発表しました。それがオープンソースでHadoopなどでよく使われるHBase やFacebookによるCassandra などのプロジェクトに影響を与えました。BigTable、HBaseやCassandraなどのストアはキーを辞書形式で保持することで選択したキーレンジでのデータ取得を効率的にします。ワイドカラムストアは高い可用性とスケーラビリティを担保します。これらはとても大規模なデータセットを扱うことによく使われます。その他の参考資料、ページ:  ワイドカラムストアSQL & NoSQL簡単に歴史をさらうBigtable アーキテクチャHBase アーキテクチャCassandra アーキテクチャグラフデータベース      Source: Graph database概要: グラフグラフデータベースでは、それぞれのノードがレコードで、それぞれのアークは二つのノードを繋ぐ関係性として定義されます。グラフデータベースは多数の外部キーや多対多などの複雑な関係性を表すのに最適です。グラフデータベースはSNSなどのサービスの複雑な関係性モデルなどについて高いパフォーマンスを発揮します。比較的新しく、まだ一般的には用いられていないので、開発ツールやリソースを探すのが他の方法に比べて難しいかもしれません。多くのグラフはREST APIsを通じてのみアクセスできます。その他の参考資料、ページ:  グラフGraphデータベースNeo4jFlockDBその他の参考資料、ページ:  NoSQL基本用語の説明NoSQLデータベースについて調査と選択ガイドスケーラビリティNoSQLのイントロダクションNoSQLパターンSQLか？NoSQLか？      Source: Transitioning from RDBMS to NoSQLSQL を選ぶ理由:構造化されたデータ厳格なスキーマリレーショナルデータ複雑なジョインをする必要性トランザクションスケールする際のパターンが明確なとき開発者の数、コミュニティ、コード等がより充実しているインデックスによるデータ探索はとても速いNoSQL を選ぶ理由:準構造化されたデータダイナミックないし、フレキシブルなスキーマノンリレーショナルなデータ複雑なジョインをする必要がないデータの多くのTB (もしくは PB) を保存する集中的、大規模なデータ負荷に耐えられるIOPSについては極めて高いスループットを示すNoSQLに適するサンプルデータ:急激なクリックストリームやログデータの収集リーダーボードやスコアリングデータショッピングカートなどの一時的情報頻繁にアクセスされる ('ホットな') テーブルメタデータやルックアップテーブルその他の参考資料、ページ:  　SQLもしくはNoSQL最初の1000万ユーザーにスケールアップするためにSQLとNoSQLの違いキャッシュ      Source: Scalable system design patternsキャッシュはページの読み込み時間を削減し、サーバーやデータベースへの負荷を低減することができます。このモデルでは、実際の処理を保存するために、ディスパッチャーがまず以前にリクエストが送信されたかどうかを確認し、直前の結果を受け取ります。データベースはそのパーティションに渡って統合された読み取り書き込みの分配を要求しますが、人気アイテムはその分配を歪めてシステム全体のボトルネックになってしまうことがあります。データベースの前にキャッシュを差し込むことでこのように、均一でない負荷やトラフィックの急激な増加を吸収することができます。クライアントキャッシングキャッシュはOSやブラウザーなどのクライアントサイド、サーバーサイド もしくは独立のキャッシュレイヤーに設置することができます。CDNキャッシングCDN もキャッシュの一つとして考えることができます。Webサーバーキャッシングリバースプロキシ や Varnish などのキャッシュは静的そして動的なコンテンツを直接配信することができます。 webサーバーもリクエストをキャッシュしてアプリケーションサーバーに接続することなしにレスポンスを返すことができます。データベースキャッシングデータベースは普通、一般的な使用状況に適するようなキャッシングの設定を初期状態で持っています。この設定を特定の仕様に合わせて調整することでパフォーマンスを向上させることができます。アプリケーションキャッシングメムキャッシュなどのIn-memoryキャッシュやRedisはアプリケーションとデータストレージの間のキーバリューストアです。データはRAMで保持されるため、データがディスクで保存される一般的なデータベースよりもだいぶ速いです。RAM容量はディスクよりも限られているので、least recently used (LRU)などのcache invalidation アルゴリズムが 'コールド' なエントリを弾き、'ホット' なデータをRAMに保存します。Redisはさらに以下のような機能を備えています:パージステンス設定ソート済みセット、リストなどの組み込みデータ構造キャッシュには様々なレベルのものがありますが、いずれも大きく二つのカテゴリーのいずれかに分類することができます: データベースクエリ と オブジェクト です:行レベルクエリレベルFully-formed serializable objectsFully-rendered HTML一般的に、ファイルベースキャッシングはクローンを作り出してオートスケーリングを難しくしてしまうので避けるべきです。データベースクエリレベルでのキャッシングデータベースをクエリする際には必ずクエリをキーとしてハッシュして結果をキャッシュに保存しましょう。この手法はキャッシュ期限切れ問題に悩むことになります:複雑なクエリによりキャッシュされた結果を削除することが困難テーブルセルなどのデータ断片が変化した時に、その変化したセルを含むかもしれない全てのキャッシュされたクエリを削除する必要がある。オブジェクトレベルでのキャッシングデータをアプリケーションコードでそうするように、オブジェクトとして捉えてみましょう。アプリケーションに、データベースからのデータセットをクラスインスタンスやデータ構造として組み立てさせます。:そのデータが変更されたら、オブジェクトをキャッシュから削除すること非同期処理を許容します: ワーカーがキャッシュされたオブジェクトの中で最新のものを集めてきます何をキャッシュするか:ユーザーのセッション完全にレンダーされたウェブページアクテビティストリームユーザーグラフデータいつキャッシュを更新するかキャッシュに保存できる容量は限られているため、自分のケースではどのキャッシュ手法が一番いいかは検討する必要があります。キャッシュアサイド      Source: From cache to in-memory data gridアプリケーションはストレージへの読み書きの処理をします。キャッシュはストレージとは直接やりとりをしません。アプリケーションは以下のことをします:キャッシュの中のエントリを参照しますが、結果としてキャッシュミスになりますデータベースからエントリを取得しますエントリをキャッシュに追加しますエントリを返しますdef get_user(self, user_id):    user = cache.get(\""user.{0}\"", user_id)    if user is None:        user = db.query(\""SELECT * FROM users WHERE user_id = {0}\"", user_id)        if user is not None:            key = \""user.{0}\"".format(user_id)            cache.set(key, json.dumps(user))    return userMemcached は通常このように使われる。その後のキャッシュデータ読み込みは速いです。キャッシュアサイドはレージーローディングであるとも言われます。リクエストされたデータのみがキャッシュされ、リクエストされていないデータでキャッシュが溢れるのを防止します。欠点: キャッシュアサイド各キャッシュミスは三つのトリップを呼び出すことになり、体感できるほどの遅延が起きてしまいます。データベースのデータが更新されるとキャッシュデータは古いものになってしまいます。time-to-live (TTL)を設定することでキャッシュエントリの更新を強制的に行う、もしくはライトスルーを採用することでこの問題は緩和できます。ノードが落ちると、新規の空のノードで代替されることでレイテンシーが増加することになります。ライトスルー      Source: Scalability, availability, stability, patternsアプリケーションはキャッシュをメインのデータストアとして使い、そこにデータの読み書きを行います。一方、キャッシュはデータベースへの読み書きを担当します。アプリケーションはキャッシュにあるエントリを追加・更新しますキャッシュは同期的にデータストアに書き込みを行いますエントリを返しますアプリケーションコード:set_user(12345, {\""foo\"":\""bar\""})キャッシュコード:def set_user(user_id, values):    user = db.query(\""UPDATE Users WHERE id = {0}\"", user_id, values)    cache.set(user_id, user)ライトスルーは書き込み処理のせいで全体としては遅いオペレーションですが、書き込まれたばかりのデータに関する読み込みは速いです。ユーザー側は一般的にデータ更新時の方が読み込み時よりもレイテンシーに許容的です。キャッシュ内のデータは最新版で保たれます。欠点: ライトスルーノードが落ちたこと、もしくはスケーリングによって新しいノードが作成された時に、新しいノードはデータベース内のエントリーが更新されるまではエントリーをキャッシュしません。キャッシュアサイドとライトスルーを併用することでこの問題を緩和できます。書き込まれたデータの大部分は一度も読み込まれることはありません。このデータはTTLによって圧縮することができます。ライトビハインド (ライトバック)      Source: Scalability, availability, stability, patternsライトビハインドではアプリケーションは以下のことをします:キャッシュのエントリーを追加・更新しますデータストアへの書き込みを非同期的に行うことで、書き込みパフォーマンスを向上させます。欠点: ライトビハインドキャッシュがデータストア内のコンテンツにヒットする前にキャッシュが落ちるとデータ欠損が起きる可能性があります。キャッシュアサイドやライトスルーよりも実装が複雑になります。リフレッシュアヘッド      Source: From cache to in-memory data grid期限切れよりも前に、直近でアクセスされた全てのキャッシュエントリを自動的に更新するように設定することができます。もしどのアイテムが将来必要になるのかを正確に予測することができるのならば、リードスルーよりもレイテンシーを削減することができます。欠点: リフレッシュアヘッドどのアイテムが必要になるかの予測が正確でない場合にはリフレッシュアヘッドがない方がレイテンシーは良いという結果になってしまいます。欠点: キャッシュcache invalidationなどを用いて、データベースなどの真のデータとキャッシュの間の一貫性を保つ必要があります。Redisやmemcachedを追加することでアプリケーション構成を変更する必要があります。Cache invalidationも難しいですがそれに加えて、いつキャッシュを更新するかという複雑な問題にも悩まされることになります。その他の参考資料、ページFrom cache to in-memory data gridスケーラブルなシステムデザインパターンスケールできるシステムを設計するためのイントロダクションスケーラビリティ、可用性、安定性、パターンスケーラビリティAWS ElastiCacheのストラテジーWikipedia非同期処理      Source: Intro to architecting systems for scale非同期のワークフローはもし、連続的に行われるとリクエスト時間を圧迫してしまうような重い処理を別で処理する手法です。また、定期的にデータを集合させるなどの時間がかかるような処理を前もって処理しておくことにも役立ちます。メッセージキューメッセージキューはメッセージを受け取り、保存し、配信します。もし、処理がインラインで行うには遅すぎる場合、以下のようなワークフローでメッセージキューを用いるといいでしょう:アプリケーションはジョブをキューに配信し、ユーザーにジョブステータスを伝えます。ワーカーがジョブキューから受け取って、処理を行い、終了したらそのシグナルを返します。ユーザーの処理が止まることはなく、ジョブはバックグラウンドで処理されます。この間に、クライアントはオプションとして、タスクが完了したかのように見せるために小規模の処理を行います。例えば、ツイートを投稿するときに、ツイートはすぐにあなたのタイムラインに反映されたように見えますが、そのツイートが実際に全てのフォロワーに配信されるまでにはもう少し時間がかかっているでしょう。Redis はシンプルなメッセージ仲介としてはいいですが、メッセージが失われてしまう可能性があります。RabbitMQ はよく使われていますが、'AMQP'プロトコルに対応して、自前のノードを立てる必要があります。Amazon SQS という選択肢もありますが、レイテンシーが高く、メッセージが重複して配信されてしまう可能性があります。タスクキュータスクキューはタスクとその関連するデータを受け取り、処理した上でその結果を返します。スケジュール管理をできるほか、バックグラウンドでとても重いジョブをこなすこともできます。Celery はスケジューリングとpythonのサポートがあります。バックプレッシャーもし、キューが拡大しすぎると、メモリーよりもキューの方が大きくなりキャッシュミスが起こり、ディスク読み出しにつながり、パフォーマンスが低下することにつながります。バックプレッシャーはキューサイズを制限することで回避することができ、高いスループットを確保しキューにすでにあるジョブについてのレスポンス時間を短縮できます。キューがいっぱいになると、クライアントはサーバービジーもしくはHTTP 503をレスポンスとして受け取りまた後で時間をおいてアクセスするようにメッセージを受け取ります。クライアントはexponential backoffなどによって後ほど再度時間を置いてリクエストすることができます。欠点: 非同期処理キューを用いることで遅延が起こり、複雑さも増すため、あまり重くない計算処理やリアルタイムワークフローにおいては同期処理の方がいいでしょう。その他の参考資料、ページIt's all a numbers gameオーバーロードした時にバックプレッシャーを適用するLittle's lawメッセージキューとタスクキューの違いとは？通信      Source: OSI 7 layer modelHypertext transfer protocol (HTTP)HTTP はクライアントとサーバー間でのデータをエンコードして転送するための手法です。リクエスト・レスポンスに関わるプロトコルです。クライアントがリクエストをサーバーに投げ、サーバーがリクエストに関係するコンテンツと完了ステータス情報をレスポンスとして返します。HTTPは自己完結するので、間にロードバランサー、キャッシュ、エンクリプション、圧縮などのどんな中間ルーターが入っても動くようにできています。基本的なHTTPリクエストはHTTP動詞(メソッド)とリソース(エンドポイント)で成り立っています。以下がよくあるHTTP動詞です。:動詞詳細冪等性*セーフキャッシュできるかGETリソースを読み取るYesYesYesPOSTリソースを作成するもしくはデータを処理するトリガーNoNoYes レスポンスが新しい情報を含む場合PUTリソースを作成もしくは入れ替えるYesNoNoPATCHリソースを部分的に更新するNoNoYes レスポンスが新しい情報を含む場合DELETEリソースを削除するYesNoNo何度呼んでも同じ結果が返ってくることHTTPはTCP や UDP などの低級プロトコルに依存しているアプリケーションレイヤーのプロトコルである。その他の参考資料、ページ: HTTPHTTPってなに?HTTP と TCPの違いPUT と PATCHの違い伝送制御プロトコル (TCP)      Source: How to make a multiplayer gameTCPはIP networkの上で成り立つ接続プロトコルです。接続はhandshakeによって開始、解除されます。全ての送信されたパケットは欠損なしで送信先に送信された順番で到達するように以下の方法で保証されています:シーケンス番号とchecksum fieldsが全てのパケットに用意されているAcknowledgementパケットと自動再送信もし送信者が正しいレスポンスを受け取らなかったとき、パケットを再送信します。複数のタイムアウトがあったとき、接続は解除されます。TCP はフロー制御 と 輻輳制御も実装しています。これらの機能によって速度は低下し、一般的にUDPよりも非効率な転送手段になっています。ハイスループットを実現するために、ウェブサーバーはかなり大きな数のTCP接続を開いておくことがあり、そのことでメモリー使用が圧迫されます。ウェブサーバスレッドと例えばmemcached サーバーの間で多数のコネクションを保っておくことは高くつくかもしれません。可能なところではUDPに切り替えるだけでなくコネクションプーリングなども役立つかもしれません。TCPは高い依存性を要し、時間制約が厳しくないものに適しているでしょう。ウェブサーバー、データベース情報、SMTP、FTPやSSHなどの例に適用されます。以下の時にUDPよりもTCPを使うといいでしょう:全てのデータが欠損することなしに届いてほしいネットワークスループットの最適な自動推測をしてオペレーションしたいユーザデータグラムプロトコル (UDP)      Source: How to make a multiplayer gameUDPはコネクションレスです。データグラム（パケットのようなもの）はデータグラムレベルでの保証しかされません。データグラムは順不同で受け取り先に到着したりそもそも着かなかったりします。UDPは輻輳制御をサポートしません。TCPにおいてはサポートされているこれらの保証がないため、UDPは一般的に、TCPよりも効率的です。UDPはサブネット上のすべての機器にデータグラムを送信することができます。これはDHCP において役に立ちます。というのも、クライアントはまだIPアドレスを取得していないので、IPアドレスを必要とするTCPによるストリームができないからです。UDPは信頼性の面では劣りますが、VoIP、ビデオチャット、ストリーミングや同時通信マルチプレイヤーゲームなどのリアルタイム性が重視される時にはとても効果的です。TCPよりもUDPを使うのは:レイテンシーを最低限に抑えたい時データ欠損よりも、データ遅延を重視するときエラー修正を自前で実装したいときその他の参考資料、ページ: TCP と UDPゲームプログラミングのためのネットワークTCP と UDP プロトコルの主な違いTCP と UDPの違いTransmission control protocolUser datagram protocolFacebookのメムキャッシュスケーリング遠隔手続呼出 (RPC)      Source: Crack the system design interviewRPCではクライアントがリモートサーバーなどの異なるアドレス空間でプロシージャーが処理されるようにします。プロシージャーはローカルでのコールのように、クライアントからサーバーにどのように通信するかという詳細を省いた状態でコードが書かれます。リモートのコールは普通、ローカルのコールよりも遅く、信頼性に欠けるため、RPCコールをローカルコールと区別させておくことが好ましいでしょう。人気のRPCフレームワークは以下です。Protobuf、 Thrift、AvroRPC は リクエストレスポンスプロトコル:クライアントプログラム - クライアントスタブプロシージャーを呼び出します。パラメータはローカルでのプロシージャーコールのようにスタックへとプッシュされていきます。クライアントスタブプロシージャー - プロシージャIDとアーギュメントをパックしてリクエストメッセージにします。クライアント通信モジュール - OSがクライアントからサーバーへとメッセージを送ります。サーバー通信モジュール - OSが受け取ったパケットをサーバースタブプロシージャーに受け渡します。サーバースタブプロシージャー -  結果を展開し、プロシージャーIDにマッチするサーバープロシージャーを呼び出し、結果を返します。サーバーレスポンスは上記のステップを逆順で繰り返します。Sample RPC calls:GET /someoperation?data=anIdPOST /anotheroperation{  \""data\"":\""anId\"";  \""anotherdata\"": \""another value\""}RPCは振る舞いを公開することに焦点を当てています。RPCは内部通信パフォーマンスを理由として使われることが多いです。というのも、使用する状況に合わせてネイティブコールを自作することができるからです。ネイティブライブラリー (aka SDK) を呼ぶのは以下の時:ターゲットのプラットフォームを知っている時ロジックがどのようにアクセスされるのかを管理したいときライブラリー外でエラーがどのようにコントロールされるかを管理したい時パフォーマンスとエンドユーザーエクスペリエンスが最優先の時REST プロトコルに従うHTTP APIはパブリックAPIにおいてよく用いられます。欠点: RPCRPCクライアントとはサービス実装により厳密に左右されることになります。新しいオペレーション、使用例があるたびに新しくAPIが定義されなければなりません。RPCをデバッグするのは難しい可能性があります。既存のテクノロジーをそのまま使ってサービスを構築することはできないかもしれません。例えば、SquidなどのサーバーにRPCコールが正しくキャッシュ されるように追加で骨を折る必要があるかもしれません。Representational state transfer (REST)RESTは、クライアントがサーバーによってマネージされるリソースに対して処理を行うクライアント・サーバーモデルを支持するアーキテキチャスタイルです。サーバーは操作できるもしくは新しいリソースレプレゼンテーションを受け取ることができるようなリソースやアクションのレプレゼンテーションを提供します。すべての通信はステートレスでキャッシュ可能でなければなりません。RESTful なインターフェースには次の四つの特徴があります:特徴的なリソース (URI in HTTP) - どのオペレーションであっても同じURIを使う。HTTP動詞によって変わる (Verbs in HTTP) - 動詞、ヘッダー、ボディを使う自己説明的なエラーメッセージ (status response in HTTP) - ステータスコードを使い、新しく作ったりしないこと。HATEOAS (HTML interface for HTTP) - 自分のwebサービスがブラウザで完全にアクセスできること。サンプル REST コール:GET /someresources/anIdPUT /someresources/anId{\""anotherdata\"": \""another value\""}RESTはデータを公開することに焦点を当てています。クライアントとサーバーのカップリングを最小限にするもので、パブリックAPIなどによく用いられます。RESTはURI、 representation through headers、そして、GET、POST、PUT、 DELETE、PATCHなどのHTTP動詞等のよりジェネリックで統一されたメソッドを用います。ステートレスであるのでRESTは水平スケーリングやパーティショニングに最適です。欠点: RESTRESTはデータ公開に焦点を当てているので、リソースが自然に整理されていなかったり、シンプルなヒエラルキーで表せられない時にはよい選択肢とは言えないかもしれません。例えば、とあるイベントのセットにマッチするすべての更新情報を返すと言った処理は簡単にはパスで表現することができません。RESTでは、URIパス、クエリパラメータ、そして場合によってはリクエストボディなどによって実装されることが多いでしょう。RESTは少数の動詞に依存しています(GET、POST、PUT、DELETE、そして PATCH) が時には使いたい事例に合わないことがあります。例えば、期限の切れたドキュメントをアーカイブに移したい場合などはこれらの動詞の中には綺麗にはフィットしません。ネストされたヒエラルキーの中にあるリソースをとってくるのはシングルビューを描画するのにクライアントとサーバー間で数回やりとりしなければなりません。例として、ブログエントリーのコンテンツとそれに対するコメントを表示する場合などです。様々なネットワーク環境で動作する可能性が考えられるモバイルアプリケーションにおいてはこのような複数のやり取りは好ましくありません。時が経つにつれて、APIレスポンスにより多くのフィールドが与えられて、古いクライアントはすでにいらないものも含めてすべてのデータフィールドを受け取ることになります。そのことで、ペイロードが大きくなりすぎて、レイテンシーも拡大することになります。RPCとREST比較OperationRPCRESTサインアップPOST /signupPOST /personsリザインPOST /resign{\""personid\"": \""1234\""}DELETE /persons/1234Person読み込みGET /readPerson?personid=1234GET /persons/1234Personのアイテムリスト読み込みGET /readUsersItemsList?personid=1234GET /persons/1234/itemsPersonのアイテムへのアイテム追加POST /addItemToUsersItemsList{\""personid\"": \""1234\"";\""itemid\"": \""456\""}POST /persons/1234/items{\""itemid\"": \""456\""}アイテム更新POST /modifyItem{\""itemid\"": \""456\"";\""key\"": \""value\""}PUT /items/456{\""key\"": \""value\""}アイテム削除POST /removeItem{\""itemid\"": \""456\""}DELETE /items/456  Source: Do you really know why you prefer REST over RPCその他の参考資料、ページ: REST と RPCDo you really know why you prefer REST over RPCWhen are RPC-ish approaches more appropriate than REST?REST vs JSON-RPCDebunking the myths of RPC and RESTWhat are the drawbacks of using RESTCrack the system design interviewThriftWhy REST for internal use and not RPCセキュリティこのセクションは更新が必要です。contributingしてください！セキュリティは幅広いトピックです。十分な経験、セキュリティ分野のバックグラウンドがなくても、セキュリティの知識を要する職に応募するのでない限り、基本以上のことを知る必要はないでしょう。情報伝達、保存における暗号化XSS や SQL injectionを防ぐために、全てのユーザー入力もしくはユーザーに露出される入力パラメーターをサニタイズするSQL injectionを防ぐためにパラメータ化されたクエリを用いる。least privilegeの原理を用いるその他の参考資料、ページ:開発者のためのセキュリティガイドOWASP top ten補遺暗算で、推計値を求める必要があることも時にはあります。例えば、ディスクから100枚イメージ分のサムネイルを作る時間を求めたり、その時にどれだけディスクメモリーが消費されるかなどの値です。2の乗数表 と 全てのプログラマーが知るべきレイテンシー値 は良い参考になるでしょう。2の乗数表乗数           厳密な値         約        Bytes---------------------------------------------------------------7                             1288                             25610                           1024   1 thousand           1 KB16                         65,536                       64 KB20                      1,048,576   1 million            1 MB30                  1,073,741,824   1 billion            1 GB32                  4,294,967,296                        4 GB40              1,099,511,627,776   1 trillion           1 TBその他の参考資料、ページ:2の乗数表全てのプログラマーが知るべきレイテンシー値Latency Comparison Numbers--------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy            10,000   ns       10 usSend 1 KB bytes over 1 Gbps network     10,000   ns       10 usRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSDRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSDSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 msNotes-----1 ns = 10^-9 seconds1 us = 10^-6 seconds = 1,000 ns1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns上記表に基づいた役に立つ数値:ディスクからの連続読み取り速度 30 MB/s1 Gbps Ethernetからの連続読み取り速度　100 MB/sSSDからの連続読み取り速度 1 GB/smain memoryからの連続読み取り速度 4 GB/s1秒で地球6-7周できる1秒でデータセンターと2000周やりとりできるレイテンシーの視覚的表その他の参考資料、ページ:全てのプログラマーが知るべきレイテンシー値 - 1全てのプログラマーが知るべきレイテンシー値 - 2Designs, lessons, and advice from building large distributed systemsSoftware Engineering Advice from Building Large-Scale Distributed Systems他のシステム設計面接例題頻出のシステム設計面接課題とその解答へのリンク質問解答Dropboxのようなファイル同期サービスを設計するyoutube.comGoogleのような検索エンジンの設計queue.acm.orgstackexchange.comardendertat.comstanford.eduGoogleのようなスケーラブルなwebクローラーの設計quora.comGoogle docsの設計code.google.comneil.fraser.nameRedisのようなキーバリューストアの設計slideshare.netMemcachedのようなキャッシュシステムの設計slideshare.netAmazonのようなレコメンデーションシステムの設計hulu.comijcai13.orgBitlyのようなURL短縮サービスの設計n00tc0d3r.blogspot.comWhatsAppのようなチャットアプリの設計highscalability.comInstagramのような写真共有サービスの設計highscalability.comhighscalability.comFacebookニュースフィードの設計quora.comquora.comslideshare.netFacebookタイムラインの設計facebook.comhighscalability.comFacebookチャットの設計erlang-factory.comfacebook.comFacebookのようなgraph検索の設計facebook.comfacebook.comfacebook.comCloudFlareのようなCDNの設計cmu.eduTwitterのトレンド機能の設計michael-noll.comsnikolov .wordpress.comランダムID発行システムの設計blog.twitter.comgithub.com一定のインターバル時間での上位k件を返すucsb.eduwpi.edu複数のデータセンターからデータを配信するサービスの設計highscalability.comオンラインの複数プレイヤーカードゲームの設計indieflashblog.combuildnewgames.comガーベッジコレクションシステムの設計stuffwithstuff.comwashington.eduシステム設計例題を追加するContribute実世界のアーキテクチャ世の中のシステムがどのように設計されているかについての記事      Source: Twitter timelines at scale以下の記事の重箱の隅をつつくような細かい詳細にこだわらないこと。むしろ共通の原理、技術、パターンを探ることそれぞれのコンポーネントでどんな問題が解決され、コンポーネントはどこでうまく使えもしくは使えないかを知ること学んだことを復習すること種類システム参考ページデータ処理MapReduce - Googleの分散データ処理システムresearch.google.comデータ処理Spark - Databricksの分散データ処理システムslideshare.netデータ処理Storm - Twitterの分散データ処理システムslideshare.netデータストアBigtable - Googleのカラム指向分散データベースharvard.eduデータストアHBase - Bigtableのオープンソース実装slideshare.netデータストアCassandra - Facebookのカラム指向分散データベースslideshare.netデータストアDynamoDB - Amazonのドキュメント指向分散データベースharvard.eduデータストアMongoDB - ドキュメント指向分散データベースslideshare.netデータストアSpanner - Googleのグローバル分散データベースresearch.google.comデータストアMemcached - 分散メモリーキャッシングシステムslideshare.netデータストアRedis - 永続性とバリュータイプを兼ね備えた分散メモリーキャッシングシステムslideshare.netファイルシステムGoogle File System (GFS) - 分散ファイルシステムresearch.google.comファイルシステムHadoop File System (HDFS) - GFSのオープンソース実装apache.orgMiscChubby - 疎結合の分散システムをロックするGoogleのサービスresearch.google.comMiscDapper - 分散システムを追跡するインフラresearch.google.comMiscKafka - LinkedInによるPub/subメッセージキューslideshare.netMiscZookeeper - 同期を可能にする中央集権インフラとサービスslideshare.netアーキテクチャを追加するContribute各企業のアーキテクチャ企業参考ページAmazonAmazon architectureCinchcastProducing 1,500 hours of audio every dayDataSiftRealtime datamining At 120,000 tweets per secondDropBoxHow we've scaled DropboxESPNOperating At 100,000 duh nuh nuhs per secondGoogleGoogle architectureInstagram14 million users, terabytes of photosWhat powers InstagramJustin.tvJustin.Tv's live video broadcasting architectureFacebookScaling memcached at FacebookTAO: Facebook’s distributed data store for the social graphFacebook’s photo storageFlickrFlickr architectureMailboxFrom 0 to one million users in 6 weeksPinterestFrom 0 To 10s of billions of page views a month18 million visitors, 10x growth, 12 employeesPlayfish50 million monthly users and growingPlentyOfFishPlentyOfFish architectureSalesforceHow they handle 1.3 billion transactions a dayStack OverflowStack Overflow architectureTripAdvisor40M visitors, 200M dynamic page views, 30TB dataTumblr15 billion page views a monthTwitterMaking Twitter 10000 percent fasterStoring 250 million tweets a day using MySQL150M active users, 300K QPS, a 22 MB/S firehoseTimelines at scaleBig and small data at TwitterOperations at Twitter: scaling beyond 100 million usersUberHow Uber scales their real-time market platformWhatsAppThe WhatsApp architecture Facebook bought for $19 billionYouTubeYouTube scalabilityYouTube architecture企業のエンジニアブログ面接を受ける企業のアーキテクチャ投げられる質問は同じ分野から来ることもあるでしょうAirbnb EngineeringAtlassian DevelopersAutodesk EngineeringAWS BlogBitly Engineering BlogBox BlogsCloudera Developer BlogDropbox Tech BlogEngineering at QuoraEbay Tech BlogEvernote Tech BlogEtsy Code as CraftFacebook EngineeringFlickr CodeFoursquare Engineering BlogGitHub Engineering BlogGoogle Research BlogGroupon Engineering BlogHeroku Engineering BlogHubspot Engineering BlogHigh ScalabilityInstagram EngineeringIntel Software BlogJane Street Tech BlogLinkedIn EngineeringMicrosoft EngineeringMicrosoft Python EngineeringNetflix Tech BlogPaypal Developer BlogPinterest Engineering BlogQuora EngineeringReddit BlogSalesforce Engineering BlogSlack Engineering BlogSpotify LabsTwilio Engineering BlogTwitter EngineeringUber Engineering BlogYahoo Engineering BlogYelp Engineering BlogZynga Engineering Blogその他の参考資料、ページ:kilimchoi/engineering-blogsここにあるリストは比較的小規模なものにとどめ、kilimchoi/engineering-blogsにより詳細に記すことで重複しないようにしておくことにする。エンジニアブログへのリンクを追加する場合はここではなく、engineering-blogsレボジトリに追加することを検討してください。進行中の作業セクションの追加や、進行中の作業を手伝っていただける場合はこちら!MapReduceによる分散コンピューティングConsistent hashingScatter gatherContributeクレジットクレジット及び、参照ページは適時このリポジトリ内に記載してありますSpecial thanks to:Hired in techCracking the coding interviewHigh scalabilitycheckcheckzz/system-design-interviewshashank88/system_designmmcgrana/services-engineeringSystem design cheat sheetA distributed systems reading listCracking the system design interviewContact infoFeel free to contact me to discuss any issues, questions, or comments.My contact info can be found on my GitHub page.LicenseI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2017 Donne MartinCreative Commons Attribution 4.0 International License (CC BY 4.0)http://creativecommons.org/licenses/by/4.0/"
59,AUTOMATIC1111/stable-diffusion-webui,https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/README.md,Python,"Stable Diffusion web UIA browser interface based on Gradio library for Stable Diffusion.FeaturesDetailed feature showcase with images:Original txt2img and img2img modesOne click install and run script (but you still must install python and git)OutpaintingInpaintingColor SketchPrompt MatrixStable Diffusion UpscaleAttention, specify parts of text that the model should pay more attention toa man in a ((tuxedo)) - will pay more attention to tuxedoa man in a (tuxedo:1.21) - alternative syntaxselect text and press Ctrl+Up or Ctrl+Down (or Command+Up or Command+Down if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)Loopback, run img2img processing multiple timesX/Y/Z plot, a way to draw a 3 dimensional plot of images with different parametersTextual Inversionhave as many embeddings as you want and use any names you like for themuse multiple embeddings with different numbers of vectors per tokenworks with half precision floating point numberstrain embeddings on 8GB (also reports of 6GB working)Extras tab with:GFPGAN, neural network that fixes facesCodeFormer, face restoration tool as an alternative to GFPGANRealESRGAN, neural network upscalerESRGAN, neural network upscaler with a lot of third party modelsSwinIR and Swin2SR (see here), neural network upscalersLDSR, Latent diffusion super resolution upscalingResizing aspect ratio optionsSampling method selectionAdjust sampler eta values (noise multiplier)More advanced noise setting optionsInterrupt processing at any time4GB video card support (also reports of 2GB working)Correct seeds for batchesLive prompt token length validationGeneration parametersparameters you used to generate images are saved with that imagein PNG chunks for PNG, in EXIF for JPEGcan drag the image to PNG info tab to restore generation parameters and automatically copy them into UIcan be disabled in settingsdrag and drop an image/text-parameters to promptboxRead Generation Parameters Button, loads parameters in promptbox to UISettings pageRunning arbitrary python code from UI (must run with --allow-code to enable)Mouseover hints for most UI elementsPossible to change defaults/mix/max/step values for UI elements via text configTiling support, a checkbox to create images that can be tiled like texturesProgress bar and live image generation previewCan use a separate neural network to produce previews with almost none VRAM or compute requirementNegative prompt, an extra text field that allows you to list what you don't want to see in generated imageStyles, a way to save part of prompt and easily apply them via dropdown laterVariations, a way to generate same image but with tiny differencesSeed resizing, a way to generate same image but at slightly different resolutionCLIP interrogator, a button that tries to guess prompt from an imagePrompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midwayBatch Processing, process a group of files using img2imgImg2img Alternative, reverse Euler method of cross attention controlHighres Fix, a convenience option to produce high resolution pictures in one click without usual distortionsReloading checkpoints on the flyCheckpoint Merger, a tab that allows you to merge up to 3 checkpoints into oneCustom scripts with many extensions from communityComposable-Diffusion, a way to use multiple prompts at onceseparate prompts using uppercase ANDalso supports weights for prompts: a cat :1.2 AND a dog AND a penguin :2.2No token limit for prompts (original stable diffusion lets you use up to 75 tokens)DeepDanbooru integration, creates danbooru style tags for anime promptsxformers, major speed increase for select cards: (add --xformers to commandline args)via extension: History tab: view, direct and delete images conveniently within the UIGenerate forever optionTraining tabhypernetworks and embeddings optionsPreprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)Clip skipHypernetworksLoras (same as Hypernetworks but more pretty)A sparate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your promptCan select to load a different VAE from settings screenEstimated completion time in progress barAPISupport for dedicated inpainting model by RunwayMLvia extension: Aesthetic Gradients, a way to generate images with a specific aesthetic by using clip images embeds (implementation of https://github.com/vicgalle/stable-diffusion-aesthetic-gradients)Stable Diffusion 2.0 support - see wiki for instructionsAlt-Diffusion support - see wiki for instructionsNow without any bad letters!Load checkpoints in safetensors formatEased resolution restriction: generated image's domension must be a multiple of 8 rather than 64Now with a license!Reorder elements in the UI from settings screenInstallation and RunningMake sure the required dependencies are met and follow the instructions available for both NVidia (recommended) and AMD GPUs.Alternatively, use online services (like Google Colab):List of Online ServicesInstallation on Windows 10/11 with NVidia-GPUs using release packageDownload sd.webui.zip from v1.0.0-pre and extract it's contents.Run update.bat.Run run.bat.For more details see Install-and-Run-on-NVidia-GPUsAutomatic Installation on WindowsInstall Python 3.10.6 (Newer version of Python does not support torch), checking \""Add Python to PATH\"".Install git.Download the stable-diffusion-webui repository, for example by running git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git.Run webui-user.bat from Windows Explorer as normal, non-administrator, user.Automatic Installation on LinuxInstall the dependencies:# Debian-based:sudo apt install wget git python3 python3-venv# Red Hat-based:sudo dnf install wget git python3# Arch-based:sudo pacman -S wget git python3Navigate to the directory you would like the webui to be installed and execute the following command:bash <(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)Run webui.sh.Check webui-user.sh for options.Installation on Apple SiliconFind the instructions here.ContributingHere's how to add code to this repo: ContributingDocumentationThe documentation was moved from this README over to the project's wiki.For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) crawlable wiki.CreditsLicenses for borrowed code can be found in Settings -> Licenses screen, and also in html/licenses.html file.Stable Diffusion - https://github.com/CompVis/stable-diffusion, https://github.com/CompVis/taming-transformersk-diffusion - https://github.com/crowsonkb/k-diffusion.gitGFPGAN - https://github.com/TencentARC/GFPGAN.gitCodeFormer - https://github.com/sczhou/CodeFormerESRGAN - https://github.com/xinntao/ESRGANSwinIR - https://github.com/JingyunLiang/SwinIRSwin2SR - https://github.com/mv-lab/swin2srLDSR - https://github.com/Hafiidz/latent-diffusionMiDaS - https://github.com/isl-org/MiDaSIdeas for optimizations - https://github.com/basujindal/stable-diffusionCross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)Sub-quadratic Cross Attention layer optimization - Alex Birch (Birch-san/diffusers#1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we're not using his code, but we are using his ideas).Idea for SD upscale - https://github.com/jquesnelle/txt2imghdNoise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-botCLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogatorIdea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorchxformers - https://github.com/facebookresearch/xformersDeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooruSampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pixSecurity advice - RyotaKUniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPCTAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesdLyCORIS - KohakuBlueleafInitial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.(You)"
60,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
61,geekcomputers/Python,https://github.com/geekcomputers/Python/blob/master/README.md,Python,"My Python Eggs 🐍 😄I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in Notepad++ 🗒️Feel free to explore the scripts and use them for your learning and automation needs!List of Scripts:batch_file_rename.py - Batch rename a group of files in a specified directory, changing their extensions.create_dir_if_not_there.py - Check if a directory exists in the user's home directory. Create it if it doesn't exist.Fast Youtube Downloader - Download YouTube videos quickly with parallel threads using aria2c.Google Image Downloader - Query a given term and retrieve images from the Google Image database.dir_test.py - Test if the directory testdir exists. If not, create it.env_check.py - Check if all the required environment variables are set.blackjack.py - Casino Blackjack-21 game in Python.fileinfo.py - Show file information for a given file.folder_size.py - Scan the current directory and all subdirectories and display their sizes.logs.py - Search for all *.log files in a directory, zip them using the specified program, and date stamp them.move_files_over_x_days.py - Move all files over a specified age (in days) from the source directory to the destination directory.nslookup_check.py - Open the file server_list.txt and perform nslookup for each server to check the DNS entry.osinfo.py - Display information about the operating system on which the script is running.ping_servers.py - Ping the servers associated with the specified application group.ping_subnet.py - Scan the final range of a given IP subnet for available addresses.powerdown_startup.py - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.puttylogs.py - Zip all the logs in the given directory.script_count.py - Scan the scripts directory and count the different types of scripts.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.script_listing.py - List all files in a given directory and its subdirectories.testlines.py - Open a file and print out 100 lines of the set line variable.tweeter.py - Tweet text or a picture from the terminal.serial_scanner.py - List available serial ports in use on Linux and Windows systems.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.CountMillionCharacter.py and CountMillionCharacter2.0 - Get character count of a text file.xkcd_downloader.py - Download the latest XKCD comic and place them in a new folder called \""comics\"".timymodule.py - An alternative to Python's 'timeit' module and easier to use.calculator.py - Implement a calculator using Python's eval() function.Google_News.py - Use BeautifulSoup to provide latest news headlines along with news links.cricket_live_score - Use BeautifulSoup to provide live cricket scores.youtube.py - Take a song name as input and fetch the YouTube URL of the best matching song and play it.site_health.py - Check the health of a remote server.SimpleStopWatch.py - Simple stop watch implementation using Python's time module.Changemac.py - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).whatsapp-monitor.py - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.whatsapp-chat-analyzer.py - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.JARVIS.py - Control Windows programs with your voice.Images Downloader - Download images from webpages on Unix-based systems.space_invader.py.py - Classical 2D space invader game to recall your childhood memories.Test Case Generator - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.Note: The content in this repository belongs to the respective authors and creators. I'm just providing a formatted README.md for better presentation."
62,ibm-developer-skills-network/jbbmo-Introduction-to-Git-and-GitHub,https://github.com/ibm-developer-skills-network/jbbmo-Introduction-to-Git-and-GitHub/blob/master/README.md,Python,"Introduction to Git and GitHubSimple Interest CalculatorA calculator that calculates simple interest given principal, annual rate of interest and time period in years.Input:   p, principal amount   t, time period in years   r, annual rate of interestOutput   simple interest = p*t*r© 2022 XYZ, Inc."
63,AntonOsika/gpt-engineer,https://github.com/AntonOsika/gpt-engineer/blob/main/README.md,Python,"GPT EngineerSpecify what you want it to build, the AI asks for clarification, and then builds it.GPT Engineer is made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt.DemoProject philosophySimple to get valueFlexible and easy to add new own \""AI steps\"". See steps.py.Incrementally build towards a user experience of:high level promptinggiving feedback to the AI that it will remember over timeFast handovers back and forth between AI and humanSimplicity, all computation is \""resumable\"" and persisted to the filesystemUsageChoose either stable or development.For stable release:python -m pip install gpt-engineerFor development:git clone https://github.com/AntonOsika/gpt-engineer.gitcd gpt-engineerpython -m pip install -e .(or: make install && source venv/bin/activate for a venv)API KeyEither just:export OPENAI_API_KEY=[your api key]Or:Create a copy of .env.template named .envAdd your OPENAI_API_KEY in .envCheck the Windows README for windows usage.RunningCreate an empty folder. If inside the repo, you can run:cp -r projects/example/ projects/my-new-projectFill in the prompt file in your new foldergpt-engineer projects/my-new-project(Note, gpt-engineer --help lets you see all available options. For example --steps use_feedback lets you improve/fix code in a project)By running gpt-engineer you agree to our terms.ResultsCheck the generated files in projects/my-new-project/workspaceAlternativesYou can check Docker instructions to use Docker, or simplydo everything in your browser:FeaturesYou can specify the \""identity\"" of the AI agent by editing the files in the preprompts folder.Editing the preprompts, and evolving how you write the project prompt, is how you make the agent remember things between projects.Each step in steps.py will have its communication history with GPT4 stored in the logs folder, and can be rerun with scripts/rerun_edited_message_logs.py.VisionThe gpt-engineer community is building the open platform for devs to tinker with and build their personal code-generation toolbox.If you are interested in contributing to this, we would be interested in having you.If you want to see our broader ambitions, check out the roadmap, and joindiscordto get input on how you can contribute to it.We are currently looking for more maintainers and community organizers. Email anton.osika@gmail.com if you are interested in an official role.Example              Demo.mov          "
64,fxsjy/jieba,https://github.com/fxsjy/jieba/blob/master/README.md,Python,"jieba“结巴”中文分词：做最好的 Python 中文分词组件\""Jieba\"" (Chinese for \""to stutter\"") Chinese text segmentation: built to be the best Python Chinese word segmentation module.Scroll down for English documentation.特点支持四种分词模式：精确模式，试图将句子最精确地切开，适合文本分析；全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。paddle模式，利用PaddlePaddle深度学习框架，训练序列标注（双向GRU）网络模型实现分词。同时支持词性标注。paddle模式使用需安装paddlepaddle-tiny，pip install paddlepaddle-tiny==1.6.1。目前paddle模式支持jieba v0.40及以上版本。jieba v0.40以下版本，请升级jieba，pip install jieba --upgrade 。PaddlePaddle官网支持繁体分词支持自定义词典MIT 授权协议安装说明代码对 Python 2/3 均兼容全自动安装：easy_install jieba 或者 pip install jieba / pip3 install jieba半自动安装：先下载 http://pypi.python.org/pypi/jieba/ ，解压后运行 python setup.py install手动安装：将 jieba 目录放置于当前目录或者 site-packages 目录通过 import jieba 来引用如果需要使用paddle模式下的分词和词性标注功能，请先安装paddlepaddle-tiny，pip install paddlepaddle-tiny==1.6.1。算法基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法主要功能分词jieba.cut 方法接受四个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型；use_paddle 参数用来控制是否使用paddle模式下的分词模式，paddle模式采用延迟加载方式，通过enable_paddle接口安装paddlepaddle-tiny，并且import相关代码；jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用jieba.lcut 以及 jieba.lcut_for_search 直接返回 listjieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。代码示例# encoding=utf-8import jiebajieba.enable_paddle()# 启动paddle模式。 0.40版之后开始支持，早期版本不支持strs=[\""我来到北京清华大学\"",\""乒乓球拍卖完了\"",\""中国科学技术大学\""]for str in strs:    seg_list = jieba.cut(str,use_paddle=True) # 使用paddle模式    print(\""Paddle Mode: \"" + '/'.join(list(seg_list)))seg_list = jieba.cut(\""我来到北京清华大学\"", cut_all=True)print(\""Full Mode: \"" + \""/ \"".join(seg_list))  # 全模式seg_list = jieba.cut(\""我来到北京清华大学\"", cut_all=False)print(\""Default Mode: \"" + \""/ \"".join(seg_list))  # 精确模式seg_list = jieba.cut(\""他来到了网易杭研大厦\"")  # 默认是精确模式print(\"", \"".join(seg_list))seg_list = jieba.cut_for_search(\""小明硕士毕业于中国科学院计算所，后在日本京都大学深造\"")  # 搜索引擎模式print(\"", \"".join(seg_list))输出:【全模式】: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学【精确模式】: 我/ 来到/ 北京/ 清华大学【新词识别】：他, 来到, 了, 网易, 杭研, 大厦    (此处，“杭研”并没有在词典中，但是也被Viterbi算法识别出来了)【搜索引擎模式】： 小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造添加自定义词典载入词典开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率用法： jieba.load_userdict(file_name) # file_name 为文件类对象或自定义词典的路径词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。词频省略时使用自动计算的能保证分出该词的词频。例如：创新办 3 i云计算 5凱特琳 nz台中更改分词器（默认为 jieba.dt）的 tmp_dir 和 cache_file 属性，可分别指定缓存文件所在的文件夹及其文件名，用于受限的文件系统。范例：自定义词典：https://github.com/fxsjy/jieba/blob/master/test/userdict.txt用法示例：https://github.com/fxsjy/jieba/blob/master/test/test_userdict.py之前： 李小福 / 是 / 创新 / 办 / 主任 / 也 / 是 / 云 / 计算 / 方面 / 的 / 专家 /加载自定义词库后：　李小福 / 是 / 创新办 / 主任 / 也 / 是 / 云计算 / 方面 / 的 / 专家 /调整词典使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。代码示例：>>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))如果/放到/post/中将/出错/。>>> jieba.suggest_freq(('中', '将'), True)494>>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))如果/放到/post/中/将/出错/。>>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))「/台/中/」/正确/应该/不会/被/切开>>> jieba.suggest_freq('台中', True)69>>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))「/台中/」/正确/应该/不会/被/切开\""通过用户自定义词典来增强歧义纠错能力\"" --- #14关键词提取基于 TF-IDF 算法的关键词抽取import jieba.analysejieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())sentence 为待提取的文本topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20withWeight 为是否一并返回关键词权重值，默认值为 FalseallowPOS 仅包括指定词性的词，默认值为空，即不筛选jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件代码示例 （关键词提取）https://github.com/fxsjy/jieba/blob/master/test/extract_tags.py关键词提取所使用逆向文件频率（IDF）文本语料库可以切换成自定义语料库的路径用法： jieba.analyse.set_idf_path(file_name) # file_name为自定义语料库的路径自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py关键词提取所使用停止词（Stop Words）文本语料库可以切换成自定义语料库的路径用法： jieba.analyse.set_stop_words(file_name) # file_name为自定义语料库的路径自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py关键词一并返回关键词权重值示例用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.py基于 TextRank 算法的关键词抽取jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) 直接使用，接口相同，注意默认过滤词性。jieba.analyse.TextRank() 新建自定义 TextRank 实例算法论文： TextRank: Bringing Order into Texts基本思想:将待抽取关键词的文本进行分词以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图计算图中节点的PageRank，注意是无向带权图使用示例:见 test/demo.py词性标注jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer 参数可指定内部使用的 jieba.Tokenizer 分词器。jieba.posseg.dt 为默认词性标注分词器。标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。除了jieba默认分词模式，提供paddle模式下的词性标注功能。paddle模式采用延迟加载方式，通过enable_paddle()安装paddlepaddle-tiny，并且import相关代码；用法示例>>> import jieba>>> import jieba.posseg as pseg>>> words = pseg.cut(\""我爱北京天安门\"") #jieba默认模式>>> jieba.enable_paddle() #启动paddle模式。 0.40版之后开始支持，早期版本不支持>>> words = pseg.cut(\""我爱北京天安门\"",use_paddle=True) #paddle模式>>> for word, flag in words:...    print('%s %s' % (word, flag))...我 r爱 v北京 ns天安门 nspaddle模式词性标注对应表如下：paddle模式词性和专名类别标签集合如下表，其中词性标签 24 个（小写字母），专名类别标签 4 个（大写字母）。标签含义标签含义标签含义标签含义n普通名词f方位名词s处所名词t时间nr人名ns地名nt机构名nw作品名nz其他专名v普通动词vd动副词vn名动词a形容词ad副形词an名形词d副词m数量词q量词r代词p介词c连词u助词xc其他虚词w标点符号PER人名LOC地名ORG机构名TIME时间并行分词原理：将目标文本按行分隔后，把各行文本分配到多个 Python 进程并行分词，然后归并结果，从而获得分词速度的可观提升基于 python 自带的 multiprocessing 模块，目前暂不支持 Windows用法：jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数jieba.disable_parallel() # 关闭并行分词模式例子：https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.py实验结果：在 4 核 3.4GHz Linux 机器上，对金庸全集进行精确分词，获得了 1MB/s 的速度，是单进程版的 3.3 倍。注意：并行分词仅支持默认分词器 jieba.dt 和 jieba.posseg.dt。Tokenize：返回词语在原文的起止位置注意，输入参数只接受 unicode默认模式result = jieba.tokenize(u'永和服装饰品有限公司')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word 永和                start: 0                end:2word 服装                start: 2                end:4word 饰品                start: 4                end:6word 有限公司            start: 6                end:10搜索模式result = jieba.tokenize(u'永和服装饰品有限公司', mode='search')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word 永和                start: 0                end:2word 服装                start: 2                end:4word 饰品                start: 4                end:6word 有限                start: 6                end:8word 公司                start: 8                end:10word 有限公司            start: 6                end:10ChineseAnalyzer for Whoosh 搜索引擎引用： from jieba.analyse import ChineseAnalyzer用法示例：https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py命令行分词使用示例：python -m jieba news.txt > cut_result.txt命令行选项（翻译）：使用: python -m jieba [options] filename结巴命令行界面。固定参数:  filename              输入文件可选参数:  -h, --help            显示此帮助信息并退出  -d [DELIM], --delimiter [DELIM]                        使用 DELIM 分隔词语，而不是用默认的' / '。                        若不指定 DELIM，则使用一个空格分隔。  -p [DELIM], --pos [DELIM]                        启用词性标注；如果指定 DELIM，词语和词性之间                        用它分隔，否则用 _ 分隔  -D DICT, --dict DICT  使用 DICT 代替默认词典  -u USER_DICT, --user-dict USER_DICT                        使用 USER_DICT 作为附加词典，与默认词典或自定义词典配合使用  -a, --cut-all         全模式分词（不支持词性标注）  -n, --no-hmm          不使用隐含马尔可夫模型  -q, --quiet           不输出载入信息到 STDERR  -V, --version         显示版本信息并退出如果没有指定文件名，则使用标准输入。--help 选项输出：$> python -m jieba --helpJieba command line interface.positional arguments:  filename              input fileoptional arguments:  -h, --help            show this help message and exit  -d [DELIM], --delimiter [DELIM]                        use DELIM instead of ' / ' for word delimiter; or a                        space if it is used without DELIM  -p [DELIM], --pos [DELIM]                        enable POS tagging; if DELIM is specified, use DELIM                        instead of '_' for POS delimiter  -D DICT, --dict DICT  use DICT as dictionary  -u USER_DICT, --user-dict USER_DICT                        use USER_DICT together with the default dictionary or                        DICT (if specified)  -a, --cut-all         full pattern cutting (ignored with POS tagging)  -n, --no-hmm          don't use the Hidden Markov Model  -q, --quiet           don't print loading messages to stderr  -V, --version         show program's version number and exitIf no filename specified, use STDIN instead.延迟加载机制jieba 采用延迟加载，import jieba 和 jieba.Tokenizer() 不会立即触发词典的加载，一旦有必要才开始加载词典构建前缀字典。如果你想手工初始 jieba，也可以手动初始化。import jiebajieba.initialize()  # 手动初始化（可选）在 0.28 之前的版本是不能指定主词典的路径的，有了延迟加载机制后，你可以改变主词典的路径:jieba.set_dictionary('data/dict.txt.big')例子： https://github.com/fxsjy/jieba/blob/master/test/test_change_dictpath.py其他词典占用内存较小的词典文件https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.small支持繁体分词更好的词典文件https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big下载你所需要的词典，然后覆盖 jieba/dict.txt 即可；或者用 jieba.set_dictionary('data/dict.txt.big')其他语言实现结巴分词 Java 版本作者：piaolingxue地址：https://github.com/huaban/jieba-analysis结巴分词 C++ 版本作者：yanyiwu地址：https://github.com/yanyiwu/cppjieba结巴分词 Rust 版本作者：messense, MnO2地址：https://github.com/messense/jieba-rs结巴分词 Node.js 版本作者：yanyiwu地址：https://github.com/yanyiwu/nodejieba结巴分词 Erlang 版本作者：falood地址：https://github.com/falood/exjieba结巴分词 R 版本作者：qinwf地址：https://github.com/qinwf/jiebaR结巴分词 iOS 版本作者：yanyiwu地址：https://github.com/yanyiwu/iosjieba结巴分词 PHP 版本作者：fukuball地址：https://github.com/fukuball/jieba-php结巴分词 .NET(C#) 版本作者：anderscui地址：https://github.com/anderscui/jieba.NET/结巴分词 Go 版本作者: wangbin 地址: https://github.com/wangbin/jiebago作者: yanyiwu 地址: https://github.com/yanyiwu/gojieba结巴分词Android版本作者   Dongliang.W  地址：https://github.com/452896915/jieba-android友情链接https://github.com/baidu/lac   百度中文词法分析（分词+词性+专名）系统https://github.com/baidu/AnyQ  百度FAQ自动问答系统https://github.com/baidu/Senta 百度情感识别系统系统集成Solr: https://github.com/sing1ee/jieba-solr分词速度1.5 MB / Second in Full Mode400 KB / Second in Default Mode测试环境: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHz；《围城》.txt常见问题1. 模型的数据是如何生成的？详见： #72. “台中”总是被切成“台 中”？（以及类似情况）P(台中) ＜ P(台)×P(中)，“台中”词频不够导致其成词概率较低解决方法：强制调高词频jieba.add_word('台中') 或者 jieba.suggest_freq('台中', True)3. “今天天气 不错”应该被切成“今天 天气 不错”？（以及类似情况）解决方法：强制调低词频jieba.suggest_freq(('今天', '天气'), True)或者直接删除该词 jieba.del_word('今天天气')4. 切出了词典中没有的词语，效果不理想？解决方法：关闭新词发现jieba.cut('丰田太省了', HMM=False)jieba.cut('我们中出了一个叛徒', HMM=False)更多问题请点击：https://github.com/fxsjy/jieba/issues?sort=updated&state=closed修订历史https://github.com/fxsjy/jieba/blob/master/Changelogjieba\""Jieba\"" (Chinese for \""to stutter\"") Chinese text segmentation: built to be the best Python Chinese word segmentation module.FeaturesSupport three types of segmentation mode:Accurate Mode attempts to cut the sentence into the most accurate segmentations, which is suitable for text analysis.Full Mode gets all the possible words from the sentence. Fast but not accurate.Search Engine Mode, based on the Accurate Mode, attempts to cut long words into several short words, which can raise the recall rate. Suitable for search engines.Supports Traditional ChineseSupports customized dictionariesMIT LicenseOnline demohttp://jiebademo.ap01.aws.af.cm/(Powered by Appfog)UsageFully automatic installation: easy_install jieba or pip install jiebaSemi-automatic installation: Download http://pypi.python.org/pypi/jieba/ , run python setup.py install after extracting.Manual installation: place the jieba directory in the current directory or python site-packages directory.import jieba.AlgorithmBased on a prefix dictionary structure to achieve efficient word graph scanning. Build a directed acyclic graph (DAG) for all possible word combinations.Use dynamic programming to find the most probable combination based on the word frequency.For unknown words, a HMM-based model is used with the Viterbi algorithm.Main FunctionsCutThe jieba.cut function accepts three input parameters: the first parameter is the string to be cut; the second parameter is cut_all, controlling the cut mode; the third parameter is to control whether to use the Hidden Markov Model.jieba.cut_for_search accepts two parameter: the string to be cut; whether to use the Hidden Markov Model. This will cut the sentence into short words suitable for search engines.The input string can be an unicode/str object, or a str/bytes object which is encoded in UTF-8 or GBK. Note that using GBK encoding is not recommended because it may be unexpectly decoded as UTF-8.jieba.cut and jieba.cut_for_search returns an generator, from which you can use a for loop to get the segmentation result (in unicode).jieba.lcut and jieba.lcut_for_search returns a list.jieba.Tokenizer(dictionary=DEFAULT_DICT) creates a new customized Tokenizer, which enables you to use different dictionaries at the same time. jieba.dt is the default Tokenizer, to which almost all global functions are mapped.Code example: segmentation#encoding=utf-8import jiebaseg_list = jieba.cut(\""我来到北京清华大学\"", cut_all=True)print(\""Full Mode: \"" + \""/ \"".join(seg_list))  # 全模式seg_list = jieba.cut(\""我来到北京清华大学\"", cut_all=False)print(\""Default Mode: \"" + \""/ \"".join(seg_list))  # 默认模式seg_list = jieba.cut(\""他来到了网易杭研大厦\"")print(\"", \"".join(seg_list))seg_list = jieba.cut_for_search(\""小明硕士毕业于中国科学院计算所，后在日本京都大学深造\"")  # 搜索引擎模式print(\"", \"".join(seg_list))Output:[Full Mode]: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学[Accurate Mode]: 我/ 来到/ 北京/ 清华大学[Unknown Words Recognize] 他, 来到, 了, 网易, 杭研, 大厦    (In this case, \""杭研\"" is not in the dictionary, but is identified by the Viterbi algorithm)[Search Engine Mode]： 小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造Add a custom dictionaryLoad dictionaryDevelopers can specify their own custom dictionary to be included in the jieba default dictionary. Jieba is able to identify new words, but you can add your own new words can ensure a higher accuracy.Usage： jieba.load_userdict(file_name) # file_name is a file-like object or the path of the custom dictionaryThe dictionary format is the same as that of dict.txt: one word per line; each line is divided into three parts separated by a space: word, word frequency, POS tag. If file_name is a path or a file opened in binary mode, the dictionary must be UTF-8 encoded.The word frequency and POS tag can be omitted respectively. The word frequency will be filled with a suitable value if omitted.For example:创新办 3 i云计算 5凱特琳 nz台中Change a Tokenizer's tmp_dir and cache_file to specify the path of the cache file, for using on a restricted file system.Example:  云计算 5  李小福 2  创新办 3  [Before]： 李小福 / 是 / 创新 / 办 / 主任 / 也 / 是 / 云 / 计算 / 方面 / 的 / 专家 /  [After]：　李小福 / 是 / 创新办 / 主任 / 也 / 是 / 云计算 / 方面 / 的 / 专家 /Modify dictionaryUse add_word(word, freq=None, tag=None) and del_word(word) to modify the dictionary dynamically in programs.Use suggest_freq(segment, tune=True) to adjust the frequency of a single word so that it can (or cannot) be segmented.Note that HMM may affect the final result.Example:>>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))如果/放到/post/中将/出错/。>>> jieba.suggest_freq(('中', '将'), True)494>>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))如果/放到/post/中/将/出错/。>>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))「/台/中/」/正确/应该/不会/被/切开>>> jieba.suggest_freq('台中', True)69>>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))「/台中/」/正确/应该/不会/被/切开Keyword Extractionimport jieba.analysejieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())sentence: the text to be extractedtopK: return how many keywords with the highest TF/IDF weights. The default value is 20withWeight: whether return TF/IDF weights with the keywords. The default value is FalseallowPOS: filter words with which POSs are included. Empty for no filtering.jieba.analyse.TFIDF(idf_path=None) creates a new TFIDF instance, idf_path specifies IDF file path.Example (keyword extraction)https://github.com/fxsjy/jieba/blob/master/test/extract_tags.pyDevelopers can specify their own custom IDF corpus in jieba keyword extractionUsage： jieba.analyse.set_idf_path(file_name) # file_name is the path for the custom corpusCustom Corpus Sample：https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.bigSample Code：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.pyDevelopers can specify their own custom stop words corpus in jieba keyword extractionUsage： jieba.analyse.set_stop_words(file_name) # file_name is the path for the custom corpusCustom Corpus Sample：https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txtSample Code：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.pyThere's also a TextRank implementation available.Use: jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))Note that it filters POS by default.jieba.analyse.TextRank() creates a new TextRank instance.Part of Speech Taggingjieba.posseg.POSTokenizer(tokenizer=None) creates a new customized Tokenizer. tokenizer specifies the jieba.Tokenizer to internally use. jieba.posseg.dt is the default POSTokenizer.Tags the POS of each word after segmentation, using labels compatible with ictclas.Example:>>> import jieba.posseg as pseg>>> words = pseg.cut(\""我爱北京天安门\"")>>> for w in words:...    print('%s %s' % (w.word, w.flag))...我 r爱 v北京 ns天安门 nsParallel ProcessingPrinciple: Split target text by line, assign the lines into multiple Python processes, and then merge the results, which is considerably faster.Based on the multiprocessing module of Python.Usage:jieba.enable_parallel(4) # Enable parallel processing. The parameter is the number of processes.jieba.disable_parallel() # Disable parallel processing.Example:https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.pyResult: On a four-core 3.4GHz Linux machine, do accurate word segmentation on Complete Works of Jin Yong, and the speed reaches 1MB/s, which is 3.3 times faster than the single-process version.Note that parallel processing supports only default tokenizers, jieba.dt and jieba.posseg.dt.Tokenize: return words with positionThe input must be unicodeDefault moderesult = jieba.tokenize(u'永和服装饰品有限公司')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word 永和                start: 0                end:2word 服装                start: 2                end:4word 饰品                start: 4                end:6word 有限公司            start: 6                end:10Search moderesult = jieba.tokenize(u'永和服装饰品有限公司',mode='search')for tk in result:    print(\""word %s\\t\\t start: %d \\t\\t end:%d\"" % (tk[0],tk[1],tk[2]))word 永和                start: 0                end:2word 服装                start: 2                end:4word 饰品                start: 4                end:6word 有限                start: 6                end:8word 公司                start: 8                end:10word 有限公司            start: 6                end:10ChineseAnalyzer for Whooshfrom jieba.analyse import ChineseAnalyzerExample: https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.pyCommand Line Interface$> python -m jieba --helpJieba command line interface.positional arguments:  filename              input fileoptional arguments:  -h, --help            show this help message and exit  -d [DELIM], --delimiter [DELIM]                        use DELIM instead of ' / ' for word delimiter; or a                        space if it is used without DELIM  -p [DELIM], --pos [DELIM]                        enable POS tagging; if DELIM is specified, use DELIM                        instead of '_' for POS delimiter  -D DICT, --dict DICT  use DICT as dictionary  -u USER_DICT, --user-dict USER_DICT                        use USER_DICT together with the default dictionary or                        DICT (if specified)  -a, --cut-all         full pattern cutting (ignored with POS tagging)  -n, --no-hmm          don't use the Hidden Markov Model  -q, --quiet           don't print loading messages to stderr  -V, --version         show program's version number and exitIf no filename specified, use STDIN instead.InitializationBy default, Jieba don't build the prefix dictionary unless it's necessary. This takes 1-3 seconds, after which it is not initialized again. If you want to initialize Jieba manually, you can call:import jiebajieba.initialize()  # (optional)You can also specify the dictionary (not supported before version 0.28) :jieba.set_dictionary('data/dict.txt.big')Using Other DictionariesIt is possible to use your own dictionary with Jieba, and there are also two dictionaries ready for download:A smaller dictionary for a smaller memory footprint:https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.smallThere is also a bigger dictionary that has better support for traditional Chinese (繁體):https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.bigBy default, an in-between dictionary is used, called dict.txt and included in the distribution.In either case, download the file you want, and then call jieba.set_dictionary('data/dict.txt.big') or just replace the existing dict.txt.Segmentation speed1.5 MB / Second in Full Mode400 KB / Second in Default ModeTest Env: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHz；《围城》.txt"
65,PaddlePaddle/PaddleOCR,https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/README.md,Python,"English | 简体中文 | हिन्दी | 日本語 | 한국인 | Pу́сский язы́к                             简介PaddleOCR旨在打造一套丰富、领先、且实用的OCR工具库，助力开发者训练出更好的模型，并应用落地。        📣 近期更新🔥2023.8.7 发布 PaddleOCR release/2.7发布PP-OCRv4，提供mobile和server两种模型PP-OCRv4-mobile：速度可比情况下，中文场景效果相比于PP-OCRv3再提升4.5%，英文场景提升10%，80语种多语言模型平均识别准确率提升8%以上PP-OCRv4-server：发布了目前精度最高的OCR模型，中英文场景上检测模型精度提升4.9%， 识别模型精度提升2%可参考快速开始 一行命令快速使用，同时也可在飞桨AI套件(PaddleX)中的通用OCR产业方案中低代码完成模型训练、推理、高性能部署全流程发布PP-ChatOCR ,使用融合PP-OCR模型和文心大模型的通用场景关键信息抽取全新方案🔨2022.11 新增实现4种前沿算法：文本检测 DRRG,  文本识别 RFL, 文本超分Text Telescope，公式识别CAN2022.10 优化JS版PP-OCRv3模型：模型大小仅4.3M，预测速度提升8倍，配套web demo开箱即用💥 直播回放：PaddleOCR研发团队详解PP-StructureV2优化策略。微信扫描下方二维码，关注公众号并填写问卷后进入官方交流群，获取直播回放链接与20G重磅OCR学习大礼包（内含PDF转Word应用程序、10种垂类模型、《动手学OCR》电子书等）🔥2022.8.24 发布 PaddleOCR release/2.6发布PP-StructureV2，系统功能性能全面升级，适配中文场景，新增支持版面复原，支持一行命令完成PDF转Word；版面分析模型优化：模型存储减少95%，速度提升11倍，平均CPU耗时仅需41ms；表格识别模型优化：设计3大优化策略，预测耗时不变情况下，模型精度提升6%；关键信息抽取模型优化：设计视觉无关模型结构，语义实体识别精度提升2.8%，关系抽取精度提升9.1%。🔥2022.8 发布 OCR场景应用集合：包含数码管、液晶屏、车牌、高精度SVTR模型、手写体识别等9个垂类模型，覆盖通用，制造、金融、交通行业的主要OCR垂类应用。更多🌟 特性支持多种OCR相关前沿算法，在此基础上打造产业级特色模型PP-OCR、PP-Structure和PP-ChatOCR，并打通数据生产、模型训练、压缩、预测部署全流程。    上述内容的使用方法建议从文档教程中的快速开始体验⚡ 快速开始在线网站体验：PP-OCRv4 在线体验地址：https://aistudio.baidu.com/aistudio/projectdetail/6611435PP-ChatOCR 在线体验地址：https://aistudio.baidu.com/aistudio/projectdetail/6488689一行命令快速使用：快速开始（中英文/多语言/文档分析）飞桨AI套件（PaddleX）中训练、推理、高性能部署全流程体验：PP-OCRv4：https://aistudio.baidu.com/aistudio/modelsdetail?modelId=286PP-ChatOCR：https://aistudio.baidu.com/aistudio/modelsdetail?modelId=332移动端demo体验：安装包DEMO下载地址(基于EasyEdge和Paddle-Lite, 支持iOS和Android系统)📖 技术交流合作飞桨AI套件(PaddleX)提供了飞桨模型训压推一站式全流程高效率开发平台，其使命是助力AI技术快速落地，愿景是使人人成为AI Developer！PaddleX 目前覆盖图像分类、目标检测、图像分割、3D、OCR和时序预测等领域方向，已内置了36种基础单模型，例如RT-DETR、PP-YOLOE、PP-HGNet、PP-LCNet、PP-LiteSeg等；集成了12种实用的产业方案，例如PP-OCRv4、PP-ChatOCR、PP-ShiTu、PP-TS、车载路面垃圾检测、野生动物违禁制品识别等。PaddleX 提供了“工具箱”和“开发者”两种AI开发模式。工具箱模式可以无代码调优关键超参，开发者模式可以低代码进行单模型训压推和多模型串联推理，同时支持云端和本地端。PaddleX 还支持联创开发，利润分成！目前 PaddleX 正在快速迭代，欢迎广大的个人开发者和企业开发者参与进来，共创繁荣的 AI 技术生态！微信扫描下面二维码添加运营同学，并回复【paddlex】，运营同学会邀请您加入官方交流群，获得更高效的问题答疑。飞桨AI套件【PaddleX】技术交流群二维码📚《动手学OCR》电子书《动手学OCR》电子书🚀 开源共建👫 加入社区：感谢大家长久以来对 PaddleOCR 的支持和关注，与广大开发者共同构建一个专业、和谐、相互帮助的开源社区是 PaddleOCR 的目标。我们非常欢迎各位开发者参与到飞桨社区的开源建设中，加入开源、共建飞桨。为感谢社区开发者在 PaddleOCR release2.7 中做出的代码贡献，我们将为贡献者制作与邮寄开源贡献证书，烦请填写问卷提供必要的邮寄信息。🤩 社区活动：飞桨开源社区长期运营与发布各类丰富的活动与开发任务，在 PaddleOCR 社区，你可以关注以下社区活动，并选择自己感兴趣的内容参与开源共建：🎁 飞桨套件快乐开源常规赛 | 传送门：OCR 社区常规赛升级版，以建设更好用的 OCR 套件为目标，包括但不限于学术前沿模型训练与推理、打磨优化 OCR 工具与应用项目开发等，任何有利于社区意见流动和问题解决的行为都热切希望大家的参与。让我们共同成长为飞桨套件的重要 Contributor 🎉🎉🎉。💡 新需求征集 | 传送门：你在日常研究和实践深度学习过程中，有哪些你期望的 feature 亟待实现？请按照格式描述你想实现的 feature 和你提出的初步实现思路，我们会定期沟通与讨论这些需求，并将其纳入未来的版本规划中。💬 PP-SIG 技术研讨会 | 传送门：PP-SIG 是飞桨社区开发者由于相同的兴趣汇聚在一起形成的虚拟组织，通过定期召开技术研讨会的方式，分享行业前沿动态、探讨社区需求与技术开发细节、发起社区联合贡献任务。PaddleOCR 希望可以通过 AI 的力量助力任何一位有梦想的开发者实现自己的想法，享受创造价值带来的愉悦。📑 项目合作：如果你有企业中明确的 OCR 垂类应用需求，我们推荐你使用训压推一站式全流程高效率开发平台 PaddleX，助力 AI 技术快速落地。PaddleX 还支持联创开发，利润分成！欢迎广大的个人开发者和企业开发者参与进来，共创繁荣的 AI 技术生态！🛠️ PP-OCR系列模型列表（更新中）模型简介模型名称推荐场景检测模型方向分类器识别模型中英文超轻量PP-OCRv4模型（15.8M）ch_PP-OCRv4_xx移动端&服务器端推理模型 / 训练模型推理模型 / 训练模型推理模型 / 训练模型中英文超轻量PP-OCRv3模型（16.2M）ch_PP-OCRv3_xx移动端&服务器端推理模型 / 训练模型推理模型 / 训练模型推理模型 / 训练模型英文超轻量PP-OCRv3模型（13.4M）en_PP-OCRv3_xx移动端&服务器端推理模型 / 训练模型推理模型 / 训练模型推理模型 / 训练模型超轻量OCR系列更多模型下载（包括多语言），可以参考PP-OCR系列模型下载，文档分析相关模型参考PP-Structure系列模型下载PaddleOCR场景应用模型行业类别亮点文档说明模型下载制造数码管识别数码管数据合成、漏识别调优光功率计数码管字符识别下载链接金融通用表单识别多模态通用表单结构化提取多模态表单识别下载链接交通车牌识别多角度图像处理、轻量模型、端侧部署轻量级车牌识别下载链接更多制造、金融、交通行业的主要OCR垂类应用模型（如电表、液晶屏、高精度SVTR模型等），可参考场景应用模型下载📖 文档教程运行环境准备PP-OCR文本检测识别🔥快速开始模型库模型训练文本检测文本识别文本方向分类器模型压缩模型量化模型裁剪知识蒸馏推理部署基于Python预测引擎推理基于C++预测引擎推理服务化部署端侧部署Paddle2ONNX模型转化与预测云上飞桨部署工具BenchmarkPP-Structure文档分析🔥快速开始模型库模型训练版面分析表格识别关键信息提取推理部署基于Python预测引擎推理基于C++预测引擎推理服务化部署前沿算法与模型🚀文本检测算法文本识别算法端到端OCR算法表格识别算法关键信息抽取算法使用PaddleOCR架构添加新算法场景应用数据标注与合成半自动标注工具PPOCRLabel数据合成工具Style-Text其它数据标注工具其它数据合成工具数据集通用中英文OCR数据集手写中文OCR数据集垂类多语言OCR数据集版面分析数据集表格识别数据集关键信息提取数据集代码组织结构效果展示《动手学OCR》电子书📚开源社区FAQ通用问题PaddleOCR实战问题参考文献许可证书👀 效果展示 morePP-OCRv3 中文模型            PP-OCRv3 英文模型        PP-OCRv3 多语言模型        PP-Structure 文档分析版面分析+表格识别    SER（语义实体识别）            RE（关系提取）            许可证书本项目的发布受Apache 2.0 license许可认证。"
66,lazyprogrammer/machine_learning_examples,https://github.com/lazyprogrammer/machine_learning_examples/blob/master/README.md,Python,"machine_learning_examplesA collection of machine learning examples and tutorials.Find associated tutorials at https://lazyprogrammer.meFind associated courses at https://deeplearningcourses.comPlease note that not all code from all courses will be found in this repository. Some newer code examples (e.g. most of Tensorflow 2.0) were done in Google Colab. Therefore, you should check the instructions given in the lectures for the course you are taking.How to I find the code for a particular course?The code for each course is separated by folder. You can determine which folder corresponds with which course by watching the \""Where to get the code\"" lecture inside the course (usually Lecture 2 or 3).Remember: one folder = one course.Why you should not fork this repoI've noticed that many people have out-of-date forks. Thus, I recommend not forking this repository if you take one of my courses. I am constantly updating my courses, and your fork will soon become out-of-date. You should clone the repository instead to make it easy to get updates (i.e. just \""git pull\"" randomly and frequently).Where is the code for your latest courses?Beginning with Tensorflow 2, I started to use Google Colab. For those courses, unless otherwise noted, the code will be on Google Colab. Links to the notebooks are provided in the course. See the lecture \""Where to get the code\"" for further details.VIP Course LinksData Science: Transformers for Natural Language Processinghttps://deeplearningcourses.com/c/data-science-transformers-nlpMachine Learning: Natural Language Processing in Python (V2)https://deeplearningcourses.com/c/natural-language-processing-in-pythonTime Series Analysis, Forecasting, and Machine Learninghttps://deeplearningcourses.com/c/time-series-analysisFinancial Engineering and Artificial Intelligence in Pythonhttps://deeplearningcourses.com/c/ai-financePyTorch: Deep Learning and Artificial Intelligencehttps://deeplearningcourses.com/c/pytorch-deep-learningTensorflow 2.0: Deep Learning and Artificial Intelligence (VIP Version)https://deeplearningcourses.com/c/deep-learning-tensorflow-2Deep Learning Courses ExclusivesData Science: Bayesian Linear Regression in Pythonhttps://deeplearningcourses.com/c/bayesian-linear-regression-in-pythonData Science: Bayesian Classification in Pythonhttps://deeplearningcourses.com/c/bayesian-classification-in-pythonClassical Statistical Inference and A/B Testing in Pythonhttps://deeplearningcourses.com/c/statistical-inference-in-pythonLinear Programming for Linear Regression in Pythonhttps://deeplearningcourses.com/c/linear-programming-pythonMATLAB for Students, Engineers, and Professionals in STEMhttps://deeplearningcourses.com/c/matlabOther Course LinksFinancial Analysis: Build a ChatGPT Pairs Trading Bothttps://deeplearningcourses.com/c/chatgpt-pairs-tradingMath 0-1: Calculus for Data Science & Machine Learninghttps://deeplearningcourses.com/c/calculus-data-scienceData Science & Machine Learning: Naive Bayes in Pythonhttps://deeplearningcourses.com/c/data-science-machine-learning-naive-bayes-in-pythonCutting-Edge AI: Deep Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/cutting-edge-artificial-intelligenceRecommender Systems and Deep Learning in Pythonhttps://deeplearningcourses.com/c/recommender-systemsMachine Learning and AI: Support Vector Machines in Pythonhttps://deeplearningcourses.com/c/support-vector-machines-in-pythonDeep Learning: Advanced Computer Visionhttps://deeplearningcourses.com/c/advanced-computer-visionDeep Learning: Advanced NLP and RNNshttps://deeplearningcourses.com/c/deep-learning-advanced-nlpDeep Learning: GANs and Variational Autoencodershttps://deeplearningcourses.com/c/deep-learning-gans-and-variational-autoencodersAdvanced AI: Deep Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/deep-reinforcement-learning-in-pythonArtificial Intelligence: Reinforcement Learning in Pythonhttps://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-pythonNatural Language Processing with Deep Learning in Pythonhttps://deeplearningcourses.com/c/natural-language-processing-with-deep-learning-in-pythonDeep Learning: Recurrent Neural Networks in Pythonhttps://deeplearningcourses.com/c/deep-learning-recurrent-neural-networks-in-pythonUnsupervised Machine Learning: Hidden Markov Models in Pythonhttps://deeplearningcourses.com/c/unsupervised-machine-learning-hidden-markov-models-in-pythonDeep Learning Prerequisites: The Numpy Stack in Pythonhttps://deeplearningcourses.com/c/deep-learning-prerequisites-the-numpy-stack-in-pythonDeep Learning Prerequisites: Linear Regression in Pythonhttps://deeplearningcourses.com/c/data-science-linear-regression-in-pythonDeep Learning Prerequisites: Logistic Regression in Pythonhttps://deeplearningcourses.com/c/data-science-logistic-regression-in-pythonData Science: Deep Learning and Neural Networks in Pythonhttps://deeplearningcourses.com/c/data-science-deep-learning-in-pythonCluster Analysis and Unsupervised Machine Learning in Pythonhttps://deeplearningcourses.com/c/cluster-analysis-unsupervised-machine-learning-pythonData Science: Supervised Machine Learning in Pythonhttps://deeplearningcourses.com/c/data-science-supervised-machine-learning-in-pythonBayesian Machine Learning in Python: A/B Testinghttps://deeplearningcourses.com/c/bayesian-machine-learning-in-python-ab-testingData Science: Natural Language Processing in Pythonhttps://deeplearningcourses.com/c/data-science-natural-language-processing-in-pythonModern Deep Learning in Pythonhttps://deeplearningcourses.com/c/data-science-deep-learning-in-theano-tensorflowEnsemble Machine Learning in Python: Random Forest and AdaBoosthttps://deeplearningcourses.com/c/machine-learning-in-python-random-forest-adaboostDeep Learning: Convolutional Neural Networks in Pythonhttps://deeplearningcourses.com/c/deep-learning-convolutional-neural-networks-theano-tensorflowUnsupervised Deep Learning in Pythonhttps://deeplearningcourses.com/c/unsupervised-deep-learning-in-python"
67,TgCatUB/catuserbot,https://github.com/TgCatUB/catuserbot/blob/master/README.md,Python,"CatUserbotA simple Telegram userbot based on Telethon .How to deploy catuserbotHeroku DeploySelf hostCheck DocsSupportInspirationX-tra-TelegramUniborg & Uniborg forkNana-RemixUserge-XDisclaimer              YOU ARE FOREWARNEDYour Telegram account may get banned.   Catuserbot or we are not responsible for your account, This bot is intended for the purpose of having fun with some fun commands and group management with some helpfull commands.If  you ended up spamming groups, getting reported left and right, and you ended up in being fight with Telegram and at the end Telegram Team deleted your account. DON'T BLAME US.No personal support will be provided / We won't spoon feed you. If you need help ask in our support group and we or our friends will try to help you.Thanks for using our bot 😺CreditsSpecial thanks to LonamiWebs for Telethon library.To all devs of these UserbotsFinally to all contributors of Catuserbot"
68,donnemartin/system-design-primer,https://github.com/donnemartin/system-design-primer/blob/master/README-ja.md,Python,"English ∙ 日本語 ∙ 简体中文 ∙ 繁體中文 | العَرَبِيَّة‎ ∙ বাংলা ∙ Português do Brasil ∙ Deutsch ∙ ελληνικά ∙ עברית ∙ Italiano ∙ 한국어 ∙ فارسی ∙ Polski ∙ русский язык ∙ Español ∙ ภาษาไทย ∙ Türkçe ∙ tiếng Việt ∙ Français | Add Translationシステム設計入門    動機・目的大規模システムのシステム設計を学ぶシステム設計面接課題に備える大規模システムの設計を学ぶスケーラブルなシステムのシステム設計を学ぶことは、より良いエンジニアになることに資するでしょう。システム設計はとても広範なトピックを含みます。システム設計原理については インターネット上には膨大な量の文献が散らばっています。このリポジトリは大規模システム構築に必要な知識を学ぶことができる 文献リストを体系的にまとめたもの です。オープンソースコミュニティから学ぶこのプロジェクトは、これからもずっと更新されていくオープンソースプロジェクトの初期段階にすぎません。Contributions は大歓迎です！システム設計面接課題に備えるコード技術面接に加えて、システム設計に関する知識は、多くのテック企業における 技術採用面接プロセス で 必要不可欠な要素 です。システム設計面接での頻出質問に備え、自分の解答と模範解答:ディスカッション、コードそして図表などを比較して学びましょう。面接準備に役立つその他のトピック:学習指針システム設計面接課題にどのように準備するかシステム設計課題例 とその解答オブジェクト指向設計課題例、 とその解答その他のシステム設計面接課題例暗記カード    このAnki用フラッシュカードデッキ は、間隔反復を活用して、システム設計のキーコンセプトの学習を支援します。システム設計デッキシステム設計練習課題デッキオブジェクト指向練習課題デッキ外出先や移動中の勉強に役立つでしょう。コーディング技術課題用の問題: 練習用インタラクティブアプリケーションコード技術面接用の問題を探している場合はこちら    姉妹リポジトリの Interactive Coding Challengesも見てみてください。追加の暗記デッキカードも入っています。Coding deckコントリビュートコミュニティから学ぶプルリクエスト等の貢献は積極的にお願いします:エラー修正セクション内容改善新規セクション追加翻訳する現在、内容の改善が必要な作業中のコンテンツはこちらです。コントリビュートの前にContributing Guidelinesを読みましょう。システム設計目次賛否も含めた様々なシステム設計の各トピックの概要。 全てはトレードオフの関係にあります。それぞれのセクションはより学びを深めるような他の文献へのリンクが貼られています。    システム設計トピック: まずはここからStep 1: スケーラビリティに関する動画を見るStep 2: スケーラビリティに関する記事を読む次のステップパフォーマンス vs スケーラビリティレイテンシー vs スループット可用性 vs 一貫性CAP理論CP - 一貫性(consistency)と分割性(partition)耐性AP - 可用性(availability)と分割性(partition)耐性一貫性 パターン弱い一貫性結果整合性強い一貫性可用性 パターンフェイルオーバーレプリケーションドメインネームシステム(DNS)コンテンツデリバリーネットワーク(CDN)プッシュCDNプルCDNロードバランサーアクティブ/パッシブ構成アクティブ/アクティブ構成Layer 4 ロードバランシングLayer 7 ロードバランシング水平スケーリングリバースプロキシ (WEBサーバー)ロードバランサー vs リバースプロキシアプリケーションレイヤーマイクロサービスサービスディスカバリーデータベースリレーショナルデータベースマネジメントシステム (RDBMS)マスター/スレーブ レプリケーションマスター/マスター レプリケーションフェデレーションシャーディングデノーマライゼーションSQL チューニングNoSQLキー/バリューストアドキュメントストアワイドカラムストアグラフ データベースSQL or NoSQLキャッシュクライアントキャッシングCDNキャッシングWebサーバーキャッシングデータベースキャッシングアプリケーションキャッシングデータベースクエリレベルでキャッシングするオブジェクトレベルでキャッシングするいつキャッシュを更新するのかキャッシュアサイドライトスルーライトビハインド (ライトバック)リフレッシュアヘッド非同期処理メッセージキュータスクキューバックプレッシャー通信伝送制御プロトコル (TCP)ユーザデータグラムプロトコル (UDP)遠隔手続呼出 (RPC)Representational state transfer (REST)セキュリティ補遺2の乗数表全てのプログラマーが知るべきレイテンシー値他のシステム設計面接例題実世界でのアーキテクチャ各企業のアーキテクチャ企業のエンジニアブログ作業中クレジット連絡情報ライセンス学習指針学習スパンに応じてみるべきトピックス (short, medium, long)Q: 面接のためには、ここにあるものすべてをやらないといけないのでしょうか？A: いえ、ここにあるすべてをやる必要はありません。面接で何を聞かれるかは以下の条件によって変わってきます:どれだけの技術経験があるかあなたの技術背景が何であるかどのポジションのために面接を受けているかどの企業の面接を受けているか運より経験のある候補者は一般的にシステム設計についてより深い知識を有していることを要求されるでしょう。システムアーキテクトやチームリーダーは各メンバーの持つような知識よりは深い見識を持っているべきでしょう。一流テック企業では複数回の設計面接を課されることが多いです。まずは広く始めて、そこからいくつかの分野に絞って深めていくのがいいでしょう。様々なシステム設計のトピックについて少しずつ知っておくことはいいことです。以下の学習ガイドを自分の学習に当てられる時間、技術経験、どの職位、どの会社に応募しているかなどを加味して自分用に調整して使うといいでしょう。短期間 - 幅広く システム設計トピックを学ぶ。いくつかの 面接課題を解くことで対策する。中期間 - 幅広く そして それなりに深くシステム設計トピックを学ぶ。多くの 面接課題を解くことで対策する。長期間 - 幅広く そして もっと深くシステム設計トピックを学ぶ。ほぼ全ての 面接課題を解くことで対策する。短期間中期間長期間システム設計トピック を読み、システム動作機序について広く知る👍👍👍次のリンク先のいくつかのページを読んで 各企業のエンジニアリングブログ 応募する会社について知る👍👍👍次のリンク先のいくつかのページを読む 実世界でのアーキテクチャ👍👍👍復習する システム設計面接課題にどのように準備するか👍👍👍とりあえず一周する システム設計課題例SomeManyMostとりあえず一周する オブジェクト指向設計問題と解答SomeManyMost復習する その他システム設計面接での質問例SomeManyMostシステム設計面接にどのようにして臨めばいいかシステム設計面接試験問題にどのように取り組むかシステム設計面接は open-ended conversation(Yes/Noでは答えられない口頭質問)です。 自分で会話を組み立てることを求められます。以下のステップに従って議論を組み立てることができるでしょう。この過程を確かなものにするために、次のセクションシステム設計課題例とその解答 を以下の指針に従って読み込むといいでしょう。ステップ 1: そのシステム使用例の概要、制約、推計値等を聞き出し、まとめるシステム仕様の要求事項を聞き出し、問題箇所を特定しましょう。使用例と制約を明確にするための質問を投げかけましょう。要求する推計値についても議論しておきましょう。誰がそのサービスを使うのか？どのように使うのか？何人のユーザーがいるのか？システムはどのような機能を果たすのか？システムへの入力と出力は？どれだけの容量のデータを捌く必要があるのか？一秒間に何リクエストの送信が想定されるか？読み書き比率の推定値はいくら程度か？ステップ 2: より高レベルのシステム設計を組み立てる重要なコンポーネントを全て考慮した高レベルのシステム設計概要を組み立てる。主要なコンポーネントと接続をスケッチして書き出す考えの裏付けをするステップ 3: 核となるコンポーネントを設計するそれぞれの主要なコンポーネントについての詳細を学ぶ。例えば、url短縮サービスの設計を問われた際には次のようにするといいでしょう:元のURLのハッシュ化したものを作り、それを保存するMD5 と Base62ハッシュ衝突SQL もしくは NoSQLデータベーススキーマハッシュ化されたURLを元のURLに再翻訳するデータベース参照API & オブジェクト指向の設計ステップ 4: システム設計のスケール与えられた制約条件からボトルネックとなりそうなところを割り出し、明確化する。  例えば、スケーラビリティの問題解決のために以下の要素を考慮する必要があるだろうか？ロードバランサー水平スケーリングキャッシングデータベースシャーディング取りうる解決策とそのトレードオフについて議論をしよう。全てのことはトレードオフの関係にある。ボトルネックについてはスケーラブルなシステム設計の原理を読むといいでしょう。ちょっとした暗算問題ちょっとした推計値を手計算ですることを求められることもあるかもしれません。補遺の以下の項目が役に立つでしょう:チラ裏計算でシステム設計する2の乗数表全てのプログラマーが知っておくべきレイテンシの参考値文献とその他の参考資料以下のリンク先ページを見てどのような質問を投げかけられるか概要を頭に入れておきましょう:システム設計面接で成功するには？システム設計面接アーキテクチャ、システム設計面接への導入システム設計課題例とその解答頻出のシステム設計面接課題と参考解答、コード及びダイアグラム解答は solutions/ フォルダ以下にリンクが貼られている問題Pastebin.com (もしくは Bit.ly) を設計する解答Twitterタイムライン (もしくはFacebookフィード)を設計するTwitter検索(もしくはFacebook検索)機能を設計する解答ウェブクローラーを設計する解答Mint.comを設計する解答SNSサービスのデータ構造を設計する解答検索エンジンのキー/バリュー構造を設計する解答Amazonのカテゴリ毎の売り上げランキングを設計する解答AWS上で100万人規模のユーザーを捌くサービスを設計する解答システム設計問題を追加するContributePastebin.com (もしくは Bit.ly) を設計する問題と解答を見るTwitterタイムライン&検索 (もしくはFacebookフィード&検索)を設計する問題と解答を見るウェブクローラーの設計問題と解答を見るMint.comの設計問題と解答を見るSNSサービスのデータ構造を設計する問題と解答を見る検索エンジンのキー/バリュー構造を設計する問題と解答を見るAmazonのカテゴリ毎の売り上げランキングを設計する問題と解答を見るAWS上で100万人規模のユーザーを捌くサービスを設計する問題と解答を見るオブジェクト指向設計問題と解答頻出のオブジェクト指向システム設計面接課題と参考解答、コード及びダイアグラム解答は solutions/ フォルダ以下にリンクが貼られている備考: このセクションは作業中です問題ハッシュマップの設計解答LRUキャッシュの設計解答コールセンターの設計解答カードのデッキの設計解答駐車場の設計解答チャットサーバーの設計解答円形配列の設計Contributeオブジェクト指向システム設計問題を追加するContributeシステム設計トピックス: まずはここからシステム設計の勉強は初めて？まず初めに、よく使われる設計原理について、それらが何であるか、どのように用いられるか、長所短所について基本的な知識を得る必要がありますステップ 1: スケーラビリティに関する動画を観て復習するHarvardでのスケーラビリティの講義ここで触れられているトピックス:垂直スケーリング水平スケーリングキャッシングロードバランシングデータベースレプリケーションデータベースパーティションステップ 2: スケーラビリティに関する資料を読んで復習するスケーラビリティここで触れられているトピックス:クローンデータベースキャッシュ非同期次のステップ次に、ハイレベルでのトレードオフについてみていく:パフォーマンス vs スケーラビリティレイテンシ vs スループット可用性 vs 一貫性全てはトレードオフの関係にあるというのを肝に命じておきましょう。それから、より深い内容、DNSやCDNそしてロードバランサーなどについて学習を進めていきましょう。パフォーマンス vs スケーラビリティリソースが追加されるのにつれて パフォーマンス が向上する場合そのサービスは スケーラブル であると言えるでしょう。一般的に、パフォーマンスを向上させるというのはすなわち計算処理を増やすことを意味しますが、データセットが増えた時などより大きな処理を捌けるようになることでもあります。1パフォーマンスvsスケーラビリティをとらえる他の考え方:パフォーマンス での問題を抱えている時、あなたのシステムは一人のユーザーにとって遅いと言えるでしょう。スケーラビリティ での問題を抱えているとき、一人のユーザーにとっては速いですが、多くのリクエストがある時には遅くなってしまうでしょう。その他の参考資料、ページスケーラビリティについてスケーラビリティ、可用性、安定性、パターンレイテンシー vs スループットレイテンシー とはなにがしかの動作を行う、もしくは結果を算出するのに要する時間スループット とはそのような動作や結果算出が単位時間に行われる回数一般的に、 最大限のスループット を 許容範囲内のレイテンシー で実現することを目指すのが普通だ。その他の参考資料、ページレイテンシー vs スループットを理解する可用性 vs 一貫性CAP 理論      Source: CAP theorem revisited分散型コンピュータシステムにおいては下の三つのうち二つまでしか同時に保証することはできない。:一貫性 - 全ての読み込みは最新の書き込みもしくはエラーを受け取る可用性 - 受け取る情報が最新のものだという保証はないが、全てのリクエストはレスポンスを必ず受け取る分断耐性 - ネットワーク問題によって順不同の分断が起きてもシステムが動作を続けるネットワークは信頼できないので、分断耐性は必ず保証しなければなりません。つまりソフトウェアシステムとしてのトレードオフは、一貫性を取るか、可用性を取るかを考えなければなりません。CP - 一貫性と分断耐性(consistency and partition tolerance)分断されたノードからのレスポンスを待ち続けているとタイムアウトエラーに陥る可能性があります。CPはあなたのサービスがアトミックな読み書き（不可分操作）を必要とする際にはいい選択肢でしょう。AP - 可用性と分断耐性(availability and partition tolerance)レスポンスはノード上にあるデータで最新のものを返します。つまり、最新版のデータが返されるとは限りません。分断が解消された後も、書き込みが反映されるのには時間がかかります。結果整合性　を求めるサービスの際にはAPを採用するのがいいでしょう。もしくは、外部エラーに関わらずシステムが稼働する必要がある際にも同様です。その他の参考資料、ページCAP 理論を振り返る平易な英語でのCAP 理論のイントロCAP FAQ一貫性パターン同じデータの複製が複数ある状態では、クライアントが一貫したデータ表示を受け取るために、どのようにそれらを同期すればいいのかという課題があります。 CAP 理論 における一貫性の定義を思い出してみましょう。全ての読み取りは最新の書き込みデータもしくはエラーを受け取るはずです。弱い一貫性書き込み後の読み取りでは、その最新の書き込みを読めたり読めなかったりする。ベストエフォート型のアプローチに基づく。このアプローチはmemcachedなどのシステムに見られます。弱い一貫性はリアルタイム性が必要なユースケース、例えばVoIP、ビデオチャット、リアルタイムマルチプレイヤーゲームなどと相性がいいでしょう。例えば、電話に出ているときに数秒間音声が受け取れなくなったとしたら、その後に接続が回復してもその接続が切断されていた間に話されていたことは聞き取れないというような感じです。結果整合性書き込みの後、読み取りは最終的にはその結果を読み取ることができる(ミリ秒ほど遅れてというのが一般的です)。データは非同期的に複製されます。このアプローチはDNSやメールシステムなどに採用されています。結果整合性は多くのリクエストを捌くサービスと相性がいいでしょう。強い一貫性書き込みの後、読み取りはそれを必ず読むことができます。データは同期的に複製されます。このアプローチはファイルシステムやRDBMSなどで採用されています。トランザクションを扱うサービスでは強い一貫性が必要でしょう。その他の参考資料、ページデータセンター間でのトランザクション可用性パターン高い可用性を担保するには主に次の二つのパターンがあります: フェイルオーバー と レプリケーション です。フェイルオーバーアクティブ・パッシブアクティブ・パッシブフェイルオーバーにおいては、周期信号はアクティブもしくはスタンバイ中のパッシブなサーバーに送られます。周期信号が中断された時には、パッシブだったサーバーがアクティブサーバーのIPアドレスを引き継いでサービスを再開します。起動までのダウンタイムはパッシブサーバーが「ホット」なスタンバイ状態にあるか、「コールド」なスタンバイ状態にあるかで変わります。アクティブなサーバーのみがトラフィックを捌きます。アクティブ・パッシブフェイルオーバーはマスター・スレーブフェイルオーバーと呼ばれることもあります。アクティブ・アクティブアクティブアクティブ構成では両方のサーバーがトラフィックを捌くことで負荷を分散します。これらのサーバーがパブリックなものの場合、DNSは両方のサーバーのパブリックIPを知っている必要があります。もし、プライベートなものな場合、アプリケーションロジックが両方のサーバーの情報について知っている必要があります。アクティブ・アクティブなフェイルオーバーはマスター・マスターフェイルオーバーと呼ばれることもあります。短所: フェイルオーバーフェイルオーバーではより多くのハードウェアを要し、複雑さが増します。最新の書き込みがパッシブサーバーに複製される前にアクティブが落ちると、データ欠損が起きる潜在可能性があります。レプリケーションマスター・スレーブ　と　マスター・マスターこのトピックは データベース セクションにおいてより詳細に解説されています:マスター・スレーブ レプリケーションマスター・マスター レプリケーションドメインネームシステム      Source: DNS security presentationドメインネームシステム (DNS) は www.example.com などのドメインネームをIPアドレスへと翻訳します。DNSは少数のオーソライズされたサーバーが上位に位置する階層的構造です。あなたのルーターもしくはISPは検索をする際にどのDNSサーバーに接続するかという情報を提供します。低い階層のDNSサーバーはその経路マップをキャッシュします。ただ、この情報は伝搬遅延によって陳腐化する可能性があります。DNSの結果はあなたのブラウザもしくはOSに一定期間（time to live (TTL)に設定された期間）キャッシュされます。NS record (name server) - あなたのドメイン・サブドメインでのDNSサーバーを特定します。MX record (mail exchange) - メッセージを受け取るメールサーバーを特定します。A record (address) - IPアドレスに名前をつけます。CNAME (canonical) - 他の名前もしくは　CNAME (example.com を www.example.com) もしくは A recordへと名前を指し示す。CloudFlare や Route 53 などのサービスはマネージドDNSサービスを提供しています。いくつかのDNSサービスでは様々な手法を使ってトラフィックを捌くことができます:加重ラウンドロビントラフィックがメンテナンス中のサーバーに行くのを防ぎます様々なクラスターサイズに応じて調整しますA/B テストレイテンシーベース地理ベース欠点: DNS上記で示されているようなキャッシングによって緩和されているとはいえ、DNSサーバーへの接続には少し遅延が生じる。DNSサーバーは、政府、ISP企業,そして大企業に管理されているが、それらの管理は複雑である。DNSサービスはDDoS attackの例で、IPアドレスなしにユーザーがTwitterなどにアクセスできなくなったように、攻撃を受ける可能性がある。その他の参考資料、ページDNS アーキテクチャWikipediaDNS 記事コンテンツデリバリーネットワーク(Content delivery network)      Source: Why use a CDNコンテンツデリバリーネットワーク(CDN)は世界中に配置されたプロキシサーバーのネットワークがユーザーに一番地理的に近いサーバーからコンテンツを配信するシステムのことです。AmazonのCloudFrontなどは例外的にダイナミックなコンテンツも配信しますが、一般的に、HTML/CSS/JS、写真、そして動画などの静的ファイルがCDNを通じて配信されます。そのサイトのDNSがクライアントにどのサーバーと交信するかという情報を伝えます。CDNを用いてコンテンツを配信することで以下の二つの理由でパフォーマンスが劇的に向上します:ユーザーは近くにあるデータセンターから受信できるバックエンドサーバーはCDNが処理してくれるリクエストに関しては処理する必要がなくなりますプッシュCDNプッシュCDNではサーバーデータに更新があった時には必ず、新しいコンテンツを受け取る方式です。コンテンツを用意し、CDNに直接アップロードし、URLをCDNを指すように指定するところまで、全て自分で責任を負う形です。コンテンツがいつ期限切れになるのか更新されるのかを設定することができます。コンテンツは新規作成時、更新時のみアップロードされることでトラフィックは最小化される一方、ストレージは最大限消費されてしまいます。トラフィックの少ない、もしくは頻繁にはコンテンツが更新されないサイトの場合にはプッシュCDNと相性がいいでしょう。コンテンツは定期的に再びプルされるのではなく、CDNに一度のみ配置されます。プルCDNプルCDNでは一人目のユーザーがリクエストした時に、新しいコンテンツをサービスのサーバーから取得します。コンテンツは自分のサーバーに保存して、CDNを指すURLを書き換えます。結果として、CDNにコンテンツがキャッシュされるまではリクエスト処理が遅くなります。time-to-live (TTL) はコンテンツがどれだけの期間キャッシュされるかを規定します。プルCDNはCDN 上でのストレージスペースを最小化しますが、有効期限が切れたファイルが更新前にプルされてしまうことで冗長なトラフィックに繋がってしまう可能性があります。大規模なトラフィックのあるサイトではプルCDNが相性がいいでしょう。というのも、トラフィックの大部分は最近リクエストされ、CDNに残っているコンテンツにアクセスするものであることが多いからです。欠点: CDNCDNのコストはトラフィック量によって変わります。もちろん、CDNを使わない場合のコストと比較するべきでしょう。TTLが切れる前にコンテンツが更新されると陳腐化する恐れがあります。CDNでは静的コンテンツがCDNを指すようにURLを更新する必要があります。その他の参考資料、ページグローバルに分散されたコンテンツデリバリーネットワークプッシュCDNとプルCDNの違いWikipediaロードバランサー      Source: Scalable system design patternsロードバランサーは入力されるクライアントのリクエストをアプリケーションサーバーやデータベースへと分散させる。どのケースでもロードバランサーはサーバー等計算リソースからのレスポンスを適切なクライアントに返す。ロードバランサーは以下のことに効果的です:リクエストが状態の良くないサーバーに行くのを防ぐリクエストを過剰に送るのを防ぐ特定箇所の欠陥でサービスが落ちることを防ぐロードバランサーは (費用の高い) ハードウェアもしくはHAProxyなどのソフトウェアで実現できる。他の利点としては:SSL termination - 入力されるリクエストを解読する、また、サーバーレスポンスを暗号化することでバックエンドのサーバーがこのコストが高くつきがちな処理を請け負わなくていいように肩代わりします。X.509 certificates をそれぞれのサーバーにインストールする必要をなくしますセッション管理 - クッキーを取り扱うウェブアプリがセッション情報を保持していない時などに、特定のクライアントのリクエストを同じインスタンスへと流します。障害に対応するために、アクティブ・パッシブ もしくは アクティブ・アクティブ モードのどちらにおいても、複数のロードバランサーを配置するのが一般的です。ロードバランサーは以下のような種々のメトリックを用いてトラフィックルーティングを行うことができます:ランダムLeast loadedセッション/クッキーラウンドロビンもしくは加重ラウンドロビンLayer 4Layer 7Layer 4 ロードバランシングLayer 4 ロードバランサーは トランスポートレイヤー を参照してどのようにリクエストを配分するか判断します。一般的に、トランスポートレイヤーとしては、ソース、送信先IPアドレス、ヘッダーに記述されたポート番号が含まれますが、パケットの中身のコンテンツは含みません。 Layer 4 ロードバランサーはネットワークパケットを上流サーバーへ届け、上流サーバーから配信することでネットワークアドレス変換 Network Address Translation (NAT) を実現します。Layer 7 ロードバランシングLayer 7 ロードバランサーは アプリケーションレイヤー を参照してどのようにリクエストを配分するか判断します。ヘッダー、メッセージ、クッキーなどのコンテンツのことです。Layer 7 ロードバランサーはネットワークトラフィックの終端を受け持ち メッセージを読み込み、ロードバランシングの判断をし、選択したサーバーとの接続を繋ぎます。例えば layer 7 ロードバランサーは動画のトラフィックを直接、そのデータをホストしているサーバーにつなぐと同時に、決済処理などのより繊細なトラフィックをセキュリティ強化されたサーバーに流すということもできる。柔軟性とのトレードオフになりますが、 layer 4 ロードバランサーではLayer 7ロードバランサーよりも所要時間、計算リソースを少なく済ませることができます。ただし、昨今の汎用ハードウェアではパフォーマンスは最小限のみしか発揮できないでしょう。水平スケーリングロードバランサーでは水平スケーリングによってパフォーマンスと可用性を向上させることができます。手頃な汎用マシンを追加することによってスケールアウトさせる方が、一つのサーバーをより高価なマシンにスケールアップする（垂直スケーリング）より費用対効果も高くなり、結果的に可用性も高くなります。また、汎用ハードウェアを扱える人材を雇う方が、特化型の商用ハードウェアを扱える人材を雇うよりも簡単でしょう。欠点: 水平スケーリング水平的にスケーリングしていくと、複雑さが増す上に、サーバーのクローニングが必要になる。サーバーはステートレスである必要がある: ユーザーに関連するセッションや、プロフィール写真などのデータを持ってはいけないセッションは一元的なデータベース (SQL、 NoSQL)などのデータストアにストアされるか キャッシュ (Redis、 Memcached)に残す必要があります。キャッシュやデータベースなどの下流サーバーは上流サーバーがスケールアウトするにつれてより多くの同時接続を保たなければなりません。欠点: ロードバランサーロードバランサーはリソースが不足していたり、設定が適切でない場合、システム全体のボトルネックになる可能性があります。単一障害点を除こうとしてロードバランサーを導入した結果、複雑さが増してしまうことになります。ロードバランサーが一つだけだとそこが単一障害点になってしまいます。一方で、ロードバランサーを複数にすると、さらに複雑さが増してしまいます。その他の参考資料、ページNGINX アーキテクチャHAProxy アーキテクチャガイドスケーラビリティWikipediaLayer 4 ロードバランシングLayer 7 ロードバランシングELB listener configリバースプロキシ(webサーバー)      Source: Wikipedia  リバースプロキシサーバーは内部サービスをまとめて外部に統一されたインターフェースを提供するウェブサーバーです。クライアントからのリクエストはそれに対応するサーバーに送られて、その後レスポンスをリバースプロキシがクライアントに返します。他には以下のような利点があります:より堅牢なセキュリティ - バックエンドサーバーの情報を隠したり、IPアドレスをブラックリスト化したり、クライアントごとの接続数を制限したりできます。スケーラビリティや柔軟性が増します - クライアントはリバースプロキシのIPしか見ないので、裏でサーバーをスケールしたり、設定を変えやすくなります。SSL termination - 入力されるリクエストを解読し、サーバーのレスポンスを暗号化することでサーバーがこのコストのかかりうる処理をしなくて済むようになります。X.509 証明書 を各サーバーにインストールする必要がなくなります。圧縮 - サーバーレスポンスを圧縮できますキャッシング - キャッシュされたリクエストに対して、レスポンスを返します静的コンテンツ - 静的コンテンツを直接送信することができます。HTML/CSS/JS写真動画などなどロードバランサー vs リバースプロキシ複数のサーバーがある時にはロードバランサーをデプロイすると役に立つでしょう。 しばしば、ロードバランサーは同じ機能を果たすサーバー群へのトラフィックを捌きます。リバースプロキシでは、上記に述べたような利点を、単一のウェブサーバーやアプリケーションレイヤーに対しても示すことができます。NGINX や HAProxy などの技術はlayer 7 リバースプロキシとロードバランサーの両方をサポートします。欠点: リバースプロキシリバースプロキシを導入するとシステムの複雑性が増します。単一のリバースプロキシは単一障害点になりえます。一方で、複数のリバースプロキシを導入すると(例: フェイルオーバー) 複雑性はより増します。その他の参考資料、ページリバースプロキシ vs ロードバランサーNGINX アーキテクチャHAProxy アーキテクチャ ガイドWikipediaアプリケーション層      Source: Intro to architecting systems for scaleウェブレイヤーをアプリケーション層 (プラットフォーム層とも言われる) と分離することでそれぞれの層を独立にスケール、設定することができるようになります。新しいAPIをアプリケーション層に追加する際に、不必要にウェブサーバーを追加する必要がなくなります。単一責任の原則 では、小さい自律的なサービスが協調して動くように提唱しています。小さいサービスの小さいチームが急成長のためにより積極的な計画を立てられるようにするためです。アプリケーション層は非同期処理もサポートします。マイクロサービス独立してデプロイできる、小規模なモジュール様式であるマイクロサービスもこの議論に関係してくる技術でしょう。それぞれのサービスは独自のプロセスを処理し、明確で軽量なメカニズムで通信して、その目的とする機能を実現します。1例えばPinterestでは以下のようなマイクロサービスに分かれています。ユーザープロフィール、フォロワー、フィード、検索、写真アップロードなどです。サービスディスカバリーConsul、 Etcd、 Zookeeper などのシステムでは、登録されているサービスの名前、アドレス、ポートの情報を監視することで、サービス同士が互いを見つけやすくしています。サービスの完全性の確認には Health checks が便利で、これには HTTP エンドポイントがよく使われます。 Consul と Etcd のいずれも組み込みの key-value store を持っており、設定データや共有データなどのデータを保存しておくことに使われます。欠点: アプリケーション層アーキテクチャ、運用、そしてプロセスを考慮すると、緩く結び付けられたアプリケーション層を追加するには、モノリシックなシステムとは異なるアプローチが必要です。マイクロサービスはデプロイと運用の点から見ると複雑性が増すことになります。その他の参考資料、ページスケールするシステムアーキテクチャを設計するためのイントロシステム設計インタビューを紐解くサービス指向アーキテクチャZookeeperのイントロダクションマイクロサービスを作るために知っておきたいことデータベース      Source: Scaling up to your first 10 million usersリレーショナルデータベースマネジメントシステム (RDBMS)SQLなどのリレーショナルデータベースはテーブルに整理されたデータの集合である。ACID はリレーショナルデータベースにおけるトランザクションのプロパティの集合である不可分性 - それぞれのトランザクションはあるかないかのいずれかである一貫性 - どんなトランザクションもデータベースをある確かな状態から次の状態に遷移させる。独立性 - 同時にトランザクションを処理することは、連続的にトランザクションを処理するのと同じ結果をもたらす。永続性 - トランザクションが処理されたら、そのように保存されるリレーショナルデータベースをスケールさせるためにはたくさんの技術がある: マスター・スレーブ レプリケーション、 マスター・マスター レプリケーション、 federation、 シャーディング、 非正規化、 そして SQL チューニングマスタースレーブ レプリケーションマスターデータベースが読み取りと書き込みを処理し、書き込みを一つ以上のスレーブデータベースに複製します。スレーブデータベースは読み取りのみを処理します。スレーブデータベースは木構造のように追加のスレーブにデータを複製することもできます。マスターデータベースがオフラインになった場合には、いずれかのスレーブがマスターに昇格するか、新しいマスターデータベースが追加されるまでは読み取り専用モードで稼働します。      Source: Scalability, availability, stability, patterns欠点: マスタースレーブ レプリケーションスレーブをマスターに昇格させるには追加のロジックが必要になる。マスタースレーブ レプリケーション、マスターマスター レプリケーションの 両方 の欠点は欠点: レプリケーションを参照マスターマスター レプリケーションいずれのマスターも読み取り書き込みの両方に対応する。書き込みに関してはそれぞれ協調する。いずれかのマスターが落ちても、システム全体としては読み書き両方に対応したまま運用できる。      Source: Scalability, availability, stability, patterns欠点: マスターマスター レプリケーションロードバランサーを導入するか、アプリケーションロジックを変更することでどこに書き込むかを指定しなければならない。大体のマスターマスターシステムは、一貫性が緩い（ACID原理を守っていない）もしくは、同期する時間がかかるために書き込みのレイテンシーが増加してしまっている。書き込みノードが追加され、レイテンシーが増加するにつれ書き込みの衝突の可能性が増える。マスタースレーブ レプリケーション、マスターマスター レプリケーションの 両方 の欠点は欠点: レプリケーション を参照欠点: レプリケーション新しいデータ書き込みを複製する前にマスターが落ちた場合にはそのデータが失われてしまう可能性がある。書き込みは読み取りレプリカにおいてリプレイされる。書き込みが多い場合、複製ノードが書き込みの処理のみで行き詰まって、読み取りの処理を満足に行えない可能性がある。読み取りスレーブノードの数が多ければ多いほど、複製しなければならない数も増え、複製時間が伸びてしまいます。システムによっては、マスターへの書き込みはマルチスレッドで並列処理できる一方、スレーブへの複製は単一スレッドで連続的に処理しなければならない場合があります。レプリケーションでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: レプリケーションスケーラビリティ、 可用性、 スタビリティ パターンマルチマスター レプリケーションFederation      Source: Scaling up to your first 10 million usersフェデレーション (もしくは機能分割化とも言う) はデータベースを機能ごとに分割する。例えば、モノリシックな単一データベースの代わりに、データベースを フォーラム、 ユーザー、 プロダクト のように三つにすることで、データベース一つあたりの書き込み・読み取りのトラフィックが減り、その結果レプリケーションのラグも短くなります。データベースが小さくなることで、メモリーに収まるデータが増えます。キャッシュの局所性が高まるため、キャッシュヒット率も上がります。単一の中央マスターで書き込みを直列化したりしないため、並列で書き込みを処理することができ、スループットの向上が期待できます。欠点: federation大規模な処理やテーブルを要するスキーマの場合、フェデレーションは効果的とは言えないでしょう。どのデータベースに読み書きをするのかを指定するアプリケーションロジックを更新しなければなりません。server linkで二つのデータベースからのデータを連結するのはより複雑になるでしょう。フェデレーションでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: federationScaling up to your first 10 million usersシャーディング      Source: Scalability, availability, stability, patternsシャーディングでは異なるデータベースにそれぞれがデータのサブセット断片のみを持つようにデータを分割します。ユーザーデータベースを例にとると、ユーザー数が増えるにつれてクラスターにはより多くの断片が加えられることになります。federationの利点に似ていて、シャーディングでは読み書きのトラフィックを減らし、レプリケーションを減らし、キャッシュヒットを増やすことができます。インデックスサイズも減らすことができます。一般的にはインデックスサイズを減らすと、パフォーマンスが向上しクエリ速度が速くなります。なにがしかのデータを複製する機能がなければデータロスにつながりますが、もし、一つのシャードが落ちても、他のシャードが動いていることになります。フェデレーションと同じく、単一の中央マスターが書き込みの処理をしなくても、並列で書き込みを処理することができ、スループットの向上が期待できます。ユーザーテーブルをシャードする一般的な方法は、ユーザーのラストネームイニシャルでシャードするか、ユーザーの地理的配置でシャードするなどです。欠点: シャーディングシャードに対応するようにアプリケーションロジックを変更しなければなりません。結果としてSQLクエリが複雑になります。シャードではデータ配分がいびつになってしまう可能性があります。例えば、標準ユーザーの集合を持つシャードがある場合、そのシャードが他のシャードよりも重い負荷を負うことになります。リバランシングをすると複雑性がより増します。consistent hashing に基づいたシャーディングでは、通信データを削減することもできます。複数のシャードからのデータを連結するのはより複雑です。シャーディングでは追加のハードウェアが必要になり、複雑性も増します。その他の参考資料、ページ: シャーディングシャードの登場シャードデータベースアーキテクチャConsistent hashing非正規化非正規化では、書き込みのパフォーマンスをいくらか犠牲にして読み込みのパフォーマンスを向上させようとします。計算的に重いテーブルの結合などをせずに、複数のテーブルに冗長なデータのコピーが書き込まれるのを許容します。いくつかのRDBMS例えば、PostgreSQL やOracleはこの冗長な情報を取り扱い、一貫性を保つためのmaterialized views という機能をサポートしています。フェデレーション や シャーディングなどのテクニックによってそれぞれのデータセンターに分配されたデータを合一させることはとても複雑な作業です。非正規化によってそのような複雑な処理をしなくて済むようになります。多くのシステムで、100対1あるいは1000対1くらいになるくらい読み取りの方が、書き込みのトラフィックよりも多いことでしょう。読み込みを行うために、複雑なデータベースのジョイン処理が含まれるものは計算的に高価につきますし、ディスクの処理時間で膨大な時間を費消してしまうことになります。欠点: 非正規化データが複製される。冗長なデータの複製が同期されるように制約が存在し、そのことでデータベース全体の設計が複雑化する。非正規化されたデータベースは過大な書き込みを処理しなければならない場合、正規化されているそれよりもパフォーマンスにおいて劣る可能性がある。その他の参考資料、ページ: 非正規化DenormalizationSQLチューニングSQLチューニングは広範な知識を必要とする分野で多くの 本 が書かれています。ボトルネックを明らかにし、シミュレートする上で、 ベンチマーク を定め、 プロファイル することはとても重要です。ベンチマーク - abなどのツールを用いて、高負荷の状況をシミュレーションしてみましょう。プロファイル - slow query log などのツールを用いて、パフォーマンス状況の確認をしましょう。ベンチマークとプロファイルをとることで以下のような効率化の選択肢をとることになるでしょう。スキーマを絞るMySQLはアクセス速度向上のため、ディスク上の連続したブロックへデータを格納しています。長さの決まったフィールドに対しては VARCHAR よりも CHAR を使うようにしましょう。CHAR の方が効率的に速くランダムにデータにアクセスできます。 一方、 VARCHAR では次のデータに移る前にデータの末尾を検知しなければならないために速度が犠牲になります。ブログの投稿など、大きなテキストには TEXT を使いましょう。 TEXT ではブーリアン型の検索も可能です。 TEXT フィールドには、テキストブロックが配置されている、ディスク上の場所へのポインターが保存されます。2の32乗や40億以下を超えない程度の大きな数には INT を使いましょう。通貨に関しては小数点表示上のエラーを避けるために DECIMAL を使いましょう。大きな BLOBS を保存するのは避けましょう。どこからそのオブジェクトを取ってくることができるかの情報を保存しましょう。VARCHAR(255) は8ビットで数えられる最大の文字数です。一部のDBMSでは、1バイトの利用効率を最大化するためにこの文字数がよく使われます。検索性能向上のため 、可能であれば NOT NULL 制約を設定しましょう。インデックスを効果的に用いるクエリ(SELECT、 GROUP BY、 ORDER BY、 JOIN) の対象となる列にインデックスを使うことで速度を向上できるかもしれません。インデックスは通常、平衡探索木であるB木の形で表されます。B木によりデータは常にソートされた状態になります。また検索、順次アクセス、挿入、削除を対数時間で行えます。インデックスを配置することはデータをメモリーに残すことにつながりより容量を必要とします。インデックスの更新も必要になるため書き込みも遅くなります。大量のデータをロードする際には、インデックスを切ってからデータをロードして再びインデックスをビルドした方が速いことがあります。高負荷なジョインを避けるパフォーマンス上必要なところには非正規化を適用するテーブルのパーティションテーブルを分割し、ホットスポットを独立したテーブルに分離してメモリーに乗せられるようにする。クエリキャッシュを調整する場合によってはクエリキャッシュ がパフォーマンス問題 を引き起こす可能性があるその他の参考資料、ページ: SQLチューニングMySQLクエリを最適化するためのTipsVARCHAR(255)をやたらよく見かけるのはなんで？null値はどのようにパフォーマンスに影響するのか？Slow query logNoSQLNoSQL は key-value store、 document-store、 wide column store、 もしくは graph databaseによって表現されるデータアイテムの集合です。データは一般的に正規化されておらず、アプリケーション側でジョインが行われます。大部分のNoSQLは真のACIDトランザクションを持たず、 結果整合性 的な振る舞いの方を好みます。BASE はしばしばNoSQLデータベースのプロパティを説明するために用いられます。CAP Theorem と対照的に、BASEは一貫性よりも可用性を優先します。Basically available - システムは可用性を保証します。Soft state - システムの状態は入力がなくても時間経過とともに変化する可能性があります。結果整合性 - システム全体は時間経過とともにその間に入力がないという前提のもと、一貫性が達成されます。SQLか？NoSQLか？ を選択するのに加えて、どのタイプのNoSQLがどの使用例に最も適するかを理解するのはとても有益です。このセクションでは キーバリューストア、 ドキュメントストア、 ワイドカラムストア、 と グラフデータベース について触れていきます。キーバリューストア概要: ハッシュテーブルキーバリューストアでは一般的にO(1)の読み書きができ、それらはメモリないしSSDで裏付けられています。データストアはキーを 辞書的順序 で保持することでキーの効率的な取得を可能にしています。キーバリューストアではメタデータを値とともに保持することが可能です。キーバリューストアはハイパフォーマンスな挙動が可能で、単純なデータモデルやインメモリーキャッシュレイヤーなどのデータが急速に変わる場合などに使われます。単純な処理のみに機能が制限されているので、追加の処理機能が必要な場合にはその複雑性はアプリケーション層に載せることになります。キーバリューストアはもっと複雑なドキュメントストアや、グラフデータベースなどの基本です。その他の参考資料、ページ: キーバリューストアキーバリューデータベースキーバリューストアの欠点Redisアーキテクチャメムキャッシュアーキテクチャドキュメントストア概要: ドキュメントがバリューとして保存されたキーバリューストアドキュメントストアはオブジェクトに関する全ての情報を持つドキュメント(XML、 JSON、 binaryなど)を中心に据えたシステムです。ドキュメントストアでは、ドキュメント自身の内部構造に基づいた、APIもしくはクエリ言語を提供します。 メモ：多くのキーバリューストアでは、値のメタデータを扱う機能を含んでいますが、そのことによって二つドキュメントストアとの境界線が曖昧になってしまっています。以上のことを実現するために、ドキュメントはコレクション、タグ、メタデータやディレクトリなどとして整理されています。ドキュメント同士はまとめてグループにできるものの、それぞれで全く異なるフィールドを持つ可能性があります。MongoDB や CouchDB などのドキュメントストアも、複雑なクエリを処理するためのSQLのような言語を提供しています。DynamoDB はキーバリューとドキュメントの両方をサポートしています。ドキュメントストアは高い柔軟性を担保するので、頻繁に変化するデータを扱う時に用いられます。その他の参考資料、ページ:  ドキュメントストアドキュメント指向 データベースMongoDB アーキテクチャCouchDB アーキテクチャElasticsearch アーキテクチャワイドカラムストア      Source: SQL & NoSQL, a brief history概要: ネストされたマップ カラムファミリー<行キー、 カラム<ColKey、 Value、 Timestamp>>ワイドカラムストアのデータの基本単位はカラム（ネーム・バリューのペア）です。それぞれのカラムはカラムファミリーとして（SQLテーブルのように）グループ化することができます。スーパーカラムファミリーはカラムファミリーの集合です。それぞれのカラムには行キーでアクセスすることができます。同じ行キーを持つカラムは同じ行として認識されます。それぞれの値は、バージョン管理とコンフリクトが起きた時のために、タイムスタンプを含みます。GoogleはBigtableを初のワイドカラムストアとして発表しました。それがオープンソースでHadoopなどでよく使われるHBase やFacebookによるCassandra などのプロジェクトに影響を与えました。BigTable、HBaseやCassandraなどのストアはキーを辞書形式で保持することで選択したキーレンジでのデータ取得を効率的にします。ワイドカラムストアは高い可用性とスケーラビリティを担保します。これらはとても大規模なデータセットを扱うことによく使われます。その他の参考資料、ページ:  ワイドカラムストアSQL & NoSQL簡単に歴史をさらうBigtable アーキテクチャHBase アーキテクチャCassandra アーキテクチャグラフデータベース      Source: Graph database概要: グラフグラフデータベースでは、それぞれのノードがレコードで、それぞれのアークは二つのノードを繋ぐ関係性として定義されます。グラフデータベースは多数の外部キーや多対多などの複雑な関係性を表すのに最適です。グラフデータベースはSNSなどのサービスの複雑な関係性モデルなどについて高いパフォーマンスを発揮します。比較的新しく、まだ一般的には用いられていないので、開発ツールやリソースを探すのが他の方法に比べて難しいかもしれません。多くのグラフはREST APIsを通じてのみアクセスできます。その他の参考資料、ページ:  グラフGraphデータベースNeo4jFlockDBその他の参考資料、ページ:  NoSQL基本用語の説明NoSQLデータベースについて調査と選択ガイドスケーラビリティNoSQLのイントロダクションNoSQLパターンSQLか？NoSQLか？      Source: Transitioning from RDBMS to NoSQLSQL を選ぶ理由:構造化されたデータ厳格なスキーマリレーショナルデータ複雑なジョインをする必要性トランザクションスケールする際のパターンが明確なとき開発者の数、コミュニティ、コード等がより充実しているインデックスによるデータ探索はとても速いNoSQL を選ぶ理由:準構造化されたデータダイナミックないし、フレキシブルなスキーマノンリレーショナルなデータ複雑なジョインをする必要がないデータの多くのTB (もしくは PB) を保存する集中的、大規模なデータ負荷に耐えられるIOPSについては極めて高いスループットを示すNoSQLに適するサンプルデータ:急激なクリックストリームやログデータの収集リーダーボードやスコアリングデータショッピングカートなどの一時的情報頻繁にアクセスされる ('ホットな') テーブルメタデータやルックアップテーブルその他の参考資料、ページ:  　SQLもしくはNoSQL最初の1000万ユーザーにスケールアップするためにSQLとNoSQLの違いキャッシュ      Source: Scalable system design patternsキャッシュはページの読み込み時間を削減し、サーバーやデータベースへの負荷を低減することができます。このモデルでは、実際の処理を保存するために、ディスパッチャーがまず以前にリクエストが送信されたかどうかを確認し、直前の結果を受け取ります。データベースはそのパーティションに渡って統合された読み取り書き込みの分配を要求しますが、人気アイテムはその分配を歪めてシステム全体のボトルネックになってしまうことがあります。データベースの前にキャッシュを差し込むことでこのように、均一でない負荷やトラフィックの急激な増加を吸収することができます。クライアントキャッシングキャッシュはOSやブラウザーなどのクライアントサイド、サーバーサイド もしくは独立のキャッシュレイヤーに設置することができます。CDNキャッシングCDN もキャッシュの一つとして考えることができます。Webサーバーキャッシングリバースプロキシ や Varnish などのキャッシュは静的そして動的なコンテンツを直接配信することができます。 webサーバーもリクエストをキャッシュしてアプリケーションサーバーに接続することなしにレスポンスを返すことができます。データベースキャッシングデータベースは普通、一般的な使用状況に適するようなキャッシングの設定を初期状態で持っています。この設定を特定の仕様に合わせて調整することでパフォーマンスを向上させることができます。アプリケーションキャッシングメムキャッシュなどのIn-memoryキャッシュやRedisはアプリケーションとデータストレージの間のキーバリューストアです。データはRAMで保持されるため、データがディスクで保存される一般的なデータベースよりもだいぶ速いです。RAM容量はディスクよりも限られているので、least recently used (LRU)などのcache invalidation アルゴリズムが 'コールド' なエントリを弾き、'ホット' なデータをRAMに保存します。Redisはさらに以下のような機能を備えています:パージステンス設定ソート済みセット、リストなどの組み込みデータ構造キャッシュには様々なレベルのものがありますが、いずれも大きく二つのカテゴリーのいずれかに分類することができます: データベースクエリ と オブジェクト です:行レベルクエリレベルFully-formed serializable objectsFully-rendered HTML一般的に、ファイルベースキャッシングはクローンを作り出してオートスケーリングを難しくしてしまうので避けるべきです。データベースクエリレベルでのキャッシングデータベースをクエリする際には必ずクエリをキーとしてハッシュして結果をキャッシュに保存しましょう。この手法はキャッシュ期限切れ問題に悩むことになります:複雑なクエリによりキャッシュされた結果を削除することが困難テーブルセルなどのデータ断片が変化した時に、その変化したセルを含むかもしれない全てのキャッシュされたクエリを削除する必要がある。オブジェクトレベルでのキャッシングデータをアプリケーションコードでそうするように、オブジェクトとして捉えてみましょう。アプリケーションに、データベースからのデータセットをクラスインスタンスやデータ構造として組み立てさせます。:そのデータが変更されたら、オブジェクトをキャッシュから削除すること非同期処理を許容します: ワーカーがキャッシュされたオブジェクトの中で最新のものを集めてきます何をキャッシュするか:ユーザーのセッション完全にレンダーされたウェブページアクテビティストリームユーザーグラフデータいつキャッシュを更新するかキャッシュに保存できる容量は限られているため、自分のケースではどのキャッシュ手法が一番いいかは検討する必要があります。キャッシュアサイド      Source: From cache to in-memory data gridアプリケーションはストレージへの読み書きの処理をします。キャッシュはストレージとは直接やりとりをしません。アプリケーションは以下のことをします:キャッシュの中のエントリを参照しますが、結果としてキャッシュミスになりますデータベースからエントリを取得しますエントリをキャッシュに追加しますエントリを返しますdef get_user(self, user_id):    user = cache.get(\""user.{0}\"", user_id)    if user is None:        user = db.query(\""SELECT * FROM users WHERE user_id = {0}\"", user_id)        if user is not None:            key = \""user.{0}\"".format(user_id)            cache.set(key, json.dumps(user))    return userMemcached は通常このように使われる。その後のキャッシュデータ読み込みは速いです。キャッシュアサイドはレージーローディングであるとも言われます。リクエストされたデータのみがキャッシュされ、リクエストされていないデータでキャッシュが溢れるのを防止します。欠点: キャッシュアサイド各キャッシュミスは三つのトリップを呼び出すことになり、体感できるほどの遅延が起きてしまいます。データベースのデータが更新されるとキャッシュデータは古いものになってしまいます。time-to-live (TTL)を設定することでキャッシュエントリの更新を強制的に行う、もしくはライトスルーを採用することでこの問題は緩和できます。ノードが落ちると、新規の空のノードで代替されることでレイテンシーが増加することになります。ライトスルー      Source: Scalability, availability, stability, patternsアプリケーションはキャッシュをメインのデータストアとして使い、そこにデータの読み書きを行います。一方、キャッシュはデータベースへの読み書きを担当します。アプリケーションはキャッシュにあるエントリを追加・更新しますキャッシュは同期的にデータストアに書き込みを行いますエントリを返しますアプリケーションコード:set_user(12345, {\""foo\"":\""bar\""})キャッシュコード:def set_user(user_id, values):    user = db.query(\""UPDATE Users WHERE id = {0}\"", user_id, values)    cache.set(user_id, user)ライトスルーは書き込み処理のせいで全体としては遅いオペレーションですが、書き込まれたばかりのデータに関する読み込みは速いです。ユーザー側は一般的にデータ更新時の方が読み込み時よりもレイテンシーに許容的です。キャッシュ内のデータは最新版で保たれます。欠点: ライトスルーノードが落ちたこと、もしくはスケーリングによって新しいノードが作成された時に、新しいノードはデータベース内のエントリーが更新されるまではエントリーをキャッシュしません。キャッシュアサイドとライトスルーを併用することでこの問題を緩和できます。書き込まれたデータの大部分は一度も読み込まれることはありません。このデータはTTLによって圧縮することができます。ライトビハインド (ライトバック)      Source: Scalability, availability, stability, patternsライトビハインドではアプリケーションは以下のことをします:キャッシュのエントリーを追加・更新しますデータストアへの書き込みを非同期的に行うことで、書き込みパフォーマンスを向上させます。欠点: ライトビハインドキャッシュがデータストア内のコンテンツにヒットする前にキャッシュが落ちるとデータ欠損が起きる可能性があります。キャッシュアサイドやライトスルーよりも実装が複雑になります。リフレッシュアヘッド      Source: From cache to in-memory data grid期限切れよりも前に、直近でアクセスされた全てのキャッシュエントリを自動的に更新するように設定することができます。もしどのアイテムが将来必要になるのかを正確に予測することができるのならば、リードスルーよりもレイテンシーを削減することができます。欠点: リフレッシュアヘッドどのアイテムが必要になるかの予測が正確でない場合にはリフレッシュアヘッドがない方がレイテンシーは良いという結果になってしまいます。欠点: キャッシュcache invalidationなどを用いて、データベースなどの真のデータとキャッシュの間の一貫性を保つ必要があります。Redisやmemcachedを追加することでアプリケーション構成を変更する必要があります。Cache invalidationも難しいですがそれに加えて、いつキャッシュを更新するかという複雑な問題にも悩まされることになります。その他の参考資料、ページFrom cache to in-memory data gridスケーラブルなシステムデザインパターンスケールできるシステムを設計するためのイントロダクションスケーラビリティ、可用性、安定性、パターンスケーラビリティAWS ElastiCacheのストラテジーWikipedia非同期処理      Source: Intro to architecting systems for scale非同期のワークフローはもし、連続的に行われるとリクエスト時間を圧迫してしまうような重い処理を別で処理する手法です。また、定期的にデータを集合させるなどの時間がかかるような処理を前もって処理しておくことにも役立ちます。メッセージキューメッセージキューはメッセージを受け取り、保存し、配信します。もし、処理がインラインで行うには遅すぎる場合、以下のようなワークフローでメッセージキューを用いるといいでしょう:アプリケーションはジョブをキューに配信し、ユーザーにジョブステータスを伝えます。ワーカーがジョブキューから受け取って、処理を行い、終了したらそのシグナルを返します。ユーザーの処理が止まることはなく、ジョブはバックグラウンドで処理されます。この間に、クライアントはオプションとして、タスクが完了したかのように見せるために小規模の処理を行います。例えば、ツイートを投稿するときに、ツイートはすぐにあなたのタイムラインに反映されたように見えますが、そのツイートが実際に全てのフォロワーに配信されるまでにはもう少し時間がかかっているでしょう。Redis はシンプルなメッセージ仲介としてはいいですが、メッセージが失われてしまう可能性があります。RabbitMQ はよく使われていますが、'AMQP'プロトコルに対応して、自前のノードを立てる必要があります。Amazon SQS という選択肢もありますが、レイテンシーが高く、メッセージが重複して配信されてしまう可能性があります。タスクキュータスクキューはタスクとその関連するデータを受け取り、処理した上でその結果を返します。スケジュール管理をできるほか、バックグラウンドでとても重いジョブをこなすこともできます。Celery はスケジューリングとpythonのサポートがあります。バックプレッシャーもし、キューが拡大しすぎると、メモリーよりもキューの方が大きくなりキャッシュミスが起こり、ディスク読み出しにつながり、パフォーマンスが低下することにつながります。バックプレッシャーはキューサイズを制限することで回避することができ、高いスループットを確保しキューにすでにあるジョブについてのレスポンス時間を短縮できます。キューがいっぱいになると、クライアントはサーバービジーもしくはHTTP 503をレスポンスとして受け取りまた後で時間をおいてアクセスするようにメッセージを受け取ります。クライアントはexponential backoffなどによって後ほど再度時間を置いてリクエストすることができます。欠点: 非同期処理キューを用いることで遅延が起こり、複雑さも増すため、あまり重くない計算処理やリアルタイムワークフローにおいては同期処理の方がいいでしょう。その他の参考資料、ページIt's all a numbers gameオーバーロードした時にバックプレッシャーを適用するLittle's lawメッセージキューとタスクキューの違いとは？通信      Source: OSI 7 layer modelHypertext transfer protocol (HTTP)HTTP はクライアントとサーバー間でのデータをエンコードして転送するための手法です。リクエスト・レスポンスに関わるプロトコルです。クライアントがリクエストをサーバーに投げ、サーバーがリクエストに関係するコンテンツと完了ステータス情報をレスポンスとして返します。HTTPは自己完結するので、間にロードバランサー、キャッシュ、エンクリプション、圧縮などのどんな中間ルーターが入っても動くようにできています。基本的なHTTPリクエストはHTTP動詞(メソッド)とリソース(エンドポイント)で成り立っています。以下がよくあるHTTP動詞です。:動詞詳細冪等性*セーフキャッシュできるかGETリソースを読み取るYesYesYesPOSTリソースを作成するもしくはデータを処理するトリガーNoNoYes レスポンスが新しい情報を含む場合PUTリソースを作成もしくは入れ替えるYesNoNoPATCHリソースを部分的に更新するNoNoYes レスポンスが新しい情報を含む場合DELETEリソースを削除するYesNoNo何度呼んでも同じ結果が返ってくることHTTPはTCP や UDP などの低級プロトコルに依存しているアプリケーションレイヤーのプロトコルである。その他の参考資料、ページ: HTTPHTTPってなに?HTTP と TCPの違いPUT と PATCHの違い伝送制御プロトコル (TCP)      Source: How to make a multiplayer gameTCPはIP networkの上で成り立つ接続プロトコルです。接続はhandshakeによって開始、解除されます。全ての送信されたパケットは欠損なしで送信先に送信された順番で到達するように以下の方法で保証されています:シーケンス番号とchecksum fieldsが全てのパケットに用意されているAcknowledgementパケットと自動再送信もし送信者が正しいレスポンスを受け取らなかったとき、パケットを再送信します。複数のタイムアウトがあったとき、接続は解除されます。TCP はフロー制御 と 輻輳制御も実装しています。これらの機能によって速度は低下し、一般的にUDPよりも非効率な転送手段になっています。ハイスループットを実現するために、ウェブサーバーはかなり大きな数のTCP接続を開いておくことがあり、そのことでメモリー使用が圧迫されます。ウェブサーバスレッドと例えばmemcached サーバーの間で多数のコネクションを保っておくことは高くつくかもしれません。可能なところではUDPに切り替えるだけでなくコネクションプーリングなども役立つかもしれません。TCPは高い依存性を要し、時間制約が厳しくないものに適しているでしょう。ウェブサーバー、データベース情報、SMTP、FTPやSSHなどの例に適用されます。以下の時にUDPよりもTCPを使うといいでしょう:全てのデータが欠損することなしに届いてほしいネットワークスループットの最適な自動推測をしてオペレーションしたいユーザデータグラムプロトコル (UDP)      Source: How to make a multiplayer gameUDPはコネクションレスです。データグラム（パケットのようなもの）はデータグラムレベルでの保証しかされません。データグラムは順不同で受け取り先に到着したりそもそも着かなかったりします。UDPは輻輳制御をサポートしません。TCPにおいてはサポートされているこれらの保証がないため、UDPは一般的に、TCPよりも効率的です。UDPはサブネット上のすべての機器にデータグラムを送信することができます。これはDHCP において役に立ちます。というのも、クライアントはまだIPアドレスを取得していないので、IPアドレスを必要とするTCPによるストリームができないからです。UDPは信頼性の面では劣りますが、VoIP、ビデオチャット、ストリーミングや同時通信マルチプレイヤーゲームなどのリアルタイム性が重視される時にはとても効果的です。TCPよりもUDPを使うのは:レイテンシーを最低限に抑えたい時データ欠損よりも、データ遅延を重視するときエラー修正を自前で実装したいときその他の参考資料、ページ: TCP と UDPゲームプログラミングのためのネットワークTCP と UDP プロトコルの主な違いTCP と UDPの違いTransmission control protocolUser datagram protocolFacebookのメムキャッシュスケーリング遠隔手続呼出 (RPC)      Source: Crack the system design interviewRPCではクライアントがリモートサーバーなどの異なるアドレス空間でプロシージャーが処理されるようにします。プロシージャーはローカルでのコールのように、クライアントからサーバーにどのように通信するかという詳細を省いた状態でコードが書かれます。リモートのコールは普通、ローカルのコールよりも遅く、信頼性に欠けるため、RPCコールをローカルコールと区別させておくことが好ましいでしょう。人気のRPCフレームワークは以下です。Protobuf、 Thrift、AvroRPC は リクエストレスポンスプロトコル:クライアントプログラム - クライアントスタブプロシージャーを呼び出します。パラメータはローカルでのプロシージャーコールのようにスタックへとプッシュされていきます。クライアントスタブプロシージャー - プロシージャIDとアーギュメントをパックしてリクエストメッセージにします。クライアント通信モジュール - OSがクライアントからサーバーへとメッセージを送ります。サーバー通信モジュール - OSが受け取ったパケットをサーバースタブプロシージャーに受け渡します。サーバースタブプロシージャー -  結果を展開し、プロシージャーIDにマッチするサーバープロシージャーを呼び出し、結果を返します。サーバーレスポンスは上記のステップを逆順で繰り返します。Sample RPC calls:GET /someoperation?data=anIdPOST /anotheroperation{  \""data\"":\""anId\"";  \""anotherdata\"": \""another value\""}RPCは振る舞いを公開することに焦点を当てています。RPCは内部通信パフォーマンスを理由として使われることが多いです。というのも、使用する状況に合わせてネイティブコールを自作することができるからです。ネイティブライブラリー (aka SDK) を呼ぶのは以下の時:ターゲットのプラットフォームを知っている時ロジックがどのようにアクセスされるのかを管理したいときライブラリー外でエラーがどのようにコントロールされるかを管理したい時パフォーマンスとエンドユーザーエクスペリエンスが最優先の時REST プロトコルに従うHTTP APIはパブリックAPIにおいてよく用いられます。欠点: RPCRPCクライアントとはサービス実装により厳密に左右されることになります。新しいオペレーション、使用例があるたびに新しくAPIが定義されなければなりません。RPCをデバッグするのは難しい可能性があります。既存のテクノロジーをそのまま使ってサービスを構築することはできないかもしれません。例えば、SquidなどのサーバーにRPCコールが正しくキャッシュ されるように追加で骨を折る必要があるかもしれません。Representational state transfer (REST)RESTは、クライアントがサーバーによってマネージされるリソースに対して処理を行うクライアント・サーバーモデルを支持するアーキテキチャスタイルです。サーバーは操作できるもしくは新しいリソースレプレゼンテーションを受け取ることができるようなリソースやアクションのレプレゼンテーションを提供します。すべての通信はステートレスでキャッシュ可能でなければなりません。RESTful なインターフェースには次の四つの特徴があります:特徴的なリソース (URI in HTTP) - どのオペレーションであっても同じURIを使う。HTTP動詞によって変わる (Verbs in HTTP) - 動詞、ヘッダー、ボディを使う自己説明的なエラーメッセージ (status response in HTTP) - ステータスコードを使い、新しく作ったりしないこと。HATEOAS (HTML interface for HTTP) - 自分のwebサービスがブラウザで完全にアクセスできること。サンプル REST コール:GET /someresources/anIdPUT /someresources/anId{\""anotherdata\"": \""another value\""}RESTはデータを公開することに焦点を当てています。クライアントとサーバーのカップリングを最小限にするもので、パブリックAPIなどによく用いられます。RESTはURI、 representation through headers、そして、GET、POST、PUT、 DELETE、PATCHなどのHTTP動詞等のよりジェネリックで統一されたメソッドを用います。ステートレスであるのでRESTは水平スケーリングやパーティショニングに最適です。欠点: RESTRESTはデータ公開に焦点を当てているので、リソースが自然に整理されていなかったり、シンプルなヒエラルキーで表せられない時にはよい選択肢とは言えないかもしれません。例えば、とあるイベントのセットにマッチするすべての更新情報を返すと言った処理は簡単にはパスで表現することができません。RESTでは、URIパス、クエリパラメータ、そして場合によってはリクエストボディなどによって実装されることが多いでしょう。RESTは少数の動詞に依存しています(GET、POST、PUT、DELETE、そして PATCH) が時には使いたい事例に合わないことがあります。例えば、期限の切れたドキュメントをアーカイブに移したい場合などはこれらの動詞の中には綺麗にはフィットしません。ネストされたヒエラルキーの中にあるリソースをとってくるのはシングルビューを描画するのにクライアントとサーバー間で数回やりとりしなければなりません。例として、ブログエントリーのコンテンツとそれに対するコメントを表示する場合などです。様々なネットワーク環境で動作する可能性が考えられるモバイルアプリケーションにおいてはこのような複数のやり取りは好ましくありません。時が経つにつれて、APIレスポンスにより多くのフィールドが与えられて、古いクライアントはすでにいらないものも含めてすべてのデータフィールドを受け取ることになります。そのことで、ペイロードが大きくなりすぎて、レイテンシーも拡大することになります。RPCとREST比較OperationRPCRESTサインアップPOST /signupPOST /personsリザインPOST /resign{\""personid\"": \""1234\""}DELETE /persons/1234Person読み込みGET /readPerson?personid=1234GET /persons/1234Personのアイテムリスト読み込みGET /readUsersItemsList?personid=1234GET /persons/1234/itemsPersonのアイテムへのアイテム追加POST /addItemToUsersItemsList{\""personid\"": \""1234\"";\""itemid\"": \""456\""}POST /persons/1234/items{\""itemid\"": \""456\""}アイテム更新POST /modifyItem{\""itemid\"": \""456\"";\""key\"": \""value\""}PUT /items/456{\""key\"": \""value\""}アイテム削除POST /removeItem{\""itemid\"": \""456\""}DELETE /items/456  Source: Do you really know why you prefer REST over RPCその他の参考資料、ページ: REST と RPCDo you really know why you prefer REST over RPCWhen are RPC-ish approaches more appropriate than REST?REST vs JSON-RPCDebunking the myths of RPC and RESTWhat are the drawbacks of using RESTCrack the system design interviewThriftWhy REST for internal use and not RPCセキュリティこのセクションは更新が必要です。contributingしてください！セキュリティは幅広いトピックです。十分な経験、セキュリティ分野のバックグラウンドがなくても、セキュリティの知識を要する職に応募するのでない限り、基本以上のことを知る必要はないでしょう。情報伝達、保存における暗号化XSS や SQL injectionを防ぐために、全てのユーザー入力もしくはユーザーに露出される入力パラメーターをサニタイズするSQL injectionを防ぐためにパラメータ化されたクエリを用いる。least privilegeの原理を用いるその他の参考資料、ページ:開発者のためのセキュリティガイドOWASP top ten補遺暗算で、推計値を求める必要があることも時にはあります。例えば、ディスクから100枚イメージ分のサムネイルを作る時間を求めたり、その時にどれだけディスクメモリーが消費されるかなどの値です。2の乗数表 と 全てのプログラマーが知るべきレイテンシー値 は良い参考になるでしょう。2の乗数表乗数           厳密な値         約        Bytes---------------------------------------------------------------7                             1288                             25610                           1024   1 thousand           1 KB16                         65,536                       64 KB20                      1,048,576   1 million            1 MB30                  1,073,741,824   1 billion            1 GB32                  4,294,967,296                        4 GB40              1,099,511,627,776   1 trillion           1 TBその他の参考資料、ページ:2の乗数表全てのプログラマーが知るべきレイテンシー値Latency Comparison Numbers--------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy            10,000   ns       10 usSend 1 KB bytes over 1 Gbps network     10,000   ns       10 usRead 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSDRead 1 MB sequentially from disk    30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSDSend packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 msNotes-----1 ns = 10^-9 seconds1 us = 10^-6 seconds = 1,000 ns1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns上記表に基づいた役に立つ数値:ディスクからの連続読み取り速度 30 MB/s1 Gbps Ethernetからの連続読み取り速度　100 MB/sSSDからの連続読み取り速度 1 GB/smain memoryからの連続読み取り速度 4 GB/s1秒で地球6-7周できる1秒でデータセンターと2000周やりとりできるレイテンシーの視覚的表その他の参考資料、ページ:全てのプログラマーが知るべきレイテンシー値 - 1全てのプログラマーが知るべきレイテンシー値 - 2Designs, lessons, and advice from building large distributed systemsSoftware Engineering Advice from Building Large-Scale Distributed Systems他のシステム設計面接例題頻出のシステム設計面接課題とその解答へのリンク質問解答Dropboxのようなファイル同期サービスを設計するyoutube.comGoogleのような検索エンジンの設計queue.acm.orgstackexchange.comardendertat.comstanford.eduGoogleのようなスケーラブルなwebクローラーの設計quora.comGoogle docsの設計code.google.comneil.fraser.nameRedisのようなキーバリューストアの設計slideshare.netMemcachedのようなキャッシュシステムの設計slideshare.netAmazonのようなレコメンデーションシステムの設計hulu.comijcai13.orgBitlyのようなURL短縮サービスの設計n00tc0d3r.blogspot.comWhatsAppのようなチャットアプリの設計highscalability.comInstagramのような写真共有サービスの設計highscalability.comhighscalability.comFacebookニュースフィードの設計quora.comquora.comslideshare.netFacebookタイムラインの設計facebook.comhighscalability.comFacebookチャットの設計erlang-factory.comfacebook.comFacebookのようなgraph検索の設計facebook.comfacebook.comfacebook.comCloudFlareのようなCDNの設計cmu.eduTwitterのトレンド機能の設計michael-noll.comsnikolov .wordpress.comランダムID発行システムの設計blog.twitter.comgithub.com一定のインターバル時間での上位k件を返すucsb.eduwpi.edu複数のデータセンターからデータを配信するサービスの設計highscalability.comオンラインの複数プレイヤーカードゲームの設計indieflashblog.combuildnewgames.comガーベッジコレクションシステムの設計stuffwithstuff.comwashington.eduシステム設計例題を追加するContribute実世界のアーキテクチャ世の中のシステムがどのように設計されているかについての記事      Source: Twitter timelines at scale以下の記事の重箱の隅をつつくような細かい詳細にこだわらないこと。むしろ共通の原理、技術、パターンを探ることそれぞれのコンポーネントでどんな問題が解決され、コンポーネントはどこでうまく使えもしくは使えないかを知ること学んだことを復習すること種類システム参考ページデータ処理MapReduce - Googleの分散データ処理システムresearch.google.comデータ処理Spark - Databricksの分散データ処理システムslideshare.netデータ処理Storm - Twitterの分散データ処理システムslideshare.netデータストアBigtable - Googleのカラム指向分散データベースharvard.eduデータストアHBase - Bigtableのオープンソース実装slideshare.netデータストアCassandra - Facebookのカラム指向分散データベースslideshare.netデータストアDynamoDB - Amazonのドキュメント指向分散データベースharvard.eduデータストアMongoDB - ドキュメント指向分散データベースslideshare.netデータストアSpanner - Googleのグローバル分散データベースresearch.google.comデータストアMemcached - 分散メモリーキャッシングシステムslideshare.netデータストアRedis - 永続性とバリュータイプを兼ね備えた分散メモリーキャッシングシステムslideshare.netファイルシステムGoogle File System (GFS) - 分散ファイルシステムresearch.google.comファイルシステムHadoop File System (HDFS) - GFSのオープンソース実装apache.orgMiscChubby - 疎結合の分散システムをロックするGoogleのサービスresearch.google.comMiscDapper - 分散システムを追跡するインフラresearch.google.comMiscKafka - LinkedInによるPub/subメッセージキューslideshare.netMiscZookeeper - 同期を可能にする中央集権インフラとサービスslideshare.netアーキテクチャを追加するContribute各企業のアーキテクチャ企業参考ページAmazonAmazon architectureCinchcastProducing 1,500 hours of audio every dayDataSiftRealtime datamining At 120,000 tweets per secondDropBoxHow we've scaled DropboxESPNOperating At 100,000 duh nuh nuhs per secondGoogleGoogle architectureInstagram14 million users, terabytes of photosWhat powers InstagramJustin.tvJustin.Tv's live video broadcasting architectureFacebookScaling memcached at FacebookTAO: Facebook’s distributed data store for the social graphFacebook’s photo storageFlickrFlickr architectureMailboxFrom 0 to one million users in 6 weeksPinterestFrom 0 To 10s of billions of page views a month18 million visitors, 10x growth, 12 employeesPlayfish50 million monthly users and growingPlentyOfFishPlentyOfFish architectureSalesforceHow they handle 1.3 billion transactions a dayStack OverflowStack Overflow architectureTripAdvisor40M visitors, 200M dynamic page views, 30TB dataTumblr15 billion page views a monthTwitterMaking Twitter 10000 percent fasterStoring 250 million tweets a day using MySQL150M active users, 300K QPS, a 22 MB/S firehoseTimelines at scaleBig and small data at TwitterOperations at Twitter: scaling beyond 100 million usersUberHow Uber scales their real-time market platformWhatsAppThe WhatsApp architecture Facebook bought for $19 billionYouTubeYouTube scalabilityYouTube architecture企業のエンジニアブログ面接を受ける企業のアーキテクチャ投げられる質問は同じ分野から来ることもあるでしょうAirbnb EngineeringAtlassian DevelopersAutodesk EngineeringAWS BlogBitly Engineering BlogBox BlogsCloudera Developer BlogDropbox Tech BlogEngineering at QuoraEbay Tech BlogEvernote Tech BlogEtsy Code as CraftFacebook EngineeringFlickr CodeFoursquare Engineering BlogGitHub Engineering BlogGoogle Research BlogGroupon Engineering BlogHeroku Engineering BlogHubspot Engineering BlogHigh ScalabilityInstagram EngineeringIntel Software BlogJane Street Tech BlogLinkedIn EngineeringMicrosoft EngineeringMicrosoft Python EngineeringNetflix Tech BlogPaypal Developer BlogPinterest Engineering BlogQuora EngineeringReddit BlogSalesforce Engineering BlogSlack Engineering BlogSpotify LabsTwilio Engineering BlogTwitter EngineeringUber Engineering BlogYahoo Engineering BlogYelp Engineering BlogZynga Engineering Blogその他の参考資料、ページ:kilimchoi/engineering-blogsここにあるリストは比較的小規模なものにとどめ、kilimchoi/engineering-blogsにより詳細に記すことで重複しないようにしておくことにする。エンジニアブログへのリンクを追加する場合はここではなく、engineering-blogsレボジトリに追加することを検討してください。進行中の作業セクションの追加や、進行中の作業を手伝っていただける場合はこちら!MapReduceによる分散コンピューティングConsistent hashingScatter gatherContributeクレジットクレジット及び、参照ページは適時このリポジトリ内に記載してありますSpecial thanks to:Hired in techCracking the coding interviewHigh scalabilitycheckcheckzz/system-design-interviewshashank88/system_designmmcgrana/services-engineeringSystem design cheat sheetA distributed systems reading listCracking the system design interviewContact infoFeel free to contact me to discuss any issues, questions, or comments.My contact info can be found on my GitHub page.LicenseI am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2017 Donne MartinCreative Commons Attribution 4.0 International License (CC BY 4.0)http://creativecommons.org/licenses/by/4.0/"
69,AUTOMATIC1111/stable-diffusion-webui,https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/README.md,Python,"Stable Diffusion web UIA browser interface based on Gradio library for Stable Diffusion.FeaturesDetailed feature showcase with images:Original txt2img and img2img modesOne click install and run script (but you still must install python and git)OutpaintingInpaintingColor SketchPrompt MatrixStable Diffusion UpscaleAttention, specify parts of text that the model should pay more attention toa man in a ((tuxedo)) - will pay more attention to tuxedoa man in a (tuxedo:1.21) - alternative syntaxselect text and press Ctrl+Up or Ctrl+Down (or Command+Up or Command+Down if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)Loopback, run img2img processing multiple timesX/Y/Z plot, a way to draw a 3 dimensional plot of images with different parametersTextual Inversionhave as many embeddings as you want and use any names you like for themuse multiple embeddings with different numbers of vectors per tokenworks with half precision floating point numberstrain embeddings on 8GB (also reports of 6GB working)Extras tab with:GFPGAN, neural network that fixes facesCodeFormer, face restoration tool as an alternative to GFPGANRealESRGAN, neural network upscalerESRGAN, neural network upscaler with a lot of third party modelsSwinIR and Swin2SR (see here), neural network upscalersLDSR, Latent diffusion super resolution upscalingResizing aspect ratio optionsSampling method selectionAdjust sampler eta values (noise multiplier)More advanced noise setting optionsInterrupt processing at any time4GB video card support (also reports of 2GB working)Correct seeds for batchesLive prompt token length validationGeneration parametersparameters you used to generate images are saved with that imagein PNG chunks for PNG, in EXIF for JPEGcan drag the image to PNG info tab to restore generation parameters and automatically copy them into UIcan be disabled in settingsdrag and drop an image/text-parameters to promptboxRead Generation Parameters Button, loads parameters in promptbox to UISettings pageRunning arbitrary python code from UI (must run with --allow-code to enable)Mouseover hints for most UI elementsPossible to change defaults/mix/max/step values for UI elements via text configTiling support, a checkbox to create images that can be tiled like texturesProgress bar and live image generation previewCan use a separate neural network to produce previews with almost none VRAM or compute requirementNegative prompt, an extra text field that allows you to list what you don't want to see in generated imageStyles, a way to save part of prompt and easily apply them via dropdown laterVariations, a way to generate same image but with tiny differencesSeed resizing, a way to generate same image but at slightly different resolutionCLIP interrogator, a button that tries to guess prompt from an imagePrompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midwayBatch Processing, process a group of files using img2imgImg2img Alternative, reverse Euler method of cross attention controlHighres Fix, a convenience option to produce high resolution pictures in one click without usual distortionsReloading checkpoints on the flyCheckpoint Merger, a tab that allows you to merge up to 3 checkpoints into oneCustom scripts with many extensions from communityComposable-Diffusion, a way to use multiple prompts at onceseparate prompts using uppercase ANDalso supports weights for prompts: a cat :1.2 AND a dog AND a penguin :2.2No token limit for prompts (original stable diffusion lets you use up to 75 tokens)DeepDanbooru integration, creates danbooru style tags for anime promptsxformers, major speed increase for select cards: (add --xformers to commandline args)via extension: History tab: view, direct and delete images conveniently within the UIGenerate forever optionTraining tabhypernetworks and embeddings optionsPreprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)Clip skipHypernetworksLoras (same as Hypernetworks but more pretty)A sparate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your promptCan select to load a different VAE from settings screenEstimated completion time in progress barAPISupport for dedicated inpainting model by RunwayMLvia extension: Aesthetic Gradients, a way to generate images with a specific aesthetic by using clip images embeds (implementation of https://github.com/vicgalle/stable-diffusion-aesthetic-gradients)Stable Diffusion 2.0 support - see wiki for instructionsAlt-Diffusion support - see wiki for instructionsNow without any bad letters!Load checkpoints in safetensors formatEased resolution restriction: generated image's domension must be a multiple of 8 rather than 64Now with a license!Reorder elements in the UI from settings screenInstallation and RunningMake sure the required dependencies are met and follow the instructions available for both NVidia (recommended) and AMD GPUs.Alternatively, use online services (like Google Colab):List of Online ServicesInstallation on Windows 10/11 with NVidia-GPUs using release packageDownload sd.webui.zip from v1.0.0-pre and extract it's contents.Run update.bat.Run run.bat.For more details see Install-and-Run-on-NVidia-GPUsAutomatic Installation on WindowsInstall Python 3.10.6 (Newer version of Python does not support torch), checking \""Add Python to PATH\"".Install git.Download the stable-diffusion-webui repository, for example by running git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git.Run webui-user.bat from Windows Explorer as normal, non-administrator, user.Automatic Installation on LinuxInstall the dependencies:# Debian-based:sudo apt install wget git python3 python3-venv# Red Hat-based:sudo dnf install wget git python3# Arch-based:sudo pacman -S wget git python3Navigate to the directory you would like the webui to be installed and execute the following command:bash <(wget -qO- https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh)Run webui.sh.Check webui-user.sh for options.Installation on Apple SiliconFind the instructions here.ContributingHere's how to add code to this repo: ContributingDocumentationThe documentation was moved from this README over to the project's wiki.For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) crawlable wiki.CreditsLicenses for borrowed code can be found in Settings -> Licenses screen, and also in html/licenses.html file.Stable Diffusion - https://github.com/CompVis/stable-diffusion, https://github.com/CompVis/taming-transformersk-diffusion - https://github.com/crowsonkb/k-diffusion.gitGFPGAN - https://github.com/TencentARC/GFPGAN.gitCodeFormer - https://github.com/sczhou/CodeFormerESRGAN - https://github.com/xinntao/ESRGANSwinIR - https://github.com/JingyunLiang/SwinIRSwin2SR - https://github.com/mv-lab/swin2srLDSR - https://github.com/Hafiidz/latent-diffusionMiDaS - https://github.com/isl-org/MiDaSIdeas for optimizations - https://github.com/basujindal/stable-diffusionCross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)Sub-quadratic Cross Attention layer optimization - Alex Birch (Birch-san/diffusers#1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we're not using his code, but we are using his ideas).Idea for SD upscale - https://github.com/jquesnelle/txt2imghdNoise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-botCLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogatorIdea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorchxformers - https://github.com/facebookresearch/xformersDeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooruSampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pixSecurity advice - RyotaKUniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPCTAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesdLyCORIS - KohakuBlueleafInitial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.(You)"
70,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
71,pallets/flask,https://github.com/pallets/flask/blob/main/README.rst,Python,"FlaskFlask is a lightweight WSGI web application framework. It is designedto make getting started quick and easy, with the ability to scale up tocomplex applications. It began as a simple wrapper around Werkzeugand Jinja and has become one of the most popular Python webapplication frameworks.Flask offers suggestions, but doesn't enforce any dependencies orproject layout. It is up to the developer to choose the tools andlibraries they want to use. There are many extensions provided by thecommunity that make adding new functionality easy.InstallingInstall and update using pip:$ pip install -U FlaskA Simple Example# save this as app.pyfrom flask import Flaskapp = Flask(__name__)@app.route(\""/\"")def hello():    return \""Hello, World!\""$ flask run  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)ContributingFor guidance on setting up a development environment and how to make acontribution to Flask, see the contributing guidelines.DonateThe Pallets organization develops and supports Flask and the librariesit uses. In order to grow the community of contributors and users, andallow the maintainers to devote more time to the projects, pleasedonate today.LinksDocumentation: https://flask.palletsprojects.com/Changes: https://flask.palletsprojects.com/changes/PyPI Releases: https://pypi.org/project/Flask/Source Code: https://github.com/pallets/flask/Issue Tracker: https://github.com/pallets/flask/issues/Chat: https://discord.gg/pallets"
72,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.⚠️ IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!⚠️ IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means you’ve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the project’s direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a project’s website for a “team” page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participants’ behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, “How do I…“ or “What do you think about…“ instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
73,geekcomputers/Python,https://github.com/geekcomputers/Python/blob/master/README.md,Python,"My Python Eggs 🐍 😄I do not consider myself as a programmer. I create these little programs as experiments to play with Python, or to solve problems for myself. I would gladly accept pointers from others to improve, simplify, or make the code more efficient. If you would like to make any comments then please feel free to email me: craig@geekcomputers.co.uk.This repository contains a collection of Python scripts that are designed to reduce human workload and serve as educational examples for beginners to get started with Python. The code documentation is aligned correctly for viewing in Notepad++ 🗒️Feel free to explore the scripts and use them for your learning and automation needs!List of Scripts:batch_file_rename.py - Batch rename a group of files in a specified directory, changing their extensions.create_dir_if_not_there.py - Check if a directory exists in the user's home directory. Create it if it doesn't exist.Fast Youtube Downloader - Download YouTube videos quickly with parallel threads using aria2c.Google Image Downloader - Query a given term and retrieve images from the Google Image database.dir_test.py - Test if the directory testdir exists. If not, create it.env_check.py - Check if all the required environment variables are set.blackjack.py - Casino Blackjack-21 game in Python.fileinfo.py - Show file information for a given file.folder_size.py - Scan the current directory and all subdirectories and display their sizes.logs.py - Search for all *.log files in a directory, zip them using the specified program, and date stamp them.move_files_over_x_days.py - Move all files over a specified age (in days) from the source directory to the destination directory.nslookup_check.py - Open the file server_list.txt and perform nslookup for each server to check the DNS entry.osinfo.py - Display information about the operating system on which the script is running.ping_servers.py - Ping the servers associated with the specified application group.ping_subnet.py - Scan the final range of a given IP subnet for available addresses.powerdown_startup.py - Ping machines in the server list. Load the putty session if the machine is up, or notify if it is not.puttylogs.py - Zip all the logs in the given directory.script_count.py - Scan the scripts directory and count the different types of scripts.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.script_listing.py - List all files in a given directory and its subdirectories.testlines.py - Open a file and print out 100 lines of the set line variable.tweeter.py - Tweet text or a picture from the terminal.serial_scanner.py - List available serial ports in use on Linux and Windows systems.get_youtube_view.py - Get more views for YouTube videos and repeat songs on YouTube.CountMillionCharacter.py and CountMillionCharacter2.0 - Get character count of a text file.xkcd_downloader.py - Download the latest XKCD comic and place them in a new folder called \""comics\"".timymodule.py - An alternative to Python's 'timeit' module and easier to use.calculator.py - Implement a calculator using Python's eval() function.Google_News.py - Use BeautifulSoup to provide latest news headlines along with news links.cricket_live_score - Use BeautifulSoup to provide live cricket scores.youtube.py - Take a song name as input and fetch the YouTube URL of the best matching song and play it.site_health.py - Check the health of a remote server.SimpleStopWatch.py - Simple stop watch implementation using Python's time module.Changemac.py - Change your MAC address, generate a random MAC address, or enter input as a new MAC address on Linux (Successfully Tested in Ubuntu 18.04).whatsapp-monitor.py - Use Selenium to give online status updates about your contacts in WhatsApp on the terminal.whatsapp-chat-analyzer.py - WhatsApp group/individual chat analyzer that visualizes chat activity using matplotlib.JARVIS.py - Control Windows programs with your voice.Images Downloader - Download images from webpages on Unix-based systems.space_invader.py.py - Classical 2D space invader game to recall your childhood memories.Test Case Generator - Generate different types of test cases with a clean and friendly UI, used in competitive programming and software testing.Note: The content in this repository belongs to the respective authors and creators. I'm just providing a formatted README.md for better presentation."
74,udacity/fullstack-nanodegree-vm,https://github.com/udacity/fullstack-nanodegree-vm/blob/master/README.md,Python,"Full Stack Web Developer Nanodegree program virtual machine  Virtual machine for the Relational Databases and Full Stack Foundations courses in the Full Stack Web Developer Nanodegree programTable of ContentsTable of ContentsIntroInstallationInstructionsTroubleshootingSupporting MaterialsIntroIn the next part of this course, you'll use a virtual machine (VM) to run an SQL database server and a web app that uses it. The VM is a Linux server system that runs on top of your own computer. You can share files easily between your computer and the VM; and you'll be running a web service inside the VM which you'll be able to access from your regular browser.We're using tools called Vagrant and VirtualBox to install and manage the VM. You'll need to install these to do some of the exercises. The instructions on this page will help you do this.Conceptual overviewThis video offers a conceptual overview of virtual machines and Vagrant. You don't need to watch it to proceed, but you may find it informative.Use a terminalYou'll be doing these exercises using a Unix-style terminal on your computer. If you are using a Mac or Linux system, your regular terminal program will do just fine. On Windows, we recommend using the Git Bash terminal that comes with the Git software. If you don't already have Git installed, download Git from git-scm.com.For a refresher on using the Unix shell, look back at our Shell Workshop.If you'd like to learn more about Git, take a look at our course about Git.InstallationInstall VirtualBoxVirtualBox is the software that actually runs the virtual machine. You can download it from virtualbox.org, here. Install the platform package for your operating system. You do not need the extension pack or the SDK. You do not need to launch VirtualBox after installing it; Vagrant will do that.Currently (October 2017), the supported version of VirtualBox to install is version 5.1. Newer versions do not work with the current release of Vagrant.Ubuntu users: If you are running Ubuntu 14.04, install VirtualBox using the Ubuntu Software Center instead. Due to a reported bug, installing VirtualBox from the site may uninstall other software you need.Install VagrantVagrant is the software that configures the VM and lets you share files between your host computer and the VM's filesystem. Download it from vagrantup.com. Install the version for your operating system.Windows users: The Installer may ask you to grant network permissions to Vagrant or make a firewall exception. Be sure to allow this.If Vagrant is successfully installed, you will be able to run vagrant --versionin your terminal to see the version number.The shell prompt in your terminal may differ. Here, the $ sign is the shell prompt.Download the VM configurationUse Github to fork and clone, or download, the repository https://github.com/udacity/fullstack-nanodegree-vm.You will end up with a new directory containing the VM files. Change to this directory in your terminal with cd. Inside, you will find another directory called vagrant. Change directory to the vagrant directory:Navigating to the FSND-Virtual-Machine directory and listing the files in it.This picture was taken on a Mac, but the commands will look the same on Git Bash on Windows.InstructionsStart the virtual machineFrom your terminal, inside the vagrant subdirectory, run the command vagrant up. This will cause Vagrant to download the Linux operating system and install it. This may take quite a while (many minutes) depending on how fast your Internet connection is.Starting the Ubuntu Linux installation with vagrant up.This screenshot shows just the beginning of many, many pages of output in a lot of colors.When vagrant up is finished running, you will get your shell prompt back. At this point, you can run vagrant ssh to log in to your newly installed Linux VM!Logging into the Linux VM with vagrant ssh.Logged inIf you are now looking at a shell prompt that starts with the word vagrant (as in the above screenshot), congratulations — you've gotten logged into your Linux VM.If not, take a look at the Troubleshooting section below.The files for this courseInside the VM, change directory to /vagrant and look around with ls.The files you see here are the same as the ones in the vagrant subdirectory on your computer (where you started Vagrant from). Any file you create in one will be automatically shared to the other. This means that you can edit code in your favorite text editor, and run it inside the VM.Files in the VM's /vagrant directory are shared with the vagrant folder on your computer. But other data inside the VM is not. For instance, the PostgreSQL database itself lives only inside the VM.Running the databaseThe PostgreSQL database server will automatically be started inside the VM. You can use the psql command-line tool to access it and run SQL statements:Running psql, the PostgreSQL command interface, inside the VM.Logging out and inIf you type exit (or Ctrl-D) at the shell prompt inside the VM, you will be logged out, and put back into your host computer's shell. To log back in, make sure you're in the same directory and type vagrant ssh again.If you reboot your computer, you will need to run vagrant up to restart the VM.TroubleshootingI'm not sure if it workedIf you can type vagrant ssh and log into your VM, then it worked! It's normal for the vagrant up process to display a lot of text in many colors, including sometimes scary-looking messages in red, green, and purple. If you get your shell prompt back at the end, and you can log in, it should be OK.vagrant up is taking a long timeBecause it's downloading a whole Linux operating system from the Internet.I'm on Windows, and when I run vagrant ssh, I don't get a shell promptSome versions of Windows and Vagrant have a problem communicating the right settings for the terminal. There is a workaround: Instead of vagrant ssh, run the command winpty vagrant ssh instead.I'm on Windows and getting an error about virtualizationSometimes other virtualization programs such as Docker or Hyper-V can interfere with VirtualBox. Try shutting these other programs down first.In addition, some Windows PCs have settings in the BIOS or UEFI (firmware) or in the operating system that disable the use of virtualization. To change this, you may need to reboot your computer and access the firmware settings. A web search can help you find the settings for your computer and operating system. Unfortunately there are so many different versions of Windows and PCs that we can't offer a simple guide to doing this.Why are we using a VM, it seems complicatedIt is complicated. In this case, the point of it is to be able to offer the same software (Linux and PostgreSQL) regardless of what kind of computer you're running on.I got some other error messageIf you're getting a specific textual error message, try looking it up on your favorite search engine. If that doesn't help, take a screenshot and post it to the discussion forums, along with as much detail as you can provide about the process you went through to get there.If all else fails, try an older versionUdacity mentors have noticed that some newer versions of Vagrant don't work on all operating systems. Version 1.9.2 is reported to be stabler on some systems, and version 1.9.1 is the supported version on Ubuntu 17.04. You can download older versions of Vagrant from the Vagrant releases index.Supporting MaterialsVirtual machine repository on GitHub(Back to TOC)"
75,apachecn/ailearning,https://github.com/apachecn/ailearning/blob/master/README.md,Python,"                                AI learning协议：CC BY-NC-SA 4.0一种新技术一旦开始流行，你要么坐上压路机，要么成为铺路石。——Stewart Brand在线阅读在线阅读（v1）QuantLearningApacheCN 中文翻译组 713436582ApacheCN 学习资源注: 广告位合作(物美价廉)，请联系 apachecn@163.com路线图入门只看: 步骤 1 => 2 => 3，你可以当大牛！中级补充 - 资料库: https://github.com/apachecn/ai-roadmap补充算法刷题: https://www.ixigua.com/pseries/6822642486343631363/面试求职: https://www.ixigua.com/pseries/6822563009391493636/机器学习实战: https://www.ixigua.com/pseries/6822816341615968772/NLP教学视频: https://www.ixigua.com/pseries/6828241431295951373/AI常用函数说明: https://github.com/apachecn/AiLearning/tree/master/AI常用函数说明.md1.机器学习 - 基础支持版本VersionSupported3.6.x❌2.7.x✅注意事项:机器学习实战: 仅仅只是学习，请使用 python 2.7.x 版本 （3.6.x 只是修改了部分）基本介绍资料来源: Machine Learning in Action(机器学习实战-个人笔记)统一数据地址: https://github.com/apachecn/data百度云打包地址: apachecn/data#3书籍下载地址: https://github.com/apachecn/data/tree/master/book机器学习下载地址: https://github.com/apachecn/data/tree/master/机器学习深度学习数据地址: https://github.com/apachecn/data/tree/master/深度学习推荐系统数据地址: https://github.com/apachecn/data/tree/master/推荐系统视频网站: 优酷 ／bilibili / Acfun / 网易云课堂，可直接在线播放。（最下方有相应链接）-- 推荐 红色石头: 台湾大学林轩田机器学习笔记-- 推荐 机器学习笔记: https://feisky.xyz/machine-learning学习文档模块章节类型负责人(GitHub)QQ机器学习实战第 1 章: 机器学习基础介绍@毛红动1306014226机器学习实战第 2 章: KNN 近邻算法分类@尤永江279393323机器学习实战第 3 章: 决策树分类@景涛844300439机器学习实战第 4 章: 朴素贝叶斯分类@wnma3mz@分析1003324213244970749机器学习实战第 5 章: Logistic回归分类@微光同尘529925688机器学习实战第 6 章: SVM 支持向量机分类@王德红934969547网上组合内容第 7 章: 集成方法（随机森林和 AdaBoost）分类@片刻529815144机器学习实战第 8 章: 回归回归@微光同尘529925688机器学习实战第 9 章: 树回归回归@微光同尘529925688机器学习实战第 10 章: K-Means 聚类聚类@徐昭清827106588机器学习实战第 11 章: 利用 Apriori 算法进行关联分析频繁项集@刘海飞1049498972机器学习实战第 12 章: FP-growth 高效发现频繁项集频繁项集@程威842725815机器学习实战第 13 章: 利用 PCA 来简化数据工具@廖立娟835670618机器学习实战第 14 章: 利用 SVD 来简化数据工具@张俊皓714974242机器学习实战第 15 章: 大数据与 MapReduce工具@wnma3mz1003324213Ml项目实战第 16 章: 推荐系统（已迁移）项目推荐系统（迁移后地址）第一期的总结2017-04-08: 第一期的总结总结总结529815144网站视频知乎问答-爆炸啦-机器学习该怎么入门？当然我知道，第一句就会被吐槽，因为科班出身的人，不屑的吐了一口唾沫，说傻X，还评论 Andrew Ng 的视频。。我还知道还有一部分人，看 Andrew Ng 的视频就是看不懂，那神秘的数学推导，那迷之微笑的英文版的教学，我何尝又不是这样走过来的？？ 我的心可能比你们都痛，因为我在网上收藏过上10部《机器学习》相关视频，外加国内本土风格的教程: 7月+小象 等等，我都很难去听懂，直到有一天，被一个百度的高级算法分析师推荐说: 《机器学习实战》还不错，通俗易懂，你去试试？？我试了试，还好我的Python基础和调试能力还不错，基本上代码都调试过一遍，很多高大上的 \""理论+推导\""，在我眼中变成了几个 \""加减乘除+循环\""，我想这不就是像我这样的程序员想要的入门教程么？很多程序员说机器学习 TM 太难学了，是的，真 TM 难学，我想最难的是: 没有一本像《机器学习实战》那样的作者愿意以程序员 Coding 角度去给大家讲解！！最近几天，GitHub 涨了 300颗 star，加群的200人， 现在还在不断的增加++，我想大家可能都是感同身受吧！很多想入门新手就是被忽悠着收藏收藏再收藏，但是最后还是什么都没有学到，也就是\""资源收藏家\""，也许新手要的就是 MachineLearning(机器学习) 学习路线图。没错，我可以给你们的一份，因为我们还通过视频记录下来我们的学习过程。水平当然也有限，不过对于新手入门，绝对没问题，如果你还不会，那算我输！！视频怎么看？理论科班出身-建议去学习 Andrew Ng 的视频（Ng 的视频绝对是权威，这个毋庸置疑）编码能力强 - 建议看我们的《机器学习实战-教学版》编码能力弱 - 建议看我们的《机器学习实战-讨论版》，不过在看理论的时候，看 教学版-理论部分；讨论版的废话太多，不过在讲解代码的时候是一行一行讲解的；所以，根据自己的需求，自由的组合。【免费】数学教学视频 - 可汗学院 入门篇@于振梓 推荐: 可汗学院-网易公开课概率统计线性代数可汗学院(概率)可汗学院(统计学)可汗学院(线性代数)机器学习视频 - ApacheCN 教学版AcFunB站优酷网易云课堂【免费】机器/深度学习视频 - 吴恩达机器学习深度学习吴恩达机器学习神经网络和深度学习2.深度学习支持版本VersionSupported3.6.x✅2.7.x❌入门基础反向传递: https://www.cnblogs.com/charlotte77/p/5629865.htmlCNN原理: http://www.cnblogs.com/charlotte77/p/7759802.htmlRNN原理: https://blog.csdn.net/qq_39422642/article/details/78676567LSTM原理: https://blog.csdn.net/weixin_42111770/article/details/80900575Pytorch - 教程-- 待更新TensorFlow 2.0 - 教程-- 待更新目录结构:安装指南Keras 快速入门实战项目 1 电影情感分类实战项目 2 汽车燃油效率实战项目 3 优化 过拟合和欠拟合实战项目 4 古诗词自动生成切分（分词）词性标注命名实体识别句法分析WordNet可以被看作是一个同义词词典词干提取（stemming）与词形还原（lemmatization）https://www.biaodianfu.com/nltk.html/ampTensorFlow 2.0学习网址https://github.com/lyhue1991/eat_tensorflow2_in_30_days3.自然语言处理支持版本VersionSupported3.6.x✅2.7.x❌学习过程中-内心复杂的变化！！！自从学习NLP以后，才发现国内与国外的典型区别:1. 对资源的态度是完全相反的:  1) 国内: 就好像为了名气，举办工作装逼的会议，就是没有干货，全部都是象征性的PPT介绍，不是针对在做的各位  2）国外: 就好像是为了推动nlp进步一样，分享者各种干货资料和具体的实现。（特别是: python自然语言处理）2. 论文的实现:   1) 各种高大上的论文实现，却还是没看到一个像样的GitHub项目！（可能我的搜索能力差了点，一直没找到）  2）国外就不举例了，我看不懂！3. 开源的框架  1）国外的开源框架:  tensorflow/pytorch 文档+教程+视频（官方提供）  2) 国内的开源框架: 额额，还真举例不出来！但是牛逼吹得不比国外差！（MXNet虽然有众多国人参与开发，但不能算是国内开源框架。基于MXNet的动手学深度学习(http://zh.d2l.ai & https://discuss.gluon.ai/t/topic/753)中文教程,已经由沐神(李沐)以及阿斯顿·张讲授录制，公开发布(文档+第一季教程+视频）。)每一次深入都要去翻墙，每一次深入都要Google，每一次看着国内的说: 哈工大、讯飞、中科大、百度、阿里多牛逼，但是资料还是得国外去找！有时候真的挺恨的！真的有点瞧不起自己国内的技术环境！当然谢谢国内很多博客大佬，特别是一些入门的Demo和基本概念。【深入的水平有限，没看懂】【入门须知】必须了解: https://github.com/apachecn/AiLearning/tree/master/nlp【入门教程】强烈推荐: PyTorch 自然语言处理: https://github.com/apachecn/NLP-with-PyTorchPython 自然语言处理 第二版: https://usyiyi.github.io/nlp-py-2e-zh推荐一个liuhuanyong大佬整理的nlp全面知识体系: https://liuhuanyong.github.io开源 - 词向量库集合:https://www.cnblogs.com/Darwin2000/p/5786984.htmlhttps://ai.tencent.com/ailab/nlp/embedding.htmlhttps://blog.csdn.net/xiezj007/article/details/85073890https://github.com/Embedding/Chinese-Word-Vectorshttps://github.com/brightmart/nlp_chinese_corpushttps://github.com/codemayq/chinese_chatbot_corpushttps://github.com/candlewill/Dialog_Corpus1.使用场景 （百度公开课）第一部分 入门介绍1.) 自然语言处理入门介绍第二部分 机器翻译2.) 机器翻译第三部分 篇章分析3.1.) 篇章分析-内容概述3.2.) 篇章分析-内容标签3.3.) 篇章分析-情感分析3.4.) 篇章分析-自动摘要第四部分 UNIT-语言理解与交互技术4.) UNIT-语言理解与交互技术应用领域中文分词:构建DAG图动态规划查找，综合正反向（正向加权反向输出）求得DAG最大概率路径使用了SBME语料训练了一套 HMM + Viterbi 模型，解决未登录词问题1.文本分类（Text Classification）文本分类是指标记句子或文档，例如电子邮件垃圾邮件分类和情感分析。下面是一些很好的初学者文本分类数据集。路透社Newswire主题分类（路透社-21578）。1987年路透社出现的一系列新闻文件，按类别编制索引。另见RCV1，RCV2和TRC2。IMDB电影评论情感分类（斯坦福）。来自网站imdb.com的一系列电影评论及其积极或消极的情绪。新闻组电影评论情感分类（康奈尔）。来自网站imdb.com的一系列电影评论及其积极或消极的情绪。有关更多信息，请参阅帖子:单标签文本分类的数据集。情感分析比赛地址: https://www.kaggle.com/c/word2vec-nlp-tutorial方案一(0.86): WordCount + 朴素 Bayes方案二(0.94): LDA + 分类模型（knn/决策树/逻辑回归/svm/xgboost/随机森林）a) 决策树效果不是很好，这种连续特征不太适合的b) 通过参数调整 200 个topic，信息量保存效果较优（计算主题）方案三(0.72): word2vec + CNN说实话: 没有一个好的机器，是调不出来一个好的结果 (: 逃通过AUC 来评估模型的效果2.语言模型（Language Modeling）语言建模涉及开发一种统计模型，用于预测句子中的下一个单词或一个单词中的下一个单词。它是语音识别和机器翻译等任务中的前置任务。它是语音识别和机器翻译等任务中的前置任务。下面是一些很好的初学者语言建模数据集。古腾堡项目，一系列免费书籍，可以用纯文本检索各种语言。还有更多正式的语料库得到了很好的研究; 例如:布朗大学现代美国英语标准语料库。大量英语单词样本。谷歌10亿字语料库。新词发现中文分词新词发现python3利用互信息和左右信息熵的中文分词新词发现https://github.com/zhanzecheng/Chinese_segment_augment句子相似度识别项目地址: https://www.kaggle.com/c/quora-question-pairs解决方案: word2vec + Bi-GRU文本纠错bi-gram + levenshtein3.图像字幕（Image Captioning）mage字幕是为给定图像生成文本描述的任务。下面是一些很好的初学者图像字幕数据集。上下文中的公共对象（COCO）。包含超过12万张带描述的图像的集合Flickr 8K。从flickr.com获取的8千个描述图像的集合。Flickr 30K。从flickr.com获取的3万个描述图像的集合。欲了解更多，请看帖子:探索图像字幕数据集，2016年4.机器翻译（Machine Translation）机器翻译是将文本从一种语言翻译成另一种语言的任务。下面是一些很好的初学者机器翻译数据集。加拿大第36届议会的协调国会议员。成对的英语和法语句子。欧洲议会诉讼平行语料库1996-2011。句子对一套欧洲语言。有大量标准数据集用于年度机器翻译挑战; 看到:统计机器翻译机器翻译Encoder + Decoder(Attention)参考案例: http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html5.问答系统（Question Answering）问答是一项任务，其中提供了一个句子或文本样本，从中提出问题并且必须回答问题。下面是一些很好的初学者问题回答数据集。斯坦福问题回答数据集（SQuAD）。回答有关维基百科文章的问题。Deepmind问题回答语料库。从每日邮报回答有关新闻文章的问题。亚马逊问答数据。回答有关亚马逊产品的问题。有关更多信息，请参阅帖子:数据集: 我如何获得问答网站的语料库，如Quora或Yahoo Answers或Stack Overflow来分析答案质量？6.语音识别（Speech Recognition）语音识别是将口语的音频转换为人类可读文本的任务。下面是一些很好的初学者语音识别数据集。TIMIT声学 - 语音连续语音语料库。不是免费的，但因其广泛使用而上市。口语美国英语和相关的转录。VoxForge。用于构建用于语音识别的开源数据库的项目。LibriSpeech ASR语料库。从LibriVox收集的大量英语有声读物。7.自动文摘（Document Summarization）文档摘要是创建较大文档的简短有意义描述的任务。下面是一些很好的初学者文档摘要数据集。法律案例报告数据集。收集了4000份法律案件及其摘要。TIPSTER文本摘要评估会议语料库。收集了近200份文件及其摘要。英语新闻文本的AQUAINT语料库。不是免费的，而是广泛使用的。新闻文章的语料库。欲了解更多信息:文档理解会议（DUC）任务。在哪里可以找到用于文本摘要的良好数据集？命名实体识别Bi-LSTM CRF参考案例: http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.htmlCRF推荐文档: https://www.jianshu.com/p/55755fc649b1文本摘要抽取式word2vec + textrankword2vec推荐文档: https://www.zhihu.com/question/44832436/answer/266068967textrank推荐文档: https://blog.csdn.net/BaiHuaXiu123/article/details/77847232Graph图计算【慢慢更新】数据集: https://github.com/apachecn/data/tree/master/graph学习资料: spark graphX实战.pdf 【文件太大不方便提供，自己百度】知识图谱知识图谱，我只认 SimmerChan: 【知识图谱-给AI装个大脑】说实话，我是看这博主老哥写的博客长大的，写的真的是深入浅出。我很喜欢，所以就分享给大家，希望你们也喜欢。进一步阅读如果您希望更深入，本节提供了其他数据集列表。维基百科研究中使用的文本数据集数据集: 计算语言学家和自然语言处理研究人员使用的主要文本语料库是什么？斯坦福统计自然语言处理语料库按字母顺序排列的NLP数据集列表该机构NLTK在DL4J上打开深度学习数据NLP数据集国内开放数据集: https://bosonnlp.com/dev/resource参考比赛收集平台pbharrin/machinelearninginactionML Mastery致谢最近无意收到群友推送的链接，发现得到大佬高度的认可，并在热心的推广。在此感谢:量子位人工智能前沿讲习赞助我们"
76,langchain-ai/langchain,https://github.com/langchain-ai/langchain/blob/master/README.md,Python,"🦜️🔗 LangChain⚡ Building applications with LLMs through composability ⚡Looking for the JS/TS version? Check out LangChain.js.Production Support: As you move your LangChains into production, we'd love to offer more hands-on support.Fill out this form to share more about what you're building, and our team will get in touch.🚨Breaking Changes for select chains (SQLDatabase) on 7/28/23In an effort to make langchain leaner and safer, we are moving select chains to langchain_experimental.This migration has already started, but we are remaining backwards compatible until 7/28.On that date, we will remove functionality from langchain.Read more about the motivation and the progress here.Read how to migrate your code here.Quick Installpip install langchainorpip install langsmith && conda install langchain -c conda-forge🤔 What is this?Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. However, using these LLMs in isolation is often insufficient for creating a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.This library aims to assist in the development of those types of applications. Common examples of these applications include:❓ Question Answering over specific documentsDocumentationEnd-to-end Example: Question Answering over Notion Database💬 ChatbotsDocumentationEnd-to-end Example: Chat-LangChain🤖 AgentsDocumentationEnd-to-end Example: GPT+WolframAlpha📖 DocumentationPlease see here for full documentation on:Getting started (installation, setting up the environment, simple examples)How-To examples (demos, integrations, helper functions)Reference (full API docs)Resources (high-level explanation of core concepts)🚀 What can this help with?There are six main areas that LangChain is designed to help with.These are, in increasing order of complexity:📃 LLMs and Prompts:This includes prompt management, prompt optimization, a generic interface for all LLMs, and common utilities for working with LLMs.🔗 Chains:Chains go beyond a single LLM call and involve sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.📚 Data Augmented Generation:Data Augmented Generation involves specific types of chains that first interact with an external data source to fetch data for use in the generation step. Examples include summarization of long pieces of text and question/answering over specific data sources.🤖 Agents:Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end-to-end agents.🧠 Memory:Memory refers to persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.🧐 Evaluation:[BETA] Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this.For more information on these concepts, please see our full documentation.💁 ContributingAs an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.For detailed information on how to contribute, see here."
77,floodsung/Deep-Learning-Papers-Reading-Roadmap,https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md,Python,"Deep Learning Papers Reading RoadmapIf you are a newcomer to the Deep Learning area, the first question you may have is \""Which paper should I start reading from?\""Here is a reading roadmap of Deep Learning papers!The roadmap is constructed in accordance with the following four guidelines:From outline to detailFrom old to state-of-the-artfrom generic to specific areasfocus on state-of-the-artYou will find many papers that are quite new but really worth reading.I would continue adding papers to this roadmap.1 Deep Learning History and Basics1.0 Book[0] Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. \""Deep learning.\"" An MIT Press book. (2015). [html] (Deep Learning Bible, you can read this book while reading following papers.) ⭐⭐⭐⭐⭐1.1 Survey[1] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. \""Deep learning.\"" Nature 521.7553 (2015): 436-444. [pdf] (Three Giants' Survey) ⭐⭐⭐⭐⭐1.2 Deep Belief Network(DBN)(Milestone of Deep Learning Eve)[2] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. \""A fast learning algorithm for deep belief nets.\"" Neural computation 18.7 (2006): 1527-1554. [pdf](Deep Learning Eve) ⭐⭐⭐[3] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. \""Reducing the dimensionality of data with neural networks.\"" Science 313.5786 (2006): 504-507. [pdf] (Milestone, Show the promise of deep learning) ⭐⭐⭐1.3 ImageNet Evolution（Deep Learning broke out from here）[4] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. \""Imagenet classification with deep convolutional neural networks.\"" Advances in neural information processing systems. 2012. [pdf] (AlexNet, Deep Learning Breakthrough) ⭐⭐⭐⭐⭐[5] Simonyan, Karen, and Andrew Zisserman. \""Very deep convolutional networks for large-scale image recognition.\"" arXiv preprint arXiv:1409.1556 (2014). [pdf] (VGGNet,Neural Networks become very deep!) ⭐⭐⭐[6] Szegedy, Christian, et al. \""Going deeper with convolutions.\"" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. [pdf] (GoogLeNet) ⭐⭐⭐[7] He, Kaiming, et al. \""Deep residual learning for image recognition.\"" arXiv preprint arXiv:1512.03385 (2015). [pdf] (ResNet,Very very deep networks, CVPR best paper) ⭐⭐⭐⭐⭐1.4 Speech Recognition Evolution[8] Hinton, Geoffrey, et al. \""Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups.\"" IEEE Signal Processing Magazine 29.6 (2012): 82-97. [pdf] (Breakthrough in speech recognition)⭐⭐⭐⭐[9] Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. \""Speech recognition with deep recurrent neural networks.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (RNN)⭐⭐⭐[10] Graves, Alex, and Navdeep Jaitly. \""Towards End-To-End Speech Recognition with Recurrent Neural Networks.\"" ICML. Vol. 14. 2014. [pdf]⭐⭐⭐[11] Sak, Haşim, et al. \""Fast and accurate recurrent neural network acoustic models for speech recognition.\"" arXiv preprint arXiv:1507.06947 (2015). [pdf] (Google Speech Recognition System) ⭐⭐⭐[12] Amodei, Dario, et al. \""Deep speech 2: End-to-end speech recognition in english and mandarin.\"" arXiv preprint arXiv:1512.02595 (2015). [pdf] (Baidu Speech Recognition System) ⭐⭐⭐⭐[13] W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig \""Achieving Human Parity in Conversational Speech Recognition.\"" arXiv preprint arXiv:1610.05256 (2016). [pdf] (State-of-the-art in speech recognition, Microsoft) ⭐⭐⭐⭐After reading above papers, you will have a basic understanding of the Deep Learning history, the basic architectures of Deep Learning model(including CNN, RNN, LSTM) and how deep learning can be applied to image and speech recognition issues. The following papers will take you in-depth understanding of the Deep Learning method, Deep Learning in different areas of application and the frontiers. I suggest that you can choose the following papers based on your interests and research direction.#2 Deep Learning Method2.1 Model[14] Hinton, Geoffrey E., et al. \""Improving neural networks by preventing co-adaptation of feature detectors.\"" arXiv preprint arXiv:1207.0580 (2012). [pdf] (Dropout) ⭐⭐⭐[15] Srivastava, Nitish, et al. \""Dropout: a simple way to prevent neural networks from overfitting.\"" Journal of Machine Learning Research 15.1 (2014): 1929-1958. [pdf] ⭐⭐⭐[16] Ioffe, Sergey, and Christian Szegedy. \""Batch normalization: Accelerating deep network training by reducing internal covariate shift.\"" arXiv preprint arXiv:1502.03167 (2015). [pdf] (An outstanding Work in 2015) ⭐⭐⭐⭐[17] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \""Layer normalization.\"" arXiv preprint arXiv:1607.06450 (2016). [pdf] (Update of Batch Normalization) ⭐⭐⭐⭐[18] Courbariaux, Matthieu, et al. \""Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or−1.\"" [pdf] (New Model,Fast)  ⭐⭐⭐[19] Jaderberg, Max, et al. \""Decoupled neural interfaces using synthetic gradients.\"" arXiv preprint arXiv:1608.05343 (2016). [pdf] (Innovation of Training Method,Amazing Work) ⭐⭐⭐⭐⭐[20] Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. \""Net2net: Accelerating learning via knowledge transfer.\"" arXiv preprint arXiv:1511.05641 (2015). [pdf] (Modify previously trained network to reduce training epochs) ⭐⭐⭐[21] Wei, Tao, et al. \""Network Morphism.\"" arXiv preprint arXiv:1603.01670 (2016). [pdf] (Modify previously trained network to reduce training epochs) ⭐⭐⭐2.2 Optimization[22] Sutskever, Ilya, et al. \""On the importance of initialization and momentum in deep learning.\"" ICML (3) 28 (2013): 1139-1147. [pdf] (Momentum optimizer) ⭐⭐[23] Kingma, Diederik, and Jimmy Ba. \""Adam: A method for stochastic optimization.\"" arXiv preprint arXiv:1412.6980 (2014). [pdf] (Maybe used most often currently) ⭐⭐⭐[24] Andrychowicz, Marcin, et al. \""Learning to learn by gradient descent by gradient descent.\"" arXiv preprint arXiv:1606.04474 (2016). [pdf] (Neural Optimizer,Amazing Work) ⭐⭐⭐⭐⭐[25] Han, Song, Huizi Mao, and William J. Dally. \""Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding.\"" CoRR, abs/1510.00149 2 (2015). [pdf] (ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup) ⭐⭐⭐⭐⭐[26] Iandola, Forrest N., et al. \""SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size.\"" arXiv preprint arXiv:1602.07360 (2016). [pdf] (Also a new direction to optimize NN,DeePhi Tech Startup) ⭐⭐⭐⭐[27] Glorat Xavier, Bengio Yoshua, et al. \""Understanding the difficulty of training deep forward neural networks.\"" Proceedings of the thirteenth International Conference on Artificial Intelligence and Statistics, PMLR 9:249-256,2010. [pdf] ⭐⭐⭐⭐2.3 Unsupervised Learning / Deep Generative Model[28] Le, Quoc V. \""Building high-level features using large scale unsupervised learning.\"" 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf] (Milestone, Andrew Ng, Google Brain Project, Cat) ⭐⭐⭐⭐[29] Kingma, Diederik P., and Max Welling. \""Auto-encoding variational bayes.\"" arXiv preprint arXiv:1312.6114 (2013). [pdf] (VAE) ⭐⭐⭐⭐[30] Goodfellow, Ian, et al. \""Generative adversarial nets.\"" Advances in Neural Information Processing Systems. 2014. [pdf] (GAN,super cool idea) ⭐⭐⭐⭐⭐[31] Radford, Alec, Luke Metz, and Soumith Chintala. \""Unsupervised representation learning with deep convolutional generative adversarial networks.\"" arXiv preprint arXiv:1511.06434 (2015). [pdf] (DCGAN) ⭐⭐⭐⭐[32] Gregor, Karol, et al. \""DRAW: A recurrent neural network for image generation.\"" arXiv preprint arXiv:1502.04623 (2015). [pdf] (VAE with attention, outstanding work) ⭐⭐⭐⭐⭐[33] Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. \""Pixel recurrent neural networks.\"" arXiv preprint arXiv:1601.06759 (2016). [pdf] (PixelRNN) ⭐⭐⭐⭐[34] Oord, Aaron van den, et al. \""Conditional image generation with PixelCNN decoders.\"" arXiv preprint arXiv:1606.05328 (2016). [pdf] (PixelCNN) ⭐⭐⭐⭐[34] S. Mehri et al., \""SampleRNN: An Unconditional End-to-End Neural Audio Generation Model.\"" arXiv preprint \tarXiv:1612.07837 (2016). [pdf] ⭐⭐⭐⭐⭐2.4 RNN / Sequence-to-Sequence Model[35] Graves, Alex. \""Generating sequences with recurrent neural networks.\"" arXiv preprint arXiv:1308.0850 (2013). [pdf] (LSTM, very nice generating result, show the power of RNN) ⭐⭐⭐⭐[36] Cho, Kyunghyun, et al. \""Learning phrase representations using RNN encoder-decoder for statistical machine translation.\"" arXiv preprint arXiv:1406.1078 (2014). [pdf] (First Seq-to-Seq Paper) ⭐⭐⭐⭐[37] Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \""Sequence to sequence learning with neural networks.\"" Advances in neural information processing systems. 2014. [pdf] (Outstanding Work) ⭐⭐⭐⭐⭐[38] Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. \""Neural Machine Translation by Jointly Learning to Align and Translate.\"" arXiv preprint arXiv:1409.0473 (2014). [pdf] ⭐⭐⭐⭐[39] Vinyals, Oriol, and Quoc Le. \""A neural conversational model.\"" arXiv preprint arXiv:1506.05869 (2015). [pdf] (Seq-to-Seq on Chatbot) ⭐⭐⭐2.5 Neural Turing Machine[40] Graves, Alex, Greg Wayne, and Ivo Danihelka. \""Neural turing machines.\"" arXiv preprint arXiv:1410.5401 (2014). [pdf] (Basic Prototype of Future Computer) ⭐⭐⭐⭐⭐[41] Zaremba, Wojciech, and Ilya Sutskever. \""Reinforcement learning neural Turing machines.\"" arXiv preprint arXiv:1505.00521 362 (2015). [pdf] ⭐⭐⭐[42] Weston, Jason, Sumit Chopra, and Antoine Bordes. \""Memory networks.\"" arXiv preprint arXiv:1410.3916 (2014). [pdf] ⭐⭐⭐[43] Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. \""End-to-end memory networks.\"" Advances in neural information processing systems. 2015. [pdf] ⭐⭐⭐⭐[44] Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. \""Pointer networks.\"" Advances in Neural Information Processing Systems. 2015. [pdf] ⭐⭐⭐⭐[45] Graves, Alex, et al. \""Hybrid computing using a neural network with dynamic external memory.\"" Nature (2016). [pdf] (Milestone,combine above papers' ideas) ⭐⭐⭐⭐⭐2.6 Deep Reinforcement Learning[46] Mnih, Volodymyr, et al. \""Playing atari with deep reinforcement learning.\"" arXiv preprint arXiv:1312.5602 (2013). [pdf]) (First Paper named deep reinforcement learning) ⭐⭐⭐⭐[47] Mnih, Volodymyr, et al. \""Human-level control through deep reinforcement learning.\"" Nature 518.7540 (2015): 529-533. [pdf] (Milestone) ⭐⭐⭐⭐⭐[48] Wang, Ziyu, Nando de Freitas, and Marc Lanctot. \""Dueling network architectures for deep reinforcement learning.\"" arXiv preprint arXiv:1511.06581 (2015). [pdf] (ICLR best paper,great idea)  ⭐⭐⭐⭐[49] Mnih, Volodymyr, et al. \""Asynchronous methods for deep reinforcement learning.\"" arXiv preprint arXiv:1602.01783 (2016). [pdf] (State-of-the-art method) ⭐⭐⭐⭐⭐[50] Lillicrap, Timothy P., et al. \""Continuous control with deep reinforcement learning.\"" arXiv preprint arXiv:1509.02971 (2015). [pdf] (DDPG) ⭐⭐⭐⭐[51] Gu, Shixiang, et al. \""Continuous Deep Q-Learning with Model-based Acceleration.\"" arXiv preprint arXiv:1603.00748 (2016). [pdf] (NAF) ⭐⭐⭐⭐[52] Schulman, John, et al. \""Trust region policy optimization.\"" CoRR, abs/1502.05477 (2015). [pdf] (TRPO) ⭐⭐⭐⭐[53] Silver, David, et al. \""Mastering the game of Go with deep neural networks and tree search.\"" Nature 529.7587 (2016): 484-489. [pdf] (AlphaGo) ⭐⭐⭐⭐⭐2.7 Deep Transfer Learning / Lifelong Learning / especially for RL[54] Bengio, Yoshua. \""Deep Learning of Representations for Unsupervised and Transfer Learning.\"" ICML Unsupervised and Transfer Learning 27 (2012): 17-36. [pdf] (A Tutorial) ⭐⭐⭐[55] Silver, Daniel L., Qiang Yang, and Lianghao Li. \""Lifelong Machine Learning Systems: Beyond Learning Algorithms.\"" AAAI Spring Symposium: Lifelong Machine Learning. 2013. [pdf] (A brief discussion about lifelong learning)  ⭐⭐⭐[56] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \""Distilling the knowledge in a neural network.\"" arXiv preprint arXiv:1503.02531 (2015). [pdf] (Godfather's Work) ⭐⭐⭐⭐[57] Rusu, Andrei A., et al. \""Policy distillation.\"" arXiv preprint arXiv:1511.06295 (2015). [pdf] (RL domain) ⭐⭐⭐[58] Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. \""Actor-mimic: Deep multitask and transfer reinforcement learning.\"" arXiv preprint arXiv:1511.06342 (2015). [pdf] (RL domain) ⭐⭐⭐[59] Rusu, Andrei A., et al. \""Progressive neural networks.\"" arXiv preprint arXiv:1606.04671 (2016). [pdf] (Outstanding Work, A novel idea) ⭐⭐⭐⭐⭐2.8 One Shot Deep Learning[60] Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. \""Human-level concept learning through probabilistic program induction.\"" Science 350.6266 (2015): 1332-1338. [pdf] (No Deep Learning,but worth reading) ⭐⭐⭐⭐⭐[61] Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. \""Siamese Neural Networks for One-shot Image Recognition.\""(2015) [pdf] ⭐⭐⭐[62] Santoro, Adam, et al. \""One-shot Learning with Memory-Augmented Neural Networks.\"" arXiv preprint arXiv:1605.06065 (2016). [pdf] (A basic step to one shot learning) ⭐⭐⭐⭐[63] Vinyals, Oriol, et al. \""Matching Networks for One Shot Learning.\"" arXiv preprint arXiv:1606.04080 (2016). [pdf] ⭐⭐⭐[64] Hariharan, Bharath, and Ross Girshick. \""Low-shot visual object recognition.\"" arXiv preprint arXiv:1606.02819 (2016). [pdf] (A step to large data) ⭐⭐⭐⭐3 Applications3.1 NLP(Natural Language Processing)[1] Antoine Bordes, et al. \""Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing.\"" AISTATS(2012) [pdf] ⭐⭐⭐⭐[2] Mikolov, et al. \""Distributed representations of words and phrases and their compositionality.\"" ANIPS(2013): 3111-3119 [pdf] (word2vec) ⭐⭐⭐[3] Sutskever, et al. \""“Sequence to sequence learning with neural networks.\"" ANIPS(2014) [pdf] ⭐⭐⭐[4] Ankit Kumar, et al. \""“Ask Me Anything: Dynamic Memory Networks for Natural Language Processing.\"" arXiv preprint arXiv:1506.07285(2015) [pdf] ⭐⭐⭐⭐[5] Yoon Kim, et al. \""Character-Aware Neural Language Models.\"" NIPS(2015) arXiv preprint arXiv:1508.06615(2015) [pdf] ⭐⭐⭐⭐[6] Jason Weston, et al. \""Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.\"" arXiv preprint arXiv:1502.05698(2015) [pdf] (bAbI tasks) ⭐⭐⭐[7] Karl Moritz Hermann, et al. \""Teaching Machines to Read and Comprehend.\"" arXiv preprint arXiv:1506.03340(2015) [pdf] (CNN/DailyMail cloze style questions) ⭐⭐[8] Alexis Conneau, et al. \""Very Deep Convolutional Networks for Natural Language Processing.\"" arXiv preprint arXiv:1606.01781(2016) [pdf] (state-of-the-art in text classification) ⭐⭐⭐[9] Armand Joulin, et al. \""Bag of Tricks for Efficient Text Classification.\"" arXiv preprint arXiv:1607.01759(2016) [pdf] (slightly worse than state-of-the-art, but a lot faster) ⭐⭐⭐3.2 Object Detection[1] Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. \""Deep neural networks for object detection.\"" Advances in Neural Information Processing Systems. 2013. [pdf] ⭐⭐⭐[2] Girshick, Ross, et al. \""Rich feature hierarchies for accurate object detection and semantic segmentation.\"" Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [pdf] (RCNN) ⭐⭐⭐⭐⭐[3] He, Kaiming, et al. \""Spatial pyramid pooling in deep convolutional networks for visual recognition.\"" European Conference on Computer Vision. Springer International Publishing, 2014. [pdf] (SPPNet) ⭐⭐⭐⭐[4] Girshick, Ross. \""Fast r-cnn.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] ⭐⭐⭐⭐[5] Ren, Shaoqing, et al. \""Faster R-CNN: Towards real-time object detection with region proposal networks.\"" Advances in neural information processing systems. 2015. [pdf] ⭐⭐⭐⭐[6] Redmon, Joseph, et al. \""You only look once: Unified, real-time object detection.\"" arXiv preprint arXiv:1506.02640 (2015). [pdf] (YOLO,Oustanding Work, really practical) ⭐⭐⭐⭐⭐[7] Liu, Wei, et al. \""SSD: Single Shot MultiBox Detector.\"" arXiv preprint arXiv:1512.02325 (2015). [pdf] ⭐⭐⭐[8] Dai, Jifeng, et al. \""R-FCN: Object Detection viaRegion-based Fully Convolutional Networks.\"" arXiv preprint arXiv:1605.06409 (2016). [pdf] ⭐⭐⭐⭐[9] He, Gkioxari, et al. \""Mask R-CNN\"" arXiv preprint arXiv:1703.06870 (2017). [pdf] ⭐⭐⭐⭐[10] Bochkovskiy, Alexey, et al. \""YOLOv4: Optimal Speed and Accuracy of Object Detection.\""  arXiv preprint arXiv:2004.10934 (2020). [pdf] ⭐⭐⭐⭐[11] Tan, Mingxing, et al. “EfficientDet: Scalable and Efficient Object Detection.\"" arXiv preprint arXiv:1911.09070 (2019). [pdf] ⭐⭐⭐⭐⭐3.3 Visual Tracking[1] Wang, Naiyan, and Dit-Yan Yeung. \""Learning a deep compact image representation for visual tracking.\"" Advances in neural information processing systems. 2013. [pdf] (First Paper to do visual tracking using Deep Learning,DLT Tracker) ⭐⭐⭐[2] Wang, Naiyan, et al. \""Transferring rich feature hierarchies for robust visual tracking.\"" arXiv preprint arXiv:1501.04587 (2015). [pdf] (SO-DLT) ⭐⭐⭐⭐[3] Wang, Lijun, et al. \""Visual tracking with fully convolutional networks.\"" Proceedings of the IEEE International Conference on Computer Vision. 2015. [pdf] (FCNT) ⭐⭐⭐⭐[4] Held, David, Sebastian Thrun, and Silvio Savarese. \""Learning to Track at 100 FPS with Deep Regression Networks.\"" arXiv preprint arXiv:1604.01802 (2016). [pdf] (GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods) ⭐⭐⭐⭐[5] Bertinetto, Luca, et al. \""Fully-Convolutional Siamese Networks for Object Tracking.\"" arXiv preprint arXiv:1606.09549 (2016). [pdf] (SiameseFC,New state-of-the-art for real-time object tracking) ⭐⭐⭐⭐[6] Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. \""Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking.\"" ECCV (2016) [pdf] (C-COT) ⭐⭐⭐⭐[7] Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. \""Modeling and Propagating CNNs in a Tree Structure for Visual Tracking.\"" arXiv preprint arXiv:1608.07242 (2016). [pdf] (VOT2016 Winner,TCNN) ⭐⭐⭐⭐3.4 Image Caption[1] Farhadi,Ali,etal. \""Every picture tells a story: Generating sentences from images\"". In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. [pdf] ⭐⭐⭐[2] Kulkarni, Girish, et al. \""Baby talk: Understanding and generating image descriptions\"". In Proceedings of the 24th CVPR, 2011. [pdf]⭐⭐⭐⭐[3] Vinyals, Oriol, et al. \""Show and tell: A neural image caption generator\"". In arXiv preprint arXiv:1411.4555, 2014. [pdf]⭐⭐⭐[4] Donahue, Jeff, et al. \""Long-term recurrent convolutional networks for visual recognition and description\"". In arXiv preprint arXiv:1411.4389 ,2014. [pdf][5] Karpathy, Andrej, and Li Fei-Fei. \""Deep visual-semantic alignments for generating image descriptions\"". In arXiv preprint arXiv:1412.2306, 2014. [pdf]⭐⭐⭐⭐⭐[6] Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. \""Deep fragment embeddings for bidirectional image sentence mapping\"". In Advances in neural information processing systems, 2014. [pdf]⭐⭐⭐⭐[7] Fang, Hao, et al. \""From captions to visual concepts and back\"". In arXiv preprint arXiv:1411.4952, 2014. [pdf]⭐⭐⭐⭐⭐[8] Chen, Xinlei, and C. Lawrence Zitnick. \""Learning a recurrent visual representation for image caption generation\"". In arXiv preprint arXiv:1411.5654, 2014. [pdf]⭐⭐⭐⭐[9] Mao, Junhua, et al. \""Deep captioning with multimodal recurrent neural networks (m-rnn)\"". In arXiv preprint arXiv:1412.6632, 2014. [pdf]⭐⭐⭐[10] Xu, Kelvin, et al. \""Show, attend and tell: Neural image caption generation with visual attention\"". In arXiv preprint arXiv:1502.03044, 2015. [pdf]⭐⭐⭐⭐⭐3.5 Machine TranslationSome milestone papers are listed in RNN / Seq-to-Seq topic.[1] Luong, Minh-Thang, et al. \""Addressing the rare word problem in neural machine translation.\"" arXiv preprint arXiv:1410.8206 (2014). [pdf] ⭐⭐⭐⭐[2] Sennrich, et al. \""Neural Machine Translation of Rare Words with Subword Units\"". In arXiv preprint arXiv:1508.07909, 2015. [pdf]⭐⭐⭐[3] Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. \""Effective approaches to attention-based neural machine translation.\"" arXiv preprint arXiv:1508.04025 (2015). [pdf] ⭐⭐⭐⭐[4] Chung, et al. \""A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation\"". In arXiv preprint arXiv:1603.06147, 2016. [pdf]⭐⭐[5] Lee, et al. \""Fully Character-Level Neural Machine Translation without Explicit Segmentation\"". In arXiv preprint arXiv:1610.03017, 2016. [pdf]⭐⭐⭐⭐⭐[6] Wu, Schuster, Chen, Le, et al. \""Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\"". In arXiv preprint arXiv:1609.08144v2, 2016. [pdf] (Milestone) ⭐⭐⭐⭐3.6 Robotics[1] Koutník, Jan, et al. \""Evolving large-scale neural networks for vision-based reinforcement learning.\"" Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. [pdf] ⭐⭐⭐[2] Levine, Sergey, et al. \""End-to-end training of deep visuomotor policies.\"" Journal of Machine Learning Research 17.39 (2016): 1-40. [pdf] ⭐⭐⭐⭐⭐[3] Pinto, Lerrel, and Abhinav Gupta. \""Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours.\"" arXiv preprint arXiv:1509.06825 (2015). [pdf] ⭐⭐⭐[4] Levine, Sergey, et al. \""Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection.\"" arXiv preprint arXiv:1603.02199 (2016). [pdf] ⭐⭐⭐⭐[5] Zhu, Yuke, et al. \""Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning.\"" arXiv preprint arXiv:1609.05143 (2016). [pdf] ⭐⭐⭐⭐[6] Yahya, Ali, et al. \""Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search.\"" arXiv preprint arXiv:1610.00673 (2016). [pdf] ⭐⭐⭐⭐[7] Gu, Shixiang, et al. \""Deep Reinforcement Learning for Robotic Manipulation.\"" arXiv preprint arXiv:1610.00633 (2016). [pdf] ⭐⭐⭐⭐[8] A Rusu, M Vecerik, Thomas Rothörl, N Heess, R Pascanu, R Hadsell.\""Sim-to-Real Robot Learning from Pixels with Progressive Nets.\"" arXiv preprint arXiv:1610.04286 (2016). [pdf] ⭐⭐⭐⭐[9] Mirowski, Piotr, et al. \""Learning to navigate in complex environments.\"" arXiv preprint arXiv:1611.03673 (2016). [pdf] ⭐⭐⭐⭐3.7 Art[1] Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). \""Inceptionism: Going Deeper into Neural Networks\"". Google Research. [html] (Deep Dream)⭐⭐⭐⭐[2] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. \""A neural algorithm of artistic style.\"" arXiv preprint arXiv:1508.06576 (2015). [pdf] (Outstanding Work, most successful method currently) ⭐⭐⭐⭐⭐[3] Zhu, Jun-Yan, et al. \""Generative Visual Manipulation on the Natural Image Manifold.\"" European Conference on Computer Vision. Springer International Publishing, 2016. [pdf] (iGAN) ⭐⭐⭐⭐[4] Champandard, Alex J. \""Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks.\"" arXiv preprint arXiv:1603.01768 (2016). [pdf] (Neural Doodle) ⭐⭐⭐⭐[5] Zhang, Richard, Phillip Isola, and Alexei A. Efros. \""Colorful Image Colorization.\"" arXiv preprint arXiv:1603.08511 (2016). [pdf] ⭐⭐⭐⭐[6] Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. \""Perceptual losses for real-time style transfer and super-resolution.\"" arXiv preprint arXiv:1603.08155 (2016). [pdf] ⭐⭐⭐⭐[7] Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. \""A learned representation for artistic style.\"" arXiv preprint arXiv:1610.07629 (2016). [pdf] ⭐⭐⭐⭐[8] Gatys, Leon and Ecker, et al.\""Controlling Perceptual Factors in Neural Style Transfer.\"" arXiv preprint arXiv:1611.07865 (2016). [pdf] (control style transfer over spatial location,colour information and across spatial scale)⭐⭐⭐⭐[9] Ulyanov, Dmitry and Lebedev, Vadim, et al. \""Texture Networks: Feed-forward Synthesis of Textures and Stylized Images.\"" arXiv preprint arXiv:1603.03417(2016). [pdf] (texture generation and style transfer) ⭐⭐⭐⭐[10] Yijun Li, Ming-Yu Liu ,Xueting Li, Ming-Hsuan Yang,Jan Kautz (NVIDIA). \""A Closed-form Solution to Photorealistic Image Stylization.\"" arXiv preprint arXiv:1802.06474(2018). [pdf] (Very fast and ultra realistic style transfer) ⭐⭐⭐⭐3.8 Object Segmentation[1] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation.” in CVPR, 2015. [pdf] ⭐⭐⭐⭐⭐[2] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. \""Semantic image segmentation with deep convolutional nets and fully connected crfs.\"" In ICLR, 2015. [pdf] ⭐⭐⭐⭐⭐[3] Pinheiro, P.O., Collobert, R., Dollar, P. \""Learning to segment object candidates.\"" In: NIPS. 2015. [pdf] ⭐⭐⭐⭐[4] Dai, J., He, K., Sun, J. \""Instance-aware semantic segmentation via multi-task network cascades.\"" in CVPR. 2016 [pdf] ⭐⭐⭐[5] Dai, J., He, K., Sun, J. \""Instance-sensitive Fully Convolutional Networks.\"" arXiv preprint arXiv:1603.08678 (2016). [pdf] ⭐⭐⭐"
78,jackfrued/Python-100-Days,https://github.com/jackfrued/Python-100-Days/blob/master/README.md,Python,"Python - 100天从新手到大师作者：骆昊说明：从项目上线到获得8w+星标以来，一直收到反馈说基础部分（前15天的内容）对新手来说是比较困难的，建议有配套视频进行讲解。最近把基础部分的内容重新制作了一个名为“Python-Core-50-Courses”的项目，用更为简单通俗的方式重写了这部分内容并附带了视频讲解，初学者可以关注下这个新项目。如果需要Python基础视频，可以在“B站”搜索《Python零基础快速上手》，这套视频是我讲课的时候录制的随堂视频，画质尚可、音质一般，但是对初学者应该会有些帮助，欢迎大家留言、评论、发弹幕。学习之后觉得有收获的小伙伴可以“一键三连”来支持UP主（千锋Python）。国内用户如果访问GitHub比较慢的话，可以关注我的知乎号Python-Jack，上面的“从零开始学Python”专栏比较适合初学者，其他的专栏也在持续创作和更新中，欢迎大家关注并点赞评论。创作不易，感谢大家的打赏支持，这些钱不会用于个人消费（例如：购买咖啡），而是通过腾讯公益、美团公益、水滴筹等平台捐赠给需要帮助的人（点击了解捐赠情况）。需要加入QQ学习群的可以扫描下面的二维码，三个群加一个即可，不要重复进群。学习群会为大家提供学习资源和问题解答，如果有Python体验课和行业公开课会提前在群里通知大家，欢迎大家加入。项目“Day80~90”部分目前仍在创作中，因为作者平时也挤不出太多时间来写文档，因此更新的速度比较缓慢，感谢大家的理解。Python应用领域和职业发展分析简单的说，Python是一个“优雅”、“明确”、“简单”的编程语言。学习曲线低，非专业人士也能上手开源系统，拥有强大的生态圈解释型语言，完美的平台可移植性动态类型语言，支持面向对象和函数式编程代码规范程度高，可读性强Python在以下领域都有用武之地。后端开发 - Python / Java / Go / PHPDevOps - Python / Shell / Ruby数据采集 - Python / C++ / Java量化交易 - Python / C++ / R数据科学 - Python / R / Julia / Matlab机器学习 - Python / R / C++ / Julia自动化测试 - Python / Shell作为一名Python开发者，根据个人的喜好和职业规划，可以选择的就业领域也非常多。Python后端开发工程师（服务器、云平台、数据接口）Python运维工程师（自动化运维、SRE、DevOps）Python数据分析师（数据分析、商业智能、数字化运营）Python数据挖掘工程师（机器学习、深度学习、算法专家）Python爬虫工程师Python测试工程师（自动化测试、测试开发）说明：目前，数据分析和数据挖掘是非常热门的方向，因为不管是互联网行业还是传统行业都已经积累了大量的数据，各行各业都需要数据分析师从已有的数据中发现更多的商业价值，从而为企业的决策提供数据的支撑，这就是所谓的数据驱动决策。给初学者的几个建议：Make English as your working language. （让英语成为你的工作语言）Practice makes perfect. （熟能生巧）All experience comes from mistakes. （所有的经验都源于你犯过的错误）Don't be one of the leeches. （不要当伸手党）Either outstanding or out. （要么出众，要么出局）Day01~15 - Python语言基础Day01 - 初识PythonPython简介 - Python的历史 / Python的优缺点 / Python的应用领域搭建编程环境 - Windows环境 / Linux环境 / MacOS环境从终端运行Python程序 - Hello, world / print函数 / 运行程序使用IDLE - 交互式环境(REPL) / 编写多行代码 / 运行程序 / 退出IDLE注释 - 注释的作用 / 单行注释 / 多行注释Day02 - 语言元素程序和进制 - 指令和程序 / 冯诺依曼机 / 二进制和十进制 / 八进制和十六进制变量和类型 - 变量的命名 / 变量的使用 / input函数 / 检查变量类型 / 类型转换数字和字符串 - 整数 / 浮点数 / 复数 / 字符串 / 字符串基本操作 / 字符编码运算符 - 数学运算符 / 赋值运算符 / 比较运算符 / 逻辑运算符 / 身份运算符 / 运算符的优先级应用案例 - 华氏温度转换成摄氏温度 / 输入圆的半径计算周长和面积 / 输入年份判断是否是闰年Day03 - 分支结构分支结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图if语句 - 简单的if / if-else结构 / if-elif-else结构 / 嵌套的if应用案例 - 用户身份验证 / 英制单位与公制单位互换 / 掷骰子决定做什么 / 百分制成绩转等级制 / 分段函数求值 / 输入三条边的长度如果能构成三角形就计算周长和面积Day04 - 循环结构循环结构的应用场景 - 条件 / 缩进 / 代码块 / 流程图while循环 - 基本结构 / break语句 / continue语句for循环 - 基本结构 / range类型 / 循环中的分支结构 / 嵌套的循环 / 提前结束程序应用案例 - 1~100求和 / 判断素数 / 猜数字游戏 / 打印九九表 / 打印三角形图案 / 猴子吃桃 / 百钱百鸡Day05 - 构造程序逻辑经典案例：水仙花数 / 百钱百鸡 / Craps赌博游戏练习题目：斐波那契数列 / 完美数 / 素数Day06 - 函数和模块的使用函数的作用 - 代码的坏味道 / 用函数封装功能模块定义函数 - def关键字 / 函数名 / 参数列表 / return语句 / 调用自定义函数调用函数 - Python内置函数 /  导入模块和函数函数的参数 - 默认参数 / 可变参数 / 关键字参数 / 命名关键字参数函数的返回值 - 没有返回值  / 返回单个值 / 返回多个值作用域问题 - 局部作用域 / 嵌套作用域 / 全局作用域 / 内置作用域 / 和作用域相关的关键字用模块管理函数 - 模块的概念 / 用自定义模块管理函数 / 命名冲突的时候会怎样（同一个模块和不同的模块）Day07 - 字符串和常用数据结构字符串的使用 - 计算长度 / 下标运算 / 切片 / 常用方法列表基本用法 - 定义列表 / 用下表访问元素 / 下标越界 / 添加元素 / 删除元素 / 修改元素 / 切片 / 循环遍历列表常用操作 - 连接 / 复制(复制元素和复制数组) / 长度 / 排序 / 倒转 / 查找生成列表 - 使用range创建数字列表 / 生成表达式 / 生成器元组的使用 - 定义元组 / 使用元组中的值 / 修改元组变量 / 元组和列表转换集合基本用法 - 集合和列表的区别 /  创建集合 / 添加元素 / 删除元素 /  清空集合常用操作 - 交集 / 并集 / 差集 / 对称差 / 子集 / 超集字典的基本用法 - 字典的特点 / 创建字典 / 添加元素 / 删除元素 / 取值 / 清空字典常用操作 - keys方法 / values方法 / items方法 / setdefault方法基础练习 - 跑马灯效果 / 列表找最大元素 / 统计考试成绩的平均分 / Fibonacci数列 / 杨辉三角综合案例 - 双色球选号 / 井字棋Day08 - 面向对象编程基础类和对象 - 什么是类 / 什么是对象 / 面向对象其他相关概念定义类 - 基本结构 / 属性和方法 / 构造器 / 析构器 / __str__方法使用对象 - 创建对象 / 给对象发消息面向对象的四大支柱 - 抽象 / 封装 / 继承 / 多态基础练习 - 定义学生类 / 定义时钟类 / 定义图形类 / 定义汽车类Day09 - 面向对象进阶属性 - 类属性 / 实例属性 / 属性访问器 / 属性修改器 / 属性删除器 / 使用__slots__类中的方法 - 实例方法 / 类方法 / 静态方法运算符重载 - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__类(的对象)之间的关系 - 关联 / 继承 / 依赖继承和多态 - 什么是继承 / 继承的语法 / 调用父类方法 / 方法重写 / 类型判定 / 多重继承 / 菱形继承(钻石继承)和C3算法综合案例 - 工资结算系统 / 图书自动折扣系统 / 自定义分数类Day10 - 图形用户界面和游戏开发使用tkinter开发GUI程序使用pygame三方库开发游戏应用“大球吃小球”游戏Day11 - 文件和异常读文件 - 读取整个文件 / 逐行读取 / 文件路径写文件 - 覆盖写入 / 追加写入 / 文本文件 / 二进制文件异常处理 - 异常机制的重要性 / try-except代码块 / else代码块 / finally代码块 / 内置异常类型 / 异常栈 / raise语句数据持久化 - CSV文件概述 / csv模块的应用 / JSON数据格式 / json模块的应用Day12 - 字符串和正则表达式字符串高级操作 - 转义字符 / 原始字符串 / 多行字符串 / in和not in运算符 / is_xxx方法 / join和split方法 / strip相关方法 / pyperclip模块 / 不变字符串和可变字符串 / StringIO的使用正则表达式入门 - 正则表达式的作用 / 元字符 / 转义 / 量词 / 分组 / 零宽断言 /贪婪匹配与惰性匹配懒惰 / 使用re模块实现正则表达式操作（匹配、搜索、替换、捕获）使用正则表达式 - re模块 / compile函数 / group和groups方法 / match方法 / search方法 / findall和finditer方法 / sub和subn方法 / split方法应用案例 - 使用正则表达式验证输入的字符串Day13 - 进程和线程进程和线程的概念 - 什么是进程 / 什么是线程 / 多线程的应用场景使用进程 - fork函数 / multiprocessing模块 / 进程池 / 进程间通信使用线程 -  threading模块 / Thread类 / RLock类 / Condition类 / 线程池Day14 - 网络编程入门和网络应用开发计算机网络基础 - 计算机网络发展史 / “TCP-IP”模型 / IP地址 / 端口 / 协议 / 其他相关概念网络应用模式 - “客户端-服务器”模式 / “浏览器-服务器”模式基于HTTP协议访问网络资源 - 网络API概述 / 访问URL / requests三方库 / 解析JSON格式数据Python网络编程 - 套接字的概念 / socket模块 /  socket函数 / 创建TCP服务器 / 创建TCP客户端 / 创建UDP服务器 / 创建UDP客户端电子邮件 - SMTP协议 / POP3协议 / IMAP协议 / smtplib模块 / poplib模块 / imaplib模块短信服务 - 调用短信服务网关Day15 - 图像和文档处理用Pillow处理图片 - 图片读写 / 图片合成 / 几何变换 / 色彩转换 / 滤镜效果读写Word文档 - 文本内容的处理 / 段落 / 页眉和页脚 / 样式的处理读写Excel文件 - xlrd / xlwt / openpyxlDay16~Day20 - Python语言进阶 常用数据结构函数的高级用法 - “一等公民” / 高阶函数 / Lambda函数 / 作用域和闭包 / 装饰器面向对象高级知识 - “三大支柱” / 类与类之间的关系 / 垃圾回收 / 魔术属性和方法 / 混入 / 元类 / 面向对象设计原则 / GoF设计模式迭代器和生成器 - 相关魔术方法 / 创建生成器的两种方式 /并发和异步编程 - 多线程 / 多进程 / 异步IO / async和awaitDay21~30 - Web前端入门用HTML标签承载页面内容用CSS渲染页面用JavaScript处理交互式行为jQuery入门和提高Vue.js入门Element的使用Bootstrap的使用Day31~35 - 玩转Linux操作系统操作系统发展史和Linux概述Linux基础命令Linux中的实用程序Linux的文件系统Vim编辑器的应用环境变量和Shell编程软件的安装和服务的配置网络访问和管理其他相关内容Day36~40 - 数据库基础和进阶关系型数据库概述MySQL的安装和使用SQL的使用DDL - 数据定义语言 - create / drop / alterDML - 数据操作语言 - insert / delete / updateDQL - 数据查询语言 - selectDCL - 数据控制语言 - grant / revokeMySQL新特性窗口函数的应用JSON数据类型相关知识数据完整性和一致性视图、函数、过程、触发器事务和锁执行计划和索引范式理论和反范式设计在Python中操作MySQLDay41~55 - 实战DjangoDay41 - Django快速上手Web应用工作机制HTTP请求和响应Django框架概述5分钟快速上手Day42 - 深入模型关系型数据库配置使用ORM完成对模型的CRUD操作管理后台的使用Django模型最佳实践模型定义参考Day43 - 静态资源和Ajax请求加载静态资源Ajax概述用Ajax实现投票功能Day44 - Cookie和Session实现用户跟踪cookie和session的关系Django框架对session的支持视图函数中的cookie读写操作Day45 - 报表和日志通过HttpResponse修改响应头使用StreamingHttpResponse处理大文件使用xlwt生成Excel报表使用reportlab生成PDF报表使用ECharts生成前端图表Day46 - 日志和调试工具栏配置日志配置Django-Debug-Toolbar优化ORM代码Day47 - 中间件的应用什么是中间件Django框架内置的中间件自定义中间件及其应用场景Day48 - 前后端分离开发入门返回JSON格式的数据用Vue.js渲染页面Day49 - RESTful架构和DRF入门Day50 - RESTful架构和DRF进阶Day51 - 使用缓存网站优化第一定律在Django项目中使用Redis提供缓存服务在视图函数中读写缓存使用装饰器实现页面缓存为数据接口提供缓存服务Day52 - 接入三方平台文件上传表单控件和图片文件预览服务器端如何处理上传的文件Day53 - 异步任务和定时任务网站优化第二定律配置消息队列服务在项目中使用Celery实现任务异步化在项目中使用Celery实现定时任务Day54 - 单元测试Day55 - 项目上线Python中的单元测试Django框架对单元测试的支持使用版本控制系统配置和使用uWSGI动静分离和Nginx配置配置HTTPS配置域名解析Day56~60 - 用FastAPI开发数据接口FastAPI五分钟上手请求和响应接入关系型数据库依赖注入中间件异步化虚拟化部署（Docker）项目实战：车辆违章查询项目Day61~65 - 爬虫开发Day61 - 网络数据采集概述网络爬虫的概念及其应用领域网络爬虫的合法性探讨开发网络爬虫的相关工具一个爬虫程序的构成Day62 - 数据抓取和解析使用requests三方库实现数据抓取页面解析的三种方式正则表达式解析XPath解析CSS选择器解析Day63 - Python中的并发编程多线程多进程异步I/ODay64 - 使用Selenium抓取网页动态内容Day65 - 爬虫框架Scrapy简介Day66~80 - 数据分析Day66 - 数据分析概述Day67 - 环境准备Day68 - NumPy的应用-1Day69 - NumPy的应用-2Day70 - Pandas的应用-1Day71 - Pandas的应用-2Day72 - Pandas的应用-3Day73 - Pandas的应用-4Day74 - Pandas的应用-5Day75 - 数据可视化-1Day76 - 数据可视化-2Day77 - 概率统计基础Day78 - 方差分析和参数估计Day79 - 相关和回归Day80 - 数据分析方法论Day81~90 - 机器学习和深度学习Day81 - 机器学习基础Day82 - k最近邻分类Day83 - 决策树Day84 - 贝叶斯分类Day85 - 支持向量机Day86 - K-均值聚类Day87 - 回归分析Day88 - 深度学习入门Day89 - PyTorch概述Day90 - PyTorch实战Day91~100 - 团队项目开发第91天：团队项目开发的问题和解决方案软件过程模型经典过程模型（瀑布模型）可行性分析（研究做还是不做），输出《可行性分析报告》。需求分析（研究做什么），输出《需求规格说明书》和产品界面原型图。概要设计和详细设计，输出概念模型图（ER图）、物理模型图、类图、时序图等。编码 / 测试。上线 / 维护。瀑布模型最大的缺点是无法拥抱需求变化，整套流程结束后才能看到产品，团队士气低落。敏捷开发（Scrum）- 产品所有者、Scrum Master、研发人员 - Sprint产品的Backlog（用户故事、产品原型）。计划会议（评估和预算）。日常开发（站立会议、番茄工作法、结对编程、测试先行、代码重构……）。修复bug（问题描述、重现步骤、测试人员、被指派人）。发布版本。评审会议（Showcase，用户需要参与）。回顾会议（对当前迭代周期做一个总结）。补充：敏捷软件开发宣言个体和互动 高于 流程和工具工作的软件 高于 详尽的文档客户合作 高于 合同谈判响应变化 高于 遵循计划角色：产品所有者（决定做什么，能对需求拍板的人）、团队负责人（解决各种问题，专注如何更好的工作，屏蔽外部对开发团队的影响）、开发团队（项目执行人员，具体指开发人员和测试人员）。准备工作：商业案例和资金、合同、憧憬、初始产品需求、初始发布计划、入股、组建团队。敏捷团队通常人数为8-10人。工作量估算：将开发任务量化，包括原型、Logo设计、UI设计、前端开发等，尽量把每个工作分解到最小任务量，最小任务量标准为工作时间不能超过两天，然后估算总体项目时间。把每个任务都贴在看板上面，看板上分三部分：to do（待完成）、in progress（进行中）和done（已完成）。项目团队组建团队的构成和角色说明：谢谢付祥英女士帮助我绘制了下面这张精美的公司组织架构图。编程规范和代码审查（flake8、pylint）Python中的一些“惯例”（请参考《Python惯例-如何编写Pythonic的代码》）影响代码可读性的原因：代码注释太少或者没有注释代码破坏了语言的最佳实践反模式编程（意大利面代码、复制-黏贴编程、自负编程、……）团队开发工具介绍版本控制：Git、Mercury缺陷管理：Gitlab、Redmine敏捷闭环工具：禅道、JIRA持续集成：Jenkins、Travis-CI请参考《团队项目开发的问题和解决方案》。项目选题和理解业务选题范围设定CMS（用户端）：新闻聚合网站、问答/分享社区、影评/书评网站等。MIS（用户端+管理端）：KMS、KPI考核系统、HRS、CRM系统、供应链系统、仓储管理系统等。App后台（管理端+数据接口）：二手交易类、报刊杂志类、小众电商类、新闻资讯类、旅游类、社交类、阅读类等。其他类型：自身行业背景和工作经验、业务容易理解和把控。需求理解、模块划分和任务分配需求理解：头脑风暴和竞品分析。模块划分：画思维导图（XMind），每个模块是一个枝节点，每个具体的功能是一个叶节点（用动词表述），需要确保每个叶节点无法再生出新节点，确定每个叶子节点的重要性、优先级和工作量。任务分配：由项目负责人根据上面的指标为每个团队成员分配任务。制定项目进度表（每日更新）模块功能人员状态完成工时计划开始实际开始计划结束实际结束备注评论添加评论王大锤正在进行50%42018/8/72018/8/7删除评论王大锤等待0%22018/8/72018/8/7查看评论白元芳正在进行20%42018/8/72018/8/7需要进行代码审查评论投票白元芳等待0%42018/8/82018/8/8OOAD和数据库设计UML（统一建模语言）的类图通过模型创建表（正向工程），例如在Django项目中可以通过下面的命令创建二维表。python manage.py makemigrations apppython manage.py migrate使用PowerDesigner绘制物理模型图。通过数据表创建模型（反向工程），例如在Django项目中可以通过下面的命令生成模型。python manage.py inspectdb > app/models.py第92天：Docker容器详解Docker简介安装Docker使用Docker创建容器（Nginx、MySQL、Redis、Gitlab、Jenkins）构建Docker镜像（Dockerfile的编写和相关指令）容器编排（Docker-compose）集群管理（Kubernetes）第93天：MySQL性能优化第94天：网络API接口设计第95天：[使用Django开发商业项目](./Day91-100/95.使用Django开发商业项\t目.md)项目开发中的公共问题数据库的配置（多数据库、主从复制、数据库路由）缓存的配置（分区缓存、键设置、超时设置、主从复制、故障恢复（哨兵））日志的配置分析和调试（Django-Debug-ToolBar）好用的Python模块（日期计算、图像处理、数据加密、三方API）REST API设计RESTful架构理解RESTful架构RESTful API设计指南RESTful API最佳实践API接口文档的撰写RAP2YAPIdjango-REST-framework的应用项目中的重点难点剖析使用缓存缓解数据库压力 - Redis使用消息队列做解耦合和削峰 - Celery + RabbitMQ第96天：软件测试和自动化测试单元测试测试的种类编写单元测试（unittest、pytest、nose2、tox、ddt、……）测试覆盖率（coverage）Django项目部署部署前的准备工作关键设置（SECRET_KEY / DEBUG / ALLOWED_HOSTS / 缓存 / 数据库）HTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECURE日志相关配置Linux常用命令回顾Linux常用服务的安装和配置uWSGI/Gunicorn和Nginx的使用Gunicorn和uWSGI的比较对于不需要大量定制化的简单应用程序，Gunicorn是一个不错的选择，uWSGI的学习曲线比Gunicorn要陡峭得多，Gunicorn的默认参数就已经能够适应大多数应用程序。uWSGI支持异构部署。由于Nginx本身支持uWSGI，在线上一般都将Nginx和uWSGI捆绑在一起部署，而且uWSGI属于功能齐全且高度定制的WSGI中间件。在性能上，Gunicorn和uWSGI其实表现相当。使用虚拟化技术（Docker）部署测试环境和生产环境性能测试AB的使用SQLslap的使用sysbench的使用自动化测试使用Shell和Python进行自动化测试使用Selenium实现自动化测试Selenium IDESelenium WebDriverSelenium Remote Control测试工具Robot Framework介绍第97天：电商网站技术要点剖析第98天：项目部署上线和性能调优MySQL数据库调优Web服务器性能优化Nginx负载均衡配置Keepalived实现高可用代码性能调优多线程异步化静态资源访问优化云存储CDN第99天：面试中的公共问题第100天：Python面试题实录"
79,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
80,Significant-Gravitas/Auto-GPT,https://github.com/Significant-Gravitas/Auto-GPT/blob/master/README.md,Python,"Auto-GPT: An Autonomous GPT-4 Experiment💡 Get help - Q&A or Discord 💬🔴 USE stable not master 🔴Download the latest stable release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.The master branch is under heavy development and may often be in a broken state.Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \""thoughts\"", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI. Demo April 16th 2023               AutoGPTDemo_Subs_WithoutFinalScreen.mp4          Demo made by Blake Werlinger🚀 Features🌐 Internet access for searches and information gathering💾 Long-term and short-term memory management🧠 GPT-4 instances for text generation🔗 Access to popular websites and platforms🗃️ File storage and summarization with GPT-3.5🔌 Extensibility with PluginsQuickstartCheck out the wikiGet an OpenAI API KeyDownload the latest releaseFollow the installation instructionsConfigure any additional features you want, or install some pluginsRun the appPlease see the documentation for full setup instructions and configuration options.📖 Documentation⚙️ Setup💻 Usage🔌 PluginsConfiguration🔍 Web Search🧠 Memory🗣️ Voice (TTS)🖼️ Image Generation 💖 Help Fund Auto-GPT's Development 💖If you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help to push the boundaries of fully autonomous AI!Your support is greatly appreciated. Development of this free, open-source project is made possible by all the contributors and sponsors. If you'd like to sponsor this project and have your avatar or company logo appear below click here.                                                                                                                                                                                                                                                                                                                                          ⚠️ LimitationsThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:Not a polished application or product, just an experimentMay not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!Quite expensive to run, so set and monitor your API key limits with OpenAI!🛡 DisclaimerThis project, Auto-GPT, is an experimental application and is provided \""as-is\"" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.The developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.Please note that the use of the GPT-4 language model can be expensive due to its token usage. By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.As an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.By using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.🐦 Connect with Us on TwitterStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.Developer: Follow @siggravitas for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!        "
81,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        简体中文 |        繁體中文 |        한국어 |        Español |        日本語 |        हिन्दी        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    🤗 Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:📝 Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.🖼️ Images, for tasks like image classification, object detection, and segmentation.🗣️ Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.🤗 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install 🤗 Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, 🤗 Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.🤗 Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by 🤗 Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: 🤗 Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from École polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Suárez*, Yoann Dupont, Laurent Romary, Éric Villemonte de la Clergerie, Djamé Seddah and Benoît Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of Göttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo Lüddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Hervé Jégou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp Krähenbühl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Hervé Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by René Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre Défossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, Loïc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Benoît Crabbé, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey Öhman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo García del Río, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Hervé Jégou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by Jörg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre Défossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noah’s Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.Nyströmformer (from the University of Wisconsin - Madison) released with the paper Nyströmformer: A Nyström-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier Hénaff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, João Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, Łukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Dollár.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault Févry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of Würzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, Paweł Krzysztof Nowak, Thomas Müller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Lučić, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper ​XLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the 🤗 Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by 🤗 TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by 🤗 Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the 🤗 Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
82,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answers⚠️ DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]🙏 PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!🎉 AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.❓ Need help?Open new issue🔥 Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accounting❗needs updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustrator❗needs updating  7674Adobe-InDesign❗needs updating  4240Adobe-Lightroom❗needs updating  2020Adobe-Photoshop❗needs updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effects❗needs updating  2413Agile Methodologies❗needs updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCAD❗needs updating  7775@djayorAutodesk Fusion 360❗needs updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambda❗needs updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++❗needs updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurity❗needs updating10196Django7171@PROCW.NET Framework6359@declarckEclipse❗needs updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSON❗needs updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excel❗needs updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Project❗needs updating4443Microsoft Word❗needs updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooks❗needs updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revit❗needs updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePoint❗needs updating5338Sketchup22SOLIDWORKS❗needs updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnity❗needs updating4746@uno-sebastianVisual Basic for Applications (VBA)❗needs updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors ✨Thanks goes to these wonderful people (emoji key):            Evgenii💻 🖋      Sergei Stadnik💻 🔍 🤔 📖      Santhosh💻      Jacob Dsa💻 🖋      Aaron Meese💻 🖋      arqarq💻 🖋      Amit Yadav💻 🖋              Javokhir Nazarov💻 🖋      saurav kumar🖋      Chetan🖋      Amir Hossein Shekari🎨 🖋 💻      SergDaut🎨      Nilotpal Pramanik🎨 💻 🖋 💼 📖 🔣 💡      Abhishek Kumar🎨              Monu Gupta🎨      KARTIKEYA GUPTA💻 🖋      kenkyusha💻 🖋      juandavidtowers💻 🖋      cyber-netics💻 🖋      jtrisw💻 🖋      Renato Regalado💻 🖋              Matthew💻 🖋      Jan S.💻 🖋      Manoli💻 🖋      Faraz tanveer💻 🖋      mohnishkarri💻 🖋 🎨      andyzhu💻 🖋      Vishal Kushwah💻 🖋              Yurii Yakymenko💻 🖋      Swetabh Suman💻 🖋      AJAY DANDGE💻 🖋      Mehmet Yesin🎨      Lok Chun Wai🎨      Adria de Juan🎨      GL-Man🎨              Jheel Patel🎨      Sameer Waskar🎨      Alexander Andrews🎨      Alexander Maxwell🎨      Slava🎨      Mayur Khatri🎨      Mascantosh💻 🖋 📢 🤔              Kivanc Enes🎨      Ritika Das🎨      Zer07793🎨      Andrew Cheung🎨      Sadha🎨      tainenko🎨 💻      github-star-coder🎨              Danilo Oliveira🎨      lordeko🎨      Shubham Kumar🎨 💻      testtree🎨      Cheryl Murphy🎨 💻      Bipin Thomas🎨      Abdulrahman Hisham🎨              Dakshitha Dissanayaka🎨      BADR KACIMI🎨      Alex Wang🎨      Maxim🎨      GordonGrant🎨 💻      Ephrem Demelash🎨      JonOrcutt🎨              topdev10🎨      cookwellwebsite🎨      xren935🎨      Nemo Frenkel🎨      MD SAIF ALAM🎨      Boris López Araya🎨      Larry Chiem🎨              Muhammad Bilal Ilyas🎨      AliMilani🎨 💻      Suraj Sahani🎨      FlyingSquirrel🎨      Erick Tijero🎨      Jaskaran Kukreja🎨      MichaelL🎨              MagicLegend🎨      Dereck Bearsong🎨      Pappu Kumar Pashi🎨      Venkata Kishore Tavva🎨      Rafat Touqir Rafsun🎨      Snehesh Dutta🎨      Timo Körner🎨 💻              alexxxan🎨      GGJason🎨      LeeAnna Ewing🎨 🤔      kamal Jyotwal🎨      Bob-Johns🎨 💻 🖋      yunussalmanlyit🎨 💻      chilcot🎨 💻              Jacky Li💻 🖋 🎨      Sarthak Trivedi🎨      Ayush Aggarwal🎨 💻      Nic Ballarini🎨      Luigi Zambetti🎨 💻      govindhaswin🎨      Addy Roy💻 🎨              Akshat Tamrakar🎨 💻      Sai Bhargava Ramu🎨      Gurkan💻      Spencer Hayes-Laverdiere💻      Aniket Soni💻      tanmay5792💻      Dina Taklit💻 🎨 🖋              Dushyant Singh💻      Ravi Prakash Singh💻      Nihal Joshi💻      Guy Klages💻      Arvind🎨 💻      mujeeb91💻      joserca🎨 💻              Prateek Agrawal💻      Teoh Tze Chuin(サラ)💻 🎨      Jayant Jain💻      Ayush Sahu💻      Hridya Krishna R💻 🎨      Rahul Bali💻 🎨      S.ZHeng🎨 💻 💼              Shriya Madan🎨 💻      mahalrupi🎨      Lucas Lermagne🎨      Jeff Deutsch🎨 💻      Betoxx1🎨      Wingman4l7🎨      Martin Espericueta🎨              Mh-Tahir🎨      Zdravko Šplajt🎨 💻      Ms3105🎨 💻 🖋      Ambika Sidhesware💻      mundoguero💻      Darkus24🖋      Sou-786🖋 🎨              Banurekha🖋      ShiraStarL🎨      Ilya Komarov🎨      DemigodMs🖋 📖      Mekha Hridya🎨 🔍      Andrey Safonov🎨 🔍      Tommaso🎨 💻              Jessica Salbert💻 🎨      JAYANTH DOLAI💻 🎨      silverstroom💻 🎨 💼      Furkan Sayım💻 🎨      Sukumar Chandrasekaran🎨      Yejin Park🎨 💻      Ali Nooshabadi🎨 💻              imitavor🎨 💻      Salih Kilicli🎨 💻      Marcelo Meneses🎨 💻      Anton Krekotun🎨 🚧 🖋 💻 📖 💼      Arnav Sarma💻 💡 🎨      meghatiku💻 🎨      Anshu Trivedi🎨              Taylor Dorsett💻 🖋 🎨      Havit Rovik💻      pushpapune💻 🎨      Ramtin Radfar🎨 🤔 💼 💵 💻 🖋 💬      Abdulmajeed Isa💻 🎨      vikassaxena02🎨      RobTables🎨 💻 💼              Daniel🎨 💻 💼 🔍      Zahid Ali💻 🎨      Chad Chai💻 🎨      Marco Biedermann💻 🎨 💼 🤔      Srinidhi Murthy🎨      Miao Cai💻 🎨      Dionicio Diaz🎨 💻              Mir Monoarul Alam🎨      Shawn Ohn💻 🎨      Amanbolat Balabekov🎨 💻      black-mamba-code💻      Jian-forks🎨 💻      shivani patel🎨      Akash Chowrasia🎨              yairg98🎨      Jay Gajjar🎨      coolerbooler💻      Md Zinnatul Islam Morol🎨      shresthashok550🎨 📖      Alan Pallath📖      Adrian Wong💻              vsDizzy💻 🎨      Frex Cuadillera🎨 💻      ashish570💻 🎨      ruchpeanuts💻 🎨      Artmasque🎨 💻      Amirhossein Mojiri Foroushani🎨      for💻 🎨              Luke🎨 💻      Hector Espinoza🎨      Adrián Buenfil🎨 💻      Amit Kumar🎨      schoppfe🎨 💻      Sofiyal C🎨 💻      spitlisk💻 🎨              PRAVIN SHARMA🎨      NIDZAAA1🎨 💻      John Mai🎨 💻      kimsoyeong🎨      Dona Ghosh💻      Ryan Hill🎨 💻      j42z🎨 💻              Ashish Sangale🎨 💻      Derek Yang🎨 💻      mohsinmsm🎨 💻      Gokulkrish2302💻      Bhaavishek💻 🎨      Louis Liao🎨      sengc92🎨 💻              Alex Marvin🎨      Balkrishna Bhatt🎨 💻      Evaldas Lavrinovičius🎨 💻      Adam Erchegyi🎨 💻      Truman Hung🎨 💻      rzamora11🎨      gaurav0224🎨              Lee GyeongJun🎨      Mirek🎨 💻      surajm245🎨      ArisLaode🎨 💻      RaviDhoriya🎨 💻      sarai-84🎨 💻      Vishnu🎨 💻              Muhammad Minhaj💻      Chandrika Deb🎨 💻      Gitgit101-bit💻 🎨      Hedi Sellami💻 🎨      saurabhvaish93💻 🎨      Nikola Begovic💻 🎨      Wang💻 🎨              Manuel Eusebio de Paz Carmona🎨      Basim Al-Jawahery🎨 💻      RAJA AHMED🎨 💻      Abhik Lodh💻      Md. Pial Ahamed💻 🎨      Hassan Shahzad💻 🎨      Christian Sosa Gago💻              Hasnain Rasheed💻 🎨      T-Radford💻      dahiyashish💻 🎨      RahulSharma468💻 🎨      Jumpod Plekhongthu💻 🎨      Thomas Young-Audet💻 🎨      VinayagamBabu💻 🎨              Deniz Koç💻 🎨      Azhar Khan💻 🎨 🖋 📖 🔣 🚧      Jacob Short💻 🎨      Uchimura85💻 🎨      Leo Nugraha💻 🎨 📖      Mujtaba Mehdi📖 🖋      Jim-ds💻 🎨              Sreehari K💻 🎨      Florian Martinez💻 🎨      Aaron💻 🎨      apoage🎨      Ignacio Guillermo Martinez 💻 🎨      AirlineDog🎨 💻      Mekel🎨 💻              hmosharrof🎨 💻      Ben Emamian💻 🎨      babeshark💻 🎨      Leonardo Jaques💻 🎨      Stefanos Apkarian💻 🎨      Ayhan Albayrak💻 🎨      KidusMT💻 🎨              hectormarroquin20💻 🎨      Edelweiss35💻 🎨      MihaiD💻 🎨      AnveshReddyAnnem💻 🎨      Hyunjae Park💻 🎨      Rajiv Albino💻 🎨      Atishay💻              Yusuf Naheem🎨      Windu🎨 💻      Superv1sor💻 🎨      Karine (:🎨 💻      Eduard Pech🎨 💻      jjeshwani🎨 💻      Steve🎨 💻              Aleigh Ohslund💻      Abhinav Suman🎨 💻      Hamza Ehtesham Farooq🎨 💻      IamNotPeterPan💻 💵 🎨      Cetger🎨      pkonopacki🎨      Yang Yang🎨 💻              Muhammad Shoaib Sarwar💻      Murilo Henrique💻 🎨      emilianoalvz🎨 💻      Sumana Saha🎨 💻      Yurii17K🎨 💻      Rupesh Bhandari🎨 💻      salmos3718💻              John Baker🎨 💻      SanjaySathiraju🎨 💻      Donat Kabashi🎨      Arul Prasad J🎨 💻      Qi Chen🎨 💻      Maksym Dmyterko🎨 💻      ilovepullrequests💻              Samira Maleki🎨 💻      NIKITA MAHOVIYA💻      jesuisdev.Net🎨 💻      Ashraf Nazar🎨      Naveed Ahmad🎨      Ajmain Naqib🎨 💻      Avinash Tingre💻 🎨              nicktids🎨      Keith Dinh💻 🎨      André Ferreira💻 🎨      eliottkespi💻 🎨      praveenpno💻 🎨      vitowidigdo💻 🎨      Devesh Pratap Singh💻 🎨              Dario Rodriguez💻 🎨      charmander_didi💻 🎨      PHBasin💻 🎨      Ritvik Singh Chauhan💻 🎨      Riya P Mathew💻 🎨      Stephanie Cherubin💻 🎨      BenitesGui💻 🎨              FarikBear💻 🎨      Dmytro Havrilov💻 🎨      Parvesh Monu💻 🎨      Dipen Panchasara💻 🎨      gudata🎨 💻      gawadeditor💻 🎨      Kirill Taletski🎨 💻              Saajan🎨 💻      Kushagra S🎨 💻      Oanh Le🎨 💻      Frane Medvidović🎨 💻      Yorman🎨 💻      Bill Chan🎨 💻      Pratik Lomte🎨 💻              LOC LAM🎨 💻      TUSAR RANJAN MAHAPATRA💻      BhargavKanjarla💻      Karel De Smet💻 🎨      sidisan🎨      ygnzayarphyo🎨 💻      svansteelandt💻              Kebechet🎨      Daniel Selvan D🎨 💻      Mahdi Razavi🎨 💻      Niklas Tiede💻 🎨      narutubaderddin💻 🎨      dylandhood💻      Dheeraj Gupta💻              Pieter Claerhout💻 🎨      Shivam Agnihotri💻      RanjithReddy-Narra💻      Nikita Wadhwani🎨 💻      rsholokh💻 🎨      Ayaan Hossain💻 🎨      Rajesh Swarna💻              Deniz Etkar🎨 💻      pro335💻 🎨      Jakub Radzik💻 🎨      Hamza Khanzada💻      ARNON🎨      Vikram Singh💻      Shoxruxbek💻 🎨              Amit Khatri💻 🎨      Wali Ullah🎨 💻      Amit11794💻 🎨      metis-macys-66898💻 🎨      Faisal Maqbool🎨 💻      Kumar Neeraj💻 🎨      Maurizio Marini🎨 💻              Saket Kothari🎨 💻      Szymon Zborowski🎨 💻      iks3000🎨 💻      Ehsan Seyedi🎨 💻      vanekbr🎨 💻      Princy_M🎨 💻      Shijie Zhou🎨 💻              lakshyamcs16🎨 💻      Filippo Facco🎨 💻      mendel5🎨 💻      Patryk🎨 💻      VishwaSangani🎨 💻      Alvin Zhao🎨 💻      Lazar Gugleta🎨 💻              vmicho🎨 💻      Sikandar Ali🎨 💻      Raja Babu🎨 💻      faizajahanzeb💻      Guil_AiT🎨 💻      Kushal Das🎨 💻      Luis Bonilla🎨 💻              jovan1013🎨 💻      Damian🎨 💻      Yash Gupta💻      lolcatnip🎨 💻      Ikko Ashimine🎨 💻      Farukh🎨 💻      Moksedul💻 🎨              Navneet Kumar🎨 💻      Saqib AlMalik💻      fahimrahman🎨 💻      vaibhav patil🎨 💻      Rahul Madan🎨 💻      kartik Kaklotar🎨 💻      ASAHI OCEAN🎨 💻              Daniel Jungbluth🎨 💻      Rajdeep Singh Borana🎨 💻      ankitha19💻      Linh Tran💻      islamarr💻 🎨      Mohamed Sabith🎨 💻      Miguel Angel Cruz Acosta🎨 💻              Adebayo Ilerioluwa 🎨      Markus🎨 💻      dkonyayev🎨 💻      Kevin A Mathew🎨 💻      David Melo🎨 🔣      DFW1N🎨 💻      Sohaib Ayub🎨 💻              Navvy🎨 💻      bloodiator2🎨 💻      Hanji🎨 💻      arthur74🎨 💻      Sri Subathra Devi B🎨 💻      Akif Aydogmus🎨 💻      Umer Javaid🎨 💻              Norio Umata🎨 💻      Gazi Hasan Rahman🎨 💻      Keith Nguyen🎨 💻      Megalomaniac🎨 💻      ShankS3🎨 💻      Farhad Alishov🎨 💻      Ronak J Vanpariya🎨 💻              azrael0learza🎨 💻      Pavel Rahman🎨 💻      chuabern🎨 💻      Rahul Tirkey🎨 💻      Ruslan Bes🎨 💻 💡 🚧 🖋 🔣 🚇      Bohdan🎨 💻      Juzdzewski🎨 💻              Grigor Minasyan🎨 💻      alvintwc🎨 💻      Anand Natarajan🎨 💻      Kashan Ali🎨 💻      Thomas Meshail🎨 💻      Son Pham🎨      Michael French💡              Yash Mishra📖      Miguel Rodriguez🎨 💻      Philipp Bachmann🎨 💻      sunny🎨 💻      Siddharth Chatterjee🎨 💻      Michael Naghavipour🎨 💻      Sahil Garg🎨 💻              MicroLion🎨 💻      wctwc🎨 💻      Rohan Sharma🔣      AshishBodla🎨 💻      Taras Pysarskyi🎨 💻      Luqman Bello O.🎨 💻      DyingDown🎨 💻              Diego Chapedelaine🎨 💻      Richlee🎨 💻      Asif Habib🎨 💻      Mazharul Hossain🎨 💻      toni🎨 💻      Pragyanshu Rai🎨 💻      Matthew Eller🎨 💻              AbhiBiju🎨 💻      Roman Zhornytskiy🎨 💻      Lucas Camino🎨 💻      João Vitor Casarin🎨 💻      Evgeniy Shay🎨 💻      Ehsan Barkhordar🎨 💻      Gabriel🎨 💻              Shibu Mohapatra🎨 💻      Pavel Kirkovsky🎨 💻      Tahir Gul🎨 💻      imDevSalman🎨 💻      Jordan Donaldson🎨 💻      js-venus🎨 💻      Faisal Shaikh🎨 💻              ashishbpatil🎨 💻      Tri Le🎨 💻      tomtreffke🎨 💻      Salah Eddine Lalami🎨 💻      Mattias Xu🎨 💻      Manas Gupta🎨 💻      wolfsong62🎨 💻              Mehdi Mirzaei🎨 💻      Van Ba Khanh🎨 💻      Sel Embee🎨 💻      Suvradip Paul🎨 💻      Sharique🎨      Seabass🎨 💻      Penny Liu🎨 💻              jatinder bhola🎨 💻      misterqbit🎨 💻      Daniel-VS9🎨 💻      Shruthi🎨 💻      beefydog🎨 💻      Suraj Kumar🎨 💻      hrishikeshps🎨 💻              Sudarshan🎨 💻      Divyansh💻 🎨      Zyaire🎨 💻      Omar Belkady🎨 💻      alexiismua🎨 💻      Eduarda Alves🎨      pycoach🎨 💻              Ruhul🎨 💻      pmoustopoulos🎨 💻      Lee Hui Ting💻 🎨      bodi1981🎨 💻      Devaraat Joshi🎨 💻      Johnny🎨 💻      rogue-coder🎨 💻              viiktr🎨      Lalit Mohan💻      João Sousa💻      言葉之靈💻 🎨      RJLABS💻      brittney0522🎨 💻      sham🎨 💻              Glenn Goossens💻 🎨      Cyber Hawk🎨 💻 🖋 💼      Ankit Yadav🎨 💻      verbality💻      Mohammed Siddiqui🎨 💻      AdamKaczor6250🎨 💻      Ramón Martinez Nieto🎨 💻              Grzegorz Dziubak🎨 💻      Ayoub BERDEDDOUCH🎨 💻      nikola-fadv🎨 💻      Akarsh Agrawal🎨 💻      Mitra Mirshafiee🎨 💻      Parker Stephens🎨 💻      alrenee99💻              Karthick Vankayala💻      Iryna 🎨 💻      palanugrah💻      Gwinbleind🎨 💻      Randy Bobandy🎨 💻      Bek Rozikoff💻      davnguye🎨 💻              Neel Patel💻      ehudbehar🎨 💻      nicholas-cod3r🎨 💻      michaelfranki🎨      Esther White🎨 💻      prathmeshpb🎨 💻      Victor Lin🎨 💻              Christine C. Yin🎨 💻      GitLearner-begin🎨 💻      Mesrop Andreasyan🎨 💻      Nathan Garcia🎨      commonsw04🎨 💻      Md. Rashad Tanjim🎨 💻      Ali Malek💻              PAODLT🎨 💻      Nikhil Bobade🎨 💻      hyuckjin21💻      Itasha Modi🎨 💻      Nikitha Reddy🎨 💻      Mahshooq Zubair🎨 💻      Subham Das💻              Onkar Birajdar🎨 💻      Nick Titomichelakis🎨 💻      Christian Leo-Pernold🎨      Matthew Marquise🎨 💻      baronfac🎨 💻      Abhishek Tilwar🎨 💻      DavidsDvm🎨 💻              Parth Parikh🎨 💻      Hector Castro🎨 💻      Rikky Arisendi🎨 💻      Ali HamXa🎨 💻      Frank.wu🎨 💻      Jatin Kumar🎨 💻 📖      masterHAWK99🎨 💻              Pushp Jain🎨 💻      Ashutosh Rout🎨 💻      Atharva Deshpande🎨 💻      Teodor Ciripescu🎨 💻      Anmol Bansal🎨 💻      Nikhil Kumar Macharla🎨 💻      Dexter🎨 💻              Aaron🎨 💻      Yogita Jaswani🎨 💻 📖 🖋      StoryDev🎨 💻      Mesut Doğansoy🎨 💻      Paras Dhawan🎨 💻      Emanuel Zhupa🎨 💻      Aaradhyaa717🎨 💻              jaacko-torus🎨 💻      mBlack💻      kalrayashwin📖 🖋 🎨 💻      Seraph💻 🎨      ZhiHong Chua🎨 💻      Amsal Khan🎨 💻 📖 🖋      Raghav Rastogi🎨 💻              Tzila📖      Shahriar Nasim Nafi📖      AG🎨 💻      Mojtaba Kamyabi🎨 💻      Ahmad Abdulrahman🎨 💻      Eclipse🎨 💻      Anshu Pal🎨 💻              Denis🎨 💻      mehmet sayin📖      WebDEV🎨 💻      Sam Komesarook🎨 💻      Kiran Ghimire🎨 💻      Joshua Davis🎨 💻      Muhammad-Huzaifa-Siddiqui💻              tobeornottobeadev🎨 💻      VAIBHAV SINGHAL🎨 💻      Keiran Pillman🎨 💻      Max Donchenko🎨 💻      sgonsal🎨 💻      diksha137🎨 💻      Vignesh🎨 💻              Gabriel França🎨 💻      Joseph🎨 💻      Bruno Rafael🎨 💻      vcamarre🎨 💻      thibault ketterer🎨 💻 🚧      VictorGonzalezToledo🎨 💻      1911510996🎨 💻              invidu🎨 💻      Nurul Furqon🎨 💻      David Asbill🎨 💻      Niko Birbilis🎨 💻      Mugundan Kottursuresh🎨      agrsachin81🎨 💻      Othmane El Alami🎨 💻              Syed Atif Ali🎨 💻      lakhanjindam🎨 💻      youssef hamdane🎨 💻      starfaerie🎨 💻      rodrigo0107🎨 💻      Michał Gralak🎨 💻      Jewel Mahmud🎨 💻              cwilson830🎨 💻      buun1030🎨 💻      Reda-ELOUAHABI🎨 💻      saad-aksa🎨 💻      Emdadul Haque🎨 💻      PROCW🎨 💻      cccppp1🎨 💻              Joanna Baile🎨 💻      Ahmed Saber🎨 💻      Masoud Keshavarz🎨 💻      mortazavian🎨 💻      Aniket Pandey🎨 💻      Vijay Nirmal🎨 💻      Daniel Carvallo💻              menaechmi🎨 💻      azenyx🎨 💻      Ahmet Özrahat🎨 💻      Abdulrahman Abouzaid🎨 💻      jmgnorbec🎨 💻      palinko91🎨 💻      Laisson R. Silveira🎨 💻              BHARGAVPATEL1244🎨 💻      Candide U🎨 💻      Sitansh Rajput🎨 💻      Houda Mouttalib🎨 💻      MumuTW🎨 💻      Suave Bajaj🎨 💻      Mehdi Parsaei🎨 💻              Dinko Osrecki🎨 💻      Dhia Djobbi🎨 💻      Mahmoud Galal🎨 💻      Anh Minh🎨 💻      Suvesh K🎨 💻      Petar Todorov🎨 💻      Alexander Nguyen🎨 💻              Morteza Jalalvand🎨 💻      Claudson Martins🎨 💻      Matt Jacobson🎨 💻      Rafael Belokurows🎨 💻       Thomas Gamauf🎨 💻      Rishabh Mahajan🎨 💻      rakeshpdgupta23🎨 💻              Shashidharknaik🎨 💻      taleleuma🎨 💻      Florian Bühler🎨 💻      Raihan Bin Wahid🎨 💻      MOHAMMED NASSER🎨 💻      federico🎨 💻      Andre Violante🎨 💻              tcunningham98🎨 💻      Jan Grießer🎨 💻      Serkan Alc🎨 💻 🖋      Jez McKean🎨 💻      meisam alifallahi🎨 💻      Mehul Thakkar🎨 💻      Saksham Soni🎨 💻              Pedro Peregrina🎨 💻      Mintu Choudhary🎨 💻      lucianmoldovanu🎨 💻      John C. Scott🎨 💻      Mia D.🎨 💻      EwenBernard🎨 💻      M. Reza Nasirloo🎨 💻              Jay Agrawal🎨 💻      DeShay🎨 💻      Jay206-Programmer🎨 💻      Elender🎨 💻 🖋      Bobby Byrne🎨 💻      Pirci🎨 💻      Hasanuzzaman🎨 💻              Josh Kautz🎨 💻      Brofar🎨 💻      Mina Karam🎨 💻      Duncan O N🎨 💻      Sean Tumulak-Nguyen🎨 💻      Artur Trześniewski🎨 💻      JJaammeessM🎨 💻              shubham agarwal🎨 💻      Michele Righi🎨 💻      Panagiotis Kontos🎨 💻      sumitbathla🎨 💻      Deepak Mathur🎨 💻      Juho Nykänen🎨 💻      Santiago González Siordia🎨 💻              SRIJITA MALLICK🎨 💻      Samriddhi B🎨 💻      Nitzan Papini🎨 💻      Mario Sanz🎨 💻      Crab^4🎨 💻      Pablo🎨 💻      Gordon Pham-Nguyen🎨 💻              Kristoffer🎨 💻      chrisblach🎨 💻      Gábor🎨 💻      Lina🎨 💻      Harrison Watts🎨 💻      Mario Petričko🎨 💻      Ben8120🎨 💻              Giovanna🎨 💻      Minal Ahuja🎨 💻      mossfarmer🎨 💻      ThaC0derDre🎨 💻      itware🎨 💻      Michael Walker🎨 💻      Tom Jacob Chirayil🎨 💻              Sachin Kumar🎨 💻      adi-ray🎨 💻      Dr-Blank-alt🎨 💻      Bogdan Cazacu🎨 💻      Gilson Urbano🎨 💻      Nina🎨 💻      Anthony🎨 💻              manushimjani🎨 💻      Michael Reyes🎨 💻      Rachel Kennelly🎨 💻      Aakash Garg🎨 💻      Daniel Livingston🎨 💻      alexrojco🎨 💻      Minh Nguyen🎨 💻              Mahesh Dattatraya Babar🎨 💻      Jin Zihang🎨 💻      Bikramjit Ganguly🎨 💻      QuestionableGuise🎨 💻      liq19ch🎨 💻      Bruno Rocha🎨 💻      Anand Dyavanapalli💻 🖋              crucian-afk🎨 💻      0xgainz🎨 💻      weirdfsh🎨 💻      Valan Baptist Mathuranayagam🎨 💻      Paul Kaefer🎨 💻      Yu-Hsiang Wang🎨 💻      Javad Adib🎨 💻              davidliu0930🎨 💻      Achilleas John Yfantis🎨 💻      Omkar Shivadekar🎨 💻 🖋 🐛      ToanTran🎨 💻      Gautam Naik🎨 💻      Marc🎨 💻      twix20🎨 💻              Kristian S.🎨 💻      Aleksey Khoroshilov🎨 💻      arjunsrsr🎨 💻      Ali Haider🎨 💻      Trisha Dring🎨 💻      Andre Marzulo🎨 💻      Krishna Modi🎨 💻              Rosemary Li🎨 💻      Alex Weller🎨 💻      Tam Nguyen🎨 💻      aquintelaoliveira🎨 💻      Norbert Brett🎨 💻      rocsogd🎨 💻      0nyr🎨 💻              rethkevin🎨 💻      RickHeadle🎨 💻      Leandre🎨 💻      Natnael Sisay🎨 💻      sbbu🎨 💻      wael🎨 💻      Fabricio Tramontano Pirini🎨 💻              Alexander Stoyanov🎨 💻      Dezx20🎨 💻      southparkkids🎨 💻      bmstar🎨 💻      kiagam🎨 💻      Juan Castillo🎨 💻      FFenne🎨 💻              Jose Toledo🎨 💻      Pat McGhen🎨 💻      Eiko Wagenknecht💻 🖋 🔣      Alan Chalmers🎨 💻      Jean Didier🎨 💻      Andy🎨 💻      pestadieu🎨 💻              Kanishka Chakraborty🎨 💻      Nandha🎨 💻      Vahid Mafi🎨 💻 🔣 🖋 💼      Akshay Ashok🎨 💻      0x08🎨 💻      Sandeep Mishra🎨 💻      Evann Regnault🎨 💻              Lenny Zeitoun🎨 💻      Eden Boaron🎨 💻      TroyBTC🎨 💻      Aby Sebastian🎨 💻      Matthew Dunn🎨 💻      ckullo🎨 💻 🖋 🔣      Mohamed Mamdouh🎨 💻              Youssef Bazina🎨 💻      Frederico Kückelhaus💻      Nushan Kodikara💻      Zach Cooper💻      Roy🎨 💻      Saurav Panchal🎨 💻      totallynotdavid🎨 💻              goosepirate🎨 💻 💡 💼      KAUTH🎨 💻      Hari Kiran Vusirikala🎨 💻      Sounak Dey🎨 💻      zia💼 🎨 💻      Reza Davari🎨 💻      AkshayAjaykumar🎨 💻              x24870🎨 💻      Ko Phone🎨 💻      Nabstar3🎨 💻      Mateusz🎨 💻      Yunus Emre Emik💻      Abhinav Sinha🎨 💻      Hung Nguyen🎨 💻              Maselino💻      Shuktika Mahanty💻      Mikołaj Gawroński🎨 💻      Hussein Habibi Juybari🎨 💻      Sean-McArthur🎨 💻      Osman F Bayram🎨 💻      Benjamin Thomas Blodgett🎨 💻              Chuanlong-Zang🎨 💻      julian🎨 💻      francisco🎨 💻      aalihhiader9211🎨 💻      Muhammad Zunair🎨 💻      Liya🎨 💻      BegadTarek🎨 💻              etorobot🎨 💻      Hussam Khan🎨 💻      Saikat Chakraborty🎨 💻      Nicholas Quisler🎨 💻      Evang Poul🎨 💻      Gregg Lind🎨 💻      Deepak Kumar🎨 💻              Callum Leslie🎨 💻      Curtis Barnard Jr.🎨 💻      Deepanshukaim🎨 💻      Manthan Ank🎨 💻      hossein varmazyar🎨 💻      Brayan Muñoz V.🎨 💻      Kamil Rasheed Siddiqui💻 🎨              mutt0-ds🎨 💻      egbertjk🎨 💻      Majid Zojaji🎨 💻      Sean Chen🎨 💻      Herbert Milhomme🎨 💻      A3🎨 💻      Killian🎨 💻              Coakeow🎨 💻      ྅༻ Ǭɀħ ༄༆ཉ🎨 💻      Pratik Solanki🎨 💻      Sunny🎨 💻      ssge🎨 💻      Bernat Frangi🎨 💻      Jeevan Rupacha🎨 💻              amirandap🎨 💻      Deepakshi Mittal🎨 💻      Abhijeet Parida🎨 💻      Khaled Riyad🎨 💻      Pratap parui🎨 💻      Prajit Panday🎨 💻      PipeSierra🎨 💻              Collins Oden🎨 💻      Kshitij Dwivedi🎨 💻      Bernardia Vitri Arumsari🎨 💻      Ömer Faruk Taşdemir🎨 💻      Spencer Stith🎨 💻      Porsche Rodjanasak🎨 💻      Shakeel Sharif🎨 💻              Victoria Cheng🎨 💻      Denis🎨 💻      Anand Prakash Tiwari🎨 💻      danijeljw-rpc🎨 💻      Ahmed H Ebrahim🎨 💻      Virginia Gardner🎨 💻      Jhironsel Diaz A.🎨 💻              Yunus Kidem🎨 💻      MT🎨 💻      Dinesh Zaldekar🎨 💻      adi🎨 💻      Farhan Shaikh🎨 💻      Elvis Salvatierra🎨 💻      Kaushik-Iyer🎨 💻              HocAndres🎨 💻      VictorHugoAguilarAguilar🎨 💻      Murat Can Abay🎨 💻      Chris🎨 💻      Shivam7-1🎨 💻      Paipai13🎨 💻      Shambles-io🎨 💻              Abhishek K M🎨 💻      Ezequiel Cuevas🎨 💻      Plamen Ivanov🎨 💻      Yuji🎨 💻      Jean-Philippe Lebœuf🎨 💻 🔣      Naufan🎨 💻      jadnov🎨 💻              vaxtangens🎨 💻      subashkonar13🎨 💻      Rushi Javiya🎨 💻      Mert Gül🎨 💻      Lily🎨 💻      Kalinoff🎨 💻      Joel Tony🎨 💻              Peter🎨 💻      Roozbeh Zarei🎨 💻      Shen🎨 💻      Joonsoo.LEE🎨 💻      Fede.Breg🎨 💻      Rui Costa🎨 💻      João Gustavo Bispo🎨 💻              Sami-I🎨 💻      Tsvetoslav Tsvetkov🎨 💻      Olabode Olaniyi David🎨 💻      theRuslan🎨 💻      leighboz🎨 💻      Frank Sossi🎨 💻      Tomasz Adamski🎨 💻              Mansoor M. Sathir🎨 💻      Golamrabbi Azad🎨 💻      Nahian Ahmed🎨 💻      Rafael de Jesus Silva Monteiro🎨 💻      Odionyebuchukwu Jude🎨 💻      The Nithin Balaji🎨 💻      Knackii🎨 💻              vittorio-giatti🎨 💻      Guilherme de Carvalho Lima Rebouças🎨 💻      aaref shami🎨 💻      Andrey Dryupin🎨 💻      Muhanned Noman🎨 💻      Jan Silva🎨 💻      emanuele-em🎨 💻 🖋              Sanjay TM🎨 💻      Joe Markberg / code editor🎨 💻      Julien Quiaios🎨 💻      Eric Ramirez Santis🎨 💻      M🎨 💻      Malcata🎨 💻      Athul Muralidharan🎨 💻              Dariusz Ochota🎨 💻      CHANDAN CHOUDHURY🎨 💻      Deep🎨 💻      Ahmet İstemihan ÖZTÜRK🎨 💻      TIM🎨 💻      jakeg814🎨 💻      Leonidos🎨 💻              Abhinandu V Nair🎨 💻      charafeddine01🎨 💻      Jasper🎨 💻      Manish Goyal🎨 💻      SATYAM_SINGH🎨 💻      Four🎨 💻      Vaishnavi Amira Yada🎨 💻              ShriKrushna Bhagwat🎨 💻      Rohit Nandagawali🎨 💻      felipe🎨 💻 🚧 🖋 ✅ 🧑‍🏫      Saurabh Mudgal🎨 💻      szenadam🎨 💻      Shubhendra Singh🎨 💻      Yoosuf Sayyid💻 🎨              Güven Çetinerler🎨 💻      Luke Jefferies🎨 💻      Chris🎨 💻      Lúcio Aguiar💻      Enuma029💻      yktsang01💻      maximumn3rd🎨 💻              Jon Galletero🎨 💻      Thaddeus  Thomas🎨 💻      Aakash Kumar💻 🎨      Ali M🎨 💻      OskyEdz🎨 💻      Ravi Gupta🎨 💻      Rafa Raizer🎨 💻              Abdullah Al Muzaki🎨 💻      Rahul Faujdar🎨 💻      Abhishek Verma🎨 💻      Ashutosh Shinde🎨 💻      Ganesh Rai🎨 💻      StefanTrpkovic🎨 💻      Erik Blanca🎨 💻              Vedant Madane🎨 💻      Antra Tripathi🎨 💻      Ethan Knights🎨 💻      Alexandru Boncut🎨 💻      Pablo Bandinopla🎨 💻 🚧 🖋      Robz-99🎨 💻      Harpal Singh🎨 💻              paulboundy99🎨 💻      Mubashir Ahmed🎨 💻      Rohan Hari🎨 💻      Erik Henrique 🎨 💻      Leandro Matheus🎨 💻      Deepak🎨 💻      AlishaSingh🎨 💻              Lynn Latt Yati🎨 💻      San Shwe🎨 💻      SKR🎨 💻      msbunnyjaguar🎨 💻      Mohamad Zabiulla🎨 💻      Hatim Zahid🎨 💻      Rauzan Sumara🎨 💻              Hosein1358🎨 💻      Mohit🎨 💻      Ali🎨 💻      Avinash1765🎨 💻      Sai Teja Madha🎨 💻      Monsur Ahmed Shafiq🎨 💻      xuxianjin-dev🎨 💻              chetna🎨 💻      Gul Zaib🎨 💻      Natalia🎨 💻      Dionísio Braga🎨 💻      Pritish Rajpurohit🎨 💻      incanlove🎨 💻      Innocent🎨 💻              Devin Almonor🎨 💻      antonyveyre🎨 💻      Beltz Anhxton🎨 💻      Mehdi🎨 💻      Muhammad Usman🎨 💻      Patrick Dantas🎨 💻      Tak Vannak🎨 💻              Ramzi RADDAOUI🎨 💻      Konstantin-Glukhov🎨 💻      uguroban🎨 💻      Humberto Alves🎨 💻      JuangZendrato🎨 💻      James Oluwaleye🎨 💻      Wasi Sadman🎨 💻              Pavle Mijatovic🎨 💻      Luiz H. S. Bispo🎨 💻      Сухас Дхолз🎨 💻      Alvaro Trujillo🎨 💻      Everton 🎨 💻      jfrozas🎨 💻      Shuaaib Badran🎨 💻              Shivam Jha🎨 💻      Mohamed Tayeh🎨 💻      Makendran G🎨 💻      mayank singh tomar🎨 💻      hossam sadany🎨 💻      Harshbardhan Singh💻 🎨      Fawad Jawaid Malik🎨 💻              Tina Lacatis🎨 💻      TeddyCuoreDolce🎨 💻      bchooxg🎨 💻      Alisha Takkar🎨 💻      Gianluigi🎨 💻      Mehran Javaherian🎨 💻      Benjamin Ololade Adedokun🎨 💻              Md. Abdul Mutalib🎨 💻      Aadil Arsh.S.R🎨 💻      J. Nathan Allen🎨 💻      Kieran Krug🎨 💻      Seth Addo🎨 💻      Satvik Singh Rathore🎨 💻      dangoth🎨 💻              Maxim🎨 💻      Phuong-Cat Ngo🎨 💻      Frenchtoast0🎨 💻      Rakshith🎨 💻      Vaibhav Arora🎨 💻      zghp🎨 💻      Bedovan🎨 💻              chiaramistro🎨 💻      him2016🎨 💻      HarshitSachdeva🎨 💻      Sadaf Saleem🎨 💻      Aaroh Srivastava🎨 💻      eloygplaza🎨 💻      Gaurav Kumar Verma🎨 💻              AndreaCUS🎨 💻      Simran🎨 💻      Prashant Bhapkar🎨 💻      mhaendler🎨 💻      Gauri Maheshwari🎨 💻      4Lajf🎨 💻      Tanmoy Sengupta🎨 💻              Sharad Tripathi🎨 💻      Niraj Chavan🎨 💻      Luisa Gualda🎨 💻      Monika-Sivakumar-3🎨 💻      harryfensome🎨 💻      Shubham Choubey🎨 💻      Ashwini Patil🎨 💻              cleversonlira🎨 💻      Nurmukhammed🎨 💻      workspace-utkarsh🎨 💻      Santosh Phadtare🎨 💻      Prashant Warghude🎨 💻      Umang Dakh🎨 💻      Shalini Chavan🎨 💻              vinit gurjar🎨 💻      Vishal Kumar🎨 💻      Wonhyeong Seo🎨 💻      Achwale Prajwal Namdevrao🎨 💻      Ankan Banerjee🎨 💻      bhaumikankan🎨 💻      JamesMacroZhang🎨 💻              Pedro Lopes🎨 💻      dia🎨 💻      tayyabhussain2910🎨 💻      Rajdeep Shrivastava 🎨 💻      Mukul Kumar🎨 💻      Mayank N🎨 💻      jdelucca🎨 💻              Sneha Mittal🎨 💻      Sarika Kushwaha🎨 💻      farzad-khb🎨 💻      Elijah Shackelford🎨 💻      The-Only-Raminator🎨 💻      Keerthana Kasthuril🎨 💻      Viachaslau Auchynnikau🎨 💻              Mohammad Osman Rasooli🎨 💻      mvedovato🎨 💻      Sonali Rajput🎨 💻      Isha Dhek🎨 💻      Ramshad Cheriyeri Peediyakkal🎨 💻      Micah🎨 💻      gauravshukla2203🎨 💻              sndmurthy🎨 💻      Shivam-Singh🎨 💻      M. Ammar Khan🎨 💻      chandolakul🎨 💻      bhatnagar221🎨 💻      Adrian Nieściur🎨 💻      nezi311🎨 💻              scottajevans🎨 💻      Marcelo Antunes Soares Fantini🎨 💻      Axel De Acetis🎨 💻      Drishti Sah🎨 💻      VipulDhillon🎨 💻      Urmi Jana🎨 💻      Ayush Mokal🎨 💻              Damola Olutoke🎨 💻      Max🎨 💻      Lakshmi N🎨 💻      ArtemReva🎨 💻      Ujjwal Aggarwal🎨 💻      Mo🎨 💻      Brian🎨 💻              chamley🎨 💻      Simone Baptiste🎨 💻      Shekhar Thakur🎨 💻      Smith🎨 💻      codernoob1🎨 💻      lok84🎨 💻      Tobias Riemenschneider🎨 💻              Tharsanan1🎨 💻      ANURAG SINGH🎨 💻      Yash Sant🎨 💻      Krishiv Patel🎨 💻      GGGalaxy🎨 💻      pardeepdhillon661🎨 💻      anujd64🎨 💻              Pedro Pereira🎨 💻      Master_Saptak🎨 💻      SURANJAN DAS🎨 💻      Tripura kant🎨 💻      shabzkhan🎨 💻      Mustafa Poya🎨 💻      Roshan Jha🎨 💻              GuillaumeLarue🎨 💻      Tomasz Rodak🎨 💻      Junil Kim🎨 💻      Surbhi Mayank🎨 💻      Nemanja Lekic🎨 💻      HemantMalokar🎨 💻      Felipe M. López🎨 💻              bibliofilo🎨 💻      GauthamG2🎨 💻      02_t🎨 💻      Yusuf Abdul-razaq🎨 💻      Vladimir🎨 💻      Sai Chandra K🎨 💻      Soroush Bonab🎨 💻              Giide0n🎨 💻      GG🎨 💻      Dáger Zúñiga🎨 💻      rsk2🎨 💻      Storozhev DJ🎨 💻      Jeevan🎨 💻      Andy Johnson🎨 💻              Aníbal Pozo🎨 💻      Jovane de Castro🎨 💻      Muhammad Hamza Amir🎨 💻      tharaka-mts🎨 💻      Ali KHYAR🎨 💻      Caio Araujo🎨 💻      Oscar Dyremyhr🎨 💻              arteality🎨 💻      Daniel Drexlmaier🎨 💻      Marco Monti🎨 💻      mikeycrystal🎨 💻      Veljanovskii🎨 💻      Ivan Gorbachev🎨 💻      Sahil Rawat🎨 💻              Hasitha Suneth🎨 💻      Yerko Vera Lezama🎨 💻      Ivan Penchev🎨 💻      Tanver Islam Tonmoy🎨 💻      Xun Cao🎨 💻      Nayan Babariya🎨 💻      Priyanshu Maurya🎨 💻              Dylan Tintenfich🎨 💻      Ron Strauss🎨 💻      Mohammed AlBanna🎨 💻      Mukund M🎨 💻      Franklin Ohaegbulam🎨 💻      Nisarg Shah🎨 💻      Unik Dahal🎨 💻              Readily🎨 💻      Alexandre Poitevin🎨 💻      Scaramir🎨 💻      Pruthvi🎨 💻      Kalmanq🎨 💻      Alfatah Nesab🎨 💻      arudesai🎨 💻              Adryenne🎨 💻      El mehdi oudaoud🎨 💻      Jayant Goel🎨 💻      Tsuki🎨 💻      Peter Lemanski🎨 💻      Annurag-byte🎨 💻      Anthony Vu🎨 💻              Vitaly Nikolaychuk🎨 💻      Nathan🎨 💻      Evgenii Petukhov🎨 💻      Loris Guerra🎨 💻      fakhriaunur🎨 💻      Mehdi HYANI🎨 💻      Sarvex Jatasra🎨 💻              santimanuelr🎨 💻      Evgeniy Rezanov🎨 💻      Sonia M🎨 💻      Grzegorz Kmita🎨 💻      Manuel Carita🎨 💻      Felipe Cisternas Alvarez🎨 💻      Guo Ci🎨 💻              Marcos Silva🎨 💻      KK🎨 💻      Shubhanjan Medhi🎨 💻      ArthurFerreiraRodrigues🎨 💻      PabloHermun🎨 💻      disha-baldawa🎨 💻      StaroMoon🎨 💻              Amila T Kumarasekara🎨 💻      Amoh Prince🎨 💻      AngeloGC🎨 💻      Ebube Glory Ogbonda🎨 💻      Prahalad Belavadi📖      Antoni Sarnowski-Trypka🎨 💻      Alberto Pasqualetto🎨 💻              Amir Babaei🎨 💻      Syed Abdul Hannan🎨 💻      Srajan Rai🎨 💻      Clarence Moore🎨 💻      Nguyen Anh Tuan🎨 💻      dar2dar2🎨 💻      Ameer Ibrahim🎨 💻              Tiago Lugatto🎨 💻      raremiroir🎨 💻      Moobie🎨 💻      AlicanDursun🎨 💻      bbalsam🎨 💻      Luboš Hájek🎨 💻      mrshahzeb7🎨 💻              Wesley Scholl🎨 💻      Lawrence Turcotte🎨 💻      Michael DiPaolo🎨 💻      Smart-Codi🎨 💻      Vivek Kumar🎨 💻      Igor Moiseev🎨 💻      Bård Pedersen🎨 💻              HOA PHAN🎨 💻      GaborModra🎨 💻      vivek-114🎨 💻      Robin🎨 💻      Alex🎨 💻      John Ehrlinger🎨 💻      Roman Zhuravlov🎨 💻              Jordan Moss🎨 💻      RaeShelly🎨 💻      gmollard🎨 💻      Md Kaif Khan🎨 💻      Pablo Romera🎨 💻      Erik Bustos🎨 💻      trogfield🎨 💻              simon-aichhorn🎨 💻      Tufan GÜLEÇ🎨 💻      Uğur Berkecan Ünlü🎨 💻      Revanth Naik🎨 💻      Lia Pires🎨 💻      Igor Mestechkin🎨 💻      Anirudh Karanth🎨 💻              KBobovskiy🎨 💻      zhatiayua🎨 💻 🖋      David Cardona🎨 💻      Paulo Castilho🎨 💻      Sebastiano Picchi🎨 💻      pjotar🎨 💻      Rimel CHERIF💻              Arsal uddin🖋      Dmitry Kasporsky💻      SoftwareDev1014🎨 💻      @Robvred🎨 💻      Kasun Shanaka💻      Ahmad M.🎨 💻      Alex Kozin🎨 💻              Mandy Meindersma🎨 💻      LEGALISE PIRACY🎨 💻      Alex Logvin🎨 💻      Aria Dahl🎨 💻      Mustafa Arifoglu🎨 💻      Yevhen Leshchenko🎨 💻      Anubhav Adhikari🎨 💻              Noah Tatko🎨 💻      Mohit Gadhavi🎨 💻      Pedro Basílio🎨 💻      RealSanjeev🎨 💻      Akash Hazra🎨 💻      Christoph Dahlen🎨 💻      Vincent du Plessis🎨 💻              Karen Tamrazyan🎨 💻      Mirza Younus Baig🎨 💻      Ashish Kumar🎨 💻      Unknown6334🎨 💻      flowaz🎨 💻      zi-aikra🎨 💻      PAYAL PM🎨 💻              Lennart Lösche🎨 💻      Yummy-Yums🎨 💻      Njuacha Hubert Mikulowski🎨 💻      Hussein Esmail🎨 💻      Bilgehan Bezir🎨 💻      Muhammed Shittu🎨 💻      Clément FERNANDES🎨 💻              JaCKoP619🎨 💻      userutf8🎨 💻      Mohamed Ubaid🎨 💻      Justin Yates🎨 💻      mohammad ali🎨 💻      Madhav Singh🎨 💻      RgbMouse69🎨 💻              Nicholas Leask🎨 💻      parthav0🎨 💻      Sigma🎨 💻      Evelina Becheva🎨 💻      Akshit Gulyan🎨 💻      Arpita Jana🎨 💻      Praveen Kumar🎨 💻              Mohammad Sami🎨 💻      eddiestefanescu🎨 💻      Ramesh Yadav🎨 💻      Sarthak Joshi🎨 💻      Nikhil12300🎨 💻      Yevgen🎨 💻      Leo🎨 💻              laurent b🎨 💻      Mettchen🎨 💻      Ali Mahdavi🎨 💻      Lucas Dondo🎨 💻      Siddhesh Agarwal🎨 💻      slimerPuncher🎨 💻      saritashh🎨 💻              Iulian-Valeriu Cioată🎨 💻      Szabolcs Nagy🎨 💻      Jarle Kvile🎨 💻      劉耀升 Vic Liu🎨 💻      Suryansh🎨 💻      Matthew Oosthuyse🎨 💻      Florin Zamfir🎨 💻              Melek🎨 💻      moesocio🎨 💻      Alan James🎨 💻      Mai Thanh Phương🎨 💻      Neville Dabre🎨 💻      Maksym🎨 💻      tamanna900🎨 💻              Adithya Awati🎨 💻      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
83,hankcs/HanLP,https://github.com/hankcs/HanLP/blob/master/README.md,Python,"HanLP: Han Language Processing                                                                                   中文 |    日本語 |    Docs |    ForumThe multilingual NLP library for researchers and companies, built on PyTorch and TensorFlow 2.x, for advancingstate-of-the-art deep learning techniques in both academia and industry. HanLP was designed from day one to beefficient, user-friendly and extendable.Thanks to open-access corpora like Universal Dependencies and OntoNotes, HanLP 2.1 now offers 10 joint tasks on 130languages: tokenization, lemmatization, part-of-speech tagging, token feature extraction, dependency parsing,constituency parsing, semantic role labeling, semantic dependency parsing, abstract meaning representation (AMR)parsing.For end users, HanLP offers light-weighted RESTful APIs and native Python APIs.RESTful APIsTiny packages in several KBs for agile development and mobile applications. Although anonymous users are welcomed, anauth key is suggestedand a free one can be applied here underthe CC BY-NC-SA 4.0 license.  Click to expand tutorials for RESTful APIsPythonpip install hanlp_restfulCreate a client with our API endpoint and your auth.from hanlp_restful import HanLPClientHanLP = HanLPClient('https://hanlp.hankcs.com/api', auth=None, language='mul') # mul: multilingual, zh: ChineseJavaInsert the following dependency into your pom.xml.<dependency>  <groupId>com.hankcs.hanlp.restful</groupId>  <artifactId>hanlp-restful</artifactId>  <version>0.0.15</version></dependency>Create a client with our API endpoint and your auth.HanLPClient HanLP = new HanLPClient(\""https://hanlp.hankcs.com/api\"", null, \""mul\""); // mul: multilingual, zh: ChineseQuick StartNo matter which language you use, the same interface can be used to parse a document.HanLP.parse(    \""In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments. 2021年、HanLPv2.1は次世代の最先端多言語NLP技術を本番環境に導入します。2021年 HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。\"")See docs for visualization, annotation guidelines and more details.Native APIspip install hanlpHanLP requires Python 3.6 or later. GPU/TPU is suggested but not mandatory.Quick Startimport hanlpHanLP = hanlp.load(hanlp.pretrained.mtl.UD_ONTONOTES_TOK_POS_LEM_FEA_NER_SRL_DEP_SDP_CON_XLMR_BASE)print(HanLP(['In 2021, HanLPv2.1 delivers state-of-the-art multilingual NLP techniques to production environments.',             '2021年、HanLPv2.1は次世代の最先端多言語NLP技術を本番環境に導入します。',             '2021年 HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。']))In particular, the Python HanLPClient can also be used as a callable function following the same semantics.See docs for visualization, annotation guidelines and more details.To process Chinese or Japanese, HanLP provides mono-lingual models in each language which significantly outperform themulti-lingual model. See docs for the list of models.Train Your Own ModelsTo write DL models is not hard, the real hard thing is to write a model able to reproduce the scores in papers. Thesnippet below shows how to surpass the state-of-the-art tokenizer in 6 minutes.tokenizer = TransformerTaggingTokenizer()save_dir = 'data/model/cws/sighan2005_pku_bert_base_96.7'tokenizer.fit(    SIGHAN2005_PKU_TRAIN_ALL,    SIGHAN2005_PKU_TEST,  # Conventionally, no devset is used. See Tian et al. (2020).    save_dir,    'bert-base-chinese',    max_seq_len=300,    char_level=True,    hard_constraint=True,    sampler_builder=SortingSamplerBuilder(batch_size=32),    epochs=3,    adam_epsilon=1e-6,    warmup_steps=0.1,    weight_decay=0.01,    word_dropout=0.1,    seed=1660853059,)tokenizer.evaluate(SIGHAN2005_PKU_TEST, save_dir)The result is guaranteed to be 96.73 as the random seed is fixed. Different from some overclaiming papers andprojects, HanLP promises every single digit in our scores is reproducible. Any issues on reproducibility will be treatedand solved as a top-priority fatal bug.PerformanceThe performance of multi-task learning models is shown in the following table.langcorporamodeltokposnerdepconsrlsdplemfeaamrfinecoarsectbpku863udpkumsraontonotesSemEval16DMPASPSDmulUD2.7OntoNotes5small98.62----93.23--74.4279.1076.8570.63-91.1993.6785.3487.7184.51-base98.97----90.32--80.3278.7471.2373.63-92.6096.0481.1985.0882.13-zhopensmall97.25-96.66-----95.0084.5787.6273.4084.57------base97.50-97.07-----96.0487.1189.8477.7887.11------closesmall96.7095.9396.8797.5695.05-96.2295.7476.7984.4488.1375.8174.28------base97.5296.4496.9997.5995.29-96.4895.7277.7785.2988.5776.5273.76------ernie96.9597.2996.7697.6495.22-97.3196.4777.9585.6789.1778.5174.10------Multi-task learning models often under-perform their single-task learning counterparts according to our latestresearch. Similarly, mono-lingual models often outperform multi-lingual models. Therefore, we strongly recommend theuse of a single-task mono-lingual model if you aretargeting at high accuracy instead of faster speed.A state-of-the-art AMR model has been released.CitingIf you use HanLP in your research, please cite this repository.@inproceedings{he-choi-2021-stem,    title = \""The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders\"",    author = \""He, Han and Choi, Jinho D.\"",    booktitle = \""Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\"",    month = nov,    year = \""2021\"",    address = \""Online and Punta Cana, Dominican Republic\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://aclanthology.org/2021.emnlp-main.451\"",    pages = \""5555--5577\"",    abstract = \""Multi-task learning with transformer encoders (MTL) has emerged as a powerful technique to improve performance on closely-related tasks for both accuracy and efficiency while a question still remains whether or not it would perform as well on tasks that are distinct in nature. We first present MTL results on five NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over single-task learning. We then conduct an extensive pruning analysis to show that a certain set of attention heads get claimed by most tasks during MTL, who interfere with one another to fine-tune those heads for their own objectives. Based on this finding, we propose the Stem Cell Hypothesis to reveal the existence of attention heads naturally talented for many tasks that cannot be jointly trained to create adequate embeddings for all of those tasks. Finally, we design novel parameter-free probes to justify our hypothesis and demonstrate how attention heads are transformed across the five tasks during MTL through label analysis.\"",}LicenseCodesHanLP is licensed under Apache License 2.0. You can use HanLP in your commercial products for free. We wouldappreciate it if you add a link to HanLP on your website.ModelsUnless otherwise specified, all models in HanLP are licensedunder  CC BY-NC-SA 4.0.Referenceshttps://hanlp.hankcs.com/docs/references.html"
84,XX-net/XX-Net,https://github.com/XX-net/XX-Net/blob/master/README.md,Python,"🚀 XX-Net (翻墙VPN)这是一个可靠的翻墙系统，已经连续运行 8 年！我们不去研究墙有什么缺陷，因为所有的缺陷都会被慢慢的补上。我们的策略是化身为普通流量，完全无法区分，最终隐身在茫茫的网络连接中。。。🔌 功能特性支持多平台： Android/iOS/Windows/Mac/Linux采用独特的混淆算法，让您的流量在网络中无法被识别开源绿色软件，无需安装，可以支持多台设备同时连接模拟Chrome浏览器行为，完全无法识别，稳定翻墙内置 ChatGPT，每个套餐赠送 ChatGPT-3.5 一百万token官网下载: https://xx-net.comTelegram: https://t.me/xxnetshareTwitter: https://twitter.com/XXNetDev中文帮助文档      English Document      فارسی صفحه اصلی最新公告：2023-08-15新版 5.5.0, 提升连接性能5.1.0，内置ChatGPT原来是4.x.x 老版本的，需要重新下载新版安装，不能应用内升级。提示：有问题请先看Wiki文档提问 前，请先看最近讨论主题 ，避免重复发问。"
85,wangzheng0822/algo,https://github.com/wangzheng0822/algo/blob/master/README.md,Python,数据结构和算法必知必会的50个代码实现微信搜索我的公众号“小争哥”，或者微信扫描下面二维码关注关注微信公众号，回复”PDF“获取独家算法资料。前Google工程师，10万人跟着学的《数据结构和算法之美》《设计模式之美》专栏作者数组实现一个支持动态扩容的数组实现一个大小固定的有序数组，支持动态增删改操作实现两个有序数组合并为一个有序数组链表实现单链表、循环链表、双向链表，支持增删操作实现单链表反转实现两个有序的链表合并为一个有序链表实现求链表的中间结点栈用数组实现一个顺序栈用链表实现一个链式栈编程模拟实现一个浏览器的前进、后退功能队列用数组实现一个顺序队列用链表实现一个链式队列实现一个循环队列递归编程实现斐波那契数列求值f(n)=f(n-1)+f(n-2)编程实现求阶乘n!编程实现一组数据集合的全排列排序实现归并排序、快速排序、插入排序、冒泡排序、选择排序编程实现O(n)时间复杂度内找到一组数据的第K大元素二分查找实现一个有序数组的二分查找算法实现模糊二分查找算法（比如大于等于给定值的第一个元素）散列表实现一个基于链表法解决冲突问题的散列表实现一个LRU缓存淘汰算法字符串实现一个字符集，只包含a～z这26个英文字母的Trie树实现朴素的字符串匹配算法二叉树实现一个二叉查找树，并且支持插入、删除、查找操作实现查找二叉查找树中某个节点的后继、前驱节点实现二叉树前、中、后序以及按层遍历堆实现一个小顶堆、大顶堆、优先级队列实现堆排序利用优先级队列合并K个有序数组求一组动态数据集合的最大Top K图实现有向图、无向图、有权图、无权图的邻接矩阵和邻接表表示方法实现图的深度优先搜索、广度优先搜索实现Dijkstra算法、A*算法实现拓扑排序的Kahn算法、DFS算法回溯利用回溯算法求解八皇后问题利用回溯算法求解0-1背包问题分治利用分治算法求一组数据的逆序对个数动态规划0-1背包问题最小路径和编程实现莱文斯坦最短编辑距离编程实现查找两个字符串的最长公共子序列编程实现一个数据序列的最长递增子序列
86,encode/django-rest-framework,https://github.com/encode/django-rest-framework/blob/master/README.md,Python,"Django REST frameworkAwesome web-browsable Web APIs.Full documentation for the project is available at https://www.django-rest-framework.org/.FundingREST framework is a collaboratively funded project. If you useREST framework commercially we strongly encourage you to invest in itscontinued development by signing up for a paid plan.The initial aim is to provide a single full-time position on REST framework.Every single sign-up makes a significant impact towards making that possible.Many thanks to all our wonderful sponsors, and in particular to our premium backers, Sentry, Stream, Spacinov, Retool, bit.io, PostHog, CryptAPI, and FEZTO.OverviewDjango REST framework is a powerful and flexible toolkit for building Web APIs.Some reasons you might want to use REST framework:The Web browsable API is a huge usability win for your developers.Authentication policies including optional packages for OAuth1a and OAuth2.Serialization that supports both ORM and non-ORM data sources.Customizable all the way down - just use regular function-based views if you don't need the more powerful features.Extensive documentation, and great community support.There is a live example API for testing purposes, available here.Below: Screenshot from the browsable APIRequirementsPython 3.6+Django 4.2, 4.1, 4.0, 3.2, 3.1, 3.0We highly recommend and only officially support the latest patch release ofeach Python and Django series.InstallationInstall using pip...pip install djangorestframeworkAdd 'rest_framework' to your INSTALLED_APPS setting.INSTALLED_APPS = [    ...    'rest_framework',]ExampleLet's take a look at a quick example of using REST framework to build a simple model-backed API for accessing users and groups.Startup up a new project like so...pip install djangopip install djangorestframeworkdjango-admin startproject example ../manage.py migrate./manage.py createsuperuserNow edit the example/urls.py module in your project:from django.contrib.auth.models import Userfrom django.urls import include, pathfrom rest_framework import routers, serializers, viewsets# Serializers define the API representation.class UserSerializer(serializers.HyperlinkedModelSerializer):    class Meta:        model = User        fields = ['url', 'username', 'email', 'is_staff']# ViewSets define the view behavior.class UserViewSet(viewsets.ModelViewSet):    queryset = User.objects.all()    serializer_class = UserSerializer# Routers provide a way of automatically determining the URL conf.router = routers.DefaultRouter()router.register(r'users', UserViewSet)# Wire up our API using automatic URL routing.# Additionally, we include login URLs for the browsable API.urlpatterns = [    path('', include(router.urls)),    path('api-auth/', include('rest_framework.urls', namespace='rest_framework')),]We'd also like to configure a couple of settings for our API.Add the following to your settings.py module:INSTALLED_APPS = [    ...  # Make sure to include the default installed apps here.    'rest_framework',]REST_FRAMEWORK = {    # Use Django's standard `django.contrib.auth` permissions,    # or allow read-only access for unauthenticated users.    'DEFAULT_PERMISSION_CLASSES': [        'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly',    ]}That's it, we're done!./manage.py runserverYou can now open the API in your browser at http://127.0.0.1:8000/, and view your new 'users' API. If you use the Login control in the top right corner you'll also be able to add, create and delete users from the system.You can also interact with the API using command line tools such as curl. For example, to list the users endpoint:$ curl -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/[    {        \""url\"": \""http://127.0.0.1:8000/users/1/\"",        \""username\"": \""admin\"",        \""email\"": \""admin@example.com\"",        \""is_staff\"": true,    }]Or to create a new user:$ curl -X POST -d username=new -d email=new@example.com -d is_staff=false -H 'Accept: application/json; indent=4' -u admin:password http://127.0.0.1:8000/users/{    \""url\"": \""http://127.0.0.1:8000/users/2/\"",    \""username\"": \""new\"",    \""email\"": \""new@example.com\"",    \""is_staff\"": false,}Documentation & SupportFull documentation for the project is available at https://www.django-rest-framework.org/.For questions and support, use the REST framework discussion group, or #restframework on libera.chat IRC.You may also want to follow the author on Twitter.SecurityPlease see the security policy."
