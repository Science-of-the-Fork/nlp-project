{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7232ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrangle\n",
    "import acquire\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import env\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import acquire\n",
    "from time import strftime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import acquire as a\n",
    "# from env import github_token, github_username\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf64d43",
   "metadata": {},
   "source": [
    "## Bring in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceed37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df = acquire.get_github_python_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c0686b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jackfrued/Python-100-Days</td>\n",
       "      <td>https://github.com/jackfrued/Python-100-Days/b...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Python - 100å¤©ä»æ–°æ‰‹åˆ°å¤§å¸ˆä½œè€…ï¼šéª†æ˜Šè¯´æ˜ï¼šä»é¡¹ç›®ä¸Šçº¿åˆ°è·å¾—8w+æ˜Ÿæ ‡ä»¥æ¥ï¼Œä¸€ç›´æ”¶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>donnemartin/system-design-primer</td>\n",
       "      <td>https://github.com/donnemartin/system-design-p...</td>\n",
       "      <td>Python</td>\n",
       "      <td>English âˆ™ æ—¥æœ¬èª âˆ™ ç®€ä½“ä¸­æ–‡ âˆ™ ç¹é«”ä¸­æ–‡ | Ø§Ù„Ø¹ÙØ±ÙØ¨ÙÙŠÙÙ‘Ø©â€ âˆ™ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Significant-Gravitas/Auto-GPT</td>\n",
       "      <td>https://github.com/Significant-Gravitas/Auto-G...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Auto-GPT: An Autonomous GPT-4 ExperimentğŸ’¡ Get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>public-apis/public-apis</td>\n",
       "      <td>https://github.com/public-apis/public-apis/blo...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Public APIs    A collective list of free A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUTOMATIC1111/stable-diffusion-webui</td>\n",
       "      <td>https://github.com/AUTOMATIC1111/stable-diffus...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Stable Diffusion web UIA browser interface bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              repo_name  \\\n",
       "0             jackfrued/Python-100-Days   \n",
       "1      donnemartin/system-design-primer   \n",
       "2         Significant-Gravitas/Auto-GPT   \n",
       "3               public-apis/public-apis   \n",
       "4  AUTOMATIC1111/stable-diffusion-webui   \n",
       "\n",
       "                                                 url language  \\\n",
       "0  https://github.com/jackfrued/Python-100-Days/b...   Python   \n",
       "1  https://github.com/donnemartin/system-design-p...   Python   \n",
       "2  https://github.com/Significant-Gravitas/Auto-G...   Python   \n",
       "3  https://github.com/public-apis/public-apis/blo...   Python   \n",
       "4  https://github.com/AUTOMATIC1111/stable-diffus...   Python   \n",
       "\n",
       "                                      readme_content  \n",
       "0  Python - 100å¤©ä»æ–°æ‰‹åˆ°å¤§å¸ˆä½œè€…ï¼šéª†æ˜Šè¯´æ˜ï¼šä»é¡¹ç›®ä¸Šçº¿åˆ°è·å¾—8w+æ˜Ÿæ ‡ä»¥æ¥ï¼Œä¸€ç›´æ”¶...  \n",
       "1  English âˆ™ æ—¥æœ¬èª âˆ™ ç®€ä½“ä¸­æ–‡ âˆ™ ç¹é«”ä¸­æ–‡ | Ø§Ù„Ø¹ÙØ±ÙØ¨ÙÙŠÙÙ‘Ø©â€ âˆ™ ...  \n",
       "2  Auto-GPT: An Autonomous GPT-4 ExperimentğŸ’¡ Get ...  \n",
       "3      Public APIs    A collective list of free A...  \n",
       "4  Stable Diffusion web UIA browser interface bas...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d49d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(python_df.readme_content[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "329be018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# javascript_df = acquire.get_github_java_script_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8960758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# javascript_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e4c8f",
   "metadata": {},
   "source": [
    "## Test the prepare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ba5039",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train, validate, test = wrangle.wrangle_readmes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3855cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    \"\"\"\n",
    "    This function puts a string in lowercase, normalizes any unicode characters, removes anything that         \n",
    "    isn't an alphanumeric symbol or single quote.\n",
    "    \"\"\"\n",
    "    # Normalize unicode characters\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    \n",
    "    # Remove unwanted characters and put string in lowercase\n",
    "    string = re.sub(r\"[^\\w0-9'\\s]\", '', string).lower()\n",
    "            \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "658d6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    \"\"\"\n",
    "    This function takes in a string, lemmatizes each word, and returns a lemmatized version of the orignal string\n",
    "    \"\"\"\n",
    "    # Build the lemmatizer\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    results = []\n",
    "    for word in string.split():\n",
    "        results.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "    # Convert back into a string\n",
    "    string = ' '.join(results)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f75469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=None, exclude_words=None):\n",
    "    \"\"\"\n",
    "    Takes in a string, with optional arguments for words to add to stock stopwords and words to ignore in the \n",
    "    stock list removes the stopwords, and returns a stopword free version of the original string\n",
    "    \"\"\"\n",
    "    # Get the list of stopwords from nltk\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Create a set of stopwords to exclude\n",
    "    excluded_stopwords = set(exclude_words) if exclude_words else set()\n",
    "    \n",
    "    # Include any extra words in the stopwords to exclude\n",
    "    stopwords_to_exclude = set(stopword_list) - excluded_stopwords\n",
    "    \n",
    "    # Add extra words to the stopwords set\n",
    "    stopwords_to_exclude |= set(extra_words) if extra_words else set()\n",
    "    \n",
    "    # Tokenize the input string\n",
    "    words = string.split()\n",
    "    \n",
    "    # Filter out stopwords from the tokenized words\n",
    "    filtered_words = [word for word in words if word not in stopwords_to_exclude]\n",
    "    \n",
    "    # Convert back to string\n",
    "    string = ' '.join(filtered_words)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c992f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_readmes(df):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and performs a 70/15/15 split. Outputs a train, validate, and test dataframe\n",
    "    \"\"\"\n",
    "    # Perfrom a 70/15/15 split\n",
    "    train_val, test = train_test_split(df, test_size=.15, random_state=123)\n",
    "    train, validate = train_test_split(train_val, test_size=.17, random_state=123)\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "385fb9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_readmes(df, col=\"readme_content\"):\n",
    "    \"\"\"\n",
    "    Takes in the dataframe and the column name that contains the corpus data, creates a column of cleaned data, then uses that \n",
    "    to create a column without stopwords that is lemmatized, performs a train-validate-test split, performs an x-y split, and\n",
    "    returns x and y train, x and y validate, and x and y test.\n",
    "    \"\"\"\n",
    "    # Create the cleaned column\n",
    "\n",
    "    cleaned_row = []\n",
    "    for i in df.readme_content.values:\n",
    "        cleaned_row.append(clean(i))\n",
    "    df = df.assign(cleaned_content=cleaned_row)\n",
    "#     df['cleaned'] = df[col].apply(lambda x: clean(x))\n",
    "    df['lemmatized'] = df['cleaned_content'].apply(lambda x: lemmatize(remove_stopwords(x)))\n",
    "    \n",
    "    # Split the dataframe (70/15/15)\n",
    "    train, validate, test = split_readmes(df)\n",
    "    \n",
    "#     # perform x-y split\n",
    "#     x_train, y_train = train.drop(columns=('language')), train.language\n",
    "#     x_validate, y_validate = validate.drop(columns=('language')), validate.language\n",
    "#     x_test, y_test = test.drop(columns=('language')), test.language\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "805bc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = prep_readmes(python_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b126fd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_content</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>josephmisiti/awesome-machine-learning</td>\n",
       "      <td>https://github.com/josephmisiti/awesome-machin...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Awesome Machine Learning  A curated list of aw...</td>\n",
       "      <td>awesome machine learning  a curated list of aw...</td>\n",
       "      <td>awesome machine learning curated list awesome ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Significant-Gravitas/Auto-GPT</td>\n",
       "      <td>https://github.com/Significant-Gravitas/Auto-G...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Auto-GPT: An Autonomous GPT-4 ExperimentğŸ’¡ Get ...</td>\n",
       "      <td>autogpt an autonomous gpt4 experiment get help...</td>\n",
       "      <td>autogpt autonomous gpt4 experiment get help qa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>josephmisiti/awesome-machine-learning</td>\n",
       "      <td>https://github.com/josephmisiti/awesome-machin...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Awesome Machine Learning  A curated list of aw...</td>\n",
       "      <td>awesome machine learning  a curated list of aw...</td>\n",
       "      <td>awesome machine learning curated list awesome ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>PaddlePaddle/PaddleOCR</td>\n",
       "      <td>https://github.com/PaddlePaddle/PaddleOCR/blob...</td>\n",
       "      <td>Python</td>\n",
       "      <td>English | ç®€ä½“ä¸­æ–‡ | à¤¹à¤¿à¤¨à¥à¤¦à¥€ | æ—¥æœ¬èª | í•œêµ­ì¸ | PÑƒÌÑÑĞºĞ¸Ğ¹...</td>\n",
       "      <td>english          p                            ...</td>\n",
       "      <td>english p paddleocrocr 202387 paddleocr releas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bregman-arie/devops-exercises</td>\n",
       "      <td>https://github.com/bregman-arie/devops-exercis...</td>\n",
       "      <td>Python</td>\n",
       "      <td>DevOps é¢è¯•é—®é¢˜â„¹ï¸ Â æœ¬ä»“åº“åŒ…å«å„ç§ DevOps ç›¸å…³ä¸»é¢˜çš„é¢è¯•é—®é¢˜ğŸ“Š Â å½“å‰æœ‰ ...</td>\n",
       "      <td>devops i   devops    413    devops    devops  ...</td>\n",
       "      <td>devops devops 413 devops devops pr devops jenk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ultralytics/yolov5</td>\n",
       "      <td>https://github.com/ultralytics/yolov5/blob/mas...</td>\n",
       "      <td>Python</td>\n",
       "      <td>English | ç®€ä½“ä¸­æ–‡                  ...</td>\n",
       "      <td>english                         ...</td>\n",
       "      <td>english yolov5 world's loved vision ai represe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>public-apis/public-apis</td>\n",
       "      <td>https://github.com/public-apis/public-apis/blo...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Public APIs    A collective list of free A...</td>\n",
       "      <td>public apis    a collective list of free a...</td>\n",
       "      <td>public apis collective list free apis use soft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>PaddlePaddle/PaddleOCR</td>\n",
       "      <td>https://github.com/PaddlePaddle/PaddleOCR/blob...</td>\n",
       "      <td>Python</td>\n",
       "      <td>English | ç®€ä½“ä¸­æ–‡ | à¤¹à¤¿à¤¨à¥à¤¦à¥€ | æ—¥æœ¬èª | í•œêµ­ì¸ | PÑƒÌÑÑĞºĞ¸Ğ¹...</td>\n",
       "      <td>english          p                            ...</td>\n",
       "      <td>english p paddleocrocr 202387 paddleocr releas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>fxsjy/jieba</td>\n",
       "      <td>https://github.com/fxsjy/jieba/blob/master/REA...</td>\n",
       "      <td>Python</td>\n",
       "      <td>jiebaâ€œç»“å·´â€ä¸­æ–‡åˆ†è¯ï¼šåšæœ€å¥½çš„ Python ä¸­æ–‡åˆ†è¯ç»„ä»¶\\\"Jieba\\\" (Chi...</td>\n",
       "      <td>jieba python jieba chinese for to stutter chin...</td>\n",
       "      <td>jieba python jieba chinese stutter chinese tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>geekcomputers/Python</td>\n",
       "      <td>https://github.com/geekcomputers/Python/blob/m...</td>\n",
       "      <td>Python</td>\n",
       "      <td>My Python Eggs ğŸ ğŸ˜„I do not consider myself as ...</td>\n",
       "      <td>my python eggs  i do not consider myself as a ...</td>\n",
       "      <td>python egg consider programmer create little p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                repo_name  \\\n",
       "55  josephmisiti/awesome-machine-learning   \n",
       "31          Significant-Gravitas/Auto-GPT   \n",
       "14  josephmisiti/awesome-machine-learning   \n",
       "78                 PaddlePaddle/PaddleOCR   \n",
       "46          bregman-arie/devops-exercises   \n",
       "..                                    ...   \n",
       "44                     ultralytics/yolov5   \n",
       "40                public-apis/public-apis   \n",
       "88                 PaddlePaddle/PaddleOCR   \n",
       "87                            fxsjy/jieba   \n",
       "25                   geekcomputers/Python   \n",
       "\n",
       "                                                  url language  \\\n",
       "55  https://github.com/josephmisiti/awesome-machin...   Python   \n",
       "31  https://github.com/Significant-Gravitas/Auto-G...   Python   \n",
       "14  https://github.com/josephmisiti/awesome-machin...   Python   \n",
       "78  https://github.com/PaddlePaddle/PaddleOCR/blob...   Python   \n",
       "46  https://github.com/bregman-arie/devops-exercis...   Python   \n",
       "..                                                ...      ...   \n",
       "44  https://github.com/ultralytics/yolov5/blob/mas...   Python   \n",
       "40  https://github.com/public-apis/public-apis/blo...   Python   \n",
       "88  https://github.com/PaddlePaddle/PaddleOCR/blob...   Python   \n",
       "87  https://github.com/fxsjy/jieba/blob/master/REA...   Python   \n",
       "25  https://github.com/geekcomputers/Python/blob/m...   Python   \n",
       "\n",
       "                                       readme_content  \\\n",
       "55  Awesome Machine Learning  A curated list of aw...   \n",
       "31  Auto-GPT: An Autonomous GPT-4 ExperimentğŸ’¡ Get ...   \n",
       "14  Awesome Machine Learning  A curated list of aw...   \n",
       "78  English | ç®€ä½“ä¸­æ–‡ | à¤¹à¤¿à¤¨à¥à¤¦à¥€ | æ—¥æœ¬èª | í•œêµ­ì¸ | PÑƒÌÑÑĞºĞ¸Ğ¹...   \n",
       "46  DevOps é¢è¯•é—®é¢˜â„¹ï¸ Â æœ¬ä»“åº“åŒ…å«å„ç§ DevOps ç›¸å…³ä¸»é¢˜çš„é¢è¯•é—®é¢˜ğŸ“Š Â å½“å‰æœ‰ ...   \n",
       "..                                                ...   \n",
       "44                English | ç®€ä½“ä¸­æ–‡                  ...   \n",
       "40      Public APIs    A collective list of free A...   \n",
       "88  English | ç®€ä½“ä¸­æ–‡ | à¤¹à¤¿à¤¨à¥à¤¦à¥€ | æ—¥æœ¬èª | í•œêµ­ì¸ | PÑƒÌÑÑĞºĞ¸Ğ¹...   \n",
       "87  jiebaâ€œç»“å·´â€ä¸­æ–‡åˆ†è¯ï¼šåšæœ€å¥½çš„ Python ä¸­æ–‡åˆ†è¯ç»„ä»¶\\\"Jieba\\\" (Chi...   \n",
       "25  My Python Eggs ğŸ ğŸ˜„I do not consider myself as ...   \n",
       "\n",
       "                                      cleaned_content  \\\n",
       "55  awesome machine learning  a curated list of aw...   \n",
       "31  autogpt an autonomous gpt4 experiment get help...   \n",
       "14  awesome machine learning  a curated list of aw...   \n",
       "78  english          p                            ...   \n",
       "46  devops i   devops    413    devops    devops  ...   \n",
       "..                                                ...   \n",
       "44                english                         ...   \n",
       "40      public apis    a collective list of free a...   \n",
       "88  english          p                            ...   \n",
       "87  jieba python jieba chinese for to stutter chin...   \n",
       "25  my python eggs  i do not consider myself as a ...   \n",
       "\n",
       "                                           lemmatized  \n",
       "55  awesome machine learning curated list awesome ...  \n",
       "31  autogpt autonomous gpt4 experiment get help qa...  \n",
       "14  awesome machine learning curated list awesome ...  \n",
       "78  english p paddleocrocr 202387 paddleocr releas...  \n",
       "46  devops devops 413 devops devops pr devops jenk...  \n",
       "..                                                ...  \n",
       "44  english yolov5 world's loved vision ai represe...  \n",
       "40  public apis collective list free apis use soft...  \n",
       "88  english p paddleocrocr 202387 paddleocr releas...  \n",
       "87  jieba python jieba chinese stutter chinese tex...  \n",
       "25  python egg consider programmer create little p...  \n",
       "\n",
       "[62 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7875631f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62, 6), (13, 6), (14, 6))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cec741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
