{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7232ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrangle\n",
    "import acquire\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import env\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import acquire\n",
    "from time import strftime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import acquire as a\n",
    "# from env import github_token, github_username\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf64d43",
   "metadata": {},
   "source": [
    "## Bring in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceed37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_df = acquire.get_github_python_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c0686b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jackfrued/Python-100-Days</td>\n",
       "      <td>https://github.com/jackfrued/Python-100-Days/b...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Python - 100天从新手到大师作者：骆昊说明：从项目上线到获得8w+星标以来，一直收...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>donnemartin/system-design-primer</td>\n",
       "      <td>https://github.com/donnemartin/system-design-p...</td>\n",
       "      <td>Python</td>\n",
       "      <td>English ∙ 日本語 ∙ 简体中文 ∙ 繁體中文 | العَرَبِيَّة‎ ∙ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Significant-Gravitas/Auto-GPT</td>\n",
       "      <td>https://github.com/Significant-Gravitas/Auto-G...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Auto-GPT: An Autonomous GPT-4 Experiment💡 Get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>public-apis/public-apis</td>\n",
       "      <td>https://github.com/public-apis/public-apis/blo...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Public APIs    A collective list of free A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUTOMATIC1111/stable-diffusion-webui</td>\n",
       "      <td>https://github.com/AUTOMATIC1111/stable-diffus...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Stable Diffusion web UIA browser interface bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              repo_name  \\\n",
       "0             jackfrued/Python-100-Days   \n",
       "1      donnemartin/system-design-primer   \n",
       "2         Significant-Gravitas/Auto-GPT   \n",
       "3               public-apis/public-apis   \n",
       "4  AUTOMATIC1111/stable-diffusion-webui   \n",
       "\n",
       "                                                 url language  \\\n",
       "0  https://github.com/jackfrued/Python-100-Days/b...   Python   \n",
       "1  https://github.com/donnemartin/system-design-p...   Python   \n",
       "2  https://github.com/Significant-Gravitas/Auto-G...   Python   \n",
       "3  https://github.com/public-apis/public-apis/blo...   Python   \n",
       "4  https://github.com/AUTOMATIC1111/stable-diffus...   Python   \n",
       "\n",
       "                                      readme_content  \n",
       "0  Python - 100天从新手到大师作者：骆昊说明：从项目上线到获得8w+星标以来，一直收...  \n",
       "1  English ∙ 日本語 ∙ 简体中文 ∙ 繁體中文 | العَرَبِيَّة‎ ∙ ...  \n",
       "2  Auto-GPT: An Autonomous GPT-4 Experiment💡 Get ...  \n",
       "3      Public APIs    A collective list of free A...  \n",
       "4  Stable Diffusion web UIA browser interface bas...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d49d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(python_df.readme_content[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "329be018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# javascript_df = acquire.get_github_java_script_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8960758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# javascript_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e4c8f",
   "metadata": {},
   "source": [
    "## Test the prepare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ba5039",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train, validate, test = wrangle.wrangle_readmes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3855cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    \"\"\"\n",
    "    This function puts a string in lowercase, normalizes any unicode characters, removes anything that         \n",
    "    isn't an alphanumeric symbol or single quote.\n",
    "    \"\"\"\n",
    "    # Normalize unicode characters\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    \n",
    "    # Remove unwanted characters and put string in lowercase\n",
    "    string = re.sub(r\"[^\\w0-9'\\s]\", '', string).lower()\n",
    "            \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "658d6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    \"\"\"\n",
    "    This function takes in a string, lemmatizes each word, and returns a lemmatized version of the orignal string\n",
    "    \"\"\"\n",
    "    # Build the lemmatizer\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    results = []\n",
    "    for word in string.split():\n",
    "        results.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "    # Convert back into a string\n",
    "    string = ' '.join(results)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f75469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=None, exclude_words=None):\n",
    "    \"\"\"\n",
    "    Takes in a string, with optional arguments for words to add to stock stopwords and words to ignore in the \n",
    "    stock list removes the stopwords, and returns a stopword free version of the original string\n",
    "    \"\"\"\n",
    "    # Get the list of stopwords from nltk\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Create a set of stopwords to exclude\n",
    "    excluded_stopwords = set(exclude_words) if exclude_words else set()\n",
    "    \n",
    "    # Include any extra words in the stopwords to exclude\n",
    "    stopwords_to_exclude = set(stopword_list) - excluded_stopwords\n",
    "    \n",
    "    # Add extra words to the stopwords set\n",
    "    stopwords_to_exclude |= set(extra_words) if extra_words else set()\n",
    "    \n",
    "    # Tokenize the input string\n",
    "    words = string.split()\n",
    "    \n",
    "    # Filter out stopwords from the tokenized words\n",
    "    filtered_words = [word for word in words if word not in stopwords_to_exclude]\n",
    "    \n",
    "    # Convert back to string\n",
    "    string = ' '.join(filtered_words)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c992f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_readmes(df):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and performs a 70/15/15 split. Outputs a train, validate, and test dataframe\n",
    "    \"\"\"\n",
    "    # Perfrom a 70/15/15 split\n",
    "    train_val, test = train_test_split(df, test_size=.15, random_state=123)\n",
    "    train, validate = train_test_split(train_val, test_size=.17, random_state=123)\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "385fb9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_readmes(df, col=\"readme_content\"):\n",
    "    \"\"\"\n",
    "    Takes in the dataframe and the column name that contains the corpus data, creates a column of cleaned data, then uses that \n",
    "    to create a column without stopwords that is lemmatized, performs a train-validate-test split, performs an x-y split, and\n",
    "    returns x and y train, x and y validate, and x and y test.\n",
    "    \"\"\"\n",
    "    # Create the cleaned column\n",
    "\n",
    "    cleaned_row = []\n",
    "    for i in df.readme_content.values:\n",
    "        cleaned_row.append(clean(i))\n",
    "    df = df.assign(cleaned_content=cleaned_row)\n",
    "#     df['cleaned'] = df[col].apply(lambda x: clean(x))\n",
    "    df['lemmatized'] = df['cleaned_content'].apply(lambda x: lemmatize(remove_stopwords(x)))\n",
    "    \n",
    "    # Split the dataframe (70/15/15)\n",
    "    train, validate, test = split_readmes(df)\n",
    "    \n",
    "#     # perform x-y split\n",
    "#     x_train, y_train = train.drop(columns=('language')), train.language\n",
    "#     x_validate, y_validate = validate.drop(columns=('language')), validate.language\n",
    "#     x_test, y_test = test.drop(columns=('language')), test.language\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "805bc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = prep_readmes(python_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b126fd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_content</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>josephmisiti/awesome-machine-learning</td>\n",
       "      <td>https://github.com/josephmisiti/awesome-machin...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Awesome Machine Learning  A curated list of aw...</td>\n",
       "      <td>awesome machine learning  a curated list of aw...</td>\n",
       "      <td>awesome machine learning curated list awesome ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Significant-Gravitas/Auto-GPT</td>\n",
       "      <td>https://github.com/Significant-Gravitas/Auto-G...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Auto-GPT: An Autonomous GPT-4 Experiment💡 Get ...</td>\n",
       "      <td>autogpt an autonomous gpt4 experiment get help...</td>\n",
       "      <td>autogpt autonomous gpt4 experiment get help qa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>josephmisiti/awesome-machine-learning</td>\n",
       "      <td>https://github.com/josephmisiti/awesome-machin...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Awesome Machine Learning  A curated list of aw...</td>\n",
       "      <td>awesome machine learning  a curated list of aw...</td>\n",
       "      <td>awesome machine learning curated list awesome ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>PaddlePaddle/PaddleOCR</td>\n",
       "      <td>https://github.com/PaddlePaddle/PaddleOCR/blob...</td>\n",
       "      <td>Python</td>\n",
       "      <td>English | 简体中文 | हिन्दी | 日本語 | 한국인 | Pу́сский...</td>\n",
       "      <td>english          p                            ...</td>\n",
       "      <td>english p paddleocrocr 202387 paddleocr releas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bregman-arie/devops-exercises</td>\n",
       "      <td>https://github.com/bregman-arie/devops-exercis...</td>\n",
       "      <td>Python</td>\n",
       "      <td>DevOps 面试问题ℹ️  本仓库包含各种 DevOps 相关主题的面试问题📊  当前有 ...</td>\n",
       "      <td>devops i   devops    413    devops    devops  ...</td>\n",
       "      <td>devops devops 413 devops devops pr devops jenk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ultralytics/yolov5</td>\n",
       "      <td>https://github.com/ultralytics/yolov5/blob/mas...</td>\n",
       "      <td>Python</td>\n",
       "      <td>English | 简体中文                  ...</td>\n",
       "      <td>english                         ...</td>\n",
       "      <td>english yolov5 world's loved vision ai represe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>public-apis/public-apis</td>\n",
       "      <td>https://github.com/public-apis/public-apis/blo...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Public APIs    A collective list of free A...</td>\n",
       "      <td>public apis    a collective list of free a...</td>\n",
       "      <td>public apis collective list free apis use soft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>PaddlePaddle/PaddleOCR</td>\n",
       "      <td>https://github.com/PaddlePaddle/PaddleOCR/blob...</td>\n",
       "      <td>Python</td>\n",
       "      <td>English | 简体中文 | हिन्दी | 日本語 | 한국인 | Pу́сский...</td>\n",
       "      <td>english          p                            ...</td>\n",
       "      <td>english p paddleocrocr 202387 paddleocr releas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>fxsjy/jieba</td>\n",
       "      <td>https://github.com/fxsjy/jieba/blob/master/REA...</td>\n",
       "      <td>Python</td>\n",
       "      <td>jieba“结巴”中文分词：做最好的 Python 中文分词组件\\\"Jieba\\\" (Chi...</td>\n",
       "      <td>jieba python jieba chinese for to stutter chin...</td>\n",
       "      <td>jieba python jieba chinese stutter chinese tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>geekcomputers/Python</td>\n",
       "      <td>https://github.com/geekcomputers/Python/blob/m...</td>\n",
       "      <td>Python</td>\n",
       "      <td>My Python Eggs 🐍 😄I do not consider myself as ...</td>\n",
       "      <td>my python eggs  i do not consider myself as a ...</td>\n",
       "      <td>python egg consider programmer create little p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                repo_name  \\\n",
       "55  josephmisiti/awesome-machine-learning   \n",
       "31          Significant-Gravitas/Auto-GPT   \n",
       "14  josephmisiti/awesome-machine-learning   \n",
       "78                 PaddlePaddle/PaddleOCR   \n",
       "46          bregman-arie/devops-exercises   \n",
       "..                                    ...   \n",
       "44                     ultralytics/yolov5   \n",
       "40                public-apis/public-apis   \n",
       "88                 PaddlePaddle/PaddleOCR   \n",
       "87                            fxsjy/jieba   \n",
       "25                   geekcomputers/Python   \n",
       "\n",
       "                                                  url language  \\\n",
       "55  https://github.com/josephmisiti/awesome-machin...   Python   \n",
       "31  https://github.com/Significant-Gravitas/Auto-G...   Python   \n",
       "14  https://github.com/josephmisiti/awesome-machin...   Python   \n",
       "78  https://github.com/PaddlePaddle/PaddleOCR/blob...   Python   \n",
       "46  https://github.com/bregman-arie/devops-exercis...   Python   \n",
       "..                                                ...      ...   \n",
       "44  https://github.com/ultralytics/yolov5/blob/mas...   Python   \n",
       "40  https://github.com/public-apis/public-apis/blo...   Python   \n",
       "88  https://github.com/PaddlePaddle/PaddleOCR/blob...   Python   \n",
       "87  https://github.com/fxsjy/jieba/blob/master/REA...   Python   \n",
       "25  https://github.com/geekcomputers/Python/blob/m...   Python   \n",
       "\n",
       "                                       readme_content  \\\n",
       "55  Awesome Machine Learning  A curated list of aw...   \n",
       "31  Auto-GPT: An Autonomous GPT-4 Experiment💡 Get ...   \n",
       "14  Awesome Machine Learning  A curated list of aw...   \n",
       "78  English | 简体中文 | हिन्दी | 日本語 | 한국인 | Pу́сский...   \n",
       "46  DevOps 面试问题ℹ️  本仓库包含各种 DevOps 相关主题的面试问题📊  当前有 ...   \n",
       "..                                                ...   \n",
       "44                English | 简体中文                  ...   \n",
       "40      Public APIs    A collective list of free A...   \n",
       "88  English | 简体中文 | हिन्दी | 日本語 | 한국인 | Pу́сский...   \n",
       "87  jieba“结巴”中文分词：做最好的 Python 中文分词组件\\\"Jieba\\\" (Chi...   \n",
       "25  My Python Eggs 🐍 😄I do not consider myself as ...   \n",
       "\n",
       "                                      cleaned_content  \\\n",
       "55  awesome machine learning  a curated list of aw...   \n",
       "31  autogpt an autonomous gpt4 experiment get help...   \n",
       "14  awesome machine learning  a curated list of aw...   \n",
       "78  english          p                            ...   \n",
       "46  devops i   devops    413    devops    devops  ...   \n",
       "..                                                ...   \n",
       "44                english                         ...   \n",
       "40      public apis    a collective list of free a...   \n",
       "88  english          p                            ...   \n",
       "87  jieba python jieba chinese for to stutter chin...   \n",
       "25  my python eggs  i do not consider myself as a ...   \n",
       "\n",
       "                                           lemmatized  \n",
       "55  awesome machine learning curated list awesome ...  \n",
       "31  autogpt autonomous gpt4 experiment get help qa...  \n",
       "14  awesome machine learning curated list awesome ...  \n",
       "78  english p paddleocrocr 202387 paddleocr releas...  \n",
       "46  devops devops 413 devops devops pr devops jenk...  \n",
       "..                                                ...  \n",
       "44  english yolov5 world's loved vision ai represe...  \n",
       "40  public apis collective list free apis use soft...  \n",
       "88  english p paddleocrocr 202387 paddleocr releas...  \n",
       "87  jieba python jieba chinese stutter chinese tex...  \n",
       "25  python egg consider programmer create little p...  \n",
       "\n",
       "[62 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7875631f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62, 6), (13, 6), (14, 6))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cec741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
