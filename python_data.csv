,repo_name,url,language,readme_content
0,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
1,google/it-cert-automation-practice,https://github.com/google/it-cert-automation-practice/blob/master/README.md,Python,Google IT Automation with Python Professional Certificate - Practice filesThis repository contains the practice files used throughout the courses that arepart of the Google IT Automation with Python Professional CertificateThere's a separate folder for each course.
2,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        ÁÆÄ‰Ωì‰∏≠Êñá |        ÁπÅÈ´î‰∏≠Êñá |        ÌïúÍµ≠Ïñ¥ |        Espa√±ol |        Êó•Êú¨Ë™û |        ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    ü§ó Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.üó£Ô∏è Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.ü§ó Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.ü§ó Transformers is backed by the three most popular deep learning libraries ‚Äî Jax, PyTorch and TensorFlow ‚Äî with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install ü§ó Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, ü§ó Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.ü§ó Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by ü§ó Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: ü§ó Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from √âcole polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Su√°rez*, Yoann Dupont, Laurent Romary, √âric Villemonte de la Clergerie, Djam√© Seddah and Beno√Æt Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of G√∂ttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo L√ºddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Herv√© J√©gou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp Kr√§henb√ºhl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, Timoth√©e Darcet, Th√©o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Herv√© Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas Oƒüuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by Ren√© Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre D√©fossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, Lo√Øc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno√Æt Crabb√©, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey √ñhman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo Garc√≠a del R√≠o, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Herv√© J√©gou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by J√∂rg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre D√©fossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noah‚Äôs Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.Nystr√∂mformer (from the University of Wisconsin - Madison) released with the paper Nystr√∂mformer: A Nystr√∂m-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier H√©naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, Jo√£o Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, ≈Åukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Doll√°r.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault F√©vry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of W√ºrzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, Pawe≈Ç Krzysztof Nowak, Thomas M√ºller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll√°r, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Luƒçiƒá, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm√°n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper ‚ÄãXLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the ü§ó Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by ü§ó TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by ü§ó Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the ü§ó Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R√©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
3,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
4,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.‚ö†Ô∏è IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!‚ö†Ô∏è IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means you‚Äôve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the project‚Äôs direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a project‚Äôs website for a ‚Äúteam‚Äù page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participants‚Äô behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, ‚ÄúHow do I‚Ä¶‚Äú or ‚ÄúWhat do you think about‚Ä¶‚Äú instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
5,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answers‚ö†Ô∏è DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]üôè PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!üéâ AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.‚ùì Need help?Open new issueüî• Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accounting‚ùóneeds updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustrator‚ùóneeds updating  7674Adobe-InDesign‚ùóneeds updating  4240Adobe-Lightroom‚ùóneeds updating  2020Adobe-Photoshop‚ùóneeds updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effects‚ùóneeds updating  2413Agile Methodologies‚ùóneeds updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCAD‚ùóneeds updating  7775@djayorAutodesk Fusion 360‚ùóneeds updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambda‚ùóneeds updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++‚ùóneeds updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurity‚ùóneeds updating10196Django7171@PROCW.NET Framework6359@declarckEclipse‚ùóneeds updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSON‚ùóneeds updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excel‚ùóneeds updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Project‚ùóneeds updating4443Microsoft Word‚ùóneeds updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooks‚ùóneeds updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revit‚ùóneeds updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePoint‚ùóneeds updating5338Sketchup22SOLIDWORKS‚ùóneeds updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnity‚ùóneeds updating4746@uno-sebastianVisual Basic for Applications (VBA)‚ùóneeds updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors ‚ú®Thanks goes to these wonderful people (emoji key):            Evgeniiüíª üñã      Sergei Stadniküíª üîç ü§î üìñ      Santhoshüíª      Jacob Dsaüíª üñã      Aaron Meeseüíª üñã      arqarqüíª üñã      Amit Yadavüíª üñã              Javokhir Nazarovüíª üñã      saurav kumarüñã      Chetanüñã      Amir Hossein Shekariüé® üñã üíª      SergDautüé®      Nilotpal Pramaniküé® üíª üñã üíº üìñ üî£ üí°      Abhishek Kumarüé®              Monu Guptaüé®      KARTIKEYA GUPTAüíª üñã      kenkyushaüíª üñã      juandavidtowersüíª üñã      cyber-neticsüíª üñã      jtriswüíª üñã      Renato Regaladoüíª üñã              Matthewüíª üñã      Jan S.üíª üñã      Manoliüíª üñã      Faraz tanveerüíª üñã      mohnishkarriüíª üñã üé®      andyzhuüíª üñã      Vishal Kushwahüíª üñã              Yurii Yakymenkoüíª üñã      Swetabh Sumanüíª üñã      AJAY DANDGEüíª üñã      Mehmet Yesinüé®      Lok Chun Waiüé®      Adria de Juanüé®      GL-Manüé®              Jheel Patelüé®      Sameer Waskarüé®      Alexander Andrewsüé®      Alexander Maxwellüé®      Slavaüé®      Mayur Khatriüé®      Mascantoshüíª üñã üì¢ ü§î              Kivanc Enesüé®      Ritika Dasüé®      Zer07793üé®      Andrew Cheungüé®      Sadhaüé®      tainenkoüé® üíª      github-star-coderüé®              Danilo Oliveiraüé®      lordekoüé®      Shubham Kumarüé® üíª      testtreeüé®      Cheryl Murphyüé® üíª      Bipin Thomasüé®      Abdulrahman Hishamüé®              Dakshitha Dissanayakaüé®      BADR KACIMIüé®      Alex Wangüé®      Maximüé®      GordonGrantüé® üíª      Ephrem Demelashüé®      JonOrcuttüé®              topdev10üé®      cookwellwebsiteüé®      xren935üé®      Nemo Frenkelüé®      MD SAIF ALAMüé®      Boris L√≥pez Arayaüé®      Larry Chiemüé®              Muhammad Bilal Ilyasüé®      AliMilaniüé® üíª      Suraj Sahaniüé®      FlyingSquirrelüé®      Erick Tijeroüé®      Jaskaran Kukrejaüé®      MichaelLüé®              MagicLegendüé®      Dereck Bearsongüé®      Pappu Kumar Pashiüé®      Venkata Kishore Tavvaüé®      Rafat Touqir Rafsunüé®      Snehesh Duttaüé®      Timo K√∂rnerüé® üíª              alexxxanüé®      GGJasonüé®      LeeAnna Ewingüé® ü§î      kamal Jyotwalüé®      Bob-Johnsüé® üíª üñã      yunussalmanlyitüé® üíª      chilcotüé® üíª              Jacky Liüíª üñã üé®      Sarthak Trivediüé®      Ayush Aggarwalüé® üíª      Nic Ballariniüé®      Luigi Zambettiüé® üíª      govindhaswinüé®      Addy Royüíª üé®              Akshat Tamrakarüé® üíª      Sai Bhargava Ramuüé®      Gurkanüíª      Spencer Hayes-Laverdiereüíª      Aniket Soniüíª      tanmay5792üíª      Dina Taklitüíª üé® üñã              Dushyant Singhüíª      Ravi Prakash Singhüíª      Nihal Joshiüíª      Guy Klagesüíª      Arvindüé® üíª      mujeeb91üíª      josercaüé® üíª              Prateek Agrawalüíª      Teoh Tze Chuin(„Çµ„É©)üíª üé®      Jayant Jainüíª      Ayush Sahuüíª      Hridya Krishna Rüíª üé®      Rahul Baliüíª üé®      S.ZHengüé® üíª üíº              Shriya Madanüé® üíª      mahalrupiüé®      Lucas Lermagneüé®      Jeff Deutschüé® üíª      Betoxx1üé®      Wingman4l7üé®      Martin Espericuetaüé®              Mh-Tahirüé®      Zdravko ≈†plajtüé® üíª      Ms3105üé® üíª üñã      Ambika Sidheswareüíª      mundogueroüíª      Darkus24üñã      Sou-786üñã üé®              Banurekhaüñã      ShiraStarLüé®      Ilya Komarovüé®      DemigodMsüñã üìñ      Mekha Hridyaüé® üîç      Andrey Safonovüé® üîç      Tommasoüé® üíª              Jessica Salbertüíª üé®      JAYANTH DOLAIüíª üé®      silverstroomüíª üé® üíº      Furkan Sayƒ±müíª üé®      Sukumar Chandrasekaranüé®      Yejin Parküé® üíª      Ali Nooshabadiüé® üíª              imitavorüé® üíª      Salih Kilicliüé® üíª      Marcelo Menesesüé® üíª      Anton Krekotunüé® üöß üñã üíª üìñ üíº      Arnav Sarmaüíª üí° üé®      meghatikuüíª üé®      Anshu Trivediüé®              Taylor Dorsettüíª üñã üé®      Havit Roviküíª      pushpapuneüíª üé®      Ramtin Radfarüé® ü§î üíº üíµ üíª üñã üí¨      Abdulmajeed Isaüíª üé®      vikassaxena02üé®      RobTablesüé® üíª üíº              Danielüé® üíª üíº üîç      Zahid Aliüíª üé®      Chad Chaiüíª üé®      Marco Biedermannüíª üé® üíº ü§î      Srinidhi Murthyüé®      Miao Caiüíª üé®      Dionicio Diazüé® üíª              Mir Monoarul Alamüé®      Shawn Ohnüíª üé®      Amanbolat Balabekovüé® üíª      black-mamba-codeüíª      Jian-forksüé® üíª      shivani patelüé®      Akash Chowrasiaüé®              yairg98üé®      Jay Gajjarüé®      coolerboolerüíª      Md Zinnatul Islam Morolüé®      shresthashok550üé® üìñ      Alan Pallathüìñ      Adrian Wongüíª              vsDizzyüíª üé®      Frex Cuadilleraüé® üíª      ashish570üíª üé®      ruchpeanutsüíª üé®      Artmasqueüé® üíª      Amirhossein Mojiri Foroushaniüé®      forüíª üé®              Lukeüé® üíª      Hector Espinozaüé®      Adri√°n Buenfilüé® üíª      Amit Kumarüé®      schoppfeüé® üíª      Sofiyal Cüé® üíª      spitlisküíª üé®              PRAVIN SHARMAüé®      NIDZAAA1üé® üíª      John Maiüé® üíª      kimsoyeongüé®      Dona Ghoshüíª      Ryan Hillüé® üíª      j42züé® üíª              Ashish Sangaleüé® üíª      Derek Yangüé® üíª      mohsinmsmüé® üíª      Gokulkrish2302üíª      Bhaavisheküíª üé®      Louis Liaoüé®      sengc92üé® üíª              Alex Marvinüé®      Balkrishna Bhattüé® üíª      Evaldas Lavrinoviƒçiusüé® üíª      Adam Erchegyiüé® üíª      Truman Hungüé® üíª      rzamora11üé®      gaurav0224üé®              Lee GyeongJunüé®      Mireküé® üíª      surajm245üé®      ArisLaodeüé® üíª      RaviDhoriyaüé® üíª      sarai-84üé® üíª      Vishnuüé® üíª              Muhammad Minhajüíª      Chandrika Debüé® üíª      Gitgit101-bitüíª üé®      Hedi Sellamiüíª üé®      saurabhvaish93üíª üé®      Nikola Begovicüíª üé®      Wangüíª üé®              Manuel Eusebio de Paz Carmonaüé®      Basim Al-Jawaheryüé® üíª      RAJA AHMEDüé® üíª      Abhik Lodhüíª      Md. Pial Ahamedüíª üé®      Hassan Shahzadüíª üé®      Christian Sosa Gagoüíª              Hasnain Rasheedüíª üé®      T-Radfordüíª      dahiyashishüíª üé®      RahulSharma468üíª üé®      Jumpod Plekhongthuüíª üé®      Thomas Young-Audetüíª üé®      VinayagamBabuüíª üé®              Deniz Ko√ßüíª üé®      Azhar Khanüíª üé® üñã üìñ üî£ üöß      Jacob Shortüíª üé®      Uchimura85üíª üé®      Leo Nugrahaüíª üé® üìñ      Mujtaba Mehdiüìñ üñã      Jim-dsüíª üé®              Sreehari Küíª üé®      Florian Martinezüíª üé®      Aaronüíª üé®      apoageüé®      Ignacio Guillermo Martinez üíª üé®      AirlineDogüé® üíª      Mekelüé® üíª              hmosharrofüé® üíª      Ben Emamianüíª üé®      babesharküíª üé®      Leonardo Jaquesüíª üé®      Stefanos Apkarianüíª üé®      Ayhan Albayraküíª üé®      KidusMTüíª üé®              hectormarroquin20üíª üé®      Edelweiss35üíª üé®      MihaiDüíª üé®      AnveshReddyAnnemüíª üé®      Hyunjae Parküíª üé®      Rajiv Albinoüíª üé®      Atishayüíª              Yusuf Naheemüé®      Winduüé® üíª      Superv1sorüíª üé®      Karine (:üé® üíª      Eduard Pechüé® üíª      jjeshwaniüé® üíª      Steveüé® üíª              Aleigh Ohslundüíª      Abhinav Sumanüé® üíª      Hamza Ehtesham Farooqüé® üíª      IamNotPeterPanüíª üíµ üé®      Cetgerüé®      pkonopackiüé®      Yang Yangüé® üíª              Muhammad Shoaib Sarwarüíª      Murilo Henriqueüíª üé®      emilianoalvzüé® üíª      Sumana Sahaüé® üíª      Yurii17Küé® üíª      Rupesh Bhandariüé® üíª      salmos3718üíª              John Bakerüé® üíª      SanjaySathirajuüé® üíª      Donat Kabashiüé®      Arul Prasad Jüé® üíª      Qi Chenüé® üíª      Maksym Dmyterkoüé® üíª      ilovepullrequestsüíª              Samira Malekiüé® üíª      NIKITA MAHOVIYAüíª      jesuisdev.Netüé® üíª      Ashraf Nazarüé®      Naveed Ahmadüé®      Ajmain Naqibüé® üíª      Avinash Tingreüíª üé®              nicktidsüé®      Keith Dinhüíª üé®      Andr√© Ferreiraüíª üé®      eliottkespiüíª üé®      praveenpnoüíª üé®      vitowidigdoüíª üé®      Devesh Pratap Singhüíª üé®              Dario Rodriguezüíª üé®      charmander_didiüíª üé®      PHBasinüíª üé®      Ritvik Singh Chauhanüíª üé®      Riya P Mathewüíª üé®      Stephanie Cherubinüíª üé®      BenitesGuiüíª üé®              FarikBearüíª üé®      Dmytro Havrilovüíª üé®      Parvesh Monuüíª üé®      Dipen Panchasaraüíª üé®      gudataüé® üíª      gawadeditorüíª üé®      Kirill Taletskiüé® üíª              Saajanüé® üíª      Kushagra Süé® üíª      Oanh Leüé® üíª      Frane Medvidoviƒáüé® üíª      Yormanüé® üíª      Bill Chanüé® üíª      Pratik Lomteüé® üíª              LOC LAMüé® üíª      TUSAR RANJAN MAHAPATRAüíª      BhargavKanjarlaüíª      Karel De Smetüíª üé®      sidisanüé®      ygnzayarphyoüé® üíª      svansteelandtüíª              Kebechetüé®      Daniel Selvan Düé® üíª      Mahdi Razaviüé® üíª      Niklas Tiedeüíª üé®      narutubaderddinüíª üé®      dylandhoodüíª      Dheeraj Guptaüíª              Pieter Claerhoutüíª üé®      Shivam Agnihotriüíª      RanjithReddy-Narraüíª      Nikita Wadhwaniüé® üíª      rsholokhüíª üé®      Ayaan Hossainüíª üé®      Rajesh Swarnaüíª              Deniz Etkarüé® üíª      pro335üíª üé®      Jakub Radziküíª üé®      Hamza Khanzadaüíª      ARNONüé®      Vikram Singhüíª      Shoxruxbeküíª üé®              Amit Khatriüíª üé®      Wali Ullahüé® üíª      Amit11794üíª üé®      metis-macys-66898üíª üé®      Faisal Maqboolüé® üíª      Kumar Neerajüíª üé®      Maurizio Mariniüé® üíª              Saket Kothariüé® üíª      Szymon Zborowskiüé® üíª      iks3000üé® üíª      Ehsan Seyediüé® üíª      vanekbrüé® üíª      Princy_Müé® üíª      Shijie Zhouüé® üíª              lakshyamcs16üé® üíª      Filippo Faccoüé® üíª      mendel5üé® üíª      Patryküé® üíª      VishwaSanganiüé® üíª      Alvin Zhaoüé® üíª      Lazar Gugletaüé® üíª              vmichoüé® üíª      Sikandar Aliüé® üíª      Raja Babuüé® üíª      faizajahanzebüíª      Guil_AiTüé® üíª      Kushal Dasüé® üíª      Luis Bonillaüé® üíª              jovan1013üé® üíª      Damianüé® üíª      Yash Guptaüíª      lolcatnipüé® üíª      Ikko Ashimineüé® üíª      Farukhüé® üíª      Moksedulüíª üé®              Navneet Kumarüé® üíª      Saqib AlMaliküíª      fahimrahmanüé® üíª      vaibhav patilüé® üíª      Rahul Madanüé® üíª      kartik Kaklotarüé® üíª      ASAHI OCEANüé® üíª              Daniel Jungbluthüé® üíª      Rajdeep Singh Boranaüé® üíª      ankitha19üíª      Linh Tranüíª      islamarrüíª üé®      Mohamed Sabithüé® üíª      Miguel Angel Cruz Acostaüé® üíª              Adebayo Ilerioluwa üé®      Markusüé® üíª      dkonyayevüé® üíª      Kevin A Mathewüé® üíª      David Meloüé® üî£      DFW1Nüé® üíª      Sohaib Ayubüé® üíª              Navvyüé® üíª      bloodiator2üé® üíª      Hanjiüé® üíª      arthur74üé® üíª      Sri Subathra Devi Büé® üíª      Akif Aydogmusüé® üíª      Umer Javaidüé® üíª              Norio Umataüé® üíª      Gazi Hasan Rahmanüé® üíª      Keith Nguyenüé® üíª      Megalomaniacüé® üíª      ShankS3üé® üíª      Farhad Alishovüé® üíª      Ronak J Vanpariyaüé® üíª              azrael0learzaüé® üíª      Pavel Rahmanüé® üíª      chuabernüé® üíª      Rahul Tirkeyüé® üíª      Ruslan Besüé® üíª üí° üöß üñã üî£ üöá      Bohdanüé® üíª      Juzdzewskiüé® üíª              Grigor Minasyanüé® üíª      alvintwcüé® üíª      Anand Natarajanüé® üíª      Kashan Aliüé® üíª      Thomas Meshailüé® üíª      Son Phamüé®      Michael Frenchüí°              Yash Mishraüìñ      Miguel Rodriguezüé® üíª      Philipp Bachmannüé® üíª      sunnyüé® üíª      Siddharth Chatterjeeüé® üíª      Michael Naghavipourüé® üíª      Sahil Gargüé® üíª              MicroLionüé® üíª      wctwcüé® üíª      Rohan Sharmaüî£      AshishBodlaüé® üíª      Taras Pysarskyiüé® üíª      Luqman Bello O.üé® üíª      DyingDownüé® üíª              Diego Chapedelaineüé® üíª      Richleeüé® üíª      Asif Habibüé® üíª      Mazharul Hossainüé® üíª      toniüé® üíª      Pragyanshu Raiüé® üíª      Matthew Ellerüé® üíª              AbhiBijuüé® üíª      Roman Zhornytskiyüé® üíª      Lucas Caminoüé® üíª      Jo√£o Vitor Casarinüé® üíª      Evgeniy Shayüé® üíª      Ehsan Barkhordarüé® üíª      Gabrielüé® üíª              Shibu Mohapatraüé® üíª      Pavel Kirkovskyüé® üíª      Tahir Gulüé® üíª      imDevSalmanüé® üíª      Jordan Donaldsonüé® üíª      js-venusüé® üíª      Faisal Shaikhüé® üíª              ashishbpatilüé® üíª      Tri Leüé® üíª      tomtreffkeüé® üíª      Salah Eddine Lalamiüé® üíª      Mattias Xuüé® üíª      Manas Guptaüé® üíª      wolfsong62üé® üíª              Mehdi Mirzaeiüé® üíª      Van Ba Khanhüé® üíª      Sel Embeeüé® üíª      Suvradip Paulüé® üíª      Shariqueüé®      Seabassüé® üíª      Penny Liuüé® üíª              jatinder bholaüé® üíª      misterqbitüé® üíª      Daniel-VS9üé® üíª      Shruthiüé® üíª      beefydogüé® üíª      Suraj Kumarüé® üíª      hrishikeshpsüé® üíª              Sudarshanüé® üíª      Divyanshüíª üé®      Zyaireüé® üíª      Omar Belkadyüé® üíª      alexiismuaüé® üíª      Eduarda Alvesüé®      pycoachüé® üíª              Ruhulüé® üíª      pmoustopoulosüé® üíª      Lee Hui Tingüíª üé®      bodi1981üé® üíª      Devaraat Joshiüé® üíª      Johnnyüé® üíª      rogue-coderüé® üíª              viiktrüé®      Lalit Mohanüíª      Jo√£o Sousaüíª      Ë®ÄËëâ‰πãÈùàüíª üé®      RJLABSüíª      brittney0522üé® üíª      shamüé® üíª              Glenn Goossensüíª üé®      Cyber Hawküé® üíª üñã üíº      Ankit Yadavüé® üíª      verbalityüíª      Mohammed Siddiquiüé® üíª      AdamKaczor6250üé® üíª      Ram√≥n Martinez Nietoüé® üíª              Grzegorz Dziubaküé® üíª      Ayoub BERDEDDOUCHüé® üíª      nikola-fadvüé® üíª      Akarsh Agrawalüé® üíª      Mitra Mirshafieeüé® üíª      Parker Stephensüé® üíª      alrenee99üíª              Karthick Vankayalaüíª      Iryna üé® üíª      palanugrahüíª      Gwinbleindüé® üíª      Randy Bobandyüé® üíª      Bek Rozikoffüíª      davnguyeüé® üíª              Neel Patelüíª      ehudbeharüé® üíª      nicholas-cod3rüé® üíª      michaelfrankiüé®      Esther Whiteüé® üíª      prathmeshpbüé® üíª      Victor Linüé® üíª              Christine C. Yinüé® üíª      GitLearner-beginüé® üíª      Mesrop Andreasyanüé® üíª      Nathan Garciaüé®      commonsw04üé® üíª      Md. Rashad Tanjimüé® üíª      Ali Maleküíª              PAODLTüé® üíª      Nikhil Bobadeüé® üíª      hyuckjin21üíª      Itasha Modiüé® üíª      Nikitha Reddyüé® üíª      Mahshooq Zubairüé® üíª      Subham Dasüíª              Onkar Birajdarüé® üíª      Nick Titomichelakisüé® üíª      Christian Leo-Pernoldüé®      Matthew Marquiseüé® üíª      baronfacüé® üíª      Abhishek Tilwarüé® üíª      DavidsDvmüé® üíª              Parth Parikhüé® üíª      Hector Castroüé® üíª      Rikky Arisendiüé® üíª      Ali HamXaüé® üíª      Frank.wuüé® üíª      Jatin Kumarüé® üíª üìñ      masterHAWK99üé® üíª              Pushp Jainüé® üíª      Ashutosh Routüé® üíª      Atharva Deshpandeüé® üíª      Teodor Ciripescuüé® üíª      Anmol Bansalüé® üíª      Nikhil Kumar Macharlaüé® üíª      Dexterüé® üíª              Aaronüé® üíª      Yogita Jaswaniüé® üíª üìñ üñã      StoryDevüé® üíª      Mesut Doƒüansoyüé® üíª      Paras Dhawanüé® üíª      Emanuel Zhupaüé® üíª      Aaradhyaa717üé® üíª              jaacko-torusüé® üíª      mBlacküíª      kalrayashwinüìñ üñã üé® üíª      Seraphüíª üé®      ZhiHong Chuaüé® üíª      Amsal Khanüé® üíª üìñ üñã      Raghav Rastogiüé® üíª              Tzilaüìñ      Shahriar Nasim Nafiüìñ      AGüé® üíª      Mojtaba Kamyabiüé® üíª      Ahmad Abdulrahmanüé® üíª      Eclipseüé® üíª      Anshu Palüé® üíª              Denisüé® üíª      mehmet sayinüìñ      WebDEVüé® üíª      Sam Komesarooküé® üíª      Kiran Ghimireüé® üíª      Joshua Davisüé® üíª      Muhammad-Huzaifa-Siddiquiüíª              tobeornottobeadevüé® üíª      VAIBHAV SINGHALüé® üíª      Keiran Pillmanüé® üíª      Max Donchenkoüé® üíª      sgonsalüé® üíª      diksha137üé® üíª      Vigneshüé® üíª              Gabriel Fran√ßaüé® üíª      Josephüé® üíª      Bruno Rafaelüé® üíª      vcamarreüé® üíª      thibault kettererüé® üíª üöß      VictorGonzalezToledoüé® üíª      1911510996üé® üíª              inviduüé® üíª      Nurul Furqonüé® üíª      David Asbillüé® üíª      Niko Birbilisüé® üíª      Mugundan Kottursureshüé®      agrsachin81üé® üíª      Othmane El Alamiüé® üíª              Syed Atif Aliüé® üíª      lakhanjindamüé® üíª      youssef hamdaneüé® üíª      starfaerieüé® üíª      rodrigo0107üé® üíª      Micha≈Ç Gralaküé® üíª      Jewel Mahmudüé® üíª              cwilson830üé® üíª      buun1030üé® üíª      Reda-ELOUAHABIüé® üíª      saad-aksaüé® üíª      Emdadul Haqueüé® üíª      PROCWüé® üíª      cccppp1üé® üíª              Joanna Baileüé® üíª      Ahmed Saberüé® üíª      Masoud Keshavarzüé® üíª      mortazavianüé® üíª      Aniket Pandeyüé® üíª      Vijay Nirmalüé® üíª      Daniel Carvalloüíª              menaechmiüé® üíª      azenyxüé® üíª      Ahmet √ñzrahatüé® üíª      Abdulrahman Abouzaidüé® üíª      jmgnorbecüé® üíª      palinko91üé® üíª      Laisson R. Silveiraüé® üíª              BHARGAVPATEL1244üé® üíª      Candide Uüé® üíª      Sitansh Rajputüé® üíª      Houda Mouttalibüé® üíª      MumuTWüé® üíª      Suave Bajajüé® üíª      Mehdi Parsaeiüé® üíª              Dinko Osreckiüé® üíª      Dhia Djobbiüé® üíª      Mahmoud Galalüé® üíª      Anh Minhüé® üíª      Suvesh Küé® üíª      Petar Todorovüé® üíª      Alexander Nguyenüé® üíª              Morteza Jalalvandüé® üíª      Claudson Martinsüé® üíª      Matt Jacobsonüé® üíª      Rafael Belokurowsüé® üíª       Thomas Gamaufüé® üíª      Rishabh Mahajanüé® üíª      rakeshpdgupta23üé® üíª              Shashidharknaiküé® üíª      taleleumaüé® üíª      Florian B√ºhlerüé® üíª      Raihan Bin Wahidüé® üíª      MOHAMMED NASSERüé® üíª      federicoüé® üíª      Andre Violanteüé® üíª              tcunningham98üé® üíª      Jan Grie√üerüé® üíª      Serkan Alcüé® üíª üñã      Jez McKeanüé® üíª      meisam alifallahiüé® üíª      Mehul Thakkarüé® üíª      Saksham Soniüé® üíª              Pedro Peregrinaüé® üíª      Mintu Choudharyüé® üíª      lucianmoldovanuüé® üíª      John C. Scottüé® üíª      Mia D.üé® üíª      EwenBernardüé® üíª      M. Reza Nasirlooüé® üíª              Jay Agrawalüé® üíª      DeShayüé® üíª      Jay206-Programmerüé® üíª      Elenderüé® üíª üñã      Bobby Byrneüé® üíª      Pirciüé® üíª      Hasanuzzamanüé® üíª              Josh Kautzüé® üíª      Brofarüé® üíª      Mina Karamüé® üíª      Duncan O Nüé® üíª      Sean Tumulak-Nguyenüé® üíª      Artur Trze≈õniewskiüé® üíª      JJaammeessMüé® üíª              shubham agarwalüé® üíª      Michele Righiüé® üíª      Panagiotis Kontosüé® üíª      sumitbathlaüé® üíª      Deepak Mathurüé® üíª      Juho Nyk√§nenüé® üíª      Santiago Gonz√°lez Siordiaüé® üíª              SRIJITA MALLICKüé® üíª      Samriddhi Büé® üíª      Nitzan Papiniüé® üíª      Mario Sanzüé® üíª      Crab^4üé® üíª      Pabloüé® üíª      Gordon Pham-Nguyenüé® üíª              Kristofferüé® üíª      chrisblachüé® üíª      G√°borüé® üíª      Linaüé® üíª      Harrison Wattsüé® üíª      Mario Petriƒçkoüé® üíª      Ben8120üé® üíª              Giovannaüé® üíª      Minal Ahujaüé® üíª      mossfarmerüé® üíª      ThaC0derDreüé® üíª      itwareüé® üíª      Michael Walkerüé® üíª      Tom Jacob Chirayilüé® üíª              Sachin Kumarüé® üíª      adi-rayüé® üíª      Dr-Blank-altüé® üíª      Bogdan Cazacuüé® üíª      Gilson Urbanoüé® üíª      Ninaüé® üíª      Anthonyüé® üíª              manushimjaniüé® üíª      Michael Reyesüé® üíª      Rachel Kennellyüé® üíª      Aakash Gargüé® üíª      Daniel Livingstonüé® üíª      alexrojcoüé® üíª      Minh Nguyenüé® üíª              Mahesh Dattatraya Babarüé® üíª      Jin Zihangüé® üíª      Bikramjit Gangulyüé® üíª      QuestionableGuiseüé® üíª      liq19chüé® üíª      Bruno Rochaüé® üíª      Anand Dyavanapalliüíª üñã              crucian-afküé® üíª      0xgainzüé® üíª      weirdfshüé® üíª      Valan Baptist Mathuranayagamüé® üíª      Paul Kaeferüé® üíª      Yu-Hsiang Wangüé® üíª      Javad Adibüé® üíª              davidliu0930üé® üíª      Achilleas John Yfantisüé® üíª      Omkar Shivadekarüé® üíª üñã üêõ      ToanTranüé® üíª      Gautam Naiküé® üíª      Marcüé® üíª      twix20üé® üíª              Kristian S.üé® üíª      Aleksey Khoroshilovüé® üíª      arjunsrsrüé® üíª      Ali Haiderüé® üíª      Trisha Dringüé® üíª      Andre Marzuloüé® üíª      Krishna Modiüé® üíª              Rosemary Liüé® üíª      Alex Wellerüé® üíª      Tam Nguyenüé® üíª      aquintelaoliveiraüé® üíª      Norbert Brettüé® üíª      rocsogdüé® üíª      0nyrüé® üíª              rethkevinüé® üíª      RickHeadleüé® üíª      Leandreüé® üíª      Natnael Sisayüé® üíª      sbbuüé® üíª      waelüé® üíª      Fabricio Tramontano Piriniüé® üíª              Alexander Stoyanovüé® üíª      Dezx20üé® üíª      southparkkidsüé® üíª      bmstarüé® üíª      kiagamüé® üíª      Juan Castilloüé® üíª      FFenneüé® üíª              Jose Toledoüé® üíª      Pat McGhenüé® üíª      Eiko Wagenknechtüíª üñã üî£      Alan Chalmersüé® üíª      Jean Didierüé® üíª      Andyüé® üíª      pestadieuüé® üíª              Kanishka Chakrabortyüé® üíª      Nandhaüé® üíª      Vahid Mafiüé® üíª üî£ üñã üíº      Akshay Ashoküé® üíª      0x08üé® üíª      Sandeep Mishraüé® üíª      Evann Regnaultüé® üíª              Lenny Zeitounüé® üíª      Eden Boaronüé® üíª      TroyBTCüé® üíª      Aby Sebastianüé® üíª      Matthew Dunnüé® üíª      ckulloüé® üíª üñã üî£      Mohamed Mamdouhüé® üíª              Youssef Bazinaüé® üíª      Frederico K√ºckelhausüíª      Nushan Kodikaraüíª      Zach Cooperüíª      Royüé® üíª      Saurav Panchalüé® üíª      totallynotdavidüé® üíª              goosepirateüé® üíª üí° üíº      KAUTHüé® üíª      Hari Kiran Vusirikalaüé® üíª      Sounak Deyüé® üíª      ziaüíº üé® üíª      Reza Davariüé® üíª      AkshayAjaykumarüé® üíª              x24870üé® üíª      Ko Phoneüé® üíª      Nabstar3üé® üíª      Mateuszüé® üíª      Yunus Emre Emiküíª      Abhinav Sinhaüé® üíª      Hung Nguyenüé® üíª              Maselinoüíª      Shuktika Mahantyüíª      Miko≈Çaj Gawro≈Ñskiüé® üíª      Hussein Habibi Juybariüé® üíª      Sean-McArthurüé® üíª      Osman F Bayramüé® üíª      Benjamin Thomas Blodgettüé® üíª              Chuanlong-Zangüé® üíª      julianüé® üíª      franciscoüé® üíª      aalihhiader9211üé® üíª      Muhammad Zunairüé® üíª      Liyaüé® üíª      BegadTareküé® üíª              etorobotüé® üíª      Hussam Khanüé® üíª      Saikat Chakrabortyüé® üíª      Nicholas Quislerüé® üíª      Evang Poulüé® üíª      Gregg Lindüé® üíª      Deepak Kumarüé® üíª              Callum Leslieüé® üíª      Curtis Barnard Jr.üé® üíª      Deepanshukaimüé® üíª      Manthan Anküé® üíª      hossein varmazyarüé® üíª      Brayan Mu√±oz V.üé® üíª      Kamil Rasheed Siddiquiüíª üé®              mutt0-dsüé® üíª      egbertjküé® üíª      Majid Zojajiüé® üíª      Sean Chenüé® üíª      Herbert Milhommeüé® üíª      A3üé® üíª      Killianüé® üíª              Coakeowüé® üíª      ‡æÖ‡ºª «¨…Äƒß ‡ºÑ‡ºÜ‡Ωâüé® üíª      Pratik Solankiüé® üíª      Sunnyüé® üíª      ssgeüé® üíª      Bernat Frangiüé® üíª      Jeevan Rupachaüé® üíª              amirandapüé® üíª      Deepakshi Mittalüé® üíª      Abhijeet Paridaüé® üíª      Khaled Riyadüé® üíª      Pratap paruiüé® üíª      Prajit Pandayüé® üíª      PipeSierraüé® üíª              Collins Odenüé® üíª      Kshitij Dwivediüé® üíª      Bernardia Vitri Arumsariüé® üíª      √ñmer Faruk Ta≈üdemirüé® üíª      Spencer Stithüé® üíª      Porsche Rodjanasaküé® üíª      Shakeel Sharifüé® üíª              Victoria Chengüé® üíª      Denisüé® üíª      Anand Prakash Tiwariüé® üíª      danijeljw-rpcüé® üíª      Ahmed H Ebrahimüé® üíª      Virginia Gardnerüé® üíª      Jhironsel Diaz A.üé® üíª              Yunus Kidemüé® üíª      MTüé® üíª      Dinesh Zaldekarüé® üíª      adiüé® üíª      Farhan Shaikhüé® üíª      Elvis Salvatierraüé® üíª      Kaushik-Iyerüé® üíª              HocAndresüé® üíª      VictorHugoAguilarAguilarüé® üíª      Murat Can Abayüé® üíª      Chrisüé® üíª      Shivam7-1üé® üíª      Paipai13üé® üíª      Shambles-ioüé® üíª              Abhishek K Müé® üíª      Ezequiel Cuevasüé® üíª      Plamen Ivanovüé® üíª      Yujiüé® üíª      Jean-Philippe Leb≈ìufüé® üíª üî£      Naufanüé® üíª      jadnovüé® üíª              vaxtangensüé® üíª      subashkonar13üé® üíª      Rushi Javiyaüé® üíª      Mert G√ºlüé® üíª      Lilyüé® üíª      Kalinoffüé® üíª      Joel Tonyüé® üíª              Peterüé® üíª      Roozbeh Zareiüé® üíª      Shenüé® üíª      Joonsoo.LEEüé® üíª      Fede.Bregüé® üíª      Rui Costaüé® üíª      Jo√£o Gustavo Bispoüé® üíª              Sami-Iüé® üíª      Tsvetoslav Tsvetkovüé® üíª      Olabode Olaniyi Davidüé® üíª      theRuslanüé® üíª      leighbozüé® üíª      Frank Sossiüé® üíª      Tomasz Adamskiüé® üíª              Mansoor M. Sathirüé® üíª      Golamrabbi Azadüé® üíª      Nahian Ahmedüé® üíª      Rafael de Jesus Silva Monteiroüé® üíª      Odionyebuchukwu Judeüé® üíª      The Nithin Balajiüé® üíª      Knackiiüé® üíª              vittorio-giattiüé® üíª      Guilherme de Carvalho Lima Rebou√ßasüé® üíª      aaref shamiüé® üíª      Andrey Dryupinüé® üíª      Muhanned Nomanüé® üíª      Jan Silvaüé® üíª      emanuele-emüé® üíª üñã              Sanjay TMüé® üíª      Joe Markberg / code editorüé® üíª      Julien Quiaiosüé® üíª      Eric Ramirez Santisüé® üíª      Müé® üíª      Malcataüé® üíª      Athul Muralidharanüé® üíª              Dariusz Ochotaüé® üíª      CHANDAN CHOUDHURYüé® üíª      Deepüé® üíª      Ahmet ƒ∞stemihan √ñZT√úRKüé® üíª      TIMüé® üíª      jakeg814üé® üíª      Leonidosüé® üíª              Abhinandu V Nairüé® üíª      charafeddine01üé® üíª      Jasperüé® üíª      Manish Goyalüé® üíª      SATYAM_SINGHüé® üíª      Fourüé® üíª      Vaishnavi Amira Yadaüé® üíª              ShriKrushna Bhagwatüé® üíª      Rohit Nandagawaliüé® üíª      felipeüé® üíª üöß üñã ‚úÖ üßë‚Äçüè´      Saurabh Mudgalüé® üíª      szenadamüé® üíª      Shubhendra Singhüé® üíª      Yoosuf Sayyidüíª üé®              G√ºven √áetinerlerüé® üíª      Luke Jefferiesüé® üíª      Chrisüé® üíª      L√∫cio Aguiarüíª      Enuma029üíª      yktsang01üíª      maximumn3rdüé® üíª              Jon Galleteroüé® üíª      Thaddeus  Thomasüé® üíª      Aakash Kumarüíª üé®      Ali Müé® üíª      OskyEdzüé® üíª      Ravi Guptaüé® üíª      Rafa Raizerüé® üíª              Abdullah Al Muzakiüé® üíª      Rahul Faujdarüé® üíª      Abhishek Vermaüé® üíª      Ashutosh Shindeüé® üíª      Ganesh Raiüé® üíª      StefanTrpkovicüé® üíª      Erik Blancaüé® üíª              Vedant Madaneüé® üíª      Antra Tripathiüé® üíª      Ethan Knightsüé® üíª      Alexandru Boncutüé® üíª      Pablo Bandinoplaüé® üíª üöß üñã      Robz-99üé® üíª      Harpal Singhüé® üíª              paulboundy99üé® üíª      Mubashir Ahmedüé® üíª      Rohan Hariüé® üíª      Erik Henrique üé® üíª      Leandro Matheusüé® üíª      Deepaküé® üíª      AlishaSinghüé® üíª              Lynn Latt Yatiüé® üíª      San Shweüé® üíª      SKRüé® üíª      msbunnyjaguarüé® üíª      Mohamad Zabiullaüé® üíª      Hatim Zahidüé® üíª      Rauzan Sumaraüé® üíª              Hosein1358üé® üíª      Mohitüé® üíª      Aliüé® üíª      Avinash1765üé® üíª      Sai Teja Madhaüé® üíª      Monsur Ahmed Shafiqüé® üíª      xuxianjin-devüé® üíª              chetnaüé® üíª      Gul Zaibüé® üíª      Nataliaüé® üíª      Dion√≠sio Bragaüé® üíª      Pritish Rajpurohitüé® üíª      incanloveüé® üíª      Innocentüé® üíª              Devin Almonorüé® üíª      antonyveyreüé® üíª      Beltz Anhxtonüé® üíª      Mehdiüé® üíª      Muhammad Usmanüé® üíª      Patrick Dantasüé® üíª      Tak Vannaküé® üíª              Ramzi RADDAOUIüé® üíª      Konstantin-Glukhovüé® üíª      ugurobanüé® üíª      Humberto Alvesüé® üíª      JuangZendratoüé® üíª      James Oluwaleyeüé® üíª      Wasi Sadmanüé® üíª              Pavle Mijatovicüé® üíª      Luiz H. S. Bispoüé® üíª      –°—É—Ö–∞—Å –î—Ö–æ–ª–∑üé® üíª      Alvaro Trujilloüé® üíª      Everton üé® üíª      jfrozasüé® üíª      Shuaaib Badranüé® üíª              Shivam Jhaüé® üíª      Mohamed Tayehüé® üíª      Makendran Güé® üíª      mayank singh tomarüé® üíª      hossam sadanyüé® üíª      Harshbardhan Singhüíª üé®      Fawad Jawaid Maliküé® üíª              Tina Lacatisüé® üíª      TeddyCuoreDolceüé® üíª      bchooxgüé® üíª      Alisha Takkarüé® üíª      Gianluigiüé® üíª      Mehran Javaherianüé® üíª      Benjamin Ololade Adedokunüé® üíª              Md. Abdul Mutalibüé® üíª      Aadil Arsh.S.Rüé® üíª      J. Nathan Allenüé® üíª      Kieran Krugüé® üíª      Seth Addoüé® üíª      Satvik Singh Rathoreüé® üíª      dangothüé® üíª              Maximüé® üíª      Phuong-Cat Ngoüé® üíª      Frenchtoast0üé® üíª      Rakshithüé® üíª      Vaibhav Aroraüé® üíª      zghpüé® üíª      Bedovanüé® üíª              chiaramistroüé® üíª      him2016üé® üíª      HarshitSachdevaüé® üíª      Sadaf Saleemüé® üíª      Aaroh Srivastavaüé® üíª      eloygplazaüé® üíª      Gaurav Kumar Vermaüé® üíª              AndreaCUSüé® üíª      Simranüé® üíª      Prashant Bhapkarüé® üíª      mhaendlerüé® üíª      Gauri Maheshwariüé® üíª      4Lajfüé® üíª      Tanmoy Senguptaüé® üíª              Sharad Tripathiüé® üíª      Niraj Chavanüé® üíª      Luisa Gualdaüé® üíª      Monika-Sivakumar-3üé® üíª      harryfensomeüé® üíª      Shubham Choubeyüé® üíª      Ashwini Patilüé® üíª              cleversonliraüé® üíª      Nurmukhammedüé® üíª      workspace-utkarshüé® üíª      Santosh Phadtareüé® üíª      Prashant Warghudeüé® üíª      Umang Dakhüé® üíª      Shalini Chavanüé® üíª              vinit gurjarüé® üíª      Vishal Kumarüé® üíª      Wonhyeong Seoüé® üíª      Achwale Prajwal Namdevraoüé® üíª      Ankan Banerjeeüé® üíª      bhaumikankanüé® üíª      JamesMacroZhangüé® üíª              Pedro Lopesüé® üíª      diaüé® üíª      tayyabhussain2910üé® üíª      Rajdeep Shrivastava üé® üíª      Mukul Kumarüé® üíª      Mayank Nüé® üíª      jdeluccaüé® üíª              Sneha Mittalüé® üíª      Sarika Kushwahaüé® üíª      farzad-khbüé® üíª      Elijah Shackelfordüé® üíª      The-Only-Raminatorüé® üíª      Keerthana Kasthurilüé® üíª      Viachaslau Auchynnikauüé® üíª              Mohammad Osman Rasooliüé® üíª      mvedovatoüé® üíª      Sonali Rajputüé® üíª      Isha Dheküé® üíª      Ramshad Cheriyeri Peediyakkalüé® üíª      Micahüé® üíª      gauravshukla2203üé® üíª              sndmurthyüé® üíª      Shivam-Singhüé® üíª      M. Ammar Khanüé® üíª      chandolakulüé® üíª      bhatnagar221üé® üíª      Adrian Nie≈õciurüé® üíª      nezi311üé® üíª              scottajevansüé® üíª      Marcelo Antunes Soares Fantiniüé® üíª      Axel De Acetisüé® üíª      Drishti Sahüé® üíª      VipulDhillonüé® üíª      Urmi Janaüé® üíª      Ayush Mokalüé® üíª              Damola Olutokeüé® üíª      Maxüé® üíª      Lakshmi Nüé® üíª      ArtemRevaüé® üíª      Ujjwal Aggarwalüé® üíª      Moüé® üíª      Brianüé® üíª              chamleyüé® üíª      Simone Baptisteüé® üíª      Shekhar Thakurüé® üíª      Smithüé® üíª      codernoob1üé® üíª      lok84üé® üíª      Tobias Riemenschneiderüé® üíª              Tharsanan1üé® üíª      ANURAG SINGHüé® üíª      Yash Santüé® üíª      Krishiv Patelüé® üíª      GGGalaxyüé® üíª      pardeepdhillon661üé® üíª      anujd64üé® üíª              Pedro Pereiraüé® üíª      Master_Saptaküé® üíª      SURANJAN DASüé® üíª      Tripura kantüé® üíª      shabzkhanüé® üíª      Mustafa Poyaüé® üíª      Roshan Jhaüé® üíª              GuillaumeLarueüé® üíª      Tomasz Rodaküé® üíª      Junil Kimüé® üíª      Surbhi Mayanküé® üíª      Nemanja Lekicüé® üíª      HemantMalokarüé® üíª      Felipe M. L√≥pezüé® üíª              bibliofiloüé® üíª      GauthamG2üé® üíª      02_tüé® üíª      Yusuf Abdul-razaqüé® üíª      Vladimirüé® üíª      Sai Chandra Küé® üíª      Soroush Bonabüé® üíª              Giide0nüé® üíª      GGüé® üíª      D√°ger Z√∫√±igaüé® üíª      rsk2üé® üíª      Storozhev DJüé® üíª      Jeevanüé® üíª      Andy Johnsonüé® üíª              An√≠bal Pozoüé® üíª      Jovane de Castroüé® üíª      Muhammad Hamza Amirüé® üíª      tharaka-mtsüé® üíª      Ali KHYARüé® üíª      Caio Araujoüé® üíª      Oscar Dyremyhrüé® üíª              artealityüé® üíª      Daniel Drexlmaierüé® üíª      Marco Montiüé® üíª      mikeycrystalüé® üíª      Veljanovskiiüé® üíª      Ivan Gorbachevüé® üíª      Sahil Rawatüé® üíª              Hasitha Sunethüé® üíª      Yerko Vera Lezamaüé® üíª      Ivan Penchevüé® üíª      Tanver Islam Tonmoyüé® üíª      Xun Caoüé® üíª      Nayan Babariyaüé® üíª      Priyanshu Mauryaüé® üíª              Dylan Tintenfichüé® üíª      Ron Straussüé® üíª      Mohammed AlBannaüé® üíª      Mukund Müé® üíª      Franklin Ohaegbulamüé® üíª      Nisarg Shahüé® üíª      Unik Dahalüé® üíª              Readilyüé® üíª      Alexandre Poitevinüé® üíª      Scaramirüé® üíª      Pruthviüé® üíª      Kalmanqüé® üíª      Alfatah Nesabüé® üíª      arudesaiüé® üíª              Adryenneüé® üíª      El mehdi oudaoudüé® üíª      Jayant Goelüé® üíª      Tsukiüé® üíª      Peter Lemanskiüé® üíª      Annurag-byteüé® üíª      Anthony Vuüé® üíª              Vitaly Nikolaychuküé® üíª      Nathanüé® üíª      Evgenii Petukhovüé® üíª      Loris Guerraüé® üíª      fakhriaunurüé® üíª      Mehdi HYANIüé® üíª      Sarvex Jatasraüé® üíª              santimanuelrüé® üíª      Evgeniy Rezanovüé® üíª      Sonia Müé® üíª      Grzegorz Kmitaüé® üíª      Manuel Caritaüé® üíª      Felipe Cisternas Alvarezüé® üíª      Guo Ciüé® üíª              Marcos Silvaüé® üíª      KKüé® üíª      Shubhanjan Medhiüé® üíª      ArthurFerreiraRodriguesüé® üíª      PabloHermunüé® üíª      disha-baldawaüé® üíª      StaroMoonüé® üíª              Amila T Kumarasekaraüé® üíª      Amoh Princeüé® üíª      AngeloGCüé® üíª      Ebube Glory Ogbondaüé® üíª      Prahalad Belavadiüìñ      Antoni Sarnowski-Trypkaüé® üíª      Alberto Pasqualettoüé® üíª              Amir Babaeiüé® üíª      Syed Abdul Hannanüé® üíª      Srajan Raiüé® üíª      Clarence Mooreüé® üíª      Nguyen Anh Tuanüé® üíª      dar2dar2üé® üíª      Ameer Ibrahimüé® üíª              Tiago Lugattoüé® üíª      raremiroirüé® üíª      Moobieüé® üíª      AlicanDursunüé® üíª      bbalsamüé® üíª      Lubo≈° H√°jeküé® üíª      mrshahzeb7üé® üíª              Wesley Schollüé® üíª      Lawrence Turcotteüé® üíª      Michael DiPaoloüé® üíª      Smart-Codiüé® üíª      Vivek Kumarüé® üíª      Igor Moiseevüé® üíª      B√•rd Pedersenüé® üíª              HOA PHANüé® üíª      GaborModraüé® üíª      vivek-114üé® üíª      Robinüé® üíª      Alexüé® üíª      John Ehrlingerüé® üíª      Roman Zhuravlovüé® üíª              Jordan Mossüé® üíª      RaeShellyüé® üíª      gmollardüé® üíª      Md Kaif Khanüé® üíª      Pablo Romeraüé® üíª      Erik Bustosüé® üíª      trogfieldüé® üíª              simon-aichhornüé® üíª      Tufan G√úLE√áüé® üíª      Uƒüur Berkecan √únl√ºüé® üíª      Revanth Naiküé® üíª      Lia Piresüé® üíª      Igor Mestechkinüé® üíª      Anirudh Karanthüé® üíª              KBobovskiyüé® üíª      zhatiayuaüé® üíª üñã      David Cardonaüé® üíª      Paulo Castilhoüé® üíª      Sebastiano Picchiüé® üíª      pjotarüé® üíª      Rimel CHERIFüíª              Arsal uddinüñã      Dmitry Kasporskyüíª      SoftwareDev1014üé® üíª      @Robvredüé® üíª      Kasun Shanakaüíª      Ahmad M.üé® üíª      Alex Kozinüé® üíª              Mandy Meindersmaüé® üíª      LEGALISE PIRACYüé® üíª      Alex Logvinüé® üíª      Aria Dahlüé® üíª      Mustafa Arifogluüé® üíª      Yevhen Leshchenkoüé® üíª      Anubhav Adhikariüé® üíª              Noah Tatkoüé® üíª      Mohit Gadhaviüé® üíª      Pedro Bas√≠lioüé® üíª      RealSanjeevüé® üíª      Akash Hazraüé® üíª      Christoph Dahlenüé® üíª      Vincent du Plessisüé® üíª              Karen Tamrazyanüé® üíª      Mirza Younus Baigüé® üíª      Ashish Kumarüé® üíª      Unknown6334üé® üíª      flowazüé® üíª      zi-aikraüé® üíª      PAYAL PMüé® üíª              Lennart L√∂scheüé® üíª      Yummy-Yumsüé® üíª      Njuacha Hubert Mikulowskiüé® üíª      Hussein Esmailüé® üíª      Bilgehan Bezirüé® üíª      Muhammed Shittuüé® üíª      Cl√©ment FERNANDESüé® üíª              JaCKoP619üé® üíª      userutf8üé® üíª      Mohamed Ubaidüé® üíª      Justin Yatesüé® üíª      mohammad aliüé® üíª      Madhav Singhüé® üíª      RgbMouse69üé® üíª              Nicholas Leasküé® üíª      parthav0üé® üíª      Sigmaüé® üíª      Evelina Bechevaüé® üíª      Akshit Gulyanüé® üíª      Arpita Janaüé® üíª      Praveen Kumarüé® üíª              Mohammad Samiüé® üíª      eddiestefanescuüé® üíª      Ramesh Yadavüé® üíª      Sarthak Joshiüé® üíª      Nikhil12300üé® üíª      Yevgenüé® üíª      Leoüé® üíª              laurent büé® üíª      Mettchenüé® üíª      Ali Mahdaviüé® üíª      Lucas Dondoüé® üíª      Siddhesh Agarwalüé® üíª      slimerPuncherüé® üíª      saritashhüé® üíª              Iulian-Valeriu CioatƒÉüé® üíª      Szabolcs Nagyüé® üíª      Jarle Kvileüé® üíª      ÂäâËÄÄÂçá Vic Liuüé® üíª      Suryanshüé® üíª      Matthew Oosthuyseüé® üíª      Florin Zamfirüé® üíª              Meleküé® üíª      moesocioüé® üíª      Alan Jamesüé® üíª      Mai Thanh Ph∆∞∆°ngüé® üíª      Neville Dabreüé® üíª      Maksymüé® üíª      tamanna900üé® üíª              Adithya Awatiüé® üíª      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
6,ageitgey/face_recognition,https://github.com/ageitgey/face_recognition/blob/master/README.md,Python,"Face RecognitionYou can also read a translated version of this file in Chinese ÁÆÄ‰Ωì‰∏≠ÊñáÁâà or in Korean ÌïúÍµ≠Ïñ¥ or in Japanese Êó•Êú¨Ë™û.Recognize and manipulate faces from Python or from the command line withthe world's simplest face recognition library.Built using dlib's state-of-the-art face recognitionbuilt with deep learning. The model has an accuracy of 99.38% on theLabeled Faces in the Wild benchmark.This also provides a simple face_recognition command line tool that letsyou do face recognition on a folder of images from the command line!FeaturesFind faces in picturesFind all the faces that appear in a picture:import face_recognitionimage = face_recognition.load_image_file(\""your_file.jpg\"")face_locations = face_recognition.face_locations(image)Find and manipulate facial features in picturesGet the locations and outlines of each person's eyes, nose, mouth and chin.import face_recognitionimage = face_recognition.load_image_file(\""your_file.jpg\"")face_landmarks_list = face_recognition.face_landmarks(image)Finding facial features is super useful for lots of important stuff. But you can also use it for really stupid stufflike applying digital make-up (think 'Meitu'):Identify faces in picturesRecognize who appears in each photo.import face_recognitionknown_image = face_recognition.load_image_file(\""biden.jpg\"")unknown_image = face_recognition.load_image_file(\""unknown.jpg\"")biden_encoding = face_recognition.face_encodings(known_image)[0]unknown_encoding = face_recognition.face_encodings(unknown_image)[0]results = face_recognition.compare_faces([biden_encoding], unknown_encoding)You can even use this library with other Python libraries to do real-time face recognition:See this example for the code.Online DemosUser-contributed shared Jupyter notebook demo (not officially supported): InstallationRequirementsPython 3.3+ or Python 2.7macOS or Linux (Windows not officially supported, but might work)Installation Options:Installing on Mac or LinuxFirst, make sure you have dlib already installed with Python bindings:How to install dlib from source on macOS or UbuntuThen, make sure you have cmake installed:brew install cmakeFinally, install this module from pypi using pip3 (or pip2 for Python 2):pip3 install face_recognitionAlternatively, you can try this library with Docker, see this section.If you are having trouble with installation, you can also try out apre-configured VM.Installing on an Nvidia Jetson Nano boardJetson Nano installation instructionsPlease follow the instructions in the article carefully. There is current a bug in the CUDA libraries on the Jetson Nano that will cause this library to fail silently if you don't follow the instructions in the article to comment out a line in dlib and recompile it.Installing on Raspberry Pi 2+Raspberry Pi 2+ installation instructionsInstalling on FreeBSDpkg install graphics/py-face_recognitionInstalling on WindowsWhile Windows isn't officially supported, helpful users have posted instructions on how to install this library:@masoudr's Windows 10 installation guide (dlib + face_recognition)Installing a pre-configured Virtual Machine imageDownload the pre-configured VM image (for VMware Player or VirtualBox).UsageCommand-Line InterfaceWhen you install face_recognition, you get two simple command-lineprograms:face_recognition - Recognize faces in a photograph or folder full forphotographs.face_detection - Find faces in a photograph or folder full for photographs.face_recognition command line toolThe face_recognition command lets you recognize faces in a photograph orfolder full  for photographs.First, you need to provide a folder with one picture of each person youalready know. There should be one image file for each person with thefiles named according to who is in the picture:Next, you need a second folder with the files you want to identify:Then in you simply run the command face_recognition, passing inthe folder of known people and the folder (or single image) with unknownpeople and it tells you who is in each image:$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama/face_recognition_test/unknown_pictures/unknown.jpg,unknown_personThere's one line in the output for each face. The data is comma-separatedwith the filename and the name of the person found.An unknown_person is a face in the image that didn't match anyone inyour folder of known people.face_detection command line toolThe face_detection command lets you find the location (pixel coordinatates)of any faces in an image.Just run the command face_detection, passing in a folder of imagesto check (or a single image):$ face_detection  ./folder_with_pictures/examples/image1.jpg,65,215,169,112examples/image2.jpg,62,394,211,244examples/image2.jpg,95,941,244,792It prints one line for each face that was detected. The coordinatesreported are the top, right, bottom and left coordinates of the face (in pixels).Adjusting Tolerance / SensitivityIf you are getting multiple matches for the same person, it might be thatthe people in your photos look very similar and a lower tolerance valueis needed to make face comparisons more strict.You can do that with the --tolerance parameter. The default tolerancevalue is 0.6 and lower numbers make face comparisons more strict:$ face_recognition --tolerance 0.54 ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama/face_recognition_test/unknown_pictures/unknown.jpg,unknown_personIf you want to see the face distance calculated for each match in orderto adjust the tolerance setting, you can use --show-distance true:$ face_recognition --show-distance true ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,NoneMore ExamplesIf you simply want to know the names of the people in each photograph but don'tcare about file names, you could do this:$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/ | cut -d ',' -f2Barack Obamaunknown_personSpeeding up Face RecognitionFace recognition can be done in parallel if you have a computer withmultiple CPU cores. For example, if your system has 4 CPU cores, you canprocess about 4 times as many images in the same amount of time by usingall your CPU cores in parallel.If you are using Python 3.4 or newer, pass in a --cpus <number_of_cpu_cores_to_use> parameter:$ face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/You can also pass in --cpus -1 to use all CPU cores in your system.Python ModuleYou can import the face_recognition module and then easily manipulatefaces with just a couple of lines of code. It's super easy!API Docs: https://face-recognition.readthedocs.io.Automatically find all the faces in an imageimport face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_locations = face_recognition.face_locations(image)# face_locations is now an array listing the co-ordinates of each face!See this exampleto try it out.You can also opt-in to a somewhat more accurate deep-learning-based face detection model.Note: GPU acceleration (via NVidia's CUDA library) is required for goodperformance with this model. You'll also want to enable CUDA supportwhen compliling dlib.import face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_locations = face_recognition.face_locations(image, model=\""cnn\"")# face_locations is now an array listing the co-ordinates of each face!See this exampleto try it out.If you have a lot of images and a GPU, you can alsofind faces in batches.Automatically locate the facial features of a person in an imageimport face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_landmarks_list = face_recognition.face_landmarks(image)# face_landmarks_list is now an array with the locations of each facial feature in each face.# face_landmarks_list[0]['left_eye'] would be the location and outline of the first person's left eye.See this exampleto try it out.Recognize faces in images and identify who they areimport face_recognitionpicture_of_me = face_recognition.load_image_file(\""me.jpg\"")my_face_encoding = face_recognition.face_encodings(picture_of_me)[0]# my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!unknown_picture = face_recognition.load_image_file(\""unknown.jpg\"")unknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]# Now we can see the two face encodings are of the same person with `compare_faces`!results = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)if results[0] == True:    print(\""It's a picture of me!\"")else:    print(\""It's not a picture of me!\"")See this exampleto try it out.Python Code ExamplesAll the examples are available here.Face DetectionFind faces in a photographFind faces in a photograph (using deep learning)Find faces in batches of images w/ GPU (using deep learning)Blur all the faces in a live video using your webcam (Requires OpenCV to be installed)Facial FeaturesIdentify specific facial features in a photographApply (horribly ugly) digital make-upFacial RecognitionFind and recognize unknown faces in a photograph based on photographs of known peopleIdentify and draw boxes around each person in a photoCompare faces by numeric face distance instead of only True/False matchesRecognize faces in live video using your webcam - Simple / Slower Version (Requires OpenCV to be installed)Recognize faces in live video using your webcam - Faster Version (Requires OpenCV to be installed)Recognize faces in a video file and write out new video file (Requires OpenCV to be installed)Recognize faces on a Raspberry Pi w/ cameraRun a web service to recognize faces via HTTP (Requires Flask to be installed)Recognize faces with a K-nearest neighbors classifierTrain multiple images per person then recognize faces using a SVMCreating a Standalone ExecutableIf you want to create a standalone executable that can run without the need to install python or face_recognition, you can use PyInstaller. However, it requires some custom configuration to work with this library. See this issue for how to do it.Articles and Guides that cover face_recognitionMy article on how Face Recognition works: Modern Face Recognition with Deep LearningCovers the algorithms and how they generally workFace recognition with OpenCV, Python, and deep learning by Adrian RosebrockCovers how to use face recognition in practiceRaspberry Pi Face Recognition by Adrian RosebrockCovers how to use this on a Raspberry PiFace clustering with Python by Adrian RosebrockCovers how to automatically cluster photos based on who appears in each photo using unsupervised learningHow Face Recognition WorksIf you want to learn how face location and recognition work instead ofdepending on a black box library, read my article.CaveatsThe face recognition model is trained on adults and does not work very well on children. It tends to mixup children quite easy using the default comparison threshold of 0.6.Accuracy may vary between ethnic groups. Please see this wiki page for more details.Deployment to Cloud Hosts (Heroku, AWS, etc)Since face_recognition depends on dlib which is written in C++, it can be tricky to deploy an appusing it to a cloud hosting provider like Heroku or AWS.To make things easier, there's an example Dockerfile in this repo that shows how to run an app built withface_recognition in a Docker container. With that, you should be able to deployto any service that supports Docker images.You can try the Docker image locally by running: docker-compose up --buildThere are also several prebuilt Docker images.Linux users with a GPU (drivers >= 384.81) and Nvidia-Docker installed can run the example on the GPU: Open the docker-compose.yml file and uncomment the dockerfile: Dockerfile.gpu and runtime: nvidia lines.Having problems?If you run into problems, please read the Common Errors section of the wiki before filing a github issue.ThanksMany, many thanks to Davis King (@nulhom)for creating dlib and for providing the trained facial feature detection and face encoding modelsused in this library. For more information on the ResNet that powers the face encodings, check outhis blog post.Thanks to everyone who works on all the awesome Python data science libraries like numpy, scipy, scikit-image,pillow, etc, etc that makes this kind of stuff so easy and fun in Python.Thanks to Cookiecutter and theaudreyr/cookiecutter-pypackage project templatefor making Python project packaging way more tolerable."
7,swisskyrepo/PayloadsAllTheThings,https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/README.md,Python,"Payloads All The ThingsA list of useful payloads and bypasses for Web Application Security.Feel free to improve with your payloads and techniques !I ‚ù§Ô∏è pull requests :)You can also contribute with a üçª IRL, or using the sponsor buttonAn alternative display version is available at PayloadsAllTheThingsWeb.  üìñ DocumentationEvery section contains the following files, you can use the _template_vuln folder to create a new chapter:README.md - vulnerability description and how to exploit it, including several payloadsIntruder - a set of files to give to Burp IntruderImages - pictures for the README.mdFiles - some files referenced in the README.mdYou might also like the Methodology and Resources folder :Methodology and ResourcesActive Directory Attack.mdCloud - AWS Pentest.mdCloud - Azure Pentest.mdCobalt Strike - Cheatsheet.mdLinux - Evasion.mdLinux - Persistence.mdLinux - Privilege Escalation.mdMetasploit - Cheatsheet.mdMethodology and enumeration.mdNetwork Pivoting Techniques.mdNetwork Discovery.mdReverse Shell Cheatsheet.mdSubdomains Enumeration.mdWindows - AMSI Bypass.mdWindows - DPAPI.mdWindows - Download and Execute.mdWindows - Mimikatz.mdWindows - Persistence.mdWindows - Privilege Escalation.mdWindows - Using credentials.mdYou want more ? Check the Books and Youtube videos selections.üë®‚Äçüíª ContributionsBe sure to read CONTRIBUTING.md  Thanks again for your contribution! ‚ù§Ô∏èüßô‚Äç‚ôÇÔ∏è SponsorsThis project is proudly sponsored by these companies."
8,xtekky/gpt4free,https://github.com/xtekky/gpt4free/blob/main/README.md,Python,"By using this repository or any code related to it, you agree to the legal notice. The author is not responsible for any copies, forks, or reuploads made by other users. This is the author's only account and repository. To prevent impersonation or irresponsible actions, you may comply with the GNU GPL license this Repository uses.This (quite censored) New Version of gpt4free, was just released, it may contain bugs, open an issue or contribute a PR when encountering one, some features were disabled.Docker is for now not available but I would be happy if someone contributes a PR. The g4f GUI will be uploaded soon enough.Newpypi package:pip install -U g4fTable of Contents:Getting StartedPrerequisitesSetting up the projectUsageThe g4f Packageinterference openai-proxy apiModelsgpt-3.5 / gpt-4Other ModelsRelated gpt4free projectsContributeChatGPT cloneCopyrightCopyright NoticeStar HistoryGetting StartedPrerequisites:Download and install Python (Version 3.x is recommended).Setting up the project:Install using pypipip install -U g4forClone the GitHub repository:git clone https://github.com/xtekky/gpt4free.gitNavigate to the project directory:cd gpt4free(Recommended) Create a virtual environment to manage Python packages for your project:python3 -m venv venvActivate the virtual environment:On Windows:.\\venv\\Scripts\\activateOn macOS and Linux:source venv/bin/activateInstall the required Python packages from requirements.txt:pip install -r requirements.txtCreate a test.py file in the root folder and start using the repo, further Instructions are belowimport g4f...UsageThe g4f Packageimport g4fprint(g4f.provider.Ails.params)  # supported args# Automatic selection of provider# streamed completionresponse = g4f.ChatCompletion.create(    model=\""gpt-3.5-turbo\"",    messages=[{\""role\"": \""user\"", \""content\"": \""Hello world\""}],    stream=True,)for message in response:    print(message, flush=True, end='')# normal responseresponse = g4f.ChatCompletion.create(    model=g4f.models.gpt_4,    messages=[{\""role\"": \""user\"", \""content\"": \""hi\""}],)  # alterative model settingprint(response)# Set with providerresponse = g4f.ChatCompletion.create(    model=\""gpt-3.5-turbo\"",    provider=g4f.provider.DeepAi,    messages=[{\""role\"": \""user\"", \""content\"": \""Hello world\""}],    stream=True,)for message in response:    print(message)providers:from g4f.provider import (    Acytoo,    Aichat,    Ails,    AiService,    AItianhu,    Bard,    Bing,    ChatgptAi,    ChatgptLogin,    DeepAi,    GetGpt)# usage:response = g4f.ChatCompletion.create(..., provider=ProviderName)interference openai-proxy api (use with openai python package)get requirements:pip install -r interference/requirements.txtrun server:python3 -m interference.appimport openaiopenai.api_key = \""\""openai.api_base = \""http://localhost:1337\""def main():    chat_completion = openai.ChatCompletion.create(        model=\""gpt-3.5-turbo\"",        messages=[{\""role\"": \""user\"", \""content\"": \""write a poem about a tree\""}],        stream=True,    )    if isinstance(chat_completion, dict):        # not stream        print(chat_completion.choices[0].message.content)    else:        # stream        for token in chat_completion:            content = token[\""choices\""][0][\""delta\""].get(\""content\"")            if content != None:                print(content, end=\""\"", flush=True)if __name__ == \""__main__\"":    main()Modelsgpt-3.5 / gpt-4WebsiteProvidergpt-3.5gpt-4StreamingStatusAuthwww.aitianhu.comg4f.provider.AItianhu‚úîÔ∏è‚ùå‚ùå‚ùåchat.acytoo.comg4f.provider.Acytoo‚úîÔ∏è‚ùå‚ùå‚ùåaiservice.vercel.appg4f.provider.AiService‚úîÔ∏è‚ùå‚ùå‚ùåchat-gpt.orgg4f.provider.Aichat‚úîÔ∏è‚ùå‚ùå‚ùåai.lsg4f.provider.Ails‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåbard.google.comg4f.provider.Bard‚ùå‚ùå‚ùå‚úîÔ∏èbing.comg4f.provider.Bing‚ùå‚úîÔ∏è‚ùå‚ùåchatgpt.aig4f.provider.ChatgptAi‚ùå‚úîÔ∏è‚ùå‚ùåchatgptlogin.acg4f.provider.ChatgptLogin‚úîÔ∏è‚ùå‚ùå‚ùådeepai.orgg4f.provider.DeepAi‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåchat.dfehub.comg4f.provider.DfeHub‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåfree.easychat.workg4f.provider.EasyChat‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåforefront.comg4f.provider.Forefront‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåchat.getgpt.worldg4f.provider.GetGpt‚úîÔ∏è‚ùå‚úîÔ∏è‚ùågpt-gm.h2o.aig4f.provider.H2o‚ùå‚ùå‚úîÔ∏è‚ùåliaobots.comg4f.provider.Liaobots‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏èsupertest.lockchat.appg4f.provider.Lockchat‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚ùåopchatgpts.netg4f.provider.Opchatgpts‚úîÔ∏è‚ùå‚ùå‚ùåbackend.raycast.comg4f.provider.Raycast‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏ètheb.aig4f.provider.Theb‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåplay.vercel.aig4f.provider.Vercel‚úîÔ∏è‚ùå‚ùå‚ùåwewordle.orgg4f.provider.Wewordle‚úîÔ∏è‚ùå‚ùå‚ùåyou.comg4f.provider.You‚úîÔ∏è‚ùå‚ùå‚ùåchat9.yqcloud.topg4f.provider.Yqcloud‚úîÔ∏è‚ùå‚ùå‚ùåOther ModelsModelBase ProviderProviderWebsitepalmGoogleg4f.provider.Bardbard.google.comh2ogpt-gm-oasst1-en-2048-falcon-7b-v3Huggingfaceg4f.provider.H2owww.h2o.aih2ogpt-gm-oasst1-en-2048-falcon-40b-v1Huggingfaceg4f.provider.H2owww.h2o.aih2ogpt-gm-oasst1-en-2048-open-llama-13bHuggingfaceg4f.provider.H2owww.h2o.aiclaude-instant-v1Anthropicg4f.provider.Vercelsdk.vercel.aiclaude-v1Anthropicg4f.provider.Vercelsdk.vercel.aiclaude-v2Anthropicg4f.provider.Vercelsdk.vercel.aicommand-light-nightlyCohereg4f.provider.Vercelsdk.vercel.aicommand-nightlyCohereg4f.provider.Vercelsdk.vercel.aigpt-neox-20bHuggingfaceg4f.provider.Vercelsdk.vercel.aioasst-sft-1-pythia-12bHuggingfaceg4f.provider.Vercelsdk.vercel.aioasst-sft-4-pythia-12b-epoch-3.5Huggingfaceg4f.provider.Vercelsdk.vercel.aisantacoderHuggingfaceg4f.provider.Vercelsdk.vercel.aibloomHuggingfaceg4f.provider.Vercelsdk.vercel.aiflan-t5-xxlHuggingfaceg4f.provider.Vercelsdk.vercel.aicode-davinci-002OpenAIg4f.provider.Vercelsdk.vercel.aigpt-3.5-turbo-16kOpenAIg4f.provider.Vercelsdk.vercel.aigpt-3.5-turbo-16k-0613OpenAIg4f.provider.Vercelsdk.vercel.aigpt-4-0613OpenAIg4f.provider.Vercelsdk.vercel.aitext-ada-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-babbage-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-curie-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-davinci-002OpenAIg4f.provider.Vercelsdk.vercel.aitext-davinci-003OpenAIg4f.provider.Vercelsdk.vercel.aillama13b-v2-chatReplicateg4f.provider.Vercelsdk.vercel.aillama7b-v2-chatReplicateg4f.provider.Vercelsdk.vercel.aiRelated gpt4free projects            üéÅ Projects      ‚≠ê Stars      üìö Forks      üõé Issues      üì¨ Pull requests                  gpt4free                                      gpt4free-ts                                      ChatGPT-Clone                                      ChatGpt Discord Bot                                      LangChain gpt4free                                      ChatGpt Telegram Bot                              Contributeto add another provider, its very simple:create a new file in g4f/provider with the name of the ProviderImplement a class that extends BaseProvider.from .base_provider import BaseProviderfrom ..typing import CreateResult, Anyclass HogeService(BaseProvider):    url = \""http://hoge.com\""    working = True    supports_gpt_35_turbo = True    @staticmethod    def create_completion(        model: str,        messages: list[dict[str, str]],        stream: bool,        **kwargs: Any,    ) -> CreateResult:        passHere, you can adjust the settings, for example if the website does support streaming, set working to True...Write code to request the provider in create_completion and yield the response, even if its a one-time response, do not hesitate to look at other providers for inspirationAdd the Provider Name in g4f/provider/init.pyfrom .base_provider import BaseProviderfrom .HogeService import HogeService__all__ = [  HogeService,]You are done !, test the provider by calling it:import g4fresponse = g4f.ChatCompletion.create(model='gpt-3.5-turbo', provider=g4f.provider.PROVIDERNAME,                                    messages=[{\""role\"": \""user\"", \""content\"": \""test\""}], stream=g4f.provider.PROVIDERNAME.supports_stream)for message in response:    print(message, flush=True, end='')ChatGPT cloneCurrently implementing new features and trying to scale it, please be patient it may be unstablehttps://chat.g4f.ai/chatThis site was developed by me and includes gpt-4/3.5, internet access and gpt-jailbreak's like DANRun locally here: https://github.com/xtekky/chatgpt-cloneCopyright:This program is licensed under the GNU GPL v3Copyright Notice:xtekky/gpt4free: Copyright (C) 2023 xtekkyThis program is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program.  If not, see <https://www.gnu.org/licenses/>.Star History         "
9,open-mmlab/mmdetection,https://github.com/open-mmlab/mmdetection/blob/main/README.md,Python,"    ¬†      OpenMMLab website                  HOT              ¬†¬†¬†¬†    OpenMMLab platform                  TRY IT OUT              ¬†üìòDocumentation |üõ†Ô∏èInstallation |üëÄModel Zoo |üÜïUpdate News |üöÄOngoing Projects |ü§îReporting IssuesEnglish | ÁÆÄ‰Ωì‰∏≠Êñá                                              IntroductionMMDetection is an open source object detection toolbox based on PyTorch. It isa part of the OpenMMLab project.The main branch works with PyTorch 1.8+.Major featuresModular DesignWe decompose the detection framework into different components and one can easily construct a customized object detection framework by combining different modules.Support of multiple tasks out of boxThe toolbox directly supports multiple detection tasks such as object detection, instance segmentation, panoptic segmentation, and semi-supervised object detection.High efficiencyAll basic bbox and mask operations run on GPUs. The training speed is faster than or comparable to other codebases, including Detectron2, maskrcnn-benchmark and SimpleDet.State of the artThe toolbox stems from the codebase developed by the MMDet team, who won COCO Detection Challenge in 2018, and we keep pushing it forward.The newly released RTMDet also obtains new state-of-the-art results on real-time instance segmentation and rotated object detection tasks and the best parameter-accuracy trade-off on object detection.Apart from MMDetection, we also released MMEngine for model training and MMCV for computer vision research, which are heavily depended on by this toolbox.What's NewHighlightWe are excited to announce our latest work on real-time object recognition tasks, RTMDet, a family of fully convolutional single-stage detectors. RTMDet not only achieves the best parameter-accuracy trade-off on object detection from tiny to extra-large model sizes but also obtains new state-of-the-art performance on instance segmentation and rotated object detection tasks. Details can be found in the technical report. Pre-trained models are here.TaskDatasetAPFPS(TRT FP16 BS1 3090)Object DetectionCOCO52.8322Instance SegmentationCOCO44.6188Rotated Object DetectionDOTA78.9(single-scale)/81.3(multi-scale)121v3.1.0 was released in 30/6/2023:Supports tracking algorithms including multi-object tracking (MOT) algorithms SORT, DeepSORT, StrongSORT, OCSORT, ByteTrack, QDTrack, and video instance segmentation (VIS) algorithm MaskTrackRCNN, Mask2Former-VIS.Support ViTDetSupports inference and evaluation of multimodal algorithms GLIP and XDecoder, and also supports datasets such as COCO semantic segmentation, COCO Caption, ADE20k general segmentation, and RefCOCO. GLIP fine-tuning will be supported in the future.Provides a gradio demo for image type tasks of MMDetection, making it easy for users to experience.InstallationPlease refer to Installation for installation instructions.Getting StartedPlease see Overview for the general introduction of MMDetection.For detailed user guides and advanced guides, please refer to our documentation:User GuidesTrain & TestLearn about ConfigsInference with existing modelsDataset PrepareTest existing models on standard datasetsTrain predefined models on standard datasetsTrain with customized datasetsTrain with customized models and standard datasetsFinetuning ModelsTest Results SubmissionWeight initializationUse a single stage detector as RPNSemi-supervised Object DetectionUseful ToolsAdvanced GuidesBasic ConceptsComponent CustomizationHow toWe also provide object detection colab tutorial  and instance segmentation colab tutorial .To migrate from MMDetection 2.x, please refer to migration.Overview of Benchmark and Model ZooResults and models are available in the model zoo.  Architectures                    Object Detection                    Instance Segmentation                    Panoptic Segmentation                    Other                                        Fast R-CNN (ICCV'2015)            Faster R-CNN (NeurIPS'2015)            RPN (NeurIPS'2015)            SSD (ECCV'2016)            RetinaNet (ICCV'2017)            Cascade R-CNN (CVPR'2018)            YOLOv3 (ArXiv'2018)            CornerNet (ECCV'2018)            Grid R-CNN (CVPR'2019)            Guided Anchoring (CVPR'2019)            FSAF (CVPR'2019)            CenterNet (CVPR'2019)            Libra R-CNN (CVPR'2019)            TridentNet (ICCV'2019)            FCOS (ICCV'2019)            RepPoints (ICCV'2019)            FreeAnchor (NeurIPS'2019)            CascadeRPN (NeurIPS'2019)            Foveabox (TIP'2020)            Double-Head R-CNN (CVPR'2020)            ATSS (CVPR'2020)            NAS-FCOS (CVPR'2020)            CentripetalNet (CVPR'2020)            AutoAssign (ArXiv'2020)            Side-Aware Boundary Localization (ECCV'2020)            Dynamic R-CNN (ECCV'2020)            DETR (ECCV'2020)            PAA (ECCV'2020)            VarifocalNet (CVPR'2021)            Sparse R-CNN (CVPR'2021)            YOLOF (CVPR'2021)            YOLOX (CVPR'2021)            Deformable DETR (ICLR'2021)            TOOD (ICCV'2021)            DDOD (ACM MM'2021)            RTMDet (ArXiv'2022)            Conditional DETR (ICCV'2021)            DAB-DETR (ICLR'2022)            DINO (ICLR'2023)            GLIP (CVPR'2022)            DiffusionDet (ArXiv'2023)            EfficientDet (CVPR'2020)            Detic (ECCV'2022)                                    Mask R-CNN (ICCV'2017)          Cascade Mask R-CNN (CVPR'2018)          Mask Scoring R-CNN (CVPR'2019)          Hybrid Task Cascade (CVPR'2019)          YOLACT (ICCV'2019)          InstaBoost (ICCV'2019)          SOLO (ECCV'2020)          PointRend (CVPR'2020)          DetectoRS (ArXiv'2020)          SOLOv2 (NeurIPS'2020)          SCNet (AAAI'2021)          QueryInst (ICCV'2021)          Mask2Former (ArXiv'2021)          CondInst (ECCV'2020)          SparseInst (CVPR'2022)          RTMDet (ArXiv'2022)          BoxInst (CVPR'2021)                                      Panoptic FPN (CVPR'2019)          MaskFormer (NeurIPS'2021)          Mask2Former (ArXiv'2021)                                      Contrastive Learning                          SwAV (NeurIPS'2020)          MoCo (CVPR'2020)          MoCov2 (ArXiv'2020)                                  Distillation                          Localization Distillation (CVPR'2022)          Label Assignment Distillation (WACV'2022)                          Semi-Supervised Object Detection                          Soft Teacher (ICCV'2021)                                        Components                    Backbones                    Necks                    Loss                    Common                                  VGG (ICLR'2015)        ResNet (CVPR'2016)        ResNeXt (CVPR'2017)        MobileNetV2 (CVPR'2018)        HRNet (CVPR'2019)        Generalized Attention (ICCV'2019)        GCNet (ICCVW'2019)        Res2Net (TPAMI'2020)        RegNet (CVPR'2020)        ResNeSt (ArXiv'2020)        PVT (ICCV'2021)        Swin (CVPR'2021)        PVTv2 (ArXiv'2021)        ResNet strikes back (ArXiv'2021)        EfficientNet (ArXiv'2021)        ConvNeXt (CVPR'2022)        ConvNeXtv2 (ArXiv'2023)                                PAFPN (CVPR'2018)        NAS-FPN (CVPR'2019)        CARAFE (ICCV'2019)        FPG (ArXiv'2020)        GRoIE (ICPR'2020)        DyHead (CVPR'2021)                                    GHM (AAAI'2019)          Generalized Focal Loss (NeurIPS'2020)          Seasaw Loss (CVPR'2021)                                      OHEM (CVPR'2016)          Group Normalization (ECCV'2018)          DCN (ICCV'2017)          DCNv2 (CVPR'2019)          Weight Standardization (ArXiv'2019)          Prime Sample Attention (CVPR'2020)          Strong Baselines (CVPR'2021)          Resnet strikes back (ArXiv'2021)                        Some other methods are also supported in projects using MMDetection.FAQPlease refer to FAQ for frequently asked questions.ContributingWe appreciate all contributions to improve MMDetection. Ongoing projects can be found in out GitHub Projects. Welcome community users to participate in these projects. Please refer to CONTRIBUTING.md for the contributing guideline.AcknowledgementMMDetection is an open source project that is contributed by researchers and engineers from various colleges and companies. We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks.We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new detectors.CitationIf you use this toolbox or benchmark in your research, please cite this project.@article{mmdetection,  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},  journal= {arXiv preprint arXiv:1906.07155},  year={2019}}LicenseThis project is released under the Apache 2.0 license.Projects in OpenMMLabMMEngine: OpenMMLab foundational library for training deep learning models.MMCV: OpenMMLab foundational library for computer vision.MMPreTrain: OpenMMLab pre-training toolbox and benchmark.MMagic: OpenMMLab Advanced, Generative and Intelligent Creation toolbox.MMDetection: OpenMMLab detection toolbox and benchmark.MMDetection3D: OpenMMLab's next-generation platform for general 3D object detection.MMRotate: OpenMMLab rotated object detection toolbox and benchmark.MMYOLO: OpenMMLab YOLO series toolbox and benchmark.MMSegmentation: OpenMMLab semantic segmentation toolbox and benchmark.MMOCR: OpenMMLab text detection, recognition, and understanding toolbox.MMPose: OpenMMLab pose estimation toolbox and benchmark.MMHuman3D: OpenMMLab 3D human parametric model toolbox and benchmark.MMSelfSup: OpenMMLab self-supervised learning toolbox and benchmark.MMRazor: OpenMMLab model compression toolbox and benchmark.MMFewShot: OpenMMLab fewshot learning toolbox and benchmark.MMAction2: OpenMMLab's next-generation action understanding toolbox and benchmark.MMTracking: OpenMMLab video perception toolbox and benchmark.MMFlow: OpenMMLab optical flow toolbox and benchmark.MMEditing: OpenMMLab image and video editing toolbox.MMGeneration: OpenMMLab image and video generative models toolbox.MMDeploy: OpenMMLab model deployment framework.MIM: MIM installs OpenMMLab packages.MMEval: A unified evaluation library for multiple machine learning libraries.Playground: A central hub for gathering and showcasing amazing projects built upon OpenMMLab."
10,pallets/flask,https://github.com/pallets/flask/blob/main/README.rst,Python,"FlaskFlask is a lightweight WSGI web application framework. It is designedto make getting started quick and easy, with the ability to scale up tocomplex applications. It began as a simple wrapper around Werkzeugand Jinja and has become one of the most popular Python webapplication frameworks.Flask offers suggestions, but doesn't enforce any dependencies orproject layout. It is up to the developer to choose the tools andlibraries they want to use. There are many extensions provided by thecommunity that make adding new functionality easy.InstallingInstall and update using pip:$ pip install -U FlaskA Simple Example# save this as app.pyfrom flask import Flaskapp = Flask(__name__)@app.route(\""/\"")def hello():    return \""Hello, World!\""$ flask run  * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)ContributingFor guidance on setting up a development environment and how to make acontribution to Flask, see the contributing guidelines.DonateThe Pallets organization develops and supports Flask and the librariesit uses. In order to grow the community of contributors and users, andallow the maintainers to devote more time to the projects, pleasedonate today.LinksDocumentation: https://flask.palletsprojects.com/Changes: https://flask.palletsprojects.com/changes/PyPI Releases: https://pypi.org/project/Flask/Source Code: https://github.com/pallets/flask/Issue Tracker: https://github.com/pallets/flask/issues/Chat: https://discord.gg/pallets"
11,apachecn/ailearning,https://github.com/apachecn/ailearning/blob/master/README.md,Python,"                                AI learningÂçèËÆÆÔºöCC BY-NC-SA 4.0‰∏ÄÁßçÊñ∞ÊäÄÊúØ‰∏ÄÊó¶ÂºÄÂßãÊµÅË°åÔºå‰Ω†Ë¶Å‰πàÂùê‰∏äÂéãË∑ØÊú∫ÔºåË¶Å‰πàÊàê‰∏∫Èì∫Ë∑ØÁü≥„ÄÇ‚Äî‚ÄîStewart BrandÂú®Á∫øÈòÖËØªÂú®Á∫øÈòÖËØªÔºàv1ÔºâQuantLearningApacheCN ‰∏≠ÊñáÁøªËØëÁªÑ 713436582ApacheCN Â≠¶‰π†ËµÑÊ∫êÊ≥®: ÂπøÂëä‰ΩçÂêà‰Ωú(Áâ©Áæé‰ª∑Âªâ)ÔºåËØ∑ËÅîÁ≥ª apachecn@163.comË∑ØÁ∫øÂõæÂÖ•Èó®Âè™Áúã: Ê≠•È™§ 1 => 2 => 3Ôºå‰Ω†ÂèØ‰ª•ÂΩìÂ§ßÁâõÔºÅ‰∏≠Á∫ßË°•ÂÖÖ - ËµÑÊñôÂ∫ì: https://github.com/apachecn/ai-roadmapË°•ÂÖÖÁÆóÊ≥ïÂà∑È¢ò: https://www.ixigua.com/pseries/6822642486343631363/Èù¢ËØïÊ±ÇËÅå: https://www.ixigua.com/pseries/6822563009391493636/Êú∫Âô®Â≠¶‰π†ÂÆûÊàò: https://www.ixigua.com/pseries/6822816341615968772/NLPÊïôÂ≠¶ËßÜÈ¢ë: https://www.ixigua.com/pseries/6828241431295951373/AIÂ∏∏Áî®ÂáΩÊï∞ËØ¥Êòé: https://github.com/apachecn/AiLearning/tree/master/AIÂ∏∏Áî®ÂáΩÊï∞ËØ¥Êòé.md1.Êú∫Âô®Â≠¶‰π† - Âü∫Á°ÄÊîØÊåÅÁâàÊú¨VersionSupported3.6.x‚ùå2.7.x‚úÖÊ≥®ÊÑè‰∫ãÈ°π:Êú∫Âô®Â≠¶‰π†ÂÆûÊàò: ‰ªÖ‰ªÖÂè™ÊòØÂ≠¶‰π†ÔºåËØ∑‰ΩøÁî® python 2.7.x ÁâàÊú¨ Ôºà3.6.x Âè™ÊòØ‰øÆÊîπ‰∫ÜÈÉ®ÂàÜÔºâÂü∫Êú¨‰ªãÁªçËµÑÊñôÊù•Ê∫ê: Machine Learning in Action(Êú∫Âô®Â≠¶‰π†ÂÆûÊàò-‰∏™‰∫∫Á¨îËÆ∞)Áªü‰∏ÄÊï∞ÊçÆÂú∞ÂùÄ: https://github.com/apachecn/dataÁôæÂ∫¶‰∫ëÊâìÂåÖÂú∞ÂùÄ: apachecn/data#3‰π¶Á±ç‰∏ãËΩΩÂú∞ÂùÄ: https://github.com/apachecn/data/tree/master/bookÊú∫Âô®Â≠¶‰π†‰∏ãËΩΩÂú∞ÂùÄ: https://github.com/apachecn/data/tree/master/Êú∫Âô®Â≠¶‰π†Ê∑±Â∫¶Â≠¶‰π†Êï∞ÊçÆÂú∞ÂùÄ: https://github.com/apachecn/data/tree/master/Ê∑±Â∫¶Â≠¶‰π†Êé®ËçêÁ≥ªÁªüÊï∞ÊçÆÂú∞ÂùÄ: https://github.com/apachecn/data/tree/master/Êé®ËçêÁ≥ªÁªüËßÜÈ¢ëÁΩëÁ´ô: ‰ºòÈÖ∑ Ôºèbilibili / Acfun / ÁΩëÊòì‰∫ëËØæÂ†ÇÔºåÂèØÁõ¥Êé•Âú®Á∫øÊí≠Êîæ„ÄÇÔºàÊúÄ‰∏ãÊñπÊúâÁõ∏Â∫îÈìæÊé•Ôºâ-- Êé®Ëçê Á∫¢Ëâ≤Áü≥Â§¥: Âè∞ÊπæÂ§ßÂ≠¶ÊûóËΩ©Áî∞Êú∫Âô®Â≠¶‰π†Á¨îËÆ∞-- Êé®Ëçê Êú∫Âô®Â≠¶‰π†Á¨îËÆ∞: https://feisky.xyz/machine-learningÂ≠¶‰π†ÊñáÊ°£Ê®°ÂùóÁ´†ËäÇÁ±ªÂûãË¥üË¥£‰∫∫(GitHub)QQÊú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 1 Á´†: Êú∫Âô®Â≠¶‰π†Âü∫Á°Ä‰ªãÁªç@ÊØõÁ∫¢Âä®1306014226Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 2 Á´†: KNN ËøëÈÇªÁÆóÊ≥ïÂàÜÁ±ª@Â∞§Ê∞∏Ê±ü279393323Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 3 Á´†: ÂÜ≥Á≠ñÊ†ëÂàÜÁ±ª@ÊôØÊ∂õ844300439Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 4 Á´†: Êú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ª@wnma3mz@ÂàÜÊûê1003324213244970749Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 5 Á´†: LogisticÂõûÂΩíÂàÜÁ±ª@ÂæÆÂÖâÂêåÂ∞ò529925688Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 6 Á´†: SVM ÊîØÊåÅÂêëÈáèÊú∫ÂàÜÁ±ª@ÁéãÂæ∑Á∫¢934969547ÁΩë‰∏äÁªÑÂêàÂÜÖÂÆπÁ¨¨ 7 Á´†: ÈõÜÊàêÊñπÊ≥ïÔºàÈöèÊú∫Ê£ÆÊûóÂíå AdaBoostÔºâÂàÜÁ±ª@ÁâáÂàª529815144Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 8 Á´†: ÂõûÂΩíÂõûÂΩí@ÂæÆÂÖâÂêåÂ∞ò529925688Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 9 Á´†: Ê†ëÂõûÂΩíÂõûÂΩí@ÂæÆÂÖâÂêåÂ∞ò529925688Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 10 Á´†: K-Means ËÅöÁ±ªËÅöÁ±ª@ÂæêÊò≠Ê∏Ö827106588Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 11 Á´†: Âà©Áî® Apriori ÁÆóÊ≥ïËøõË°åÂÖ≥ËÅîÂàÜÊûêÈ¢ëÁπÅÈ°πÈõÜ@ÂàòÊµ∑È£û1049498972Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 12 Á´†: FP-growth È´òÊïàÂèëÁé∞È¢ëÁπÅÈ°πÈõÜÈ¢ëÁπÅÈ°πÈõÜ@Á®ãÂ®Å842725815Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 13 Á´†: Âà©Áî® PCA Êù•ÁÆÄÂåñÊï∞ÊçÆÂ∑•ÂÖ∑@ÂªñÁ´ãÂ®ü835670618Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 14 Á´†: Âà©Áî® SVD Êù•ÁÆÄÂåñÊï∞ÊçÆÂ∑•ÂÖ∑@Âº†‰øäÁöì714974242Êú∫Âô®Â≠¶‰π†ÂÆûÊàòÁ¨¨ 15 Á´†: Â§ßÊï∞ÊçÆ‰∏é MapReduceÂ∑•ÂÖ∑@wnma3mz1003324213MlÈ°πÁõÆÂÆûÊàòÁ¨¨ 16 Á´†: Êé®ËçêÁ≥ªÁªüÔºàÂ∑≤ËøÅÁßªÔºâÈ°πÁõÆÊé®ËçêÁ≥ªÁªüÔºàËøÅÁßªÂêéÂú∞ÂùÄÔºâÁ¨¨‰∏ÄÊúüÁöÑÊÄªÁªì2017-04-08: Á¨¨‰∏ÄÊúüÁöÑÊÄªÁªìÊÄªÁªìÊÄªÁªì529815144ÁΩëÁ´ôËßÜÈ¢ëÁü•‰πéÈóÆÁ≠î-ÁàÜÁÇ∏Âï¶-Êú∫Âô®Â≠¶‰π†ËØ•ÊÄé‰πàÂÖ•Èó®ÔºüÂΩìÁÑ∂ÊàëÁü•ÈÅìÔºåÁ¨¨‰∏ÄÂè•Â∞±‰ºöË¢´ÂêêÊßΩÔºåÂõ†‰∏∫ÁßëÁè≠Âá∫Ë∫´ÁöÑ‰∫∫Ôºå‰∏çÂ±ëÁöÑÂêê‰∫Ü‰∏ÄÂè£ÂîæÊ≤´ÔºåËØ¥ÂÇªXÔºåËøòËØÑËÆ∫ Andrew Ng ÁöÑËßÜÈ¢ë„ÄÇ„ÄÇÊàëËøòÁü•ÈÅìËøòÊúâ‰∏ÄÈÉ®ÂàÜ‰∫∫ÔºåÁúã Andrew Ng ÁöÑËßÜÈ¢ëÂ∞±ÊòØÁúã‰∏çÊáÇÔºåÈÇ£Á•ûÁßòÁöÑÊï∞Â≠¶Êé®ÂØºÔºåÈÇ£Ëø∑‰πãÂæÆÁ¨ëÁöÑËã±ÊñáÁâàÁöÑÊïôÂ≠¶ÔºåÊàë‰ΩïÂ∞ùÂèà‰∏çÊòØËøôÊ†∑Ëµ∞ËøáÊù•ÁöÑÔºüÔºü ÊàëÁöÑÂøÉÂèØËÉΩÊØî‰Ω†‰ª¨ÈÉΩÁóõÔºåÂõ†‰∏∫ÊàëÂú®ÁΩë‰∏äÊî∂ËóèËøá‰∏ä10ÈÉ®„ÄäÊú∫Âô®Â≠¶‰π†„ÄãÁõ∏ÂÖ≥ËßÜÈ¢ëÔºåÂ§ñÂä†ÂõΩÂÜÖÊú¨ÂúüÈ£éÊ†ºÁöÑÊïôÁ®ã: 7Êúà+Â∞èË±° Á≠âÁ≠âÔºåÊàëÈÉΩÂæàÈöæÂéªÂê¨ÊáÇÔºåÁõ¥Âà∞Êúâ‰∏ÄÂ§©ÔºåË¢´‰∏Ä‰∏™ÁôæÂ∫¶ÁöÑÈ´òÁ∫ßÁÆóÊ≥ïÂàÜÊûêÂ∏àÊé®ËçêËØ¥: „ÄäÊú∫Âô®Â≠¶‰π†ÂÆûÊàò„ÄãËøò‰∏çÈîôÔºåÈÄö‰øóÊòìÊáÇÔºå‰Ω†ÂéªËØïËØïÔºüÔºüÊàëËØï‰∫ÜËØïÔºåËøòÂ•ΩÊàëÁöÑPythonÂü∫Á°ÄÂíåË∞ÉËØïËÉΩÂäõËøò‰∏çÈîôÔºåÂü∫Êú¨‰∏ä‰ª£Á†ÅÈÉΩË∞ÉËØïËøá‰∏ÄÈÅçÔºåÂæàÂ§öÈ´òÂ§ß‰∏äÁöÑ \""ÁêÜËÆ∫+Êé®ÂØº\""ÔºåÂú®ÊàëÁúº‰∏≠ÂèòÊàê‰∫ÜÂá†‰∏™ \""Âä†Âáè‰πòÈô§+Âæ™ÁéØ\""ÔºåÊàëÊÉ≥Ëøô‰∏çÂ∞±ÊòØÂÉèÊàëËøôÊ†∑ÁöÑÁ®ãÂ∫èÂëòÊÉ≥Ë¶ÅÁöÑÂÖ•Èó®ÊïôÁ®ã‰πàÔºüÂæàÂ§öÁ®ãÂ∫èÂëòËØ¥Êú∫Âô®Â≠¶‰π† TM Â§™ÈöæÂ≠¶‰∫ÜÔºåÊòØÁöÑÔºåÁúü TM ÈöæÂ≠¶ÔºåÊàëÊÉ≥ÊúÄÈöæÁöÑÊòØ: Ê≤°Êúâ‰∏ÄÊú¨ÂÉè„ÄäÊú∫Âô®Â≠¶‰π†ÂÆûÊàò„ÄãÈÇ£Ê†∑ÁöÑ‰ΩúËÄÖÊÑøÊÑè‰ª•Á®ãÂ∫èÂëò Coding ËßíÂ∫¶ÂéªÁªôÂ§ßÂÆ∂ËÆ≤Ëß£ÔºÅÔºÅÊúÄËøëÂá†Â§©ÔºåGitHub Ê∂®‰∫Ü 300È¢ó starÔºåÂä†Áæ§ÁöÑ200‰∫∫Ôºå Áé∞Âú®ËøòÂú®‰∏çÊñ≠ÁöÑÂ¢ûÂä†++ÔºåÊàëÊÉ≥Â§ßÂÆ∂ÂèØËÉΩÈÉΩÊòØÊÑüÂêåË∫´ÂèóÂêßÔºÅÂæàÂ§öÊÉ≥ÂÖ•Èó®Êñ∞ÊâãÂ∞±ÊòØË¢´ÂøΩÊÇ†ÁùÄÊî∂ËóèÊî∂ËóèÂÜçÊî∂ËóèÔºå‰ΩÜÊòØÊúÄÂêéËøòÊòØ‰ªÄ‰πàÈÉΩÊ≤°ÊúâÂ≠¶Âà∞Ôºå‰πüÂ∞±ÊòØ\""ËµÑÊ∫êÊî∂ËóèÂÆ∂\""Ôºå‰πüËÆ∏Êñ∞ÊâãË¶ÅÁöÑÂ∞±ÊòØ MachineLearning(Êú∫Âô®Â≠¶‰π†) Â≠¶‰π†Ë∑ØÁ∫øÂõæ„ÄÇÊ≤°ÈîôÔºåÊàëÂèØ‰ª•Áªô‰Ω†‰ª¨ÁöÑ‰∏Ä‰ªΩÔºåÂõ†‰∏∫Êàë‰ª¨ËøòÈÄöËøáËßÜÈ¢ëËÆ∞ÂΩï‰∏ãÊù•Êàë‰ª¨ÁöÑÂ≠¶‰π†ËøáÁ®ã„ÄÇÊ∞¥Âπ≥ÂΩìÁÑ∂‰πüÊúâÈôêÔºå‰∏çËøáÂØπ‰∫éÊñ∞ÊâãÂÖ•Èó®ÔºåÁªùÂØπÊ≤°ÈóÆÈ¢òÔºåÂ¶ÇÊûú‰Ω†Ëøò‰∏ç‰ºöÔºåÈÇ£ÁÆóÊàëËæìÔºÅÔºÅËßÜÈ¢ëÊÄé‰πàÁúãÔºüÁêÜËÆ∫ÁßëÁè≠Âá∫Ë∫´-Âª∫ËÆÆÂéªÂ≠¶‰π† Andrew Ng ÁöÑËßÜÈ¢ëÔºàNg ÁöÑËßÜÈ¢ëÁªùÂØπÊòØÊùÉÂ®ÅÔºåËøô‰∏™ÊØãÂ∫∏ÁΩÆÁñëÔºâÁºñÁ†ÅËÉΩÂäõÂº∫ - Âª∫ËÆÆÁúãÊàë‰ª¨ÁöÑ„ÄäÊú∫Âô®Â≠¶‰π†ÂÆûÊàò-ÊïôÂ≠¶Áâà„ÄãÁºñÁ†ÅËÉΩÂäõÂº± - Âª∫ËÆÆÁúãÊàë‰ª¨ÁöÑ„ÄäÊú∫Âô®Â≠¶‰π†ÂÆûÊàò-ËÆ®ËÆ∫Áâà„ÄãÔºå‰∏çËøáÂú®ÁúãÁêÜËÆ∫ÁöÑÊó∂ÂÄôÔºåÁúã ÊïôÂ≠¶Áâà-ÁêÜËÆ∫ÈÉ®ÂàÜÔºõËÆ®ËÆ∫ÁâàÁöÑÂ∫üËØùÂ§™Â§öÔºå‰∏çËøáÂú®ËÆ≤Ëß£‰ª£Á†ÅÁöÑÊó∂ÂÄôÊòØ‰∏ÄË°å‰∏ÄË°åËÆ≤Ëß£ÁöÑÔºõÊâÄ‰ª•ÔºåÊ†πÊçÆËá™Â∑±ÁöÑÈúÄÊ±ÇÔºåËá™Áî±ÁöÑÁªÑÂêà„ÄÇ„ÄêÂÖçË¥π„ÄëÊï∞Â≠¶ÊïôÂ≠¶ËßÜÈ¢ë - ÂèØÊ±óÂ≠¶Èô¢ ÂÖ•Èó®ÁØá@‰∫éÊåØÊ¢ì Êé®Ëçê: ÂèØÊ±óÂ≠¶Èô¢-ÁΩëÊòìÂÖ¨ÂºÄËØæÊ¶ÇÁéáÁªüËÆ°Á∫øÊÄß‰ª£Êï∞ÂèØÊ±óÂ≠¶Èô¢(Ê¶ÇÁéá)ÂèØÊ±óÂ≠¶Èô¢(ÁªüËÆ°Â≠¶)ÂèØÊ±óÂ≠¶Èô¢(Á∫øÊÄß‰ª£Êï∞)Êú∫Âô®Â≠¶‰π†ËßÜÈ¢ë - ApacheCN ÊïôÂ≠¶ÁâàAcFunBÁ´ô‰ºòÈÖ∑ÁΩëÊòì‰∫ëËØæÂ†Ç„ÄêÂÖçË¥π„ÄëÊú∫Âô®/Ê∑±Â∫¶Â≠¶‰π†ËßÜÈ¢ë - Âê¥ÊÅ©ËææÊú∫Âô®Â≠¶‰π†Ê∑±Â∫¶Â≠¶‰π†Âê¥ÊÅ©ËææÊú∫Âô®Â≠¶‰π†Á•ûÁªèÁΩëÁªúÂíåÊ∑±Â∫¶Â≠¶‰π†2.Ê∑±Â∫¶Â≠¶‰π†ÊîØÊåÅÁâàÊú¨VersionSupported3.6.x‚úÖ2.7.x‚ùåÂÖ•Èó®Âü∫Á°ÄÂèçÂêë‰º†ÈÄí: https://www.cnblogs.com/charlotte77/p/5629865.htmlCNNÂéüÁêÜ: http://www.cnblogs.com/charlotte77/p/7759802.htmlRNNÂéüÁêÜ: https://blog.csdn.net/qq_39422642/article/details/78676567LSTMÂéüÁêÜ: https://blog.csdn.net/weixin_42111770/article/details/80900575Pytorch - ÊïôÁ®ã-- ÂæÖÊõ¥Êñ∞TensorFlow 2.0 - ÊïôÁ®ã-- ÂæÖÊõ¥Êñ∞ÁõÆÂΩïÁªìÊûÑ:ÂÆâË£ÖÊåáÂçóKeras Âø´ÈÄüÂÖ•Èó®ÂÆûÊàòÈ°πÁõÆ 1 ÁîµÂΩ±ÊÉÖÊÑüÂàÜÁ±ªÂÆûÊàòÈ°πÁõÆ 2 Ê±ΩËΩ¶ÁáÉÊ≤πÊïàÁéáÂÆûÊàòÈ°πÁõÆ 3 ‰ºòÂåñ ËøáÊãüÂêàÂíåÊ¨†ÊãüÂêàÂÆûÊàòÈ°πÁõÆ 4 Âè§ËØóËØçËá™Âä®ÁîüÊàêÂàáÂàÜÔºàÂàÜËØçÔºâËØçÊÄßÊ†áÊ≥®ÂëΩÂêçÂÆû‰ΩìËØÜÂà´Âè•Ê≥ïÂàÜÊûêWordNetÂèØ‰ª•Ë¢´Áúã‰ΩúÊòØ‰∏Ä‰∏™Âêå‰πâËØçËØçÂÖ∏ËØçÂπ≤ÊèêÂèñÔºàstemmingÔºâ‰∏éËØçÂΩ¢ËøòÂéüÔºàlemmatizationÔºâhttps://www.biaodianfu.com/nltk.html/ampTensorFlow 2.0Â≠¶‰π†ÁΩëÂùÄhttps://github.com/lyhue1991/eat_tensorflow2_in_30_days3.Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊîØÊåÅÁâàÊú¨VersionSupported3.6.x‚úÖ2.7.x‚ùåÂ≠¶‰π†ËøáÁ®ã‰∏≠-ÂÜÖÂøÉÂ§çÊùÇÁöÑÂèòÂåñÔºÅÔºÅÔºÅËá™‰ªéÂ≠¶‰π†NLP‰ª•ÂêéÔºåÊâçÂèëÁé∞ÂõΩÂÜÖ‰∏éÂõΩÂ§ñÁöÑÂÖ∏ÂûãÂå∫Âà´:1. ÂØπËµÑÊ∫êÁöÑÊÄÅÂ∫¶ÊòØÂÆåÂÖ®Áõ∏ÂèçÁöÑ:  1) ÂõΩÂÜÖ: Â∞±Â•ΩÂÉè‰∏∫‰∫ÜÂêçÊ∞îÔºå‰∏æÂäûÂ∑•‰ΩúË£ÖÈÄºÁöÑ‰ºöËÆÆÔºåÂ∞±ÊòØÊ≤°ÊúâÂπ≤Ë¥ßÔºåÂÖ®ÈÉ®ÈÉΩÊòØË±°ÂæÅÊÄßÁöÑPPT‰ªãÁªçÔºå‰∏çÊòØÈíàÂØπÂú®ÂÅöÁöÑÂêÑ‰Ωç  2ÔºâÂõΩÂ§ñ: Â∞±Â•ΩÂÉèÊòØ‰∏∫‰∫ÜÊé®Âä®nlpËøõÊ≠•‰∏ÄÊ†∑ÔºåÂàÜ‰∫´ËÄÖÂêÑÁßçÂπ≤Ë¥ßËµÑÊñôÂíåÂÖ∑‰ΩìÁöÑÂÆûÁé∞„ÄÇÔºàÁâπÂà´ÊòØ: pythonËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºâ2. ËÆ∫ÊñáÁöÑÂÆûÁé∞:   1) ÂêÑÁßçÈ´òÂ§ß‰∏äÁöÑËÆ∫ÊñáÂÆûÁé∞ÔºåÂç¥ËøòÊòØÊ≤°ÁúãÂà∞‰∏Ä‰∏™ÂÉèÊ†∑ÁöÑGitHubÈ°πÁõÆÔºÅÔºàÂèØËÉΩÊàëÁöÑÊêúÁ¥¢ËÉΩÂäõÂ∑Æ‰∫ÜÁÇπÔºå‰∏ÄÁõ¥Ê≤°ÊâæÂà∞Ôºâ  2ÔºâÂõΩÂ§ñÂ∞±‰∏ç‰∏æ‰æã‰∫ÜÔºåÊàëÁúã‰∏çÊáÇÔºÅ3. ÂºÄÊ∫êÁöÑÊ°ÜÊû∂  1ÔºâÂõΩÂ§ñÁöÑÂºÄÊ∫êÊ°ÜÊû∂:  tensorflow/pytorch ÊñáÊ°£+ÊïôÁ®ã+ËßÜÈ¢ëÔºàÂÆòÊñπÊèê‰æõÔºâ  2) ÂõΩÂÜÖÁöÑÂºÄÊ∫êÊ°ÜÊû∂: È¢ùÈ¢ùÔºåËøòÁúü‰∏æ‰æã‰∏çÂá∫Êù•ÔºÅ‰ΩÜÊòØÁâõÈÄºÂêπÂæó‰∏çÊØîÂõΩÂ§ñÂ∑ÆÔºÅÔºàMXNetËôΩÁÑ∂Êúâ‰ºóÂ§öÂõΩ‰∫∫ÂèÇ‰∏éÂºÄÂèëÔºå‰ΩÜ‰∏çËÉΩÁÆóÊòØÂõΩÂÜÖÂºÄÊ∫êÊ°ÜÊû∂„ÄÇÂü∫‰∫éMXNetÁöÑÂä®ÊâãÂ≠¶Ê∑±Â∫¶Â≠¶‰π†(http://zh.d2l.ai & https://discuss.gluon.ai/t/topic/753)‰∏≠ÊñáÊïôÁ®ã,Â∑≤ÁªèÁî±Ê≤êÁ•û(ÊùéÊ≤ê)‰ª•ÂèäÈòøÊñØÈ°ø¬∑Âº†ËÆ≤ÊéàÂΩïÂà∂ÔºåÂÖ¨ÂºÄÂèëÂ∏É(ÊñáÊ°£+Á¨¨‰∏ÄÂ≠£ÊïôÁ®ã+ËßÜÈ¢ëÔºâ„ÄÇ)ÊØè‰∏ÄÊ¨°Ê∑±ÂÖ•ÈÉΩË¶ÅÂéªÁøªÂ¢ôÔºåÊØè‰∏ÄÊ¨°Ê∑±ÂÖ•ÈÉΩË¶ÅGoogleÔºåÊØè‰∏ÄÊ¨°ÁúãÁùÄÂõΩÂÜÖÁöÑËØ¥: ÂìàÂ∑•Â§ß„ÄÅËÆØÈ£û„ÄÅ‰∏≠ÁßëÂ§ß„ÄÅÁôæÂ∫¶„ÄÅÈòøÈáåÂ§öÁâõÈÄºÔºå‰ΩÜÊòØËµÑÊñôËøòÊòØÂæóÂõΩÂ§ñÂéªÊâæÔºÅÊúâÊó∂ÂÄôÁúüÁöÑÊå∫ÊÅ®ÁöÑÔºÅÁúüÁöÑÊúâÁÇπÁûß‰∏çËµ∑Ëá™Â∑±ÂõΩÂÜÖÁöÑÊäÄÊúØÁéØÂ¢ÉÔºÅÂΩìÁÑ∂Ë∞¢Ë∞¢ÂõΩÂÜÖÂæàÂ§öÂçöÂÆ¢Â§ß‰Ω¨ÔºåÁâπÂà´ÊòØ‰∏Ä‰∫õÂÖ•Èó®ÁöÑDemoÂíåÂü∫Êú¨Ê¶ÇÂøµ„ÄÇ„ÄêÊ∑±ÂÖ•ÁöÑÊ∞¥Âπ≥ÊúâÈôêÔºåÊ≤°ÁúãÊáÇ„Äë„ÄêÂÖ•Èó®È°ªÁü•„ÄëÂøÖÈ°ª‰∫ÜËß£: https://github.com/apachecn/AiLearning/tree/master/nlp„ÄêÂÖ•Èó®ÊïôÁ®ã„ÄëÂº∫ÁÉàÊé®Ëçê: PyTorch Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ: https://github.com/apachecn/NLP-with-PyTorchPython Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ Á¨¨‰∫åÁâà: https://usyiyi.github.io/nlp-py-2e-zhÊé®Ëçê‰∏Ä‰∏™liuhuanyongÂ§ß‰Ω¨Êï¥ÁêÜÁöÑnlpÂÖ®Èù¢Áü•ËØÜ‰ΩìÁ≥ª: https://liuhuanyong.github.ioÂºÄÊ∫ê - ËØçÂêëÈáèÂ∫ìÈõÜÂêà:https://www.cnblogs.com/Darwin2000/p/5786984.htmlhttps://ai.tencent.com/ailab/nlp/embedding.htmlhttps://blog.csdn.net/xiezj007/article/details/85073890https://github.com/Embedding/Chinese-Word-Vectorshttps://github.com/brightmart/nlp_chinese_corpushttps://github.com/codemayq/chinese_chatbot_corpushttps://github.com/candlewill/Dialog_Corpus1.‰ΩøÁî®Âú∫ÊôØ ÔºàÁôæÂ∫¶ÂÖ¨ÂºÄËØæÔºâÁ¨¨‰∏ÄÈÉ®ÂàÜ ÂÖ•Èó®‰ªãÁªç1.) Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂÖ•Èó®‰ªãÁªçÁ¨¨‰∫åÈÉ®ÂàÜ Êú∫Âô®ÁøªËØë2.) Êú∫Âô®ÁøªËØëÁ¨¨‰∏âÈÉ®ÂàÜ ÁØáÁ´†ÂàÜÊûê3.1.) ÁØáÁ´†ÂàÜÊûê-ÂÜÖÂÆπÊ¶ÇËø∞3.2.) ÁØáÁ´†ÂàÜÊûê-ÂÜÖÂÆπÊ†áÁ≠æ3.3.) ÁØáÁ´†ÂàÜÊûê-ÊÉÖÊÑüÂàÜÊûê3.4.) ÁØáÁ´†ÂàÜÊûê-Ëá™Âä®ÊëòË¶ÅÁ¨¨ÂõõÈÉ®ÂàÜ UNIT-ËØ≠Ë®ÄÁêÜËß£‰∏é‰∫§‰∫íÊäÄÊúØ4.) UNIT-ËØ≠Ë®ÄÁêÜËß£‰∏é‰∫§‰∫íÊäÄÊúØÂ∫îÁî®È¢ÜÂüü‰∏≠ÊñáÂàÜËØç:ÊûÑÂª∫DAGÂõæÂä®ÊÄÅËßÑÂàíÊü•ÊâæÔºåÁªºÂêàÊ≠£ÂèçÂêëÔºàÊ≠£ÂêëÂä†ÊùÉÂèçÂêëËæìÂá∫ÔºâÊ±ÇÂæóDAGÊúÄÂ§ßÊ¶ÇÁéáË∑ØÂæÑ‰ΩøÁî®‰∫ÜSBMEËØ≠ÊñôËÆ≠ÁªÉ‰∫Ü‰∏ÄÂ•ó HMM + Viterbi Ê®°ÂûãÔºåËß£ÂÜ≥Êú™ÁôªÂΩïËØçÈóÆÈ¢ò1.ÊñáÊú¨ÂàÜÁ±ªÔºàText ClassificationÔºâÊñáÊú¨ÂàÜÁ±ªÊòØÊåáÊ†áËÆ∞Âè•Â≠êÊàñÊñáÊ°£Ôºå‰æãÂ¶ÇÁîµÂ≠êÈÇÆ‰ª∂ÂûÉÂúæÈÇÆ‰ª∂ÂàÜÁ±ªÂíåÊÉÖÊÑüÂàÜÊûê„ÄÇ‰∏ãÈù¢ÊòØ‰∏Ä‰∫õÂæàÂ•ΩÁöÑÂàùÂ≠¶ËÄÖÊñáÊú¨ÂàÜÁ±ªÊï∞ÊçÆÈõÜ„ÄÇË∑ØÈÄèÁ§æNewswire‰∏ªÈ¢òÂàÜÁ±ªÔºàË∑ØÈÄèÁ§æ-21578Ôºâ„ÄÇ1987Âπ¥Ë∑ØÈÄèÁ§æÂá∫Áé∞ÁöÑ‰∏ÄÁ≥ªÂàóÊñ∞ÈóªÊñá‰ª∂ÔºåÊåâÁ±ªÂà´ÁºñÂà∂Á¥¢Âºï„ÄÇÂè¶ËßÅRCV1ÔºåRCV2ÂíåTRC2„ÄÇIMDBÁîµÂΩ±ËØÑËÆ∫ÊÉÖÊÑüÂàÜÁ±ªÔºàÊñØÂù¶Á¶èÔºâ„ÄÇÊù•Ëá™ÁΩëÁ´ôimdb.comÁöÑ‰∏ÄÁ≥ªÂàóÁîµÂΩ±ËØÑËÆ∫ÂèäÂÖ∂ÁßØÊûÅÊàñÊ∂àÊûÅÁöÑÊÉÖÁª™„ÄÇÊñ∞ÈóªÁªÑÁîµÂΩ±ËØÑËÆ∫ÊÉÖÊÑüÂàÜÁ±ªÔºàÂ∫∑Â•àÂ∞îÔºâ„ÄÇÊù•Ëá™ÁΩëÁ´ôimdb.comÁöÑ‰∏ÄÁ≥ªÂàóÁîµÂΩ±ËØÑËÆ∫ÂèäÂÖ∂ÁßØÊûÅÊàñÊ∂àÊûÅÁöÑÊÉÖÁª™„ÄÇÊúâÂÖ≥Êõ¥Â§ö‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖÂ∏ñÂ≠ê:ÂçïÊ†áÁ≠æÊñáÊú¨ÂàÜÁ±ªÁöÑÊï∞ÊçÆÈõÜ„ÄÇÊÉÖÊÑüÂàÜÊûêÊØîËµõÂú∞ÂùÄ: https://www.kaggle.com/c/word2vec-nlp-tutorialÊñπÊ°à‰∏Ä(0.86): WordCount + Êú¥Á¥† BayesÊñπÊ°à‰∫å(0.94): LDA + ÂàÜÁ±ªÊ®°ÂûãÔºàknn/ÂÜ≥Á≠ñÊ†ë/ÈÄªËæëÂõûÂΩí/svm/xgboost/ÈöèÊú∫Ê£ÆÊûóÔºâa) ÂÜ≥Á≠ñÊ†ëÊïàÊûú‰∏çÊòØÂæàÂ•ΩÔºåËøôÁßçËøûÁª≠ÁâπÂæÅ‰∏çÂ§™ÈÄÇÂêàÁöÑb) ÈÄöËøáÂèÇÊï∞Ë∞ÉÊï¥ 200 ‰∏™topicÔºå‰ø°ÊÅØÈáè‰øùÂ≠òÊïàÊûúËæÉ‰ºòÔºàËÆ°ÁÆó‰∏ªÈ¢òÔºâÊñπÊ°à‰∏â(0.72): word2vec + CNNËØ¥ÂÆûËØù: Ê≤°Êúâ‰∏Ä‰∏™Â•ΩÁöÑÊú∫Âô®ÔºåÊòØË∞É‰∏çÂá∫Êù•‰∏Ä‰∏™Â•ΩÁöÑÁªìÊûú (: ÈÄÉÈÄöËøáAUC Êù•ËØÑ‰º∞Ê®°ÂûãÁöÑÊïàÊûú2.ËØ≠Ë®ÄÊ®°ÂûãÔºàLanguage ModelingÔºâËØ≠Ë®ÄÂª∫Ê®°Ê∂âÂèäÂºÄÂèë‰∏ÄÁßçÁªüËÆ°Ê®°ÂûãÔºåÁî®‰∫éÈ¢ÑÊµãÂè•Â≠ê‰∏≠ÁöÑ‰∏ã‰∏Ä‰∏™ÂçïËØçÊàñ‰∏Ä‰∏™ÂçïËØç‰∏≠ÁöÑ‰∏ã‰∏Ä‰∏™ÂçïËØç„ÄÇÂÆÉÊòØËØ≠Èü≥ËØÜÂà´ÂíåÊú∫Âô®ÁøªËØëÁ≠â‰ªªÂä°‰∏≠ÁöÑÂâçÁΩÆ‰ªªÂä°„ÄÇÂÆÉÊòØËØ≠Èü≥ËØÜÂà´ÂíåÊú∫Âô®ÁøªËØëÁ≠â‰ªªÂä°‰∏≠ÁöÑÂâçÁΩÆ‰ªªÂä°„ÄÇ‰∏ãÈù¢ÊòØ‰∏Ä‰∫õÂæàÂ•ΩÁöÑÂàùÂ≠¶ËÄÖËØ≠Ë®ÄÂª∫Ê®°Êï∞ÊçÆÈõÜ„ÄÇÂè§ËÖæÂ†°È°πÁõÆÔºå‰∏ÄÁ≥ªÂàóÂÖçË¥π‰π¶Á±çÔºåÂèØ‰ª•Áî®Á∫ØÊñáÊú¨Ê£ÄÁ¥¢ÂêÑÁßçËØ≠Ë®Ä„ÄÇËøòÊúâÊõ¥Â§öÊ≠£ÂºèÁöÑËØ≠ÊñôÂ∫ìÂæóÂà∞‰∫ÜÂæàÂ•ΩÁöÑÁ†îÁ©∂; ‰æãÂ¶Ç:Â∏ÉÊúóÂ§ßÂ≠¶Áé∞‰ª£ÁæéÂõΩËã±ËØ≠Ê†áÂáÜËØ≠ÊñôÂ∫ì„ÄÇÂ§ßÈáèËã±ËØ≠ÂçïËØçÊ†∑Êú¨„ÄÇË∞∑Ê≠å10‰∫øÂ≠óËØ≠ÊñôÂ∫ì„ÄÇÊñ∞ËØçÂèëÁé∞‰∏≠ÊñáÂàÜËØçÊñ∞ËØçÂèëÁé∞python3Âà©Áî®‰∫í‰ø°ÊÅØÂíåÂ∑¶Âè≥‰ø°ÊÅØÁÜµÁöÑ‰∏≠ÊñáÂàÜËØçÊñ∞ËØçÂèëÁé∞https://github.com/zhanzecheng/Chinese_segment_augmentÂè•Â≠êÁõ∏‰ººÂ∫¶ËØÜÂà´È°πÁõÆÂú∞ÂùÄ: https://www.kaggle.com/c/quora-question-pairsËß£ÂÜ≥ÊñπÊ°à: word2vec + Bi-GRUÊñáÊú¨Á∫†Èîôbi-gram + levenshtein3.ÂõæÂÉèÂ≠óÂπïÔºàImage CaptioningÔºâmageÂ≠óÂπïÊòØ‰∏∫ÁªôÂÆöÂõæÂÉèÁîüÊàêÊñáÊú¨ÊèèËø∞ÁöÑ‰ªªÂä°„ÄÇ‰∏ãÈù¢ÊòØ‰∏Ä‰∫õÂæàÂ•ΩÁöÑÂàùÂ≠¶ËÄÖÂõæÂÉèÂ≠óÂπïÊï∞ÊçÆÈõÜ„ÄÇ‰∏ä‰∏ãÊñá‰∏≠ÁöÑÂÖ¨ÂÖ±ÂØπË±°ÔºàCOCOÔºâ„ÄÇÂåÖÂê´Ë∂ÖËøá12‰∏áÂº†Â∏¶ÊèèËø∞ÁöÑÂõæÂÉèÁöÑÈõÜÂêàFlickr 8K„ÄÇ‰ªéflickr.comËé∑ÂèñÁöÑ8ÂçÉ‰∏™ÊèèËø∞ÂõæÂÉèÁöÑÈõÜÂêà„ÄÇFlickr 30K„ÄÇ‰ªéflickr.comËé∑ÂèñÁöÑ3‰∏á‰∏™ÊèèËø∞ÂõæÂÉèÁöÑÈõÜÂêà„ÄÇÊ¨≤‰∫ÜËß£Êõ¥Â§öÔºåËØ∑ÁúãÂ∏ñÂ≠ê:Êé¢Á¥¢ÂõæÂÉèÂ≠óÂπïÊï∞ÊçÆÈõÜÔºå2016Âπ¥4.Êú∫Âô®ÁøªËØëÔºàMachine TranslationÔºâÊú∫Âô®ÁøªËØëÊòØÂ∞ÜÊñáÊú¨‰ªé‰∏ÄÁßçËØ≠Ë®ÄÁøªËØëÊàêÂè¶‰∏ÄÁßçËØ≠Ë®ÄÁöÑ‰ªªÂä°„ÄÇ‰∏ãÈù¢ÊòØ‰∏Ä‰∫õÂæàÂ•ΩÁöÑÂàùÂ≠¶ËÄÖÊú∫Âô®ÁøªËØëÊï∞ÊçÆÈõÜ„ÄÇÂä†ÊãøÂ§ßÁ¨¨36Â±äËÆÆ‰ºöÁöÑÂçèË∞ÉÂõΩ‰ºöËÆÆÂëò„ÄÇÊàêÂØπÁöÑËã±ËØ≠ÂíåÊ≥ïËØ≠Âè•Â≠ê„ÄÇÊ¨ßÊ¥≤ËÆÆ‰ºöËØâËÆºÂπ≥Ë°åËØ≠ÊñôÂ∫ì1996-2011„ÄÇÂè•Â≠êÂØπ‰∏ÄÂ•óÊ¨ßÊ¥≤ËØ≠Ë®Ä„ÄÇÊúâÂ§ßÈáèÊ†áÂáÜÊï∞ÊçÆÈõÜÁî®‰∫éÂπ¥Â∫¶Êú∫Âô®ÁøªËØëÊåëÊàò; ÁúãÂà∞:ÁªüËÆ°Êú∫Âô®ÁøªËØëÊú∫Âô®ÁøªËØëEncoder + Decoder(Attention)ÂèÇËÄÉÊ°à‰æã: http://pytorch.apachecn.org/cn/tutorials/intermediate/seq2seq_translation_tutorial.html5.ÈóÆÁ≠îÁ≥ªÁªüÔºàQuestion AnsweringÔºâÈóÆÁ≠îÊòØ‰∏ÄÈ°π‰ªªÂä°ÔºåÂÖ∂‰∏≠Êèê‰æõ‰∫Ü‰∏Ä‰∏™Âè•Â≠êÊàñÊñáÊú¨Ê†∑Êú¨Ôºå‰ªé‰∏≠ÊèêÂá∫ÈóÆÈ¢òÂπ∂‰∏îÂøÖÈ°ªÂõûÁ≠îÈóÆÈ¢ò„ÄÇ‰∏ãÈù¢ÊòØ‰∏Ä‰∫õÂæàÂ•ΩÁöÑÂàùÂ≠¶ËÄÖÈóÆÈ¢òÂõûÁ≠îÊï∞ÊçÆÈõÜ„ÄÇÊñØÂù¶Á¶èÈóÆÈ¢òÂõûÁ≠îÊï∞ÊçÆÈõÜÔºàSQuADÔºâ„ÄÇÂõûÁ≠îÊúâÂÖ≥Áª¥Âü∫ÁôæÁßëÊñáÁ´†ÁöÑÈóÆÈ¢ò„ÄÇDeepmindÈóÆÈ¢òÂõûÁ≠îËØ≠ÊñôÂ∫ì„ÄÇ‰ªéÊØèÊó•ÈÇÆÊä•ÂõûÁ≠îÊúâÂÖ≥Êñ∞ÈóªÊñáÁ´†ÁöÑÈóÆÈ¢ò„ÄÇ‰∫öÈ©¨ÈÄäÈóÆÁ≠îÊï∞ÊçÆ„ÄÇÂõûÁ≠îÊúâÂÖ≥‰∫öÈ©¨ÈÄä‰∫ßÂìÅÁöÑÈóÆÈ¢ò„ÄÇÊúâÂÖ≥Êõ¥Â§ö‰ø°ÊÅØÔºåËØ∑ÂèÇÈòÖÂ∏ñÂ≠ê:Êï∞ÊçÆÈõÜ: ÊàëÂ¶Ç‰ΩïËé∑ÂæóÈóÆÁ≠îÁΩëÁ´ôÁöÑËØ≠ÊñôÂ∫ìÔºåÂ¶ÇQuoraÊàñYahoo AnswersÊàñStack OverflowÊù•ÂàÜÊûêÁ≠îÊ°àË¥®ÈáèÔºü6.ËØ≠Èü≥ËØÜÂà´ÔºàSpeech RecognitionÔºâËØ≠Èü≥ËØÜÂà´ÊòØÂ∞ÜÂè£ËØ≠ÁöÑÈü≥È¢ëËΩ¨Êç¢‰∏∫‰∫∫Á±ªÂèØËØªÊñáÊú¨ÁöÑ‰ªªÂä°„ÄÇ‰∏ãÈù¢ÊòØ‰∏Ä‰∫õÂæàÂ•ΩÁöÑÂàùÂ≠¶ËÄÖËØ≠Èü≥ËØÜÂà´Êï∞ÊçÆÈõÜ„ÄÇTIMITÂ£∞Â≠¶ - ËØ≠Èü≥ËøûÁª≠ËØ≠Èü≥ËØ≠ÊñôÂ∫ì„ÄÇ‰∏çÊòØÂÖçË¥πÁöÑÔºå‰ΩÜÂõ†ÂÖ∂ÂπøÊ≥õ‰ΩøÁî®ËÄå‰∏äÂ∏Ç„ÄÇÂè£ËØ≠ÁæéÂõΩËã±ËØ≠ÂíåÁõ∏ÂÖ≥ÁöÑËΩ¨ÂΩï„ÄÇVoxForge„ÄÇÁî®‰∫éÊûÑÂª∫Áî®‰∫éËØ≠Èü≥ËØÜÂà´ÁöÑÂºÄÊ∫êÊï∞ÊçÆÂ∫ìÁöÑÈ°πÁõÆ„ÄÇLibriSpeech ASRËØ≠ÊñôÂ∫ì„ÄÇ‰ªéLibriVoxÊî∂ÈõÜÁöÑÂ§ßÈáèËã±ËØ≠ÊúâÂ£∞ËØªÁâ©„ÄÇ7.Ëá™Âä®ÊñáÊëòÔºàDocument SummarizationÔºâÊñáÊ°£ÊëòË¶ÅÊòØÂàõÂª∫ËæÉÂ§ßÊñáÊ°£ÁöÑÁÆÄÁü≠ÊúâÊÑè‰πâÊèèËø∞ÁöÑ‰ªªÂä°„ÄÇ‰∏ãÈù¢ÊòØ‰∏Ä‰∫õÂæàÂ•ΩÁöÑÂàùÂ≠¶ËÄÖÊñáÊ°£ÊëòË¶ÅÊï∞ÊçÆÈõÜ„ÄÇÊ≥ïÂæãÊ°à‰æãÊä•ÂëäÊï∞ÊçÆÈõÜ„ÄÇÊî∂ÈõÜ‰∫Ü4000‰ªΩÊ≥ïÂæãÊ°à‰ª∂ÂèäÂÖ∂ÊëòË¶Å„ÄÇTIPSTERÊñáÊú¨ÊëòË¶ÅËØÑ‰º∞‰ºöËÆÆËØ≠ÊñôÂ∫ì„ÄÇÊî∂ÈõÜ‰∫ÜËøë200‰ªΩÊñá‰ª∂ÂèäÂÖ∂ÊëòË¶Å„ÄÇËã±ËØ≠Êñ∞ÈóªÊñáÊú¨ÁöÑAQUAINTËØ≠ÊñôÂ∫ì„ÄÇ‰∏çÊòØÂÖçË¥πÁöÑÔºåËÄåÊòØÂπøÊ≥õ‰ΩøÁî®ÁöÑ„ÄÇÊñ∞ÈóªÊñáÁ´†ÁöÑËØ≠ÊñôÂ∫ì„ÄÇÊ¨≤‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØ:ÊñáÊ°£ÁêÜËß£‰ºöËÆÆÔºàDUCÔºâ‰ªªÂä°„ÄÇÂú®Âì™ÈáåÂèØ‰ª•ÊâæÂà∞Áî®‰∫éÊñáÊú¨ÊëòË¶ÅÁöÑËâØÂ•ΩÊï∞ÊçÆÈõÜÔºüÂëΩÂêçÂÆû‰ΩìËØÜÂà´Bi-LSTM CRFÂèÇËÄÉÊ°à‰æã: http://pytorch.apachecn.org/cn/tutorials/beginner/nlp/advanced_tutorial.htmlCRFÊé®ËçêÊñáÊ°£: https://www.jianshu.com/p/55755fc649b1ÊñáÊú¨ÊëòË¶ÅÊäΩÂèñÂºèword2vec + textrankword2vecÊé®ËçêÊñáÊ°£: https://www.zhihu.com/question/44832436/answer/266068967textrankÊé®ËçêÊñáÊ°£: https://blog.csdn.net/BaiHuaXiu123/article/details/77847232GraphÂõæËÆ°ÁÆó„ÄêÊÖ¢ÊÖ¢Êõ¥Êñ∞„ÄëÊï∞ÊçÆÈõÜ: https://github.com/apachecn/data/tree/master/graphÂ≠¶‰π†ËµÑÊñô: spark graphXÂÆûÊàò.pdf „ÄêÊñá‰ª∂Â§™Â§ß‰∏çÊñπ‰æøÊèê‰æõÔºåËá™Â∑±ÁôæÂ∫¶„ÄëÁü•ËØÜÂõæË∞±Áü•ËØÜÂõæË∞±ÔºåÊàëÂè™ËÆ§ SimmerChan: „ÄêÁü•ËØÜÂõæË∞±-ÁªôAIË£Ö‰∏™Â§ßËÑë„ÄëËØ¥ÂÆûËØùÔºåÊàëÊòØÁúãËøôÂçö‰∏ªËÄÅÂì•ÂÜôÁöÑÂçöÂÆ¢ÈïøÂ§ßÁöÑÔºåÂÜôÁöÑÁúüÁöÑÊòØÊ∑±ÂÖ•ÊµÖÂá∫„ÄÇÊàëÂæàÂñúÊ¨¢ÔºåÊâÄ‰ª•Â∞±ÂàÜ‰∫´ÁªôÂ§ßÂÆ∂ÔºåÂ∏åÊúõ‰Ω†‰ª¨‰πüÂñúÊ¨¢„ÄÇËøõ‰∏ÄÊ≠•ÈòÖËØªÂ¶ÇÊûúÊÇ®Â∏åÊúõÊõ¥Ê∑±ÂÖ•ÔºåÊú¨ËäÇÊèê‰æõ‰∫ÜÂÖ∂‰ªñÊï∞ÊçÆÈõÜÂàóË°®„ÄÇÁª¥Âü∫ÁôæÁßëÁ†îÁ©∂‰∏≠‰ΩøÁî®ÁöÑÊñáÊú¨Êï∞ÊçÆÈõÜÊï∞ÊçÆÈõÜ: ËÆ°ÁÆóËØ≠Ë®ÄÂ≠¶ÂÆ∂ÂíåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁ†îÁ©∂‰∫∫Âëò‰ΩøÁî®ÁöÑ‰∏ªË¶ÅÊñáÊú¨ËØ≠ÊñôÂ∫ìÊòØ‰ªÄ‰πàÔºüÊñØÂù¶Á¶èÁªüËÆ°Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜËØ≠ÊñôÂ∫ìÊåâÂ≠óÊØçÈ°∫Â∫èÊéíÂàóÁöÑNLPÊï∞ÊçÆÈõÜÂàóË°®ËØ•Êú∫ÊûÑNLTKÂú®DL4J‰∏äÊâìÂºÄÊ∑±Â∫¶Â≠¶‰π†Êï∞ÊçÆNLPÊï∞ÊçÆÈõÜÂõΩÂÜÖÂºÄÊîæÊï∞ÊçÆÈõÜ: https://bosonnlp.com/dev/resourceÂèÇËÄÉÊØîËµõÊî∂ÈõÜÂπ≥Âè∞pbharrin/machinelearninginactionML MasteryËá¥Ë∞¢ÊúÄËøëÊó†ÊÑèÊî∂Âà∞Áæ§ÂèãÊé®ÈÄÅÁöÑÈìæÊé•ÔºåÂèëÁé∞ÂæóÂà∞Â§ß‰Ω¨È´òÂ∫¶ÁöÑËÆ§ÂèØÔºåÂπ∂Âú®ÁÉ≠ÂøÉÁöÑÊé®Âπø„ÄÇÂú®Ê≠§ÊÑüË∞¢:ÈáèÂ≠ê‰Ωç‰∫∫Â∑•Êô∫ËÉΩÂâçÊ≤øËÆ≤‰π†ËµûÂä©Êàë‰ª¨"
12,vagabond-systems/jpmc-task-1,https://github.com/vagabond-systems/jpmc-task-1/blob/main/README.md,Python,JPMC Task 1Starter repo for task 1 of the JPMC software engineering program
13,langchain-ai/langchain,https://github.com/langchain-ai/langchain/blob/master/README.md,Python,"ü¶úÔ∏èüîó LangChain‚ö° Building applications with LLMs through composability ‚ö°Looking for the JS/TS version? Check out LangChain.js.Production Support: As you move your LangChains into production, we'd love to offer more hands-on support.Fill out this form to share more about what you're building, and our team will get in touch.üö®Breaking Changes for select chains (SQLDatabase) on 7/28/23In an effort to make langchain leaner and safer, we are moving select chains to langchain_experimental.This migration has already started, but we are remaining backwards compatible until 7/28.On that date, we will remove functionality from langchain.Read more about the motivation and the progress here.Read how to migrate your code here.Quick Installpip install langchainorpip install langsmith && conda install langchain -c conda-forgeü§î What is this?Large language models (LLMs) are emerging as a transformative technology, enabling developers to build applications that they previously could not. However, using these LLMs in isolation is often insufficient for creating a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.This library aims to assist in the development of those types of applications. Common examples of these applications include:‚ùì Question Answering over specific documentsDocumentationEnd-to-end Example: Question Answering over Notion Databaseüí¨ ChatbotsDocumentationEnd-to-end Example: Chat-LangChainü§ñ AgentsDocumentationEnd-to-end Example: GPT+WolframAlphaüìñ DocumentationPlease see here for full documentation on:Getting started (installation, setting up the environment, simple examples)How-To examples (demos, integrations, helper functions)Reference (full API docs)Resources (high-level explanation of core concepts)üöÄ What can this help with?There are six main areas that LangChain is designed to help with.These are, in increasing order of complexity:üìÉ LLMs and Prompts:This includes prompt management, prompt optimization, a generic interface for all LLMs, and common utilities for working with LLMs.üîó Chains:Chains go beyond a single LLM call and involve sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.üìö Data Augmented Generation:Data Augmented Generation involves specific types of chains that first interact with an external data source to fetch data for use in the generation step. Examples include summarization of long pieces of text and question/answering over specific data sources.ü§ñ Agents:Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end-to-end agents.üß† Memory:Memory refers to persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.üßê Evaluation:[BETA] Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this.For more information on these concepts, please see our full documentation.üíÅ ContributingAs an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.For detailed information on how to contribute, see here."
14,pytorch/vision,https://github.com/pytorch/vision/blob/main/README.md,Python,"torchvisionThe torchvision package consists of popular datasets, model architectures, and common image transformations for computervision.InstallationPlease refer to the officialinstructions to install the stableversions of torch and torchvision on your system.To build source, refer to our contributingpage.The following is the corresponding torchvision versions and supported Pythonversions.torchtorchvisionPythonmain / nightlymain / nightly>=3.8, <=3.112.00.15>=3.8, <=3.111.130.14>=3.7.2, <=3.101.120.13>=3.7, <=3.10    older versionstorchtorchvisionPython1.110.12>=3.7, <=3.101.100.11>=3.6, <=3.91.90.10>=3.6, <=3.91.80.9>=3.6, <=3.91.70.8>=3.6, <=3.91.60.7>=3.6, <=3.81.50.6>=3.5, <=3.81.40.5==2.7, >=3.5, <=3.81.30.4.2 / 0.4.3==2.7, >=3.5, <=3.71.20.4.1==2.7, >=3.5, <=3.71.10.3==2.7, >=3.5, <=3.7<=1.00.2==2.7, >=3.5, <=3.7Image BackendsTorchvision currently supports the following image backends:torch tensorsPIL images:PillowPillow-SIMD - a much faster drop-in replacement for Pillow with SIMD.Read more in in our docs.[UNSTABLE] Video BackendTorchvision currently supports the following video backends:pyav (default) - Pythonic binding for ffmpeg libraries.video_reader - This needs ffmpeg to be installed and torchvision to be built from source. There shouldn't be anyconflicting version of ffmpeg installed. Currently, this is only supported on Linux.conda install -c conda-forge ffmpegpython setup.py installUsing the models on C++TorchVision provides an example project for how to use the models on C++ using JIT Script.Installation From source:mkdir buildcd build# Add -DWITH_CUDA=on support for the CUDA if neededcmake ..makemake installOnce installed, the library can be accessed in cmake (after properly configuring CMAKE_PREFIX_PATH) via theTorchVision::TorchVision target:find_package(TorchVision REQUIRED)target_link_libraries(my-target PUBLIC TorchVision::TorchVision)The TorchVision package will also automatically look for the Torch package and add it as a dependency tomy-target, so make sure that it is also available to cmake via the CMAKE_PREFIX_PATH.For an example setup, take a look at examples/cpp/hello_world.Python linking is disabled by default when compiling TorchVision with CMake, this allows you to run models without anyPython dependency. In some special cases where TorchVision's operators are used from Python code, you may need to linkto Python. This can be done by passing -DUSE_PYTHON=on to CMake.TorchVision OperatorsIn order to get the torchvision operators registered with torch (eg. for the JIT), all you need to do is to ensure thatyou #include <torchvision/vision.h> in your project.DocumentationYou can find the API documentation on the pytorch website: https://pytorch.org/vision/stable/index.htmlContributingSee the CONTRIBUTING file for how to help out.Disclaimer on DatasetsThis is a utility library that downloads and prepares public datasets. We do not host or distribute these datasets,vouch for their quality or fairness, or claim that you have license to use the dataset. It is your responsibility todetermine whether you have permission to use the dataset under the dataset's license.If you're a dataset owner and wish to update any part of it (description, citation, etc.), or do not want your datasetto be included in this library, please get in touch through a GitHub issue. Thanks for your contribution to the MLcommunity!Pre-trained Model LicenseThe pre-trained models provided in this library may have their own licenses or terms and conditions derived from thedataset used for training. It is your responsibility to determine whether you have permission to use the models for youruse case.More specifically, SWAG models are released under the CC-BY-NC 4.0 license. SeeSWAG LICENSE for additional details.Citing TorchVisionIf you find TorchVision useful in your work, please consider citing the following BibTeX entry:@software{torchvision2016,    title        = {TorchVision: PyTorch's Computer Vision library},    author       = {TorchVision maintainers and contributors},    year         = 2016,    journal      = {GitHub repository},    publisher    = {GitHub},    howpublished = {\\url{https://github.com/pytorch/vision}}}"
15,unifyai/ivy,https://github.com/unifyai/ivy/blob/main/README.md,Python,"üöÄ We are granting pilot access to Ivy's Compiler and Transpilerto some users, join the waitlist if youwant to test them out!                    Status                                                                                                                                Unified AI                                                                                                Ivy is both an ML transpiler and a framework, currently supporting JAX,TensorFlow, PyTorch and Numpy.Ivy unifies all ML frameworks üí• enabling you not only to write codethat can be used with any of these frameworks as the backend, but alsoto convert üîÑ any function, model or library written in any of them toyour preferred framework!You can check out Ivy as a transpiler and Ivyas a framework to learn more about this, try outIvy straight away going through the Setting up Ivysection, or dive deep into Ivy's Documentation andExamples!If you would like to contribute, you can join our growingCommunity üåç, check out our Contributingguide, and take a look at the opentasksif you'd like to dive straight in üßë‚ÄçüíªLet's unify.ai together ü¶æIvy as a transpilerIvy's transpiler allows you to use code from any other framework (orfrom any other version of the same framework!) in your own code, by justadding one line of code. Under the hood, Ivy traces a computationalgraph and leverages the frontends and backends to link one framework toanother.This way, Ivy makes all ML-related projects available for you,independently of the framework you want to use to research, develop, ordeploy systems. Feel free to head over to the docs for the full APIreference, but the functions you'd most likely want to use are:# Compiles a function into an efficient fully-functional graph, removing all wrapping and redundant codeivy.compile()# Converts framework-specific code to a different frameworkivy.transpile()# Converts framework-specific code to Ivyivy.unify()These functions can be used eagerly or lazily. If you pass the necessaryarguments for function tracing, the compilation/transpilation step willhappen instantly (eagerly). Otherwise, the compilation/transpilationwill happen only when the returned function is first invoked.import ivyimport jaxivy.set_backend(\""jax\"")# Simple JAX function to transpiledef test_fn(x):    return jax.numpy.sum(x)x1 = ivy.array([1., 2.])# Arguments are available -> transpilation happens eagerlyeager_graph = ivy.transpile(test_fn, source=\""jax\"", to=\""torch\"", args=(x1,))# eager_graph is now torch code and runs efficientlyret = eager_graph(x1)# Arguments are not available -> transpilation happens lazilylazy_graph = ivy.transpile(test_fn, source=\""jax\"", to=\""torch\"")# The transpiled graph is initialized, transpilation will happen hereret = lazy_graph(x1)# lazy_graph is now torch code and runs efficientlyret = lazy_graph(x1)If you want to learn more, you can find more information in the Ivy asa transpiler section of thedocs!When should I use Ivy as a transpiler?If you want to use building blocks published in other frameworks (neuralnetworks, layers, array computing libraries, training pipelines...),you want to integrate code developed in various frameworks, or maybestraight up move code from one framework to another, the transpiler isdefinitely the tool üîß for the job! As the output of transpilation isnative code in the target framework, you can use the converted code justas if it was code originally developed in that framework, applyingframework-specific optimizations or tools, instantly exposing yourproject to all of the unique perks of a different framework.Ivy as a frameworkThe Ivy framework is built on top of various essential components,mainly the BackendHandler,which manages what framework is being used behind the scenes and theBackend FunctionalAPIs,which provide framework-specific implementations of the Ivy functions.Likewise, classes such as ivy.Container or ivy.Array are alsoavailable, facilitating the use of structured data and array-likeobjects (learn more about themhere!).All of the functionalities in Ivy are exposed through theIvy functional API and the Ivy stateful API. All functions in theFunctionalAPIare Framework Agnostic Functions, which mean that we can use themlike this:import ivyimport jax.numpy as jnpimport tensorflow as tfimport numpy as npimport torchdef mse_loss(y, target):    return ivy.mean((y - target)**2)jax_mse   = mse_loss(jnp.ones((5,)), jnp.ones((5,)))tf_mse    = mse_loss(tf.ones((5,)), tf.ones((5,)))np_mse    = mse_loss(np.ones((5,)), np.ones((5,)))torch_mse = mse_loss(torch.ones((5,)), torch.ones((5,)))In the example above we show how Ivy's functions are compatible withtensors from different frameworks. This is the same for ALL Ivyfunctions. They can accept tensors from any framework and return thecorrect result.The Ivy StatefulAPI,on the other hand, allows you to define trainable modules and layers,which you can use alone or as a part of any other framework code!import ivyclass Regressor(ivy.Module):    def __init__(self, input_dim, output_dim):        self.input_dim = input_dim        self.output_dim = output_dim        super().__init__()    def _build(self, *args, **kwargs):        self.linear0 = ivy.Linear(self.input_dim, 128)        self.linear1 = ivy.Linear(128, self.output_dim)    def _forward(self, x):        x = self.linear0(x)        x = ivy.functional.relu(x)        x = self.linear1(x)        return xIf we put it all together, we'll have something like this. This exampleuses PyTorch as the backend, but this can easily be changed to yourfavorite framework, such as TensorFlow, or JAX.import ivyclass Regressor(ivy.Module):    def __init__(self, input_dim, output_dim):        self.input_dim = input_dim        self.output_dim = output_dim        super().__init__()    def _build(self, *args, **kwargs):        self.linear0 = ivy.Linear(self.input_dim, 128)        self.linear1 = ivy.Linear(128, self.output_dim)    def _forward(self, x):        x = self.linear0(x)        x = ivy.functional.relu(x)        x = self.linear1(x)        return xivy.set_backend('torch')  # set backend to PyTorch (or any other backend!)model = Regressor(input_dim=1, output_dim=1)optimizer = ivy.Adam(0.3)n_training_examples = 2000noise = ivy.random.random_normal(shape=(n_training_examples, 1), mean=0, std=0.1)x = ivy.linspace(-6, 3, n_training_examples).reshape((n_training_examples, 1))y = 0.2 * x ** 2 + 0.5 * x + 0.1 + noisedef loss_fn(v, x, target):    pred = model(x, v=v)    return ivy.mean((pred - target) ** 2)for epoch in range(40):    # forward pass    pred = model(x)    # compute loss and gradients    loss, grads = ivy.execute_with_gradients(lambda params: loss_fn(*params), (model.v, x, y))    # update parameters    model.v = optimizer.step(model.v, grads)    # print current loss    print(f'Epoch: {epoch + 1:2d} --- Loss: {ivy.to_numpy(loss).item():.5f}')print('Finished training!')The model's output can be visualized as follows:   Last but not least, we are also working on specific extension totallywritten in Ivy and therefore usable within any framework, coveringtopics like Mechanics, ComputerVision,Robotics, a Reinforcement LearningGym,Memory and implementation ofvarious Models or Buildertools with trainers, data loadersand more!                                                        As always, you can find more information about Ivy as a framework inthedocs!When should I use Ivy as a framework?As Ivy supports multiple backends, writing code in Ivy breaks you freefrom framework limitations. If you want to publish highly flexible codefor everyone to use, independently of the framework they are using, oryou plan to develop ML-related tools and want them to be interoperablewith not only the already existing frameworks, but also with futureframeworks, then Ivy is for you!Setting up IvyThere are various ways to use Ivy, depending on your preferredenvironment:Installing using pipThe easiest way to set up Ivy is to install it using pip with thefollowing command:pip install ivyor alternatively:python3 -m pip install ivyDockerIf you prefer to use containers, we also have pre-built Docker imageswith all the supported frameworks and some relevant packages alreadyinstalled, which you can pull from:docker pull unifyai/ivy:latestIf you are working on a GPU device, you can pull from:docker pull unifyai/ivy:latest-gpuInstalling from sourceYou can also install Ivy from source if you want to take advantage ofthe latest changes, but we can't ensure everything will work asexpected. üòÖgit clone https://github.com/unifyai/ivy.gitcd ivy pip install --user -e .or alternatively, for the last step:python3 -m pip install --user -e .If you want to set up testing and various frameworks it's probably bestto check out the Contributing - SettingUppage, where OS-specific and IDE-specific instructions and videotutorials to do so are available!Using IvyYou can find quite a lot more examples in the corresponding sectionbelow, but using Ivy is as simple as:Multi-backend Supportimport ivyimport torchimport jaxivy.set_backend(\""jax\"")x = jax.numpy.array([1, 2, 3])y = jax.numpy.array([3, 2, 1])z = ivy.add(x, y)ivy.set_backend('torch')x = torch.tensor([1, 2, 3])y = torch.tensor([3, 2, 1])z = ivy.add(x, y)Transpilation APIimport ivyimport torchimport jaxdef jax_fn(x):    a = jax.numpy.dot(x, x)    b = jax.numpy.mean(x)    return x * a + bjax_x = jax.numpy.array([1, 2, 3])torch_x = torch.tensor([1, 2, 3])torch_fn = ivy.transpile(jax_fn, source=\""jax\"", to=\""torch\"", args=(jax_x,))ret = torch_fn(torch_x)DocumentationThe Ivy Docs page holds all the relevantinformation about Ivy and its framework API reference.There, you will find theDesign page, which isa user-focused guide about the architecture and the building blocks ofIvy. Likewise, you can take a look at the Deepdive, which isoriented towards potential contributors of the code base and explainsthe nuances of Ivy in full detail üîéAnother important sections of the docs isBackground, whichcontextualises the problem Ivy is trying to solve and the current MLExplosion,explaining both (1) why is important to solve thisproblemand (2) how we are adhering to existingstandardsto make this happen.Lastly, you can also find there the RelatedWork section,which paints a clear picture of the role Ivy plays in the ML stack,comparing it to other existing solutions in terms of functionalities andlevel.ExamplesThe Examples page features a wide range ofdemos and tutorials showcasing the functionalities of Ivy along withmultiple use cases, but feel free to check out some shorterframework-specific examples here ‚¨áÔ∏èI'm using PyTorch‚ÄÇ   You can use Ivy to get PyTorch code from:               Any model                                    From TensorFlowimport ivyimport torchimport tensorflow as tf# Get a pretrained keras modeleff_encoder = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(    include_top=False, weights=\""imagenet\"", input_shape=(224, 224, 3))# Transpile it into a torch.nn.Module with the corresponding parametersnoise = tf.random.normal(shape=(1, 224, 224, 3))torch_eff_encoder = ivy.transpile(eff_encoder, to=\""torch\"", args=(noise,))# Build a classifier using the transpiled encoderclass Classifier(torch.nn.Module):    def __init__(self, num_classes=20):        super(Classifier, self).__init__()        self.encoder = torch_eff_encoder        self.fc = torch.nn.Linear(1280, num_classes)    def forward(self, x):        x = self.encoder(x)        return self.fc(x)# Initialize a trainable, customizable, torch.nn.Moduleclassifier = Classifier()ret = classifier(torch.rand((1, 244, 244, 3)))   From JAXimport ivyimport jaximport torch# Get a pretrained haiku model# https://unify.ai/demos/scripts/deepmind_perceiver_io.pyfrom deepmind_perceiver_io import key, perceiver_backbone# Transpile it into a torch.nn.Module with the corresponding parametersdummy_input = jax.random.uniform(key, shape=(1, 3, 224, 224))params = perceiver_backbone.init(rng=key, images=dummy_input)backbone = ivy.transpile(    perceiver_backbone, to=\""torch\"", params_v=params, kwargs={\""images\"": dummy_input})# Build a classifier using the transpiled backboneclass PerceiverIOClassifier(torch.nn.Module):    def __init__(self, num_classes=20):        super(PerceiverIOClassifier, self).__init__()        self.backbone = backbone        self.max_pool = torch.nn.MaxPool2d((512, 1))        self.flatten = torch.nn.Flatten()        self.fc = torch.nn.Linear(1024, num_classes)    def forward(self, x):        x = self.backbone(images=x)        x = self.flatten(self.max_pool(x))        return self.fc(x)# Initialize a trainable, customizable, torch.nn.Moduleclassifier = PerceiverIOClassifier()ret = classifier(torch.rand((1, 3, 224, 224)))Any library   From Tensorflowimport ivyimport torchimport osos.environ[\""SM_FRAMEWORK\""] = \""tf.keras\""import segmentation_models as sm# transpile sm from tensorflow to torchtorch_sm = ivy.transpile(sm, source=\""tensorflow\"", to=\""torch\"")# get some image-like arraysoutput = torch.rand((1, 3, 512, 512))target = torch.rand((1, 3, 512, 512))# and use the transpiled version of any function from the library!out = torch_sm.metrics.iou_score(output, target)   From JAXimport ivyimport raximport torch# transpile rax from jax to torchtorch_rax = ivy.transpile(rax, source=\""jax\"", to=\""torch\"")# get some arraysscores = torch.tensor([2.2, 1.3, 5.4])labels = torch.tensor([1.0, 0.0, 0.0])# and use the transpiled version of any function from the library!out = torch_rax.poly1_softmax_loss(scores, labels)   From NumPyimport ivyimport torchimport madmom# transpile madmon from numpy to torchtorch_madmom = ivy.transpile(madmom, source=\""numpy\"", to=\""torch\"")# get some arraysfreqs = torch.arange(20) * 10# and use the transpiled version of any function from the library!out = torch_madmom.audio.filters.hz2midi(freqs)Any function   From Tensorflowimport ivyimport tensorflow as tfimport torchdef loss(predictions, targets):    return tf.sqrt(tf.reduce_mean(tf.square(predictions - targets)))# transpile any function from tf to torchtorch_loss = ivy.transpile(loss, source=\""tensorflow\"", to=\""torch\"")# get some arraysp = torch.tensor([3.0, 2.0, 1.0])t = torch.tensor([0.0, 0.0, 0.0])# and use the transpiled version!out = torch_loss(p, t)   From JAXimport ivyimport jax.numpy as jnpimport torchdef loss(predictions, targets):    return jnp.sqrt(jnp.mean((predictions - targets) ** 2))# transpile any function from jax to torchtorch_loss = ivy.transpile(loss, source=\""jax\"", to=\""torch\"")# get some arraysp = torch.tensor([3.0, 2.0, 1.0])t = torch.tensor([0.0, 0.0, 0.0])# and use the transpiled version!out = torch_loss(p, t)   From NumPyimport ivyimport numpy as npimport torchdef loss(predictions, targets):    return np.sqrt(np.mean((predictions - targets) ** 2))# transpile any function from numpy to torchtorch_loss = ivy.transpile(loss, source=\""numpy\"", to=\""torch\"")# get some arraysp = torch.tensor([3.0, 2.0, 1.0])t = torch.tensor([0.0, 0.0, 0.0])# and use the transpiled version!out = torch_loss(p, t)I'm using TensorFlow‚ÄÇYou can use Ivy to get TensorFlow code from:Any model   From PyTorchimport ivyimport torchimport timmimport tensorflow as tf# Get a pretrained pytorch modelmlp_encoder = timm.create_model(\""mixer_b16_224\"", pretrained=True, num_classes=0)# Transpile it into a keras.Model with the corresponding parametersnoise = torch.randn(1, 3, 224, 224)mlp_encoder = ivy.transpile(mlp_encoder, to=\""tensorflow\"", args=(noise,))# Build a classifier using the transpiled encoderclass Classifier(tf.keras.Model):    def __init__(self):        super(Classifier, self).__init__()        self.encoder = mlp_encoder        self.output_dense = tf.keras.layers.Dense(units=1000, activation=\""softmax\"")    def call(self, x):        x = self.encoder(x)        return self.output_dense(x)# Transform the classifier and use it as a standard keras.Modelx = tf.random.normal(shape=(1, 3, 224, 224))model = Classifier()ret = model(x)   From JAXimport ivyimport jaximport tensorflow as tf# Get a pretrained haiku model# https://unify.ai/demos/scripts/deepmind_perceiver_io.pyfrom deepmind_perceiver_io import key, perceiver_backbone# Transpile it into a tf.keras.Model with the corresponding parametersdummy_input = jax.random.uniform(key, shape=(1, 3, 224, 224))params = perceiver_backbone.init(rng=key, images=dummy_input)backbone = ivy.transpile(    perceiver_backbone, to=\""tensorflow\"", params_v=params, args=(dummy_input,))# Build a classifier using the transpiled backboneclass PerceiverIOClassifier(tf.keras.Model):    def __init__(self, num_classes=20):        super(PerceiverIOClassifier, self).__init__()        self.backbone = backbone        self.max_pool = tf.keras.layers.MaxPooling1D(pool_size=512)        self.flatten = tf.keras.layers.Flatten()        self.fc = tf.keras.layers.Dense(num_classes)    def call(self, x):        x = self.backbone(x)        x = self.flatten(self.max_pool(x))        return self.fc(x)# Initialize a trainable, customizable, tf.keras.Modelx = tf.random.normal(shape=(1, 3, 224, 224))classifier = PerceiverIOClassifier()ret = classifier(x)Any library   From PyTorchimport ivyimport korniaimport requestsimport numpy as npimport tensorflow as tffrom PIL import Image# transpile kornia from torch to tensorflowtf_kornia = ivy.transpile(kornia, source=\""torch\"", to=\""tensorflow\"")# get an imageurl = \""http://images.cocodataset.org/train2017/000000000034.jpg\""raw_img = Image.open(requests.get(url, stream=True).raw)# convert it to the format expected by korniaimg = np.array(raw_img)img = tf.transpose(tf.constant(img), (2, 0, 1))img = tf.expand_dims(img, 0) / 255# and use the transpiled version of any function from the library!out = tf_kornia.enhance.sharpness(img, 5)   From JAXimport ivyimport raximport tensorflow as tf# transpile rax from jax to tensorflowtf_rax = ivy.transpile(rax, source=\""jax\"", to=\""tensorflow\"")# get some arraysscores = tf.constant([2.2, 1.3, 5.4])labels = tf.constant([1.0, 0.0, 0.0])# and use the transpiled version of any function from the library!out = tf_rax.poly1_softmax_loss(scores, labels)   From NumPyimport ivyimport madmomimport tensorflow as tf# transpile madmom from numpy to tensorflowtf_madmom = ivy.transpile(madmom, source=\""numpy\"", to=\""tensorflow\"")# get some arraysfreqs = tf.range(20) * 10# and use the transpiled version of any function from the library!out = tf_madmom.audio.filters.hz2midi(freqs)Any function   From PyTorchimport ivyimport torchimport tensorflow as tfdef loss(predictions, targets):    return torch.sqrt(torch.mean((predictions - targets) ** 2))# transpile any function from torch to tensorflowtf_loss = ivy.transpile(loss, source=\""torch\"", to=\""tensorflow\"")# get some arraysp = tf.constant([3.0, 2.0, 1.0])t = tf.constant([0.0, 0.0, 0.0])# and use the transpiled version!out = tf_loss(p, t)   From JAXimport ivyimport jax.numpy as jnpimport tensorflow as tfdef loss(predictions, targets):    return jnp.sqrt(jnp.mean((predictions - targets) ** 2))# transpile any function from jax to tensorflowtf_loss = ivy.transpile(loss, source=\""jax\"", to=\""tensorflow\"")# get some arraysp = tf.constant([3.0, 2.0, 1.0])t = tf.constant([0.0, 0.0, 0.0])# and use the transpiled version!out = tf_loss(p, t)   From NumPyimport ivyimport numpy as npimport tensorflow as tfdef loss(predictions, targets):    return np.sqrt(np.mean((predictions - targets) ** 2))# transpile any function from numpy to tensorflowtf_loss = ivy.transpile(loss, source=\""numpy\"", to=\""tensorflow\"")# get some arraysp = tf.constant([3.0, 2.0, 1.0])t = tf.constant([0.0, 0.0, 0.0])# and use the transpiled version!out = tf_loss(p, t)I'm using Jax‚ÄÇYou can use Ivy to get JAX code from:Any model   From PyTorchimport ivyimport timmimport torchimport jaximport haiku as hk# Get a pretrained pytorch modelmlp_encoder = timm.create_model(\""mixer_b16_224\"", pretrained=True, num_classes=0)# Transpile it into a hk.Module with the corresponding parametersnoise = torch.randn(1, 3, 224, 224)mlp_encoder = ivy.transpile(mlp_encoder, to=\""jax\"", args=(noise,))# Build a classifier using the transpiled encoderclass Classifier(hk.Module):    def __init__(self, num_classes=1000):        super(Classifier, self).__init__()        self.encoder = mlp_encoder()        self.fc = hk.Linear(output_size=num_classes, with_bias=True)    def __call__(self, x):        x = self.encoder(x)        x = self.fc(x)        return xdef _forward_classifier(x):    module = Classifier()    return module(x)# Transform the classifier and use it as a standard hk.Modulerng_key = jax.random.PRNGKey(42)x = jax.random.uniform(key=rng_key, shape=(1, 3, 224, 224), dtype=jax.numpy.float32)forward_classifier = hk.transform(_forward_classifier)params = forward_classifier.init(rng=rng_key, x=x)ret = forward_classifier.apply(params, None, x)   From TensorFlowimport ivyimport jaximport haiku as hkimport tensorflow as tf# Get a pretrained keras modeleff_encoder = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(    include_top=False, weights=\""imagenet\"", input_shape=(224, 224, 3))# Transpile it into a hk.Module with the corresponding parametersnoise = tf.random.normal(shape=(1, 224, 224, 3))hk_eff_encoder = ivy.transpile(eff_encoder, to=\""jax\"", args=(noise,))# Build a classifier using the transpiled encoderclass Classifier(hk.Module):    def __init__(self, num_classes=1000):        super(Classifier, self).__init__()        self.encoder = hk_eff_encoder()        self.fc = hk.Linear(output_size=num_classes, with_bias=True)    def __call__(self, x):        x = self.encoder(x)        x = self.fc(x)        return xdef _forward_classifier(x):    module = Classifier()    return module(x)# Transform the classifier and use it as a standard hk.Modulerng_key = jax.random.PRNGKey(42)dummy_x = jax.random.uniform(key=rng_key, shape=(1, 224, 224, 3))forward_classifier = hk.transform(_forward_classifier)params = forward_classifier.init(rng=rng_key, x=dummy_x)ret = forward_classifier.apply(params, None, dummy_x)Any library   From PyTorchimport ivyimport korniaimport requestsimport jax.numpy as jnpfrom PIL import Image# transpile kornia from torch to jaxjax_kornia = ivy.transpile(kornia, source=\""torch\"", to=\""jax\"")# get an imageurl = \""http://images.cocodataset.org/train2017/000000000034.jpg\""raw_img = Image.open(requests.get(url, stream=True).raw)# convert it to the format expected by korniaimg = jnp.transpose(jnp.array(raw_img), (2, 0, 1))img = jnp.expand_dims(img, 0) / 255# and use the transpiled version of any function from the library!out = jax_kornia.enhance.sharpness(img, 5)   From TensorFlowimport ivyimport jaximport osos.environ[\""SM_FRAMEWORK\""] = \""tf.keras\""import segmentation_models as sm# transpile sm from tensorflow to jaxjax_sm = ivy.transpile(sm, source=\""tensorflow\"", to=\""jax\"")# get some image-like arrayskey = jax.random.PRNGKey(23)key1, key2 = jax.random.split(key)output = jax.random.uniform(key1, (1, 3, 512, 512))target = jax.random.uniform(key2, (1, 3, 512, 512))# and use the transpiled version of any function from the library!out = jax_sm.metrics.iou_score(output, target)   From NumPyimport ivyimport madmomimport jax.numpy as jnp# transpile madmon from numpy to jaxjax_madmom = ivy.transpile(madmom, source=\""numpy\"", to=\""jax\"")# get some arraysfreqs = jnp.arange(20) * 10# and use the transpiled version of any function from the library!out = jax_madmom.audio.filters.hz2midi(freqs)Any function   From PyTorchimport ivyimport torchimport jax.numpy as jnpdef loss(predictions, targets):    return torch.sqrt(torch.mean((predictions - targets) ** 2))# transpile any function from torch to jaxjax_loss = ivy.transpile(loss, source=\""torch\"", to=\""jax\"")# get some arraysp = jnp.array([3.0, 2.0, 1.0])t = jnp.array([0.0, 0.0, 0.0])# and use the transpiled version!out = jax_loss(p, t)   From TensorFlowimport ivyimport tensorflow as tfimport jax.numpy as jnpdef loss(predictions, targets):    return tf.sqrt(tf.reduce_mean(tf.square(predictions - targets)))# transpile any function from tf to jaxjax_loss = ivy.transpile(loss, source=\""tensorflow\"", to=\""jax\"")# get some arraysp = jnp.array([3.0, 2.0, 1.0])t = jnp.array([0.0, 0.0, 0.0])# and use the transpiled version!out = jax_loss(p, t)   From NumPyimport ivyimport numpy as npimport jaximport jax.numpy as jnpjax.config.update('jax_enable_x64', True)def loss(predictions, targets):    return np.sqrt(np.mean((predictions - targets) ** 2))# transpile any function from numpy to jaxjax_loss = ivy.transpile(loss, source=\""numpy\"", to=\""jax\"")# get some arraysp = jnp.array([3.0, 2.0, 1.0])t = jnp.array([0.0, 0.0, 0.0])# and use the transpiled version!out = jax_loss(p, t)I'm using NumPy‚ÄÇYou can use Ivy to get NumPy code from:Any library   From PyTorchimport ivyimport korniaimport requestsimport numpy as npfrom PIL import Image# transpile kornia from torch to npnp_kornia = ivy.transpile(kornia, source=\""torch\"", to=\""numpy\"")# get an imageurl = \""http://images.cocodataset.org/train2017/000000000034.jpg\""raw_img = Image.open(requests.get(url, stream=True).raw)# convert it to the format expected by korniaimg = np.transpose(np.array(raw_img), (2, 0, 1))img = np.expand_dims(img, 0) / 255# and use the transpiled version of any function from the library!out = np_kornia.enhance.sharpness(img, 5)   From TensorFlowimport ivyimport numpy as npimport osos.environ[\""SM_FRAMEWORK\""] = \""tf.keras\""import segmentation_models as sm# transpile sm from tensorflow to numpynp_sm = ivy.transpile(sm, source=\""tensorflow\"", to=\""numpy\"")# get some image-like arraysoutput = np.random.rand(1, 3, 512, 512).astype(dtype=np.float32)target = np.random.rand(1, 3, 512, 512).astype(dtype=np.float32)# and use the transpiled version of any function from the library!out = np_sm.metrics.iou_score(output, target)   From Jaximport ivyimport raximport numpy as np# transpile rax from jax to numpynp_rax = ivy.transpile(rax, source=\""jax\"", to=\""numpy\"")# get some arraysscores = np.array([2.2, 1.3, 5.4])labels = np.array([1.0, 0.0, 0.0])# and use the transpiled version of any function from the library!out = np_rax.poly1_softmax_loss(scores, labels)Any function   From PyTorchimport ivyimport torchimport numpy as npdef loss(predictions, targets):    return torch.sqrt(torch.mean((predictions - targets) ** 2))# transpile any function from torch to numpynp_loss = ivy.transpile(loss, source=\""torch\"", to=\""numpy\"")# get some arraysp = np.array([3.0, 2.0, 1.0])t = np.array([0.0, 0.0, 0.0])# and use the transpiled version!out = np_loss(p, t)   From TensorFlowimport ivyimport tensorflow as tfimport numpy as npdef loss(predictions, targets):    return tf.sqrt(tf.reduce_mean(tf.square(predictions - targets)))# transpile any function from tf to numpynp_loss = ivy.transpile(loss, source=\""tensorflow\"", to=\""numpy\"")# get some arraysp = np.array([3.0, 2.0, 1.0])t = np.array([0.0, 0.0, 0.0])# and use the transpiled version!out = np_loss(p, t)   From JAXimport ivyimport jax.numpy as jnpimport numpy as npdef loss(predictions, targets):    return jnp.sqrt(jnp.mean((predictions - targets) ** 2))# transpile any function from jax to numpynp_loss = ivy.transpile(loss, source=\""jax\"", to=\""numpy\"")# get some arraysp = np.array([3.0, 2.0, 1.0])t = np.array([0.0, 0.0, 0.0])# and use the transpiled version!out = np_loss(p, t)I'm using Ivy‚ÄÇOr you can use Ivy as a framework, breaking yourself (and your code)free from deciding which community to support, allowing anyone to runyour code in their framework of choice!import ivy# a simple image classification modelclass IvyNet(ivy.Module):    def __init__(        self,        h_w=(32, 32),        input_channels=3,        output_channels=512,        num_classes=2,        data_format=\""NCHW\"",        device=\""cpu\"",    ):        self.h_w = h_w        self.input_channels = input_channels        self.output_channels = output_channels        self.num_classes = num_classes        self.data_format = data_format        self.device = device        super().__init__()    def _build(self, *args, **kwargs):        self.extractor = ivy.Sequential(            ivy.Conv2D(self.input_channels, 6, [5, 5], 1, \""SAME\"", data_format=self.data_format),            ivy.GELU(),            ivy.Conv2D(6, 16, [5, 5], 1, \""SAME\"", data_format=self.data_format),            ivy.GELU(),            ivy.Conv2D(16, self.output_channels, [5, 5], 1, \""SAME\"", data_format=self.data_format),            ivy.GELU(),        )        self.classifier = ivy.Sequential(            # since padding is \""SAME\"", this would be image_height x image_width x output_channels            ivy.Linear(self.h_w[0] * self.h_w[1] * self.output_channels, 512),            ivy.GELU(),            ivy.Linear(512, self.num_classes),        )    def _forward(self, x):        x = self.extractor(x)        # flatten all dims except batch dim        x = ivy.flatten(x, start_dim=1, end_dim=-1)        logits = self.classifier(x)        probs = ivy.softmax(logits)        return logits, probsAfter building your model in Ivy, you can set your favourite frameworkas the backend to use its operations under the hood!ivy.set_backend(\""torch\"")model = IvyNet()x = torch.randn(1, 3, 32, 32)logits, probs = model(x)ivy.set_backend(\""tensorflow\"")model = IvyNet()x = tf.random.uniform(shape=(1, 3, 32, 32))logits, probs = model(x)ivy.set_backend(\""jax\"")model = IvyNet()x = jax.random.uniform(key, shape=(1, 3, 32, 32))logits, probs = model(x)ivy.set_backend(\""numpy\"")model = IvyNet()x = np.random.uniform(size=(1, 3, 32, 32))logits, probs = model(x)Last but not least, we can also build the training pipeline in pure ivy‚¨áÔ∏èLet's define some helper functions first# helper function for loading the dataset in batchesdef generate_batches(images, classes, dataset_size, batch_size=32):    targets = {k: v for v, k in enumerate(np.unique(classes))}    y_train = [targets[classes[i]] for i in range(len(classes))]    if batch_size > dataset_size:        raise ivy.utils.exceptions.IvyError(\""Use a smaller batch size\"")    for idx in range(0, dataset_size, batch_size):        yield ivy.stack(images[idx : min(idx + batch_size, dataset_size)]), ivy.array(            y_train[idx : min(idx + batch_size, dataset_size)]        )# helper function to get the number of current predictionsdef num_correct(preds, labels):    return (preds.argmax() == labels).sum().to_numpy().item()# define a loss functiondef loss_fn(params):    v, model, x, y = params    y_pred, probs = model(x)    return ivy.cross_entropy(y, probs), probsAnd train this model!# train the model on gpu if it's availabledevice = \""cuda:0\"" if ivy.gpu_is_available() else \""cpu\""# training hyperparamsoptimizer= ivy.Adam(1e-4)batch_size = 64 num_epochs = 20num_classes = 10model = IvyNet(    h_w=(28, 28),    input_channels=1,    output_channels=120,    num_classes=num_classes,    device=device,)model_name = type(model).__name__.lower()# training loopdef train(images, classes, epochs, model, device, num_classes=10, batch_size=32):    # training metrics    epoch_loss = 0.0    running_loss = 0.0    fields = [\""epoch\"", \""epoch_loss\"", \""training_accuracy\""]    metrics = []    dataset_size = len(images)    for epoch in range(epochs):        train_loss, train_correct = 0, 0        train_loop = tqdm(            generate_batches(images, classes, len(images), batch_size=batch_size),            total=dataset_size // batch_size,            position=0,            leave=True,        )        for xbatch, ybatch in train_loop:            if device != \""cpu\"":                xbatch, ybatch = xbatch.to_device(\""gpu:0\""), ybatch.to_device(\""gpu:0\"")            # since the cross entropy function expects the target classes to be in one-hot encoded format            ybatch_encoded = ivy.one_hot(ybatch, num_classes)            # update model params            loss_probs, grads = ivy.execute_with_gradients(                loss_fn,                (model.v, model, xbatch, ybatch_encoded),            )            model.v = optimizer.step(model.v, grads[\""0\""])            batch_loss = ivy.to_numpy(loss_probs[0]).mean().item()  # batch mean loss            epoch_loss += batch_loss * xbatch.shape[0]            train_correct += num_correct(loss_probs[1], ybatch)            train_loop.set_description(f\""Epoch [{epoch + 1:2d}/{epochs}]\"")            train_loop.set_postfix(                running_loss=batch_loss,                accuracy_percentage=(train_correct / dataset_size) * 100,            )        epoch_loss = epoch_loss / dataset_size        training_accuracy = train_correct / dataset_size        metrics.append([epoch, epoch_loss, training_accuracy])        train_loop.write(            f\""\Average training loss: {epoch_loss:.6f}, Train Correct: {train_correct}\"",            end=\""\\"",        )    # write metrics for plotting    with open(f\""/{model_name}_train_summary.csv\"", \""w\"") as f:        f = csv.writer(f)        f.writerow(fields)        f.writerows(metrics)# assuming the dataset(images and classes) are already prepared in a folder      train(images, classes, num_epochs, model, device, num_classes = num_classes, batch_size = batch_size)ContributingWe believe that everyone can contribute and make a difference. Whetherit's writing code üíª, fixing bugs üêõ, or simply sharing feedback üí¨,your contributions are definitely welcome and appreciated üôåCheck out all of our open tasks, and find out more info in ourContributingguide in thedocs!Join our amazing community as a code contributor, and help accelerateour journey to unify all ML frameworks!  CommunityIn order to achieve the ambitious goal of unifying AI we definitely needas many hands as possible on it! Whether you are a seasoned developer orjust starting out, you'll find a place here! Join the Ivy community inour Discord üëæ server, which is theperfect place to ask questions, share ideas, and get help from bothfellow developers and the Ivy Team directly!Also! Feel free to follow us onTwitter üê¶ as well, we use it toshare updates, sneak peeks, and all sorts of relevant news, certainly agreat way to stay in the loop üòÑCan't wait to see you there!CitationIf you use Ivy for your work, please don't forget to give proper creditby including the accompanying paperüìÑ in your references. It's a small way to show appreciation and helpto continue to support this and other open source projects üôå@article{lenton2021ivy,  title={Ivy: Templated deep learning for inter-framework portability},  author={Lenton, Daniel and Pardo, Fabio and Falck, Fabian and James, Stephen and Clark, Ronald},  journal={arXiv preprint arXiv:2102.02886},  year={2021}}"
16,quantopian/zipline,https://github.com/quantopian/zipline/blob/master/README.rst,Python,"Zipline is a Pythonic algorithmic trading library. It is an event-drivensystem for backtesting. Zipline is currently used in production as the backtesting and live-tradingengine powering Quantopian -- a free,community-centered, hosted platform for building and executing tradingstrategies. Quantopian also offers a fully managed service for professionalsthat includes Zipline, Alphalens, Pyfolio, FactSet data, and more.Join our Community!DocumentationWant to Contribute? See our Development GuidelinesFeaturesEase of Use: Zipline tries to get out of your way so that you canfocus on algorithm development. See below for a code example.\""Batteries Included\"": many common statistics likemoving average and linear regression can be readily accessed fromwithin a user-written algorithm.PyData Integration: Input of historical data and output of performance statistics arebased on Pandas DataFrames to integrate nicely into the existingPyData ecosystem.Statistics and Machine Learning Libraries: You can use libraries like matplotlib, scipy,statsmodels, and sklearn to support development, analysis, andvisualization of state-of-the-art trading systems.InstallationZipline currently supports Python 2.7, 3.5, and 3.6, and may be installed viaeither pip or conda.Note: Installing Zipline is slightly more involved than the average Pythonpackage. See the full Zipline Install Documentation for detailedinstructions.For a development installation (used to develop Zipline itself), create andactivate a virtualenv, then run the etc/dev-install script.QuickstartSee our getting started tutorial.The following code implements a simple dual moving average algorithm.from zipline.api import order_target, record, symboldef initialize(context):    context.i = 0    context.asset = symbol('AAPL')def handle_data(context, data):    # Skip first 300 days to get full windows    context.i += 1    if context.i < 300:        return    # Compute averages    # data.history() has to be called with the same params    # from above and returns a pandas dataframe.    short_mavg = data.history(context.asset, 'price', bar_count=100, frequency=\""1d\"").mean()    long_mavg = data.history(context.asset, 'price', bar_count=300, frequency=\""1d\"").mean()    # Trading logic    if short_mavg > long_mavg:        # order_target orders as many shares as needed to        # achieve the desired number of shares.        order_target(context.asset, 100)    elif short_mavg < long_mavg:        order_target(context.asset, 0)    # Save values for later inspection    record(AAPL=data.current(context.asset, 'price'),           short_mavg=short_mavg,           long_mavg=long_mavg)You can then run this algorithm using the Zipline CLI.First, you must download some sample pricing and asset data:$ zipline ingest$ zipline run -f dual_moving_average.py --start 2014-1-1 --end 2018-1-1 -o dma.pickle --no-benchmarkThis will download asset pricing data data sourced from Quandl, and stream it through the algorithm over the specified time range.Then, the resulting performance DataFrame is saved in dma.pickle, which you can load and analyze from within Python.You can find other examples in the zipline/examples directory.Questions?If you find a bug, feel free to open an issue and fill out the issue template.ContributingAll contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome. Details on how to set up a development environment can be found in our development guidelines.If you are looking to start working with the Zipline codebase, navigate to the GitHub issues tab and start looking through interesting issues. Sometimes there are issues labeled as Beginner Friendly or Help Wanted.Feel free to ask questions on the mailing list or on Gitter.NotePlease note that Zipline is not a community-led project. Zipline ismaintained by the Quantopian engineering team, and we are quite small andoften busy.Because of this, we want to warn you that we may not attend to your pullrequest, issue, or direct mention in months, or even years. We hope youunderstand, and we hope that this note might help reduce any frustration orwasted time."
17,s0md3v/roop,https://github.com/s0md3v/roop/blob/main/README.md,Python,"RoopTake a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training.InstallationBe aware, the installation needs technical skills and is not for beginners. Please do not open platform and installation related issues on GitHub. We have a very helpful Discord community that will guide you to install roop.Basic - It is more likely to work on your computer, but will be quite slowAcceleration - Unleash the full potential of your CPU and GPUUsageStart the program with arguments:python run.py [options]-h, --help                                                                 show this help message and exit-s SOURCE_PATH, --source SOURCE_PATH                                       select an source image-t TARGET_PATH, --target TARGET_PATH                                       select an target image or video-o OUTPUT_PATH, --output OUTPUT_PATH                                       select output file or directory--frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]                    frame processors (choices: face_swapper, face_enhancer, ...)--keep-fps                                                                 keep target fps--keep-frames                                                              keep temporary frames--skip-audio                                                               skip target audio--many-faces                                                               process every face--reference-face-position REFERENCE_FACE_POSITION                          position of the reference face--reference-frame-number REFERENCE_FRAME_NUMBER                            number of the reference frame--similar-face-distance SIMILAR_FACE_DISTANCE                              face distance used for recognition--temp-frame-format {jpg,png}                                              image format used for frame extraction--temp-frame-quality [0-100]                                               image quality used for frame extraction--output-video-encoder {libx264,libx265,libvpx-vp9,h264_nvenc,hevc_nvenc}  encoder used for the output video--output-video-quality [0-100]                                             quality used for the output video--max-memory MAX_MEMORY                                                    maximum amount of RAM in GB--execution-provider {cpu} [{cpu} ...]                                     available execution provider (choices: cpu, ...)--execution-threads EXECUTION_THREADS                                      number of execution threads-v, --version                                                              show program's version number and exitHeadlessUsing the -s/--source, -t/--target and -o/--output argument will run the program in headless mode.DisclaimerThis software is designed to contribute positively to the AI-generated media industry, assisting artists with tasks like character animation and models for clothing.We are aware of the potential ethical issues and have implemented measures to prevent the software from being used for inappropriate content, such as nudity.Users are expected to follow local laws and use the software responsibly. If using real faces, get consent and clearly label deepfakes when sharing. The developers aren't liable for user actions.LicensesOur software uses a lot of third party libraries as well pre-trained models. The users should keep in mind that these third party components have their own license and terms, therefore our license is not being applied.Creditsdeepinsight for their insightface project which provided a well-made library and models.all developers behind the libraries used in this projectDocumentationRead the documentation for a deep dive."
18,owid/covid-19-data,https://github.com/owid/covid-19-data/blob/master/README.md,Python,"COVID-19 Dataset by Our World in Dataüì¢ Find our data on COVID-19 and its documentation in public/data!Project structureThe project contains two independent directories:public/data: Contains the final datasets. This is for people interested in consuming the data andunderstanding all the caveats about it and its metrics.scripts: Contains all the code and intermediate files to produce the final dataset. This is for people interested incontributing to the project or better understanding our internal technical processes.DocumentationIf you are interested in the final dataset file, refer to this document. If you want tolearn more about our processes, refer to our technical documentation.ContributeThanks for considering contributing to this project! A good place to start is our contributionguideline."
19,wbond/package_control_channel,https://github.com/owid/covid-19-data/blob/master/README.md,Python,"COVID-19 Dataset by Our World in Dataüì¢ Find our data on COVID-19 and its documentation in public/data!Project structureThe project contains two independent directories:public/data: Contains the final datasets. This is for people interested in consuming the data andunderstanding all the caveats about it and its metrics.scripts: Contains all the code and intermediate files to produce the final dataset. This is for people interested incontributing to the project or better understanding our internal technical processes.DocumentationIf you are interested in the final dataset file, refer to this document. If you want tolearn more about our processes, refer to our technical documentation.ContributeThanks for considering contributing to this project! A good place to start is our contributionguideline."
20,google/it-cert-automation-practice,https://github.com/google/it-cert-automation-practice/blob/master/README.md,Python,Google IT Automation with Python Professional Certificate - Practice filesThis repository contains the practice files used throughout the courses that arepart of the Google IT Automation with Python Professional CertificateThere's a separate folder for each course.
21,keras-team/keras,https://github.com/keras-team/keras/blob/master/README.md,Python,"Keras: Deep Learning for humansThis repository hosts the development of the Keras library.Read the documentation at keras.io.About KerasKeras is a deep learning API written in Python,running on top of the machine learning platform TensorFlow.It was developed with a focus on enabling fast experimentation andproviding a delightful developer experience.The purpose of Keras is to give an unfair advantage to any developer looking to ship ML-powered apps.Keras is:Simple -- but not simplistic. Keras reduces developer cognitive loadto free you to focus on the parts of the problem that really matter.Keras focuses on ease of use, debugging speed, code elegance & conciseness,maintainability, and deployability (via TFServing, TFLite, TF.js).Flexible -- Keras adopts the principle of progressive disclosure ofcomplexity: simple workflows should be quick and easy, while arbitrarilyadvanced workflows should be possible via a clear path that builds uponwhat you've already learned.Powerful -- Keras provides industry-strength performance andscalability: it is used by organizations and companies including NASA,YouTube, and Waymo. That's right -- your YouTube recommendations arepowered by Keras, and so is the world's most advanced driverless vehicle.Keras & TensorFlow 2TensorFlow 2 is an end-to-end, open-source machine learning platform.You can think of it as an infrastructure layer fordifferentiable programming.It combines four key abilities:Efficiently executing low-level tensor operations on CPU, GPU, or TPU.Computing the gradient of arbitrary differentiable expressions.Scaling computation to many devices, such as clusters of hundreds of GPUs.Exporting programs (\""graphs\"") to external runtimes such as servers, browsers, mobile and embedded devices.Keras is the high-level API of TensorFlow 2: an approachable, highly-productive interfacefor solving machine learning problems,with a focus on modern deep learning. It provides essential abstractions and building blocks for developingand shipping machine learning solutions with high iteration velocity.Keras empowers engineers and researchers to take full advantage of the scalabilityand cross-platform capabilities of TensorFlow 2: you can run Keras on TPU or on large clusters of GPUs,and you can export your Keras models to run in the browser or on a mobile device.First contact with KerasThe core data structures of Keras are layers and models.The simplest type of model is the Sequential model, a linear stack of layers.For more complex architectures, you should use the Keras functional API,which allows you to build arbitrary graphs of layers or write models entirely from scratch via subclassing.Here is the Sequential model:from tensorflow.keras.models import Sequentialmodel = Sequential()Stacking layers is as easy as .add():from tensorflow.keras.layers import Densemodel.add(Dense(units=64, activation='relu'))model.add(Dense(units=10, activation='softmax'))Once your model looks good, configure its learning process with .compile():model.compile(loss='categorical_crossentropy',              optimizer='sgd',              metrics=['accuracy'])If you need to, you can further configure your optimizer. The Keras philosophy is to keep simple things simple,while allowing the user to be fully in control when they need to be (the ultimate control being the easy extensibility of the source code via subclassing).model.compile(loss=tf.keras.losses.categorical_crossentropy,              optimizer=tf.keras.optimizers.SGD(                  learning_rate=0.01, momentum=0.9, nesterov=True))You can now iterate on your training data in batches:# x_train and y_train are Numpy arrays.model.fit(x_train, y_train, epochs=5, batch_size=32)Evaluate your test loss and metrics in one line:loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)Or generate predictions on new data:classes = model.predict(x_test, batch_size=128)What you just saw is the most elementary way to use Keras.However, Keras is also a highly-flexible framework suitable to iterate on state-of-the-art research ideas.Keras follows the principle of progressive disclosure of complexity: it makes it easy to get started,yet it makes it possible to handle arbitrarily advanced use cases,only requiring incremental learning at each step.In pretty much the same way that you were able to train & evaluate a simple neural network above in a few lines,you can use Keras to quickly develop new training procedures or exotic model architectures.Here's a low-level training loop example, combining Keras functionality with the TensorFlow GradientTape:import tensorflow as tf# Prepare an optimizer.optimizer = tf.keras.optimizers.Adam()# Prepare a loss function.loss_fn = tf.keras.losses.kl_divergence# Iterate over the batches of a dataset.for inputs, targets in dataset:    # Open a GradientTape.    with tf.GradientTape() as tape:        # Forward pass.        predictions = model(inputs)        # Compute the loss value for this batch.        loss_value = loss_fn(targets, predictions)    # Get gradients of loss wrt the weights.    gradients = tape.gradient(loss_value, model.trainable_weights)    # Update the weights of the model.    optimizer.apply_gradients(zip(gradients, model.trainable_weights))For more in-depth tutorials about Keras, you can check out:Introduction to Keras for engineersIntroduction to Keras for researchersDeveloper guidesOther learning resourcesInstallationKeras comes packaged with TensorFlow 2 as tensorflow.keras.To start using Keras, simply install TensorFlow 2.You can then import Keras as follows:from tensorflow import kerasRelease and compatibilityKeras has nightly releases (keras-nightly on PyPI)and stable releases (keras on PyPI).The nightly Keras releases are usually compatible with the corresponding versionof the tf-nightly releases(e.g. keras-nightly==2.7.0.dev2021100607 should beused with tf-nightly==2.7.0.dev2021100607).We don't maintain backward compatibility for nightly releases.For stable releases, each Kerasversion maps to a specific stable version of TensorFlow.The table below shows the compatibility version mappingbetween TensorFlow versions and Keras versions.All the release branches can be found on GitHub.All the release binaries can be found on Pypi.SupportYou can ask questions and join the development discussion:In the TensorFlow forum.On the Keras mailing list.Opening an issueYou can also post bug reports and feature requests (only)in GitHub issues.Opening a PRWe welcome contributions! Before opening a PR, please readour contributor guide,and the API design guideline."
22,open-mmlab/mmdetection,https://github.com/open-mmlab/mmdetection/blob/main/README.md,Python,"    ¬†      OpenMMLab website                  HOT              ¬†¬†¬†¬†    OpenMMLab platform                  TRY IT OUT              ¬†üìòDocumentation |üõ†Ô∏èInstallation |üëÄModel Zoo |üÜïUpdate News |üöÄOngoing Projects |ü§îReporting IssuesEnglish | ÁÆÄ‰Ωì‰∏≠Êñá                                              IntroductionMMDetection is an open source object detection toolbox based on PyTorch. It isa part of the OpenMMLab project.The main branch works with PyTorch 1.8+.Major featuresModular DesignWe decompose the detection framework into different components and one can easily construct a customized object detection framework by combining different modules.Support of multiple tasks out of boxThe toolbox directly supports multiple detection tasks such as object detection, instance segmentation, panoptic segmentation, and semi-supervised object detection.High efficiencyAll basic bbox and mask operations run on GPUs. The training speed is faster than or comparable to other codebases, including Detectron2, maskrcnn-benchmark and SimpleDet.State of the artThe toolbox stems from the codebase developed by the MMDet team, who won COCO Detection Challenge in 2018, and we keep pushing it forward.The newly released RTMDet also obtains new state-of-the-art results on real-time instance segmentation and rotated object detection tasks and the best parameter-accuracy trade-off on object detection.Apart from MMDetection, we also released MMEngine for model training and MMCV for computer vision research, which are heavily depended on by this toolbox.What's NewHighlightWe are excited to announce our latest work on real-time object recognition tasks, RTMDet, a family of fully convolutional single-stage detectors. RTMDet not only achieves the best parameter-accuracy trade-off on object detection from tiny to extra-large model sizes but also obtains new state-of-the-art performance on instance segmentation and rotated object detection tasks. Details can be found in the technical report. Pre-trained models are here.TaskDatasetAPFPS(TRT FP16 BS1 3090)Object DetectionCOCO52.8322Instance SegmentationCOCO44.6188Rotated Object DetectionDOTA78.9(single-scale)/81.3(multi-scale)121v3.1.0 was released in 30/6/2023:Supports tracking algorithms including multi-object tracking (MOT) algorithms SORT, DeepSORT, StrongSORT, OCSORT, ByteTrack, QDTrack, and video instance segmentation (VIS) algorithm MaskTrackRCNN, Mask2Former-VIS.Support ViTDetSupports inference and evaluation of multimodal algorithms GLIP and XDecoder, and also supports datasets such as COCO semantic segmentation, COCO Caption, ADE20k general segmentation, and RefCOCO. GLIP fine-tuning will be supported in the future.Provides a gradio demo for image type tasks of MMDetection, making it easy for users to experience.InstallationPlease refer to Installation for installation instructions.Getting StartedPlease see Overview for the general introduction of MMDetection.For detailed user guides and advanced guides, please refer to our documentation:User GuidesTrain & TestLearn about ConfigsInference with existing modelsDataset PrepareTest existing models on standard datasetsTrain predefined models on standard datasetsTrain with customized datasetsTrain with customized models and standard datasetsFinetuning ModelsTest Results SubmissionWeight initializationUse a single stage detector as RPNSemi-supervised Object DetectionUseful ToolsAdvanced GuidesBasic ConceptsComponent CustomizationHow toWe also provide object detection colab tutorial  and instance segmentation colab tutorial .To migrate from MMDetection 2.x, please refer to migration.Overview of Benchmark and Model ZooResults and models are available in the model zoo.  Architectures                    Object Detection                    Instance Segmentation                    Panoptic Segmentation                    Other                                        Fast R-CNN (ICCV'2015)            Faster R-CNN (NeurIPS'2015)            RPN (NeurIPS'2015)            SSD (ECCV'2016)            RetinaNet (ICCV'2017)            Cascade R-CNN (CVPR'2018)            YOLOv3 (ArXiv'2018)            CornerNet (ECCV'2018)            Grid R-CNN (CVPR'2019)            Guided Anchoring (CVPR'2019)            FSAF (CVPR'2019)            CenterNet (CVPR'2019)            Libra R-CNN (CVPR'2019)            TridentNet (ICCV'2019)            FCOS (ICCV'2019)            RepPoints (ICCV'2019)            FreeAnchor (NeurIPS'2019)            CascadeRPN (NeurIPS'2019)            Foveabox (TIP'2020)            Double-Head R-CNN (CVPR'2020)            ATSS (CVPR'2020)            NAS-FCOS (CVPR'2020)            CentripetalNet (CVPR'2020)            AutoAssign (ArXiv'2020)            Side-Aware Boundary Localization (ECCV'2020)            Dynamic R-CNN (ECCV'2020)            DETR (ECCV'2020)            PAA (ECCV'2020)            VarifocalNet (CVPR'2021)            Sparse R-CNN (CVPR'2021)            YOLOF (CVPR'2021)            YOLOX (CVPR'2021)            Deformable DETR (ICLR'2021)            TOOD (ICCV'2021)            DDOD (ACM MM'2021)            RTMDet (ArXiv'2022)            Conditional DETR (ICCV'2021)            DAB-DETR (ICLR'2022)            DINO (ICLR'2023)            GLIP (CVPR'2022)            DiffusionDet (ArXiv'2023)            EfficientDet (CVPR'2020)            Detic (ECCV'2022)                                    Mask R-CNN (ICCV'2017)          Cascade Mask R-CNN (CVPR'2018)          Mask Scoring R-CNN (CVPR'2019)          Hybrid Task Cascade (CVPR'2019)          YOLACT (ICCV'2019)          InstaBoost (ICCV'2019)          SOLO (ECCV'2020)          PointRend (CVPR'2020)          DetectoRS (ArXiv'2020)          SOLOv2 (NeurIPS'2020)          SCNet (AAAI'2021)          QueryInst (ICCV'2021)          Mask2Former (ArXiv'2021)          CondInst (ECCV'2020)          SparseInst (CVPR'2022)          RTMDet (ArXiv'2022)          BoxInst (CVPR'2021)                                      Panoptic FPN (CVPR'2019)          MaskFormer (NeurIPS'2021)          Mask2Former (ArXiv'2021)                                      Contrastive Learning                          SwAV (NeurIPS'2020)          MoCo (CVPR'2020)          MoCov2 (ArXiv'2020)                                  Distillation                          Localization Distillation (CVPR'2022)          Label Assignment Distillation (WACV'2022)                          Semi-Supervised Object Detection                          Soft Teacher (ICCV'2021)                                        Components                    Backbones                    Necks                    Loss                    Common                                  VGG (ICLR'2015)        ResNet (CVPR'2016)        ResNeXt (CVPR'2017)        MobileNetV2 (CVPR'2018)        HRNet (CVPR'2019)        Generalized Attention (ICCV'2019)        GCNet (ICCVW'2019)        Res2Net (TPAMI'2020)        RegNet (CVPR'2020)        ResNeSt (ArXiv'2020)        PVT (ICCV'2021)        Swin (CVPR'2021)        PVTv2 (ArXiv'2021)        ResNet strikes back (ArXiv'2021)        EfficientNet (ArXiv'2021)        ConvNeXt (CVPR'2022)        ConvNeXtv2 (ArXiv'2023)                                PAFPN (CVPR'2018)        NAS-FPN (CVPR'2019)        CARAFE (ICCV'2019)        FPG (ArXiv'2020)        GRoIE (ICPR'2020)        DyHead (CVPR'2021)                                    GHM (AAAI'2019)          Generalized Focal Loss (NeurIPS'2020)          Seasaw Loss (CVPR'2021)                                      OHEM (CVPR'2016)          Group Normalization (ECCV'2018)          DCN (ICCV'2017)          DCNv2 (CVPR'2019)          Weight Standardization (ArXiv'2019)          Prime Sample Attention (CVPR'2020)          Strong Baselines (CVPR'2021)          Resnet strikes back (ArXiv'2021)                        Some other methods are also supported in projects using MMDetection.FAQPlease refer to FAQ for frequently asked questions.ContributingWe appreciate all contributions to improve MMDetection. Ongoing projects can be found in out GitHub Projects. Welcome community users to participate in these projects. Please refer to CONTRIBUTING.md for the contributing guideline.AcknowledgementMMDetection is an open source project that is contributed by researchers and engineers from various colleges and companies. We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks.We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new detectors.CitationIf you use this toolbox or benchmark in your research, please cite this project.@article{mmdetection,  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},  journal= {arXiv preprint arXiv:1906.07155},  year={2019}}LicenseThis project is released under the Apache 2.0 license.Projects in OpenMMLabMMEngine: OpenMMLab foundational library for training deep learning models.MMCV: OpenMMLab foundational library for computer vision.MMPreTrain: OpenMMLab pre-training toolbox and benchmark.MMagic: OpenMMLab Advanced, Generative and Intelligent Creation toolbox.MMDetection: OpenMMLab detection toolbox and benchmark.MMDetection3D: OpenMMLab's next-generation platform for general 3D object detection.MMRotate: OpenMMLab rotated object detection toolbox and benchmark.MMYOLO: OpenMMLab YOLO series toolbox and benchmark.MMSegmentation: OpenMMLab semantic segmentation toolbox and benchmark.MMOCR: OpenMMLab text detection, recognition, and understanding toolbox.MMPose: OpenMMLab pose estimation toolbox and benchmark.MMHuman3D: OpenMMLab 3D human parametric model toolbox and benchmark.MMSelfSup: OpenMMLab self-supervised learning toolbox and benchmark.MMRazor: OpenMMLab model compression toolbox and benchmark.MMFewShot: OpenMMLab fewshot learning toolbox and benchmark.MMAction2: OpenMMLab's next-generation action understanding toolbox and benchmark.MMTracking: OpenMMLab video perception toolbox and benchmark.MMFlow: OpenMMLab optical flow toolbox and benchmark.MMEditing: OpenMMLab image and video editing toolbox.MMGeneration: OpenMMLab image and video generative models toolbox.MMDeploy: OpenMMLab model deployment framework.MIM: MIM installs OpenMMLab packages.MMEval: A unified evaluation library for multiple machine learning libraries.Playground: A central hub for gathering and showcasing amazing projects built upon OpenMMLab."
23,gto76/python-cheatsheet,https://github.com/gto76/python-cheatsheet/blob/main/README.md,Python,"Comprehensive Python CheatsheetDownload text file, Buy PDF, Fork me on GitHub or Check out FAQ.Contents¬†¬†¬† 1. Collections: ¬† List, Dictionary, Set, Tuple, Range, Enumerate, Iterator, Generator.¬†¬†¬† 2. Types: ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Type, String, Regular_Exp, Format, Numbers, Combinatorics, Datetime.¬†¬†¬† 3. Syntax: ¬†¬†¬†¬†¬†¬†¬†¬†¬† Args, Inline, Import, Decorator, Class, Duck_Types, Enum, Exception.¬†¬†¬† 4. System: ¬†¬†¬†¬†¬†¬†¬†¬† Exit, Print, Input, Command_Line_Arguments, Open, Path, OS_Commands.¬†¬†¬† 5. Data: ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† JSON, Pickle, CSV, SQLite, Bytes, Struct, Array, Memory_View, Deque.¬†¬†¬† 6. Advanced: ¬†¬†¬† Threading, Operator, Introspection, Metaprograming, Eval, Coroutines.¬†¬†¬† 7. Libraries: ¬†¬†¬†¬†¬†¬† Progress_Bar, Plot, Table, Curses, Logging, Scraping, Web, Profile,¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† NumPy, Image, Audio, Games, Data.Mainif __name__ == '__main__':      # Runs main() if file wasn't imported.    main()List<list> = <list>[<slice>]        # Or: <list>[from_inclusive : to_exclusive : ¬±step]<list>.append(<el>)             # Or: <list> += [<el>]<list>.extend(<collection>)     # Or: <list> += <collection><list>.sort()                   # Sorts in ascending order.<list>.reverse()                # Reverses the list in-place.<list> = sorted(<collection>)   # Returns a new sorted list.<iter> = reversed(<list>)       # Returns reversed iterator.sum_of_elements  = sum(<collection>)elementwise_sum  = [sum(pair) for pair in zip(list_a, list_b)]sorted_by_second = sorted(<collection>, key=lambda el: el[1])sorted_by_both   = sorted(<collection>, key=lambda el: (el[1], el[0]))flatter_list     = list(itertools.chain.from_iterable(<list>))product_of_elems = functools.reduce(lambda out, el: out * el, <collection>)list_of_chars    = list(<str>)For details about sorted(), min() and max() see sortable.Module operator provides functions itemgetter() and mul() that offer the same functionality as lambda expressions above.<list>.insert(<int>, <el>)      # Inserts item at index and moves the rest to the right.<el>  = <list>.pop([<int>])     # Removes and returns item at index or from the end.<int> = <list>.count(<el>)      # Returns number of occurrences. Also works on strings.<int> = <list>.index(<el>)      # Returns index of the first occurrence or raises ValueError.<list>.remove(<el>)             # Removes first occurrence of the item or raises ValueError.<list>.clear()                  # Removes all items. Also works on dictionary and set.Dictionary<view> = <dict>.keys()                          # Coll. of keys that reflects changes.<view> = <dict>.values()                        # Coll. of values that reflects changes.<view> = <dict>.items()                         # Coll. of key-value tuples that reflects chgs.value  = <dict>.get(key, default=None)          # Returns default if key is missing.value  = <dict>.setdefault(key, default=None)   # Returns and writes default if key is missing.<dict> = collections.defaultdict(<type>)        # Returns a dict with default value of type.<dict> = collections.defaultdict(lambda: 1)     # Returns a dict with default value 1.<dict> = dict(<collection>)                     # Creates a dict from coll. of key-value pairs.<dict> = dict(zip(keys, values))                # Creates a dict from two collections.<dict> = dict.fromkeys(keys [, value])          # Creates a dict from collection of keys.<dict>.update(<dict>)                           # Adds items. Replaces ones with matching keys.value = <dict>.pop(key)                         # Removes item or raises KeyError.{k for k, v in <dict>.items() if v == value}    # Returns set of keys that point to the value.{k: v for k, v in <dict>.items() if k in keys}  # Returns a dictionary, filtered by keys.Counter>>> from collections import Counter>>> colors = ['blue', 'blue', 'blue', 'red', 'red']>>> counter = Counter(colors)>>> counter['yellow'] += 1Counter({'blue': 3, 'red': 2, 'yellow': 1})>>> counter.most_common()[0]('blue', 3)Set<set> = set()                                   # `{}` returns a dictionary.<set>.add(<el>)                                 # Or: <set> |= {<el>}<set>.update(<collection> [, ...])              # Or: <set> |= <set><set>  = <set>.union(<coll.>)                   # Or: <set> | <set><set>  = <set>.intersection(<coll.>)            # Or: <set> & <set><set>  = <set>.difference(<coll.>)              # Or: <set> - <set><set>  = <set>.symmetric_difference(<coll.>)    # Or: <set> ^ <set><bool> = <set>.issubset(<coll.>)                # Or: <set> <= <set><bool> = <set>.issuperset(<coll.>)              # Or: <set> >= <set><el> = <set>.pop()                              # Raises KeyError if empty.<set>.remove(<el>)                              # Raises KeyError if missing.<set>.discard(<el>)                             # Doesn't raise an error.Frozen SetIs immutable and hashable.That means it can be used as a key in a dictionary or as an element in a set.<frozenset> = frozenset(<collection>)TupleTuple is an immutable and hashable list.<tuple> = ()                               # Empty tuple.<tuple> = (<el>,)                          # Or: <el>,<tuple> = (<el_1>, <el_2> [, ...])         # Or: <el_1>, <el_2> [, ...]Named TupleTuple's subclass with named elements.>>> from collections import namedtuple>>> Point = namedtuple('Point', 'x y')>>> p = Point(1, y=2)Point(x=1, y=2)>>> p[0]1>>> p.x1>>> getattr(p, 'y')2RangeImmutable and hashable sequence of integers.<range> = range(stop)                      # range(to_exclusive)<range> = range(start, stop)               # range(from_inclusive, to_exclusive)<range> = range(start, stop, ¬±step)        # range(from_inclusive, to_exclusive, ¬±step_size)>>> [i for i in range(3)][0, 1, 2]Enumeratefor i, el in enumerate(<collection> [, i_start]):    ...Iterator<iter> = iter(<collection>)                # `iter(<iter>)` returns unmodified iterator.<iter> = iter(<function>, to_exclusive)    # A sequence of return values until 'to_exclusive'.<el>   = next(<iter> [, default])          # Raises StopIteration or returns 'default' on end.<list> = list(<iter>)                      # Returns a list of iterator's remaining elements.Itertoolsimport itertools as it<iter> = it.count(start=0, step=1)         # Returns updated value endlessly. Accepts floats.<iter> = it.repeat(<el> [, times])         # Returns element endlessly or 'times' times.<iter> = it.cycle(<collection>)            # Repeats the sequence endlessly.<iter> = it.chain(<coll>, <coll> [, ...])  # Empties collections in order (figuratively).<iter> = it.chain.from_iterable(<coll>)    # Empties collections inside a collection in order.<iter> = it.islice(<coll>, to_exclusive)   # Only returns first 'to_exclusive' elements.<iter> = it.islice(<coll>, from_inc, ‚Ä¶)    # `to_exclusive, +step_size`. Indices can be None.GeneratorAny function that contains a yield statement returns a generator.Generators and iterators are interchangeable.def count(start, step):    while True:        yield start        start += step>>> counter = count(10, 2)>>> next(counter), next(counter), next(counter)(10, 12, 14)TypeEverything is an object.Every object has a type.Type and class are synonymous.<type> = type(<el>)                          # Or: <el>.__class__<bool> = isinstance(<el>, <type>)            # Or: issubclass(type(<el>), <type>)>>> type('a'), 'a'.__class__, str(<class 'str'>, <class 'str'>, <class 'str'>)Some types do not have built-in names, so they must be imported:from types import FunctionType, MethodType, LambdaType, GeneratorType, ModuleTypeAbstract Base ClassesEach abstract base class specifies a set of virtual subclasses. These classes are then recognized by isinstance() and issubclass() as subclasses of the ABC, although they are really not. ABC can also manually decide whether or not a specific class is its virtual subclass, usually based on which methods the class has implemented. For instance, Iterable ABC looks for method iter(), while Collection ABC looks for iter(), contains() and len().>>> from collections.abc import Iterable, Collection, Sequence>>> isinstance([1, 2, 3], Iterable)True+------------------+------------+------------+------------+|                  |  Iterable  | Collection |  Sequence  |+------------------+------------+------------+------------+| list, range, str |    yes     |    yes     |    yes     || dict, set        |    yes     |    yes     |            || iter             |    yes     |            |            |+------------------+------------+------------+------------+>>> from numbers import Number, Complex, Real, Rational, Integral>>> isinstance(123, Number)True+--------------------+----------+----------+----------+----------+----------+|                    |  Number  |  Complex |   Real   | Rational | Integral |+--------------------+----------+----------+----------+----------+----------+| int                |   yes    |   yes    |   yes    |   yes    |   yes    || fractions.Fraction |   yes    |   yes    |   yes    |   yes    |          || float              |   yes    |   yes    |   yes    |          |          || complex            |   yes    |   yes    |          |          |          || decimal.Decimal    |   yes    |          |          |          |          |+--------------------+----------+----------+----------+----------+----------+String<str>  = <str>.strip()                       # Strips all whitespace characters from both ends.<str>  = <str>.strip('<chars>')              # Strips all passed characters from both ends.<list> = <str>.split()                       # Splits on one or more whitespace characters.<list> = <str>.split(sep=None, maxsplit=-1)  # Splits on 'sep' str at most 'maxsplit' times.<list> = <str>.splitlines(keepends=False)    # On [\\\r\\f\\v\\x1c-\\x1e\\x85\\u2028\\u2029] and \\r\.<str>  = <str>.join(<coll_of_strings>)       # Joins elements using string as a separator.<bool> = <sub_str> in <str>                  # Checks if string contains the substring.<bool> = <str>.startswith(<sub_str>)         # Pass tuple of strings for multiple options.<bool> = <str>.endswith(<sub_str>)           # Pass tuple of strings for multiple options.<int>  = <str>.find(<sub_str>)               # Returns start index of the first match or -1.<int>  = <str>.index(<sub_str>)              # Same, but raises ValueError if missing.<str>  = <str>.replace(old, new [, count])   # Replaces 'old' with 'new' at most 'count' times.<str>  = <str>.translate(<table>)            # Use `str.maketrans(<dict>)` to generate table.<str>  = chr(<int>)                          # Converts int to Unicode character.<int>  = ord(<str>)                          # Converts Unicode character to int.Also: 'lstrip()', 'rstrip()' and 'rsplit()'.Also: 'lower()', 'upper()', 'capitalize()' and 'title()'.Property Methods+---------------+----------+----------+----------+----------+----------+|               | [ !#$%‚Ä¶] | [a-zA-Z] |  [¬º¬Ω¬æ]   |  [¬≤¬≥¬π]   |  [0-9]   |+---------------+----------+----------+----------+----------+----------+| isprintable() |   yes    |   yes    |   yes    |   yes    |   yes    || isalnum()     |          |   yes    |   yes    |   yes    |   yes    || isnumeric()   |          |          |   yes    |   yes    |   yes    || isdigit()     |          |          |          |   yes    |   yes    || isdecimal()   |          |          |          |          |   yes    |+---------------+----------+----------+----------+----------+----------+'isspace()' checks for whitespaces: '[ \\t\\\r\\f\\v\\x1c-\\x1f\\x85\\xa0\\u1680‚Ä¶]'.Regeximport re<str>   = re.sub(<regex>, new, text, count=0)  # Substitutes all occurrences with 'new'.<list>  = re.findall(<regex>, text)            # Returns all occurrences as strings.<list>  = re.split(<regex>, text, maxsplit=0)  # Use brackets in regex to include the matches.<Match> = re.search(<regex>, text)             # Searches for first occurrence of the pattern.<Match> = re.match(<regex>, text)              # Searches only at the beginning of the text.<iter>  = re.finditer(<regex>, text)           # Returns all occurrences as Match objects.Argument 'new' can be a function that accepts a Match object and returns a string.Search() and match() return None if they can't find a match.Argument 'flags=re.IGNORECASE' can be used with all functions.Argument 'flags=re.MULTILINE' makes '^' and '$' match the start/end of each line.Argument 'flags=re.DOTALL' makes '.' also accept the '\'.Use r'\\1' or '\\\\1' for backreference ('\\1' returns a character with octal code 1).Add '?' after '*' and '+' to make them non-greedy.Match Object<str>   = <Match>.group()                      # Returns the whole match. Also group(0).<str>   = <Match>.group(1)                     # Returns part in the first bracket.<tuple> = <Match>.groups()                     # Returns all bracketed parts.<int>   = <Match>.start()                      # Returns start index of the match.<int>   = <Match>.end()                        # Returns exclusive end index of the match.Special Sequences'\\d' == '[0-9]'                                # Matches decimal characters.'\\w' == '[a-zA-Z0-9_]'                         # Matches alphanumerics and underscore.'\\s' == '[ \\t\\\r\\f\\v]'                        # Matches whitespaces.By default, decimal characters, alphanumerics and whitespaces from all alphabets are matched unless 'flags=re.ASCII' argument is used.As shown above, it restricts all special sequence matches to the first 128 characters and prevents '\\s' from accepting '[\\x1c-\\x1f]' (the so-called separator characters).Use a capital letter for negation (all non-ASCII characters will be matched when used in combination with ASCII flag).Format<str> = f'{<el_1>}, {<el_2>}'            # Curly brackets can also contain expressions.<str> = '{}, {}'.format(<el_1>, <el_2>)  # Or: '{0}, {a}'.format(<el_1>, a=<el_2>)<str> = '%s, %s' % (<el_1>, <el_2>)      # Redundant and inferior C-style formatting.Example>>> Person = collections.namedtuple('Person', 'name height')>>> person = Person('Jean-Luc', 187)>>> f'{person.name} is {person.height / 100} meters tall.''Jean-Luc is 1.87 meters tall.'General Options{<el>:<10}                               # '<el>      '{<el>:^10}                               # '   <el>   '{<el>:>10}                               # '      <el>'{<el>:.<10}                              # '<el>......'{<el>:0}                                 # '<el>'Options can be generated dynamically: f'{<el>:{<str/int>}[‚Ä¶]}'.Adding '=' to the expression prepends it to the output: f'{1+1=}' returns '1+1=2'.Adding '!r' to the expression converts object to string by calling its repr() method.Strings{'abcde':10}                             # 'abcde     '{'abcde':10.3}                           # 'abc       '{'abcde':.3}                             # 'abc'{'abcde'!r:10}                           # \""'abcde'   \""Numbers{123456:10}                              # '    123456'{123456:10,}                             # '   123,456'{123456:10_}                             # '   123_456'{123456:+10}                             # '   +123456'{123456:=+10}                            # '+   123456'{123456: }                               # ' 123456'{-123456: }                              # '-123456'Floats{1.23456:10.3}                           # '      1.23'{1.23456:10.3f}                          # '     1.235'{1.23456:10.3e}                          # ' 1.235e+00'{1.23456:10.3%}                          # '  123.456%'Comparison of presentation types:+--------------+----------------+----------------+----------------+----------------+|              |    {<float>}   |   {<float>:f}  |   {<float>:e}  |   {<float>:%}  |+--------------+----------------+----------------+----------------+----------------+|  0.000056789 |   '5.6789e-05' |    '0.000057'  | '5.678900e-05' |    '0.005679%' ||  0.00056789  |   '0.00056789' |    '0.000568'  | '5.678900e-04' |    '0.056789%' ||  0.0056789   |   '0.0056789'  |    '0.005679'  | '5.678900e-03' |    '0.567890%' ||  0.056789    |   '0.056789'   |    '0.056789'  | '5.678900e-02' |    '5.678900%' ||  0.56789     |   '0.56789'    |    '0.567890'  | '5.678900e-01' |   '56.789000%' ||  5.6789      |   '5.6789'     |    '5.678900'  | '5.678900e+00' |  '567.890000%' || 56.789       |  '56.789'      |   '56.789000'  | '5.678900e+01' | '5678.900000%' |+--------------+----------------+----------------+----------------+----------------++--------------+----------------+----------------+----------------+----------------+|              |  {<float>:.2}  |  {<float>:.2f} |  {<float>:.2e} |  {<float>:.2%} |+--------------+----------------+----------------+----------------+----------------+|  0.000056789 |    '5.7e-05'   |      '0.00'    |   '5.68e-05'   |      '0.01%'   ||  0.00056789  |    '0.00057'   |      '0.00'    |   '5.68e-04'   |      '0.06%'   ||  0.0056789   |    '0.0057'    |      '0.01'    |   '5.68e-03'   |      '0.57%'   ||  0.056789    |    '0.057'     |      '0.06'    |   '5.68e-02'   |      '5.68%'   ||  0.56789     |    '0.57'      |      '0.57'    |   '5.68e-01'   |     '56.79%'   ||  5.6789      |    '5.7'       |      '5.68'    |   '5.68e+00'   |    '567.89%'   || 56.789       |    '5.7e+01'   |     '56.79'    |   '5.68e+01'   |   '5678.90%'   |+--------------+----------------+----------------+----------------+----------------+'{<float>:g}' is '{<float>:.6}' with stripped zeros, exponent starting at 7 figures.When both rounding up and rounding down are possible, the one that returns result with even last digit is chosen. That makes '{6.5:.0f}' a '6' and '{7.5:.0f}' an '8'.This rule only effects numbers that can be represented exactly by a float (.5, .25, ‚Ä¶).Ints{90:c}                                   # 'Z'{90:b}                                   # '1011010'{90:X}                                   # '5A'Numbers<int>      = int(<float/str/bool>)                # Or: math.floor(<float>)<float>    = float(<int/str/bool>)                # Or: <int/float>e¬±<int><complex>  = complex(real=0, imag=0)              # Or: <int/float/Fraction> ¬± <int/float>j<Fraction> = fractions.Fraction(0, 1)             # Or: Fraction(numerator=0, denominator=1)<Decimal>  = decimal.Decimal(<str/int>)           # Or: Decimal((sign, digits, exponent))'int(<str>)' and 'float(<str>)' raise ValueError on malformed strings.Decimal numbers are stored exactly, unlike most floats where '1.1 + 2.2 != 3.3'.Floats can be compared with: 'math.isclose(<float>, <float>)'.Precision of decimal operations is set with: 'decimal.getcontext().prec = <int>'.Basic Functions<num> = pow(<num>, <num>)                         # Or: <num> ** <num><num> = abs(<num>)                                # <float> = abs(<complex>)<num> = round(<num> [, ¬±ndigits])                 # `round(126, -1) == 130`Mathfrom math import e, pi, inf, nan, isinf, isnan    # `<el> == nan` is always False.from math import sin, cos, tan, asin, acos, atan  # Also: degrees, radians.from math import log, log10, log2                 # Log can accept base as second arg.Statisticsfrom statistics import mean, median, variance     # Also: stdev, quantiles, groupby.Randomfrom random import random, randint, choice        # Also: shuffle, gauss, triangular, seed.<float> = random()                                # A float inside [0, 1).<int>   = randint(from_inc, to_inc)               # An int inside [from_inc, to_inc].<el>    = choice(<sequence>)                      # Keeps the sequence intact.Bin, Hex<int> = ¬±0b<bin>                                  # Or: ¬±0x<hex><int> = int('¬±<bin>', 2)                          # Or: int('¬±<hex>', 16)<int> = int('¬±0b<bin>', 0)                        # Or: int('¬±0x<hex>', 0)<str> = bin(<int>)                                # Returns '[-]0b<bin>'.Bitwise Operators<int> = <int> & <int>                             # And (0b1100 & 0b1010 == 0b1000).<int> = <int> | <int>                             # Or  (0b1100 | 0b1010 == 0b1110).<int> = <int> ^ <int>                             # Xor (0b1100 ^ 0b1010 == 0b0110).<int> = <int> << n_bits                           # Left shift. Use >> for right.<int> = ~<int>                                    # Not. Also -<int> - 1.Combinatoricsimport itertools as it>>> list(it.product([0, 1], repeat=3))[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]>>> list(it.product('abc', 'abc'))                    #   a  b  c[('a', 'a'), ('a', 'b'), ('a', 'c'),                  # a x  x  x ('b', 'a'), ('b', 'b'), ('b', 'c'),                  # b x  x  x ('c', 'a'), ('c', 'b'), ('c', 'c')]                  # c x  x  x>>> list(it.combinations('abc', 2))                   #   a  b  c[('a', 'b'), ('a', 'c'),                              # a .  x  x ('b', 'c')]                                          # b .  .  x>>> list(it.combinations_with_replacement('abc', 2))  #   a  b  c[('a', 'a'), ('a', 'b'), ('a', 'c'),                  # a x  x  x ('b', 'b'), ('b', 'c'),                              # b .  x  x ('c', 'c')]                                          # c .  .  x>>> list(it.permutations('abc', 2))                   #   a  b  c[('a', 'b'), ('a', 'c'),                              # a .  x  x ('b', 'a'), ('b', 'c'),                              # b x  .  x ('c', 'a'), ('c', 'b')]                              # c x  x  .DatetimeProvides 'date', 'time', 'datetime' and 'timedelta' classes. All are immutable and hashable.# pip3 install python-dateutilfrom datetime import date, time, datetime, timedelta, timezonefrom dateutil.tz import tzlocal, gettz, datetime_exists, resolve_imaginary<D>  = date(year, month, day)               # Only accepts valid dates from 1 to 9999 AD.<T>  = time(hour=0, minute=0, second=0)     # Also: `microsecond=0, tzinfo=None, fold=0`.<DT> = datetime(year, month, day, hour=0)   # Also: `minute=0, second=0, microsecond=0, ‚Ä¶`.<TD> = timedelta(weeks=0, days=0, hours=0)  # Also: `minutes=0, seconds=0, microseconds=0`.Aware <a> time and datetime objects have defined timezone, while naive <n> don't.If object is naive, it is presumed to be in the system's timezone.'fold=1' means the second pass in case of time jumping back for one hour.Timedelta normalizes arguments to ¬±days, seconds (< 86‚ÄØ400) and microseconds (< 1M).Use '<D/DT>.weekday()' to get the day of the week as an int, with Monday being 0.'<DTa> = resolve_imaginary(<DTa>)' fixes DTs that fall into the missing hour.Now<D/DTn>  = D/DT.today()                     # Current local date or naive datetime.<DTn>    = DT.utcnow()                      # Naive datetime from current UTC time.<DTa>    = DT.now(<tzinfo>)                 # Aware datetime from current tz time.To extract time use '<DTn>.time()', '<DTa>.time()' or '<DTa>.timetz()'.Timezone<tzinfo> = timezone.utc                     # London without daylight saving time.<tzinfo> = timezone(<timedelta>)            # Timezone with fixed offset from UTC.<tzinfo> = tzlocal()                        # Local timezone. Also gettz().<tzinfo> = gettz('<Continent>/<City>')      # 'Continent/City_Name' timezone or None.<DTa>    = <DT>.astimezone([<tzinfo>])      # Converts DT to the passed or local timezone.<Ta/DTa> = <T/DT>.replace(tzinfo=<tzinfo>)  # Changes object's timezone without conversion.Standard library's zoneinfo.ZoneInfo() can be used instead of gettz() on Python 3.9 and later. It requires 'tzdata' package on Windows.Encode<D/T/DT> = D/T/DT.fromisoformat('<iso>')    # Object from ISO string. Raises ValueError.<DT>     = DT.strptime(<str>, '<format>')   # Datetime from str, according to format.<D/DTn>  = D/DT.fromordinal(<int>)          # D/DTn from days since the Gregorian NYE 1.<DTn>    = DT.fromtimestamp(<real>)         # Local time DTn from seconds since the Epoch.<DTa>    = DT.fromtimestamp(<real>, <tz.>)  # Aware datetime from seconds since the Epoch.ISO strings come in following forms: 'YYYY-MM-DD', 'HH:MM:SS.mmmuuu[¬±HH:MM]', or both separated by an arbitrary character. All parts following the hours are optional.Python uses the Unix Epoch: '1970-01-01 00:00 UTC', '1970-01-01 01:00 CET', ...Decode<str>    = <D/T/DT>.isoformat(sep='T')      # Also `timespec='auto/hours/minutes/seconds/‚Ä¶'`.<str>    = <D/T/DT>.strftime('<format>')    # Custom string representation.<int>    = <D/DT>.toordinal()               # Days since Gregorian NYE 1, ignoring time and tz.<float>  = <DTn>.timestamp()                # Seconds since the Epoch, from DTn in local tz.<float>  = <DTa>.timestamp()                # Seconds since the Epoch, from aware datetime.Format>>> dt = datetime.strptime('2015-05-14 23:39:00.00 +0200', '%Y-%m-%d %H:%M:%S.%f %z')>>> dt.strftime(\""%A, %dth of %B '%y, %I:%M%p %Z\"")\""Thursday, 14th of May '15, 11:39PM UTC+02:00\""'%z' accepts '¬±HH[:]MM' and returns '¬±HHMM' or empty string if datetime is naive.'%Z' accepts 'UTC/GMT' and local timezone's code and returns timezone's name, 'UTC[¬±HH:MM]' if timezone is nameless, or an empty string if datetime is naive.For abbreviated weekday and month use '%a' and '%b'.Arithmetics<D/DT>   = <D/DT>  ¬± <TD>                   # Returned datetime can fall into missing hour.<TD>     = <D/DTn> - <D/DTn>                # Returns the difference. Ignores time jumps.<TD>     = <DTa>   - <DTa>                  # Ignores time jumps if they share tzinfo object.<TD>     = <TD>    * <int/float>            # Also: <TD> = abs(<TD>) and <TD> = <TD> ¬±% <TD>.<float>  = <TD>    / <TD>                   # How many weeks/years there are in TD. Also //.ArgumentsInside Function Callfunc(<positional_args>)                           # func(0, 0)func(<keyword_args>)                              # func(x=0, y=0)func(<positional_args>, <keyword_args>)           # func(0, y=0)Inside Function Definitiondef func(<nondefault_args>): ...                  # def func(x, y): ...def func(<default_args>): ...                     # def func(x=0, y=0): ...def func(<nondefault_args>, <default_args>): ...  # def func(x, y=0): ...Default values are evaluated when function is first encountered in the scope.Any mutation of a mutable default value will persist between invocations!Splat OperatorInside Function CallSplat expands a collection into positional arguments, while splatty-splat expands a dictionary into keyword arguments.args   = (1, 2)kwargs = {'x': 3, 'y': 4, 'z': 5}func(*args, **kwargs)Is the same as:func(1, 2, x=3, y=4, z=5)Inside Function DefinitionSplat combines zero or more positional arguments into a tuple, while splatty-splat combines zero or more keyword arguments into a dictionary.def add(*a):    return sum(a)>>> add(1, 2, 3)6Legal argument combinations:def f(*args): ...               # f(1, 2, 3)def f(x, *args): ...            # f(1, 2, 3)def f(*args, z): ...            # f(1, 2, z=3)def f(**kwargs): ...            # f(x=1, y=2, z=3)def f(x, **kwargs): ...         # f(x=1, y=2, z=3) | f(1, y=2, z=3)def f(*args, **kwargs): ...     # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)def f(x, *args, **kwargs): ...  # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)def f(*args, y, **kwargs): ...  # f(x=1, y=2, z=3) | f(1, y=2, z=3)def f(*, x, y, z): ...          # f(x=1, y=2, z=3)def f(x, *, y, z): ...          # f(x=1, y=2, z=3) | f(1, y=2, z=3)def f(x, y, *, z): ...          # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3)Other Uses<list>  = [*<coll.> [, ...]]    # Or: list(<collection>) [+ ...]<tuple> = (*<coll.>, [...])     # Or: tuple(<collection>) [+ ...]<set>   = {*<coll.> [, ...]}    # Or: set(<collection>) [| ...]<dict>  = {**<dict> [, ...]}    # Or: dict(**<dict> [, ...])head, *body, tail = <coll.>     # Head or tail can be omitted.InlineLambda<func> = lambda: <return_value>                     # A single statement function.<func> = lambda <arg_1>, <arg_2>: <return_value>    # Also accepts default arguments.Comprehensions<list> = [i+1 for i in range(10)]                   # Or: [1, 2, ..., 10]<iter> = (i for i in range(10) if i > 5)            # Or: iter([6, 7, 8, 9])<set>  = {i+5 for i in range(10)}                   # Or: {5, 6, ..., 14}<dict> = {i: i*2 for i in range(10)}                # Or: {0: 0, 1: 2, ..., 9: 18}>>> [l+r for l in 'abc' for r in 'abc']['aa', 'ab', 'ac', ..., 'cc']Map, Filter, Reducefrom functools import reduce<iter> = map(lambda x: x + 1, range(10))            # Or: iter([1, 2, ..., 10])<iter> = filter(lambda x: x > 5, range(10))         # Or: iter([6, 7, 8, 9])<obj>  = reduce(lambda out, x: out + x, range(10))  # Or: 45Any, All<bool> = any(<collection>)                          # Is `bool(<el>)` True for any element.<bool> = all(<collection>)                          # Is True for all elements or empty.Conditional Expression<obj> = <exp> if <condition> else <exp>             # Only one expression gets evaluated.>>> [a if a else 'zero' for a in (0, 1, 2, 3)]      # `any([0, '', [], None]) == False`['zero', 1, 2, 3]Named Tuple, Enum, Dataclassfrom collections import namedtuplePoint = namedtuple('Point', 'x y')                  # Creates a tuple's subclass.point = Point(0, 0)                                 # Returns its instance.from enum import EnumDirection = Enum('Direction', 'N E S W')            # Creates an enum.direction = Direction.N                             # Returns its member.from dataclasses import make_dataclassPlayer = make_dataclass('Player', ['loc', 'dir'])   # Creates a class.player = Player(point, direction)                   # Returns its instance.Importsimport <module>            # Imports a built-in or '<module>.py'.import <package>           # Imports a built-in or '<package>/__init__.py'.import <package>.<module>  # Imports a built-in or '<package>/<module>.py'.Package is a collection of modules, but it can also define its own objects.On a filesystem this corresponds to a directory of Python files with an optional init script.Running 'import <package>' does not automatically provide access to the package's modules unless they are explicitly imported in its init script.ClosureWe have/get a closure in Python when:A nested function references a value of its enclosing function and thenthe enclosing function returns the nested function.def get_multiplier(a):    def out(b):        return a * b    return out>>> multiply_by_3 = get_multiplier(3)>>> multiply_by_3(10)30If multiple nested functions within enclosing function reference the same value, that value gets shared.To dynamically access function's first free variable use '<function>.__closure__[0].cell_contents'.Partialfrom functools import partial<function> = partial(<function> [, <arg_1>, <arg_2>, ...])>>> def multiply(a, b):...     return a * b>>> multiply_by_3 = partial(multiply, 3)>>> multiply_by_3(10)30Partial is also useful in cases when function needs to be passed as an argument because it enables us to set its arguments beforehand.A few examples being: 'defaultdict(<function>)', 'iter(<function>, to_exclusive)' and dataclass's 'field(default_factory=<function>)'.Non-LocalIf variable is being assigned to anywhere in the scope, it is regarded as a local variable, unless it is declared as a 'global' or a 'nonlocal'.def get_counter():    i = 0    def out():        nonlocal i        i += 1        return i    return out>>> counter = get_counter()>>> counter(), counter(), counter()(1, 2, 3)DecoratorA decorator takes a function, adds some functionality and returns it.It can be any callable, but is usually implemented as a function that returns a closure.@decorator_namedef function_that_gets_passed_to_decorator():    ...Debugger ExampleDecorator that prints function's name every time the function is called.from functools import wrapsdef debug(func):    @wraps(func)    def out(*args, **kwargs):        print(func.__name__)        return func(*args, **kwargs)    return out@debugdef add(x, y):    return x + yWraps is a helper decorator that copies the metadata of the passed function (func) to the function it is wrapping (out).Without it 'add.__name__' would return 'out'.LRU CacheDecorator that caches function's return values. All function's arguments must be hashable.from functools import lru_cache@lru_cache(maxsize=None)def fib(n):    return n if n < 2 else fib(n-2) + fib(n-1)Default size of the cache is 128 values. Passing 'maxsize=None' makes it unbounded.CPython interpreter limits recursion depth to 1000 by default. To increase it use 'sys.setrecursionlimit(<depth>)'.Parametrized DecoratorA decorator that accepts arguments and returns a normal decorator that accepts a function.from functools import wrapsdef debug(print_result=False):    def decorator(func):        @wraps(func)        def out(*args, **kwargs):            result = func(*args, **kwargs)            print(func.__name__, result if print_result else '')            return result        return out    return decorator@debug(print_result=True)def add(x, y):    return x + yUsing only '@debug' to decorate the add() function would not work here, because debug would then receive the add() function as a 'print_result' argument. Decorators can however manually check if the argument they received is a function and act accordingly.Classclass <name>:    def __init__(self, a):        self.a = a    def __repr__(self):        class_name = self.__class__.__name__        return f'{class_name}({self.a!r})'    def __str__(self):        return str(self.a)    @classmethod    def get_class_name(cls):        return cls.__name__Return value of repr() should be unambiguous and of str() readable.If only repr() is defined, it will also be used for str().Methods decorated with '@staticmethod' do not receive 'self' nor 'cls' as their first arg.Expressions that call the str() method:print(<el>)f'{<el>}'logging.warning(<el>)csv.writer(<file>).writerow([<el>])raise Exception(<el>)Expressions that call the repr() method:print/str/repr([<el>])print/str/repr({<el>: <el>})f'{<el>!r}'Z = dataclasses.make_dataclass('Z', ['a']); print/str/repr(Z(<el>))>>> <el>Constructor Overloadingclass <name>:    def __init__(self, a=None):        self.a = aInheritanceclass Person:    def __init__(self, name, age):        self.name = name        self.age  = ageclass Employee(Person):    def __init__(self, name, age, staff_num):        super().__init__(name, age)        self.staff_num = staff_numMultiple Inheritanceclass A: passclass B: passclass C(A, B): passMRO determines the order in which parent classes are traversed when searching for a method or an attribute:>>> C.mro()[<class 'C'>, <class 'A'>, <class 'B'>, <class 'object'>]PropertyPythonic way of implementing getters and setters.class Person:    @property    def name(self):        return ' '.join(self._name)    @name.setter    def name(self, value):        self._name = value.split()>>> person = Person()>>> person.name = '\\t Guido  van Rossum \'>>> person.name'Guido van Rossum'DataclassDecorator that automatically generates init(), repr() and eq() special methods.from dataclasses import dataclass, field@dataclass(order=False, frozen=False)class <class_name>:    <attr_name>: <type>    <attr_name>: <type> = <default_value>    <attr_name>: list/dict/set = field(default_factory=list/dict/set)Objects can be made sortable with 'order=True' and immutable with 'frozen=True'.For object to be hashable, all attributes must be hashable and 'frozen' must be True.Function field() is needed because '<attr_name>: list = []' would make a list that is shared among all instances. Its 'default_factory' argument can be any callable.For attributes of arbitrary type use 'typing.Any'.Inline:from dataclasses import make_dataclass<class> = make_dataclass('<class_name>', <coll_of_attribute_names>)<class> = make_dataclass('<class_name>', <coll_of_tuples>)<tuple> = ('<attr_name>', <type> [, <default_value>])Rest of type annotations (CPython interpreter ignores them all):import collections.abc as abc, typing as tp<var_name>: list/set/abc.Iterable/abc.Sequence/tp.Optional[<type>] [= <obj>]<var_name>: dict/tuple/tp.Union[<type>, ...] [= <obj>]def func(<arg_name>: <type> [= <obj>]) -> <type>: ...SlotsMechanism that restricts objects to attributes listed in 'slots' and significantly reduces their memory footprint.class MyClassWithSlots:    __slots__ = ['a']    def __init__(self):        self.a = 1Copyfrom copy import copy, deepcopy<object> = copy(<object>)<object> = deepcopy(<object>)Duck TypesA duck type is an implicit type that prescribes a set of special methods. Any object that has those methods defined is considered a member of that duck type.ComparableIf eq() method is not overridden, it returns 'id(self) == id(other)', which is the same as 'self is other'.That means all objects compare not equal by default.Only the left side object has eq() method called, unless it returns NotImplemented, in which case the right object is consulted. False is returned if both return NotImplemented.Ne() automatically works on any object that has eq() defined.class MyComparable:    def __init__(self, a):        self.a = a    def __eq__(self, other):        if isinstance(other, type(self)):            return self.a == other.a        return NotImplementedHashableHashable object needs both hash() and eq() methods and its hash value should never change.Hashable objects that compare equal must have the same hash value, meaning default hash() that returns 'id(self)' will not do.That is why Python automatically makes classes unhashable if you only implement eq().class MyHashable:    def __init__(self, a):        self._a = a    @property    def a(self):        return self._a    def __eq__(self, other):        if isinstance(other, type(self)):            return self.a == other.a        return NotImplemented    def __hash__(self):        return hash(self.a)SortableWith 'total_ordering' decorator, you only need to provide eq() and one of lt(), gt(), le() or ge() special methods and the rest will be automatically generated.Functions sorted() and min() only require lt() method, while max() only requires gt(). However, it is best to define them all so that confusion doesn't arise in other contexts.When two lists, strings or dataclasses are compared, their values get compared in order until a pair of unequal values is found. The comparison of this two values is then returned. The shorter sequence is considered smaller in case of all values being equal.For proper alphabetical order pass 'key=locale.strxfrm' to sorted() after running 'locale.setlocale(locale.LC_COLLATE, \""en_US.UTF-8\"")'.from functools import total_ordering@total_orderingclass MySortable:    def __init__(self, a):        self.a = a    def __eq__(self, other):        if isinstance(other, type(self)):            return self.a == other.a        return NotImplemented    def __lt__(self, other):        if isinstance(other, type(self)):            return self.a < other.a        return NotImplementedIteratorAny object that has methods next() and iter() is an iterator.Next() should return next item or raise StopIteration.Iter() should return 'self'.class Counter:    def __init__(self):        self.i = 0    def __next__(self):        self.i += 1        return self.i    def __iter__(self):        return self>>> counter = Counter()>>> next(counter), next(counter), next(counter)(1, 2, 3)Python has many different iterator objects:Sequence iterators returned by the iter() function, such as list_iterator and set_iterator.Objects returned by the itertools module, such as count, repeat and cycle.Generators returned by the generator functions and generator expressions.File objects returned by the open() function, etc.CallableAll functions and classes have a call() method, hence are callable.When this cheatsheet uses '<function>' as an argument, it actually means '<callable>'.class Counter:    def __init__(self):        self.i = 0    def __call__(self):        self.i += 1        return self.i>>> counter = Counter()>>> counter(), counter(), counter()(1, 2, 3)Context ManagerWith statements only work with objects that have enter() and exit() special methods.Enter() should lock the resources and optionally return an object.Exit() should release the resources.Any exception that happens inside the with block is passed to the exit() method.The exit() method can suppress the exception by returning a true value.class MyOpen:    def __init__(self, filename):        self.filename = filename    def __enter__(self):        self.file = open(self.filename)        return self.file    def __exit__(self, exc_type, exception, traceback):        self.file.close()>>> with open('test.txt', 'w') as file:...     file.write('Hello World!')>>> with MyOpen('test.txt') as file:...     print(file.read())Hello World!Iterable Duck TypesIterableOnly required method is iter(). It should return an iterator of object's items.Contains() automatically works on any object that has iter() defined.class MyIterable:    def __init__(self, a):        self.a = a    def __iter__(self):        return iter(self.a)    def __contains__(self, el):        return el in self.a>>> obj = MyIterable([1, 2, 3])>>> [el for el in obj][1, 2, 3]>>> 1 in objTrueCollectionOnly required methods are iter() and len(). Len() should return the number of items.This cheatsheet actually means '<iterable>' when it uses '<collection>'.I chose not to use the name 'iterable' because it sounds scarier and more vague than 'collection'. The only drawback of this decision is that the reader could think a certain function doesn't accept iterators when it does, since iterators are the only built-in objects that are iterable but are not collections.class MyCollection:    def __init__(self, a):        self.a = a    def __iter__(self):        return iter(self.a)    def __contains__(self, el):        return el in self.a    def __len__(self):        return len(self.a)SequenceOnly required methods are getitem() and len().Getitem() should return an item at the passed index or raise IndexError.Iter() and contains() automatically work on any object that has getitem() defined.Reversed() automatically works on any object that has getitem() and len() defined.class MySequence:    def __init__(self, a):        self.a = a    def __iter__(self):        return iter(self.a)    def __contains__(self, el):        return el in self.a    def __len__(self):        return len(self.a)    def __getitem__(self, i):        return self.a[i]    def __reversed__(self):        return reversed(self.a)Discrepancies between glossary definitions and abstract base classes:Glossary defines iterable as any object with iter() or getitem() and sequence as any object with getitem() and len(). It does not define collection.Passing ABC Iterable to isinstance() or issubclass() checks whether object/class has method iter(), while ABC Collection checks for iter(), contains() and len().ABC SequenceIt's a richer interface than the basic sequence.Extending it generates iter(), contains(), reversed(), index() and count().Unlike 'abc.Iterable' and 'abc.Collection', it is not a duck type. That is why 'issubclass(MySequence, abc.Sequence)' would return False even if MySequence had all the methods defined. It however recognizes list, tuple, range, str, bytes, bytearray, array, memoryview and deque, because they are registered as its virtual subclasses.from collections import abcclass MyAbcSequence(abc.Sequence):    def __init__(self, a):        self.a = a    def __len__(self):        return len(self.a)    def __getitem__(self, i):        return self.a[i]Table of required and automatically available special methods:+------------+------------+------------+------------+--------------+|            |  Iterable  | Collection |  Sequence  | abc.Sequence |+------------+------------+------------+------------+--------------+| iter()     |    REQ     |    REQ     |    Yes     |     Yes      || contains() |    Yes     |    Yes     |    Yes     |     Yes      || len()      |            |    REQ     |    REQ     |     REQ      || getitem()  |            |            |    REQ     |     REQ      || reversed() |            |            |    Yes     |     Yes      || index()    |            |            |            |     Yes      || count()    |            |            |            |     Yes      |+------------+------------+------------+------------+--------------+Other ABCs that generate missing methods are: MutableSequence, Set, MutableSet, Mapping and MutableMapping.Names of their required methods are stored in '<abc>.__abstractmethods__'.Enumfrom enum import Enum, autoclass <enum_name>(Enum):    <member_name> = auto()    <member_name> = <value>    <member_name> = <value>, <value>Function auto() returns an increment of the last numeric value or 1.Accessing a member named after a reserved keyword causes SyntaxError.Methods receive the member they were called on as the 'self' argument.<member> = <enum>.<member_name>           # Returns a member.<member> = <enum>['<member_name>']        # Returns a member. Raises KeyError.<member> = <enum>(<value>)                # Returns a member. Raises ValueError.<str>    = <member>.name                  # Returns member's name.<obj>    = <member>.value                 # Returns member's value.<list>   = list(<enum>)                   # Returns enum's members.<list>   = [a.name for a in <enum>]       # Returns enum's member names.<list>   = [a.value for a in <enum>]      # Returns enum's member values.<member> = random.choice(list(<enum>))    # Returns a random member.def get_next_member(member):    members = list(type(member))    index = members.index(member) + 1    return members[index % len(members)]InlineCutlery = Enum('Cutlery', 'FORK KNIFE SPOON')Cutlery = Enum('Cutlery', ['FORK', 'KNIFE', 'SPOON'])Cutlery = Enum('Cutlery', {'FORK': 1, 'KNIFE': 2, 'SPOON': 3})User-defined functions cannot be values, so they must be wrapped:from functools import partialLogicOp = Enum('LogicOp', {'AND': partial(lambda l, r: l and r),                           'OR':  partial(lambda l, r: l or r)})Exceptionstry:    <code>except <exception>:    <code>Complex Exampletry:    <code_1>except <exception_a>:    <code_2_a>except <exception_b>:    <code_2_b>else:    <code_2_c>finally:    <code_3>Code inside the 'else' block will only be executed if 'try' block had no exceptions.Code inside the 'finally' block will always be executed (unless a signal is received).All variables that are initialized in executed blocks are also visible in all subsequent blocks, as well as outside the try/except clause (only function blocks delimit scope).To catch signals use 'signal.signal(signal_number, <func>)'.Catching Exceptionsexcept <exception>: ...except <exception> as <name>: ...except (<exception>, [...]): ...except (<exception>, [...]) as <name>: ...Also catches subclasses of the exception.Use 'traceback.print_exc()' to print the error message to stderr.Use 'print(<name>)' to print just the cause of the exception (its arguments).Use 'logging.exception(<message>)' to log the passed message, followed by the full error message of the caught exception.Raising Exceptionsraise <exception>raise <exception>()raise <exception>(<el> [, ...])Re-raising caught exception:except <exception> [as <name>]:    ...    raiseException Objectarguments = <name>.argsexc_type  = <name>.__class__filename  = <name>.__traceback__.tb_frame.f_code.co_filenamefunc_name = <name>.__traceback__.tb_frame.f_code.co_nameline      = linecache.getline(filename, <name>.__traceback__.tb_lineno)trace_str = ''.join(traceback.format_tb(<name>.__traceback__))error_msg = ''.join(traceback.format_exception(type(<name>), <name>, <name>.__traceback__))Built-in ExceptionsBaseException +-- SystemExit                   # Raised by the sys.exit() function. +-- KeyboardInterrupt            # Raised when the user hits the interrupt key (ctrl-c). +-- Exception                    # User-defined exceptions should be derived from this class.      +-- ArithmeticError         # Base class for arithmetic errors such as ZeroDivisionError.      +-- AssertionError          # Raised by `assert <exp>` if expression returns false value.      +-- AttributeError          # Raised when object doesn't have requested attribute/method.      +-- EOFError                # Raised by input() when it hits an end-of-file condition.      +-- LookupError             # Base class for errors when a collection can't find an item.      |    +-- IndexError         # Raised when a sequence index is out of range.      |    +-- KeyError           # Raised when a dictionary key or set element is missing.      +-- MemoryError             # Out of memory. Could be too late to start deleting vars.      +-- NameError               # Raised when nonexistent name (variable/func/class) is used.      |    +-- UnboundLocalError  # Raised when local name is used before it's being defined.      +-- OSError                 # Errors such as FileExistsError/PermissionError (see #Open).      |    +-- ConnectionError    # Errors such as BrokenPipeError/ConnectionAbortedError.      +-- RuntimeError            # Raised by errors that don't fall into other categories.      |    +-- NotImplementedErr  # Can be raised by abstract methods or by unfinished code.      |    +-- RecursionError     # Raised when the maximum recursion depth is exceeded.      +-- StopIteration           # Raised by next() when run on an empty iterator.      +-- TypeError               # Raised when an argument is of the wrong type.      +-- ValueError              # When argument has the right type but inappropriate value.Collections and their exceptions:+-----------+------------+------------+------------+|           |    List    |    Set     |    Dict    |+-----------+------------+------------+------------+| getitem() | IndexError |            |  KeyError  || pop()     | IndexError |  KeyError  |  KeyError  || remove()  | ValueError |  KeyError  |            || index()   | ValueError |            |            |+-----------+------------+------------+------------+Useful built-in exceptions:raise TypeError('Argument is of the wrong type!')raise ValueError('Argument has the right type but an inappropriate value!')raise RuntimeError('None of above!')User-defined Exceptionsclass MyError(Exception): passclass MyInputError(MyError): passExitExits the interpreter by raising SystemExit exception.import syssys.exit()                        # Exits with exit code 0 (success).sys.exit(<el>)                    # Prints to stderr and exits with 1.sys.exit(<int>)                   # Exits with passed exit code.Printprint(<el_1>, ..., sep=' ', end='\', file=sys.stdout, flush=False)Use 'file=sys.stderr' for messages about errors.Use 'flush=True' to forcibly flush the stream.Pretty Printfrom pprint import pprintpprint(<collection>, width=80, depth=None, compact=False, sort_dicts=True)Levels deeper than 'depth' get replaced by '...'.InputReads a line from the user input or pipe if present.<str> = input(prompt=None)Trailing newline gets stripped.Prompt string is printed to the standard output before reading input.Raises EOFError when user hits EOF (ctrl-d/ctrl-z‚èé) or input stream gets exhausted.Command Line Argumentsimport sysscripts_path = sys.argv[0]arguments    = sys.argv[1:]Argument Parserfrom argparse import ArgumentParser, FileTypep = ArgumentParser(description=<str>)p.add_argument('-<short_name>', '--<name>', action='store_true')  # Flag.p.add_argument('-<short_name>', '--<name>', type=<type>)          # Option.p.add_argument('<name>', type=<type>, nargs=1)                    # First argument.p.add_argument('<name>', type=<type>, nargs='+')                  # Remaining arguments.p.add_argument('<name>', type=<type>, nargs='*')                  # Optional arguments.args  = p.parse_args()                                            # Exits on error.value = args.<name>Use 'help=<str>' to set argument description that will be displayed in help message.Use 'default=<el>' to set the default value.Use 'type=FileType(<mode>)' for files. Accepts 'encoding', but 'newline' is None.OpenOpens the file and returns a corresponding file object.<file> = open(<path>, mode='r', encoding=None, newline=None)'encoding=None' means that the default encoding is used, which is platform dependent. Best practice is to use 'encoding=\""utf-8\""' whenever possible.'newline=None' means all different end of line combinations are converted to '\' on read, while on write all '\' characters are converted to system's default line separator.'newline=\""\""' means no conversions take place, but input is still broken into chunks by readline() and readlines() on every '\', '\\r' and '\\r\'.Modes'r'  - Read (default).'w'  - Write (truncate).'x'  - Write or fail if the file already exists.'a'  - Append.'w+' - Read and write (truncate).'r+' - Read and write from the start.'a+' - Read and write from the end.'t'  - Text mode (default).'b'  - Binary mode ('br', 'bw', 'bx', ‚Ä¶).Exceptions'FileNotFoundError' can be raised when reading with 'r' or 'r+'.'FileExistsError' can be raised when writing with 'x'.'IsADirectoryError' and 'PermissionError' can be raised by any.'OSError' is the parent class of all listed exceptions.File Object<file>.seek(0)                      # Moves to the start of the file.<file>.seek(offset)                 # Moves 'offset' chars/bytes from the start.<file>.seek(0, 2)                   # Moves to the end of the file.<bin_file>.seek(¬±offset, <anchor>)  # Anchor: 0 start, 1 current position, 2 end.<str/bytes> = <file>.read(size=-1)  # Reads 'size' chars/bytes or until EOF.<str/bytes> = <file>.readline()     # Returns a line or empty string/bytes on EOF.<list>      = <file>.readlines()    # Returns a list of remaining lines.<str/bytes> = next(<file>)          # Returns a line using buffer. Do not mix.<file>.write(<str/bytes>)           # Writes a string or bytes object.<file>.writelines(<collection>)     # Writes a coll. of strings or bytes objects.<file>.flush()                      # Flushes write buffer. Runs every 4096/8192 B.Methods do not add or strip trailing newlines, not even writelines().Read Text from Filedef read_file(filename):    with open(filename, encoding='utf-8') as file:        return file.readlines()Write Text to Filedef write_to_file(filename, text):    with open(filename, 'w', encoding='utf-8') as file:        file.write(text)Pathsimport os, globfrom pathlib import Path<str>  = os.getcwd()                # Returns the current working directory.<str>  = os.path.join(<path>, ...)  # Joins two or more pathname components.<str>  = os.path.realpath(<path>)   # Resolves symlinks and calls path.abspath().<str>  = os.path.basename(<path>)   # Returns final component of the path.<str>  = os.path.dirname(<path>)    # Returns path without the final component.<tup.> = os.path.splitext(<path>)   # Splits on last period of the final component.<list> = os.listdir(path='.')       # Returns filenames located at the path.<list> = glob.glob('<pattern>')     # Returns paths matching the wildcard pattern.<bool> = os.path.exists(<path>)     # Or: <Path>.exists()<bool> = os.path.isfile(<path>)     # Or: <DirEntry/Path>.is_file()<bool> = os.path.isdir(<path>)      # Or: <DirEntry/Path>.is_dir()<stat> = os.stat(<path>)            # Or: <DirEntry/Path>.stat()<real> = <stat>.st_mtime/st_size/‚Ä¶  # Modification time, size in bytes, ...DirEntryUnlike listdir(), scandir() returns DirEntry objects that cache isfile, isdir and on Windows also stat information, thus significantly increasing the performance of code that requires it.<iter> = os.scandir(path='.')       # Returns DirEntry objects located at the path.<str>  = <DirEntry>.path            # Returns the whole path as a string.<str>  = <DirEntry>.name            # Returns final component as a string.<file> = open(<DirEntry>)           # Opens the file and returns a file object.Path Object<Path> = Path(<path> [, ...])       # Accepts strings, Paths and DirEntry objects.<Path> = <path> / <path> [/ ...]    # First or second path must be a Path object.<Path> = <Path>.resolve()           # Returns absolute path with resolved symlinks.<Path> = Path()                     # Returns relative cwd. Also Path('.').<Path> = Path.cwd()                 # Returns absolute cwd. Also Path().resolve().<Path> = Path.home()                # Returns user's home directory (absolute).<Path> = Path(__file__).resolve()   # Returns script's path if cwd wasn't changed.<Path> = <Path>.parent              # Returns Path without the final component.<str>  = <Path>.name                # Returns final component as a string.<str>  = <Path>.stem                # Returns final component without extension.<str>  = <Path>.suffix              # Returns final component's extension.<tup.> = <Path>.parts               # Returns all components as strings.<iter> = <Path>.iterdir()           # Returns directory contents as Path objects.<iter> = <Path>.glob('<pattern>')   # Returns Paths matching the wildcard pattern.<str>  = str(<Path>)                # Returns path as a string.<file> = open(<Path>)               # Also <Path>.read/write_text/bytes().OS Commandsimport os, shutil, subprocessos.chdir(<path>)                    # Changes the current working directory.os.mkdir(<path>, mode=0o777)        # Creates a directory. Permissions are in octal.os.makedirs(<path>, mode=0o777)     # Creates all path's dirs. Also `exist_ok=False`.shutil.copy(from, to)               # Copies the file. 'to' can exist or be a dir.shutil.copy2(from, to)              # Also copies creation and modification time.shutil.copytree(from, to)           # Copies the directory. 'to' must not exist.os.rename(from, to)                 # Renames/moves the file or directory.os.replace(from, to)                # Same, but overwrites file 'to' even on Windows.shutil.move(from, to)               # Rename() that moves into 'to' if it's a dir.os.remove(<path>)                   # Deletes the file.os.rmdir(<path>)                    # Deletes the empty directory.shutil.rmtree(<path>)               # Deletes the directory.Paths can be either strings, Paths or DirEntry objects.Functions report OS related errors by raising either OSError or one of its subclasses.Shell Commands<pipe> = os.popen('<command>')      # Executes command in sh/cmd. Returns its stdout pipe.<str>  = <pipe>.read(size=-1)       # Reads 'size' chars or until EOF. Also readline/s().<int>  = <pipe>.close()             # Closes the pipe. Returns None on success (returncode 0).Sends '1 + 1' to the basic calculator and captures its output:>>> subprocess.run('bc', input='1 + 1\', capture_output=True, text=True)CompletedProcess(args='bc', returncode=0, stdout='2\', stderr='')Sends test.in to the basic calculator running in standard mode and saves its output to test.out:>>> from shlex import split>>> os.popen('echo 1 + 1 > test.in')>>> subprocess.run(split('bc -s'), stdin=open('test.in'), stdout=open('test.out', 'w'))CompletedProcess(args=['bc', '-s'], returncode=0)>>> open('test.out').read()'2\'JSONText file format for storing collections of strings and numbers.import json<str>    = json.dumps(<object>)     # Converts object to JSON string.<object> = json.loads(<str>)        # Converts JSON string to object.Read Object from JSON Filedef read_json_file(filename):    with open(filename, encoding='utf-8') as file:        return json.load(file)Write Object to JSON Filedef write_to_json_file(filename, an_object):    with open(filename, 'w', encoding='utf-8') as file:        json.dump(an_object, file, ensure_ascii=False, indent=2)PickleBinary file format for storing Python objects.import pickle<bytes>  = pickle.dumps(<object>)   # Converts object to bytes object.<object> = pickle.loads(<bytes>)    # Converts bytes object to object.Read Object from Filedef read_pickle_file(filename):    with open(filename, 'rb') as file:        return pickle.load(file)Write Object to Filedef write_to_pickle_file(filename, an_object):    with open(filename, 'wb') as file:        pickle.dump(an_object, file)CSVText file format for storing spreadsheets.import csvRead<reader> = csv.reader(<file>)       # Also: `dialect='excel', delimiter=','`.<list>   = next(<reader>)           # Returns next row as a list of strings.<list>   = list(<reader>)           # Returns a list of remaining rows.File must be opened with a 'newline=\""\""' argument, or newlines embedded inside quoted fields will not be interpreted correctly!To print the spreadsheet to the console use Tabulate library.For XML and binary Excel files (xlsx, xlsm and xlsb) use Pandas library.Reader accepts any iterator of strings, not just files.Write<writer> = csv.writer(<file>)       # Also: `dialect='excel', delimiter=','`.<writer>.writerow(<collection>)     # Encodes objects using `str(<el>)`.<writer>.writerows(<coll_of_coll>)  # Appends multiple rows.File must be opened with a 'newline=\""\""' argument, or '\\r' will be added in front of every '\' on platforms that use '\\r\' line endings!Parameters'dialect' - Master parameter that sets the default values. String or a 'csv.Dialect' object.'delimiter' - A one-character string used to separate fields.'quotechar' - Character for quoting fields that contain special characters.'doublequote' - Whether quotechars inside fields are/get doubled or escaped.'skipinitialspace' - Is space character at the start of the field stripped by the reader.'lineterminator' - How writer terminates rows. Reader is hardcoded to '\', '\\r', '\\r\'.'quoting' - 0: As necessary, 1: All, 2: All but numbers which are read as floats, 3: None.'escapechar' - Character for escaping quotechars if 'doublequote' is False.Dialects+------------------+--------------+--------------+--------------+|                  |     excel    |   excel-tab  |     unix     |+------------------+--------------+--------------+--------------+| delimiter        |       ','    |      '\\t'    |       ','    || quotechar        |       '\""'    |       '\""'    |       '\""'    || doublequote      |      True    |      True    |      True    || skipinitialspace |     False    |     False    |     False    || lineterminator   |    '\\r\'    |    '\\r\'    |      '\'    || quoting          |         0    |         0    |         1    || escapechar       |      None    |      None    |      None    |+------------------+--------------+--------------+--------------+Read Rows from CSV Filedef read_csv_file(filename, dialect='excel', **params):    with open(filename, encoding='utf-8', newline='') as file:        return list(csv.reader(file, dialect, **params))Write Rows to CSV Filedef write_to_csv_file(filename, rows, dialect='excel', **params):    with open(filename, 'w', encoding='utf-8', newline='') as file:        writer = csv.writer(file, dialect, **params)        writer.writerows(rows)SQLiteA server-less database engine that stores each database into a separate file.import sqlite3<conn> = sqlite3.connect(<path>)                # Opens existing or new file. Also ':memory:'.<conn>.close()                                  # Closes the connection.Read<cursor> = <conn>.execute('<query>')            # Can raise a subclass of sqlite3.Error.<tuple>  = <cursor>.fetchone()                  # Returns next row. Also next(<cursor>).<list>   = <cursor>.fetchall()                  # Returns remaining rows. Also list(<cursor>).Write<conn>.execute('<query>')                       # Can raise a subclass of sqlite3.Error.<conn>.commit()                                 # Saves all changes since the last commit.<conn>.rollback()                               # Discards all changes since the last commit.Or:with <conn>:                                    # Exits the block with commit() or rollback(),    <conn>.execute('<query>')                   # depending on whether any exception occurred.Placeholders<conn>.execute('<query>', <list/tuple>)         # Replaces '?'s in query with values.<conn>.execute('<query>', <dict/namedtuple>)    # Replaces ':<key>'s with values.<conn>.executemany('<query>', <coll_of_above>)  # Runs execute() multiple times.Passed values can be of type str, int, float, bytes, None, bool, datetime.date or datetime.datetime.Bools will be stored and returned as ints and dates as ISO formatted strings.ExampleValues are not actually saved in this example because 'conn.commit()' is omitted!>>> conn = sqlite3.connect('test.db')>>> conn.execute('CREATE TABLE person (person_id INTEGER PRIMARY KEY, name, height)')>>> conn.execute('INSERT INTO person VALUES (NULL, ?, ?)', ('Jean-Luc', 187)).lastrowid1>>> conn.execute('SELECT * FROM person').fetchall()[(1, 'Jean-Luc', 187)]SqlAlchemy# $ pip3 install sqlalchemyfrom sqlalchemy import create_engine, text<engine> = create_engine('<url>')               # Url: 'dialect://user:password@host/dbname'.<conn>   = <engine>.connect()                   # Creates a connection. Also <conn>.close().<cursor> = <conn>.execute(text('<query>'), ‚Ä¶)   # Replaces ':<key>'s with keyword arguments.with <conn>.begin(): ...                        # Exits the block with commit or rollback.+------------+--------------+----------+----------------------------------+| Dialect    | pip3 install | import   |           Dependencies           |+------------+--------------+----------+----------------------------------+| mysql      | mysqlclient  | MySQLdb  | www.pypi.org/project/mysqlclient || postgresql | psycopg2     | psycopg2 | www.pypi.org/project/psycopg2    || mssql      | pyodbc       | pyodbc   | www.pypi.org/project/pyodbc      || oracle     | oracledb     | oracledb | www.pypi.org/project/oracledb    |+------------+--------------+----------+----------------------------------+BytesBytes object is an immutable sequence of single bytes. Mutable version is called bytearray.<bytes> = b'<str>'                          # Only accepts ASCII characters and \\x00-\\xff.<int>   = <bytes>[<index>]                  # Returns an int in range from 0 to 255.<bytes> = <bytes>[<slice>]                  # Returns bytes even if it has only one element.<bytes> = <bytes>.join(<coll_of_bytes>)     # Joins elements using bytes as a separator.Encode<bytes> = bytes(<coll_of_ints>)             # Ints must be in range from 0 to 255.<bytes> = bytes(<str>, 'utf-8')             # Or: <str>.encode('utf-8')<bytes> = <int>.to_bytes(n_bytes, ‚Ä¶)        # `byteorder='big/little', signed=False`.<bytes> = bytes.fromhex('<hex>')            # Hex pairs can be separated by whitespaces.Decode<list>  = list(<bytes>)                     # Returns ints in range from 0 to 255.<str>   = str(<bytes>, 'utf-8')             # Or: <bytes>.decode('utf-8')<int>   = int.from_bytes(<bytes>, ‚Ä¶)        # `byteorder='big/little', signed=False`.'<hex>' = <bytes>.hex()                     # Returns hex pairs. Accepts `sep=<str>`.Read Bytes from Filedef read_bytes(filename):    with open(filename, 'rb') as file:        return file.read()Write Bytes to Filedef write_bytes(filename, bytes_obj):    with open(filename, 'wb') as file:        file.write(bytes_obj)StructModule that performs conversions between a sequence of numbers and a bytes object.System‚Äôs type sizes, byte order, and alignment rules are used by default.from struct import pack, unpack<bytes> = pack('<format>', <el_1> [, ...])  # Packages arguments or raises struct.error.<tuple> = unpack('<format>', <bytes>)       # Use iter_unpack() for iterator of tuples.>>> pack('>hhl', 1, 2, 3)b'\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x03'>>> unpack('>hhl', b'\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x03')(1, 2, 3)FormatFor standard type sizes and manual alignment (padding) start format string with:'=' - System's byte order (usually little-endian).'<' - Little-endian.'>' - Big-endian (also '!').Besides numbers, pack() and unpack() also support bytes objects as part of the sequence:'c' - A bytes object with a single element. For pad byte use 'x'.'<n>s' - A bytes object with n elements.Integer types. Use a capital letter for unsigned type. Minimum and standard sizes are in brackets:'b' - char (1/1)'h' - short (2/2)'i' - int (2/4)'l' - long (4/4)'q' - long long (8/8)Floating point types (struct always uses standard sizes):'f' - float (4/4)'d' - double (8/8)ArrayList that can only hold numbers of a predefined type. Available types and their minimum sizes in bytes are listed above. Sizes and byte order are always determined by the system, however bytes of each element can be swapped with byteswap() method.from array import array<array> = array('<typecode>', <collection>)    # Array from collection of numbers.<array> = array('<typecode>', <bytes>)         # Array from bytes object.<array> = array('<typecode>', <array>)         # Treats array as a sequence of numbers.<bytes> = bytes(<array>)                       # Or: <array>.tobytes()<file>.write(<array>)                          # Writes array to the binary file.Memory ViewA sequence object that points to the memory of another bytes-like object.Each element can reference a single or multiple consecutive bytes, depending on format.Order and number of elements can be changed with slicing.Casting only works between char and other types and uses system's sizes.Byte order is always determined by the system.<mview> = memoryview(<bytes/bytearray/array>)  # Immutable if bytes, else mutable.<real>  = <mview>[<index>]                     # Returns an int or a float.<mview> = <mview>[<slice>]                     # Mview with rearranged elements.<mview> = <mview>.cast('<typecode>')           # Casts memoryview to the new format.<mview>.release()                              # Releases the object's memory buffer.<bytes> = bytes(<mview>)                       # Returns a new bytes object.<bytes> = <bytes>.join(<coll_of_mviews>)       # Joins mviews using bytes object as sep.<array> = array('<typecode>', <mview>)         # Treats mview as a sequence of numbers.<file>.write(<mview>)                          # Writes mview to the binary file.<list>  = list(<mview>)                        # Returns a list of ints or floats.<str>   = str(<mview>, 'utf-8')                # Treats mview as a bytes object.<int>   = int.from_bytes(<mview>, ‚Ä¶)           # `byteorder='big/little', signed=False`.'<hex>' = <mview>.hex()                        # Treats mview as a bytes object.DequeA thread-safe list with efficient appends and pops from either side. Pronounced \""deck\"".from collections import deque<deque> = deque(<collection>)                  # Also `maxlen=None`.<deque>.appendleft(<el>)                       # Opposite element is dropped if full.<deque>.extendleft(<collection>)               # Collection gets reversed.<el> = <deque>.popleft()                       # Raises IndexError if empty.<deque>.rotate(n=1)                            # Rotates elements to the right.ThreadingCPython interpreter can only run a single thread at a time.That is why using multiple threads won't result in a faster execution, unless at least one of the threads contains an I/O operation.from threading import Thread, RLock, Semaphore, Event, Barrierfrom concurrent.futures import ThreadPoolExecutor, as_completedThread<Thread> = Thread(target=<function>)           # Use `args=<collection>` to set the arguments.<Thread>.start()                               # Starts the thread.<bool> = <Thread>.is_alive()                   # Checks if the thread has finished executing.<Thread>.join()                                # Waits for the thread to finish.Use 'kwargs=<dict>' to pass keyword arguments to the function.Use 'daemon=True', or the program will not be able to exit while the thread is alive.Lock<lock> = RLock()                               # Lock that can only be released by acquirer.<lock>.acquire()                               # Waits for the lock to be available.<lock>.release()                               # Makes the lock available again.Or:with <lock>:                                   # Enters the block by calling acquire() and    ...                                        # exits it with release(), even on error.Semaphore, Event, Barrier<Semaphore> = Semaphore(value=1)               # Lock that can be acquired by 'value' threads.<Event>     = Event()                          # Method wait() blocks until set() is called.<Barrier>   = Barrier(n_times)                 # Wait() blocks until it's called n_times.Queue<Queue> = queue.Queue(maxsize=0)               # A thread-safe FIFO queue. Also LifoQueue.<Queue>.put(<el>)                              # Blocks until queue stops being full.<Queue>.put_nowait(<el>)                       # Raises queue.Full exception if full.<el> = <Queue>.get()                           # Blocks until queue stops being empty.<el> = <Queue>.get_nowait()                    # Raises queue.Empty exception if empty.Thread Pool Executor<Exec> = ThreadPoolExecutor(max_workers=None)  # Or: `with ThreadPoolExecutor() as <name>: ‚Ä¶`<iter> = <Exec>.map(<func>, <args_1>, ...)     # Multithreaded and non-lazy map(). Keeps order.<Futr> = <Exec>.submit(<func>, <arg_1>, ...)   # Creates a thread and returns its Future obj.<Exec>.shutdown(wait=True)                     # Blocks until all threads finish executing.<bool> = <Future>.done()                       # Checks if the thread has finished executing.<obj>  = <Future>.result(timeout=None)         # Waits for thread to finish and returns result.<bool> = <Future>.cancel()                     # Returns False if thread is already running.<iter> = as_completed(<coll_of_Futures>)       # Each Future is yielded as it completes.Map() and as_completed() also accept 'timeout' argument that causes TimeoutError if result isn't available in 'timeout' seconds after next() is called.Exceptions that happen inside threads are raised when next() is called on map's iterator or when result() is called on a Future. Its exception() method returns exception or None.ProcessPoolExecutor provides true parallelism, but everything sent to/from workers must be pickable. Queues must be sent using executor's 'initargs' and 'initializer' parameters.OperatorModule of functions that provide the functionality of operators. Functions are ordered by operator precedence, starting with least binding.import operator as op<bool> = op.not_(<obj>)                                        # not (or/and are not provided)<bool> = op.eq/ne/lt/le/gt/ge/contains(<obj>, <obj>)           # ==, !=, <, <=, >, >=, in<obj>  = op.or_/xor/and_(<int/set>, <int/set>)                 # |, ^, &<obj>  = op.add/sub/mul/truediv/floordiv/mod(<obj>, <obj>)     # +, -, *, /, //, %<num>  = op.neg/invert(<num>)                                  # -, ~<num>  = op.pow(<num>, <num>)                                  # **<func> = op.itemgetter/attrgetter/methodcaller(<obj> [, ...])  # [index/key], .name, .name()elementwise_sum  = map(op.add, list_a, list_b)sorted_by_second = sorted(<collection>, key=op.itemgetter(1))sorted_by_both   = sorted(<collection>, key=op.itemgetter(1, 0))product_of_elems = functools.reduce(op.mul, <collection>)union_of_sets    = functools.reduce(op.or_, <coll_of_sets>)first_element    = op.methodcaller('pop', 0)(<list>)Bitwise operators require objects to have and(), or() and xor() special methods, unlike logical operators that work on all types of objects.Also: '<bool> = <bool> &|^ <bool>' and '<int> = <bool> &|^ <int>'.Introspection<list> = dir()                             # Names of local variables, functions, classes, etc.<dict> = vars()                            # Dict of local variables, etc. Also locals().<dict> = globals()                         # Dict of global vars, etc. (incl. '__builtins__').Attributes<list> = dir(<object>)                     # Names of object's attributes (incl. methods).<dict> = vars(<object>)                    # Dict of writable attributes. Also <obj>.__dict__.<bool> = hasattr(<object>, '<attr_name>')  # Checks if getattr() raises an AttributeError.value  = getattr(<object>, '<attr_name>')  # Raises AttributeError if attribute is missing.setattr(<object>, '<attr_name>', value)    # Only works on objects with '__dict__' attribute.delattr(<object>, '<attr_name>')           # Same. Also `del <object>.<attr_name>`.Parameters<Sig>  = inspect.signature(<function>)     # Function's Signature object.<dict> = <Sig>.parameters                  # Dict of Parameter objects.<memb> = <Param>.kind                      # Member of ParameterKind enum.<obj>  = <Param>.default                   # Default value or Parameter.empty.<type> = <Param>.annotation                # Type or Parameter.empty.MetaprogrammingCode that generates code.TypeType is the root class. If only passed an object it returns its type (class). Otherwise it creates a new class.<class> = type('<class_name>', <tuple_of_parents>, <dict_of_class_attributes>)>>> Z = type('Z', (), {'a': 'abcde', 'b': 12345})>>> z = Z()Meta ClassA class that creates classes.def my_meta_class(name, parents, attrs):    attrs['a'] = 'abcde'    return type(name, parents, attrs)Or:class MyMetaClass(type):    def __new__(cls, name, parents, attrs):        attrs['a'] = 'abcde'        return type.__new__(cls, name, parents, attrs)New() is a class method that gets called before init(). If it returns an instance of its class, then that instance gets passed to init() as a 'self' argument.It receives the same arguments as init(), except for the first one that specifies the desired type of the returned instance (MyMetaClass in our case).Like in our case, new() can also be called directly, usually from a new() method of a child class (def __new__(cls): return super().__new__(cls)).The only difference between the examples above is that my_meta_class() returns a class of type type, while MyMetaClass() returns a class of type MyMetaClass.Metaclass AttributeRight before a class is created it checks if it has the 'metaclass' attribute defined. If not, it recursively checks if any of its parents has it defined and eventually comes to type().class MyClass(metaclass=MyMetaClass):    b = 12345>>> MyClass.a, MyClass.b('abcde', 12345)Type Diagramtype(MyClass) == MyMetaClass         # MyClass is an instance of MyMetaClass.type(MyMetaClass) == type            # MyMetaClass is an instance of type.+-------------+-------------+|   Classes   | Metaclasses |+-------------+-------------||   MyClass <-- MyMetaClass ||             |     ^       ||    object <----- type <+  ||             |     | +--+  ||     str <---------+       |+-------------+-------------+Inheritance DiagramMyClass.__base__ == object           # MyClass is a subclass of object.MyMetaClass.__base__ == type         # MyMetaClass is a subclass of type.+-------------+-------------+|   Classes   | Metaclasses |+-------------+-------------||   MyClass   | MyMetaClass ||      ^      |     ^       ||    object -----> type     ||      v      |             ||     str     |             |+-------------+-------------+Eval>>> from ast import literal_eval>>> literal_eval('[1, 2, 3]')[1, 2, 3]>>> literal_eval('1 + 2')ValueError: malformed node or stringCoroutinesCoroutines have a lot in common with threads, but unlike threads, they only give up control when they call another coroutine and they don‚Äôt use as much memory.Coroutine definition starts with 'async' and its call with 'await'.'asyncio.run(<coroutine>)' is the main entry point for asynchronous programs.Functions wait(), gather() and as_completed() start multiple coroutines at the same time.Asyncio module also provides its own Queue, Event, Lock and Semaphore classes.Runs a terminal game where you control an asterisk that must avoid numbers:import asyncio, collections, curses, curses.textpad, enum, randomP = collections.namedtuple('P', 'x y')         # PositionD = enum.Enum('D', 'n e s w')                  # DirectionW, H = 15, 7                                   # Width, Heightdef main(screen):    curses.curs_set(0)                         # Makes cursor invisible.    screen.nodelay(True)                       # Makes getch() non-blocking.    asyncio.run(main_coroutine(screen))        # Starts running asyncio code.async def main_coroutine(screen):    moves = asyncio.Queue()    state = {'*': P(0, 0), **{id_: P(W//2, H//2) for id_ in range(10)}}    ai    = [random_controller(id_, moves) for id_ in range(10)]    mvc   = [human_controller(screen, moves), model(moves, state), view(state, screen)]    tasks = [asyncio.create_task(cor) for cor in ai + mvc]    await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)async def random_controller(id_, moves):    while True:        d = random.choice(list(D))        moves.put_nowait((id_, d))        await asyncio.sleep(random.triangular(0.01, 0.65))async def human_controller(screen, moves):    while True:        key_mappings = {258: D.s, 259: D.n, 260: D.w, 261: D.e}        if d := key_mappings.get(screen.getch()):            moves.put_nowait(('*', d))        await asyncio.sleep(0.005)async def model(moves, state):    while state['*'] not in (state[id_] for id_ in range(10)):        id_, d = await moves.get()        x, y   = state[id_]        deltas = {D.n: P(0, -1), D.e: P(1, 0), D.s: P(0, 1), D.w: P(-1, 0)}        state[id_] = P((x + deltas[d].x) % W, (y + deltas[d].y) % H)async def view(state, screen):    offset = P(curses.COLS//2 - W//2, curses.LINES//2 - H//2)    while True:        screen.erase()        curses.textpad.rectangle(screen, offset.y-1, offset.x-1, offset.y+H, offset.x+W)        for id_, p in state.items():            screen.addstr(offset.y + (p.y - state['*'].y + H//2) % H,                          offset.x + (p.x - state['*'].x + W//2) % W, str(id_))        screen.refresh()        await asyncio.sleep(0.005)if __name__ == '__main__':    curses.wrapper(main)LibrariesProgress Bar# $ pip3 install tqdm>>> from tqdm import tqdm>>> from time import sleep>>> for el in tqdm([1, 2, 3], desc='Processing'):...     sleep(1)Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.00s/it]Plot# $ pip3 install matplotlibimport matplotlib.pyplot as pltplt.plot/bar/scatter(x_data, y_data [, label=<str>])  # Or: plt.plot(y_data)plt.legend()                                          # Adds a legend.plt.savefig(<path>)                                   # Saves the figure.plt.show()                                            # Displays the figure.plt.clf()                                             # Clears the figure.TablePrints a CSV file as an ASCII table:# $ pip3 install tabulateimport csv, tabulatewith open('test.csv', encoding='utf-8', newline='') as file:    rows   = csv.reader(file)    header = next(rows)    table  = tabulate.tabulate(rows, header)print(table)CursesRuns a basic file explorer in the terminal:import curses, osfrom curses import A_REVERSE, KEY_DOWN, KEY_UP, KEY_LEFT, KEY_RIGHT, KEY_ENTERdef main(screen):    ch, first, selected, paths = 0, 0, 0, os.listdir()    while ch != ord('q'):        height, width = screen.getmaxyx()        screen.erase()        for y, filename in enumerate(paths[first : first+height]):            color = A_REVERSE if filename == paths[selected] else 0            screen.addnstr(y, 0, filename, width-1, color)        ch = screen.getch()        selected += (ch == KEY_DOWN) - (ch == KEY_UP)        selected = max(0, min(len(paths)-1, selected))        first += (selected >= first + height) - (selected < first)        if ch in [KEY_LEFT, KEY_RIGHT, KEY_ENTER, ord('\'), ord('\\r')]:            new_dir = '..' if ch == KEY_LEFT else paths[selected]            if os.path.isdir(new_dir):                os.chdir(new_dir)                first, selected, paths = 0, 0, os.listdir()if __name__ == '__main__':    curses.wrapper(main)Loggingimport logginglogging.basicConfig(filename=<path>)              # Configures the root logger.logging.debug/info/warning/error/critical(<str>)  # Logs to the root logger.<Logger> = logging.getLogger(__name__)            # Logger named after the module.<Logger>.<level>(<str>)                           # Messages propagate to the root logger.<Logger>.exception(<str>)                         # Calls error() with caught exception.Setuplogging.basicConfig(    filename=None,                                # Logs to console by default.    format='%(levelname)s:%(name)s:%(message)s',  # Add `%(asctime)s` for datetime.    level=logging.WARNING,                        # Drops messages with lower priority.    handlers=[logging.StreamHandler()]            # Uses FileHandler if filename is set.)<Formatter> = logging.Formatter('<format>')       # Creates a Formatter.<Handler> = logging.FileHandler(<path>)           # Creates a Handler.<Handler>.setFormatter(<Formatter>)               # Adds Formatter to the Handler.<Handler>.setLevel(<int/str>)                     # Processes all messages by default.<Logger>.addHandler(<Handler>)                    # Adds Handler to the Logger.<Logger>.setLevel(<int/str>)                      # What is sent to handlers and parent.Parent logger can be specified by naming the child logger '<parent>.<name>'.Formatter also supports: pathname, filename, funcName, lineno, thread and process.A 'handlers.RotatingFileHandler' creates and deletes log files based on 'maxBytes' and 'backupCount' arguments.Creates a logger that writes all messages to a file and sends them to the root logger that prints to stdout:>>> logging.basicConfig(level='WARNING')>>> logger = logging.getLogger('my_module')>>> handler = logging.FileHandler('test.log')>>> formatter = logging.Formatter('%(asctime)s %(levelname)s:%(name)s:%(message)s')>>> handler.setFormatter(formatter)>>> logger.addHandler(handler)>>> logger.critical('Running out of disk space.')CRITICAL:my_module:Running out of disk space.>>> print(open('test.log').read())2023-02-07 23:21:01,430 CRITICAL:my_module:Running out of disk space.ScrapingScrapes Python's URL, version number and logo from its Wikipedia page:# $ pip3 install requests beautifulsoup4import requests, bs4, os, sysWIKI_URL = 'https://en.wikipedia.org/wiki/Python_(programming_language)'try:    html       = requests.get(WIKI_URL).text    document   = bs4.BeautifulSoup(html, 'html.parser')    table      = document.find('table', class_='infobox vevent')    python_url = table.find('th', text='Website').next_sibling.a['href']    version    = table.find('th', text='Stable release').next_sibling.strings.__next__()    logo_url   = table.find('img')['src']    logo       = requests.get(f'https:{logo_url}').content    filename   = os.path.basename(logo_url)    with open(filename, 'wb') as file:        file.write(logo)    print(f'{python_url}, {version}, file://{os.path.abspath(filename)}')except requests.exceptions.ConnectionError:    print(\""You've got problems with connection.\"", file=sys.stderr)WebFlask is a micro web framework/server. If you just want to open a html file in a web browser use 'webbrowser.open(<path>)' instead.# $ pip3 install flaskfrom flask import Flask, send_from_directory, render_template_string, requestapp = Flask(__name__)app.run(host=None, port=None, debug=None)Starts the app at 'http://localhost:5000'. Use 'host=\""0.0.0.0\""' to run externally.Install a WSGI server like Waitress and a HTTP server such as Nginx for better security.Debug mode restarts the app whenever script changes and displays errors in the browser.Static Request@app.route('/img/<path:filename>')def serve_file(filename):    return send_from_directory('dirname/', filename)Dynamic Request@app.route('/<sport>')def serve_html(sport):    return render_template_string('<h1>{{title}}</h1>', title=sport)To return an error code use 'abort(<int>)' and to redirect use 'redirect(<url>)'.'request.args[<str>]' returns parameter from the query string (URL part after '?').Use 'session[key] = value' to store session data like username, etc.REST Request@app.post('/<sport>/odds')def serve_json(sport):    team = request.form['team']    return {'team': team, 'odds': [2.09, 3.74, 3.68]}Starts the app in its own thread and queries it with a post request:# $ pip3 install requests>>> import threading, requests>>> threading.Thread(target=app.run, daemon=True).start()>>> url = 'http://localhost:5000/football/odds'>>> request_data = {'team': 'arsenal f.c.'}>>> response = requests.post(url, data=request_data)>>> response.json(){'team': 'arsenal f.c.', 'odds': [2.09, 3.74, 3.68]}Profilingfrom time import perf_counterstart_time = perf_counter()...duration_in_seconds = perf_counter() - start_timeTiming a Snippet>>> from timeit import timeit>>> timeit('list(range(10000))', number=1000, globals=globals(), setup='pass')0.19373Profiling by Line$ pip3 install line_profiler$ echo '@profiledef main():    a = list(range(10000))    b = set(range(10000))main()' > test.py$ kernprof -lv test.pyLine #   Hits     Time  Per Hit   % Time  Line Contents=======================================================     1                                    @profile     2                                    def main():     3      1    219.0    219.0     31.1      a = list(range(10000))     4      1    487.0    487.0     68.9      b = set(range(10000))Call and Flame Graphs$ pip3 install gprof2dot snakeviz; apt/brew install graphviz$ tail -n 4 test.py > test.py$ python3 -m cProfile -o test.prof test.py$ gprof2dot -f pstats test.prof | dot -Tpng -o test.png; xdg-open/open test.png$ snakeviz test.profSampling and Memory Profilers+--------------+-------------------------------+------------+----------+------+| pip3 install |          How to run           |   Target   |   Type   | Live |+--------------+-------------------------------+------------+----------+------+| py-spy       | py-spy top -- python3 test.py |    CPU     | Sampling | Yes  || pyinstrument | pyinstrument test.py          |    CPU     | Sampling | No   || scalene      | scalene test.py               | CPU+Memory | Sampling | No   || memray       | memray run --live test.py     |   Memory   | Tracing  | Yes  || filprofiler  | fil-profile run test.py       |   Memory   | Tracing  | No   |+--------------+-------------------------------+------------+----------+------+NumPyArray manipulation mini-language. It can run up to one hundred times faster than the equivalent Python code. An even faster alternative that runs on a GPU is called CuPy.# $ pip3 install numpyimport numpy as np<array> = np.array(<list/list_of_lists/‚Ä¶>)              # Returns a 1d/2d/‚Ä¶ NumPy array.<array> = np.zeros/ones/empty(<shape>)                  # Also np.full(<shape>, <el>).<array> = np.arange(from_inc, to_exc, ¬±step)            # Also np.linspace(start, stop, len).<array> = np.random.randint(from_inc, to_exc, <shape>)  # Also np.random.random(<shape>).<view>  = <array>.reshape(<shape>)                      # Also `<array>.shape = <shape>`.<array> = <array>.flatten()                             # Also `<view> = <array>.ravel()`.<view>  = <array>.transpose()                           # Or: <array>.T<array> = np.copy/abs/sqrt/log/int64(<array>)           # Returns new array of the same shape.<array> = <array>.sum/max/mean/argmax/all(axis)         # Passed dimension gets aggregated.<array> = np.apply_along_axis(<func>, axis, <array>)    # Func can return a scalar or array.<array> = np.concatenate(<list_of_arrays>, axis=0)      # Links arrays along first axis (rows).<array> = np.row_stack/column_stack(<list_of_arrays>)   # Treats 1d arrays as rows or columns.<array> = np.tile/repeat(<array>, <int/list>)           # Tiles array or repeats its elements.Shape is a tuple of dimension sizes. A 100x50 RGB image has shape (50, 100, 3).Axis is an index of the dimension that gets aggregated. Leftmost dimension has index 0. Summing the RGB image along axis 2 will return a greyscale image with shape (50, 100).Indexing<el>       = <2d_array>[row_index, column_index]        # <3d_a>[table_i, row_i, column_i]<1d_view>  = <2d_array>[row_index]                      # <3d_a>[table_i, row_i]<1d_view>  = <2d_array>[:, column_index]                # <3d_a>[table_i, :, column_i]<2d_view>  = <2d_array>[rows_slice, columns_slice]      # <3d_a>[table_i, rows_s, columns_s]<2d_array> = <2d_array>[row_indexes]                    # <3d_a>[table_i/is, row_is]<2d_array> = <2d_array>[:, column_indexes]              # <3d_a>[table_i/is, :, column_is]<1d_array> = <2d_array>[row_indexes, column_indexes]    # <3d_a>[table_i/is, row_is, column_is]<1d_array> = <2d_array>[row_indexes, column_index]      # <3d_a>[table_i/is, row_is, column_i]<2d_bools> = <2d_array> ><== <el/1d/2d_array>           # 1d_array must have size of a row.<1d/2d_a>  = <2d_array>[<2d/1d_bools>]                  # 1d_bools must have size of a column.Indexes should not be tuples because Python converts 'obj[i, j]'  to 'obj[(i, j)]'!Any value that is broadcastable to the indexed shape can be assigned to the selection.BroadcastingSet of rules by which NumPy functions operate on arrays of different sizes and/or dimensions.left  = [[0.1], [0.6], [0.8]]                           # Shape: (3, 1)right = [ 0.1 ,  0.6 ,  0.8 ]                           # Shape: (3,)1. If array shapes differ in length, left-pad the shorter shape with ones:left  = [[0.1], [0.6], [0.8]]                           # Shape: (3, 1)right = [[0.1 ,  0.6 ,  0.8]]                           # Shape: (1, 3) <- !2. If any dimensions differ in size, expand the ones that have size 1 by duplicating their elements:left  = [[0.1,  0.1,  0.1],                             # Shape: (3, 3) <- !         [0.6,  0.6,  0.6],         [0.8,  0.8,  0.8]]right = [[0.1,  0.6,  0.8],                             # Shape: (3, 3) <- !         [0.1,  0.6,  0.8],         [0.1,  0.6,  0.8]]ExampleFor each point returns index of its nearest point ([0.1, 0.6, 0.8] => [1, 2, 1]):>>> points = np.array([0.1, 0.6, 0.8]) [ 0.1,  0.6,  0.8]>>> wrapped_points = points.reshape(3, 1)[[ 0.1], [ 0.6], [ 0.8]]>>> distances = wrapped_points - points[[ 0. , -0.5, -0.7], [ 0.5,  0. , -0.2], [ 0.7,  0.2,  0. ]]>>> distances = np.abs(distances)[[ 0. ,  0.5,  0.7], [ 0.5,  0. ,  0.2], [ 0.7,  0.2,  0. ]]>>> i = np.arange(3)[0, 1, 2]>>> distances[i, i] = np.inf[[ inf,  0.5,  0.7], [ 0.5,  inf,  0.2], [ 0.7,  0.2,  inf]]>>> distances.argmin(1)[1, 2, 1]Image# $ pip3 install pillowfrom PIL import Image, ImageDraw<Image> = Image.new('<mode>', (width, height))  # Also `color=<int/tuple/str>`.<Image> = Image.open(<path>)                    # Identifies format based on file contents.<Image> = <Image>.convert('<mode>')             # Converts image to the new mode.<Image>.save(<path>)                            # Selects format based on the path extension.<Image>.show()                                  # Opens image in the default preview app.<int/tuple> = <Image>.getpixel((x, y))          # Returns a pixel.<Image>.putpixel((x, y), <int/tuple>)           # Writes a pixel to the image.<ImagingCore> = <Image>.getdata()               # Returns a flattened view of the pixels.<Image>.putdata(<list/ImagingCore>)             # Writes a flattened sequence of pixels.<Image>.paste(<Image>, (x, y))                  # Writes passed image to the image.<Image> = <Image>.filter(<Filter>)              # `<Filter> = ImageFilter.<name>([<args>])`<Image> = <Enhance>.enhance(<float>)            # `<Enhance> = ImageEnhance.<name>(<Image>)`<array> = np.array(<Image>)                     # Creates NumPy array from the image.<Image> = Image.fromarray(np.uint8(<array>))    # Use <array>.clip(0, 255) to clip the values.Modes'1' - 1-bit pixels, black and white, stored with one pixel per byte.'L' - 8-bit pixels, greyscale.'RGB' - 3x8-bit pixels, true color.'RGBA' - 4x8-bit pixels, true color with transparency mask.'HSV' - 3x8-bit pixels, Hue, Saturation, Value color space.ExamplesCreates a PNG image of a rainbow gradient:WIDTH, HEIGHT = 100, 100n_pixels = WIDTH * HEIGHThues = (255 * i/n_pixels for i in range(n_pixels))img = Image.new('HSV', (WIDTH, HEIGHT))img.putdata([(int(h), 255, 255) for h in hues])img.convert('RGB').save('test.png')Adds noise to a PNG image and displays it:from random import randintadd_noise = lambda value: max(0, min(255, value + randint(-20, 20)))img = Image.open('test.png').convert('HSV')img.putdata([(add_noise(h), s, v) for h, s, v in img.getdata()])img.show()Image Draw<ImageDraw> = ImageDraw.Draw(<Image>)           # Object for adding 2D graphics to the image.<ImageDraw>.point((x, y))                       # Draws a point. Truncates floats into ints.<ImageDraw>.line((x1, y1, x2, y2 [, ...]))      # To get anti-aliasing use Image's resize().<ImageDraw>.arc((x1, y1, x2, y2), deg1, deg2)   # Always draws in clockwise direction.<ImageDraw>.rectangle((x1, y1, x2, y2))         # To rotate use Image's rotate() and paste().<ImageDraw>.polygon((x1, y1, x2, y2, ...))      # Last point gets connected to the first.<ImageDraw>.ellipse((x1, y1, x2, y2))           # To rotate use Image's rotate() and paste().<ImageDraw>.text((x, y), text, font=<Font>)     # `<Font> = ImageFont.truetype(<path>, size)`Use 'fill=<color>' to set the primary color.Use 'width=<int>' to set the width of lines or contours.Use 'outline=<color>' to set the color of the contours.Color can be an int, tuple, '#rrggbb[aa]' string or a color name.AnimationCreates a GIF of a bouncing ball:# $ pip3 install imageiofrom PIL import Image, ImageDrawimport imageioWIDTH, HEIGHT, R = 126, 126, 10frames = []for velocity in range(1, 16):    y = sum(range(velocity))    frame = Image.new('L', (WIDTH, HEIGHT))    draw  = ImageDraw.Draw(frame)    draw.ellipse((WIDTH/2-R, y, WIDTH/2+R, y+R*2), fill='white')    frames.append(frame)frames += reversed(frames[1:-1])imageio.mimsave('test.gif', frames, duration=0.03)Audioimport wave<Wave_read>  = wave.open('<path>', 'rb')        # Opens the WAV file.framerate    = <Wave_read>.getframerate()       # Number of frames per second.nchannels    = <Wave_read>.getnchannels()       # Number of samples per frame.sampwidth    = <Wave_read>.getsampwidth()       # Sample size in bytes.nframes      = <Wave_read>.getnframes()         # Number of frames.<params>     = <Wave_read>.getparams()          # Immutable collection of above.<bytes>      = <Wave_read>.readframes(nframes)  # Returns next 'nframes' frames.<Wave_write> = wave.open('<path>', 'wb')        # Truncates existing file.<Wave_write>.setframerate(<int>)                # 44100 for CD, 48000 for video.<Wave_write>.setnchannels(<int>)                # 1 for mono, 2 for stereo.<Wave_write>.setsampwidth(<int>)                # 2 for CD quality sound.<Wave_write>.setparams(<params>)                # Sets all parameters.<Wave_write>.writeframes(<bytes>)               # Appends frames to the file.Bytes object contains a sequence of frames, each consisting of one or more samples.In a stereo signal, the first sample of a frame belongs to the left channel.Each sample consists of one or more bytes that, when converted to an integer, indicate the displacement of a speaker membrane at a given moment.If sample width is one byte, then the integer should be encoded unsigned.For all other sizes, the integer should be encoded signed with little-endian byte order.Sample Values+-----------+-----------+------+-----------+| sampwidth |    min    | zero |    max    |+-----------+-----------+------+-----------+|     1     |         0 |  128 |       255 ||     2     |    -32768 |    0 |     32767 ||     3     |  -8388608 |    0 |   8388607 |+-----------+-----------+------+-----------+Read Float Samples from WAV Filedef read_wav_file(filename):    def get_int(bytes_obj):        an_int = int.from_bytes(bytes_obj, 'little', signed=(sampwidth != 1))        return an_int - 128 * (sampwidth == 1)    with wave.open(filename, 'rb') as file:        sampwidth = file.getsampwidth()        frames = file.readframes(-1)    bytes_samples = (frames[i : i+sampwidth] for i in range(0, len(frames), sampwidth))    return [get_int(b) / pow(2, sampwidth * 8 - 1) for b in bytes_samples]Write Float Samples to WAV Filedef write_to_wav_file(filename, float_samples, nchannels=1, sampwidth=2, framerate=44100):    def get_bytes(a_float):        a_float = max(-1, min(1 - 2e-16, a_float))        a_float += sampwidth == 1        a_float *= pow(2, sampwidth * 8 - 1)        return int(a_float).to_bytes(sampwidth, 'little', signed=(sampwidth != 1))    with wave.open(filename, 'wb') as file:        file.setnchannels(nchannels)        file.setsampwidth(sampwidth)        file.setframerate(framerate)        file.writeframes(b''.join(get_bytes(f) for f in float_samples))ExamplesSaves a 440 Hz sine wave to a mono WAV file:from math import pi, sinsamples_f = (sin(i * 2 * pi * 440 / 44100) for i in range(100_000))write_to_wav_file('test.wav', samples_f)Adds noise to a mono WAV file:from random import randomadd_noise = lambda value: value + (random() - 0.5) * 0.03samples_f = (add_noise(f) for f in read_wav_file('test.wav'))write_to_wav_file('test.wav', samples_f)Plays a WAV file:# $ pip3 install simpleaudiofrom simpleaudio import play_bufferwith wave.open('test.wav', 'rb') as file:    p = file.getparams()    frames = file.readframes(-1)    play_buffer(frames, p.nchannels, p.sampwidth, p.framerate)Text to Speech# $ pip3 install pyttsx3import pyttsx3engine = pyttsx3.init()engine.say('Sally sells seashells by the seashore.')engine.runAndWait()SynthesizerPlays Popcorn by Gershon Kingsley:# $ pip3 install simpleaudioimport array, itertools as it, math, simpleaudioF  = 44100P1 = '71‚ô©,69‚ô™,,71‚ô©,66‚ô™,,62‚ô©,66‚ô™,,59‚ô©,,'P2 = '71‚ô©,73‚ô™,,74‚ô©,73‚ô™,,74‚ô™,,71‚ô™,,73‚ô©,71‚ô™,,73‚ô™,,69‚ô™,,71‚ô©,69‚ô™,,71‚ô™,,67‚ô™,,71‚ô©,,'get_pause   = lambda seconds: it.repeat(0, int(seconds * F))sin_f       = lambda i, hz: math.sin(i * 2 * math.pi * hz / F)get_wave    = lambda hz, seconds: (sin_f(i, hz) for i in range(int(seconds * F)))get_hz      = lambda key: 8.176 * 2 ** (int(key) / 12)parse_note  = lambda note: (get_hz(note[:2]), 1/4 if '‚ô©' in note else 1/8)get_samples = lambda note: get_wave(*parse_note(note)) if note else get_pause(1/8)samples_f   = it.chain.from_iterable(get_samples(n) for n in f'{P1},{P1},{P2}'.split(','))samples_i   = array.array('h', (int(f * 30000) for f in samples_f))simpleaudio.play_buffer(samples_i, 1, 2, F)Pygame# $ pip3 install pygameimport pygame as pgpg.init()screen = pg.display.set_mode((500, 500))rect = pg.Rect(240, 240, 20, 20)while not pg.event.get(pg.QUIT):    deltas = {pg.K_UP: (0, -20), pg.K_RIGHT: (20, 0), pg.K_DOWN: (0, 20), pg.K_LEFT: (-20, 0)}    for event in pg.event.get(pg.KEYDOWN):        dx, dy = deltas.get(event.key, (0, 0))        rect = rect.move((dx, dy))    screen.fill((0, 0, 0))    pg.draw.rect(screen, (255, 255, 255), rect)    pg.display.flip()RectangleObject for storing rectangular coordinates.<Rect> = pg.Rect(x, y, width, height)           # Floats get truncated into ints.<int>  = <Rect>.x/y/centerx/centery/‚Ä¶           # Top, right, bottom, left. Allows assignments.<tup.> = <Rect>.topleft/center/‚Ä¶                # Topright, bottomright, bottomleft. Same.<Rect> = <Rect>.move((delta_x, delta_y))        # Use move_ip() to move in-place.<bool> = <Rect>.collidepoint((x, y))            # Checks if rectangle contains the point.<bool> = <Rect>.colliderect(<Rect>)             # Checks if two rectangles overlap.<int>  = <Rect>.collidelist(<list_of_Rect>)     # Returns index of first colliding Rect or -1.<list> = <Rect>.collidelistall(<list_of_Rect>)  # Returns indexes of all colliding rectangles.SurfaceObject for representing images.<Surf> = pg.display.set_mode((width, height))   # Opens new window and returns its surface.<Surf> = pg.Surface((width, height))            # New RGB surface. RGBA if `flags=pg.SRCALPHA`.<Surf> = pg.image.load(<path/file>)             # Loads the image. Format depends on source.<Surf> = pg.surfarray.make_surface(<np_array>)  # Also `<np_arr> = surfarray.pixels3d(<Surf>)`.<Surf> = <Surf>.subsurface(<Rect>)              # Creates a new surface from the cutout.<Surf>.fill(color)                              # Tuple, Color('#rrggbb[aa]') or Color(<name>).<Surf>.set_at((x, y), color)                    # Updates pixel. Also <Surf>.get_at((x, y)).<Surf>.blit(<Surf>, (x, y))                     # Draws passed surface to the surface.from pygame.transform import scale, ...<Surf> = scale(<Surf>, (width, height))         # Returns scaled surface.<Surf> = rotate(<Surf>, anticlock_degrees)      # Returns rotated and scaled surface.<Surf> = flip(<Surf>, x_bool, y_bool)           # Returns flipped surface.from pygame.draw import line, ...line(<Surf>, color, (x1, y1), (x2, y2), width)  # Draws a line to the surface.arc(<Surf>, color, <Rect>, from_rad, to_rad)    # Also ellipse(<Surf>, color, <Rect>, width=0).rect(<Surf>, color, <Rect>, width=0)            # Also polygon(<Surf>, color, points, width=0).Font<Font> = pg.font.Font(<path/file>, size)        # Loads TTF file. Pass None for default font.<Surf> = <Font>.render(text, antialias, color)  # Background color can be specified at the end.Sound<Sound> = pg.mixer.Sound(<path/file/bytes>)     # Loads WAV file or array of signed shorts.<Sound>.play/stop()                             # Also <Sound>.set_volume(<float>).Basic Mario Brothers Exampleimport collections, dataclasses, enum, io, itertools as it, pygame as pg, urllib.requestfrom random import randintP = collections.namedtuple('P', 'x y')          # PositionD = enum.Enum('D', 'n e s w')                   # DirectionW, H, MAX_S = 50, 50, P(5, 10)                  # Width, Height, Max speeddef main():    def get_screen():        pg.init()        return pg.display.set_mode((W*16, H*16))    def get_images():        url = 'https://gto76.github.io/python-cheatsheet/web/mario_bros.png'        img = pg.image.load(io.BytesIO(urllib.request.urlopen(url).read()))        return [img.subsurface(get_rect(x, 0)) for x in range(img.get_width() // 16)]    def get_mario():        Mario = dataclasses.make_dataclass('Mario', 'rect spd facing_left frame_cycle'.split())        return Mario(get_rect(1, 1), P(0, 0), False, it.cycle(range(3)))    def get_tiles():        border = [(x, y) for x in range(W) for y in range(H) if x in [0, W-1] or y in [0, H-1]]        platforms = [(randint(1, W-2), randint(2, H-2)) for _ in range(W*H // 10)]        return [get_rect(x, y) for x, y in border + platforms]    def get_rect(x, y):        return pg.Rect(x*16, y*16, 16, 16)    run(get_screen(), get_images(), get_mario(), get_tiles())def run(screen, images, mario, tiles):    clock = pg.time.Clock()    pressed = set()    while not pg.event.get(pg.QUIT) and clock.tick(28):        keys = {pg.K_UP: D.n, pg.K_RIGHT: D.e, pg.K_DOWN: D.s, pg.K_LEFT: D.w}        pressed |= {keys.get(e.key) for e in pg.event.get(pg.KEYDOWN)}        pressed -= {keys.get(e.key) for e in pg.event.get(pg.KEYUP)}        update_speed(mario, tiles, pressed)        update_position(mario, tiles)        draw(screen, images, mario, tiles, pressed)def update_speed(mario, tiles, pressed):    x, y = mario.spd    x += 2 * ((D.e in pressed) - (D.w in pressed))    x += (x < 0) - (x > 0)    y += 1 if D.s not in get_boundaries(mario.rect, tiles) else (D.n in pressed) * -10    mario.spd = P(x=max(-MAX_S.x, min(MAX_S.x, x)), y=max(-MAX_S.y, min(MAX_S.y, y)))def update_position(mario, tiles):    x, y = mario.rect.topleft    n_steps = max(abs(s) for s in mario.spd)    for _ in range(n_steps):        mario.spd = stop_on_collision(mario.spd, get_boundaries(mario.rect, tiles))        mario.rect.topleft = x, y = x + (mario.spd.x / n_steps), y + (mario.spd.y / n_steps)def get_boundaries(rect, tiles):    deltas = {D.n: P(0, -1), D.e: P(1, 0), D.s: P(0, 1), D.w: P(-1, 0)}    return {d for d, delta in deltas.items() if rect.move(delta).collidelist(tiles) != -1}def stop_on_collision(spd, bounds):    return P(x=0 if (D.w in bounds and spd.x < 0) or (D.e in bounds and spd.x > 0) else spd.x,             y=0 if (D.n in bounds and spd.y < 0) or (D.s in bounds and spd.y > 0) else spd.y)def draw(screen, images, mario, tiles, pressed):    def get_marios_image_index():        if D.s not in get_boundaries(mario.rect, tiles):            return 4        return next(mario.frame_cycle) if {D.w, D.e} & pressed else 6    screen.fill((85, 168, 255))    mario.facing_left = (D.w in pressed) if {D.w, D.e} & pressed else mario.facing_left    screen.blit(images[get_marios_image_index() + mario.facing_left * 9], mario.rect)    for t in tiles:        screen.blit(images[18 if t.x in [0, (W-1)*16] or t.y in [0, (H-1)*16] else 19], t)    pg.display.flip()if __name__ == '__main__':    main()Pandas# $ pip3 install pandas matplotlibimport pandas as pd, matplotlib.pyplot as pltSeriesOrdered dictionary with a name.>>> pd.Series([1, 2], index=['x', 'y'], name='a')x    1y    2Name: a, dtype: int64<Sr> = pd.Series(<list>)                       # Assigns RangeIndex starting at 0.<Sr> = pd.Series(<dict>)                       # Takes dictionary's keys for index.<Sr> = pd.Series(<dict/Series>, index=<list>)  # Only keeps items with keys specified in index.<el> = <Sr>.loc[key]                           # Or: <Sr>.iloc[index]<Sr> = <Sr>.loc[keys]                          # Or: <Sr>.iloc[indexes]<Sr> = <Sr>.loc[from_key : to_key_inclusive]   # Or: <Sr>.iloc[from_i : to_i_exclusive]<el> = <Sr>[key/index]                         # Or: <Sr>.key<Sr> = <Sr>[keys/indexes]                      # Or: <Sr>[<keys_slice/slice>]<Sr> = <Sr>[bools]                             # Or: <Sr>.loc/iloc[bools]<Sr> = <Sr> ><== <el/Sr>                       # Returns a Series of bools.<Sr> = <Sr> +-*/ <el/Sr>                       # Items with non-matching keys get value NaN.<Sr> = pd.concat(<coll_of_Sr>)                 # Concats multiple Series into one long Series.<Sr> = <Sr>.combine_first(<Sr>)                # Adds items that are not yet present.<Sr>.update(<Sr>)                              # Updates items that are already present.<Sr>.plot.line/area/bar/pie/hist()             # Generates a Matplotlib plot.plt.show()                                     # Displays the plot. Also plt.savefig(<path>).Series ‚Äî Aggregate, Transform, Map:<el> = <Sr>.sum/max/mean/idxmax/all()          # Or: <Sr>.agg(lambda <Sr>: <el>)<Sr> = <Sr>.rank/diff/cumsum/ffill/interpl()   # Or: <Sr>.agg/transform(lambda <Sr>: <Sr>)<Sr> = <Sr>.fillna(<el>)                       # Or: <Sr>.agg/transform/map(lambda <el>: <el>)>>> sr = pd.Series([1, 2], index=['x', 'y'])x    1y    2+---------------+-------------+-------------+---------------+|               |    'sum'    |   ['sum']   | {'s': 'sum'}  |+---------------+-------------+-------------+---------------+| sr.apply(‚Ä¶)   |      3      |    sum  3   |     s  3      || sr.agg(‚Ä¶)     |             |             |               |+---------------+-------------+-------------+---------------++---------------+-------------+-------------+---------------+|               |    'rank'   |   ['rank']  | {'r': 'rank'} |+---------------+-------------+-------------+---------------+| sr.apply(‚Ä¶)   |             |      rank   |               || sr.agg(‚Ä¶)     |     x  1    |   x     1   |    r  x  1    ||               |     y  2    |   y     2   |       y  2    |+---------------+-------------+-------------+---------------+Keys/indexes/bools can't be tuples because 'obj[x, y]' is converted to 'obj[(x, y)]'!Methods ffill(), interpolate(), fillna() and dropna() accept 'inplace=True'.Last result has a hierarchical index. Use '<Sr>[key_1, key_2]' to get its values.DataFrameTable with labeled rows and columns.>>> pd.DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])   x  ya  1  2b  3  4<DF>    = pd.DataFrame(<list_of_rows>)         # Rows can be either lists, dicts or series.<DF>    = pd.DataFrame(<dict_of_columns>)      # Columns can be either lists, dicts or series.<el>    = <DF>.loc[row_key, column_key]        # Or: <DF>.iloc[row_index, column_index]<Sr/DF> = <DF>.loc[row_key/s]                  # Or: <DF>.iloc[row_index/es]<Sr/DF> = <DF>.loc[:, column_key/s]            # Or: <DF>.iloc[:, column_index/es]<DF>    = <DF>.loc[row_bools, column_bools]    # Or: <DF>.iloc[row_bools, column_bools]<Sr/DF> = <DF>[column_key/s]                   # Or: <DF>.column_key<DF>    = <DF>[row_bools]                      # Keeps rows as specified by bools.<DF>    = <DF>[<DF_of_bools>]                  # Assigns NaN to False values.<DF>    = <DF> ><== <el/Sr/DF>                 # Returns DF of bools. Sr is treated as a row.<DF>    = <DF> +-*/ <el/Sr/DF>                 # Items with non-matching keys get value NaN.<DF>    = <DF>.set_index(column_key)           # Replaces row keys with values from a column.<DF>    = <DF>.reset_index(drop=False)         # Drops or moves row keys to column named index.<DF>    = <DF>.sort_index(ascending=True)      # Sorts rows by row keys. Use `axis=1` for cols.<DF>    = <DF>.sort_values(column_key/s)       # Sorts rows by the passed column/s. Same.DataFrame ‚Äî Merge, Join, Concat:>>> l = pd.DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])   x  ya  1  2b  3  4>>> r = pd.DataFrame([[4, 5], [6, 7]], index=['b', 'c'], columns=['y', 'z'])   y  zb  4  5c  6  7+------------------------+---------------+------------+------------+--------------------------+|                        |    'outer'    |   'inner'  |   'left'   |       Description        |+------------------------+---------------+------------+------------+--------------------------+| l.merge(r, on='y',     |    x   y   z  | x   y   z  | x   y   z  | Merges on column if 'on' ||            how=‚Ä¶)      | 0  1   2   .  | 3   4   5  | 1   2   .  | or 'left/right_on' are   ||                        | 1  3   4   5  |            | 3   4   5  | set, else on shared cols.||                        | 2  .   6   7  |            |            | Uses 'inner' by default. |+------------------------+---------------+------------+------------+--------------------------+| l.join(r, lsuffix='l', |    x yl yr  z |            | x yl yr  z | Merges on row keys.      ||           rsuffix='r', | a  1  2  .  . | x yl yr  z | 1  2  .  . | Uses 'left' by default.  ||           how=‚Ä¶)       | b  3  4  4  5 | 3  4  4  5 | 3  4  4  5 | If r is a Series, it is  ||                        | c  .  .  6  7 |            |            | treated as a column.     |+------------------------+---------------+------------+------------+--------------------------+| pd.concat([l, r],      |    x   y   z  |     y      |            | Adds rows at the bottom. ||           axis=0,      | a  1   2   .  |     2      |            | Uses 'outer' by default. ||           join=‚Ä¶)      | b  3   4   .  |     4      |            | A Series is treated as a ||                        | b  .   4   5  |     4      |            | column. To add a row use ||                        | c  .   6   7  |     6      |            | pd.concat([l, DF([sr])]).|+------------------------+---------------+------------+------------+--------------------------+| pd.concat([l, r],      |    x  y  y  z |            |            | Adds columns at the      ||           axis=1,      | a  1  2  .  . | x  y  y  z |            | right end. Uses 'outer'  ||           join=‚Ä¶)      | b  3  4  4  5 | 3  4  4  5 |            | by default. A Series is  ||                        | c  .  .  6  7 |            |            | treated as a column.     |+------------------------+---------------+------------+------------+--------------------------+| l.combine_first(r)     |    x   y   z  |            |            | Adds missing rows and    ||                        | a  1   2   .  |            |            | columns. Also updates    ||                        | b  3   4   5  |            |            | items that contain NaN.  ||                        | c  .   6   7  |            |            | R must be a DataFrame.   |+------------------------+---------------+------------+------------+--------------------------+DataFrame ‚Äî Aggregate, Transform, Map:<Sr> = <DF>.sum/max/mean/idxmax/all()          # Or: <DF>.apply/agg(lambda <Sr>: <el>)<DF> = <DF>.rank/diff/cumsum/ffill/interpl()   # Or: <DF>.apply/agg/transfrm(lambda <Sr>: <Sr>)<DF> = <DF>.fillna(<el>)                       # Or: <DF>.applymap(lambda <el>: <el>)All operations operate on columns by default. Pass 'axis=1' to process the rows instead.>>> df = pd.DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])   x  ya  1  2b  3  4+-----------------+-------------+-------------+---------------+|                 |    'sum'    |   ['sum']   | {'x': 'sum'}  |+-----------------+-------------+-------------+---------------+| df.apply(‚Ä¶)     |             |       x  y  |               || df.agg(‚Ä¶)       |     x  4    |  sum  4  6  |     x  4      ||                 |     y  6    |             |               |+-----------------+-------------+-------------+---------------++-----------------+-------------+-------------+---------------+|                 |    'rank'   |   ['rank']  | {'x': 'rank'} |+-----------------+-------------+-------------+---------------+| df.apply(‚Ä¶)     |      x  y   |      x    y |        x      || df.agg(‚Ä¶)       |   a  1  1   |   rank rank |     a  1      || df.transform(‚Ä¶) |   b  2  2   | a    1    1 |     b  2      ||                 |             | b    2    2 |               |+-----------------+-------------+-------------+---------------+Use '<DF>[col_key_1, col_key_2][row_key]' to get the fifth result's values.DataFrame ‚Äî Plot, Encode, Decode:<DF>.plot.line/area/bar/hist/scatter/box()     # Also: `x=column_key, y=column_key/s`.plt.show()                                     # Displays the plot. Also plt.savefig(<path>).<DF> = pd.read_json/html('<str/path/url>')     # Run `$ pip3 install beautifulsoup4 lxml`.<DF> = pd.read_csv/pickle/excel('<path/url>')  # Use `sheet_name=None` to get all Excel sheets.<DF> = pd.read_sql('<table/query>', <conn.>)   # Accepts SQLite3 or SQLAlchemy connection.<DF> = pd.read_clipboard()                     # Reads a copied table from the clipboard.<dict> = <DF>.to_dict(['d/l/s/‚Ä¶'])             # Returns columns as dicts, lists or series.<str>  = <DF>.to_json/html/csv([<path>])       # Also to_markdown/latex([<path>]).<DF>.to_pickle/excel(<path>)                   # Run `$ pip3 install \""pandas[excel]\"" odfpy`.<DF>.to_sql('<table_name>', <connection>)      # Accepts SQLite3 or SQLAlchemy connection.GroupByObject that groups together rows of a dataframe based on the value of the passed column.>>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 6]], list('abc'), list('xyz'))>>> df.groupby('z').get_group(6)   x  y  zb  4  5  6c  7  8  6<GB> = <DF>.groupby(column_key/s)              # Splits DF into groups based on passed column.<DF> = <GB>.apply(<func>)                      # Maps each group. Func can return DF, Sr or el.<GB> = <GB>[column_key]                        # Single column GB. All operations return a Sr.GroupBy ‚Äî Aggregate, Transform, Map:<DF> = <GB>.sum/max/mean/idxmax/all()          # Or: <GB>.agg(lambda <Sr>: <el>)<DF> = <GB>.rank/diff/cumsum/ffill()           # Or: <GB>.transform(lambda <Sr>: <Sr>)<DF> = <GB>.fillna(<el>)                       # Or: <GB>.transform(lambda <Sr>: <Sr>)>>> gb = df.groupby('z')      x  y  z3: a  1  2  36: b  4  5  6   c  7  8  6+-----------------+-------------+-------------+-------------+---------------+|                 |    'sum'    |    'rank'   |   ['rank']  | {'x': 'rank'} |+-----------------+-------------+-------------+-------------+---------------+| gb.agg(‚Ä¶)       |      x   y  |      x  y   |      x    y |        x      ||                 |  z          |   a  1  1   |   rank rank |     a  1      ||                 |  3   1   2  |   b  1  1   | a    1    1 |     b  1      ||                 |  6  11  13  |   c  2  2   | b    1    1 |     c  2      ||                 |             |             | c    2    2 |               |+-----------------+-------------+-------------+-------------+---------------+| gb.transform(‚Ä¶) |      x   y  |      x  y   |             |               ||                 |  a   1   2  |   a  1  1   |             |               ||                 |  b  11  13  |   b  1  1   |             |               ||                 |  c  11  13  |   c  2  2   |             |               |+-----------------+-------------+-------------+-------------+---------------+RollingObject for rolling window calculations.<RSr/RDF/RGB> = <Sr/DF/GB>.rolling(win_size)   # Also: `min_periods=None, center=False`.<RSr/RDF/RGB> = <RDF/RGB>[column_key/s]        # Or: <RDF/RGB>.column_key<Sr/DF>       = <R>.mean/sum/max()             # Or: <R>.apply/agg(<agg_func/str>)Plotly# $ pip3 install plotly kaleidofrom plotly.express import line<Figure> = line(<DF>, x=<col_name>, y=<col_name>)           # Or: line(x=<list>, y=<list>)<Figure>.update_layout(margin=dict(t=0, r=0, b=0, l=0), ‚Ä¶)  # `paper_bgcolor='rgb(0, 0, 0)'`.<Figure>.write_html/json/image('<path>')                    # Also <Figure>.show().Displays a line chart of total coronavirus deaths per million grouped by continent:covid = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv',                    usecols=['iso_code', 'date', 'total_deaths', 'population'])continents = pd.read_csv('https://gist.githubusercontent.com/stevewithington/20a69c0b6d2ff'                         '846ea5d35e5fc47f26c/raw/country-and-continent-codes-list-csv.csv',                         usecols=['Three_Letter_Country_Code', 'Continent_Name'])df = pd.merge(covid, continents, left_on='iso_code', right_on='Three_Letter_Country_Code')df = df.groupby(['Continent_Name', 'date']).sum().reset_index()df['Total Deaths per Million'] = df.total_deaths * 1e6 / df.populationdf = df[df.date > '2020-03-14']df = df.rename({'date': 'Date', 'Continent_Name': 'Continent'}, axis='columns')line(df, x='Date', y='Total Deaths per Million', color='Continent').show()Displays a multi-axis line chart of total coronavirus cases and changes in prices of Bitcoin, Dow Jones and gold:import pandas as pd, plotly.graph_objects as godef main():    display_data(wrangle_data(*scrape_data()))def scrape_data():    def scrape_covid():        url = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'        df = pd.read_csv(url, usecols=['location', 'date', 'total_cases'])        return df[df.location == 'World'].set_index('date').total_cases    def scrape_yahoo(slug):        url = (f'https://query1.finance.yahoo.com/v7/finance/download/{slug}?'               'period1=1579651200&period2=9999999999&interval=1d&events=history')        df = pd.read_csv(url, usecols=['Date', 'Close'])        return df.set_index('Date').Close    out = scrape_covid(), scrape_yahoo('BTC-USD'), scrape_yahoo('GC=F'), scrape_yahoo('^DJI')    return map(pd.Series.rename, out, ['Total Cases', 'Bitcoin', 'Gold', 'Dow Jones'])def wrangle_data(covid, bitcoin, gold, dow):    df = pd.concat([bitcoin, gold, dow], axis=1)  # Joins columns on dates.    df = df.sort_index().interpolate()            # Sorts by date and interpolates NaN-s.    df = df.loc['2020-02-23':]                    # Discards rows before '2020-02-23'.    df = (df / df.iloc[0]) * 100                  # Calculates percentages relative to day 1.    df = df.join(covid)                           # Adds column with covid cases.    return df.sort_values(df.index[-1], axis=1)   # Sorts columns by last day's value.def display_data(df):    figure = go.Figure()    for col_name in reversed(df.columns):        yaxis = 'y1' if col_name == 'Total Cases' else 'y2'        trace = go.Scatter(x=df.index, y=df[col_name], name=col_name, yaxis=yaxis)        figure.add_trace(trace)    figure.update_layout(        yaxis1=dict(title='Total Cases', rangemode='tozero'),        yaxis2=dict(title='%', rangemode='tozero', overlaying='y', side='right'),        legend=dict(x=1.1),        height=450    )    figure.show()if __name__ == '__main__':    main()PySimpleGUI# $ pip3 install PySimpleGUIimport PySimpleGUI as sglayout = [[sg.Text(\""What's your name?\"")], [sg.Input()], [sg.Button('Ok')]]window = sg.Window('Window Title', layout)event, values = window.read()print(f'Hello {values[0]}!' if event == 'Ok' else '')AppendixCythonLibrary that compiles Python code into C.# $ pip3 install cythonimport pyximport; pyximport.install()import <cython_script><cython_script>.main()Definitions:All 'cdef' definitions are optional, but they contribute to the speed-up.Script needs to be saved with a 'pyx' extension.cdef <ctype> <var_name> = <el>cdef <ctype>[n_elements] <var_name> = [<el>, <el>, ...]cdef <ctype/void> <func_name>(<ctype> <arg_name>): ...cdef class <class_name>:    cdef public <ctype> <attr_name>    def __init__(self, <ctype> <arg_name>):        self.<attr_name> = <arg_name>cdef enum <enum_name>: <member_name>, <member_name>, ...Virtual EnvironmentsSystem for installing libraries directly into project's directory.$ python3 -m venv <name>      # Creates virtual environment in current directory.$ source <name>/bin/activate  # Activates venv. On Windows run `<name>\\Scripts\\activate`.$ pip3 install <library>      # Installs the library into active environment.$ python3 <path>              # Runs the script in active environment. Also `./<path>`.$ deactivate                  # Deactivates virtual environment.Basic Script Template#!/usr/bin/env python3## Usage: .py#from sys import argv, exitfrom collections import defaultdict, namedtuplefrom dataclasses import make_dataclassfrom enum import Enumimport functools as ft, itertools as it, operator as op, redef main():    pass#####  UTIL#def read_file(filename):    with open(filename, encoding='utf-8') as file:        return file.readlines()if __name__ == '__main__':    main()IndexOnly available in the PDF.Ctrl+F / ‚åòF is usually sufficient.Searching '#<title>' on the webpage will limit the search to the titles."
24,facebookresearch/fairseq,https://github.com/facebookresearch/fairseq/blob/main/README.md,Python,"                  Fairseq(-py) is a sequence modeling toolkit that allows researchers anddevelopers to train custom models for translation, summarization, languagemodeling and other text generation tasks.We provide reference implementations of various sequence modeling papers:List of implemented papersConvolutional Neural Networks (CNN)Language Modeling with Gated Convolutional Networks (Dauphin et al., 2017)Convolutional Sequence to Sequence Learning (Gehring et al., 2017)Classical Structured Prediction Losses for Sequence to Sequence Learning (Edunov et al., 2018)Hierarchical Neural Story Generation (Fan et al., 2018)wav2vec: Unsupervised Pre-training for Speech Recognition (Schneider et al., 2019)LightConv and DynamicConv modelsPay Less Attention with Lightweight and Dynamic Convolutions (Wu et al., 2019)Long Short-Term Memory (LSTM) networksEffective Approaches to Attention-based Neural Machine Translation (Luong et al., 2015)Transformer (self-attention) networksAttention Is All You Need (Vaswani et al., 2017)Scaling Neural Machine Translation (Ott et al., 2018)Understanding Back-Translation at Scale (Edunov et al., 2018)Adaptive Input Representations for Neural Language Modeling (Baevski and Auli, 2018)Lexically constrained decoding with dynamic beam allocation (Post & Vilar, 2018)Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context (Dai et al., 2019)Adaptive Attention Span in Transformers (Sukhbaatar et al., 2019)Mixture Models for Diverse Machine Translation: Tricks of the Trade (Shen et al., 2019)RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al., 2019)Facebook FAIR's WMT19 News Translation Task Submission (Ng et al., 2019)Jointly Learning to Align and Translate with Transformer Models (Garg et al., 2019)Multilingual Denoising Pre-training for Neural Machine Translation (Liu et at., 2020)Neural Machine Translation with Byte-Level Subwords (Wang et al., 2020)Unsupervised Quality Estimation for Neural Machine Translation (Fomicheva et al., 2020)wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations (Baevski et al., 2020)Generating Medical Reports from Patient-Doctor Conversations Using Sequence-to-Sequence Models (Enarvi et al., 2020)Linformer: Self-Attention with Linear Complexity (Wang et al., 2020)Cross-lingual Retrieval for Iterative Self-Supervised Training (Tran et al., 2020)Deep Transformers with Latent Depth (Li et al., 2020)Unsupervised Cross-lingual Representation Learning for Speech Recognition (Conneau et al., 2020)Self-training and Pre-training are Complementary for Speech Recognition (Xu et al., 2020)Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training (Hsu, et al., 2021)Unsupervised Speech Recognition (Baevski, et al., 2021)Simple and Effective Zero-shot Cross-lingual Phoneme Recognition (Xu et al., 2021)VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding (Xu et. al., 2021)VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding (Xu et. al., 2021)NormFormer: Improved Transformer Pretraining with Extra Normalization (Shleifer et. al, 2021)Non-autoregressive TransformersNon-Autoregressive Neural Machine Translation (Gu et al., 2017)Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement (Lee et al. 2018)Insertion Transformer: Flexible Sequence Generation via Insertion Operations (Stern et al. 2019)Mask-Predict: Parallel Decoding of Conditional Masked Language Models (Ghazvininejad et al., 2019)Levenshtein Transformer (Gu et al., 2019)FinetuningBetter Fine-Tuning by Reducing Representational Collapse (Aghajanyan et al. 2020)What's New:May 2023 Released models for Scaling Speech Technology to 1,000+ Languages  (Pratap, et al., 2023)June 2022 Released code for wav2vec-U 2.0 from Towards End-to-end Unsupervised Speech Recognition (Liu, et al., 2022)May 2022 Integration with xFormersDecember 2021 Released Direct speech-to-speech translation codeOctober 2021 Released VideoCLIP and VLM modelsOctober 2021 Released multilingual finetuned XLSR-53 modelSeptember 2021 master branch renamed to main.July 2021 Released DrNMT codeJuly 2021 Released Robust wav2vec 2.0 modelJune 2021 Released XLMR-XL and XLMR-XXL modelsMay 2021 Released Unsupervised Speech Recognition codeMarch 2021 Added full parameter and optimizer state sharding + CPU offloadingFebruary 2021 Added LASER training codeDecember 2020: Added Adaptive Attention Span codeDecember 2020: GottBERT model and code releasedNovember 2020: Adopted the Hydra configuration frameworksee documentation explaining how to use it for new and existing projectsNovember 2020: fairseq 0.10.0 releasedOctober 2020: Added R3F/R4F (Better Fine-Tuning) codeOctober 2020: Deep Transformer with Latent Depth code releasedOctober 2020: Added CRISS models and codePrevious updatesSeptember 2020: Added Linformer codeSeptember 2020: Added pointer-generator networksAugust 2020: Added lexically constrained decodingAugust 2020: wav2vec2 models and code releasedJuly 2020: Unsupervised Quality Estimation code releasedMay 2020: Follow fairseq on TwitterApril 2020: Monotonic Multihead Attention code releasedApril 2020: Quant-Noise code releasedApril 2020: Initial model parallel support and 11B parameters unidirectional LM releasedMarch 2020: Byte-level BPE code releasedFebruary 2020: mBART model and code releasedFebruary 2020: Added tutorial for back-translationDecember 2019: fairseq 0.9.0 releasedNovember 2019: VizSeq released (a visual analysis toolkit for evaluating fairseq models)November 2019: CamemBERT model and code releasedNovember 2019: BART model and code releasedNovember 2019: XLM-R models and code releasedSeptember 2019: Nonautoregressive translation code releasedAugust 2019: WMT'19 models releasedJuly 2019: fairseq relicensed under MIT licenseJuly 2019: RoBERTa models and code releasedJune 2019: wav2vec models and code releasedFeatures:multi-GPU training on one machine or across multiple machines (data and model parallel)fast generation on both CPU and GPU with multiple search algorithms implemented:beam searchDiverse Beam Search (Vijayakumar et al., 2016)sampling (unconstrained, top-k and top-p/nucleus)lexically constrained decoding (Post & Vilar, 2018)gradient accumulation enables training with large mini-batches even on a single GPUmixed precision training (trains faster with less GPU memory on NVIDIA tensor cores)extensible: easily register new models, criterions, tasks, optimizers and learning rate schedulersflexible configuration based on Hydra allowing a combination of code, command-line and file based configurationfull parameter and optimizer state shardingoffloading parameters to CPUWe also provide pre-trained models for translation and language modelingwith a convenient torch.hub interface:en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model')en2de.translate('Hello world', beam=5)# 'Hallo Welt'See the PyTorch Hub tutorials for translationand RoBERTa for more examples.Requirements and InstallationPyTorch version >= 1.10.0Python version >= 3.8For training new models, you'll also need an NVIDIA GPU and NCCLTo install fairseq and develop locally:git clone https://github.com/pytorch/fairseqcd fairseqpip install --editable ./# on MacOS:# CFLAGS=\""-stdlib=libc++\"" pip install --editable ./# to install the latest stable release (0.10.x)# pip install fairseqFor faster training install NVIDIA's apex library:git clone https://github.com/NVIDIA/apexcd apexpip install -v --no-cache-dir --global-option=\""--cpp_ext\"" --global-option=\""--cuda_ext\"" \\  --global-option=\""--deprecated_fused_adam\"" --global-option=\""--xentropy\"" \\  --global-option=\""--fast_multihead_attn\"" ./For large datasets install PyArrow: pip install pyarrowIf you use Docker make sure to increase the shared memory size either with --ipc=host or --shm-sizeas command line options to nvidia-docker run .Getting StartedThe full documentation contains instructionsfor getting started, training new models and extending fairseq with new modeltypes and tasks.Pre-trained models and examplesWe provide pre-trained models and pre-processed, binarized test sets for several tasks listed below,as well as example training and evaluation commands.Translation: convolutional and transformer models are availableLanguage Modeling: convolutional and transformer models are availableWe also have more detailed READMEs to reproduce results from specific papers:XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale (Babu et al., 2021)Cross-lingual Retrieval for Iterative Self-Supervised Training (Tran et al., 2020)wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations (Baevski et al., 2020)Unsupervised Quality Estimation for Neural Machine Translation (Fomicheva et al., 2020)Training with Quantization Noise for Extreme Model Compression ({Fan*, Stock*} et al., 2020)Neural Machine Translation with Byte-Level Subwords (Wang et al., 2020)Multilingual Denoising Pre-training for Neural Machine Translation (Liu et at., 2020)Reducing Transformer Depth on Demand with Structured Dropout (Fan et al., 2019)Jointly Learning to Align and Translate with Transformer Models (Garg et al., 2019)Levenshtein Transformer (Gu et al., 2019)Facebook FAIR's WMT19 News Translation Task Submission (Ng et al., 2019)RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al., 2019)wav2vec: Unsupervised Pre-training for Speech Recognition (Schneider et al., 2019)Mixture Models for Diverse Machine Translation: Tricks of the Trade (Shen et al., 2019)Pay Less Attention with Lightweight and Dynamic Convolutions (Wu et al., 2019)Understanding Back-Translation at Scale (Edunov et al., 2018)Classical Structured Prediction Losses for Sequence to Sequence Learning (Edunov et al., 2018)Hierarchical Neural Story Generation (Fan et al., 2018)Scaling Neural Machine Translation (Ott et al., 2018)Convolutional Sequence to Sequence Learning (Gehring et al., 2017)Language Modeling with Gated Convolutional Networks (Dauphin et al., 2017)Join the fairseq communityTwitter: https://twitter.com/fairseqFacebook page: https://www.facebook.com/groups/fairseq.usersGoogle group: https://groups.google.com/forum/#!forum/fairseq-usersLicensefairseq(-py) is MIT-licensed.The license applies to the pre-trained models as well.CitationPlease cite as:@inproceedings{ott2019fairseq,  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},  year = {2019},}"
25,Jack-Cherish/python-spider,https://github.com/Jack-Cherish/python-spider/blob/master/README.md,Python,Ê≥®Ôºö2020Âπ¥ÊúÄÊñ∞ËøûËΩΩÊïôÁ®ãËØ∑ÁßªÊ≠•ÔºöPython Spider 2020Python SpiderÂéüÂàõÊñáÁ´†ÊØèÂë®ÊúÄÂ∞ë‰∏§ÁØáÔºåÂêéÁª≠ÊúÄÊñ∞ÊñáÁ´†‰ºöÂú®„ÄêÂÖ¨‰ºóÂè∑„ÄëÈ¶ñÂèëÔºåËßÜÈ¢ë„ÄêBÁ´ô„ÄëÈ¶ñÂèëÔºåÂ§ßÂÆ∂ÂèØ‰ª•Âä†Êàë„ÄêÂæÆ‰ø°„ÄëËøõ‰∫§ÊµÅÁæ§ÔºåÊäÄÊúØ‰∫§ÊµÅÊàñÊèêÊÑèËßÅÈÉΩÂèØ‰ª•ÔºåÊ¨¢ËøéStarÔºÅ              Â£∞Êòé‰ª£Á†Å„ÄÅÊïôÁ®ã‰ªÖÈôê‰∫éÂ≠¶‰π†‰∫§ÊµÅÔºåËØ∑ÂãøÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÁî®ÈÄîÔºÅÁõÆÂΩïÁà¨Ëô´Â∞èÂ∑•ÂÖ∑Êñá‰ª∂‰∏ãËΩΩÂ∞èÂä©ÊâãÁà¨Ëô´ÂÆûÊàòÁ¨îË∂£ÁúãÂ∞èËØ¥‰∏ãËΩΩÁôæÂ∫¶ÊñáÂ∫ìÂÖçË¥πÊñáÁ´†‰∏ãËΩΩÂä©Êâã_rev1ÁôæÂ∫¶ÊñáÂ∫ìÂÖçË¥πÊñáÁ´†‰∏ãËΩΩÂä©Êâã_rev2„ÄäÂ∏ÖÂïä„ÄãÁΩëÂ∏ÖÂì•ÂõæÁâá‰∏ãËΩΩÊûÑÂª∫‰ª£ÁêÜIPÊ±†„ÄäÁÅ´ÂΩ±ÂøçËÄÖ„ÄãÊº´Áîª‰∏ãËΩΩË¥¢Âä°Êä•Ë°®‰∏ãËΩΩÂ∞èÂä©Êâã‰∏ÄÂ∞èÊó∂ÂÖ•Èó®ÁΩëÁªúÁà¨Ëô´ÊäñÈü≥AppËßÜÈ¢ë‰∏ãËΩΩGEETESTÈ™åËØÅÁ†ÅËØÜÂà´12306Êä¢Á•®Â∞èÂä©ÊâãÁôæ‰∏áËã±ÈõÑÁ≠îÈ¢òËæÖÂä©Á≥ªÁªüÁΩëÊòì‰∫ëÈü≥‰πêÂÖçË¥πÈü≥‰πêÊâπÈáè‰∏ãËΩΩBÁ´ôÂÖçË¥πËßÜÈ¢ëÂíåÂºπÂπïÊâπÈáè‰∏ãËΩΩ‰∫¨‰∏úÂïÜÂìÅÊôíÂçïÂõæ‰∏ãËΩΩÊ≠£ÊñπÊïôÂä°ÁÆ°ÁêÜÁ≥ªÁªü‰∏™‰∫∫‰ø°ÊÅØÊü•ËØ¢ÂÖ∂ÂÆÉÁà¨Ëô´Â∞èÂ∑•ÂÖ∑downloader.py:Êñá‰ª∂‰∏ãËΩΩÂ∞èÂä©Êâã‰∏Ä‰∏™ÂèØ‰ª•Áî®‰∫é‰∏ãËΩΩÂõæÁâá„ÄÅËßÜÈ¢ë„ÄÅÊñá‰ª∂ÁöÑÂ∞èÂ∑•ÂÖ∑ÔºåÊúâ‰∏ãËΩΩËøõÂ∫¶ÊòæÁ§∫ÂäüËÉΩ„ÄÇÁ®çÂä†‰øÆÊîπÂç≥ÂèØÊ∑ªÂä†Âà∞Ëá™Â∑±ÁöÑÁà¨Ëô´‰∏≠„ÄÇÂä®ÊÄÅÁ§∫ÊÑèÂõæÔºöÁà¨Ëô´ÂÆûÊàòbiqukan.py:„ÄäÁ¨îË∂£Áúã„ÄãÁõóÁâàÂ∞èËØ¥ÁΩëÁ´ôÔºåÁà¨ÂèñÂ∞èËØ¥Â∑•ÂÖ∑Á¨¨‰∏âÊñπ‰æùËµñÂ∫ìÂÆâË£ÖÔºö pip3 install beautifulsoup4‰ΩøÁî®ÊñπÊ≥ïÔºö python biqukan.pybaiduwenku.py: ÁôæÂ∫¶ÊñáÂ∫ìwordÊñáÁ´†Áà¨ÂèñÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/72331737‰ª£Á†Å‰∏çÂÆåÂñÑÔºåÊ≤°ÊúâËøõË°åÊâìÂåÖÔºå‰∏çÂÖ∑ÈÄöÁî®ÊÄßÔºåÁ∫ØÂ±ûÂ®±‰πê„ÄÇshuaia.py: Áà¨Âèñ„ÄäÂ∏ÖÂïä„ÄãÁΩëÔºåÂ∏ÖÂì•ÂõæÁâá„ÄäÂ∏ÖÂïä„ÄãÁΩëURLÔºöhttp://www.shuaia.net/index.htmlÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/72597755Á¨¨‰∏âÊñπ‰æùËµñÂ∫ìÂÆâË£ÖÔºö pip3 install requests beautifulsoup4daili.py: ÊûÑÂª∫‰ª£ÁêÜIPÊ±†ÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/72793480carton: ‰ΩøÁî®ScrapyÁà¨Âèñ„ÄäÁÅ´ÂΩ±ÂøçËÄÖ„ÄãÊº´Áîª‰ª£Á†ÅÂèØ‰ª•Áà¨ÂèñÊï¥‰∏™„ÄäÁÅ´ÂΩ±ÂøçËÄÖ„ÄãÊº´ÁîªÊâÄÊúâÁ´†ËäÇÁöÑÂÜÖÂÆπÔºå‰øùÂ≠òÂà∞Êú¨Âú∞„ÄÇÊõ¥ÊîπÂú∞ÂùÄÔºåÂèØ‰ª•Áà¨ÂèñÂÖ∂‰ªñÊº´Áîª„ÄÇ‰øùÂ≠òÂú∞ÂùÄÂèØ‰ª•Âú®settings.py‰∏≠‰øÆÊîπ„ÄÇÂä®Êº´ÁΩëÁ´ôÔºöhttp://comic.kukudm.com/ÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/72858983hero.py: „ÄäÁéãËÄÖËç£ËÄÄ„ÄãÊé®ËçêÂá∫Ë£ÖÊü•ËØ¢Â∞èÂä©ÊâãÁΩëÈ°µÁà¨ÂèñÂ∑≤Áªè‰ºö‰∫ÜÔºåÊÉ≥ËøáÁà¨ÂèñÊâãÊú∫APPÈáåÁöÑÂÜÖÂÆπÂêóÔºüÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/76850843financical.py: Ë¥¢Âä°Êä•Ë°®‰∏ãËΩΩÂ∞èÂä©ÊâãÁà¨ÂèñÁöÑÊï∞ÊçÆÂ≠òÂÖ•Êï∞ÊçÆÂ∫ì‰ºöÂêóÔºü„ÄäË∑üËÇ°Á•ûÂ∑¥Ëè≤ÁâπÂ≠¶‰π†ÁÇíËÇ°‰πãË¥¢Âä°Êä•Ë°®ÂÖ•Â∫ì(MySQL)„Äã‰πüËÆ∏ËÉΩÁªô‰Ω†‰∏Ä‰∫õÊÄùË∑Ø„ÄÇÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/77801899Âä®ÊÄÅÁ§∫ÊÑèÂõæÔºöone_hour_spider:‰∏ÄÂ∞èÊó∂ÂÖ•Èó®Python3ÁΩëÁªúÁà¨Ëô´„ÄÇÂéüÁêÜËØ¥Êòé:Áü•‰πéÔºöhttps://zhuanlan.zhihu.com/p/29809609CSDNÔºöhttp://blog.csdn.net/c406495762/article/details/78123502Êú¨Ê¨°ÂÆûÊàòÂÜÖÂÆπÊúâÔºöÁΩëÁªúÂ∞èËØ¥‰∏ãËΩΩ(ÈùôÊÄÅÁΩëÁ´ô)-biqukan‰ºòÁæéÂ£ÅÁ∫∏‰∏ãËΩΩ(Âä®ÊÄÅÁΩëÁ´ô)-unsplashËßÜÈ¢ë‰∏ãËΩΩdouyin.py:ÊäñÈü≥AppËßÜÈ¢ë‰∏ãËΩΩÊäñÈü≥AppÁöÑËßÜÈ¢ë‰∏ãËΩΩÔºåÂ∞±ÊòØÊôÆÈÄöÁöÑAppÁà¨Âèñ„ÄÇÂéüÁêÜËØ¥Êòé:‰∏™‰∫∫ÁΩëÁ´ôÔºöhttp://cuijiahua.com/blog/2018/03/spider-5.htmldouyin_pro:ÊäñÈü≥AppËßÜÈ¢ë‰∏ãËΩΩÔºàÂçáÁ∫ßÁâàÔºâÊäñÈü≥AppÁöÑËßÜÈ¢ë‰∏ãËΩΩÔºåÊ∑ªÂä†ËßÜÈ¢ëËß£ÊûêÁΩëÁ´ôÔºåÊîØÊåÅÊó†Ê∞¥Âç∞ËßÜÈ¢ë‰∏ãËΩΩÔºå‰ΩøÁî®Á¨¨‰∏âÊñπÂπ≥Âè∞Ëß£Êûê„ÄÇÂéüÁêÜËØ¥Êòé:‰∏™‰∫∫ÁΩëÁ´ôÔºöhttp://cuijiahua.com/blog/2018/03/spider-5.htmldouyin:ÊäñÈü≥AppËßÜÈ¢ë‰∏ãËΩΩÔºàÂçáÁ∫ßÁâà2ÔºâÊäñÈü≥AppÁöÑËßÜÈ¢ë‰∏ãËΩΩÔºåÊ∑ªÂä†ËßÜÈ¢ëËß£ÊûêÁΩëÁ´ôÔºåÊîØÊåÅÊó†Ê∞¥Âç∞ËßÜÈ¢ë‰∏ãËΩΩÔºåÈÄöËøáurlËß£ÊûêÔºåÊó†ÈúÄÁ¨¨‰∏âÊñπÂπ≥Âè∞„ÄÇÂéüÁêÜËØ¥Êòé:‰∏™‰∫∫ÁΩëÁ´ôÔºöhttp://cuijiahua.com/blog/2018/03/spider-5.htmlÂä®ÊÄÅÁ§∫ÊÑèÂõæÔºögeetest.py:GEETESTÈ™åËØÅÁ†ÅËØÜÂà´ÂéüÁêÜËØ¥Êòé:Êó†12306.py:Áî®PythonÊä¢ÁÅ´ËΩ¶Á•®ÁÆÄÂçï‰ª£Á†ÅÂèØ‰ª•Ëá™Â∑±ÊÖ¢ÊÖ¢‰∏∞ÂØåÔºåËõÆÁÆÄÂçïÔºåÊúâÁà¨Ëô´Âü∫Á°ÄÂæàÂ•ΩÊìç‰ΩúÔºåÊ≤°ÊúâÂéüÁêÜËØ¥Êòé„ÄÇbaiwan:Áôæ‰∏áËã±ÈõÑËæÖÂä©Á≠îÈ¢òÊïàÊûúÂõæÔºöÂéüÁêÜËØ¥ÊòéÔºö‰∏™‰∫∫ÁΩëÁ´ôÔºöhttp://cuijiahua.com/blog/2018/01/spider_3.htmlÂäüËÉΩ‰ªãÁªçÔºöÊúçÂä°Âô®Á´ØÔºå‰ΩøÁî®PythonÔºàbaiwan.pyÔºâÈÄöËøáÊäìÂåÖËé∑ÂæóÁöÑÊé•Âè£Ëé∑ÂèñÁ≠îÈ¢òÊï∞ÊçÆÔºåËß£Êûê‰πãÂêéÈÄöËøáÁôæÂ∫¶Áü•ÈÅìÊêúÁ¥¢Êé•Âè£ÂåπÈÖçÁ≠îÊ°àÔºåÂ∞ÜÊúÄÁªàÂåπÈÖçÁöÑÁªìÊûúÂÜôÂÖ•Êñá‰ª∂Ôºàfile.txt)„ÄÇÊâãÊú∫ÊäìÂåÖ‰∏ç‰ºöÁöÑÊúãÂèãÔºåÂèØ‰ª•Áúã‰∏ãÊàëÁöÑÊó©ÊúüÊâãÊú∫APPÊäìÂåÖÊïôÁ®ã„ÄÇNode.jsÔºàapp.jsÔºâÊØèÈöî1sËØªÂèñ‰∏ÄÊ¨°file.txtÊñá‰ª∂ÔºåÂπ∂Â∞ÜËØªÂèñÁªìÊûúÈÄöËøásocket.ioÊé®ÈÄÅÁªôÂÆ¢Êà∑Á´ØÔºàindex.htmlÔºâ„ÄÇ‰∫≤ÊµãÁ≠îÈ¢òÂª∂Êó∂Âú®3sÂ∑¶Âè≥„ÄÇÂ£∞ÊòéÔºöÊ≤°ÂÅöËøáÂêéÁ´ØÂíåÂâçÁ´ØÔºåËä±‰∫Ü‰∏ÄÂ§©Êó∂Èó¥ÔºåÁé∞Â≠¶Áé∞ÂçñÂºÑÂ•ΩÁöÑÔºåjavascript‰πüÊòØÁé∞ÁúãÁé∞Áî®ÔºåÁôæÂ∫¶ÁöÑÁ®ãÂ∫èÔºåË∞ÉËØïË∞ÉËØïËÄåÂ∑≤„ÄÇÂèØËÉΩÊúâÂæàÂ§öÁî®Ê≥ïÊØîËæÉlowÁöÑÂú∞ÊñπÔºåÁî®Ê≥ï‰∏çÂØπÔºåËØ∑ÂãøËßÅÊÄ™ÔºåÊúâÂ§ßÁâõÊÑüÂÖ¥Ë∂£ÔºåÂèØ‰ª•Ëá™Ë°åÂÆåÂñÑ„ÄÇNetease:Ê†πÊçÆÊ≠åÂçï‰∏ãËΩΩÁΩëÊòì‰∫ëÈü≥‰πêÊïàÊûúÂõæÔºöÂéüÁêÜËØ¥ÊòéÔºöÊöÇÊó†ÂäüËÉΩ‰ªãÁªçÔºöÊ†πÊçÆmusic_list.txtÊñá‰ª∂ÈáåÁöÑÊ≠åÂçïÁöÑ‰ø°ÊÅØ‰∏ãËΩΩÁΩëÊòì‰∫ëÈü≥‰πêÔºåÂ∞ÜËá™Â∑±ÂñúÊ¨¢ÁöÑÈü≥‰πêËøõË°åÊâπÈáè‰∏ãËΩΩ„ÄÇbilibiliÔºöBÁ´ôËßÜÈ¢ëÂíåÂºπÂπïÊâπÈáè‰∏ãËΩΩÂéüÁêÜËØ¥ÊòéÔºöÊöÇÊó†‰ΩøÁî®ËØ¥ÊòéÔºö python bilibili.py -d Áå´ -k Áå´ -p 10 ‰∏â‰∏™ÂèÇÊï∞Ôºö -d\t‰øùÂ≠òËßÜÈ¢ëÁöÑÊñá‰ª∂Â§πÂêç -k\tBÁ´ôÊêúÁ¥¢ÁöÑÂÖ≥ÈîÆÂ≠ó -p\t‰∏ãËΩΩÊêúÁ¥¢ÁªìÊûúÂâçÂ§öÂ∞ëÈ°µjingdongÔºö‰∫¨‰∏úÂïÜÂìÅÊôíÂçïÂõæ‰∏ãËΩΩÊïàÊûúÂõæÔºöÂéüÁêÜËØ¥ÊòéÔºöÊöÇÊó†‰ΩøÁî®ËØ¥ÊòéÔºö python jd.py -k ËäíÊûú  ‰∏â‰∏™ÂèÇÊï∞Ôºö -d\t‰øùÂ≠òÂõæÁâáÁöÑË∑ØÂæÑÔºåÈªòËÆ§‰∏∫fd.pyÊñá‰ª∂ÊâÄÂú®Êñá‰ª∂Â§π -k\tÊêúÁ¥¢ÂÖ≥ÈîÆËØç -n  \t‰∏ãËΩΩÂïÜÂìÅÁöÑÊôíÂçïÂõæ‰∏™Êï∞ÔºåÂç≥n‰∏™ÂïÜÂ∫óÁöÑÊôíÂçïÂõæzhengfang_system_spiderÔºöÂØπÊ≠£ÊñπÊïôÂä°ÁÆ°ÁêÜÁ≥ªÁªü‰∏™‰∫∫ËØæË°®Ôºå‰∏™‰∫∫Â≠¶ÁîüÊàêÁª©ÔºåÁª©ÁÇπÁ≠âÁÆÄÂçïÁà¨ÂèñÊïàÊûúÂõæÔºöÂéüÁêÜËØ¥ÊòéÔºöÊöÇÊó†‰ΩøÁî®ËØ¥ÊòéÔºö cd zhengfang_system_spider pip install -r requirements.txt python spider.pyÂÖ∂ÂÆÉÊ¨¢Ëøé Pull requestsÔºåÊÑüË∞¢Ë¥°ÁåÆ„ÄÇÊõ¥Â§öÁ≤æÂΩ©ÔºåÊï¨ËØ∑ÊúüÂæÖÔºÅ 
26,Yorko/mlcourse.ai,https://github.com/Yorko/mlcourse.ai/blob/main/README.md,Python,"mlcourse.ai ‚Äì Open Machine Learning Coursemlcourse.ai is an open Machine Learning course by OpenDataScience (ods.ai), led by Yury Kashnitsky (yorko). Having both a Ph.D. degree in applied math and a Kaggle Competitions Master tier, Yury aimed at designing an ML course with a perfect balance between theory and practice. Thus, the course meets you with math formulae in lectures, and a lot of practice in a form of assignments and  Kaggle Inclass competitions. Currently, the course is in a self-paced mode. Here we guide you through the self-paced mlcourse.ai.Bonus:Additionally, you can purchase a Bonus Assignments pack with the best non-demo versions of mlcourse.ai assignments. Select the \""Bonus Assignments\"" tier. Refer to the details of the deal on the main page mlcourse.ai.Mirrors (üá¨üáß-only): mlcourse.ai (main site), Kaggle Dataset (same notebooks as Kaggle Notebooks)Self-paced passingYou are guided through 10 weeks of mlcourse.ai. For each week, from Pandas to Gradient Boosting, instructions are given on which articles to read, lectures to watch, what assignments to accomplish.ArticlesThis is the list of published articles on medium.com üá¨üáß, habr.com üá∑üá∫. Also notebooks in Chinese are mentioned üá®üá≥ and links to Kaggle Notebooks (in English) are given. Icons are clickable.Exploratory Data Analysis with Pandas üá¨üáß üá∑üá∫ üá®üá≥, Kaggle NotebookVisual Data Analysis with Python üá¨üáß üá∑üá∫ üá®üá≥, Kaggle Notebooks: part1, part2Classification, Decision Trees and k Nearest Neighbors üá¨üáß üá∑üá∫ üá®üá≥, Kaggle NotebookLinear Classification and Regression üá¨üáß üá∑üá∫ üá®üá≥, Kaggle Notebooks: part1, part2, part3, part4, part5Bagging and Random Forest üá¨üáß üá∑üá∫ üá®üá≥, Kaggle Notebooks: part1, part2, part3Feature Engineering and Feature Selection üá¨üáß üá∑üá∫ üá®üá≥, Kaggle NotebookUnsupervised Learning: Principal Component Analysis and Clustering üá¨üáß üá∑üá∫ üá®üá≥, Kaggle NotebookVowpal Wabbit: Learning with Gigabytes of Data üá¨üáß üá∑üá∫ üá®üá≥, Kaggle NotebookTime Series Analysis with Python, part 1 üá¨üáß üá∑üá∫ üá®üá≥. Predicting future with Facebook Prophet, part 2 üá¨üáß, üá®üá≥ Kaggle Notebooks: part1, part2Gradient Boosting üá¨üáß üá∑üá∫, üá®üá≥, Kaggle NotebookLecturesVideolectures are uploaded to this YouTube playlist.Introduction, video, slidesExploratory data analysis with Pandas, videoVisualization, main plots for EDA, videoDecision trees: theory and practical partLogistic regression: theoretical foundations, practical part (baselines in the \""Alice\"" competition)Ensembles and Random Forest ‚Äì part 1. Classification metrics ‚Äì part 2. Example of a business task, predicting a customer payment ‚Äì part 3Linear regression and regularization - theory, LASSO & Ridge, LTV prediction - practiceUnsupervised learning - Principal Component Analysis and ClusteringStochastic Gradient Descent for classification and regression - part 1, part 2 TBATime series analysis with Python (ARIMA, Prophet) - videoGradient boosting: basic ideas - part 1, key ideas behind Xgboost, LightGBM, and CatBoost + practice - part 2AssignmentsThe following are demo-assignments. Additionally, within the \""Bonus Assignments\"" tier you can get access to non-demo assignments.Exploratory data analysis with Pandas, nbviewer, Kaggle Notebook, solutionAnalyzing cardiovascular disease data, nbviewer, Kaggle Notebook, solutionDecision trees with a toy task and the UCI Adult dataset, nbviewer, Kaggle Notebook, solutionSarcasm detection, Kaggle Notebook, solution. Linear Regression as an optimization problem, nbviewer, Kaggle NotebookLogistic Regression and Random Forest in the credit scoring problem, nbviewer, Kaggle Notebook, solutionExploring OLS, Lasso and Random Forest in a regression task, nbviewer, Kaggle Notebook, solutionUnsupervised learning, nbviewer, Kaggle Notebook, solutionImplementing online regressor, nbviewer, Kaggle Notebook, solutionTime series analysis, nbviewer, Kaggle Notebook, solutionBeating baseline in a competition, Kaggle NotebookBonus assignmentsAdditionally, you can purchase a Bonus Assignments pack with the best non-demo versions of mlcourse.ai assignments. Select the \""Bonus Assignments\"" tier on Patreon or a similar tier on Boosty (rus).                   ¬†¬†                     Details of the dealmlcourse.ai is still in self-paced mode but we offer you Bonus Assignments with solutions for a contribution of $17/month. The idea is that you pay for ~1-5 months while studying the course materials, but a single contribution is still fine and opens your access to the bonus pack.Note: the first payment is charged at the moment of joining the Tier Patreon, and the next payment is charged on the 1st day of the next month, thus it's better to purchase the pack in the 1st half of the month.mlcourse.ai is never supposed to go fully monetized (it's created in the wonderful open ODS.ai community and will remain open and free) but it'd help to cover some operational costs, and Yury also put in quite some effort into assembling all the best assignments into one pack. Please note that unlike the rest of the course content, Bonus Assignments are copyrighted. Informally, Yury's fine if you share the pack with 2-3 friends but public sharing of the Bonus Assignments pack is prohibited.  The bonus pack contains 10 assignments, in some of them you are challenged to beat a baseline in a Kaggle competition under thorough guidance (\""Alice\"" and \""Medium\"") or implement an algorithm from scratch -- efficient stochastic gradient descent classifier and gradient boosting.Kaggle competitionsCatch Me If You Can: Intruder Detection through Webpage Session Tracking. Kaggle InclassPredicting popularity of a Medium article. Kaggle InclassDotA 2 winner prediction. Kaggle InclassCiting mlcourse.aiIf you happen to cite mlcourse.ai in your work, you can use this BibTeX record:@misc{mlcourse_ai,    author = {Kashnitsky, Yury},    title = {mlcourse.ai ‚Äì Open Machine Learning Course},    year = {2020},    publisher = {GitHub},    journal = {GitHub repository},    howpublished = {\\url{https://github.com/Yorko/mlcourse.ai}},}CommunityYou can join the Singularis.ai Slack community to ask questions on the course materials. The community is mostly Russian-speaking but questions in English are still welcome."
27,jenkins-docs/simple-python-pyinstaller-app,https://github.com/jenkins-docs/simple-python-pyinstaller-app/blob/master/README.md,Python,"simple-python-pyinstaller-appThis repository is for theBuild a Python app with PyInstallertutorial in the Jenkins User Documentation.The repository contains a simple Python application which is a command line tool \""add2vals\"" that outputs the addition of two values. If at least one of thevalues is a string, \""add2vals\"" treats both values as a string and insteadconcatenates the values. The \""add2\"" function in the \""calc\"" library (which\""add2vals\"" imports) is accompanied by a set of unit tests. These are tested with pytest to check that this function works as expected and the results are savedto a JUnit XML report.The delivery of the \""add2vals\"" tool through PyInstaller converts this tool intoa standalone executable file for Linux, which you can download through Jenkinsand execute at the command line on Linux machines without Python.The jenkins directory contains an example of the Jenkinsfile (i.e. Pipeline)you'll be creating yourself during the tutorial."
28,davidsandberg/facenet,https://github.com/davidsandberg/facenet/blob/master/README.md,Python,"Face Recognition using Tensorflow This is a TensorFlow implementation of the face recognizer described in the paper\""FaceNet: A Unified Embedding for Face Recognition and Clustering\"". The project also uses ideas from the paper \""Deep Face Recognition\"" from the Visual Geometry Group at Oxford.CompatibilityThe code is tested using Tensorflow r1.7 under Ubuntu 14.04 with Python 2.7 and Python 3.5. The test cases can be found here and the results can be found here.NewsDateUpdate2018-04-10Added new models trained on Casia-WebFace and VGGFace2 (see below). Note that the models uses fixed image standardization (see wiki).2018-03-31Added a new, more flexible input pipeline as well as a bunch of minor updates.2017-05-13Removed a bunch of older non-slim models. Moved the last bottleneck layer into the respective models. Corrected normalization of Center Loss.2017-05-06Added code to train a classifier on your own images. Renamed facenet_train.py to train_tripletloss.py and facenet_train_classifier.py to train_softmax.py.2017-03-02Added pretrained models that generate 128-dimensional embeddings.2017-02-22Updated to Tensorflow r1.0. Added Continuous Integration using Travis-CI.2017-02-03Added models where only trainable variables has been stored in the checkpoint. These are therefore significantly smaller.2017-01-27Added a model trained on a subset of the MS-Celeb-1M dataset. The LFW accuracy of this model is around 0.994.2017‚Äë01‚Äë02Updated to run with Tensorflow r0.12. Not sure if it runs with older versions of Tensorflow though.Pre-trained modelsModel nameLFW accuracyTraining datasetArchitecture20180408-1029000.9905CASIA-WebFaceInception ResNet v120180402-1147590.9965VGGFace2Inception ResNet v1NOTE: If you use any of the models, please do not forget to give proper credit to those providing the training dataset as well.InspirationThe code is heavily inspired by the OpenFace implementation.Training dataThe CASIA-WebFace dataset has been used for training. This training set consists of total of 453 453 images over 10 575 identities after face detection. Some performance improvement has been seen if the dataset has been filtered before training. Some more information about how this was done will come later.The best performing model has been trained on the VGGFace2 dataset consisting of ~3.3M faces and ~9000 classes.Pre-processingFace alignment using MTCNNOne problem with the above approach seems to be that the Dlib face detector misses some of the hard examples (partial occlusion, silhouettes, etc). This makes the training set too \""easy\"" which causes the model to perform worse on other benchmarks.To solve this, other face landmark detectors has been tested. One face landmark detector that has proven to work very well in this setting is theMulti-task CNN. A Matlab/Caffe implementation can be found here and this has been used for face alignment with very good results. A Python/Tensorflow implementation of MTCNN can be found here. This implementation does not give identical results to the Matlab/Caffe implementation but the performance is very similar.Running trainingCurrently, the best results are achieved by training the model using softmax loss. Details on how to train a model using softmax loss on the CASIA-WebFace dataset can be found on the page Classifier training of Inception-ResNet-v1 and .Pre-trained modelsInception-ResNet-v1 modelA couple of pretrained models are provided. They are trained using softmax loss with the Inception-Resnet-v1 model. The datasets has been aligned using MTCNN.PerformanceThe accuracy on LFW for the model 20180402-114759 is 0.99650+-0.00252. A description of how to run the test can be found on the page Validate on LFW. Note that the input images to the model need to be standardized using fixed image standardization (use the option --use_fixed_image_standardization when running e.g. validate_on_lfw.py)."
29,yandex-praktikum/calc_and_win,https://github.com/yandex-praktikum/calc_and_win/blob/master/README.md,Python,"calc_and_win–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏–≥—Ä—ã \""–†–∞—Å—Å—á–∏—Ç–∞–π –∏ –ø–æ–±–µ–¥–∏!\"""
30,google/it-cert-automation-practice,https://github.com/google/it-cert-automation-practice/blob/master/README.md,Python,Google IT Automation with Python Professional Certificate - Practice filesThis repository contains the practice files used throughout the courses that arepart of the Google IT Automation with Python Professional CertificateThere's a separate folder for each course.
31,keras-team/keras,https://github.com/keras-team/keras/blob/master/README.md,Python,"Keras: Deep Learning for humansThis repository hosts the development of the Keras library.Read the documentation at keras.io.About KerasKeras is a deep learning API written in Python,running on top of the machine learning platform TensorFlow.It was developed with a focus on enabling fast experimentation andproviding a delightful developer experience.The purpose of Keras is to give an unfair advantage to any developer looking to ship ML-powered apps.Keras is:Simple -- but not simplistic. Keras reduces developer cognitive loadto free you to focus on the parts of the problem that really matter.Keras focuses on ease of use, debugging speed, code elegance & conciseness,maintainability, and deployability (via TFServing, TFLite, TF.js).Flexible -- Keras adopts the principle of progressive disclosure ofcomplexity: simple workflows should be quick and easy, while arbitrarilyadvanced workflows should be possible via a clear path that builds uponwhat you've already learned.Powerful -- Keras provides industry-strength performance andscalability: it is used by organizations and companies including NASA,YouTube, and Waymo. That's right -- your YouTube recommendations arepowered by Keras, and so is the world's most advanced driverless vehicle.Keras & TensorFlow 2TensorFlow 2 is an end-to-end, open-source machine learning platform.You can think of it as an infrastructure layer fordifferentiable programming.It combines four key abilities:Efficiently executing low-level tensor operations on CPU, GPU, or TPU.Computing the gradient of arbitrary differentiable expressions.Scaling computation to many devices, such as clusters of hundreds of GPUs.Exporting programs (\""graphs\"") to external runtimes such as servers, browsers, mobile and embedded devices.Keras is the high-level API of TensorFlow 2: an approachable, highly-productive interfacefor solving machine learning problems,with a focus on modern deep learning. It provides essential abstractions and building blocks for developingand shipping machine learning solutions with high iteration velocity.Keras empowers engineers and researchers to take full advantage of the scalabilityand cross-platform capabilities of TensorFlow 2: you can run Keras on TPU or on large clusters of GPUs,and you can export your Keras models to run in the browser or on a mobile device.First contact with KerasThe core data structures of Keras are layers and models.The simplest type of model is the Sequential model, a linear stack of layers.For more complex architectures, you should use the Keras functional API,which allows you to build arbitrary graphs of layers or write models entirely from scratch via subclassing.Here is the Sequential model:from tensorflow.keras.models import Sequentialmodel = Sequential()Stacking layers is as easy as .add():from tensorflow.keras.layers import Densemodel.add(Dense(units=64, activation='relu'))model.add(Dense(units=10, activation='softmax'))Once your model looks good, configure its learning process with .compile():model.compile(loss='categorical_crossentropy',              optimizer='sgd',              metrics=['accuracy'])If you need to, you can further configure your optimizer. The Keras philosophy is to keep simple things simple,while allowing the user to be fully in control when they need to be (the ultimate control being the easy extensibility of the source code via subclassing).model.compile(loss=tf.keras.losses.categorical_crossentropy,              optimizer=tf.keras.optimizers.SGD(                  learning_rate=0.01, momentum=0.9, nesterov=True))You can now iterate on your training data in batches:# x_train and y_train are Numpy arrays.model.fit(x_train, y_train, epochs=5, batch_size=32)Evaluate your test loss and metrics in one line:loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)Or generate predictions on new data:classes = model.predict(x_test, batch_size=128)What you just saw is the most elementary way to use Keras.However, Keras is also a highly-flexible framework suitable to iterate on state-of-the-art research ideas.Keras follows the principle of progressive disclosure of complexity: it makes it easy to get started,yet it makes it possible to handle arbitrarily advanced use cases,only requiring incremental learning at each step.In pretty much the same way that you were able to train & evaluate a simple neural network above in a few lines,you can use Keras to quickly develop new training procedures or exotic model architectures.Here's a low-level training loop example, combining Keras functionality with the TensorFlow GradientTape:import tensorflow as tf# Prepare an optimizer.optimizer = tf.keras.optimizers.Adam()# Prepare a loss function.loss_fn = tf.keras.losses.kl_divergence# Iterate over the batches of a dataset.for inputs, targets in dataset:    # Open a GradientTape.    with tf.GradientTape() as tape:        # Forward pass.        predictions = model(inputs)        # Compute the loss value for this batch.        loss_value = loss_fn(targets, predictions)    # Get gradients of loss wrt the weights.    gradients = tape.gradient(loss_value, model.trainable_weights)    # Update the weights of the model.    optimizer.apply_gradients(zip(gradients, model.trainable_weights))For more in-depth tutorials about Keras, you can check out:Introduction to Keras for engineersIntroduction to Keras for researchersDeveloper guidesOther learning resourcesInstallationKeras comes packaged with TensorFlow 2 as tensorflow.keras.To start using Keras, simply install TensorFlow 2.You can then import Keras as follows:from tensorflow import kerasRelease and compatibilityKeras has nightly releases (keras-nightly on PyPI)and stable releases (keras on PyPI).The nightly Keras releases are usually compatible with the corresponding versionof the tf-nightly releases(e.g. keras-nightly==2.7.0.dev2021100607 should beused with tf-nightly==2.7.0.dev2021100607).We don't maintain backward compatibility for nightly releases.For stable releases, each Kerasversion maps to a specific stable version of TensorFlow.The table below shows the compatibility version mappingbetween TensorFlow versions and Keras versions.All the release branches can be found on GitHub.All the release binaries can be found on Pypi.SupportYou can ask questions and join the development discussion:In the TensorFlow forum.On the Keras mailing list.Opening an issueYou can also post bug reports and feature requests (only)in GitHub issues.Opening a PRWe welcome contributions! Before opening a PR, please readour contributor guide,and the API design guideline."
32,open-mmlab/mmdetection,https://github.com/open-mmlab/mmdetection/blob/main/README.md,Python,"    ¬†      OpenMMLab website                  HOT              ¬†¬†¬†¬†    OpenMMLab platform                  TRY IT OUT              ¬†üìòDocumentation |üõ†Ô∏èInstallation |üëÄModel Zoo |üÜïUpdate News |üöÄOngoing Projects |ü§îReporting IssuesEnglish | ÁÆÄ‰Ωì‰∏≠Êñá                                              IntroductionMMDetection is an open source object detection toolbox based on PyTorch. It isa part of the OpenMMLab project.The main branch works with PyTorch 1.8+.Major featuresModular DesignWe decompose the detection framework into different components and one can easily construct a customized object detection framework by combining different modules.Support of multiple tasks out of boxThe toolbox directly supports multiple detection tasks such as object detection, instance segmentation, panoptic segmentation, and semi-supervised object detection.High efficiencyAll basic bbox and mask operations run on GPUs. The training speed is faster than or comparable to other codebases, including Detectron2, maskrcnn-benchmark and SimpleDet.State of the artThe toolbox stems from the codebase developed by the MMDet team, who won COCO Detection Challenge in 2018, and we keep pushing it forward.The newly released RTMDet also obtains new state-of-the-art results on real-time instance segmentation and rotated object detection tasks and the best parameter-accuracy trade-off on object detection.Apart from MMDetection, we also released MMEngine for model training and MMCV for computer vision research, which are heavily depended on by this toolbox.What's NewHighlightWe are excited to announce our latest work on real-time object recognition tasks, RTMDet, a family of fully convolutional single-stage detectors. RTMDet not only achieves the best parameter-accuracy trade-off on object detection from tiny to extra-large model sizes but also obtains new state-of-the-art performance on instance segmentation and rotated object detection tasks. Details can be found in the technical report. Pre-trained models are here.TaskDatasetAPFPS(TRT FP16 BS1 3090)Object DetectionCOCO52.8322Instance SegmentationCOCO44.6188Rotated Object DetectionDOTA78.9(single-scale)/81.3(multi-scale)121v3.1.0 was released in 30/6/2023:Supports tracking algorithms including multi-object tracking (MOT) algorithms SORT, DeepSORT, StrongSORT, OCSORT, ByteTrack, QDTrack, and video instance segmentation (VIS) algorithm MaskTrackRCNN, Mask2Former-VIS.Support ViTDetSupports inference and evaluation of multimodal algorithms GLIP and XDecoder, and also supports datasets such as COCO semantic segmentation, COCO Caption, ADE20k general segmentation, and RefCOCO. GLIP fine-tuning will be supported in the future.Provides a gradio demo for image type tasks of MMDetection, making it easy for users to experience.InstallationPlease refer to Installation for installation instructions.Getting StartedPlease see Overview for the general introduction of MMDetection.For detailed user guides and advanced guides, please refer to our documentation:User GuidesTrain & TestLearn about ConfigsInference with existing modelsDataset PrepareTest existing models on standard datasetsTrain predefined models on standard datasetsTrain with customized datasetsTrain with customized models and standard datasetsFinetuning ModelsTest Results SubmissionWeight initializationUse a single stage detector as RPNSemi-supervised Object DetectionUseful ToolsAdvanced GuidesBasic ConceptsComponent CustomizationHow toWe also provide object detection colab tutorial  and instance segmentation colab tutorial .To migrate from MMDetection 2.x, please refer to migration.Overview of Benchmark and Model ZooResults and models are available in the model zoo.  Architectures                    Object Detection                    Instance Segmentation                    Panoptic Segmentation                    Other                                        Fast R-CNN (ICCV'2015)            Faster R-CNN (NeurIPS'2015)            RPN (NeurIPS'2015)            SSD (ECCV'2016)            RetinaNet (ICCV'2017)            Cascade R-CNN (CVPR'2018)            YOLOv3 (ArXiv'2018)            CornerNet (ECCV'2018)            Grid R-CNN (CVPR'2019)            Guided Anchoring (CVPR'2019)            FSAF (CVPR'2019)            CenterNet (CVPR'2019)            Libra R-CNN (CVPR'2019)            TridentNet (ICCV'2019)            FCOS (ICCV'2019)            RepPoints (ICCV'2019)            FreeAnchor (NeurIPS'2019)            CascadeRPN (NeurIPS'2019)            Foveabox (TIP'2020)            Double-Head R-CNN (CVPR'2020)            ATSS (CVPR'2020)            NAS-FCOS (CVPR'2020)            CentripetalNet (CVPR'2020)            AutoAssign (ArXiv'2020)            Side-Aware Boundary Localization (ECCV'2020)            Dynamic R-CNN (ECCV'2020)            DETR (ECCV'2020)            PAA (ECCV'2020)            VarifocalNet (CVPR'2021)            Sparse R-CNN (CVPR'2021)            YOLOF (CVPR'2021)            YOLOX (CVPR'2021)            Deformable DETR (ICLR'2021)            TOOD (ICCV'2021)            DDOD (ACM MM'2021)            RTMDet (ArXiv'2022)            Conditional DETR (ICCV'2021)            DAB-DETR (ICLR'2022)            DINO (ICLR'2023)            GLIP (CVPR'2022)            DiffusionDet (ArXiv'2023)            EfficientDet (CVPR'2020)            Detic (ECCV'2022)                                    Mask R-CNN (ICCV'2017)          Cascade Mask R-CNN (CVPR'2018)          Mask Scoring R-CNN (CVPR'2019)          Hybrid Task Cascade (CVPR'2019)          YOLACT (ICCV'2019)          InstaBoost (ICCV'2019)          SOLO (ECCV'2020)          PointRend (CVPR'2020)          DetectoRS (ArXiv'2020)          SOLOv2 (NeurIPS'2020)          SCNet (AAAI'2021)          QueryInst (ICCV'2021)          Mask2Former (ArXiv'2021)          CondInst (ECCV'2020)          SparseInst (CVPR'2022)          RTMDet (ArXiv'2022)          BoxInst (CVPR'2021)                                      Panoptic FPN (CVPR'2019)          MaskFormer (NeurIPS'2021)          Mask2Former (ArXiv'2021)                                      Contrastive Learning                          SwAV (NeurIPS'2020)          MoCo (CVPR'2020)          MoCov2 (ArXiv'2020)                                  Distillation                          Localization Distillation (CVPR'2022)          Label Assignment Distillation (WACV'2022)                          Semi-Supervised Object Detection                          Soft Teacher (ICCV'2021)                                        Components                    Backbones                    Necks                    Loss                    Common                                  VGG (ICLR'2015)        ResNet (CVPR'2016)        ResNeXt (CVPR'2017)        MobileNetV2 (CVPR'2018)        HRNet (CVPR'2019)        Generalized Attention (ICCV'2019)        GCNet (ICCVW'2019)        Res2Net (TPAMI'2020)        RegNet (CVPR'2020)        ResNeSt (ArXiv'2020)        PVT (ICCV'2021)        Swin (CVPR'2021)        PVTv2 (ArXiv'2021)        ResNet strikes back (ArXiv'2021)        EfficientNet (ArXiv'2021)        ConvNeXt (CVPR'2022)        ConvNeXtv2 (ArXiv'2023)                                PAFPN (CVPR'2018)        NAS-FPN (CVPR'2019)        CARAFE (ICCV'2019)        FPG (ArXiv'2020)        GRoIE (ICPR'2020)        DyHead (CVPR'2021)                                    GHM (AAAI'2019)          Generalized Focal Loss (NeurIPS'2020)          Seasaw Loss (CVPR'2021)                                      OHEM (CVPR'2016)          Group Normalization (ECCV'2018)          DCN (ICCV'2017)          DCNv2 (CVPR'2019)          Weight Standardization (ArXiv'2019)          Prime Sample Attention (CVPR'2020)          Strong Baselines (CVPR'2021)          Resnet strikes back (ArXiv'2021)                        Some other methods are also supported in projects using MMDetection.FAQPlease refer to FAQ for frequently asked questions.ContributingWe appreciate all contributions to improve MMDetection. Ongoing projects can be found in out GitHub Projects. Welcome community users to participate in these projects. Please refer to CONTRIBUTING.md for the contributing guideline.AcknowledgementMMDetection is an open source project that is contributed by researchers and engineers from various colleges and companies. We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks.We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new detectors.CitationIf you use this toolbox or benchmark in your research, please cite this project.@article{mmdetection,  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},  journal= {arXiv preprint arXiv:1906.07155},  year={2019}}LicenseThis project is released under the Apache 2.0 license.Projects in OpenMMLabMMEngine: OpenMMLab foundational library for training deep learning models.MMCV: OpenMMLab foundational library for computer vision.MMPreTrain: OpenMMLab pre-training toolbox and benchmark.MMagic: OpenMMLab Advanced, Generative and Intelligent Creation toolbox.MMDetection: OpenMMLab detection toolbox and benchmark.MMDetection3D: OpenMMLab's next-generation platform for general 3D object detection.MMRotate: OpenMMLab rotated object detection toolbox and benchmark.MMYOLO: OpenMMLab YOLO series toolbox and benchmark.MMSegmentation: OpenMMLab semantic segmentation toolbox and benchmark.MMOCR: OpenMMLab text detection, recognition, and understanding toolbox.MMPose: OpenMMLab pose estimation toolbox and benchmark.MMHuman3D: OpenMMLab 3D human parametric model toolbox and benchmark.MMSelfSup: OpenMMLab self-supervised learning toolbox and benchmark.MMRazor: OpenMMLab model compression toolbox and benchmark.MMFewShot: OpenMMLab fewshot learning toolbox and benchmark.MMAction2: OpenMMLab's next-generation action understanding toolbox and benchmark.MMTracking: OpenMMLab video perception toolbox and benchmark.MMFlow: OpenMMLab optical flow toolbox and benchmark.MMEditing: OpenMMLab image and video editing toolbox.MMGeneration: OpenMMLab image and video generative models toolbox.MMDeploy: OpenMMLab model deployment framework.MIM: MIM installs OpenMMLab packages.MMEval: A unified evaluation library for multiple machine learning libraries.Playground: A central hub for gathering and showcasing amazing projects built upon OpenMMLab."
33,gto76/python-cheatsheet,https://github.com/gto76/python-cheatsheet/blob/main/README.md,Python,"Comprehensive Python CheatsheetDownload text file, Buy PDF, Fork me on GitHub or Check out FAQ.Contents¬†¬†¬† 1. Collections: ¬† List, Dictionary, Set, Tuple, Range, Enumerate, Iterator, Generator.¬†¬†¬† 2. Types: ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† Type, String, Regular_Exp, Format, Numbers, Combinatorics, Datetime.¬†¬†¬† 3. Syntax: ¬†¬†¬†¬†¬†¬†¬†¬†¬† Args, Inline, Import, Decorator, Class, Duck_Types, Enum, Exception.¬†¬†¬† 4. System: ¬†¬†¬†¬†¬†¬†¬†¬† Exit, Print, Input, Command_Line_Arguments, Open, Path, OS_Commands.¬†¬†¬† 5. Data: ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† JSON, Pickle, CSV, SQLite, Bytes, Struct, Array, Memory_View, Deque.¬†¬†¬† 6. Advanced: ¬†¬†¬† Threading, Operator, Introspection, Metaprograming, Eval, Coroutines.¬†¬†¬† 7. Libraries: ¬†¬†¬†¬†¬†¬† Progress_Bar, Plot, Table, Curses, Logging, Scraping, Web, Profile,¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† NumPy, Image, Audio, Games, Data.Mainif __name__ == '__main__':      # Runs main() if file wasn't imported.    main()List<list> = <list>[<slice>]        # Or: <list>[from_inclusive : to_exclusive : ¬±step]<list>.append(<el>)             # Or: <list> += [<el>]<list>.extend(<collection>)     # Or: <list> += <collection><list>.sort()                   # Sorts in ascending order.<list>.reverse()                # Reverses the list in-place.<list> = sorted(<collection>)   # Returns a new sorted list.<iter> = reversed(<list>)       # Returns reversed iterator.sum_of_elements  = sum(<collection>)elementwise_sum  = [sum(pair) for pair in zip(list_a, list_b)]sorted_by_second = sorted(<collection>, key=lambda el: el[1])sorted_by_both   = sorted(<collection>, key=lambda el: (el[1], el[0]))flatter_list     = list(itertools.chain.from_iterable(<list>))product_of_elems = functools.reduce(lambda out, el: out * el, <collection>)list_of_chars    = list(<str>)For details about sorted(), min() and max() see sortable.Module operator provides functions itemgetter() and mul() that offer the same functionality as lambda expressions above.<list>.insert(<int>, <el>)      # Inserts item at index and moves the rest to the right.<el>  = <list>.pop([<int>])     # Removes and returns item at index or from the end.<int> = <list>.count(<el>)      # Returns number of occurrences. Also works on strings.<int> = <list>.index(<el>)      # Returns index of the first occurrence or raises ValueError.<list>.remove(<el>)             # Removes first occurrence of the item or raises ValueError.<list>.clear()                  # Removes all items. Also works on dictionary and set.Dictionary<view> = <dict>.keys()                          # Coll. of keys that reflects changes.<view> = <dict>.values()                        # Coll. of values that reflects changes.<view> = <dict>.items()                         # Coll. of key-value tuples that reflects chgs.value  = <dict>.get(key, default=None)          # Returns default if key is missing.value  = <dict>.setdefault(key, default=None)   # Returns and writes default if key is missing.<dict> = collections.defaultdict(<type>)        # Returns a dict with default value of type.<dict> = collections.defaultdict(lambda: 1)     # Returns a dict with default value 1.<dict> = dict(<collection>)                     # Creates a dict from coll. of key-value pairs.<dict> = dict(zip(keys, values))                # Creates a dict from two collections.<dict> = dict.fromkeys(keys [, value])          # Creates a dict from collection of keys.<dict>.update(<dict>)                           # Adds items. Replaces ones with matching keys.value = <dict>.pop(key)                         # Removes item or raises KeyError.{k for k, v in <dict>.items() if v == value}    # Returns set of keys that point to the value.{k: v for k, v in <dict>.items() if k in keys}  # Returns a dictionary, filtered by keys.Counter>>> from collections import Counter>>> colors = ['blue', 'blue', 'blue', 'red', 'red']>>> counter = Counter(colors)>>> counter['yellow'] += 1Counter({'blue': 3, 'red': 2, 'yellow': 1})>>> counter.most_common()[0]('blue', 3)Set<set> = set()                                   # `{}` returns a dictionary.<set>.add(<el>)                                 # Or: <set> |= {<el>}<set>.update(<collection> [, ...])              # Or: <set> |= <set><set>  = <set>.union(<coll.>)                   # Or: <set> | <set><set>  = <set>.intersection(<coll.>)            # Or: <set> & <set><set>  = <set>.difference(<coll.>)              # Or: <set> - <set><set>  = <set>.symmetric_difference(<coll.>)    # Or: <set> ^ <set><bool> = <set>.issubset(<coll.>)                # Or: <set> <= <set><bool> = <set>.issuperset(<coll.>)              # Or: <set> >= <set><el> = <set>.pop()                              # Raises KeyError if empty.<set>.remove(<el>)                              # Raises KeyError if missing.<set>.discard(<el>)                             # Doesn't raise an error.Frozen SetIs immutable and hashable.That means it can be used as a key in a dictionary or as an element in a set.<frozenset> = frozenset(<collection>)TupleTuple is an immutable and hashable list.<tuple> = ()                               # Empty tuple.<tuple> = (<el>,)                          # Or: <el>,<tuple> = (<el_1>, <el_2> [, ...])         # Or: <el_1>, <el_2> [, ...]Named TupleTuple's subclass with named elements.>>> from collections import namedtuple>>> Point = namedtuple('Point', 'x y')>>> p = Point(1, y=2)Point(x=1, y=2)>>> p[0]1>>> p.x1>>> getattr(p, 'y')2RangeImmutable and hashable sequence of integers.<range> = range(stop)                      # range(to_exclusive)<range> = range(start, stop)               # range(from_inclusive, to_exclusive)<range> = range(start, stop, ¬±step)        # range(from_inclusive, to_exclusive, ¬±step_size)>>> [i for i in range(3)][0, 1, 2]Enumeratefor i, el in enumerate(<collection> [, i_start]):    ...Iterator<iter> = iter(<collection>)                # `iter(<iter>)` returns unmodified iterator.<iter> = iter(<function>, to_exclusive)    # A sequence of return values until 'to_exclusive'.<el>   = next(<iter> [, default])          # Raises StopIteration or returns 'default' on end.<list> = list(<iter>)                      # Returns a list of iterator's remaining elements.Itertoolsimport itertools as it<iter> = it.count(start=0, step=1)         # Returns updated value endlessly. Accepts floats.<iter> = it.repeat(<el> [, times])         # Returns element endlessly or 'times' times.<iter> = it.cycle(<collection>)            # Repeats the sequence endlessly.<iter> = it.chain(<coll>, <coll> [, ...])  # Empties collections in order (figuratively).<iter> = it.chain.from_iterable(<coll>)    # Empties collections inside a collection in order.<iter> = it.islice(<coll>, to_exclusive)   # Only returns first 'to_exclusive' elements.<iter> = it.islice(<coll>, from_inc, ‚Ä¶)    # `to_exclusive, +step_size`. Indices can be None.GeneratorAny function that contains a yield statement returns a generator.Generators and iterators are interchangeable.def count(start, step):    while True:        yield start        start += step>>> counter = count(10, 2)>>> next(counter), next(counter), next(counter)(10, 12, 14)TypeEverything is an object.Every object has a type.Type and class are synonymous.<type> = type(<el>)                          # Or: <el>.__class__<bool> = isinstance(<el>, <type>)            # Or: issubclass(type(<el>), <type>)>>> type('a'), 'a'.__class__, str(<class 'str'>, <class 'str'>, <class 'str'>)Some types do not have built-in names, so they must be imported:from types import FunctionType, MethodType, LambdaType, GeneratorType, ModuleTypeAbstract Base ClassesEach abstract base class specifies a set of virtual subclasses. These classes are then recognized by isinstance() and issubclass() as subclasses of the ABC, although they are really not. ABC can also manually decide whether or not a specific class is its virtual subclass, usually based on which methods the class has implemented. For instance, Iterable ABC looks for method iter(), while Collection ABC looks for iter(), contains() and len().>>> from collections.abc import Iterable, Collection, Sequence>>> isinstance([1, 2, 3], Iterable)True+------------------+------------+------------+------------+|                  |  Iterable  | Collection |  Sequence  |+------------------+------------+------------+------------+| list, range, str |    yes     |    yes     |    yes     || dict, set        |    yes     |    yes     |            || iter             |    yes     |            |            |+------------------+------------+------------+------------+>>> from numbers import Number, Complex, Real, Rational, Integral>>> isinstance(123, Number)True+--------------------+----------+----------+----------+----------+----------+|                    |  Number  |  Complex |   Real   | Rational | Integral |+--------------------+----------+----------+----------+----------+----------+| int                |   yes    |   yes    |   yes    |   yes    |   yes    || fractions.Fraction |   yes    |   yes    |   yes    |   yes    |          || float              |   yes    |   yes    |   yes    |          |          || complex            |   yes    |   yes    |          |          |          || decimal.Decimal    |   yes    |          |          |          |          |+--------------------+----------+----------+----------+----------+----------+String<str>  = <str>.strip()                       # Strips all whitespace characters from both ends.<str>  = <str>.strip('<chars>')              # Strips all passed characters from both ends.<list> = <str>.split()                       # Splits on one or more whitespace characters.<list> = <str>.split(sep=None, maxsplit=-1)  # Splits on 'sep' str at most 'maxsplit' times.<list> = <str>.splitlines(keepends=False)    # On [\\\r\\f\\v\\x1c-\\x1e\\x85\\u2028\\u2029] and \\r\.<str>  = <str>.join(<coll_of_strings>)       # Joins elements using string as a separator.<bool> = <sub_str> in <str>                  # Checks if string contains the substring.<bool> = <str>.startswith(<sub_str>)         # Pass tuple of strings for multiple options.<bool> = <str>.endswith(<sub_str>)           # Pass tuple of strings for multiple options.<int>  = <str>.find(<sub_str>)               # Returns start index of the first match or -1.<int>  = <str>.index(<sub_str>)              # Same, but raises ValueError if missing.<str>  = <str>.replace(old, new [, count])   # Replaces 'old' with 'new' at most 'count' times.<str>  = <str>.translate(<table>)            # Use `str.maketrans(<dict>)` to generate table.<str>  = chr(<int>)                          # Converts int to Unicode character.<int>  = ord(<str>)                          # Converts Unicode character to int.Also: 'lstrip()', 'rstrip()' and 'rsplit()'.Also: 'lower()', 'upper()', 'capitalize()' and 'title()'.Property Methods+---------------+----------+----------+----------+----------+----------+|               | [ !#$%‚Ä¶] | [a-zA-Z] |  [¬º¬Ω¬æ]   |  [¬≤¬≥¬π]   |  [0-9]   |+---------------+----------+----------+----------+----------+----------+| isprintable() |   yes    |   yes    |   yes    |   yes    |   yes    || isalnum()     |          |   yes    |   yes    |   yes    |   yes    || isnumeric()   |          |          |   yes    |   yes    |   yes    || isdigit()     |          |          |          |   yes    |   yes    || isdecimal()   |          |          |          |          |   yes    |+---------------+----------+----------+----------+----------+----------+'isspace()' checks for whitespaces: '[ \\t\\\r\\f\\v\\x1c-\\x1f\\x85\\xa0\\u1680‚Ä¶]'.Regeximport re<str>   = re.sub(<regex>, new, text, count=0)  # Substitutes all occurrences with 'new'.<list>  = re.findall(<regex>, text)            # Returns all occurrences as strings.<list>  = re.split(<regex>, text, maxsplit=0)  # Use brackets in regex to include the matches.<Match> = re.search(<regex>, text)             # Searches for first occurrence of the pattern.<Match> = re.match(<regex>, text)              # Searches only at the beginning of the text.<iter>  = re.finditer(<regex>, text)           # Returns all occurrences as Match objects.Argument 'new' can be a function that accepts a Match object and returns a string.Search() and match() return None if they can't find a match.Argument 'flags=re.IGNORECASE' can be used with all functions.Argument 'flags=re.MULTILINE' makes '^' and '$' match the start/end of each line.Argument 'flags=re.DOTALL' makes '.' also accept the '\'.Use r'\\1' or '\\\\1' for backreference ('\\1' returns a character with octal code 1).Add '?' after '*' and '+' to make them non-greedy.Match Object<str>   = <Match>.group()                      # Returns the whole match. Also group(0).<str>   = <Match>.group(1)                     # Returns part in the first bracket.<tuple> = <Match>.groups()                     # Returns all bracketed parts.<int>   = <Match>.start()                      # Returns start index of the match.<int>   = <Match>.end()                        # Returns exclusive end index of the match.Special Sequences'\\d' == '[0-9]'                                # Matches decimal characters.'\\w' == '[a-zA-Z0-9_]'                         # Matches alphanumerics and underscore.'\\s' == '[ \\t\\\r\\f\\v]'                        # Matches whitespaces.By default, decimal characters, alphanumerics and whitespaces from all alphabets are matched unless 'flags=re.ASCII' argument is used.As shown above, it restricts all special sequence matches to the first 128 characters and prevents '\\s' from accepting '[\\x1c-\\x1f]' (the so-called separator characters).Use a capital letter for negation (all non-ASCII characters will be matched when used in combination with ASCII flag).Format<str> = f'{<el_1>}, {<el_2>}'            # Curly brackets can also contain expressions.<str> = '{}, {}'.format(<el_1>, <el_2>)  # Or: '{0}, {a}'.format(<el_1>, a=<el_2>)<str> = '%s, %s' % (<el_1>, <el_2>)      # Redundant and inferior C-style formatting.Example>>> Person = collections.namedtuple('Person', 'name height')>>> person = Person('Jean-Luc', 187)>>> f'{person.name} is {person.height / 100} meters tall.''Jean-Luc is 1.87 meters tall.'General Options{<el>:<10}                               # '<el>      '{<el>:^10}                               # '   <el>   '{<el>:>10}                               # '      <el>'{<el>:.<10}                              # '<el>......'{<el>:0}                                 # '<el>'Options can be generated dynamically: f'{<el>:{<str/int>}[‚Ä¶]}'.Adding '=' to the expression prepends it to the output: f'{1+1=}' returns '1+1=2'.Adding '!r' to the expression converts object to string by calling its repr() method.Strings{'abcde':10}                             # 'abcde     '{'abcde':10.3}                           # 'abc       '{'abcde':.3}                             # 'abc'{'abcde'!r:10}                           # \""'abcde'   \""Numbers{123456:10}                              # '    123456'{123456:10,}                             # '   123,456'{123456:10_}                             # '   123_456'{123456:+10}                             # '   +123456'{123456:=+10}                            # '+   123456'{123456: }                               # ' 123456'{-123456: }                              # '-123456'Floats{1.23456:10.3}                           # '      1.23'{1.23456:10.3f}                          # '     1.235'{1.23456:10.3e}                          # ' 1.235e+00'{1.23456:10.3%}                          # '  123.456%'Comparison of presentation types:+--------------+----------------+----------------+----------------+----------------+|              |    {<float>}   |   {<float>:f}  |   {<float>:e}  |   {<float>:%}  |+--------------+----------------+----------------+----------------+----------------+|  0.000056789 |   '5.6789e-05' |    '0.000057'  | '5.678900e-05' |    '0.005679%' ||  0.00056789  |   '0.00056789' |    '0.000568'  | '5.678900e-04' |    '0.056789%' ||  0.0056789   |   '0.0056789'  |    '0.005679'  | '5.678900e-03' |    '0.567890%' ||  0.056789    |   '0.056789'   |    '0.056789'  | '5.678900e-02' |    '5.678900%' ||  0.56789     |   '0.56789'    |    '0.567890'  | '5.678900e-01' |   '56.789000%' ||  5.6789      |   '5.6789'     |    '5.678900'  | '5.678900e+00' |  '567.890000%' || 56.789       |  '56.789'      |   '56.789000'  | '5.678900e+01' | '5678.900000%' |+--------------+----------------+----------------+----------------+----------------++--------------+----------------+----------------+----------------+----------------+|              |  {<float>:.2}  |  {<float>:.2f} |  {<float>:.2e} |  {<float>:.2%} |+--------------+----------------+----------------+----------------+----------------+|  0.000056789 |    '5.7e-05'   |      '0.00'    |   '5.68e-05'   |      '0.01%'   ||  0.00056789  |    '0.00057'   |      '0.00'    |   '5.68e-04'   |      '0.06%'   ||  0.0056789   |    '0.0057'    |      '0.01'    |   '5.68e-03'   |      '0.57%'   ||  0.056789    |    '0.057'     |      '0.06'    |   '5.68e-02'   |      '5.68%'   ||  0.56789     |    '0.57'      |      '0.57'    |   '5.68e-01'   |     '56.79%'   ||  5.6789      |    '5.7'       |      '5.68'    |   '5.68e+00'   |    '567.89%'   || 56.789       |    '5.7e+01'   |     '56.79'    |   '5.68e+01'   |   '5678.90%'   |+--------------+----------------+----------------+----------------+----------------+'{<float>:g}' is '{<float>:.6}' with stripped zeros, exponent starting at 7 figures.When both rounding up and rounding down are possible, the one that returns result with even last digit is chosen. That makes '{6.5:.0f}' a '6' and '{7.5:.0f}' an '8'.This rule only effects numbers that can be represented exactly by a float (.5, .25, ‚Ä¶).Ints{90:c}                                   # 'Z'{90:b}                                   # '1011010'{90:X}                                   # '5A'Numbers<int>      = int(<float/str/bool>)                # Or: math.floor(<float>)<float>    = float(<int/str/bool>)                # Or: <int/float>e¬±<int><complex>  = complex(real=0, imag=0)              # Or: <int/float/Fraction> ¬± <int/float>j<Fraction> = fractions.Fraction(0, 1)             # Or: Fraction(numerator=0, denominator=1)<Decimal>  = decimal.Decimal(<str/int>)           # Or: Decimal((sign, digits, exponent))'int(<str>)' and 'float(<str>)' raise ValueError on malformed strings.Decimal numbers are stored exactly, unlike most floats where '1.1 + 2.2 != 3.3'.Floats can be compared with: 'math.isclose(<float>, <float>)'.Precision of decimal operations is set with: 'decimal.getcontext().prec = <int>'.Basic Functions<num> = pow(<num>, <num>)                         # Or: <num> ** <num><num> = abs(<num>)                                # <float> = abs(<complex>)<num> = round(<num> [, ¬±ndigits])                 # `round(126, -1) == 130`Mathfrom math import e, pi, inf, nan, isinf, isnan    # `<el> == nan` is always False.from math import sin, cos, tan, asin, acos, atan  # Also: degrees, radians.from math import log, log10, log2                 # Log can accept base as second arg.Statisticsfrom statistics import mean, median, variance     # Also: stdev, quantiles, groupby.Randomfrom random import random, randint, choice        # Also: shuffle, gauss, triangular, seed.<float> = random()                                # A float inside [0, 1).<int>   = randint(from_inc, to_inc)               # An int inside [from_inc, to_inc].<el>    = choice(<sequence>)                      # Keeps the sequence intact.Bin, Hex<int> = ¬±0b<bin>                                  # Or: ¬±0x<hex><int> = int('¬±<bin>', 2)                          # Or: int('¬±<hex>', 16)<int> = int('¬±0b<bin>', 0)                        # Or: int('¬±0x<hex>', 0)<str> = bin(<int>)                                # Returns '[-]0b<bin>'.Bitwise Operators<int> = <int> & <int>                             # And (0b1100 & 0b1010 == 0b1000).<int> = <int> | <int>                             # Or  (0b1100 | 0b1010 == 0b1110).<int> = <int> ^ <int>                             # Xor (0b1100 ^ 0b1010 == 0b0110).<int> = <int> << n_bits                           # Left shift. Use >> for right.<int> = ~<int>                                    # Not. Also -<int> - 1.Combinatoricsimport itertools as it>>> list(it.product([0, 1], repeat=3))[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]>>> list(it.product('abc', 'abc'))                    #   a  b  c[('a', 'a'), ('a', 'b'), ('a', 'c'),                  # a x  x  x ('b', 'a'), ('b', 'b'), ('b', 'c'),                  # b x  x  x ('c', 'a'), ('c', 'b'), ('c', 'c')]                  # c x  x  x>>> list(it.combinations('abc', 2))                   #   a  b  c[('a', 'b'), ('a', 'c'),                              # a .  x  x ('b', 'c')]                                          # b .  .  x>>> list(it.combinations_with_replacement('abc', 2))  #   a  b  c[('a', 'a'), ('a', 'b'), ('a', 'c'),                  # a x  x  x ('b', 'b'), ('b', 'c'),                              # b .  x  x ('c', 'c')]                                          # c .  .  x>>> list(it.permutations('abc', 2))                   #   a  b  c[('a', 'b'), ('a', 'c'),                              # a .  x  x ('b', 'a'), ('b', 'c'),                              # b x  .  x ('c', 'a'), ('c', 'b')]                              # c x  x  .DatetimeProvides 'date', 'time', 'datetime' and 'timedelta' classes. All are immutable and hashable.# pip3 install python-dateutilfrom datetime import date, time, datetime, timedelta, timezonefrom dateutil.tz import tzlocal, gettz, datetime_exists, resolve_imaginary<D>  = date(year, month, day)               # Only accepts valid dates from 1 to 9999 AD.<T>  = time(hour=0, minute=0, second=0)     # Also: `microsecond=0, tzinfo=None, fold=0`.<DT> = datetime(year, month, day, hour=0)   # Also: `minute=0, second=0, microsecond=0, ‚Ä¶`.<TD> = timedelta(weeks=0, days=0, hours=0)  # Also: `minutes=0, seconds=0, microseconds=0`.Aware <a> time and datetime objects have defined timezone, while naive <n> don't.If object is naive, it is presumed to be in the system's timezone.'fold=1' means the second pass in case of time jumping back for one hour.Timedelta normalizes arguments to ¬±days, seconds (< 86‚ÄØ400) and microseconds (< 1M).Use '<D/DT>.weekday()' to get the day of the week as an int, with Monday being 0.'<DTa> = resolve_imaginary(<DTa>)' fixes DTs that fall into the missing hour.Now<D/DTn>  = D/DT.today()                     # Current local date or naive datetime.<DTn>    = DT.utcnow()                      # Naive datetime from current UTC time.<DTa>    = DT.now(<tzinfo>)                 # Aware datetime from current tz time.To extract time use '<DTn>.time()', '<DTa>.time()' or '<DTa>.timetz()'.Timezone<tzinfo> = timezone.utc                     # London without daylight saving time.<tzinfo> = timezone(<timedelta>)            # Timezone with fixed offset from UTC.<tzinfo> = tzlocal()                        # Local timezone. Also gettz().<tzinfo> = gettz('<Continent>/<City>')      # 'Continent/City_Name' timezone or None.<DTa>    = <DT>.astimezone([<tzinfo>])      # Converts DT to the passed or local timezone.<Ta/DTa> = <T/DT>.replace(tzinfo=<tzinfo>)  # Changes object's timezone without conversion.Standard library's zoneinfo.ZoneInfo() can be used instead of gettz() on Python 3.9 and later. It requires 'tzdata' package on Windows.Encode<D/T/DT> = D/T/DT.fromisoformat('<iso>')    # Object from ISO string. Raises ValueError.<DT>     = DT.strptime(<str>, '<format>')   # Datetime from str, according to format.<D/DTn>  = D/DT.fromordinal(<int>)          # D/DTn from days since the Gregorian NYE 1.<DTn>    = DT.fromtimestamp(<real>)         # Local time DTn from seconds since the Epoch.<DTa>    = DT.fromtimestamp(<real>, <tz.>)  # Aware datetime from seconds since the Epoch.ISO strings come in following forms: 'YYYY-MM-DD', 'HH:MM:SS.mmmuuu[¬±HH:MM]', or both separated by an arbitrary character. All parts following the hours are optional.Python uses the Unix Epoch: '1970-01-01 00:00 UTC', '1970-01-01 01:00 CET', ...Decode<str>    = <D/T/DT>.isoformat(sep='T')      # Also `timespec='auto/hours/minutes/seconds/‚Ä¶'`.<str>    = <D/T/DT>.strftime('<format>')    # Custom string representation.<int>    = <D/DT>.toordinal()               # Days since Gregorian NYE 1, ignoring time and tz.<float>  = <DTn>.timestamp()                # Seconds since the Epoch, from DTn in local tz.<float>  = <DTa>.timestamp()                # Seconds since the Epoch, from aware datetime.Format>>> dt = datetime.strptime('2015-05-14 23:39:00.00 +0200', '%Y-%m-%d %H:%M:%S.%f %z')>>> dt.strftime(\""%A, %dth of %B '%y, %I:%M%p %Z\"")\""Thursday, 14th of May '15, 11:39PM UTC+02:00\""'%z' accepts '¬±HH[:]MM' and returns '¬±HHMM' or empty string if datetime is naive.'%Z' accepts 'UTC/GMT' and local timezone's code and returns timezone's name, 'UTC[¬±HH:MM]' if timezone is nameless, or an empty string if datetime is naive.For abbreviated weekday and month use '%a' and '%b'.Arithmetics<D/DT>   = <D/DT>  ¬± <TD>                   # Returned datetime can fall into missing hour.<TD>     = <D/DTn> - <D/DTn>                # Returns the difference. Ignores time jumps.<TD>     = <DTa>   - <DTa>                  # Ignores time jumps if they share tzinfo object.<TD>     = <TD>    * <int/float>            # Also: <TD> = abs(<TD>) and <TD> = <TD> ¬±% <TD>.<float>  = <TD>    / <TD>                   # How many weeks/years there are in TD. Also //.ArgumentsInside Function Callfunc(<positional_args>)                           # func(0, 0)func(<keyword_args>)                              # func(x=0, y=0)func(<positional_args>, <keyword_args>)           # func(0, y=0)Inside Function Definitiondef func(<nondefault_args>): ...                  # def func(x, y): ...def func(<default_args>): ...                     # def func(x=0, y=0): ...def func(<nondefault_args>, <default_args>): ...  # def func(x, y=0): ...Default values are evaluated when function is first encountered in the scope.Any mutation of a mutable default value will persist between invocations!Splat OperatorInside Function CallSplat expands a collection into positional arguments, while splatty-splat expands a dictionary into keyword arguments.args   = (1, 2)kwargs = {'x': 3, 'y': 4, 'z': 5}func(*args, **kwargs)Is the same as:func(1, 2, x=3, y=4, z=5)Inside Function DefinitionSplat combines zero or more positional arguments into a tuple, while splatty-splat combines zero or more keyword arguments into a dictionary.def add(*a):    return sum(a)>>> add(1, 2, 3)6Legal argument combinations:def f(*args): ...               # f(1, 2, 3)def f(x, *args): ...            # f(1, 2, 3)def f(*args, z): ...            # f(1, 2, z=3)def f(**kwargs): ...            # f(x=1, y=2, z=3)def f(x, **kwargs): ...         # f(x=1, y=2, z=3) | f(1, y=2, z=3)def f(*args, **kwargs): ...     # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)def f(x, *args, **kwargs): ...  # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3) | f(1, 2, 3)def f(*args, y, **kwargs): ...  # f(x=1, y=2, z=3) | f(1, y=2, z=3)def f(*, x, y, z): ...          # f(x=1, y=2, z=3)def f(x, *, y, z): ...          # f(x=1, y=2, z=3) | f(1, y=2, z=3)def f(x, y, *, z): ...          # f(x=1, y=2, z=3) | f(1, y=2, z=3) | f(1, 2, z=3)Other Uses<list>  = [*<coll.> [, ...]]    # Or: list(<collection>) [+ ...]<tuple> = (*<coll.>, [...])     # Or: tuple(<collection>) [+ ...]<set>   = {*<coll.> [, ...]}    # Or: set(<collection>) [| ...]<dict>  = {**<dict> [, ...]}    # Or: dict(**<dict> [, ...])head, *body, tail = <coll.>     # Head or tail can be omitted.InlineLambda<func> = lambda: <return_value>                     # A single statement function.<func> = lambda <arg_1>, <arg_2>: <return_value>    # Also accepts default arguments.Comprehensions<list> = [i+1 for i in range(10)]                   # Or: [1, 2, ..., 10]<iter> = (i for i in range(10) if i > 5)            # Or: iter([6, 7, 8, 9])<set>  = {i+5 for i in range(10)}                   # Or: {5, 6, ..., 14}<dict> = {i: i*2 for i in range(10)}                # Or: {0: 0, 1: 2, ..., 9: 18}>>> [l+r for l in 'abc' for r in 'abc']['aa', 'ab', 'ac', ..., 'cc']Map, Filter, Reducefrom functools import reduce<iter> = map(lambda x: x + 1, range(10))            # Or: iter([1, 2, ..., 10])<iter> = filter(lambda x: x > 5, range(10))         # Or: iter([6, 7, 8, 9])<obj>  = reduce(lambda out, x: out + x, range(10))  # Or: 45Any, All<bool> = any(<collection>)                          # Is `bool(<el>)` True for any element.<bool> = all(<collection>)                          # Is True for all elements or empty.Conditional Expression<obj> = <exp> if <condition> else <exp>             # Only one expression gets evaluated.>>> [a if a else 'zero' for a in (0, 1, 2, 3)]      # `any([0, '', [], None]) == False`['zero', 1, 2, 3]Named Tuple, Enum, Dataclassfrom collections import namedtuplePoint = namedtuple('Point', 'x y')                  # Creates a tuple's subclass.point = Point(0, 0)                                 # Returns its instance.from enum import EnumDirection = Enum('Direction', 'N E S W')            # Creates an enum.direction = Direction.N                             # Returns its member.from dataclasses import make_dataclassPlayer = make_dataclass('Player', ['loc', 'dir'])   # Creates a class.player = Player(point, direction)                   # Returns its instance.Importsimport <module>            # Imports a built-in or '<module>.py'.import <package>           # Imports a built-in or '<package>/__init__.py'.import <package>.<module>  # Imports a built-in or '<package>/<module>.py'.Package is a collection of modules, but it can also define its own objects.On a filesystem this corresponds to a directory of Python files with an optional init script.Running 'import <package>' does not automatically provide access to the package's modules unless they are explicitly imported in its init script.ClosureWe have/get a closure in Python when:A nested function references a value of its enclosing function and thenthe enclosing function returns the nested function.def get_multiplier(a):    def out(b):        return a * b    return out>>> multiply_by_3 = get_multiplier(3)>>> multiply_by_3(10)30If multiple nested functions within enclosing function reference the same value, that value gets shared.To dynamically access function's first free variable use '<function>.__closure__[0].cell_contents'.Partialfrom functools import partial<function> = partial(<function> [, <arg_1>, <arg_2>, ...])>>> def multiply(a, b):...     return a * b>>> multiply_by_3 = partial(multiply, 3)>>> multiply_by_3(10)30Partial is also useful in cases when function needs to be passed as an argument because it enables us to set its arguments beforehand.A few examples being: 'defaultdict(<function>)', 'iter(<function>, to_exclusive)' and dataclass's 'field(default_factory=<function>)'.Non-LocalIf variable is being assigned to anywhere in the scope, it is regarded as a local variable, unless it is declared as a 'global' or a 'nonlocal'.def get_counter():    i = 0    def out():        nonlocal i        i += 1        return i    return out>>> counter = get_counter()>>> counter(), counter(), counter()(1, 2, 3)DecoratorA decorator takes a function, adds some functionality and returns it.It can be any callable, but is usually implemented as a function that returns a closure.@decorator_namedef function_that_gets_passed_to_decorator():    ...Debugger ExampleDecorator that prints function's name every time the function is called.from functools import wrapsdef debug(func):    @wraps(func)    def out(*args, **kwargs):        print(func.__name__)        return func(*args, **kwargs)    return out@debugdef add(x, y):    return x + yWraps is a helper decorator that copies the metadata of the passed function (func) to the function it is wrapping (out).Without it 'add.__name__' would return 'out'.LRU CacheDecorator that caches function's return values. All function's arguments must be hashable.from functools import lru_cache@lru_cache(maxsize=None)def fib(n):    return n if n < 2 else fib(n-2) + fib(n-1)Default size of the cache is 128 values. Passing 'maxsize=None' makes it unbounded.CPython interpreter limits recursion depth to 1000 by default. To increase it use 'sys.setrecursionlimit(<depth>)'.Parametrized DecoratorA decorator that accepts arguments and returns a normal decorator that accepts a function.from functools import wrapsdef debug(print_result=False):    def decorator(func):        @wraps(func)        def out(*args, **kwargs):            result = func(*args, **kwargs)            print(func.__name__, result if print_result else '')            return result        return out    return decorator@debug(print_result=True)def add(x, y):    return x + yUsing only '@debug' to decorate the add() function would not work here, because debug would then receive the add() function as a 'print_result' argument. Decorators can however manually check if the argument they received is a function and act accordingly.Classclass <name>:    def __init__(self, a):        self.a = a    def __repr__(self):        class_name = self.__class__.__name__        return f'{class_name}({self.a!r})'    def __str__(self):        return str(self.a)    @classmethod    def get_class_name(cls):        return cls.__name__Return value of repr() should be unambiguous and of str() readable.If only repr() is defined, it will also be used for str().Methods decorated with '@staticmethod' do not receive 'self' nor 'cls' as their first arg.Expressions that call the str() method:print(<el>)f'{<el>}'logging.warning(<el>)csv.writer(<file>).writerow([<el>])raise Exception(<el>)Expressions that call the repr() method:print/str/repr([<el>])print/str/repr({<el>: <el>})f'{<el>!r}'Z = dataclasses.make_dataclass('Z', ['a']); print/str/repr(Z(<el>))>>> <el>Constructor Overloadingclass <name>:    def __init__(self, a=None):        self.a = aInheritanceclass Person:    def __init__(self, name, age):        self.name = name        self.age  = ageclass Employee(Person):    def __init__(self, name, age, staff_num):        super().__init__(name, age)        self.staff_num = staff_numMultiple Inheritanceclass A: passclass B: passclass C(A, B): passMRO determines the order in which parent classes are traversed when searching for a method or an attribute:>>> C.mro()[<class 'C'>, <class 'A'>, <class 'B'>, <class 'object'>]PropertyPythonic way of implementing getters and setters.class Person:    @property    def name(self):        return ' '.join(self._name)    @name.setter    def name(self, value):        self._name = value.split()>>> person = Person()>>> person.name = '\\t Guido  van Rossum \'>>> person.name'Guido van Rossum'DataclassDecorator that automatically generates init(), repr() and eq() special methods.from dataclasses import dataclass, field@dataclass(order=False, frozen=False)class <class_name>:    <attr_name>: <type>    <attr_name>: <type> = <default_value>    <attr_name>: list/dict/set = field(default_factory=list/dict/set)Objects can be made sortable with 'order=True' and immutable with 'frozen=True'.For object to be hashable, all attributes must be hashable and 'frozen' must be True.Function field() is needed because '<attr_name>: list = []' would make a list that is shared among all instances. Its 'default_factory' argument can be any callable.For attributes of arbitrary type use 'typing.Any'.Inline:from dataclasses import make_dataclass<class> = make_dataclass('<class_name>', <coll_of_attribute_names>)<class> = make_dataclass('<class_name>', <coll_of_tuples>)<tuple> = ('<attr_name>', <type> [, <default_value>])Rest of type annotations (CPython interpreter ignores them all):import collections.abc as abc, typing as tp<var_name>: list/set/abc.Iterable/abc.Sequence/tp.Optional[<type>] [= <obj>]<var_name>: dict/tuple/tp.Union[<type>, ...] [= <obj>]def func(<arg_name>: <type> [= <obj>]) -> <type>: ...SlotsMechanism that restricts objects to attributes listed in 'slots' and significantly reduces their memory footprint.class MyClassWithSlots:    __slots__ = ['a']    def __init__(self):        self.a = 1Copyfrom copy import copy, deepcopy<object> = copy(<object>)<object> = deepcopy(<object>)Duck TypesA duck type is an implicit type that prescribes a set of special methods. Any object that has those methods defined is considered a member of that duck type.ComparableIf eq() method is not overridden, it returns 'id(self) == id(other)', which is the same as 'self is other'.That means all objects compare not equal by default.Only the left side object has eq() method called, unless it returns NotImplemented, in which case the right object is consulted. False is returned if both return NotImplemented.Ne() automatically works on any object that has eq() defined.class MyComparable:    def __init__(self, a):        self.a = a    def __eq__(self, other):        if isinstance(other, type(self)):            return self.a == other.a        return NotImplementedHashableHashable object needs both hash() and eq() methods and its hash value should never change.Hashable objects that compare equal must have the same hash value, meaning default hash() that returns 'id(self)' will not do.That is why Python automatically makes classes unhashable if you only implement eq().class MyHashable:    def __init__(self, a):        self._a = a    @property    def a(self):        return self._a    def __eq__(self, other):        if isinstance(other, type(self)):            return self.a == other.a        return NotImplemented    def __hash__(self):        return hash(self.a)SortableWith 'total_ordering' decorator, you only need to provide eq() and one of lt(), gt(), le() or ge() special methods and the rest will be automatically generated.Functions sorted() and min() only require lt() method, while max() only requires gt(). However, it is best to define them all so that confusion doesn't arise in other contexts.When two lists, strings or dataclasses are compared, their values get compared in order until a pair of unequal values is found. The comparison of this two values is then returned. The shorter sequence is considered smaller in case of all values being equal.For proper alphabetical order pass 'key=locale.strxfrm' to sorted() after running 'locale.setlocale(locale.LC_COLLATE, \""en_US.UTF-8\"")'.from functools import total_ordering@total_orderingclass MySortable:    def __init__(self, a):        self.a = a    def __eq__(self, other):        if isinstance(other, type(self)):            return self.a == other.a        return NotImplemented    def __lt__(self, other):        if isinstance(other, type(self)):            return self.a < other.a        return NotImplementedIteratorAny object that has methods next() and iter() is an iterator.Next() should return next item or raise StopIteration.Iter() should return 'self'.class Counter:    def __init__(self):        self.i = 0    def __next__(self):        self.i += 1        return self.i    def __iter__(self):        return self>>> counter = Counter()>>> next(counter), next(counter), next(counter)(1, 2, 3)Python has many different iterator objects:Sequence iterators returned by the iter() function, such as list_iterator and set_iterator.Objects returned by the itertools module, such as count, repeat and cycle.Generators returned by the generator functions and generator expressions.File objects returned by the open() function, etc.CallableAll functions and classes have a call() method, hence are callable.When this cheatsheet uses '<function>' as an argument, it actually means '<callable>'.class Counter:    def __init__(self):        self.i = 0    def __call__(self):        self.i += 1        return self.i>>> counter = Counter()>>> counter(), counter(), counter()(1, 2, 3)Context ManagerWith statements only work with objects that have enter() and exit() special methods.Enter() should lock the resources and optionally return an object.Exit() should release the resources.Any exception that happens inside the with block is passed to the exit() method.The exit() method can suppress the exception by returning a true value.class MyOpen:    def __init__(self, filename):        self.filename = filename    def __enter__(self):        self.file = open(self.filename)        return self.file    def __exit__(self, exc_type, exception, traceback):        self.file.close()>>> with open('test.txt', 'w') as file:...     file.write('Hello World!')>>> with MyOpen('test.txt') as file:...     print(file.read())Hello World!Iterable Duck TypesIterableOnly required method is iter(). It should return an iterator of object's items.Contains() automatically works on any object that has iter() defined.class MyIterable:    def __init__(self, a):        self.a = a    def __iter__(self):        return iter(self.a)    def __contains__(self, el):        return el in self.a>>> obj = MyIterable([1, 2, 3])>>> [el for el in obj][1, 2, 3]>>> 1 in objTrueCollectionOnly required methods are iter() and len(). Len() should return the number of items.This cheatsheet actually means '<iterable>' when it uses '<collection>'.I chose not to use the name 'iterable' because it sounds scarier and more vague than 'collection'. The only drawback of this decision is that the reader could think a certain function doesn't accept iterators when it does, since iterators are the only built-in objects that are iterable but are not collections.class MyCollection:    def __init__(self, a):        self.a = a    def __iter__(self):        return iter(self.a)    def __contains__(self, el):        return el in self.a    def __len__(self):        return len(self.a)SequenceOnly required methods are getitem() and len().Getitem() should return an item at the passed index or raise IndexError.Iter() and contains() automatically work on any object that has getitem() defined.Reversed() automatically works on any object that has getitem() and len() defined.class MySequence:    def __init__(self, a):        self.a = a    def __iter__(self):        return iter(self.a)    def __contains__(self, el):        return el in self.a    def __len__(self):        return len(self.a)    def __getitem__(self, i):        return self.a[i]    def __reversed__(self):        return reversed(self.a)Discrepancies between glossary definitions and abstract base classes:Glossary defines iterable as any object with iter() or getitem() and sequence as any object with getitem() and len(). It does not define collection.Passing ABC Iterable to isinstance() or issubclass() checks whether object/class has method iter(), while ABC Collection checks for iter(), contains() and len().ABC SequenceIt's a richer interface than the basic sequence.Extending it generates iter(), contains(), reversed(), index() and count().Unlike 'abc.Iterable' and 'abc.Collection', it is not a duck type. That is why 'issubclass(MySequence, abc.Sequence)' would return False even if MySequence had all the methods defined. It however recognizes list, tuple, range, str, bytes, bytearray, array, memoryview and deque, because they are registered as its virtual subclasses.from collections import abcclass MyAbcSequence(abc.Sequence):    def __init__(self, a):        self.a = a    def __len__(self):        return len(self.a)    def __getitem__(self, i):        return self.a[i]Table of required and automatically available special methods:+------------+------------+------------+------------+--------------+|            |  Iterable  | Collection |  Sequence  | abc.Sequence |+------------+------------+------------+------------+--------------+| iter()     |    REQ     |    REQ     |    Yes     |     Yes      || contains() |    Yes     |    Yes     |    Yes     |     Yes      || len()      |            |    REQ     |    REQ     |     REQ      || getitem()  |            |            |    REQ     |     REQ      || reversed() |            |            |    Yes     |     Yes      || index()    |            |            |            |     Yes      || count()    |            |            |            |     Yes      |+------------+------------+------------+------------+--------------+Other ABCs that generate missing methods are: MutableSequence, Set, MutableSet, Mapping and MutableMapping.Names of their required methods are stored in '<abc>.__abstractmethods__'.Enumfrom enum import Enum, autoclass <enum_name>(Enum):    <member_name> = auto()    <member_name> = <value>    <member_name> = <value>, <value>Function auto() returns an increment of the last numeric value or 1.Accessing a member named after a reserved keyword causes SyntaxError.Methods receive the member they were called on as the 'self' argument.<member> = <enum>.<member_name>           # Returns a member.<member> = <enum>['<member_name>']        # Returns a member. Raises KeyError.<member> = <enum>(<value>)                # Returns a member. Raises ValueError.<str>    = <member>.name                  # Returns member's name.<obj>    = <member>.value                 # Returns member's value.<list>   = list(<enum>)                   # Returns enum's members.<list>   = [a.name for a in <enum>]       # Returns enum's member names.<list>   = [a.value for a in <enum>]      # Returns enum's member values.<member> = random.choice(list(<enum>))    # Returns a random member.def get_next_member(member):    members = list(type(member))    index = members.index(member) + 1    return members[index % len(members)]InlineCutlery = Enum('Cutlery', 'FORK KNIFE SPOON')Cutlery = Enum('Cutlery', ['FORK', 'KNIFE', 'SPOON'])Cutlery = Enum('Cutlery', {'FORK': 1, 'KNIFE': 2, 'SPOON': 3})User-defined functions cannot be values, so they must be wrapped:from functools import partialLogicOp = Enum('LogicOp', {'AND': partial(lambda l, r: l and r),                           'OR':  partial(lambda l, r: l or r)})Exceptionstry:    <code>except <exception>:    <code>Complex Exampletry:    <code_1>except <exception_a>:    <code_2_a>except <exception_b>:    <code_2_b>else:    <code_2_c>finally:    <code_3>Code inside the 'else' block will only be executed if 'try' block had no exceptions.Code inside the 'finally' block will always be executed (unless a signal is received).All variables that are initialized in executed blocks are also visible in all subsequent blocks, as well as outside the try/except clause (only function blocks delimit scope).To catch signals use 'signal.signal(signal_number, <func>)'.Catching Exceptionsexcept <exception>: ...except <exception> as <name>: ...except (<exception>, [...]): ...except (<exception>, [...]) as <name>: ...Also catches subclasses of the exception.Use 'traceback.print_exc()' to print the error message to stderr.Use 'print(<name>)' to print just the cause of the exception (its arguments).Use 'logging.exception(<message>)' to log the passed message, followed by the full error message of the caught exception.Raising Exceptionsraise <exception>raise <exception>()raise <exception>(<el> [, ...])Re-raising caught exception:except <exception> [as <name>]:    ...    raiseException Objectarguments = <name>.argsexc_type  = <name>.__class__filename  = <name>.__traceback__.tb_frame.f_code.co_filenamefunc_name = <name>.__traceback__.tb_frame.f_code.co_nameline      = linecache.getline(filename, <name>.__traceback__.tb_lineno)trace_str = ''.join(traceback.format_tb(<name>.__traceback__))error_msg = ''.join(traceback.format_exception(type(<name>), <name>, <name>.__traceback__))Built-in ExceptionsBaseException +-- SystemExit                   # Raised by the sys.exit() function. +-- KeyboardInterrupt            # Raised when the user hits the interrupt key (ctrl-c). +-- Exception                    # User-defined exceptions should be derived from this class.      +-- ArithmeticError         # Base class for arithmetic errors such as ZeroDivisionError.      +-- AssertionError          # Raised by `assert <exp>` if expression returns false value.      +-- AttributeError          # Raised when object doesn't have requested attribute/method.      +-- EOFError                # Raised by input() when it hits an end-of-file condition.      +-- LookupError             # Base class for errors when a collection can't find an item.      |    +-- IndexError         # Raised when a sequence index is out of range.      |    +-- KeyError           # Raised when a dictionary key or set element is missing.      +-- MemoryError             # Out of memory. Could be too late to start deleting vars.      +-- NameError               # Raised when nonexistent name (variable/func/class) is used.      |    +-- UnboundLocalError  # Raised when local name is used before it's being defined.      +-- OSError                 # Errors such as FileExistsError/PermissionError (see #Open).      |    +-- ConnectionError    # Errors such as BrokenPipeError/ConnectionAbortedError.      +-- RuntimeError            # Raised by errors that don't fall into other categories.      |    +-- NotImplementedErr  # Can be raised by abstract methods or by unfinished code.      |    +-- RecursionError     # Raised when the maximum recursion depth is exceeded.      +-- StopIteration           # Raised by next() when run on an empty iterator.      +-- TypeError               # Raised when an argument is of the wrong type.      +-- ValueError              # When argument has the right type but inappropriate value.Collections and their exceptions:+-----------+------------+------------+------------+|           |    List    |    Set     |    Dict    |+-----------+------------+------------+------------+| getitem() | IndexError |            |  KeyError  || pop()     | IndexError |  KeyError  |  KeyError  || remove()  | ValueError |  KeyError  |            || index()   | ValueError |            |            |+-----------+------------+------------+------------+Useful built-in exceptions:raise TypeError('Argument is of the wrong type!')raise ValueError('Argument has the right type but an inappropriate value!')raise RuntimeError('None of above!')User-defined Exceptionsclass MyError(Exception): passclass MyInputError(MyError): passExitExits the interpreter by raising SystemExit exception.import syssys.exit()                        # Exits with exit code 0 (success).sys.exit(<el>)                    # Prints to stderr and exits with 1.sys.exit(<int>)                   # Exits with passed exit code.Printprint(<el_1>, ..., sep=' ', end='\', file=sys.stdout, flush=False)Use 'file=sys.stderr' for messages about errors.Use 'flush=True' to forcibly flush the stream.Pretty Printfrom pprint import pprintpprint(<collection>, width=80, depth=None, compact=False, sort_dicts=True)Levels deeper than 'depth' get replaced by '...'.InputReads a line from the user input or pipe if present.<str> = input(prompt=None)Trailing newline gets stripped.Prompt string is printed to the standard output before reading input.Raises EOFError when user hits EOF (ctrl-d/ctrl-z‚èé) or input stream gets exhausted.Command Line Argumentsimport sysscripts_path = sys.argv[0]arguments    = sys.argv[1:]Argument Parserfrom argparse import ArgumentParser, FileTypep = ArgumentParser(description=<str>)p.add_argument('-<short_name>', '--<name>', action='store_true')  # Flag.p.add_argument('-<short_name>', '--<name>', type=<type>)          # Option.p.add_argument('<name>', type=<type>, nargs=1)                    # First argument.p.add_argument('<name>', type=<type>, nargs='+')                  # Remaining arguments.p.add_argument('<name>', type=<type>, nargs='*')                  # Optional arguments.args  = p.parse_args()                                            # Exits on error.value = args.<name>Use 'help=<str>' to set argument description that will be displayed in help message.Use 'default=<el>' to set the default value.Use 'type=FileType(<mode>)' for files. Accepts 'encoding', but 'newline' is None.OpenOpens the file and returns a corresponding file object.<file> = open(<path>, mode='r', encoding=None, newline=None)'encoding=None' means that the default encoding is used, which is platform dependent. Best practice is to use 'encoding=\""utf-8\""' whenever possible.'newline=None' means all different end of line combinations are converted to '\' on read, while on write all '\' characters are converted to system's default line separator.'newline=\""\""' means no conversions take place, but input is still broken into chunks by readline() and readlines() on every '\', '\\r' and '\\r\'.Modes'r'  - Read (default).'w'  - Write (truncate).'x'  - Write or fail if the file already exists.'a'  - Append.'w+' - Read and write (truncate).'r+' - Read and write from the start.'a+' - Read and write from the end.'t'  - Text mode (default).'b'  - Binary mode ('br', 'bw', 'bx', ‚Ä¶).Exceptions'FileNotFoundError' can be raised when reading with 'r' or 'r+'.'FileExistsError' can be raised when writing with 'x'.'IsADirectoryError' and 'PermissionError' can be raised by any.'OSError' is the parent class of all listed exceptions.File Object<file>.seek(0)                      # Moves to the start of the file.<file>.seek(offset)                 # Moves 'offset' chars/bytes from the start.<file>.seek(0, 2)                   # Moves to the end of the file.<bin_file>.seek(¬±offset, <anchor>)  # Anchor: 0 start, 1 current position, 2 end.<str/bytes> = <file>.read(size=-1)  # Reads 'size' chars/bytes or until EOF.<str/bytes> = <file>.readline()     # Returns a line or empty string/bytes on EOF.<list>      = <file>.readlines()    # Returns a list of remaining lines.<str/bytes> = next(<file>)          # Returns a line using buffer. Do not mix.<file>.write(<str/bytes>)           # Writes a string or bytes object.<file>.writelines(<collection>)     # Writes a coll. of strings or bytes objects.<file>.flush()                      # Flushes write buffer. Runs every 4096/8192 B.Methods do not add or strip trailing newlines, not even writelines().Read Text from Filedef read_file(filename):    with open(filename, encoding='utf-8') as file:        return file.readlines()Write Text to Filedef write_to_file(filename, text):    with open(filename, 'w', encoding='utf-8') as file:        file.write(text)Pathsimport os, globfrom pathlib import Path<str>  = os.getcwd()                # Returns the current working directory.<str>  = os.path.join(<path>, ...)  # Joins two or more pathname components.<str>  = os.path.realpath(<path>)   # Resolves symlinks and calls path.abspath().<str>  = os.path.basename(<path>)   # Returns final component of the path.<str>  = os.path.dirname(<path>)    # Returns path without the final component.<tup.> = os.path.splitext(<path>)   # Splits on last period of the final component.<list> = os.listdir(path='.')       # Returns filenames located at the path.<list> = glob.glob('<pattern>')     # Returns paths matching the wildcard pattern.<bool> = os.path.exists(<path>)     # Or: <Path>.exists()<bool> = os.path.isfile(<path>)     # Or: <DirEntry/Path>.is_file()<bool> = os.path.isdir(<path>)      # Or: <DirEntry/Path>.is_dir()<stat> = os.stat(<path>)            # Or: <DirEntry/Path>.stat()<real> = <stat>.st_mtime/st_size/‚Ä¶  # Modification time, size in bytes, ...DirEntryUnlike listdir(), scandir() returns DirEntry objects that cache isfile, isdir and on Windows also stat information, thus significantly increasing the performance of code that requires it.<iter> = os.scandir(path='.')       # Returns DirEntry objects located at the path.<str>  = <DirEntry>.path            # Returns the whole path as a string.<str>  = <DirEntry>.name            # Returns final component as a string.<file> = open(<DirEntry>)           # Opens the file and returns a file object.Path Object<Path> = Path(<path> [, ...])       # Accepts strings, Paths and DirEntry objects.<Path> = <path> / <path> [/ ...]    # First or second path must be a Path object.<Path> = <Path>.resolve()           # Returns absolute path with resolved symlinks.<Path> = Path()                     # Returns relative cwd. Also Path('.').<Path> = Path.cwd()                 # Returns absolute cwd. Also Path().resolve().<Path> = Path.home()                # Returns user's home directory (absolute).<Path> = Path(__file__).resolve()   # Returns script's path if cwd wasn't changed.<Path> = <Path>.parent              # Returns Path without the final component.<str>  = <Path>.name                # Returns final component as a string.<str>  = <Path>.stem                # Returns final component without extension.<str>  = <Path>.suffix              # Returns final component's extension.<tup.> = <Path>.parts               # Returns all components as strings.<iter> = <Path>.iterdir()           # Returns directory contents as Path objects.<iter> = <Path>.glob('<pattern>')   # Returns Paths matching the wildcard pattern.<str>  = str(<Path>)                # Returns path as a string.<file> = open(<Path>)               # Also <Path>.read/write_text/bytes().OS Commandsimport os, shutil, subprocessos.chdir(<path>)                    # Changes the current working directory.os.mkdir(<path>, mode=0o777)        # Creates a directory. Permissions are in octal.os.makedirs(<path>, mode=0o777)     # Creates all path's dirs. Also `exist_ok=False`.shutil.copy(from, to)               # Copies the file. 'to' can exist or be a dir.shutil.copy2(from, to)              # Also copies creation and modification time.shutil.copytree(from, to)           # Copies the directory. 'to' must not exist.os.rename(from, to)                 # Renames/moves the file or directory.os.replace(from, to)                # Same, but overwrites file 'to' even on Windows.shutil.move(from, to)               # Rename() that moves into 'to' if it's a dir.os.remove(<path>)                   # Deletes the file.os.rmdir(<path>)                    # Deletes the empty directory.shutil.rmtree(<path>)               # Deletes the directory.Paths can be either strings, Paths or DirEntry objects.Functions report OS related errors by raising either OSError or one of its subclasses.Shell Commands<pipe> = os.popen('<command>')      # Executes command in sh/cmd. Returns its stdout pipe.<str>  = <pipe>.read(size=-1)       # Reads 'size' chars or until EOF. Also readline/s().<int>  = <pipe>.close()             # Closes the pipe. Returns None on success (returncode 0).Sends '1 + 1' to the basic calculator and captures its output:>>> subprocess.run('bc', input='1 + 1\', capture_output=True, text=True)CompletedProcess(args='bc', returncode=0, stdout='2\', stderr='')Sends test.in to the basic calculator running in standard mode and saves its output to test.out:>>> from shlex import split>>> os.popen('echo 1 + 1 > test.in')>>> subprocess.run(split('bc -s'), stdin=open('test.in'), stdout=open('test.out', 'w'))CompletedProcess(args=['bc', '-s'], returncode=0)>>> open('test.out').read()'2\'JSONText file format for storing collections of strings and numbers.import json<str>    = json.dumps(<object>)     # Converts object to JSON string.<object> = json.loads(<str>)        # Converts JSON string to object.Read Object from JSON Filedef read_json_file(filename):    with open(filename, encoding='utf-8') as file:        return json.load(file)Write Object to JSON Filedef write_to_json_file(filename, an_object):    with open(filename, 'w', encoding='utf-8') as file:        json.dump(an_object, file, ensure_ascii=False, indent=2)PickleBinary file format for storing Python objects.import pickle<bytes>  = pickle.dumps(<object>)   # Converts object to bytes object.<object> = pickle.loads(<bytes>)    # Converts bytes object to object.Read Object from Filedef read_pickle_file(filename):    with open(filename, 'rb') as file:        return pickle.load(file)Write Object to Filedef write_to_pickle_file(filename, an_object):    with open(filename, 'wb') as file:        pickle.dump(an_object, file)CSVText file format for storing spreadsheets.import csvRead<reader> = csv.reader(<file>)       # Also: `dialect='excel', delimiter=','`.<list>   = next(<reader>)           # Returns next row as a list of strings.<list>   = list(<reader>)           # Returns a list of remaining rows.File must be opened with a 'newline=\""\""' argument, or newlines embedded inside quoted fields will not be interpreted correctly!To print the spreadsheet to the console use Tabulate library.For XML and binary Excel files (xlsx, xlsm and xlsb) use Pandas library.Reader accepts any iterator of strings, not just files.Write<writer> = csv.writer(<file>)       # Also: `dialect='excel', delimiter=','`.<writer>.writerow(<collection>)     # Encodes objects using `str(<el>)`.<writer>.writerows(<coll_of_coll>)  # Appends multiple rows.File must be opened with a 'newline=\""\""' argument, or '\\r' will be added in front of every '\' on platforms that use '\\r\' line endings!Parameters'dialect' - Master parameter that sets the default values. String or a 'csv.Dialect' object.'delimiter' - A one-character string used to separate fields.'quotechar' - Character for quoting fields that contain special characters.'doublequote' - Whether quotechars inside fields are/get doubled or escaped.'skipinitialspace' - Is space character at the start of the field stripped by the reader.'lineterminator' - How writer terminates rows. Reader is hardcoded to '\', '\\r', '\\r\'.'quoting' - 0: As necessary, 1: All, 2: All but numbers which are read as floats, 3: None.'escapechar' - Character for escaping quotechars if 'doublequote' is False.Dialects+------------------+--------------+--------------+--------------+|                  |     excel    |   excel-tab  |     unix     |+------------------+--------------+--------------+--------------+| delimiter        |       ','    |      '\\t'    |       ','    || quotechar        |       '\""'    |       '\""'    |       '\""'    || doublequote      |      True    |      True    |      True    || skipinitialspace |     False    |     False    |     False    || lineterminator   |    '\\r\'    |    '\\r\'    |      '\'    || quoting          |         0    |         0    |         1    || escapechar       |      None    |      None    |      None    |+------------------+--------------+--------------+--------------+Read Rows from CSV Filedef read_csv_file(filename, dialect='excel', **params):    with open(filename, encoding='utf-8', newline='') as file:        return list(csv.reader(file, dialect, **params))Write Rows to CSV Filedef write_to_csv_file(filename, rows, dialect='excel', **params):    with open(filename, 'w', encoding='utf-8', newline='') as file:        writer = csv.writer(file, dialect, **params)        writer.writerows(rows)SQLiteA server-less database engine that stores each database into a separate file.import sqlite3<conn> = sqlite3.connect(<path>)                # Opens existing or new file. Also ':memory:'.<conn>.close()                                  # Closes the connection.Read<cursor> = <conn>.execute('<query>')            # Can raise a subclass of sqlite3.Error.<tuple>  = <cursor>.fetchone()                  # Returns next row. Also next(<cursor>).<list>   = <cursor>.fetchall()                  # Returns remaining rows. Also list(<cursor>).Write<conn>.execute('<query>')                       # Can raise a subclass of sqlite3.Error.<conn>.commit()                                 # Saves all changes since the last commit.<conn>.rollback()                               # Discards all changes since the last commit.Or:with <conn>:                                    # Exits the block with commit() or rollback(),    <conn>.execute('<query>')                   # depending on whether any exception occurred.Placeholders<conn>.execute('<query>', <list/tuple>)         # Replaces '?'s in query with values.<conn>.execute('<query>', <dict/namedtuple>)    # Replaces ':<key>'s with values.<conn>.executemany('<query>', <coll_of_above>)  # Runs execute() multiple times.Passed values can be of type str, int, float, bytes, None, bool, datetime.date or datetime.datetime.Bools will be stored and returned as ints and dates as ISO formatted strings.ExampleValues are not actually saved in this example because 'conn.commit()' is omitted!>>> conn = sqlite3.connect('test.db')>>> conn.execute('CREATE TABLE person (person_id INTEGER PRIMARY KEY, name, height)')>>> conn.execute('INSERT INTO person VALUES (NULL, ?, ?)', ('Jean-Luc', 187)).lastrowid1>>> conn.execute('SELECT * FROM person').fetchall()[(1, 'Jean-Luc', 187)]SqlAlchemy# $ pip3 install sqlalchemyfrom sqlalchemy import create_engine, text<engine> = create_engine('<url>')               # Url: 'dialect://user:password@host/dbname'.<conn>   = <engine>.connect()                   # Creates a connection. Also <conn>.close().<cursor> = <conn>.execute(text('<query>'), ‚Ä¶)   # Replaces ':<key>'s with keyword arguments.with <conn>.begin(): ...                        # Exits the block with commit or rollback.+------------+--------------+----------+----------------------------------+| Dialect    | pip3 install | import   |           Dependencies           |+------------+--------------+----------+----------------------------------+| mysql      | mysqlclient  | MySQLdb  | www.pypi.org/project/mysqlclient || postgresql | psycopg2     | psycopg2 | www.pypi.org/project/psycopg2    || mssql      | pyodbc       | pyodbc   | www.pypi.org/project/pyodbc      || oracle     | oracledb     | oracledb | www.pypi.org/project/oracledb    |+------------+--------------+----------+----------------------------------+BytesBytes object is an immutable sequence of single bytes. Mutable version is called bytearray.<bytes> = b'<str>'                          # Only accepts ASCII characters and \\x00-\\xff.<int>   = <bytes>[<index>]                  # Returns an int in range from 0 to 255.<bytes> = <bytes>[<slice>]                  # Returns bytes even if it has only one element.<bytes> = <bytes>.join(<coll_of_bytes>)     # Joins elements using bytes as a separator.Encode<bytes> = bytes(<coll_of_ints>)             # Ints must be in range from 0 to 255.<bytes> = bytes(<str>, 'utf-8')             # Or: <str>.encode('utf-8')<bytes> = <int>.to_bytes(n_bytes, ‚Ä¶)        # `byteorder='big/little', signed=False`.<bytes> = bytes.fromhex('<hex>')            # Hex pairs can be separated by whitespaces.Decode<list>  = list(<bytes>)                     # Returns ints in range from 0 to 255.<str>   = str(<bytes>, 'utf-8')             # Or: <bytes>.decode('utf-8')<int>   = int.from_bytes(<bytes>, ‚Ä¶)        # `byteorder='big/little', signed=False`.'<hex>' = <bytes>.hex()                     # Returns hex pairs. Accepts `sep=<str>`.Read Bytes from Filedef read_bytes(filename):    with open(filename, 'rb') as file:        return file.read()Write Bytes to Filedef write_bytes(filename, bytes_obj):    with open(filename, 'wb') as file:        file.write(bytes_obj)StructModule that performs conversions between a sequence of numbers and a bytes object.System‚Äôs type sizes, byte order, and alignment rules are used by default.from struct import pack, unpack<bytes> = pack('<format>', <el_1> [, ...])  # Packages arguments or raises struct.error.<tuple> = unpack('<format>', <bytes>)       # Use iter_unpack() for iterator of tuples.>>> pack('>hhl', 1, 2, 3)b'\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x03'>>> unpack('>hhl', b'\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x03')(1, 2, 3)FormatFor standard type sizes and manual alignment (padding) start format string with:'=' - System's byte order (usually little-endian).'<' - Little-endian.'>' - Big-endian (also '!').Besides numbers, pack() and unpack() also support bytes objects as part of the sequence:'c' - A bytes object with a single element. For pad byte use 'x'.'<n>s' - A bytes object with n elements.Integer types. Use a capital letter for unsigned type. Minimum and standard sizes are in brackets:'b' - char (1/1)'h' - short (2/2)'i' - int (2/4)'l' - long (4/4)'q' - long long (8/8)Floating point types (struct always uses standard sizes):'f' - float (4/4)'d' - double (8/8)ArrayList that can only hold numbers of a predefined type. Available types and their minimum sizes in bytes are listed above. Sizes and byte order are always determined by the system, however bytes of each element can be swapped with byteswap() method.from array import array<array> = array('<typecode>', <collection>)    # Array from collection of numbers.<array> = array('<typecode>', <bytes>)         # Array from bytes object.<array> = array('<typecode>', <array>)         # Treats array as a sequence of numbers.<bytes> = bytes(<array>)                       # Or: <array>.tobytes()<file>.write(<array>)                          # Writes array to the binary file.Memory ViewA sequence object that points to the memory of another bytes-like object.Each element can reference a single or multiple consecutive bytes, depending on format.Order and number of elements can be changed with slicing.Casting only works between char and other types and uses system's sizes.Byte order is always determined by the system.<mview> = memoryview(<bytes/bytearray/array>)  # Immutable if bytes, else mutable.<real>  = <mview>[<index>]                     # Returns an int or a float.<mview> = <mview>[<slice>]                     # Mview with rearranged elements.<mview> = <mview>.cast('<typecode>')           # Casts memoryview to the new format.<mview>.release()                              # Releases the object's memory buffer.<bytes> = bytes(<mview>)                       # Returns a new bytes object.<bytes> = <bytes>.join(<coll_of_mviews>)       # Joins mviews using bytes object as sep.<array> = array('<typecode>', <mview>)         # Treats mview as a sequence of numbers.<file>.write(<mview>)                          # Writes mview to the binary file.<list>  = list(<mview>)                        # Returns a list of ints or floats.<str>   = str(<mview>, 'utf-8')                # Treats mview as a bytes object.<int>   = int.from_bytes(<mview>, ‚Ä¶)           # `byteorder='big/little', signed=False`.'<hex>' = <mview>.hex()                        # Treats mview as a bytes object.DequeA thread-safe list with efficient appends and pops from either side. Pronounced \""deck\"".from collections import deque<deque> = deque(<collection>)                  # Also `maxlen=None`.<deque>.appendleft(<el>)                       # Opposite element is dropped if full.<deque>.extendleft(<collection>)               # Collection gets reversed.<el> = <deque>.popleft()                       # Raises IndexError if empty.<deque>.rotate(n=1)                            # Rotates elements to the right.ThreadingCPython interpreter can only run a single thread at a time.That is why using multiple threads won't result in a faster execution, unless at least one of the threads contains an I/O operation.from threading import Thread, RLock, Semaphore, Event, Barrierfrom concurrent.futures import ThreadPoolExecutor, as_completedThread<Thread> = Thread(target=<function>)           # Use `args=<collection>` to set the arguments.<Thread>.start()                               # Starts the thread.<bool> = <Thread>.is_alive()                   # Checks if the thread has finished executing.<Thread>.join()                                # Waits for the thread to finish.Use 'kwargs=<dict>' to pass keyword arguments to the function.Use 'daemon=True', or the program will not be able to exit while the thread is alive.Lock<lock> = RLock()                               # Lock that can only be released by acquirer.<lock>.acquire()                               # Waits for the lock to be available.<lock>.release()                               # Makes the lock available again.Or:with <lock>:                                   # Enters the block by calling acquire() and    ...                                        # exits it with release(), even on error.Semaphore, Event, Barrier<Semaphore> = Semaphore(value=1)               # Lock that can be acquired by 'value' threads.<Event>     = Event()                          # Method wait() blocks until set() is called.<Barrier>   = Barrier(n_times)                 # Wait() blocks until it's called n_times.Queue<Queue> = queue.Queue(maxsize=0)               # A thread-safe FIFO queue. Also LifoQueue.<Queue>.put(<el>)                              # Blocks until queue stops being full.<Queue>.put_nowait(<el>)                       # Raises queue.Full exception if full.<el> = <Queue>.get()                           # Blocks until queue stops being empty.<el> = <Queue>.get_nowait()                    # Raises queue.Empty exception if empty.Thread Pool Executor<Exec> = ThreadPoolExecutor(max_workers=None)  # Or: `with ThreadPoolExecutor() as <name>: ‚Ä¶`<iter> = <Exec>.map(<func>, <args_1>, ...)     # Multithreaded and non-lazy map(). Keeps order.<Futr> = <Exec>.submit(<func>, <arg_1>, ...)   # Creates a thread and returns its Future obj.<Exec>.shutdown(wait=True)                     # Blocks until all threads finish executing.<bool> = <Future>.done()                       # Checks if the thread has finished executing.<obj>  = <Future>.result(timeout=None)         # Waits for thread to finish and returns result.<bool> = <Future>.cancel()                     # Returns False if thread is already running.<iter> = as_completed(<coll_of_Futures>)       # Each Future is yielded as it completes.Map() and as_completed() also accept 'timeout' argument that causes TimeoutError if result isn't available in 'timeout' seconds after next() is called.Exceptions that happen inside threads are raised when next() is called on map's iterator or when result() is called on a Future. Its exception() method returns exception or None.ProcessPoolExecutor provides true parallelism, but everything sent to/from workers must be pickable. Queues must be sent using executor's 'initargs' and 'initializer' parameters.OperatorModule of functions that provide the functionality of operators. Functions are ordered by operator precedence, starting with least binding.import operator as op<bool> = op.not_(<obj>)                                        # not (or/and are not provided)<bool> = op.eq/ne/lt/le/gt/ge/contains(<obj>, <obj>)           # ==, !=, <, <=, >, >=, in<obj>  = op.or_/xor/and_(<int/set>, <int/set>)                 # |, ^, &<obj>  = op.add/sub/mul/truediv/floordiv/mod(<obj>, <obj>)     # +, -, *, /, //, %<num>  = op.neg/invert(<num>)                                  # -, ~<num>  = op.pow(<num>, <num>)                                  # **<func> = op.itemgetter/attrgetter/methodcaller(<obj> [, ...])  # [index/key], .name, .name()elementwise_sum  = map(op.add, list_a, list_b)sorted_by_second = sorted(<collection>, key=op.itemgetter(1))sorted_by_both   = sorted(<collection>, key=op.itemgetter(1, 0))product_of_elems = functools.reduce(op.mul, <collection>)union_of_sets    = functools.reduce(op.or_, <coll_of_sets>)first_element    = op.methodcaller('pop', 0)(<list>)Bitwise operators require objects to have and(), or() and xor() special methods, unlike logical operators that work on all types of objects.Also: '<bool> = <bool> &|^ <bool>' and '<int> = <bool> &|^ <int>'.Introspection<list> = dir()                             # Names of local variables, functions, classes, etc.<dict> = vars()                            # Dict of local variables, etc. Also locals().<dict> = globals()                         # Dict of global vars, etc. (incl. '__builtins__').Attributes<list> = dir(<object>)                     # Names of object's attributes (incl. methods).<dict> = vars(<object>)                    # Dict of writable attributes. Also <obj>.__dict__.<bool> = hasattr(<object>, '<attr_name>')  # Checks if getattr() raises an AttributeError.value  = getattr(<object>, '<attr_name>')  # Raises AttributeError if attribute is missing.setattr(<object>, '<attr_name>', value)    # Only works on objects with '__dict__' attribute.delattr(<object>, '<attr_name>')           # Same. Also `del <object>.<attr_name>`.Parameters<Sig>  = inspect.signature(<function>)     # Function's Signature object.<dict> = <Sig>.parameters                  # Dict of Parameter objects.<memb> = <Param>.kind                      # Member of ParameterKind enum.<obj>  = <Param>.default                   # Default value or Parameter.empty.<type> = <Param>.annotation                # Type or Parameter.empty.MetaprogrammingCode that generates code.TypeType is the root class. If only passed an object it returns its type (class). Otherwise it creates a new class.<class> = type('<class_name>', <tuple_of_parents>, <dict_of_class_attributes>)>>> Z = type('Z', (), {'a': 'abcde', 'b': 12345})>>> z = Z()Meta ClassA class that creates classes.def my_meta_class(name, parents, attrs):    attrs['a'] = 'abcde'    return type(name, parents, attrs)Or:class MyMetaClass(type):    def __new__(cls, name, parents, attrs):        attrs['a'] = 'abcde'        return type.__new__(cls, name, parents, attrs)New() is a class method that gets called before init(). If it returns an instance of its class, then that instance gets passed to init() as a 'self' argument.It receives the same arguments as init(), except for the first one that specifies the desired type of the returned instance (MyMetaClass in our case).Like in our case, new() can also be called directly, usually from a new() method of a child class (def __new__(cls): return super().__new__(cls)).The only difference between the examples above is that my_meta_class() returns a class of type type, while MyMetaClass() returns a class of type MyMetaClass.Metaclass AttributeRight before a class is created it checks if it has the 'metaclass' attribute defined. If not, it recursively checks if any of its parents has it defined and eventually comes to type().class MyClass(metaclass=MyMetaClass):    b = 12345>>> MyClass.a, MyClass.b('abcde', 12345)Type Diagramtype(MyClass) == MyMetaClass         # MyClass is an instance of MyMetaClass.type(MyMetaClass) == type            # MyMetaClass is an instance of type.+-------------+-------------+|   Classes   | Metaclasses |+-------------+-------------||   MyClass <-- MyMetaClass ||             |     ^       ||    object <----- type <+  ||             |     | +--+  ||     str <---------+       |+-------------+-------------+Inheritance DiagramMyClass.__base__ == object           # MyClass is a subclass of object.MyMetaClass.__base__ == type         # MyMetaClass is a subclass of type.+-------------+-------------+|   Classes   | Metaclasses |+-------------+-------------||   MyClass   | MyMetaClass ||      ^      |     ^       ||    object -----> type     ||      v      |             ||     str     |             |+-------------+-------------+Eval>>> from ast import literal_eval>>> literal_eval('[1, 2, 3]')[1, 2, 3]>>> literal_eval('1 + 2')ValueError: malformed node or stringCoroutinesCoroutines have a lot in common with threads, but unlike threads, they only give up control when they call another coroutine and they don‚Äôt use as much memory.Coroutine definition starts with 'async' and its call with 'await'.'asyncio.run(<coroutine>)' is the main entry point for asynchronous programs.Functions wait(), gather() and as_completed() start multiple coroutines at the same time.Asyncio module also provides its own Queue, Event, Lock and Semaphore classes.Runs a terminal game where you control an asterisk that must avoid numbers:import asyncio, collections, curses, curses.textpad, enum, randomP = collections.namedtuple('P', 'x y')         # PositionD = enum.Enum('D', 'n e s w')                  # DirectionW, H = 15, 7                                   # Width, Heightdef main(screen):    curses.curs_set(0)                         # Makes cursor invisible.    screen.nodelay(True)                       # Makes getch() non-blocking.    asyncio.run(main_coroutine(screen))        # Starts running asyncio code.async def main_coroutine(screen):    moves = asyncio.Queue()    state = {'*': P(0, 0), **{id_: P(W//2, H//2) for id_ in range(10)}}    ai    = [random_controller(id_, moves) for id_ in range(10)]    mvc   = [human_controller(screen, moves), model(moves, state), view(state, screen)]    tasks = [asyncio.create_task(cor) for cor in ai + mvc]    await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)async def random_controller(id_, moves):    while True:        d = random.choice(list(D))        moves.put_nowait((id_, d))        await asyncio.sleep(random.triangular(0.01, 0.65))async def human_controller(screen, moves):    while True:        key_mappings = {258: D.s, 259: D.n, 260: D.w, 261: D.e}        if d := key_mappings.get(screen.getch()):            moves.put_nowait(('*', d))        await asyncio.sleep(0.005)async def model(moves, state):    while state['*'] not in (state[id_] for id_ in range(10)):        id_, d = await moves.get()        x, y   = state[id_]        deltas = {D.n: P(0, -1), D.e: P(1, 0), D.s: P(0, 1), D.w: P(-1, 0)}        state[id_] = P((x + deltas[d].x) % W, (y + deltas[d].y) % H)async def view(state, screen):    offset = P(curses.COLS//2 - W//2, curses.LINES//2 - H//2)    while True:        screen.erase()        curses.textpad.rectangle(screen, offset.y-1, offset.x-1, offset.y+H, offset.x+W)        for id_, p in state.items():            screen.addstr(offset.y + (p.y - state['*'].y + H//2) % H,                          offset.x + (p.x - state['*'].x + W//2) % W, str(id_))        screen.refresh()        await asyncio.sleep(0.005)if __name__ == '__main__':    curses.wrapper(main)LibrariesProgress Bar# $ pip3 install tqdm>>> from tqdm import tqdm>>> from time import sleep>>> for el in tqdm([1, 2, 3], desc='Processing'):...     sleep(1)Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.00s/it]Plot# $ pip3 install matplotlibimport matplotlib.pyplot as pltplt.plot/bar/scatter(x_data, y_data [, label=<str>])  # Or: plt.plot(y_data)plt.legend()                                          # Adds a legend.plt.savefig(<path>)                                   # Saves the figure.plt.show()                                            # Displays the figure.plt.clf()                                             # Clears the figure.TablePrints a CSV file as an ASCII table:# $ pip3 install tabulateimport csv, tabulatewith open('test.csv', encoding='utf-8', newline='') as file:    rows   = csv.reader(file)    header = next(rows)    table  = tabulate.tabulate(rows, header)print(table)CursesRuns a basic file explorer in the terminal:import curses, osfrom curses import A_REVERSE, KEY_DOWN, KEY_UP, KEY_LEFT, KEY_RIGHT, KEY_ENTERdef main(screen):    ch, first, selected, paths = 0, 0, 0, os.listdir()    while ch != ord('q'):        height, width = screen.getmaxyx()        screen.erase()        for y, filename in enumerate(paths[first : first+height]):            color = A_REVERSE if filename == paths[selected] else 0            screen.addnstr(y, 0, filename, width-1, color)        ch = screen.getch()        selected += (ch == KEY_DOWN) - (ch == KEY_UP)        selected = max(0, min(len(paths)-1, selected))        first += (selected >= first + height) - (selected < first)        if ch in [KEY_LEFT, KEY_RIGHT, KEY_ENTER, ord('\'), ord('\\r')]:            new_dir = '..' if ch == KEY_LEFT else paths[selected]            if os.path.isdir(new_dir):                os.chdir(new_dir)                first, selected, paths = 0, 0, os.listdir()if __name__ == '__main__':    curses.wrapper(main)Loggingimport logginglogging.basicConfig(filename=<path>)              # Configures the root logger.logging.debug/info/warning/error/critical(<str>)  # Logs to the root logger.<Logger> = logging.getLogger(__name__)            # Logger named after the module.<Logger>.<level>(<str>)                           # Messages propagate to the root logger.<Logger>.exception(<str>)                         # Calls error() with caught exception.Setuplogging.basicConfig(    filename=None,                                # Logs to console by default.    format='%(levelname)s:%(name)s:%(message)s',  # Add `%(asctime)s` for datetime.    level=logging.WARNING,                        # Drops messages with lower priority.    handlers=[logging.StreamHandler()]            # Uses FileHandler if filename is set.)<Formatter> = logging.Formatter('<format>')       # Creates a Formatter.<Handler> = logging.FileHandler(<path>)           # Creates a Handler.<Handler>.setFormatter(<Formatter>)               # Adds Formatter to the Handler.<Handler>.setLevel(<int/str>)                     # Processes all messages by default.<Logger>.addHandler(<Handler>)                    # Adds Handler to the Logger.<Logger>.setLevel(<int/str>)                      # What is sent to handlers and parent.Parent logger can be specified by naming the child logger '<parent>.<name>'.Formatter also supports: pathname, filename, funcName, lineno, thread and process.A 'handlers.RotatingFileHandler' creates and deletes log files based on 'maxBytes' and 'backupCount' arguments.Creates a logger that writes all messages to a file and sends them to the root logger that prints to stdout:>>> logging.basicConfig(level='WARNING')>>> logger = logging.getLogger('my_module')>>> handler = logging.FileHandler('test.log')>>> formatter = logging.Formatter('%(asctime)s %(levelname)s:%(name)s:%(message)s')>>> handler.setFormatter(formatter)>>> logger.addHandler(handler)>>> logger.critical('Running out of disk space.')CRITICAL:my_module:Running out of disk space.>>> print(open('test.log').read())2023-02-07 23:21:01,430 CRITICAL:my_module:Running out of disk space.ScrapingScrapes Python's URL, version number and logo from its Wikipedia page:# $ pip3 install requests beautifulsoup4import requests, bs4, os, sysWIKI_URL = 'https://en.wikipedia.org/wiki/Python_(programming_language)'try:    html       = requests.get(WIKI_URL).text    document   = bs4.BeautifulSoup(html, 'html.parser')    table      = document.find('table', class_='infobox vevent')    python_url = table.find('th', text='Website').next_sibling.a['href']    version    = table.find('th', text='Stable release').next_sibling.strings.__next__()    logo_url   = table.find('img')['src']    logo       = requests.get(f'https:{logo_url}').content    filename   = os.path.basename(logo_url)    with open(filename, 'wb') as file:        file.write(logo)    print(f'{python_url}, {version}, file://{os.path.abspath(filename)}')except requests.exceptions.ConnectionError:    print(\""You've got problems with connection.\"", file=sys.stderr)WebFlask is a micro web framework/server. If you just want to open a html file in a web browser use 'webbrowser.open(<path>)' instead.# $ pip3 install flaskfrom flask import Flask, send_from_directory, render_template_string, requestapp = Flask(__name__)app.run(host=None, port=None, debug=None)Starts the app at 'http://localhost:5000'. Use 'host=\""0.0.0.0\""' to run externally.Install a WSGI server like Waitress and a HTTP server such as Nginx for better security.Debug mode restarts the app whenever script changes and displays errors in the browser.Static Request@app.route('/img/<path:filename>')def serve_file(filename):    return send_from_directory('dirname/', filename)Dynamic Request@app.route('/<sport>')def serve_html(sport):    return render_template_string('<h1>{{title}}</h1>', title=sport)To return an error code use 'abort(<int>)' and to redirect use 'redirect(<url>)'.'request.args[<str>]' returns parameter from the query string (URL part after '?').Use 'session[key] = value' to store session data like username, etc.REST Request@app.post('/<sport>/odds')def serve_json(sport):    team = request.form['team']    return {'team': team, 'odds': [2.09, 3.74, 3.68]}Starts the app in its own thread and queries it with a post request:# $ pip3 install requests>>> import threading, requests>>> threading.Thread(target=app.run, daemon=True).start()>>> url = 'http://localhost:5000/football/odds'>>> request_data = {'team': 'arsenal f.c.'}>>> response = requests.post(url, data=request_data)>>> response.json(){'team': 'arsenal f.c.', 'odds': [2.09, 3.74, 3.68]}Profilingfrom time import perf_counterstart_time = perf_counter()...duration_in_seconds = perf_counter() - start_timeTiming a Snippet>>> from timeit import timeit>>> timeit('list(range(10000))', number=1000, globals=globals(), setup='pass')0.19373Profiling by Line$ pip3 install line_profiler$ echo '@profiledef main():    a = list(range(10000))    b = set(range(10000))main()' > test.py$ kernprof -lv test.pyLine #   Hits     Time  Per Hit   % Time  Line Contents=======================================================     1                                    @profile     2                                    def main():     3      1    219.0    219.0     31.1      a = list(range(10000))     4      1    487.0    487.0     68.9      b = set(range(10000))Call and Flame Graphs$ pip3 install gprof2dot snakeviz; apt/brew install graphviz$ tail -n 4 test.py > test.py$ python3 -m cProfile -o test.prof test.py$ gprof2dot -f pstats test.prof | dot -Tpng -o test.png; xdg-open/open test.png$ snakeviz test.profSampling and Memory Profilers+--------------+-------------------------------+------------+----------+------+| pip3 install |          How to run           |   Target   |   Type   | Live |+--------------+-------------------------------+------------+----------+------+| py-spy       | py-spy top -- python3 test.py |    CPU     | Sampling | Yes  || pyinstrument | pyinstrument test.py          |    CPU     | Sampling | No   || scalene      | scalene test.py               | CPU+Memory | Sampling | No   || memray       | memray run --live test.py     |   Memory   | Tracing  | Yes  || filprofiler  | fil-profile run test.py       |   Memory   | Tracing  | No   |+--------------+-------------------------------+------------+----------+------+NumPyArray manipulation mini-language. It can run up to one hundred times faster than the equivalent Python code. An even faster alternative that runs on a GPU is called CuPy.# $ pip3 install numpyimport numpy as np<array> = np.array(<list/list_of_lists/‚Ä¶>)              # Returns a 1d/2d/‚Ä¶ NumPy array.<array> = np.zeros/ones/empty(<shape>)                  # Also np.full(<shape>, <el>).<array> = np.arange(from_inc, to_exc, ¬±step)            # Also np.linspace(start, stop, len).<array> = np.random.randint(from_inc, to_exc, <shape>)  # Also np.random.random(<shape>).<view>  = <array>.reshape(<shape>)                      # Also `<array>.shape = <shape>`.<array> = <array>.flatten()                             # Also `<view> = <array>.ravel()`.<view>  = <array>.transpose()                           # Or: <array>.T<array> = np.copy/abs/sqrt/log/int64(<array>)           # Returns new array of the same shape.<array> = <array>.sum/max/mean/argmax/all(axis)         # Passed dimension gets aggregated.<array> = np.apply_along_axis(<func>, axis, <array>)    # Func can return a scalar or array.<array> = np.concatenate(<list_of_arrays>, axis=0)      # Links arrays along first axis (rows).<array> = np.row_stack/column_stack(<list_of_arrays>)   # Treats 1d arrays as rows or columns.<array> = np.tile/repeat(<array>, <int/list>)           # Tiles array or repeats its elements.Shape is a tuple of dimension sizes. A 100x50 RGB image has shape (50, 100, 3).Axis is an index of the dimension that gets aggregated. Leftmost dimension has index 0. Summing the RGB image along axis 2 will return a greyscale image with shape (50, 100).Indexing<el>       = <2d_array>[row_index, column_index]        # <3d_a>[table_i, row_i, column_i]<1d_view>  = <2d_array>[row_index]                      # <3d_a>[table_i, row_i]<1d_view>  = <2d_array>[:, column_index]                # <3d_a>[table_i, :, column_i]<2d_view>  = <2d_array>[rows_slice, columns_slice]      # <3d_a>[table_i, rows_s, columns_s]<2d_array> = <2d_array>[row_indexes]                    # <3d_a>[table_i/is, row_is]<2d_array> = <2d_array>[:, column_indexes]              # <3d_a>[table_i/is, :, column_is]<1d_array> = <2d_array>[row_indexes, column_indexes]    # <3d_a>[table_i/is, row_is, column_is]<1d_array> = <2d_array>[row_indexes, column_index]      # <3d_a>[table_i/is, row_is, column_i]<2d_bools> = <2d_array> ><== <el/1d/2d_array>           # 1d_array must have size of a row.<1d/2d_a>  = <2d_array>[<2d/1d_bools>]                  # 1d_bools must have size of a column.Indexes should not be tuples because Python converts 'obj[i, j]'  to 'obj[(i, j)]'!Any value that is broadcastable to the indexed shape can be assigned to the selection.BroadcastingSet of rules by which NumPy functions operate on arrays of different sizes and/or dimensions.left  = [[0.1], [0.6], [0.8]]                           # Shape: (3, 1)right = [ 0.1 ,  0.6 ,  0.8 ]                           # Shape: (3,)1. If array shapes differ in length, left-pad the shorter shape with ones:left  = [[0.1], [0.6], [0.8]]                           # Shape: (3, 1)right = [[0.1 ,  0.6 ,  0.8]]                           # Shape: (1, 3) <- !2. If any dimensions differ in size, expand the ones that have size 1 by duplicating their elements:left  = [[0.1,  0.1,  0.1],                             # Shape: (3, 3) <- !         [0.6,  0.6,  0.6],         [0.8,  0.8,  0.8]]right = [[0.1,  0.6,  0.8],                             # Shape: (3, 3) <- !         [0.1,  0.6,  0.8],         [0.1,  0.6,  0.8]]ExampleFor each point returns index of its nearest point ([0.1, 0.6, 0.8] => [1, 2, 1]):>>> points = np.array([0.1, 0.6, 0.8]) [ 0.1,  0.6,  0.8]>>> wrapped_points = points.reshape(3, 1)[[ 0.1], [ 0.6], [ 0.8]]>>> distances = wrapped_points - points[[ 0. , -0.5, -0.7], [ 0.5,  0. , -0.2], [ 0.7,  0.2,  0. ]]>>> distances = np.abs(distances)[[ 0. ,  0.5,  0.7], [ 0.5,  0. ,  0.2], [ 0.7,  0.2,  0. ]]>>> i = np.arange(3)[0, 1, 2]>>> distances[i, i] = np.inf[[ inf,  0.5,  0.7], [ 0.5,  inf,  0.2], [ 0.7,  0.2,  inf]]>>> distances.argmin(1)[1, 2, 1]Image# $ pip3 install pillowfrom PIL import Image, ImageDraw<Image> = Image.new('<mode>', (width, height))  # Also `color=<int/tuple/str>`.<Image> = Image.open(<path>)                    # Identifies format based on file contents.<Image> = <Image>.convert('<mode>')             # Converts image to the new mode.<Image>.save(<path>)                            # Selects format based on the path extension.<Image>.show()                                  # Opens image in the default preview app.<int/tuple> = <Image>.getpixel((x, y))          # Returns a pixel.<Image>.putpixel((x, y), <int/tuple>)           # Writes a pixel to the image.<ImagingCore> = <Image>.getdata()               # Returns a flattened view of the pixels.<Image>.putdata(<list/ImagingCore>)             # Writes a flattened sequence of pixels.<Image>.paste(<Image>, (x, y))                  # Writes passed image to the image.<Image> = <Image>.filter(<Filter>)              # `<Filter> = ImageFilter.<name>([<args>])`<Image> = <Enhance>.enhance(<float>)            # `<Enhance> = ImageEnhance.<name>(<Image>)`<array> = np.array(<Image>)                     # Creates NumPy array from the image.<Image> = Image.fromarray(np.uint8(<array>))    # Use <array>.clip(0, 255) to clip the values.Modes'1' - 1-bit pixels, black and white, stored with one pixel per byte.'L' - 8-bit pixels, greyscale.'RGB' - 3x8-bit pixels, true color.'RGBA' - 4x8-bit pixels, true color with transparency mask.'HSV' - 3x8-bit pixels, Hue, Saturation, Value color space.ExamplesCreates a PNG image of a rainbow gradient:WIDTH, HEIGHT = 100, 100n_pixels = WIDTH * HEIGHThues = (255 * i/n_pixels for i in range(n_pixels))img = Image.new('HSV', (WIDTH, HEIGHT))img.putdata([(int(h), 255, 255) for h in hues])img.convert('RGB').save('test.png')Adds noise to a PNG image and displays it:from random import randintadd_noise = lambda value: max(0, min(255, value + randint(-20, 20)))img = Image.open('test.png').convert('HSV')img.putdata([(add_noise(h), s, v) for h, s, v in img.getdata()])img.show()Image Draw<ImageDraw> = ImageDraw.Draw(<Image>)           # Object for adding 2D graphics to the image.<ImageDraw>.point((x, y))                       # Draws a point. Truncates floats into ints.<ImageDraw>.line((x1, y1, x2, y2 [, ...]))      # To get anti-aliasing use Image's resize().<ImageDraw>.arc((x1, y1, x2, y2), deg1, deg2)   # Always draws in clockwise direction.<ImageDraw>.rectangle((x1, y1, x2, y2))         # To rotate use Image's rotate() and paste().<ImageDraw>.polygon((x1, y1, x2, y2, ...))      # Last point gets connected to the first.<ImageDraw>.ellipse((x1, y1, x2, y2))           # To rotate use Image's rotate() and paste().<ImageDraw>.text((x, y), text, font=<Font>)     # `<Font> = ImageFont.truetype(<path>, size)`Use 'fill=<color>' to set the primary color.Use 'width=<int>' to set the width of lines or contours.Use 'outline=<color>' to set the color of the contours.Color can be an int, tuple, '#rrggbb[aa]' string or a color name.AnimationCreates a GIF of a bouncing ball:# $ pip3 install imageiofrom PIL import Image, ImageDrawimport imageioWIDTH, HEIGHT, R = 126, 126, 10frames = []for velocity in range(1, 16):    y = sum(range(velocity))    frame = Image.new('L', (WIDTH, HEIGHT))    draw  = ImageDraw.Draw(frame)    draw.ellipse((WIDTH/2-R, y, WIDTH/2+R, y+R*2), fill='white')    frames.append(frame)frames += reversed(frames[1:-1])imageio.mimsave('test.gif', frames, duration=0.03)Audioimport wave<Wave_read>  = wave.open('<path>', 'rb')        # Opens the WAV file.framerate    = <Wave_read>.getframerate()       # Number of frames per second.nchannels    = <Wave_read>.getnchannels()       # Number of samples per frame.sampwidth    = <Wave_read>.getsampwidth()       # Sample size in bytes.nframes      = <Wave_read>.getnframes()         # Number of frames.<params>     = <Wave_read>.getparams()          # Immutable collection of above.<bytes>      = <Wave_read>.readframes(nframes)  # Returns next 'nframes' frames.<Wave_write> = wave.open('<path>', 'wb')        # Truncates existing file.<Wave_write>.setframerate(<int>)                # 44100 for CD, 48000 for video.<Wave_write>.setnchannels(<int>)                # 1 for mono, 2 for stereo.<Wave_write>.setsampwidth(<int>)                # 2 for CD quality sound.<Wave_write>.setparams(<params>)                # Sets all parameters.<Wave_write>.writeframes(<bytes>)               # Appends frames to the file.Bytes object contains a sequence of frames, each consisting of one or more samples.In a stereo signal, the first sample of a frame belongs to the left channel.Each sample consists of one or more bytes that, when converted to an integer, indicate the displacement of a speaker membrane at a given moment.If sample width is one byte, then the integer should be encoded unsigned.For all other sizes, the integer should be encoded signed with little-endian byte order.Sample Values+-----------+-----------+------+-----------+| sampwidth |    min    | zero |    max    |+-----------+-----------+------+-----------+|     1     |         0 |  128 |       255 ||     2     |    -32768 |    0 |     32767 ||     3     |  -8388608 |    0 |   8388607 |+-----------+-----------+------+-----------+Read Float Samples from WAV Filedef read_wav_file(filename):    def get_int(bytes_obj):        an_int = int.from_bytes(bytes_obj, 'little', signed=(sampwidth != 1))        return an_int - 128 * (sampwidth == 1)    with wave.open(filename, 'rb') as file:        sampwidth = file.getsampwidth()        frames = file.readframes(-1)    bytes_samples = (frames[i : i+sampwidth] for i in range(0, len(frames), sampwidth))    return [get_int(b) / pow(2, sampwidth * 8 - 1) for b in bytes_samples]Write Float Samples to WAV Filedef write_to_wav_file(filename, float_samples, nchannels=1, sampwidth=2, framerate=44100):    def get_bytes(a_float):        a_float = max(-1, min(1 - 2e-16, a_float))        a_float += sampwidth == 1        a_float *= pow(2, sampwidth * 8 - 1)        return int(a_float).to_bytes(sampwidth, 'little', signed=(sampwidth != 1))    with wave.open(filename, 'wb') as file:        file.setnchannels(nchannels)        file.setsampwidth(sampwidth)        file.setframerate(framerate)        file.writeframes(b''.join(get_bytes(f) for f in float_samples))ExamplesSaves a 440 Hz sine wave to a mono WAV file:from math import pi, sinsamples_f = (sin(i * 2 * pi * 440 / 44100) for i in range(100_000))write_to_wav_file('test.wav', samples_f)Adds noise to a mono WAV file:from random import randomadd_noise = lambda value: value + (random() - 0.5) * 0.03samples_f = (add_noise(f) for f in read_wav_file('test.wav'))write_to_wav_file('test.wav', samples_f)Plays a WAV file:# $ pip3 install simpleaudiofrom simpleaudio import play_bufferwith wave.open('test.wav', 'rb') as file:    p = file.getparams()    frames = file.readframes(-1)    play_buffer(frames, p.nchannels, p.sampwidth, p.framerate)Text to Speech# $ pip3 install pyttsx3import pyttsx3engine = pyttsx3.init()engine.say('Sally sells seashells by the seashore.')engine.runAndWait()SynthesizerPlays Popcorn by Gershon Kingsley:# $ pip3 install simpleaudioimport array, itertools as it, math, simpleaudioF  = 44100P1 = '71‚ô©,69‚ô™,,71‚ô©,66‚ô™,,62‚ô©,66‚ô™,,59‚ô©,,'P2 = '71‚ô©,73‚ô™,,74‚ô©,73‚ô™,,74‚ô™,,71‚ô™,,73‚ô©,71‚ô™,,73‚ô™,,69‚ô™,,71‚ô©,69‚ô™,,71‚ô™,,67‚ô™,,71‚ô©,,'get_pause   = lambda seconds: it.repeat(0, int(seconds * F))sin_f       = lambda i, hz: math.sin(i * 2 * math.pi * hz / F)get_wave    = lambda hz, seconds: (sin_f(i, hz) for i in range(int(seconds * F)))get_hz      = lambda key: 8.176 * 2 ** (int(key) / 12)parse_note  = lambda note: (get_hz(note[:2]), 1/4 if '‚ô©' in note else 1/8)get_samples = lambda note: get_wave(*parse_note(note)) if note else get_pause(1/8)samples_f   = it.chain.from_iterable(get_samples(n) for n in f'{P1},{P1},{P2}'.split(','))samples_i   = array.array('h', (int(f * 30000) for f in samples_f))simpleaudio.play_buffer(samples_i, 1, 2, F)Pygame# $ pip3 install pygameimport pygame as pgpg.init()screen = pg.display.set_mode((500, 500))rect = pg.Rect(240, 240, 20, 20)while not pg.event.get(pg.QUIT):    deltas = {pg.K_UP: (0, -20), pg.K_RIGHT: (20, 0), pg.K_DOWN: (0, 20), pg.K_LEFT: (-20, 0)}    for event in pg.event.get(pg.KEYDOWN):        dx, dy = deltas.get(event.key, (0, 0))        rect = rect.move((dx, dy))    screen.fill((0, 0, 0))    pg.draw.rect(screen, (255, 255, 255), rect)    pg.display.flip()RectangleObject for storing rectangular coordinates.<Rect> = pg.Rect(x, y, width, height)           # Floats get truncated into ints.<int>  = <Rect>.x/y/centerx/centery/‚Ä¶           # Top, right, bottom, left. Allows assignments.<tup.> = <Rect>.topleft/center/‚Ä¶                # Topright, bottomright, bottomleft. Same.<Rect> = <Rect>.move((delta_x, delta_y))        # Use move_ip() to move in-place.<bool> = <Rect>.collidepoint((x, y))            # Checks if rectangle contains the point.<bool> = <Rect>.colliderect(<Rect>)             # Checks if two rectangles overlap.<int>  = <Rect>.collidelist(<list_of_Rect>)     # Returns index of first colliding Rect or -1.<list> = <Rect>.collidelistall(<list_of_Rect>)  # Returns indexes of all colliding rectangles.SurfaceObject for representing images.<Surf> = pg.display.set_mode((width, height))   # Opens new window and returns its surface.<Surf> = pg.Surface((width, height))            # New RGB surface. RGBA if `flags=pg.SRCALPHA`.<Surf> = pg.image.load(<path/file>)             # Loads the image. Format depends on source.<Surf> = pg.surfarray.make_surface(<np_array>)  # Also `<np_arr> = surfarray.pixels3d(<Surf>)`.<Surf> = <Surf>.subsurface(<Rect>)              # Creates a new surface from the cutout.<Surf>.fill(color)                              # Tuple, Color('#rrggbb[aa]') or Color(<name>).<Surf>.set_at((x, y), color)                    # Updates pixel. Also <Surf>.get_at((x, y)).<Surf>.blit(<Surf>, (x, y))                     # Draws passed surface to the surface.from pygame.transform import scale, ...<Surf> = scale(<Surf>, (width, height))         # Returns scaled surface.<Surf> = rotate(<Surf>, anticlock_degrees)      # Returns rotated and scaled surface.<Surf> = flip(<Surf>, x_bool, y_bool)           # Returns flipped surface.from pygame.draw import line, ...line(<Surf>, color, (x1, y1), (x2, y2), width)  # Draws a line to the surface.arc(<Surf>, color, <Rect>, from_rad, to_rad)    # Also ellipse(<Surf>, color, <Rect>, width=0).rect(<Surf>, color, <Rect>, width=0)            # Also polygon(<Surf>, color, points, width=0).Font<Font> = pg.font.Font(<path/file>, size)        # Loads TTF file. Pass None for default font.<Surf> = <Font>.render(text, antialias, color)  # Background color can be specified at the end.Sound<Sound> = pg.mixer.Sound(<path/file/bytes>)     # Loads WAV file or array of signed shorts.<Sound>.play/stop()                             # Also <Sound>.set_volume(<float>).Basic Mario Brothers Exampleimport collections, dataclasses, enum, io, itertools as it, pygame as pg, urllib.requestfrom random import randintP = collections.namedtuple('P', 'x y')          # PositionD = enum.Enum('D', 'n e s w')                   # DirectionW, H, MAX_S = 50, 50, P(5, 10)                  # Width, Height, Max speeddef main():    def get_screen():        pg.init()        return pg.display.set_mode((W*16, H*16))    def get_images():        url = 'https://gto76.github.io/python-cheatsheet/web/mario_bros.png'        img = pg.image.load(io.BytesIO(urllib.request.urlopen(url).read()))        return [img.subsurface(get_rect(x, 0)) for x in range(img.get_width() // 16)]    def get_mario():        Mario = dataclasses.make_dataclass('Mario', 'rect spd facing_left frame_cycle'.split())        return Mario(get_rect(1, 1), P(0, 0), False, it.cycle(range(3)))    def get_tiles():        border = [(x, y) for x in range(W) for y in range(H) if x in [0, W-1] or y in [0, H-1]]        platforms = [(randint(1, W-2), randint(2, H-2)) for _ in range(W*H // 10)]        return [get_rect(x, y) for x, y in border + platforms]    def get_rect(x, y):        return pg.Rect(x*16, y*16, 16, 16)    run(get_screen(), get_images(), get_mario(), get_tiles())def run(screen, images, mario, tiles):    clock = pg.time.Clock()    pressed = set()    while not pg.event.get(pg.QUIT) and clock.tick(28):        keys = {pg.K_UP: D.n, pg.K_RIGHT: D.e, pg.K_DOWN: D.s, pg.K_LEFT: D.w}        pressed |= {keys.get(e.key) for e in pg.event.get(pg.KEYDOWN)}        pressed -= {keys.get(e.key) for e in pg.event.get(pg.KEYUP)}        update_speed(mario, tiles, pressed)        update_position(mario, tiles)        draw(screen, images, mario, tiles, pressed)def update_speed(mario, tiles, pressed):    x, y = mario.spd    x += 2 * ((D.e in pressed) - (D.w in pressed))    x += (x < 0) - (x > 0)    y += 1 if D.s not in get_boundaries(mario.rect, tiles) else (D.n in pressed) * -10    mario.spd = P(x=max(-MAX_S.x, min(MAX_S.x, x)), y=max(-MAX_S.y, min(MAX_S.y, y)))def update_position(mario, tiles):    x, y = mario.rect.topleft    n_steps = max(abs(s) for s in mario.spd)    for _ in range(n_steps):        mario.spd = stop_on_collision(mario.spd, get_boundaries(mario.rect, tiles))        mario.rect.topleft = x, y = x + (mario.spd.x / n_steps), y + (mario.spd.y / n_steps)def get_boundaries(rect, tiles):    deltas = {D.n: P(0, -1), D.e: P(1, 0), D.s: P(0, 1), D.w: P(-1, 0)}    return {d for d, delta in deltas.items() if rect.move(delta).collidelist(tiles) != -1}def stop_on_collision(spd, bounds):    return P(x=0 if (D.w in bounds and spd.x < 0) or (D.e in bounds and spd.x > 0) else spd.x,             y=0 if (D.n in bounds and spd.y < 0) or (D.s in bounds and spd.y > 0) else spd.y)def draw(screen, images, mario, tiles, pressed):    def get_marios_image_index():        if D.s not in get_boundaries(mario.rect, tiles):            return 4        return next(mario.frame_cycle) if {D.w, D.e} & pressed else 6    screen.fill((85, 168, 255))    mario.facing_left = (D.w in pressed) if {D.w, D.e} & pressed else mario.facing_left    screen.blit(images[get_marios_image_index() + mario.facing_left * 9], mario.rect)    for t in tiles:        screen.blit(images[18 if t.x in [0, (W-1)*16] or t.y in [0, (H-1)*16] else 19], t)    pg.display.flip()if __name__ == '__main__':    main()Pandas# $ pip3 install pandas matplotlibimport pandas as pd, matplotlib.pyplot as pltSeriesOrdered dictionary with a name.>>> pd.Series([1, 2], index=['x', 'y'], name='a')x    1y    2Name: a, dtype: int64<Sr> = pd.Series(<list>)                       # Assigns RangeIndex starting at 0.<Sr> = pd.Series(<dict>)                       # Takes dictionary's keys for index.<Sr> = pd.Series(<dict/Series>, index=<list>)  # Only keeps items with keys specified in index.<el> = <Sr>.loc[key]                           # Or: <Sr>.iloc[index]<Sr> = <Sr>.loc[keys]                          # Or: <Sr>.iloc[indexes]<Sr> = <Sr>.loc[from_key : to_key_inclusive]   # Or: <Sr>.iloc[from_i : to_i_exclusive]<el> = <Sr>[key/index]                         # Or: <Sr>.key<Sr> = <Sr>[keys/indexes]                      # Or: <Sr>[<keys_slice/slice>]<Sr> = <Sr>[bools]                             # Or: <Sr>.loc/iloc[bools]<Sr> = <Sr> ><== <el/Sr>                       # Returns a Series of bools.<Sr> = <Sr> +-*/ <el/Sr>                       # Items with non-matching keys get value NaN.<Sr> = pd.concat(<coll_of_Sr>)                 # Concats multiple Series into one long Series.<Sr> = <Sr>.combine_first(<Sr>)                # Adds items that are not yet present.<Sr>.update(<Sr>)                              # Updates items that are already present.<Sr>.plot.line/area/bar/pie/hist()             # Generates a Matplotlib plot.plt.show()                                     # Displays the plot. Also plt.savefig(<path>).Series ‚Äî Aggregate, Transform, Map:<el> = <Sr>.sum/max/mean/idxmax/all()          # Or: <Sr>.agg(lambda <Sr>: <el>)<Sr> = <Sr>.rank/diff/cumsum/ffill/interpl()   # Or: <Sr>.agg/transform(lambda <Sr>: <Sr>)<Sr> = <Sr>.fillna(<el>)                       # Or: <Sr>.agg/transform/map(lambda <el>: <el>)>>> sr = pd.Series([1, 2], index=['x', 'y'])x    1y    2+---------------+-------------+-------------+---------------+|               |    'sum'    |   ['sum']   | {'s': 'sum'}  |+---------------+-------------+-------------+---------------+| sr.apply(‚Ä¶)   |      3      |    sum  3   |     s  3      || sr.agg(‚Ä¶)     |             |             |               |+---------------+-------------+-------------+---------------++---------------+-------------+-------------+---------------+|               |    'rank'   |   ['rank']  | {'r': 'rank'} |+---------------+-------------+-------------+---------------+| sr.apply(‚Ä¶)   |             |      rank   |               || sr.agg(‚Ä¶)     |     x  1    |   x     1   |    r  x  1    ||               |     y  2    |   y     2   |       y  2    |+---------------+-------------+-------------+---------------+Keys/indexes/bools can't be tuples because 'obj[x, y]' is converted to 'obj[(x, y)]'!Methods ffill(), interpolate(), fillna() and dropna() accept 'inplace=True'.Last result has a hierarchical index. Use '<Sr>[key_1, key_2]' to get its values.DataFrameTable with labeled rows and columns.>>> pd.DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])   x  ya  1  2b  3  4<DF>    = pd.DataFrame(<list_of_rows>)         # Rows can be either lists, dicts or series.<DF>    = pd.DataFrame(<dict_of_columns>)      # Columns can be either lists, dicts or series.<el>    = <DF>.loc[row_key, column_key]        # Or: <DF>.iloc[row_index, column_index]<Sr/DF> = <DF>.loc[row_key/s]                  # Or: <DF>.iloc[row_index/es]<Sr/DF> = <DF>.loc[:, column_key/s]            # Or: <DF>.iloc[:, column_index/es]<DF>    = <DF>.loc[row_bools, column_bools]    # Or: <DF>.iloc[row_bools, column_bools]<Sr/DF> = <DF>[column_key/s]                   # Or: <DF>.column_key<DF>    = <DF>[row_bools]                      # Keeps rows as specified by bools.<DF>    = <DF>[<DF_of_bools>]                  # Assigns NaN to False values.<DF>    = <DF> ><== <el/Sr/DF>                 # Returns DF of bools. Sr is treated as a row.<DF>    = <DF> +-*/ <el/Sr/DF>                 # Items with non-matching keys get value NaN.<DF>    = <DF>.set_index(column_key)           # Replaces row keys with values from a column.<DF>    = <DF>.reset_index(drop=False)         # Drops or moves row keys to column named index.<DF>    = <DF>.sort_index(ascending=True)      # Sorts rows by row keys. Use `axis=1` for cols.<DF>    = <DF>.sort_values(column_key/s)       # Sorts rows by the passed column/s. Same.DataFrame ‚Äî Merge, Join, Concat:>>> l = pd.DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])   x  ya  1  2b  3  4>>> r = pd.DataFrame([[4, 5], [6, 7]], index=['b', 'c'], columns=['y', 'z'])   y  zb  4  5c  6  7+------------------------+---------------+------------+------------+--------------------------+|                        |    'outer'    |   'inner'  |   'left'   |       Description        |+------------------------+---------------+------------+------------+--------------------------+| l.merge(r, on='y',     |    x   y   z  | x   y   z  | x   y   z  | Merges on column if 'on' ||            how=‚Ä¶)      | 0  1   2   .  | 3   4   5  | 1   2   .  | or 'left/right_on' are   ||                        | 1  3   4   5  |            | 3   4   5  | set, else on shared cols.||                        | 2  .   6   7  |            |            | Uses 'inner' by default. |+------------------------+---------------+------------+------------+--------------------------+| l.join(r, lsuffix='l', |    x yl yr  z |            | x yl yr  z | Merges on row keys.      ||           rsuffix='r', | a  1  2  .  . | x yl yr  z | 1  2  .  . | Uses 'left' by default.  ||           how=‚Ä¶)       | b  3  4  4  5 | 3  4  4  5 | 3  4  4  5 | If r is a Series, it is  ||                        | c  .  .  6  7 |            |            | treated as a column.     |+------------------------+---------------+------------+------------+--------------------------+| pd.concat([l, r],      |    x   y   z  |     y      |            | Adds rows at the bottom. ||           axis=0,      | a  1   2   .  |     2      |            | Uses 'outer' by default. ||           join=‚Ä¶)      | b  3   4   .  |     4      |            | A Series is treated as a ||                        | b  .   4   5  |     4      |            | column. To add a row use ||                        | c  .   6   7  |     6      |            | pd.concat([l, DF([sr])]).|+------------------------+---------------+------------+------------+--------------------------+| pd.concat([l, r],      |    x  y  y  z |            |            | Adds columns at the      ||           axis=1,      | a  1  2  .  . | x  y  y  z |            | right end. Uses 'outer'  ||           join=‚Ä¶)      | b  3  4  4  5 | 3  4  4  5 |            | by default. A Series is  ||                        | c  .  .  6  7 |            |            | treated as a column.     |+------------------------+---------------+------------+------------+--------------------------+| l.combine_first(r)     |    x   y   z  |            |            | Adds missing rows and    ||                        | a  1   2   .  |            |            | columns. Also updates    ||                        | b  3   4   5  |            |            | items that contain NaN.  ||                        | c  .   6   7  |            |            | R must be a DataFrame.   |+------------------------+---------------+------------+------------+--------------------------+DataFrame ‚Äî Aggregate, Transform, Map:<Sr> = <DF>.sum/max/mean/idxmax/all()          # Or: <DF>.apply/agg(lambda <Sr>: <el>)<DF> = <DF>.rank/diff/cumsum/ffill/interpl()   # Or: <DF>.apply/agg/transfrm(lambda <Sr>: <Sr>)<DF> = <DF>.fillna(<el>)                       # Or: <DF>.applymap(lambda <el>: <el>)All operations operate on columns by default. Pass 'axis=1' to process the rows instead.>>> df = pd.DataFrame([[1, 2], [3, 4]], index=['a', 'b'], columns=['x', 'y'])   x  ya  1  2b  3  4+-----------------+-------------+-------------+---------------+|                 |    'sum'    |   ['sum']   | {'x': 'sum'}  |+-----------------+-------------+-------------+---------------+| df.apply(‚Ä¶)     |             |       x  y  |               || df.agg(‚Ä¶)       |     x  4    |  sum  4  6  |     x  4      ||                 |     y  6    |             |               |+-----------------+-------------+-------------+---------------++-----------------+-------------+-------------+---------------+|                 |    'rank'   |   ['rank']  | {'x': 'rank'} |+-----------------+-------------+-------------+---------------+| df.apply(‚Ä¶)     |      x  y   |      x    y |        x      || df.agg(‚Ä¶)       |   a  1  1   |   rank rank |     a  1      || df.transform(‚Ä¶) |   b  2  2   | a    1    1 |     b  2      ||                 |             | b    2    2 |               |+-----------------+-------------+-------------+---------------+Use '<DF>[col_key_1, col_key_2][row_key]' to get the fifth result's values.DataFrame ‚Äî Plot, Encode, Decode:<DF>.plot.line/area/bar/hist/scatter/box()     # Also: `x=column_key, y=column_key/s`.plt.show()                                     # Displays the plot. Also plt.savefig(<path>).<DF> = pd.read_json/html('<str/path/url>')     # Run `$ pip3 install beautifulsoup4 lxml`.<DF> = pd.read_csv/pickle/excel('<path/url>')  # Use `sheet_name=None` to get all Excel sheets.<DF> = pd.read_sql('<table/query>', <conn.>)   # Accepts SQLite3 or SQLAlchemy connection.<DF> = pd.read_clipboard()                     # Reads a copied table from the clipboard.<dict> = <DF>.to_dict(['d/l/s/‚Ä¶'])             # Returns columns as dicts, lists or series.<str>  = <DF>.to_json/html/csv([<path>])       # Also to_markdown/latex([<path>]).<DF>.to_pickle/excel(<path>)                   # Run `$ pip3 install \""pandas[excel]\"" odfpy`.<DF>.to_sql('<table_name>', <connection>)      # Accepts SQLite3 or SQLAlchemy connection.GroupByObject that groups together rows of a dataframe based on the value of the passed column.>>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 6]], list('abc'), list('xyz'))>>> df.groupby('z').get_group(6)   x  y  zb  4  5  6c  7  8  6<GB> = <DF>.groupby(column_key/s)              # Splits DF into groups based on passed column.<DF> = <GB>.apply(<func>)                      # Maps each group. Func can return DF, Sr or el.<GB> = <GB>[column_key]                        # Single column GB. All operations return a Sr.GroupBy ‚Äî Aggregate, Transform, Map:<DF> = <GB>.sum/max/mean/idxmax/all()          # Or: <GB>.agg(lambda <Sr>: <el>)<DF> = <GB>.rank/diff/cumsum/ffill()           # Or: <GB>.transform(lambda <Sr>: <Sr>)<DF> = <GB>.fillna(<el>)                       # Or: <GB>.transform(lambda <Sr>: <Sr>)>>> gb = df.groupby('z')      x  y  z3: a  1  2  36: b  4  5  6   c  7  8  6+-----------------+-------------+-------------+-------------+---------------+|                 |    'sum'    |    'rank'   |   ['rank']  | {'x': 'rank'} |+-----------------+-------------+-------------+-------------+---------------+| gb.agg(‚Ä¶)       |      x   y  |      x  y   |      x    y |        x      ||                 |  z          |   a  1  1   |   rank rank |     a  1      ||                 |  3   1   2  |   b  1  1   | a    1    1 |     b  1      ||                 |  6  11  13  |   c  2  2   | b    1    1 |     c  2      ||                 |             |             | c    2    2 |               |+-----------------+-------------+-------------+-------------+---------------+| gb.transform(‚Ä¶) |      x   y  |      x  y   |             |               ||                 |  a   1   2  |   a  1  1   |             |               ||                 |  b  11  13  |   b  1  1   |             |               ||                 |  c  11  13  |   c  2  2   |             |               |+-----------------+-------------+-------------+-------------+---------------+RollingObject for rolling window calculations.<RSr/RDF/RGB> = <Sr/DF/GB>.rolling(win_size)   # Also: `min_periods=None, center=False`.<RSr/RDF/RGB> = <RDF/RGB>[column_key/s]        # Or: <RDF/RGB>.column_key<Sr/DF>       = <R>.mean/sum/max()             # Or: <R>.apply/agg(<agg_func/str>)Plotly# $ pip3 install plotly kaleidofrom plotly.express import line<Figure> = line(<DF>, x=<col_name>, y=<col_name>)           # Or: line(x=<list>, y=<list>)<Figure>.update_layout(margin=dict(t=0, r=0, b=0, l=0), ‚Ä¶)  # `paper_bgcolor='rgb(0, 0, 0)'`.<Figure>.write_html/json/image('<path>')                    # Also <Figure>.show().Displays a line chart of total coronavirus deaths per million grouped by continent:covid = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv',                    usecols=['iso_code', 'date', 'total_deaths', 'population'])continents = pd.read_csv('https://gist.githubusercontent.com/stevewithington/20a69c0b6d2ff'                         '846ea5d35e5fc47f26c/raw/country-and-continent-codes-list-csv.csv',                         usecols=['Three_Letter_Country_Code', 'Continent_Name'])df = pd.merge(covid, continents, left_on='iso_code', right_on='Three_Letter_Country_Code')df = df.groupby(['Continent_Name', 'date']).sum().reset_index()df['Total Deaths per Million'] = df.total_deaths * 1e6 / df.populationdf = df[df.date > '2020-03-14']df = df.rename({'date': 'Date', 'Continent_Name': 'Continent'}, axis='columns')line(df, x='Date', y='Total Deaths per Million', color='Continent').show()Displays a multi-axis line chart of total coronavirus cases and changes in prices of Bitcoin, Dow Jones and gold:import pandas as pd, plotly.graph_objects as godef main():    display_data(wrangle_data(*scrape_data()))def scrape_data():    def scrape_covid():        url = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'        df = pd.read_csv(url, usecols=['location', 'date', 'total_cases'])        return df[df.location == 'World'].set_index('date').total_cases    def scrape_yahoo(slug):        url = (f'https://query1.finance.yahoo.com/v7/finance/download/{slug}?'               'period1=1579651200&period2=9999999999&interval=1d&events=history')        df = pd.read_csv(url, usecols=['Date', 'Close'])        return df.set_index('Date').Close    out = scrape_covid(), scrape_yahoo('BTC-USD'), scrape_yahoo('GC=F'), scrape_yahoo('^DJI')    return map(pd.Series.rename, out, ['Total Cases', 'Bitcoin', 'Gold', 'Dow Jones'])def wrangle_data(covid, bitcoin, gold, dow):    df = pd.concat([bitcoin, gold, dow], axis=1)  # Joins columns on dates.    df = df.sort_index().interpolate()            # Sorts by date and interpolates NaN-s.    df = df.loc['2020-02-23':]                    # Discards rows before '2020-02-23'.    df = (df / df.iloc[0]) * 100                  # Calculates percentages relative to day 1.    df = df.join(covid)                           # Adds column with covid cases.    return df.sort_values(df.index[-1], axis=1)   # Sorts columns by last day's value.def display_data(df):    figure = go.Figure()    for col_name in reversed(df.columns):        yaxis = 'y1' if col_name == 'Total Cases' else 'y2'        trace = go.Scatter(x=df.index, y=df[col_name], name=col_name, yaxis=yaxis)        figure.add_trace(trace)    figure.update_layout(        yaxis1=dict(title='Total Cases', rangemode='tozero'),        yaxis2=dict(title='%', rangemode='tozero', overlaying='y', side='right'),        legend=dict(x=1.1),        height=450    )    figure.show()if __name__ == '__main__':    main()PySimpleGUI# $ pip3 install PySimpleGUIimport PySimpleGUI as sglayout = [[sg.Text(\""What's your name?\"")], [sg.Input()], [sg.Button('Ok')]]window = sg.Window('Window Title', layout)event, values = window.read()print(f'Hello {values[0]}!' if event == 'Ok' else '')AppendixCythonLibrary that compiles Python code into C.# $ pip3 install cythonimport pyximport; pyximport.install()import <cython_script><cython_script>.main()Definitions:All 'cdef' definitions are optional, but they contribute to the speed-up.Script needs to be saved with a 'pyx' extension.cdef <ctype> <var_name> = <el>cdef <ctype>[n_elements] <var_name> = [<el>, <el>, ...]cdef <ctype/void> <func_name>(<ctype> <arg_name>): ...cdef class <class_name>:    cdef public <ctype> <attr_name>    def __init__(self, <ctype> <arg_name>):        self.<attr_name> = <arg_name>cdef enum <enum_name>: <member_name>, <member_name>, ...Virtual EnvironmentsSystem for installing libraries directly into project's directory.$ python3 -m venv <name>      # Creates virtual environment in current directory.$ source <name>/bin/activate  # Activates venv. On Windows run `<name>\\Scripts\\activate`.$ pip3 install <library>      # Installs the library into active environment.$ python3 <path>              # Runs the script in active environment. Also `./<path>`.$ deactivate                  # Deactivates virtual environment.Basic Script Template#!/usr/bin/env python3## Usage: .py#from sys import argv, exitfrom collections import defaultdict, namedtuplefrom dataclasses import make_dataclassfrom enum import Enumimport functools as ft, itertools as it, operator as op, redef main():    pass#####  UTIL#def read_file(filename):    with open(filename, encoding='utf-8') as file:        return file.readlines()if __name__ == '__main__':    main()IndexOnly available in the PDF.Ctrl+F / ‚åòF is usually sufficient.Searching '#<title>' on the webpage will limit the search to the titles."
34,facebookresearch/fairseq,https://github.com/facebookresearch/fairseq/blob/main/README.md,Python,"                  Fairseq(-py) is a sequence modeling toolkit that allows researchers anddevelopers to train custom models for translation, summarization, languagemodeling and other text generation tasks.We provide reference implementations of various sequence modeling papers:List of implemented papersConvolutional Neural Networks (CNN)Language Modeling with Gated Convolutional Networks (Dauphin et al., 2017)Convolutional Sequence to Sequence Learning (Gehring et al., 2017)Classical Structured Prediction Losses for Sequence to Sequence Learning (Edunov et al., 2018)Hierarchical Neural Story Generation (Fan et al., 2018)wav2vec: Unsupervised Pre-training for Speech Recognition (Schneider et al., 2019)LightConv and DynamicConv modelsPay Less Attention with Lightweight and Dynamic Convolutions (Wu et al., 2019)Long Short-Term Memory (LSTM) networksEffective Approaches to Attention-based Neural Machine Translation (Luong et al., 2015)Transformer (self-attention) networksAttention Is All You Need (Vaswani et al., 2017)Scaling Neural Machine Translation (Ott et al., 2018)Understanding Back-Translation at Scale (Edunov et al., 2018)Adaptive Input Representations for Neural Language Modeling (Baevski and Auli, 2018)Lexically constrained decoding with dynamic beam allocation (Post & Vilar, 2018)Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context (Dai et al., 2019)Adaptive Attention Span in Transformers (Sukhbaatar et al., 2019)Mixture Models for Diverse Machine Translation: Tricks of the Trade (Shen et al., 2019)RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al., 2019)Facebook FAIR's WMT19 News Translation Task Submission (Ng et al., 2019)Jointly Learning to Align and Translate with Transformer Models (Garg et al., 2019)Multilingual Denoising Pre-training for Neural Machine Translation (Liu et at., 2020)Neural Machine Translation with Byte-Level Subwords (Wang et al., 2020)Unsupervised Quality Estimation for Neural Machine Translation (Fomicheva et al., 2020)wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations (Baevski et al., 2020)Generating Medical Reports from Patient-Doctor Conversations Using Sequence-to-Sequence Models (Enarvi et al., 2020)Linformer: Self-Attention with Linear Complexity (Wang et al., 2020)Cross-lingual Retrieval for Iterative Self-Supervised Training (Tran et al., 2020)Deep Transformers with Latent Depth (Li et al., 2020)Unsupervised Cross-lingual Representation Learning for Speech Recognition (Conneau et al., 2020)Self-training and Pre-training are Complementary for Speech Recognition (Xu et al., 2020)Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training (Hsu, et al., 2021)Unsupervised Speech Recognition (Baevski, et al., 2021)Simple and Effective Zero-shot Cross-lingual Phoneme Recognition (Xu et al., 2021)VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding (Xu et. al., 2021)VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding (Xu et. al., 2021)NormFormer: Improved Transformer Pretraining with Extra Normalization (Shleifer et. al, 2021)Non-autoregressive TransformersNon-Autoregressive Neural Machine Translation (Gu et al., 2017)Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement (Lee et al. 2018)Insertion Transformer: Flexible Sequence Generation via Insertion Operations (Stern et al. 2019)Mask-Predict: Parallel Decoding of Conditional Masked Language Models (Ghazvininejad et al., 2019)Levenshtein Transformer (Gu et al., 2019)FinetuningBetter Fine-Tuning by Reducing Representational Collapse (Aghajanyan et al. 2020)What's New:May 2023 Released models for Scaling Speech Technology to 1,000+ Languages  (Pratap, et al., 2023)June 2022 Released code for wav2vec-U 2.0 from Towards End-to-end Unsupervised Speech Recognition (Liu, et al., 2022)May 2022 Integration with xFormersDecember 2021 Released Direct speech-to-speech translation codeOctober 2021 Released VideoCLIP and VLM modelsOctober 2021 Released multilingual finetuned XLSR-53 modelSeptember 2021 master branch renamed to main.July 2021 Released DrNMT codeJuly 2021 Released Robust wav2vec 2.0 modelJune 2021 Released XLMR-XL and XLMR-XXL modelsMay 2021 Released Unsupervised Speech Recognition codeMarch 2021 Added full parameter and optimizer state sharding + CPU offloadingFebruary 2021 Added LASER training codeDecember 2020: Added Adaptive Attention Span codeDecember 2020: GottBERT model and code releasedNovember 2020: Adopted the Hydra configuration frameworksee documentation explaining how to use it for new and existing projectsNovember 2020: fairseq 0.10.0 releasedOctober 2020: Added R3F/R4F (Better Fine-Tuning) codeOctober 2020: Deep Transformer with Latent Depth code releasedOctober 2020: Added CRISS models and codePrevious updatesSeptember 2020: Added Linformer codeSeptember 2020: Added pointer-generator networksAugust 2020: Added lexically constrained decodingAugust 2020: wav2vec2 models and code releasedJuly 2020: Unsupervised Quality Estimation code releasedMay 2020: Follow fairseq on TwitterApril 2020: Monotonic Multihead Attention code releasedApril 2020: Quant-Noise code releasedApril 2020: Initial model parallel support and 11B parameters unidirectional LM releasedMarch 2020: Byte-level BPE code releasedFebruary 2020: mBART model and code releasedFebruary 2020: Added tutorial for back-translationDecember 2019: fairseq 0.9.0 releasedNovember 2019: VizSeq released (a visual analysis toolkit for evaluating fairseq models)November 2019: CamemBERT model and code releasedNovember 2019: BART model and code releasedNovember 2019: XLM-R models and code releasedSeptember 2019: Nonautoregressive translation code releasedAugust 2019: WMT'19 models releasedJuly 2019: fairseq relicensed under MIT licenseJuly 2019: RoBERTa models and code releasedJune 2019: wav2vec models and code releasedFeatures:multi-GPU training on one machine or across multiple machines (data and model parallel)fast generation on both CPU and GPU with multiple search algorithms implemented:beam searchDiverse Beam Search (Vijayakumar et al., 2016)sampling (unconstrained, top-k and top-p/nucleus)lexically constrained decoding (Post & Vilar, 2018)gradient accumulation enables training with large mini-batches even on a single GPUmixed precision training (trains faster with less GPU memory on NVIDIA tensor cores)extensible: easily register new models, criterions, tasks, optimizers and learning rate schedulersflexible configuration based on Hydra allowing a combination of code, command-line and file based configurationfull parameter and optimizer state shardingoffloading parameters to CPUWe also provide pre-trained models for translation and language modelingwith a convenient torch.hub interface:en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model')en2de.translate('Hello world', beam=5)# 'Hallo Welt'See the PyTorch Hub tutorials for translationand RoBERTa for more examples.Requirements and InstallationPyTorch version >= 1.10.0Python version >= 3.8For training new models, you'll also need an NVIDIA GPU and NCCLTo install fairseq and develop locally:git clone https://github.com/pytorch/fairseqcd fairseqpip install --editable ./# on MacOS:# CFLAGS=\""-stdlib=libc++\"" pip install --editable ./# to install the latest stable release (0.10.x)# pip install fairseqFor faster training install NVIDIA's apex library:git clone https://github.com/NVIDIA/apexcd apexpip install -v --no-cache-dir --global-option=\""--cpp_ext\"" --global-option=\""--cuda_ext\"" \\  --global-option=\""--deprecated_fused_adam\"" --global-option=\""--xentropy\"" \\  --global-option=\""--fast_multihead_attn\"" ./For large datasets install PyArrow: pip install pyarrowIf you use Docker make sure to increase the shared memory size either with --ipc=host or --shm-sizeas command line options to nvidia-docker run .Getting StartedThe full documentation contains instructionsfor getting started, training new models and extending fairseq with new modeltypes and tasks.Pre-trained models and examplesWe provide pre-trained models and pre-processed, binarized test sets for several tasks listed below,as well as example training and evaluation commands.Translation: convolutional and transformer models are availableLanguage Modeling: convolutional and transformer models are availableWe also have more detailed READMEs to reproduce results from specific papers:XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale (Babu et al., 2021)Cross-lingual Retrieval for Iterative Self-Supervised Training (Tran et al., 2020)wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations (Baevski et al., 2020)Unsupervised Quality Estimation for Neural Machine Translation (Fomicheva et al., 2020)Training with Quantization Noise for Extreme Model Compression ({Fan*, Stock*} et al., 2020)Neural Machine Translation with Byte-Level Subwords (Wang et al., 2020)Multilingual Denoising Pre-training for Neural Machine Translation (Liu et at., 2020)Reducing Transformer Depth on Demand with Structured Dropout (Fan et al., 2019)Jointly Learning to Align and Translate with Transformer Models (Garg et al., 2019)Levenshtein Transformer (Gu et al., 2019)Facebook FAIR's WMT19 News Translation Task Submission (Ng et al., 2019)RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al., 2019)wav2vec: Unsupervised Pre-training for Speech Recognition (Schneider et al., 2019)Mixture Models for Diverse Machine Translation: Tricks of the Trade (Shen et al., 2019)Pay Less Attention with Lightweight and Dynamic Convolutions (Wu et al., 2019)Understanding Back-Translation at Scale (Edunov et al., 2018)Classical Structured Prediction Losses for Sequence to Sequence Learning (Edunov et al., 2018)Hierarchical Neural Story Generation (Fan et al., 2018)Scaling Neural Machine Translation (Ott et al., 2018)Convolutional Sequence to Sequence Learning (Gehring et al., 2017)Language Modeling with Gated Convolutional Networks (Dauphin et al., 2017)Join the fairseq communityTwitter: https://twitter.com/fairseqFacebook page: https://www.facebook.com/groups/fairseq.usersGoogle group: https://groups.google.com/forum/#!forum/fairseq-usersLicensefairseq(-py) is MIT-licensed.The license applies to the pre-trained models as well.CitationPlease cite as:@inproceedings{ott2019fairseq,  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},  year = {2019},}"
35,Jack-Cherish/python-spider,https://github.com/Jack-Cherish/python-spider/blob/master/README.md,Python,Ê≥®Ôºö2020Âπ¥ÊúÄÊñ∞ËøûËΩΩÊïôÁ®ãËØ∑ÁßªÊ≠•ÔºöPython Spider 2020Python SpiderÂéüÂàõÊñáÁ´†ÊØèÂë®ÊúÄÂ∞ë‰∏§ÁØáÔºåÂêéÁª≠ÊúÄÊñ∞ÊñáÁ´†‰ºöÂú®„ÄêÂÖ¨‰ºóÂè∑„ÄëÈ¶ñÂèëÔºåËßÜÈ¢ë„ÄêBÁ´ô„ÄëÈ¶ñÂèëÔºåÂ§ßÂÆ∂ÂèØ‰ª•Âä†Êàë„ÄêÂæÆ‰ø°„ÄëËøõ‰∫§ÊµÅÁæ§ÔºåÊäÄÊúØ‰∫§ÊµÅÊàñÊèêÊÑèËßÅÈÉΩÂèØ‰ª•ÔºåÊ¨¢ËøéStarÔºÅ              Â£∞Êòé‰ª£Á†Å„ÄÅÊïôÁ®ã‰ªÖÈôê‰∫éÂ≠¶‰π†‰∫§ÊµÅÔºåËØ∑ÂãøÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÁî®ÈÄîÔºÅÁõÆÂΩïÁà¨Ëô´Â∞èÂ∑•ÂÖ∑Êñá‰ª∂‰∏ãËΩΩÂ∞èÂä©ÊâãÁà¨Ëô´ÂÆûÊàòÁ¨îË∂£ÁúãÂ∞èËØ¥‰∏ãËΩΩÁôæÂ∫¶ÊñáÂ∫ìÂÖçË¥πÊñáÁ´†‰∏ãËΩΩÂä©Êâã_rev1ÁôæÂ∫¶ÊñáÂ∫ìÂÖçË¥πÊñáÁ´†‰∏ãËΩΩÂä©Êâã_rev2„ÄäÂ∏ÖÂïä„ÄãÁΩëÂ∏ÖÂì•ÂõæÁâá‰∏ãËΩΩÊûÑÂª∫‰ª£ÁêÜIPÊ±†„ÄäÁÅ´ÂΩ±ÂøçËÄÖ„ÄãÊº´Áîª‰∏ãËΩΩË¥¢Âä°Êä•Ë°®‰∏ãËΩΩÂ∞èÂä©Êâã‰∏ÄÂ∞èÊó∂ÂÖ•Èó®ÁΩëÁªúÁà¨Ëô´ÊäñÈü≥AppËßÜÈ¢ë‰∏ãËΩΩGEETESTÈ™åËØÅÁ†ÅËØÜÂà´12306Êä¢Á•®Â∞èÂä©ÊâãÁôæ‰∏áËã±ÈõÑÁ≠îÈ¢òËæÖÂä©Á≥ªÁªüÁΩëÊòì‰∫ëÈü≥‰πêÂÖçË¥πÈü≥‰πêÊâπÈáè‰∏ãËΩΩBÁ´ôÂÖçË¥πËßÜÈ¢ëÂíåÂºπÂπïÊâπÈáè‰∏ãËΩΩ‰∫¨‰∏úÂïÜÂìÅÊôíÂçïÂõæ‰∏ãËΩΩÊ≠£ÊñπÊïôÂä°ÁÆ°ÁêÜÁ≥ªÁªü‰∏™‰∫∫‰ø°ÊÅØÊü•ËØ¢ÂÖ∂ÂÆÉÁà¨Ëô´Â∞èÂ∑•ÂÖ∑downloader.py:Êñá‰ª∂‰∏ãËΩΩÂ∞èÂä©Êâã‰∏Ä‰∏™ÂèØ‰ª•Áî®‰∫é‰∏ãËΩΩÂõæÁâá„ÄÅËßÜÈ¢ë„ÄÅÊñá‰ª∂ÁöÑÂ∞èÂ∑•ÂÖ∑ÔºåÊúâ‰∏ãËΩΩËøõÂ∫¶ÊòæÁ§∫ÂäüËÉΩ„ÄÇÁ®çÂä†‰øÆÊîπÂç≥ÂèØÊ∑ªÂä†Âà∞Ëá™Â∑±ÁöÑÁà¨Ëô´‰∏≠„ÄÇÂä®ÊÄÅÁ§∫ÊÑèÂõæÔºöÁà¨Ëô´ÂÆûÊàòbiqukan.py:„ÄäÁ¨îË∂£Áúã„ÄãÁõóÁâàÂ∞èËØ¥ÁΩëÁ´ôÔºåÁà¨ÂèñÂ∞èËØ¥Â∑•ÂÖ∑Á¨¨‰∏âÊñπ‰æùËµñÂ∫ìÂÆâË£ÖÔºö pip3 install beautifulsoup4‰ΩøÁî®ÊñπÊ≥ïÔºö python biqukan.pybaiduwenku.py: ÁôæÂ∫¶ÊñáÂ∫ìwordÊñáÁ´†Áà¨ÂèñÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/72331737‰ª£Á†Å‰∏çÂÆåÂñÑÔºåÊ≤°ÊúâËøõË°åÊâìÂåÖÔºå‰∏çÂÖ∑ÈÄöÁî®ÊÄßÔºåÁ∫ØÂ±ûÂ®±‰πê„ÄÇshuaia.py: Áà¨Âèñ„ÄäÂ∏ÖÂïä„ÄãÁΩëÔºåÂ∏ÖÂì•ÂõæÁâá„ÄäÂ∏ÖÂïä„ÄãÁΩëURLÔºöhttp://www.shuaia.net/index.htmlÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/72597755Á¨¨‰∏âÊñπ‰æùËµñÂ∫ìÂÆâË£ÖÔºö pip3 install requests beautifulsoup4daili.py: ÊûÑÂª∫‰ª£ÁêÜIPÊ±†ÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/72793480carton: ‰ΩøÁî®ScrapyÁà¨Âèñ„ÄäÁÅ´ÂΩ±ÂøçËÄÖ„ÄãÊº´Áîª‰ª£Á†ÅÂèØ‰ª•Áà¨ÂèñÊï¥‰∏™„ÄäÁÅ´ÂΩ±ÂøçËÄÖ„ÄãÊº´ÁîªÊâÄÊúâÁ´†ËäÇÁöÑÂÜÖÂÆπÔºå‰øùÂ≠òÂà∞Êú¨Âú∞„ÄÇÊõ¥ÊîπÂú∞ÂùÄÔºåÂèØ‰ª•Áà¨ÂèñÂÖ∂‰ªñÊº´Áîª„ÄÇ‰øùÂ≠òÂú∞ÂùÄÂèØ‰ª•Âú®settings.py‰∏≠‰øÆÊîπ„ÄÇÂä®Êº´ÁΩëÁ´ôÔºöhttp://comic.kukudm.com/ÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/72858983hero.py: „ÄäÁéãËÄÖËç£ËÄÄ„ÄãÊé®ËçêÂá∫Ë£ÖÊü•ËØ¢Â∞èÂä©ÊâãÁΩëÈ°µÁà¨ÂèñÂ∑≤Áªè‰ºö‰∫ÜÔºåÊÉ≥ËøáÁà¨ÂèñÊâãÊú∫APPÈáåÁöÑÂÜÖÂÆπÂêóÔºüÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/76850843financical.py: Ë¥¢Âä°Êä•Ë°®‰∏ãËΩΩÂ∞èÂä©ÊâãÁà¨ÂèñÁöÑÊï∞ÊçÆÂ≠òÂÖ•Êï∞ÊçÆÂ∫ì‰ºöÂêóÔºü„ÄäË∑üËÇ°Á•ûÂ∑¥Ëè≤ÁâπÂ≠¶‰π†ÁÇíËÇ°‰πãË¥¢Âä°Êä•Ë°®ÂÖ•Â∫ì(MySQL)„Äã‰πüËÆ∏ËÉΩÁªô‰Ω†‰∏Ä‰∫õÊÄùË∑Ø„ÄÇÂéüÁêÜËØ¥ÊòéÔºöhttp://blog.csdn.net/c406495762/article/details/77801899Âä®ÊÄÅÁ§∫ÊÑèÂõæÔºöone_hour_spider:‰∏ÄÂ∞èÊó∂ÂÖ•Èó®Python3ÁΩëÁªúÁà¨Ëô´„ÄÇÂéüÁêÜËØ¥Êòé:Áü•‰πéÔºöhttps://zhuanlan.zhihu.com/p/29809609CSDNÔºöhttp://blog.csdn.net/c406495762/article/details/78123502Êú¨Ê¨°ÂÆûÊàòÂÜÖÂÆπÊúâÔºöÁΩëÁªúÂ∞èËØ¥‰∏ãËΩΩ(ÈùôÊÄÅÁΩëÁ´ô)-biqukan‰ºòÁæéÂ£ÅÁ∫∏‰∏ãËΩΩ(Âä®ÊÄÅÁΩëÁ´ô)-unsplashËßÜÈ¢ë‰∏ãËΩΩdouyin.py:ÊäñÈü≥AppËßÜÈ¢ë‰∏ãËΩΩÊäñÈü≥AppÁöÑËßÜÈ¢ë‰∏ãËΩΩÔºåÂ∞±ÊòØÊôÆÈÄöÁöÑAppÁà¨Âèñ„ÄÇÂéüÁêÜËØ¥Êòé:‰∏™‰∫∫ÁΩëÁ´ôÔºöhttp://cuijiahua.com/blog/2018/03/spider-5.htmldouyin_pro:ÊäñÈü≥AppËßÜÈ¢ë‰∏ãËΩΩÔºàÂçáÁ∫ßÁâàÔºâÊäñÈü≥AppÁöÑËßÜÈ¢ë‰∏ãËΩΩÔºåÊ∑ªÂä†ËßÜÈ¢ëËß£ÊûêÁΩëÁ´ôÔºåÊîØÊåÅÊó†Ê∞¥Âç∞ËßÜÈ¢ë‰∏ãËΩΩÔºå‰ΩøÁî®Á¨¨‰∏âÊñπÂπ≥Âè∞Ëß£Êûê„ÄÇÂéüÁêÜËØ¥Êòé:‰∏™‰∫∫ÁΩëÁ´ôÔºöhttp://cuijiahua.com/blog/2018/03/spider-5.htmldouyin:ÊäñÈü≥AppËßÜÈ¢ë‰∏ãËΩΩÔºàÂçáÁ∫ßÁâà2ÔºâÊäñÈü≥AppÁöÑËßÜÈ¢ë‰∏ãËΩΩÔºåÊ∑ªÂä†ËßÜÈ¢ëËß£ÊûêÁΩëÁ´ôÔºåÊîØÊåÅÊó†Ê∞¥Âç∞ËßÜÈ¢ë‰∏ãËΩΩÔºåÈÄöËøáurlËß£ÊûêÔºåÊó†ÈúÄÁ¨¨‰∏âÊñπÂπ≥Âè∞„ÄÇÂéüÁêÜËØ¥Êòé:‰∏™‰∫∫ÁΩëÁ´ôÔºöhttp://cuijiahua.com/blog/2018/03/spider-5.htmlÂä®ÊÄÅÁ§∫ÊÑèÂõæÔºögeetest.py:GEETESTÈ™åËØÅÁ†ÅËØÜÂà´ÂéüÁêÜËØ¥Êòé:Êó†12306.py:Áî®PythonÊä¢ÁÅ´ËΩ¶Á•®ÁÆÄÂçï‰ª£Á†ÅÂèØ‰ª•Ëá™Â∑±ÊÖ¢ÊÖ¢‰∏∞ÂØåÔºåËõÆÁÆÄÂçïÔºåÊúâÁà¨Ëô´Âü∫Á°ÄÂæàÂ•ΩÊìç‰ΩúÔºåÊ≤°ÊúâÂéüÁêÜËØ¥Êòé„ÄÇbaiwan:Áôæ‰∏áËã±ÈõÑËæÖÂä©Á≠îÈ¢òÊïàÊûúÂõæÔºöÂéüÁêÜËØ¥ÊòéÔºö‰∏™‰∫∫ÁΩëÁ´ôÔºöhttp://cuijiahua.com/blog/2018/01/spider_3.htmlÂäüËÉΩ‰ªãÁªçÔºöÊúçÂä°Âô®Á´ØÔºå‰ΩøÁî®PythonÔºàbaiwan.pyÔºâÈÄöËøáÊäìÂåÖËé∑ÂæóÁöÑÊé•Âè£Ëé∑ÂèñÁ≠îÈ¢òÊï∞ÊçÆÔºåËß£Êûê‰πãÂêéÈÄöËøáÁôæÂ∫¶Áü•ÈÅìÊêúÁ¥¢Êé•Âè£ÂåπÈÖçÁ≠îÊ°àÔºåÂ∞ÜÊúÄÁªàÂåπÈÖçÁöÑÁªìÊûúÂÜôÂÖ•Êñá‰ª∂Ôºàfile.txt)„ÄÇÊâãÊú∫ÊäìÂåÖ‰∏ç‰ºöÁöÑÊúãÂèãÔºåÂèØ‰ª•Áúã‰∏ãÊàëÁöÑÊó©ÊúüÊâãÊú∫APPÊäìÂåÖÊïôÁ®ã„ÄÇNode.jsÔºàapp.jsÔºâÊØèÈöî1sËØªÂèñ‰∏ÄÊ¨°file.txtÊñá‰ª∂ÔºåÂπ∂Â∞ÜËØªÂèñÁªìÊûúÈÄöËøásocket.ioÊé®ÈÄÅÁªôÂÆ¢Êà∑Á´ØÔºàindex.htmlÔºâ„ÄÇ‰∫≤ÊµãÁ≠îÈ¢òÂª∂Êó∂Âú®3sÂ∑¶Âè≥„ÄÇÂ£∞ÊòéÔºöÊ≤°ÂÅöËøáÂêéÁ´ØÂíåÂâçÁ´ØÔºåËä±‰∫Ü‰∏ÄÂ§©Êó∂Èó¥ÔºåÁé∞Â≠¶Áé∞ÂçñÂºÑÂ•ΩÁöÑÔºåjavascript‰πüÊòØÁé∞ÁúãÁé∞Áî®ÔºåÁôæÂ∫¶ÁöÑÁ®ãÂ∫èÔºåË∞ÉËØïË∞ÉËØïËÄåÂ∑≤„ÄÇÂèØËÉΩÊúâÂæàÂ§öÁî®Ê≥ïÊØîËæÉlowÁöÑÂú∞ÊñπÔºåÁî®Ê≥ï‰∏çÂØπÔºåËØ∑ÂãøËßÅÊÄ™ÔºåÊúâÂ§ßÁâõÊÑüÂÖ¥Ë∂£ÔºåÂèØ‰ª•Ëá™Ë°åÂÆåÂñÑ„ÄÇNetease:Ê†πÊçÆÊ≠åÂçï‰∏ãËΩΩÁΩëÊòì‰∫ëÈü≥‰πêÊïàÊûúÂõæÔºöÂéüÁêÜËØ¥ÊòéÔºöÊöÇÊó†ÂäüËÉΩ‰ªãÁªçÔºöÊ†πÊçÆmusic_list.txtÊñá‰ª∂ÈáåÁöÑÊ≠åÂçïÁöÑ‰ø°ÊÅØ‰∏ãËΩΩÁΩëÊòì‰∫ëÈü≥‰πêÔºåÂ∞ÜËá™Â∑±ÂñúÊ¨¢ÁöÑÈü≥‰πêËøõË°åÊâπÈáè‰∏ãËΩΩ„ÄÇbilibiliÔºöBÁ´ôËßÜÈ¢ëÂíåÂºπÂπïÊâπÈáè‰∏ãËΩΩÂéüÁêÜËØ¥ÊòéÔºöÊöÇÊó†‰ΩøÁî®ËØ¥ÊòéÔºö python bilibili.py -d Áå´ -k Áå´ -p 10 ‰∏â‰∏™ÂèÇÊï∞Ôºö -d\t‰øùÂ≠òËßÜÈ¢ëÁöÑÊñá‰ª∂Â§πÂêç -k\tBÁ´ôÊêúÁ¥¢ÁöÑÂÖ≥ÈîÆÂ≠ó -p\t‰∏ãËΩΩÊêúÁ¥¢ÁªìÊûúÂâçÂ§öÂ∞ëÈ°µjingdongÔºö‰∫¨‰∏úÂïÜÂìÅÊôíÂçïÂõæ‰∏ãËΩΩÊïàÊûúÂõæÔºöÂéüÁêÜËØ¥ÊòéÔºöÊöÇÊó†‰ΩøÁî®ËØ¥ÊòéÔºö python jd.py -k ËäíÊûú  ‰∏â‰∏™ÂèÇÊï∞Ôºö -d\t‰øùÂ≠òÂõæÁâáÁöÑË∑ØÂæÑÔºåÈªòËÆ§‰∏∫fd.pyÊñá‰ª∂ÊâÄÂú®Êñá‰ª∂Â§π -k\tÊêúÁ¥¢ÂÖ≥ÈîÆËØç -n  \t‰∏ãËΩΩÂïÜÂìÅÁöÑÊôíÂçïÂõæ‰∏™Êï∞ÔºåÂç≥n‰∏™ÂïÜÂ∫óÁöÑÊôíÂçïÂõæzhengfang_system_spiderÔºöÂØπÊ≠£ÊñπÊïôÂä°ÁÆ°ÁêÜÁ≥ªÁªü‰∏™‰∫∫ËØæË°®Ôºå‰∏™‰∫∫Â≠¶ÁîüÊàêÁª©ÔºåÁª©ÁÇπÁ≠âÁÆÄÂçïÁà¨ÂèñÊïàÊûúÂõæÔºöÂéüÁêÜËØ¥ÊòéÔºöÊöÇÊó†‰ΩøÁî®ËØ¥ÊòéÔºö cd zhengfang_system_spider pip install -r requirements.txt python spider.pyÂÖ∂ÂÆÉÊ¨¢Ëøé Pull requestsÔºåÊÑüË∞¢Ë¥°ÁåÆ„ÄÇÊõ¥Â§öÁ≤æÂΩ©ÔºåÊï¨ËØ∑ÊúüÂæÖÔºÅ 
36,Yorko/mlcourse.ai,https://github.com/Yorko/mlcourse.ai/blob/main/README.md,Python,"mlcourse.ai ‚Äì Open Machine Learning Coursemlcourse.ai is an open Machine Learning course by OpenDataScience (ods.ai), led by Yury Kashnitsky (yorko). Having both a Ph.D. degree in applied math and a Kaggle Competitions Master tier, Yury aimed at designing an ML course with a perfect balance between theory and practice. Thus, the course meets you with math formulae in lectures, and a lot of practice in a form of assignments and  Kaggle Inclass competitions. Currently, the course is in a self-paced mode. Here we guide you through the self-paced mlcourse.ai.Bonus:Additionally, you can purchase a Bonus Assignments pack with the best non-demo versions of mlcourse.ai assignments. Select the \""Bonus Assignments\"" tier. Refer to the details of the deal on the main page mlcourse.ai.Mirrors (üá¨üáß-only): mlcourse.ai (main site), Kaggle Dataset (same notebooks as Kaggle Notebooks)Self-paced passingYou are guided through 10 weeks of mlcourse.ai. For each week, from Pandas to Gradient Boosting, instructions are given on which articles to read, lectures to watch, what assignments to accomplish.ArticlesThis is the list of published articles on medium.com üá¨üáß, habr.com üá∑üá∫. Also notebooks in Chinese are mentioned üá®üá≥ and links to Kaggle Notebooks (in English) are given. Icons are clickable.Exploratory Data Analysis with Pandas üá¨üáß üá∑üá∫ üá®üá≥, Kaggle NotebookVisual Data Analysis with Python üá¨üáß üá∑üá∫ üá®üá≥, Kaggle Notebooks: part1, part2Classification, Decision Trees and k Nearest Neighbors üá¨üáß üá∑üá∫ üá®üá≥, Kaggle NotebookLinear Classification and Regression üá¨üáß üá∑üá∫ üá®üá≥, Kaggle Notebooks: part1, part2, part3, part4, part5Bagging and Random Forest üá¨üáß üá∑üá∫ üá®üá≥, Kaggle Notebooks: part1, part2, part3Feature Engineering and Feature Selection üá¨üáß üá∑üá∫ üá®üá≥, Kaggle NotebookUnsupervised Learning: Principal Component Analysis and Clustering üá¨üáß üá∑üá∫ üá®üá≥, Kaggle NotebookVowpal Wabbit: Learning with Gigabytes of Data üá¨üáß üá∑üá∫ üá®üá≥, Kaggle NotebookTime Series Analysis with Python, part 1 üá¨üáß üá∑üá∫ üá®üá≥. Predicting future with Facebook Prophet, part 2 üá¨üáß, üá®üá≥ Kaggle Notebooks: part1, part2Gradient Boosting üá¨üáß üá∑üá∫, üá®üá≥, Kaggle NotebookLecturesVideolectures are uploaded to this YouTube playlist.Introduction, video, slidesExploratory data analysis with Pandas, videoVisualization, main plots for EDA, videoDecision trees: theory and practical partLogistic regression: theoretical foundations, practical part (baselines in the \""Alice\"" competition)Ensembles and Random Forest ‚Äì part 1. Classification metrics ‚Äì part 2. Example of a business task, predicting a customer payment ‚Äì part 3Linear regression and regularization - theory, LASSO & Ridge, LTV prediction - practiceUnsupervised learning - Principal Component Analysis and ClusteringStochastic Gradient Descent for classification and regression - part 1, part 2 TBATime series analysis with Python (ARIMA, Prophet) - videoGradient boosting: basic ideas - part 1, key ideas behind Xgboost, LightGBM, and CatBoost + practice - part 2AssignmentsThe following are demo-assignments. Additionally, within the \""Bonus Assignments\"" tier you can get access to non-demo assignments.Exploratory data analysis with Pandas, nbviewer, Kaggle Notebook, solutionAnalyzing cardiovascular disease data, nbviewer, Kaggle Notebook, solutionDecision trees with a toy task and the UCI Adult dataset, nbviewer, Kaggle Notebook, solutionSarcasm detection, Kaggle Notebook, solution. Linear Regression as an optimization problem, nbviewer, Kaggle NotebookLogistic Regression and Random Forest in the credit scoring problem, nbviewer, Kaggle Notebook, solutionExploring OLS, Lasso and Random Forest in a regression task, nbviewer, Kaggle Notebook, solutionUnsupervised learning, nbviewer, Kaggle Notebook, solutionImplementing online regressor, nbviewer, Kaggle Notebook, solutionTime series analysis, nbviewer, Kaggle Notebook, solutionBeating baseline in a competition, Kaggle NotebookBonus assignmentsAdditionally, you can purchase a Bonus Assignments pack with the best non-demo versions of mlcourse.ai assignments. Select the \""Bonus Assignments\"" tier on Patreon or a similar tier on Boosty (rus).                   ¬†¬†                     Details of the dealmlcourse.ai is still in self-paced mode but we offer you Bonus Assignments with solutions for a contribution of $17/month. The idea is that you pay for ~1-5 months while studying the course materials, but a single contribution is still fine and opens your access to the bonus pack.Note: the first payment is charged at the moment of joining the Tier Patreon, and the next payment is charged on the 1st day of the next month, thus it's better to purchase the pack in the 1st half of the month.mlcourse.ai is never supposed to go fully monetized (it's created in the wonderful open ODS.ai community and will remain open and free) but it'd help to cover some operational costs, and Yury also put in quite some effort into assembling all the best assignments into one pack. Please note that unlike the rest of the course content, Bonus Assignments are copyrighted. Informally, Yury's fine if you share the pack with 2-3 friends but public sharing of the Bonus Assignments pack is prohibited.  The bonus pack contains 10 assignments, in some of them you are challenged to beat a baseline in a Kaggle competition under thorough guidance (\""Alice\"" and \""Medium\"") or implement an algorithm from scratch -- efficient stochastic gradient descent classifier and gradient boosting.Kaggle competitionsCatch Me If You Can: Intruder Detection through Webpage Session Tracking. Kaggle InclassPredicting popularity of a Medium article. Kaggle InclassDotA 2 winner prediction. Kaggle InclassCiting mlcourse.aiIf you happen to cite mlcourse.ai in your work, you can use this BibTeX record:@misc{mlcourse_ai,    author = {Kashnitsky, Yury},    title = {mlcourse.ai ‚Äì Open Machine Learning Course},    year = {2020},    publisher = {GitHub},    journal = {GitHub repository},    howpublished = {\\url{https://github.com/Yorko/mlcourse.ai}},}CommunityYou can join the Singularis.ai Slack community to ask questions on the course materials. The community is mostly Russian-speaking but questions in English are still welcome."
37,davidsandberg/facenet,https://github.com/davidsandberg/facenet/blob/master/README.md,Python,"Face Recognition using Tensorflow This is a TensorFlow implementation of the face recognizer described in the paper\""FaceNet: A Unified Embedding for Face Recognition and Clustering\"". The project also uses ideas from the paper \""Deep Face Recognition\"" from the Visual Geometry Group at Oxford.CompatibilityThe code is tested using Tensorflow r1.7 under Ubuntu 14.04 with Python 2.7 and Python 3.5. The test cases can be found here and the results can be found here.NewsDateUpdate2018-04-10Added new models trained on Casia-WebFace and VGGFace2 (see below). Note that the models uses fixed image standardization (see wiki).2018-03-31Added a new, more flexible input pipeline as well as a bunch of minor updates.2017-05-13Removed a bunch of older non-slim models. Moved the last bottleneck layer into the respective models. Corrected normalization of Center Loss.2017-05-06Added code to train a classifier on your own images. Renamed facenet_train.py to train_tripletloss.py and facenet_train_classifier.py to train_softmax.py.2017-03-02Added pretrained models that generate 128-dimensional embeddings.2017-02-22Updated to Tensorflow r1.0. Added Continuous Integration using Travis-CI.2017-02-03Added models where only trainable variables has been stored in the checkpoint. These are therefore significantly smaller.2017-01-27Added a model trained on a subset of the MS-Celeb-1M dataset. The LFW accuracy of this model is around 0.994.2017‚Äë01‚Äë02Updated to run with Tensorflow r0.12. Not sure if it runs with older versions of Tensorflow though.Pre-trained modelsModel nameLFW accuracyTraining datasetArchitecture20180408-1029000.9905CASIA-WebFaceInception ResNet v120180402-1147590.9965VGGFace2Inception ResNet v1NOTE: If you use any of the models, please do not forget to give proper credit to those providing the training dataset as well.InspirationThe code is heavily inspired by the OpenFace implementation.Training dataThe CASIA-WebFace dataset has been used for training. This training set consists of total of 453 453 images over 10 575 identities after face detection. Some performance improvement has been seen if the dataset has been filtered before training. Some more information about how this was done will come later.The best performing model has been trained on the VGGFace2 dataset consisting of ~3.3M faces and ~9000 classes.Pre-processingFace alignment using MTCNNOne problem with the above approach seems to be that the Dlib face detector misses some of the hard examples (partial occlusion, silhouettes, etc). This makes the training set too \""easy\"" which causes the model to perform worse on other benchmarks.To solve this, other face landmark detectors has been tested. One face landmark detector that has proven to work very well in this setting is theMulti-task CNN. A Matlab/Caffe implementation can be found here and this has been used for face alignment with very good results. A Python/Tensorflow implementation of MTCNN can be found here. This implementation does not give identical results to the Matlab/Caffe implementation but the performance is very similar.Running trainingCurrently, the best results are achieved by training the model using softmax loss. Details on how to train a model using softmax loss on the CASIA-WebFace dataset can be found on the page Classifier training of Inception-ResNet-v1 and .Pre-trained modelsInception-ResNet-v1 modelA couple of pretrained models are provided. They are trained using softmax loss with the Inception-Resnet-v1 model. The datasets has been aligned using MTCNN.PerformanceThe accuracy on LFW for the model 20180402-114759 is 0.99650+-0.00252. A description of how to run the test can be found on the page Validate on LFW. Note that the input images to the model need to be standardized using fixed image standardization (use the option --use_fixed_image_standardization when running e.g. validate_on_lfw.py)."
38,yandex-praktikum/calc_and_win,https://github.com/yandex-praktikum/calc_and_win/blob/master/README.md,Python,"calc_and_win–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏–≥—Ä—ã \""–†–∞—Å—Å—á–∏—Ç–∞–π –∏ –ø–æ–±–µ–¥–∏!\"""
39,facebook/prophet,https://github.com/facebook/prophet/blob/main/README.md,Python,"Prophet: Automatic Forecasting Procedure2023 Update: We discuss our plans for the future of Prophet in this blog post: facebook/prophet in 2023 and beyondProphet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.Prophet is open source software released by Facebook's Core Data Science team. It is available for download on CRAN and PyPI.Important linksHomepage: https://facebook.github.io/prophet/HTML documentation: https://facebook.github.io/prophet/docs/quick_start.htmlIssue tracker: https://github.com/facebook/prophet/issuesSource code repository: https://github.com/facebook/prophetContributing: https://facebook.github.io/prophet/docs/contributing.htmlProphet R package: https://cran.r-project.org/package=prophetProphet Python package: https://pypi.python.org/pypi/prophet/Release blogpost: https://research.facebook.com/blog/2017/2/prophet-forecasting-at-scale/Prophet paper: Sean J. Taylor, Benjamin Letham (2018) Forecasting at scale. The American Statistician 72(1):37-45 (https://peerj.com/preprints/3190.pdf).Installation in R - CRAN‚ö†Ô∏è The CRAN version of prophet is fairly outdated. To get the latest bug fixes and updated country holiday data, we suggest installing the latest release.Prophet is a CRAN package so you can use install.packages.install.packages('prophet')After installation, you can get started!Installation in R - Latest releaseinstall.packages('remotes')remotes::install_github('facebook/prophet@*release', subdir = 'R')Experimental backend - cmdstanrYou can also choose an experimental alternative stan backend called cmdstanr. Once you've installed prophet,follow these instructions to use cmdstanr instead of rstan as the backend:# R# We recommend running this in a fresh R session or restarting your current sessioninstall.packages(c(\""cmdstanr\"", \""posterior\""), repos = c(\""https://mc-stan.org/r-packages/\"", getOption(\""repos\"")))# If you haven't installed cmdstan before, run:cmdstanr::install_cmdstan()# Otherwise, you can point cmdstanr to your cmdstan path:cmdstanr::set_cmdstan_path(path = <your existing cmdstan>)# Set the R_STAN_BACKEND environment variableSys.setenv(R_STAN_BACKEND = \""CMDSTANR\"")WindowsOn Windows, R requires a compiler so you'll need to follow the instructions provided by rstan. The key step is installing Rtools before attempting to install the package.If you have custom Stan compiler settings, install from source rather than the CRAN binary.Installation in Python - PyPI releaseProphet is on PyPI, so you can use pip to install it.python -m pip install prophetFrom v0.6 onwards, Python 2 is no longer supported.As of v1.0, the package name on PyPI is \""prophet\""; prior to v1.0 it was \""fbprophet\"".As of v1.1, the minimum supported Python version is 3.7.After installation, you can get started!AnacondaProphet can also be installed through conda-forge.conda install -c conda-forge prophetInstallation in Python - Development versionTo get the latest code changes as they are merged, you can clone this repo and build from source manually. This is not guaranteed to be stable.git clone https://github.com/facebook/prophet.gitcd prophet/pythonpython -m pip install -e .By default, Prophet will use a fixed version of cmdstan (downloading and installing it if necessary) to compile the model executables. If this is undesired and you would like to use your own existing cmdstan installation, you can set the environment variable PROPHET_REPACKAGE_CMDSTAN to False:export PROPHET_REPACKAGE_CMDSTAN=False; python -m pip install -e .LinuxMake sure compilers (gcc, g++, build-essential) and Python development tools (python-dev, python3-dev) are installed. In Red Hat systems, install the packages gcc64 and gcc64-c++. If you are using a VM, be aware that you will need at least 4GB of memory to install prophet, and at least 2GB of memory to use prophet.WindowsUsing cmdstanpy with Windows requires a Unix-compatible C compiler such as mingw-gcc. If cmdstanpy is installed first, one can be installed via the cmdstanpy.install_cxx_toolchain command.ChangelogVersion 1.1.4 (2023.05.30)PythonWe now rely solely on holidays package for country holidays.Upgraded cmdstan version to 2.31.0, enabling Apple M1 support.Fixed bug with Windows installation caused by long paths.RUpdated holidays data based on holidays version 0.25.Version 1.1.2 (2023.01.20)PythonSped up .predict() by up to 10x by removing intermediate DataFrame creations.Sped up fourier series generation, leading to at least 1.5x speed improvement for train() and predict() pipelines.Fixed bug in how warm start values were being read.Wheels are now version-agnostic.RFixed a bug in construct_holiday_dataframe()Updated holidays data based on holidays version 0.18.Version 1.1.1 (2022.09.08)(Python) Improved runtime (3-7x) of uncertainty predictions via vectorization.Bugfixes relating to Python package versions and R holiday objects.Version 1.1 (2022.06.25)Replaced pystan2 dependency with cmdstan + cmdstanpy.Pre-packaged model binaries for Python package, uploaded binary distributions to PyPI.Improvements in the stan model code, cross-validation metric calculations, holidays.Version 1.0 (2021.03.28)Python package name changed from fbprophet to prophetFixed R Windows build issues to get latest version back on CRANImprovements in serialization, holidays, and R timezone handlingPlotting improvementsVersion 0.7 (2020.09.05)Built-in json serializationAdded \""flat\"" growth optionBugfixes related to holidays and pandasPlotting improvementsImprovements in cross validation, such as parallelization and directly specifying cutoffsVersion 0.6 (2020.03.03)Fix bugs related to upstream changes in holidays and pandas packages.Compile model during first use, not during install (to comply with CRAN policy)cmdstanpy backend now available in PythonPython 2 no longer supportedVersion 0.5 (2019.05.14)Conditional seasonalitiesImproved cross validation estimatesPlotly plot in PythonBugfixesVersion 0.4 (2018.12.18)Added holidays functionalityBugfixesVersion 0.3 (2018.06.01)Multiplicative seasonalityCross validation error metrics and visualizationsParameter to set range of potential changepointsUnified Stan model for both trend typesImproved future trend uncertainty for sub-daily dataBugfixesVersion 0.2.1 (2017.11.08)BugfixesVersion 0.2 (2017.09.02)Forecasting with sub-daily dataDaily seasonality, and custom seasonalitiesExtra regressorsAccess to posterior predictive samplesCross-validation functionSaturating minimumsBugfixesVersion 0.1.1 (2017.04.17)BugfixesNew options for detecting yearly and weekly seasonality (now the default)Version 0.1 (2017.02.23)Initial releaseLicenseProphet is licensed under the MIT license."
40,jackfrued/Python-100-Days,https://github.com/jackfrued/Python-100-Days/blob/master/README.md,Python,"Python - 100Â§©‰ªéÊñ∞ÊâãÂà∞Â§ßÂ∏à‰ΩúËÄÖÔºöÈ™ÜÊòäËØ¥ÊòéÔºö‰ªéÈ°πÁõÆ‰∏äÁ∫øÂà∞Ëé∑Âæó8w+ÊòüÊ†á‰ª•Êù•Ôºå‰∏ÄÁõ¥Êî∂Âà∞ÂèçÈ¶àËØ¥Âü∫Á°ÄÈÉ®ÂàÜÔºàÂâç15Â§©ÁöÑÂÜÖÂÆπÔºâÂØπÊñ∞ÊâãÊù•ËØ¥ÊòØÊØîËæÉÂõ∞ÈöæÁöÑÔºåÂª∫ËÆÆÊúâÈÖçÂ•óËßÜÈ¢ëËøõË°åËÆ≤Ëß£„ÄÇÊúÄËøëÊääÂü∫Á°ÄÈÉ®ÂàÜÁöÑÂÜÖÂÆπÈáçÊñ∞Âà∂‰Ωú‰∫Ü‰∏Ä‰∏™Âêç‰∏∫‚ÄúPython-Core-50-Courses‚ÄùÁöÑÈ°πÁõÆÔºåÁî®Êõ¥‰∏∫ÁÆÄÂçïÈÄö‰øóÁöÑÊñπÂºèÈáçÂÜô‰∫ÜËøôÈÉ®ÂàÜÂÜÖÂÆπÂπ∂ÈôÑÂ∏¶‰∫ÜËßÜÈ¢ëËÆ≤Ëß£ÔºåÂàùÂ≠¶ËÄÖÂèØ‰ª•ÂÖ≥Ê≥®‰∏ãËøô‰∏™Êñ∞È°πÁõÆ„ÄÇÂ¶ÇÊûúÈúÄË¶ÅPythonÂü∫Á°ÄËßÜÈ¢ëÔºåÂèØ‰ª•Âú®‚ÄúBÁ´ô‚ÄùÊêúÁ¥¢„ÄäPythonÈõ∂Âü∫Á°ÄÂø´ÈÄü‰∏äÊâã„ÄãÔºåËøôÂ•óËßÜÈ¢ëÊòØÊàëËÆ≤ËØæÁöÑÊó∂ÂÄôÂΩïÂà∂ÁöÑÈöèÂ†ÇËßÜÈ¢ëÔºåÁîªË¥®Â∞öÂèØ„ÄÅÈü≥Ë¥®‰∏ÄËà¨Ôºå‰ΩÜÊòØÂØπÂàùÂ≠¶ËÄÖÂ∫îËØ•‰ºöÊúâ‰∫õÂ∏ÆÂä©ÔºåÊ¨¢ËøéÂ§ßÂÆ∂ÁïôË®Ä„ÄÅËØÑËÆ∫„ÄÅÂèëÂºπÂπï„ÄÇÂ≠¶‰π†‰πãÂêéËßâÂæóÊúâÊî∂Ëé∑ÁöÑÂ∞è‰ºô‰º¥ÂèØ‰ª•‚Äú‰∏ÄÈîÆ‰∏âËøû‚ÄùÊù•ÊîØÊåÅUP‰∏ªÔºàÂçÉÈîãPythonÔºâ„ÄÇÂõΩÂÜÖÁî®Êà∑Â¶ÇÊûúËÆøÈóÆGitHubÊØîËæÉÊÖ¢ÁöÑËØùÔºåÂèØ‰ª•ÂÖ≥Ê≥®ÊàëÁöÑÁü•‰πéÂè∑Python-JackÔºå‰∏äÈù¢ÁöÑ‚Äú‰ªéÈõ∂ÂºÄÂßãÂ≠¶Python‚Äù‰∏ìÊ†èÊØîËæÉÈÄÇÂêàÂàùÂ≠¶ËÄÖÔºåÂÖ∂‰ªñÁöÑ‰∏ìÊ†è‰πüÂú®ÊåÅÁª≠Âàõ‰ΩúÂíåÊõ¥Êñ∞‰∏≠ÔºåÊ¨¢ËøéÂ§ßÂÆ∂ÂÖ≥Ê≥®Âπ∂ÁÇπËµûËØÑËÆ∫„ÄÇÂàõ‰Ωú‰∏çÊòìÔºåÊÑüË∞¢Â§ßÂÆ∂ÁöÑÊâìËµèÊîØÊåÅÔºåËøô‰∫õÈí±‰∏ç‰ºöÁî®‰∫é‰∏™‰∫∫Ê∂àË¥πÔºà‰æãÂ¶ÇÔºöË¥≠‰π∞ÂíñÂï°ÔºâÔºåËÄåÊòØÈÄöËøáËÖæËÆØÂÖ¨Áõä„ÄÅÁæéÂõ¢ÂÖ¨Áõä„ÄÅÊ∞¥Êª¥Á≠πÁ≠âÂπ≥Âè∞ÊçêËµ†ÁªôÈúÄË¶ÅÂ∏ÆÂä©ÁöÑ‰∫∫ÔºàÁÇπÂáª‰∫ÜËß£ÊçêËµ†ÊÉÖÂÜµÔºâ„ÄÇÈúÄË¶ÅÂä†ÂÖ•QQÂ≠¶‰π†Áæ§ÁöÑÂèØ‰ª•Êâ´Êèè‰∏ãÈù¢ÁöÑ‰∫åÁª¥Á†ÅÔºå‰∏â‰∏™Áæ§Âä†‰∏Ä‰∏™Âç≥ÂèØÔºå‰∏çË¶ÅÈáçÂ§çËøõÁæ§„ÄÇÂ≠¶‰π†Áæ§‰ºö‰∏∫Â§ßÂÆ∂Êèê‰æõÂ≠¶‰π†ËµÑÊ∫êÂíåÈóÆÈ¢òËß£Á≠îÔºåÂ¶ÇÊûúÊúâPython‰ΩìÈ™åËØæÂíåË°å‰∏öÂÖ¨ÂºÄËØæ‰ºöÊèêÂâçÂú®Áæ§ÈáåÈÄöÁü•Â§ßÂÆ∂ÔºåÊ¨¢ËøéÂ§ßÂÆ∂Âä†ÂÖ•„ÄÇÈ°πÁõÆ‚ÄúDay80~90‚ÄùÈÉ®ÂàÜÁõÆÂâç‰ªçÂú®Âàõ‰Ωú‰∏≠ÔºåÂõ†‰∏∫‰ΩúËÄÖÂπ≥Êó∂‰πüÊå§‰∏çÂá∫Â§™Â§öÊó∂Èó¥Êù•ÂÜôÊñáÊ°£ÔºåÂõ†Ê≠§Êõ¥Êñ∞ÁöÑÈÄüÂ∫¶ÊØîËæÉÁºìÊÖ¢ÔºåÊÑüË∞¢Â§ßÂÆ∂ÁöÑÁêÜËß£„ÄÇPythonÂ∫îÁî®È¢ÜÂüüÂíåËÅå‰∏öÂèëÂ±ïÂàÜÊûêÁÆÄÂçïÁöÑËØ¥ÔºåPythonÊòØ‰∏Ä‰∏™‚Äú‰ºòÈõÖ‚Äù„ÄÅ‚ÄúÊòéÁ°Æ‚Äù„ÄÅ‚ÄúÁÆÄÂçï‚ÄùÁöÑÁºñÁ®ãËØ≠Ë®Ä„ÄÇÂ≠¶‰π†Êõ≤Á∫ø‰ΩéÔºåÈùû‰∏ì‰∏ö‰∫∫Â£´‰πüËÉΩ‰∏äÊâãÂºÄÊ∫êÁ≥ªÁªüÔºåÊã•ÊúâÂº∫Â§ßÁöÑÁîüÊÄÅÂúàËß£ÈáäÂûãËØ≠Ë®ÄÔºåÂÆåÁæéÁöÑÂπ≥Âè∞ÂèØÁßªÊ§çÊÄßÂä®ÊÄÅÁ±ªÂûãËØ≠Ë®ÄÔºåÊîØÊåÅÈù¢ÂêëÂØπË±°ÂíåÂáΩÊï∞ÂºèÁºñÁ®ã‰ª£Á†ÅËßÑËåÉÁ®ãÂ∫¶È´òÔºåÂèØËØªÊÄßÂº∫PythonÂú®‰ª•‰∏ãÈ¢ÜÂüüÈÉΩÊúâÁî®Ê≠¶‰πãÂú∞„ÄÇÂêéÁ´ØÂºÄÂèë - Python / Java / Go / PHPDevOps - Python / Shell / RubyÊï∞ÊçÆÈááÈõÜ - Python / C++ / JavaÈáèÂåñ‰∫§Êòì - Python / C++ / RÊï∞ÊçÆÁßëÂ≠¶ - Python / R / Julia / MatlabÊú∫Âô®Â≠¶‰π† - Python / R / C++ / JuliaËá™Âä®ÂåñÊµãËØï - Python / Shell‰Ωú‰∏∫‰∏ÄÂêçPythonÂºÄÂèëËÄÖÔºåÊ†πÊçÆ‰∏™‰∫∫ÁöÑÂñúÂ•ΩÂíåËÅå‰∏öËßÑÂàíÔºåÂèØ‰ª•ÈÄâÊã©ÁöÑÂ∞±‰∏öÈ¢ÜÂüü‰πüÈùûÂ∏∏Â§ö„ÄÇPythonÂêéÁ´ØÂºÄÂèëÂ∑•Á®ãÂ∏àÔºàÊúçÂä°Âô®„ÄÅ‰∫ëÂπ≥Âè∞„ÄÅÊï∞ÊçÆÊé•Âè£ÔºâPythonËøêÁª¥Â∑•Á®ãÂ∏àÔºàËá™Âä®ÂåñËøêÁª¥„ÄÅSRE„ÄÅDevOpsÔºâPythonÊï∞ÊçÆÂàÜÊûêÂ∏àÔºàÊï∞ÊçÆÂàÜÊûê„ÄÅÂïÜ‰∏öÊô∫ËÉΩ„ÄÅÊï∞Â≠óÂåñËøêËê•ÔºâPythonÊï∞ÊçÆÊåñÊéòÂ∑•Á®ãÂ∏àÔºàÊú∫Âô®Â≠¶‰π†„ÄÅÊ∑±Â∫¶Â≠¶‰π†„ÄÅÁÆóÊ≥ï‰∏ìÂÆ∂ÔºâPythonÁà¨Ëô´Â∑•Á®ãÂ∏àPythonÊµãËØïÂ∑•Á®ãÂ∏àÔºàËá™Âä®ÂåñÊµãËØï„ÄÅÊµãËØïÂºÄÂèëÔºâËØ¥ÊòéÔºöÁõÆÂâçÔºåÊï∞ÊçÆÂàÜÊûêÂíåÊï∞ÊçÆÊåñÊéòÊòØÈùûÂ∏∏ÁÉ≠Èó®ÁöÑÊñπÂêëÔºåÂõ†‰∏∫‰∏çÁÆ°ÊòØ‰∫íËÅîÁΩëË°å‰∏öËøòÊòØ‰º†ÁªüË°å‰∏öÈÉΩÂ∑≤ÁªèÁßØÁ¥Ø‰∫ÜÂ§ßÈáèÁöÑÊï∞ÊçÆÔºåÂêÑË°åÂêÑ‰∏öÈÉΩÈúÄË¶ÅÊï∞ÊçÆÂàÜÊûêÂ∏à‰ªéÂ∑≤ÊúâÁöÑÊï∞ÊçÆ‰∏≠ÂèëÁé∞Êõ¥Â§öÁöÑÂïÜ‰∏ö‰ª∑ÂÄºÔºå‰ªéËÄå‰∏∫‰ºÅ‰∏öÁöÑÂÜ≥Á≠ñÊèê‰æõÊï∞ÊçÆÁöÑÊîØÊíëÔºåËøôÂ∞±ÊòØÊâÄË∞ìÁöÑÊï∞ÊçÆÈ©±Âä®ÂÜ≥Á≠ñ„ÄÇÁªôÂàùÂ≠¶ËÄÖÁöÑÂá†‰∏™Âª∫ËÆÆÔºöMake English as your working language. ÔºàËÆ©Ëã±ËØ≠Êàê‰∏∫‰Ω†ÁöÑÂ∑•‰ΩúËØ≠Ë®ÄÔºâPractice makes perfect. ÔºàÁÜüËÉΩÁîüÂ∑ßÔºâAll experience comes from mistakes. ÔºàÊâÄÊúâÁöÑÁªèÈ™åÈÉΩÊ∫ê‰∫é‰Ω†ÁäØËøáÁöÑÈîôËØØÔºâDon't be one of the leeches. Ôºà‰∏çË¶ÅÂΩì‰º∏ÊâãÂÖöÔºâEither outstanding or out. ÔºàË¶Å‰πàÂá∫‰ºóÔºåË¶Å‰πàÂá∫Â±ÄÔºâDay01~15 - PythonËØ≠Ë®ÄÂü∫Á°ÄDay01 - ÂàùËØÜPythonPythonÁÆÄ‰ªã - PythonÁöÑÂéÜÂè≤ / PythonÁöÑ‰ºòÁº∫ÁÇπ / PythonÁöÑÂ∫îÁî®È¢ÜÂüüÊê≠Âª∫ÁºñÁ®ãÁéØÂ¢É - WindowsÁéØÂ¢É / LinuxÁéØÂ¢É / MacOSÁéØÂ¢É‰ªéÁªàÁ´ØËøêË°åPythonÁ®ãÂ∫è - Hello, world / printÂáΩÊï∞ / ËøêË°åÁ®ãÂ∫è‰ΩøÁî®IDLE - ‰∫§‰∫íÂºèÁéØÂ¢É(REPL) / ÁºñÂÜôÂ§öË°å‰ª£Á†Å / ËøêË°åÁ®ãÂ∫è / ÈÄÄÂá∫IDLEÊ≥®Èáä - Ê≥®ÈáäÁöÑ‰ΩúÁî® / ÂçïË°åÊ≥®Èáä / Â§öË°åÊ≥®ÈáäDay02 - ËØ≠Ë®ÄÂÖÉÁ¥†Á®ãÂ∫èÂíåËøõÂà∂ - Êåá‰ª§ÂíåÁ®ãÂ∫è / ÂÜØËØ∫‰æùÊõºÊú∫ / ‰∫åËøõÂà∂ÂíåÂçÅËøõÂà∂ / ÂÖ´ËøõÂà∂ÂíåÂçÅÂÖ≠ËøõÂà∂ÂèòÈáèÂíåÁ±ªÂûã - ÂèòÈáèÁöÑÂëΩÂêç / ÂèòÈáèÁöÑ‰ΩøÁî® / inputÂáΩÊï∞ / Ê£ÄÊü•ÂèòÈáèÁ±ªÂûã / Á±ªÂûãËΩ¨Êç¢Êï∞Â≠óÂíåÂ≠óÁ¨¶‰∏≤ - Êï¥Êï∞ / ÊµÆÁÇπÊï∞ / Â§çÊï∞ / Â≠óÁ¨¶‰∏≤ / Â≠óÁ¨¶‰∏≤Âü∫Êú¨Êìç‰Ωú / Â≠óÁ¨¶ÁºñÁ†ÅËøêÁÆóÁ¨¶ - Êï∞Â≠¶ËøêÁÆóÁ¨¶ / ËµãÂÄºËøêÁÆóÁ¨¶ / ÊØîËæÉËøêÁÆóÁ¨¶ / ÈÄªËæëËøêÁÆóÁ¨¶ / Ë∫´‰ªΩËøêÁÆóÁ¨¶ / ËøêÁÆóÁ¨¶ÁöÑ‰ºòÂÖàÁ∫ßÂ∫îÁî®Ê°à‰æã - ÂçéÊ∞èÊ∏©Â∫¶ËΩ¨Êç¢ÊàêÊëÑÊ∞èÊ∏©Â∫¶ / ËæìÂÖ•ÂúÜÁöÑÂçäÂæÑËÆ°ÁÆóÂë®ÈïøÂíåÈù¢ÁßØ / ËæìÂÖ•Âπ¥‰ªΩÂà§Êñ≠ÊòØÂê¶ÊòØÈó∞Âπ¥Day03 - ÂàÜÊîØÁªìÊûÑÂàÜÊîØÁªìÊûÑÁöÑÂ∫îÁî®Âú∫ÊôØ - Êù°‰ª∂ / Áº©Ëøõ / ‰ª£Á†ÅÂùó / ÊµÅÁ®ãÂõæifËØ≠Âè• - ÁÆÄÂçïÁöÑif / if-elseÁªìÊûÑ / if-elif-elseÁªìÊûÑ / ÂµåÂ•óÁöÑifÂ∫îÁî®Ê°à‰æã - Áî®Êà∑Ë∫´‰ªΩÈ™åËØÅ / Ëã±Âà∂Âçï‰Ωç‰∏éÂÖ¨Âà∂Âçï‰Ωç‰∫íÊç¢ / Êé∑È™∞Â≠êÂÜ≥ÂÆöÂÅö‰ªÄ‰πà / ÁôæÂàÜÂà∂ÊàêÁª©ËΩ¨Á≠âÁ∫ßÂà∂ / ÂàÜÊÆµÂáΩÊï∞Ê±ÇÂÄº / ËæìÂÖ•‰∏âÊù°ËæπÁöÑÈïøÂ∫¶Â¶ÇÊûúËÉΩÊûÑÊàê‰∏âËßíÂΩ¢Â∞±ËÆ°ÁÆóÂë®ÈïøÂíåÈù¢ÁßØDay04 - Âæ™ÁéØÁªìÊûÑÂæ™ÁéØÁªìÊûÑÁöÑÂ∫îÁî®Âú∫ÊôØ - Êù°‰ª∂ / Áº©Ëøõ / ‰ª£Á†ÅÂùó / ÊµÅÁ®ãÂõæwhileÂæ™ÁéØ - Âü∫Êú¨ÁªìÊûÑ / breakËØ≠Âè• / continueËØ≠Âè•forÂæ™ÁéØ - Âü∫Êú¨ÁªìÊûÑ / rangeÁ±ªÂûã / Âæ™ÁéØ‰∏≠ÁöÑÂàÜÊîØÁªìÊûÑ / ÂµåÂ•óÁöÑÂæ™ÁéØ / ÊèêÂâçÁªìÊùüÁ®ãÂ∫èÂ∫îÁî®Ê°à‰æã - 1~100Ê±ÇÂíå / Âà§Êñ≠Á¥†Êï∞ / ÁåúÊï∞Â≠óÊ∏∏Êàè / ÊâìÂç∞‰πù‰πùË°® / ÊâìÂç∞‰∏âËßíÂΩ¢ÂõæÊ°à / Áå¥Â≠êÂêÉÊ°É / ÁôæÈí±ÁôæÈ∏°Day05 - ÊûÑÈÄ†Á®ãÂ∫èÈÄªËæëÁªèÂÖ∏Ê°à‰æãÔºöÊ∞¥‰ªôËä±Êï∞ / ÁôæÈí±ÁôæÈ∏° / CrapsËµåÂçöÊ∏∏ÊàèÁªÉ‰π†È¢òÁõÆÔºöÊñêÊ≥¢ÈÇ£Â•ëÊï∞Âàó / ÂÆåÁæéÊï∞ / Á¥†Êï∞Day06 - ÂáΩÊï∞ÂíåÊ®°ÂùóÁöÑ‰ΩøÁî®ÂáΩÊï∞ÁöÑ‰ΩúÁî® - ‰ª£Á†ÅÁöÑÂùèÂë≥ÈÅì / Áî®ÂáΩÊï∞Â∞ÅË£ÖÂäüËÉΩÊ®°ÂùóÂÆö‰πâÂáΩÊï∞ - defÂÖ≥ÈîÆÂ≠ó / ÂáΩÊï∞Âêç / ÂèÇÊï∞ÂàóË°® / returnËØ≠Âè• / Ë∞ÉÁî®Ëá™ÂÆö‰πâÂáΩÊï∞Ë∞ÉÁî®ÂáΩÊï∞ - PythonÂÜÖÁΩÆÂáΩÊï∞ /  ÂØºÂÖ•Ê®°ÂùóÂíåÂáΩÊï∞ÂáΩÊï∞ÁöÑÂèÇÊï∞ - ÈªòËÆ§ÂèÇÊï∞ / ÂèØÂèòÂèÇÊï∞ / ÂÖ≥ÈîÆÂ≠óÂèÇÊï∞ / ÂëΩÂêçÂÖ≥ÈîÆÂ≠óÂèÇÊï∞ÂáΩÊï∞ÁöÑËøîÂõûÂÄº - Ê≤°ÊúâËøîÂõûÂÄº  / ËøîÂõûÂçï‰∏™ÂÄº / ËøîÂõûÂ§ö‰∏™ÂÄº‰ΩúÁî®ÂüüÈóÆÈ¢ò - Â±ÄÈÉ®‰ΩúÁî®Âüü / ÂµåÂ•ó‰ΩúÁî®Âüü / ÂÖ®Â±Ä‰ΩúÁî®Âüü / ÂÜÖÁΩÆ‰ΩúÁî®Âüü / Âíå‰ΩúÁî®ÂüüÁõ∏ÂÖ≥ÁöÑÂÖ≥ÈîÆÂ≠óÁî®Ê®°ÂùóÁÆ°ÁêÜÂáΩÊï∞ - Ê®°ÂùóÁöÑÊ¶ÇÂøµ / Áî®Ëá™ÂÆö‰πâÊ®°ÂùóÁÆ°ÁêÜÂáΩÊï∞ / ÂëΩÂêçÂÜ≤Á™ÅÁöÑÊó∂ÂÄô‰ºöÊÄéÊ†∑ÔºàÂêå‰∏Ä‰∏™Ê®°ÂùóÂíå‰∏çÂêåÁöÑÊ®°ÂùóÔºâDay07 - Â≠óÁ¨¶‰∏≤ÂíåÂ∏∏Áî®Êï∞ÊçÆÁªìÊûÑÂ≠óÁ¨¶‰∏≤ÁöÑ‰ΩøÁî® - ËÆ°ÁÆóÈïøÂ∫¶ / ‰∏ãÊ†áËøêÁÆó / ÂàáÁâá / Â∏∏Áî®ÊñπÊ≥ïÂàóË°®Âü∫Êú¨Áî®Ê≥ï - ÂÆö‰πâÂàóË°® / Áî®‰∏ãË°®ËÆøÈóÆÂÖÉÁ¥† / ‰∏ãÊ†áË∂äÁïå / Ê∑ªÂä†ÂÖÉÁ¥† / Âà†Èô§ÂÖÉÁ¥† / ‰øÆÊîπÂÖÉÁ¥† / ÂàáÁâá / Âæ™ÁéØÈÅçÂéÜÂàóË°®Â∏∏Áî®Êìç‰Ωú - ËøûÊé• / Â§çÂà∂(Â§çÂà∂ÂÖÉÁ¥†ÂíåÂ§çÂà∂Êï∞ÁªÑ) / ÈïøÂ∫¶ / ÊéíÂ∫è / ÂÄíËΩ¨ / Êü•ÊâæÁîüÊàêÂàóË°® - ‰ΩøÁî®rangeÂàõÂª∫Êï∞Â≠óÂàóË°® / ÁîüÊàêË°®ËææÂºè / ÁîüÊàêÂô®ÂÖÉÁªÑÁöÑ‰ΩøÁî® - ÂÆö‰πâÂÖÉÁªÑ / ‰ΩøÁî®ÂÖÉÁªÑ‰∏≠ÁöÑÂÄº / ‰øÆÊîπÂÖÉÁªÑÂèòÈáè / ÂÖÉÁªÑÂíåÂàóË°®ËΩ¨Êç¢ÈõÜÂêàÂü∫Êú¨Áî®Ê≥ï - ÈõÜÂêàÂíåÂàóË°®ÁöÑÂå∫Âà´ /  ÂàõÂª∫ÈõÜÂêà / Ê∑ªÂä†ÂÖÉÁ¥† / Âà†Èô§ÂÖÉÁ¥† /  Ê∏ÖÁ©∫ÈõÜÂêàÂ∏∏Áî®Êìç‰Ωú - ‰∫§ÈõÜ / Âπ∂ÈõÜ / Â∑ÆÈõÜ / ÂØπÁß∞Â∑Æ / Â≠êÈõÜ / Ë∂ÖÈõÜÂ≠óÂÖ∏ÁöÑÂü∫Êú¨Áî®Ê≥ï - Â≠óÂÖ∏ÁöÑÁâπÁÇπ / ÂàõÂª∫Â≠óÂÖ∏ / Ê∑ªÂä†ÂÖÉÁ¥† / Âà†Èô§ÂÖÉÁ¥† / ÂèñÂÄº / Ê∏ÖÁ©∫Â≠óÂÖ∏Â∏∏Áî®Êìç‰Ωú - keysÊñπÊ≥ï / valuesÊñπÊ≥ï / itemsÊñπÊ≥ï / setdefaultÊñπÊ≥ïÂü∫Á°ÄÁªÉ‰π† - Ë∑ëÈ©¨ÁÅØÊïàÊûú / ÂàóË°®ÊâæÊúÄÂ§ßÂÖÉÁ¥† / ÁªüËÆ°ËÄÉËØïÊàêÁª©ÁöÑÂπ≥ÂùáÂàÜ / FibonacciÊï∞Âàó / Êù®Ëæâ‰∏âËßíÁªºÂêàÊ°à‰æã - ÂèåËâ≤ÁêÉÈÄâÂè∑ / ‰∫ïÂ≠óÊ£ãDay08 - Èù¢ÂêëÂØπË±°ÁºñÁ®ãÂü∫Á°ÄÁ±ªÂíåÂØπË±° - ‰ªÄ‰πàÊòØÁ±ª / ‰ªÄ‰πàÊòØÂØπË±° / Èù¢ÂêëÂØπË±°ÂÖ∂‰ªñÁõ∏ÂÖ≥Ê¶ÇÂøµÂÆö‰πâÁ±ª - Âü∫Êú¨ÁªìÊûÑ / Â±ûÊÄßÂíåÊñπÊ≥ï / ÊûÑÈÄ†Âô® / ÊûêÊûÑÂô® / __str__ÊñπÊ≥ï‰ΩøÁî®ÂØπË±° - ÂàõÂª∫ÂØπË±° / ÁªôÂØπË±°ÂèëÊ∂àÊÅØÈù¢ÂêëÂØπË±°ÁöÑÂõõÂ§ßÊîØÊü± - ÊäΩË±° / Â∞ÅË£Ö / ÁªßÊâø / Â§öÊÄÅÂü∫Á°ÄÁªÉ‰π† - ÂÆö‰πâÂ≠¶ÁîüÁ±ª / ÂÆö‰πâÊó∂ÈíüÁ±ª / ÂÆö‰πâÂõæÂΩ¢Á±ª / ÂÆö‰πâÊ±ΩËΩ¶Á±ªDay09 - Èù¢ÂêëÂØπË±°ËøõÈò∂Â±ûÊÄß - Á±ªÂ±ûÊÄß / ÂÆû‰æãÂ±ûÊÄß / Â±ûÊÄßËÆøÈóÆÂô® / Â±ûÊÄß‰øÆÊîπÂô® / Â±ûÊÄßÂà†Èô§Âô® / ‰ΩøÁî®__slots__Á±ª‰∏≠ÁöÑÊñπÊ≥ï - ÂÆû‰æãÊñπÊ≥ï / Á±ªÊñπÊ≥ï / ÈùôÊÄÅÊñπÊ≥ïËøêÁÆóÁ¨¶ÈáçËΩΩ - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__Á±ª(ÁöÑÂØπË±°)‰πãÈó¥ÁöÑÂÖ≥Á≥ª - ÂÖ≥ËÅî / ÁªßÊâø / ‰æùËµñÁªßÊâøÂíåÂ§öÊÄÅ - ‰ªÄ‰πàÊòØÁªßÊâø / ÁªßÊâøÁöÑËØ≠Ê≥ï / Ë∞ÉÁî®Áà∂Á±ªÊñπÊ≥ï / ÊñπÊ≥ïÈáçÂÜô / Á±ªÂûãÂà§ÂÆö / Â§öÈáçÁªßÊâø / Ëè±ÂΩ¢ÁªßÊâø(ÈíªÁü≥ÁªßÊâø)ÂíåC3ÁÆóÊ≥ïÁªºÂêàÊ°à‰æã - Â∑•ËµÑÁªìÁÆóÁ≥ªÁªü / Âõæ‰π¶Ëá™Âä®ÊäòÊâ£Á≥ªÁªü / Ëá™ÂÆö‰πâÂàÜÊï∞Á±ªDay10 - ÂõæÂΩ¢Áî®Êà∑ÁïåÈù¢ÂíåÊ∏∏ÊàèÂºÄÂèë‰ΩøÁî®tkinterÂºÄÂèëGUIÁ®ãÂ∫è‰ΩøÁî®pygame‰∏âÊñπÂ∫ìÂºÄÂèëÊ∏∏ÊàèÂ∫îÁî®‚ÄúÂ§ßÁêÉÂêÉÂ∞èÁêÉ‚ÄùÊ∏∏ÊàèDay11 - Êñá‰ª∂ÂíåÂºÇÂ∏∏ËØªÊñá‰ª∂ - ËØªÂèñÊï¥‰∏™Êñá‰ª∂ / ÈÄêË°åËØªÂèñ / Êñá‰ª∂Ë∑ØÂæÑÂÜôÊñá‰ª∂ - Ë¶ÜÁõñÂÜôÂÖ• / ËøΩÂä†ÂÜôÂÖ• / ÊñáÊú¨Êñá‰ª∂ / ‰∫åËøõÂà∂Êñá‰ª∂ÂºÇÂ∏∏Â§ÑÁêÜ - ÂºÇÂ∏∏Êú∫Âà∂ÁöÑÈáçË¶ÅÊÄß / try-except‰ª£Á†ÅÂùó / else‰ª£Á†ÅÂùó / finally‰ª£Á†ÅÂùó / ÂÜÖÁΩÆÂºÇÂ∏∏Á±ªÂûã / ÂºÇÂ∏∏Ê†à / raiseËØ≠Âè•Êï∞ÊçÆÊåÅ‰πÖÂåñ - CSVÊñá‰ª∂Ê¶ÇËø∞ / csvÊ®°ÂùóÁöÑÂ∫îÁî® / JSONÊï∞ÊçÆÊ†ºÂºè / jsonÊ®°ÂùóÁöÑÂ∫îÁî®Day12 - Â≠óÁ¨¶‰∏≤ÂíåÊ≠£ÂàôË°®ËææÂºèÂ≠óÁ¨¶‰∏≤È´òÁ∫ßÊìç‰Ωú - ËΩ¨‰πâÂ≠óÁ¨¶ / ÂéüÂßãÂ≠óÁ¨¶‰∏≤ / Â§öË°åÂ≠óÁ¨¶‰∏≤ / inÂíånot inËøêÁÆóÁ¨¶ / is_xxxÊñπÊ≥ï / joinÂíåsplitÊñπÊ≥ï / stripÁõ∏ÂÖ≥ÊñπÊ≥ï / pyperclipÊ®°Âùó / ‰∏çÂèòÂ≠óÁ¨¶‰∏≤ÂíåÂèØÂèòÂ≠óÁ¨¶‰∏≤ / StringIOÁöÑ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÂÖ•Èó® - Ê≠£ÂàôË°®ËææÂºèÁöÑ‰ΩúÁî® / ÂÖÉÂ≠óÁ¨¶ / ËΩ¨‰πâ / ÈáèËØç / ÂàÜÁªÑ / Èõ∂ÂÆΩÊñ≠Ë®Ä /Ë¥™Â©™ÂåπÈÖç‰∏éÊÉ∞ÊÄßÂåπÈÖçÊáíÊÉ∞ / ‰ΩøÁî®reÊ®°ÂùóÂÆûÁé∞Ê≠£ÂàôË°®ËææÂºèÊìç‰ΩúÔºàÂåπÈÖç„ÄÅÊêúÁ¥¢„ÄÅÊõøÊç¢„ÄÅÊçïËé∑Ôºâ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºè - reÊ®°Âùó / compileÂáΩÊï∞ / groupÂíågroupsÊñπÊ≥ï / matchÊñπÊ≥ï / searchÊñπÊ≥ï / findallÂíåfinditerÊñπÊ≥ï / subÂíåsubnÊñπÊ≥ï / splitÊñπÊ≥ïÂ∫îÁî®Ê°à‰æã - ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÈ™åËØÅËæìÂÖ•ÁöÑÂ≠óÁ¨¶‰∏≤Day13 - ËøõÁ®ãÂíåÁ∫øÁ®ãËøõÁ®ãÂíåÁ∫øÁ®ãÁöÑÊ¶ÇÂøµ - ‰ªÄ‰πàÊòØËøõÁ®ã / ‰ªÄ‰πàÊòØÁ∫øÁ®ã / Â§öÁ∫øÁ®ãÁöÑÂ∫îÁî®Âú∫ÊôØ‰ΩøÁî®ËøõÁ®ã - forkÂáΩÊï∞ / multiprocessingÊ®°Âùó / ËøõÁ®ãÊ±† / ËøõÁ®ãÈó¥ÈÄö‰ø°‰ΩøÁî®Á∫øÁ®ã -  threadingÊ®°Âùó / ThreadÁ±ª / RLockÁ±ª / ConditionÁ±ª / Á∫øÁ®ãÊ±†Day14 - ÁΩëÁªúÁºñÁ®ãÂÖ•Èó®ÂíåÁΩëÁªúÂ∫îÁî®ÂºÄÂèëËÆ°ÁÆóÊú∫ÁΩëÁªúÂü∫Á°Ä - ËÆ°ÁÆóÊú∫ÁΩëÁªúÂèëÂ±ïÂè≤ / ‚ÄúTCP-IP‚ÄùÊ®°Âûã / IPÂú∞ÂùÄ / Á´ØÂè£ / ÂçèËÆÆ / ÂÖ∂‰ªñÁõ∏ÂÖ≥Ê¶ÇÂøµÁΩëÁªúÂ∫îÁî®Ê®°Âºè - ‚ÄúÂÆ¢Êà∑Á´Ø-ÊúçÂä°Âô®‚ÄùÊ®°Âºè / ‚ÄúÊµèËßàÂô®-ÊúçÂä°Âô®‚ÄùÊ®°ÂºèÂü∫‰∫éHTTPÂçèËÆÆËÆøÈóÆÁΩëÁªúËµÑÊ∫ê - ÁΩëÁªúAPIÊ¶ÇËø∞ / ËÆøÈóÆURL / requests‰∏âÊñπÂ∫ì / Ëß£ÊûêJSONÊ†ºÂºèÊï∞ÊçÆPythonÁΩëÁªúÁºñÁ®ã - Â•óÊé•Â≠óÁöÑÊ¶ÇÂøµ / socketÊ®°Âùó /  socketÂáΩÊï∞ / ÂàõÂª∫TCPÊúçÂä°Âô® / ÂàõÂª∫TCPÂÆ¢Êà∑Á´Ø / ÂàõÂª∫UDPÊúçÂä°Âô® / ÂàõÂª∫UDPÂÆ¢Êà∑Á´ØÁîµÂ≠êÈÇÆ‰ª∂ - SMTPÂçèËÆÆ / POP3ÂçèËÆÆ / IMAPÂçèËÆÆ / smtplibÊ®°Âùó / poplibÊ®°Âùó / imaplibÊ®°ÂùóÁü≠‰ø°ÊúçÂä° - Ë∞ÉÁî®Áü≠‰ø°ÊúçÂä°ÁΩëÂÖ≥Day15 - ÂõæÂÉèÂíåÊñáÊ°£Â§ÑÁêÜÁî®PillowÂ§ÑÁêÜÂõæÁâá - ÂõæÁâáËØªÂÜô / ÂõæÁâáÂêàÊàê / Âá†‰ΩïÂèòÊç¢ / Ëâ≤ÂΩ©ËΩ¨Êç¢ / Êª§ÈïúÊïàÊûúËØªÂÜôWordÊñáÊ°£ - ÊñáÊú¨ÂÜÖÂÆπÁöÑÂ§ÑÁêÜ / ÊÆµËêΩ / È°µÁúâÂíåÈ°µËÑö / Ê†∑ÂºèÁöÑÂ§ÑÁêÜËØªÂÜôExcelÊñá‰ª∂ - xlrd / xlwt / openpyxlDay16~Day20 - PythonËØ≠Ë®ÄËøõÈò∂ Â∏∏Áî®Êï∞ÊçÆÁªìÊûÑÂáΩÊï∞ÁöÑÈ´òÁ∫ßÁî®Ê≥ï - ‚Äú‰∏ÄÁ≠âÂÖ¨Ê∞ë‚Äù / È´òÈò∂ÂáΩÊï∞ / LambdaÂáΩÊï∞ / ‰ΩúÁî®ÂüüÂíåÈó≠ÂåÖ / Ë£ÖÈ•∞Âô®Èù¢ÂêëÂØπË±°È´òÁ∫ßÁü•ËØÜ - ‚Äú‰∏âÂ§ßÊîØÊü±‚Äù / Á±ª‰∏éÁ±ª‰πãÈó¥ÁöÑÂÖ≥Á≥ª / ÂûÉÂúæÂõûÊî∂ / È≠îÊúØÂ±ûÊÄßÂíåÊñπÊ≥ï / Ê∑∑ÂÖ• / ÂÖÉÁ±ª / Èù¢ÂêëÂØπË±°ËÆæËÆ°ÂéüÂàô / GoFËÆæËÆ°Ê®°ÂºèËø≠‰ª£Âô®ÂíåÁîüÊàêÂô® - Áõ∏ÂÖ≥È≠îÊúØÊñπÊ≥ï / ÂàõÂª∫ÁîüÊàêÂô®ÁöÑ‰∏§ÁßçÊñπÂºè /Âπ∂ÂèëÂíåÂºÇÊ≠•ÁºñÁ®ã - Â§öÁ∫øÁ®ã / Â§öËøõÁ®ã / ÂºÇÊ≠•IO / asyncÂíåawaitDay21~30 - WebÂâçÁ´ØÂÖ•Èó®Áî®HTMLÊ†áÁ≠æÊâøËΩΩÈ°µÈù¢ÂÜÖÂÆπÁî®CSSÊ∏≤ÊüìÈ°µÈù¢Áî®JavaScriptÂ§ÑÁêÜ‰∫§‰∫íÂºèË°å‰∏∫jQueryÂÖ•Èó®ÂíåÊèêÈ´òVue.jsÂÖ•Èó®ElementÁöÑ‰ΩøÁî®BootstrapÁöÑ‰ΩøÁî®Day31~35 - Áé©ËΩ¨LinuxÊìç‰ΩúÁ≥ªÁªüÊìç‰ΩúÁ≥ªÁªüÂèëÂ±ïÂè≤ÂíåLinuxÊ¶ÇËø∞LinuxÂü∫Á°ÄÂëΩ‰ª§Linux‰∏≠ÁöÑÂÆûÁî®Á®ãÂ∫èLinuxÁöÑÊñá‰ª∂Á≥ªÁªüVimÁºñËæëÂô®ÁöÑÂ∫îÁî®ÁéØÂ¢ÉÂèòÈáèÂíåShellÁºñÁ®ãËΩØ‰ª∂ÁöÑÂÆâË£ÖÂíåÊúçÂä°ÁöÑÈÖçÁΩÆÁΩëÁªúËÆøÈóÆÂíåÁÆ°ÁêÜÂÖ∂‰ªñÁõ∏ÂÖ≥ÂÜÖÂÆπDay36~40 - Êï∞ÊçÆÂ∫ìÂü∫Á°ÄÂíåËøõÈò∂ÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÊ¶ÇËø∞MySQLÁöÑÂÆâË£ÖÂíå‰ΩøÁî®SQLÁöÑ‰ΩøÁî®DDL - Êï∞ÊçÆÂÆö‰πâËØ≠Ë®Ä - create / drop / alterDML - Êï∞ÊçÆÊìç‰ΩúËØ≠Ë®Ä - insert / delete / updateDQL - Êï∞ÊçÆÊü•ËØ¢ËØ≠Ë®Ä - selectDCL - Êï∞ÊçÆÊéßÂà∂ËØ≠Ë®Ä - grant / revokeMySQLÊñ∞ÁâπÊÄßÁ™óÂè£ÂáΩÊï∞ÁöÑÂ∫îÁî®JSONÊï∞ÊçÆÁ±ªÂûãÁõ∏ÂÖ≥Áü•ËØÜÊï∞ÊçÆÂÆåÊï¥ÊÄßÂíå‰∏ÄËá¥ÊÄßËßÜÂõæ„ÄÅÂáΩÊï∞„ÄÅËøáÁ®ã„ÄÅËß¶ÂèëÂô®‰∫ãÂä°ÂíåÈîÅÊâßË°åËÆ°ÂàíÂíåÁ¥¢ÂºïËåÉÂºèÁêÜËÆ∫ÂíåÂèçËåÉÂºèËÆæËÆ°Âú®Python‰∏≠Êìç‰ΩúMySQLDay41~55 - ÂÆûÊàòDjangoDay41 - DjangoÂø´ÈÄü‰∏äÊâãWebÂ∫îÁî®Â∑•‰ΩúÊú∫Âà∂HTTPËØ∑Ê±ÇÂíåÂìçÂ∫îDjangoÊ°ÜÊû∂Ê¶ÇËø∞5ÂàÜÈíüÂø´ÈÄü‰∏äÊâãDay42 - Ê∑±ÂÖ•Ê®°ÂûãÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÈÖçÁΩÆ‰ΩøÁî®ORMÂÆåÊàêÂØπÊ®°ÂûãÁöÑCRUDÊìç‰ΩúÁÆ°ÁêÜÂêéÂè∞ÁöÑ‰ΩøÁî®DjangoÊ®°ÂûãÊúÄ‰Ω≥ÂÆûË∑µÊ®°ÂûãÂÆö‰πâÂèÇËÄÉDay43 - ÈùôÊÄÅËµÑÊ∫êÂíåAjaxËØ∑Ê±ÇÂä†ËΩΩÈùôÊÄÅËµÑÊ∫êAjaxÊ¶ÇËø∞Áî®AjaxÂÆûÁé∞ÊäïÁ•®ÂäüËÉΩDay44 - CookieÂíåSessionÂÆûÁé∞Áî®Êà∑Ë∑üË∏™cookieÂíåsessionÁöÑÂÖ≥Á≥ªDjangoÊ°ÜÊû∂ÂØπsessionÁöÑÊîØÊåÅËßÜÂõæÂáΩÊï∞‰∏≠ÁöÑcookieËØªÂÜôÊìç‰ΩúDay45 - Êä•Ë°®ÂíåÊó•ÂøóÈÄöËøáHttpResponse‰øÆÊîπÂìçÂ∫îÂ§¥‰ΩøÁî®StreamingHttpResponseÂ§ÑÁêÜÂ§ßÊñá‰ª∂‰ΩøÁî®xlwtÁîüÊàêExcelÊä•Ë°®‰ΩøÁî®reportlabÁîüÊàêPDFÊä•Ë°®‰ΩøÁî®EChartsÁîüÊàêÂâçÁ´ØÂõæË°®Day46 - Êó•ÂøóÂíåË∞ÉËØïÂ∑•ÂÖ∑Ê†èÈÖçÁΩÆÊó•ÂøóÈÖçÁΩÆDjango-Debug-Toolbar‰ºòÂåñORM‰ª£Á†ÅDay47 - ‰∏≠Èó¥‰ª∂ÁöÑÂ∫îÁî®‰ªÄ‰πàÊòØ‰∏≠Èó¥‰ª∂DjangoÊ°ÜÊû∂ÂÜÖÁΩÆÁöÑ‰∏≠Èó¥‰ª∂Ëá™ÂÆö‰πâ‰∏≠Èó¥‰ª∂ÂèäÂÖ∂Â∫îÁî®Âú∫ÊôØDay48 - ÂâçÂêéÁ´ØÂàÜÁ¶ªÂºÄÂèëÂÖ•Èó®ËøîÂõûJSONÊ†ºÂºèÁöÑÊï∞ÊçÆÁî®Vue.jsÊ∏≤ÊüìÈ°µÈù¢Day49 - RESTfulÊû∂ÊûÑÂíåDRFÂÖ•Èó®Day50 - RESTfulÊû∂ÊûÑÂíåDRFËøõÈò∂Day51 - ‰ΩøÁî®ÁºìÂ≠òÁΩëÁ´ô‰ºòÂåñÁ¨¨‰∏ÄÂÆöÂæãÂú®DjangoÈ°πÁõÆ‰∏≠‰ΩøÁî®RedisÊèê‰æõÁºìÂ≠òÊúçÂä°Âú®ËßÜÂõæÂáΩÊï∞‰∏≠ËØªÂÜôÁºìÂ≠ò‰ΩøÁî®Ë£ÖÈ•∞Âô®ÂÆûÁé∞È°µÈù¢ÁºìÂ≠ò‰∏∫Êï∞ÊçÆÊé•Âè£Êèê‰æõÁºìÂ≠òÊúçÂä°Day52 - Êé•ÂÖ•‰∏âÊñπÂπ≥Âè∞Êñá‰ª∂‰∏ä‰º†Ë°®ÂçïÊéß‰ª∂ÂíåÂõæÁâáÊñá‰ª∂È¢ÑËßàÊúçÂä°Âô®Á´ØÂ¶Ç‰ΩïÂ§ÑÁêÜ‰∏ä‰º†ÁöÑÊñá‰ª∂Day53 - ÂºÇÊ≠•‰ªªÂä°ÂíåÂÆöÊó∂‰ªªÂä°ÁΩëÁ´ô‰ºòÂåñÁ¨¨‰∫åÂÆöÂæãÈÖçÁΩÆÊ∂àÊÅØÈòüÂàóÊúçÂä°Âú®È°πÁõÆ‰∏≠‰ΩøÁî®CeleryÂÆûÁé∞‰ªªÂä°ÂºÇÊ≠•ÂåñÂú®È°πÁõÆ‰∏≠‰ΩøÁî®CeleryÂÆûÁé∞ÂÆöÊó∂‰ªªÂä°Day54 - ÂçïÂÖÉÊµãËØïDay55 - È°πÁõÆ‰∏äÁ∫øPython‰∏≠ÁöÑÂçïÂÖÉÊµãËØïDjangoÊ°ÜÊû∂ÂØπÂçïÂÖÉÊµãËØïÁöÑÊîØÊåÅ‰ΩøÁî®ÁâàÊú¨ÊéßÂà∂Á≥ªÁªüÈÖçÁΩÆÂíå‰ΩøÁî®uWSGIÂä®ÈùôÂàÜÁ¶ªÂíåNginxÈÖçÁΩÆÈÖçÁΩÆHTTPSÈÖçÁΩÆÂüüÂêçËß£ÊûêDay56~60 - Áî®FastAPIÂºÄÂèëÊï∞ÊçÆÊé•Âè£FastAPI‰∫îÂàÜÈíü‰∏äÊâãËØ∑Ê±ÇÂíåÂìçÂ∫îÊé•ÂÖ•ÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ì‰æùËµñÊ≥®ÂÖ•‰∏≠Èó¥‰ª∂ÂºÇÊ≠•ÂåñËôöÊãüÂåñÈÉ®ÁΩ≤ÔºàDockerÔºâÈ°πÁõÆÂÆûÊàòÔºöËΩ¶ËæÜËøùÁ´†Êü•ËØ¢È°πÁõÆDay61~65 - Áà¨Ëô´ÂºÄÂèëDay61 - ÁΩëÁªúÊï∞ÊçÆÈááÈõÜÊ¶ÇËø∞ÁΩëÁªúÁà¨Ëô´ÁöÑÊ¶ÇÂøµÂèäÂÖ∂Â∫îÁî®È¢ÜÂüüÁΩëÁªúÁà¨Ëô´ÁöÑÂêàÊ≥ïÊÄßÊé¢ËÆ®ÂºÄÂèëÁΩëÁªúÁà¨Ëô´ÁöÑÁõ∏ÂÖ≥Â∑•ÂÖ∑‰∏Ä‰∏™Áà¨Ëô´Á®ãÂ∫èÁöÑÊûÑÊàêDay62 - Êï∞ÊçÆÊäìÂèñÂíåËß£Êûê‰ΩøÁî®requests‰∏âÊñπÂ∫ìÂÆûÁé∞Êï∞ÊçÆÊäìÂèñÈ°µÈù¢Ëß£ÊûêÁöÑ‰∏âÁßçÊñπÂºèÊ≠£ÂàôË°®ËææÂºèËß£ÊûêXPathËß£ÊûêCSSÈÄâÊã©Âô®Ëß£ÊûêDay63 - Python‰∏≠ÁöÑÂπ∂ÂèëÁºñÁ®ãÂ§öÁ∫øÁ®ãÂ§öËøõÁ®ãÂºÇÊ≠•I/ODay64 - ‰ΩøÁî®SeleniumÊäìÂèñÁΩëÈ°µÂä®ÊÄÅÂÜÖÂÆπDay65 - Áà¨Ëô´Ê°ÜÊû∂ScrapyÁÆÄ‰ªãDay66~80 - Êï∞ÊçÆÂàÜÊûêDay66 - Êï∞ÊçÆÂàÜÊûêÊ¶ÇËø∞Day67 - ÁéØÂ¢ÉÂáÜÂ§áDay68 - NumPyÁöÑÂ∫îÁî®-1Day69 - NumPyÁöÑÂ∫îÁî®-2Day70 - PandasÁöÑÂ∫îÁî®-1Day71 - PandasÁöÑÂ∫îÁî®-2Day72 - PandasÁöÑÂ∫îÁî®-3Day73 - PandasÁöÑÂ∫îÁî®-4Day74 - PandasÁöÑÂ∫îÁî®-5Day75 - Êï∞ÊçÆÂèØËßÜÂåñ-1Day76 - Êï∞ÊçÆÂèØËßÜÂåñ-2Day77 - Ê¶ÇÁéáÁªüËÆ°Âü∫Á°ÄDay78 - ÊñπÂ∑ÆÂàÜÊûêÂíåÂèÇÊï∞‰º∞ËÆ°Day79 - Áõ∏ÂÖ≥ÂíåÂõûÂΩíDay80 - Êï∞ÊçÆÂàÜÊûêÊñπÊ≥ïËÆ∫Day81~90 - Êú∫Âô®Â≠¶‰π†ÂíåÊ∑±Â∫¶Â≠¶‰π†Day81 - Êú∫Âô®Â≠¶‰π†Âü∫Á°ÄDay82 - kÊúÄËøëÈÇªÂàÜÁ±ªDay83 - ÂÜ≥Á≠ñÊ†ëDay84 - Ë¥ùÂè∂ÊñØÂàÜÁ±ªDay85 - ÊîØÊåÅÂêëÈáèÊú∫Day86 - K-ÂùáÂÄºËÅöÁ±ªDay87 - ÂõûÂΩíÂàÜÊûêDay88 - Ê∑±Â∫¶Â≠¶‰π†ÂÖ•Èó®Day89 - PyTorchÊ¶ÇËø∞Day90 - PyTorchÂÆûÊàòDay91~100 - Âõ¢ÈòüÈ°πÁõÆÂºÄÂèëÁ¨¨91Â§©ÔºöÂõ¢ÈòüÈ°πÁõÆÂºÄÂèëÁöÑÈóÆÈ¢òÂíåËß£ÂÜ≥ÊñπÊ°àËΩØ‰ª∂ËøáÁ®ãÊ®°ÂûãÁªèÂÖ∏ËøáÁ®ãÊ®°ÂûãÔºàÁÄëÂ∏ÉÊ®°ÂûãÔºâÂèØË°åÊÄßÂàÜÊûêÔºàÁ†îÁ©∂ÂÅöËøòÊòØ‰∏çÂÅöÔºâÔºåËæìÂá∫„ÄäÂèØË°åÊÄßÂàÜÊûêÊä•Âëä„Äã„ÄÇÈúÄÊ±ÇÂàÜÊûêÔºàÁ†îÁ©∂ÂÅö‰ªÄ‰πàÔºâÔºåËæìÂá∫„ÄäÈúÄÊ±ÇËßÑÊ†ºËØ¥Êòé‰π¶„ÄãÂíå‰∫ßÂìÅÁïåÈù¢ÂéüÂûãÂõæ„ÄÇÊ¶ÇË¶ÅËÆæËÆ°ÂíåËØ¶ÁªÜËÆæËÆ°ÔºåËæìÂá∫Ê¶ÇÂøµÊ®°ÂûãÂõæÔºàERÂõæÔºâ„ÄÅÁâ©ÁêÜÊ®°ÂûãÂõæ„ÄÅÁ±ªÂõæ„ÄÅÊó∂Â∫èÂõæÁ≠â„ÄÇÁºñÁ†Å / ÊµãËØï„ÄÇ‰∏äÁ∫ø / Áª¥Êä§„ÄÇÁÄëÂ∏ÉÊ®°ÂûãÊúÄÂ§ßÁöÑÁº∫ÁÇπÊòØÊó†Ê≥ïÊã•Êä±ÈúÄÊ±ÇÂèòÂåñÔºåÊï¥Â•óÊµÅÁ®ãÁªìÊùüÂêéÊâçËÉΩÁúãÂà∞‰∫ßÂìÅÔºåÂõ¢ÈòüÂ£´Ê∞î‰ΩéËêΩ„ÄÇÊïèÊç∑ÂºÄÂèëÔºàScrumÔºâ- ‰∫ßÂìÅÊâÄÊúâËÄÖ„ÄÅScrum Master„ÄÅÁ†îÂèë‰∫∫Âëò - Sprint‰∫ßÂìÅÁöÑBacklogÔºàÁî®Êà∑ÊïÖ‰∫ã„ÄÅ‰∫ßÂìÅÂéüÂûãÔºâ„ÄÇËÆ°Âàí‰ºöËÆÆÔºàËØÑ‰º∞ÂíåÈ¢ÑÁÆóÔºâ„ÄÇÊó•Â∏∏ÂºÄÂèëÔºàÁ´ôÁ´ã‰ºöËÆÆ„ÄÅÁï™ËåÑÂ∑•‰ΩúÊ≥ï„ÄÅÁªìÂØπÁºñÁ®ã„ÄÅÊµãËØïÂÖàË°å„ÄÅ‰ª£Á†ÅÈáçÊûÑ‚Ä¶‚Ä¶Ôºâ„ÄÇ‰øÆÂ§çbugÔºàÈóÆÈ¢òÊèèËø∞„ÄÅÈáçÁé∞Ê≠•È™§„ÄÅÊµãËØï‰∫∫Âëò„ÄÅË¢´ÊåáÊ¥æ‰∫∫Ôºâ„ÄÇÂèëÂ∏ÉÁâàÊú¨„ÄÇËØÑÂÆ°‰ºöËÆÆÔºàShowcaseÔºåÁî®Êà∑ÈúÄË¶ÅÂèÇ‰∏éÔºâ„ÄÇÂõûÈ°æ‰ºöËÆÆÔºàÂØπÂΩìÂâçËø≠‰ª£Âë®ÊúüÂÅö‰∏Ä‰∏™ÊÄªÁªìÔºâ„ÄÇË°•ÂÖÖÔºöÊïèÊç∑ËΩØ‰ª∂ÂºÄÂèëÂÆ£Ë®Ä‰∏™‰ΩìÂíå‰∫íÂä® È´ò‰∫é ÊµÅÁ®ãÂíåÂ∑•ÂÖ∑Â∑•‰ΩúÁöÑËΩØ‰ª∂ È´ò‰∫é ËØ¶Â∞ΩÁöÑÊñáÊ°£ÂÆ¢Êà∑Âêà‰Ωú È´ò‰∫é ÂêàÂêåË∞àÂà§ÂìçÂ∫îÂèòÂåñ È´ò‰∫é ÈÅµÂæ™ËÆ°ÂàíËßíËâ≤Ôºö‰∫ßÂìÅÊâÄÊúâËÄÖÔºàÂÜ≥ÂÆöÂÅö‰ªÄ‰πàÔºåËÉΩÂØπÈúÄÊ±ÇÊãçÊùøÁöÑ‰∫∫Ôºâ„ÄÅÂõ¢ÈòüË¥üË¥£‰∫∫ÔºàËß£ÂÜ≥ÂêÑÁßçÈóÆÈ¢òÔºå‰∏ìÊ≥®Â¶Ç‰ΩïÊõ¥Â•ΩÁöÑÂ∑•‰ΩúÔºåÂ±èËîΩÂ§ñÈÉ®ÂØπÂºÄÂèëÂõ¢ÈòüÁöÑÂΩ±ÂìçÔºâ„ÄÅÂºÄÂèëÂõ¢ÈòüÔºàÈ°πÁõÆÊâßË°å‰∫∫ÂëòÔºåÂÖ∑‰ΩìÊåáÂºÄÂèë‰∫∫ÂëòÂíåÊµãËØï‰∫∫ÂëòÔºâ„ÄÇÂáÜÂ§áÂ∑•‰ΩúÔºöÂïÜ‰∏öÊ°à‰æãÂíåËµÑÈáë„ÄÅÂêàÂêå„ÄÅÊÜßÊÜ¨„ÄÅÂàùÂßã‰∫ßÂìÅÈúÄÊ±Ç„ÄÅÂàùÂßãÂèëÂ∏ÉËÆ°Âàí„ÄÅÂÖ•ËÇ°„ÄÅÁªÑÂª∫Âõ¢Èòü„ÄÇÊïèÊç∑Âõ¢ÈòüÈÄöÂ∏∏‰∫∫Êï∞‰∏∫8-10‰∫∫„ÄÇÂ∑•‰ΩúÈáè‰º∞ÁÆóÔºöÂ∞ÜÂºÄÂèë‰ªªÂä°ÈáèÂåñÔºåÂåÖÊã¨ÂéüÂûã„ÄÅLogoËÆæËÆ°„ÄÅUIËÆæËÆ°„ÄÅÂâçÁ´ØÂºÄÂèëÁ≠âÔºåÂ∞ΩÈáèÊääÊØè‰∏™Â∑•‰ΩúÂàÜËß£Âà∞ÊúÄÂ∞è‰ªªÂä°ÈáèÔºåÊúÄÂ∞è‰ªªÂä°ÈáèÊ†áÂáÜ‰∏∫Â∑•‰ΩúÊó∂Èó¥‰∏çËÉΩË∂ÖËøá‰∏§Â§©ÔºåÁÑ∂Âêé‰º∞ÁÆóÊÄª‰ΩìÈ°πÁõÆÊó∂Èó¥„ÄÇÊääÊØè‰∏™‰ªªÂä°ÈÉΩË¥¥Âú®ÁúãÊùø‰∏äÈù¢ÔºåÁúãÊùø‰∏äÂàÜ‰∏âÈÉ®ÂàÜÔºöto doÔºàÂæÖÂÆåÊàêÔºâ„ÄÅin progressÔºàËøõË°å‰∏≠ÔºâÂíådoneÔºàÂ∑≤ÂÆåÊàêÔºâ„ÄÇÈ°πÁõÆÂõ¢ÈòüÁªÑÂª∫Âõ¢ÈòüÁöÑÊûÑÊàêÂíåËßíËâ≤ËØ¥ÊòéÔºöË∞¢Ë∞¢‰ªòÁ••Ëã±Â•≥Â£´Â∏ÆÂä©ÊàëÁªòÂà∂‰∫Ü‰∏ãÈù¢ËøôÂº†Á≤æÁæéÁöÑÂÖ¨Âè∏ÁªÑÁªáÊû∂ÊûÑÂõæ„ÄÇÁºñÁ®ãËßÑËåÉÂíå‰ª£Á†ÅÂÆ°Êü•Ôºàflake8„ÄÅpylintÔºâPython‰∏≠ÁöÑ‰∏Ä‰∫õ‚ÄúÊÉØ‰æã‚ÄùÔºàËØ∑ÂèÇËÄÉ„ÄäPythonÊÉØ‰æã-Â¶Ç‰ΩïÁºñÂÜôPythonicÁöÑ‰ª£Á†Å„ÄãÔºâÂΩ±Âìç‰ª£Á†ÅÂèØËØªÊÄßÁöÑÂéüÂõ†Ôºö‰ª£Á†ÅÊ≥®ÈáäÂ§™Â∞ëÊàñËÄÖÊ≤°ÊúâÊ≥®Èáä‰ª£Á†ÅÁ†¥Âùè‰∫ÜËØ≠Ë®ÄÁöÑÊúÄ‰Ω≥ÂÆûË∑µÂèçÊ®°ÂºèÁºñÁ®ãÔºàÊÑèÂ§ßÂà©Èù¢‰ª£Á†Å„ÄÅÂ§çÂà∂-ÈªèË¥¥ÁºñÁ®ã„ÄÅËá™Ë¥üÁºñÁ®ã„ÄÅ‚Ä¶‚Ä¶ÔºâÂõ¢ÈòüÂºÄÂèëÂ∑•ÂÖ∑‰ªãÁªçÁâàÊú¨ÊéßÂà∂ÔºöGit„ÄÅMercuryÁº∫Èô∑ÁÆ°ÁêÜÔºöGitlab„ÄÅRedmineÊïèÊç∑Èó≠ÁéØÂ∑•ÂÖ∑ÔºöÁ¶ÖÈÅì„ÄÅJIRAÊåÅÁª≠ÈõÜÊàêÔºöJenkins„ÄÅTravis-CIËØ∑ÂèÇËÄÉ„ÄäÂõ¢ÈòüÈ°πÁõÆÂºÄÂèëÁöÑÈóÆÈ¢òÂíåËß£ÂÜ≥ÊñπÊ°à„Äã„ÄÇÈ°πÁõÆÈÄâÈ¢òÂíåÁêÜËß£‰∏öÂä°ÈÄâÈ¢òËåÉÂõ¥ËÆæÂÆöCMSÔºàÁî®Êà∑Á´ØÔºâÔºöÊñ∞ÈóªËÅöÂêàÁΩëÁ´ô„ÄÅÈóÆÁ≠î/ÂàÜ‰∫´Á§æÂå∫„ÄÅÂΩ±ËØÑ/‰π¶ËØÑÁΩëÁ´ôÁ≠â„ÄÇMISÔºàÁî®Êà∑Á´Ø+ÁÆ°ÁêÜÁ´ØÔºâÔºöKMS„ÄÅKPIËÄÉÊ†∏Á≥ªÁªü„ÄÅHRS„ÄÅCRMÁ≥ªÁªü„ÄÅ‰æõÂ∫îÈìæÁ≥ªÁªü„ÄÅ‰ªìÂÇ®ÁÆ°ÁêÜÁ≥ªÁªüÁ≠â„ÄÇAppÂêéÂè∞ÔºàÁÆ°ÁêÜÁ´Ø+Êï∞ÊçÆÊé•Âè£ÔºâÔºö‰∫åÊâã‰∫§ÊòìÁ±ª„ÄÅÊä•ÂàäÊùÇÂøóÁ±ª„ÄÅÂ∞è‰ºóÁîµÂïÜÁ±ª„ÄÅÊñ∞ÈóªËµÑËÆØÁ±ª„ÄÅÊóÖÊ∏∏Á±ª„ÄÅÁ§æ‰∫§Á±ª„ÄÅÈòÖËØªÁ±ªÁ≠â„ÄÇÂÖ∂‰ªñÁ±ªÂûãÔºöËá™Ë∫´Ë°å‰∏öËÉåÊôØÂíåÂ∑•‰ΩúÁªèÈ™å„ÄÅ‰∏öÂä°ÂÆπÊòìÁêÜËß£ÂíåÊääÊéß„ÄÇÈúÄÊ±ÇÁêÜËß£„ÄÅÊ®°ÂùóÂàíÂàÜÂíå‰ªªÂä°ÂàÜÈÖçÈúÄÊ±ÇÁêÜËß£ÔºöÂ§¥ËÑëÈ£éÊö¥ÂíåÁ´ûÂìÅÂàÜÊûê„ÄÇÊ®°ÂùóÂàíÂàÜÔºöÁîªÊÄùÁª¥ÂØºÂõæÔºàXMindÔºâÔºåÊØè‰∏™Ê®°ÂùóÊòØ‰∏Ä‰∏™ÊûùËäÇÁÇπÔºåÊØè‰∏™ÂÖ∑‰ΩìÁöÑÂäüËÉΩÊòØ‰∏Ä‰∏™Âè∂ËäÇÁÇπÔºàÁî®Âä®ËØçË°®Ëø∞ÔºâÔºåÈúÄË¶ÅÁ°Æ‰øùÊØè‰∏™Âè∂ËäÇÁÇπÊó†Ê≥ïÂÜçÁîüÂá∫Êñ∞ËäÇÁÇπÔºåÁ°ÆÂÆöÊØè‰∏™Âè∂Â≠êËäÇÁÇπÁöÑÈáçË¶ÅÊÄß„ÄÅ‰ºòÂÖàÁ∫ßÂíåÂ∑•‰ΩúÈáè„ÄÇ‰ªªÂä°ÂàÜÈÖçÔºöÁî±È°πÁõÆË¥üË¥£‰∫∫Ê†πÊçÆ‰∏äÈù¢ÁöÑÊåáÊ†á‰∏∫ÊØè‰∏™Âõ¢ÈòüÊàêÂëòÂàÜÈÖç‰ªªÂä°„ÄÇÂà∂ÂÆöÈ°πÁõÆËøõÂ∫¶Ë°®ÔºàÊØèÊó•Êõ¥Êñ∞ÔºâÊ®°ÂùóÂäüËÉΩ‰∫∫ÂëòÁä∂ÊÄÅÂÆåÊàêÂ∑•Êó∂ËÆ°ÂàíÂºÄÂßãÂÆûÈôÖÂºÄÂßãËÆ°ÂàíÁªìÊùüÂÆûÈôÖÁªìÊùüÂ§áÊ≥®ËØÑËÆ∫Ê∑ªÂä†ËØÑËÆ∫ÁéãÂ§ßÈî§Ê≠£Âú®ËøõË°å50%42018/8/72018/8/7Âà†Èô§ËØÑËÆ∫ÁéãÂ§ßÈî§Á≠âÂæÖ0%22018/8/72018/8/7Êü•ÁúãËØÑËÆ∫ÁôΩÂÖÉËä≥Ê≠£Âú®ËøõË°å20%42018/8/72018/8/7ÈúÄË¶ÅËøõË°å‰ª£Á†ÅÂÆ°Êü•ËØÑËÆ∫ÊäïÁ•®ÁôΩÂÖÉËä≥Á≠âÂæÖ0%42018/8/82018/8/8OOADÂíåÊï∞ÊçÆÂ∫ìËÆæËÆ°UMLÔºàÁªü‰∏ÄÂª∫Ê®°ËØ≠Ë®ÄÔºâÁöÑÁ±ªÂõæÈÄöËøáÊ®°ÂûãÂàõÂª∫Ë°®ÔºàÊ≠£ÂêëÂ∑•Á®ãÔºâÔºå‰æãÂ¶ÇÂú®DjangoÈ°πÁõÆ‰∏≠ÂèØ‰ª•ÈÄöËøá‰∏ãÈù¢ÁöÑÂëΩ‰ª§ÂàõÂª∫‰∫åÁª¥Ë°®„ÄÇpython manage.py makemigrations apppython manage.py migrate‰ΩøÁî®PowerDesignerÁªòÂà∂Áâ©ÁêÜÊ®°ÂûãÂõæ„ÄÇÈÄöËøáÊï∞ÊçÆË°®ÂàõÂª∫Ê®°ÂûãÔºàÂèçÂêëÂ∑•Á®ãÔºâÔºå‰æãÂ¶ÇÂú®DjangoÈ°πÁõÆ‰∏≠ÂèØ‰ª•ÈÄöËøá‰∏ãÈù¢ÁöÑÂëΩ‰ª§ÁîüÊàêÊ®°Âûã„ÄÇpython manage.py inspectdb > app/models.pyÁ¨¨92Â§©ÔºöDockerÂÆπÂô®ËØ¶Ëß£DockerÁÆÄ‰ªãÂÆâË£ÖDocker‰ΩøÁî®DockerÂàõÂª∫ÂÆπÂô®ÔºàNginx„ÄÅMySQL„ÄÅRedis„ÄÅGitlab„ÄÅJenkinsÔºâÊûÑÂª∫DockerÈïúÂÉèÔºàDockerfileÁöÑÁºñÂÜôÂíåÁõ∏ÂÖ≥Êåá‰ª§ÔºâÂÆπÂô®ÁºñÊéíÔºàDocker-composeÔºâÈõÜÁæ§ÁÆ°ÁêÜÔºàKubernetesÔºâÁ¨¨93Â§©ÔºöMySQLÊÄßËÉΩ‰ºòÂåñÁ¨¨94Â§©ÔºöÁΩëÁªúAPIÊé•Âè£ËÆæËÆ°Á¨¨95Â§©Ôºö[‰ΩøÁî®DjangoÂºÄÂèëÂïÜ‰∏öÈ°πÁõÆ](./Day91-100/95.‰ΩøÁî®DjangoÂºÄÂèëÂïÜ‰∏öÈ°π\tÁõÆ.md)È°πÁõÆÂºÄÂèë‰∏≠ÁöÑÂÖ¨ÂÖ±ÈóÆÈ¢òÊï∞ÊçÆÂ∫ìÁöÑÈÖçÁΩÆÔºàÂ§öÊï∞ÊçÆÂ∫ì„ÄÅ‰∏ª‰ªéÂ§çÂà∂„ÄÅÊï∞ÊçÆÂ∫ìË∑ØÁî±ÔºâÁºìÂ≠òÁöÑÈÖçÁΩÆÔºàÂàÜÂå∫ÁºìÂ≠ò„ÄÅÈîÆËÆæÁΩÆ„ÄÅË∂ÖÊó∂ËÆæÁΩÆ„ÄÅ‰∏ª‰ªéÂ§çÂà∂„ÄÅÊïÖÈöúÊÅ¢Â§çÔºàÂì®ÂÖµÔºâÔºâÊó•ÂøóÁöÑÈÖçÁΩÆÂàÜÊûêÂíåË∞ÉËØïÔºàDjango-Debug-ToolBarÔºâÂ•ΩÁî®ÁöÑPythonÊ®°ÂùóÔºàÊó•ÊúüËÆ°ÁÆó„ÄÅÂõæÂÉèÂ§ÑÁêÜ„ÄÅÊï∞ÊçÆÂä†ÂØÜ„ÄÅ‰∏âÊñπAPIÔºâREST APIËÆæËÆ°RESTfulÊû∂ÊûÑÁêÜËß£RESTfulÊû∂ÊûÑRESTful APIËÆæËÆ°ÊåáÂçóRESTful APIÊúÄ‰Ω≥ÂÆûË∑µAPIÊé•Âè£ÊñáÊ°£ÁöÑÊí∞ÂÜôRAP2YAPIdjango-REST-frameworkÁöÑÂ∫îÁî®È°πÁõÆ‰∏≠ÁöÑÈáçÁÇπÈöæÁÇπÂâñÊûê‰ΩøÁî®ÁºìÂ≠òÁºìËß£Êï∞ÊçÆÂ∫ìÂéãÂäõ - Redis‰ΩøÁî®Ê∂àÊÅØÈòüÂàóÂÅöËß£ËÄ¶ÂêàÂíåÂâäÂ≥∞ - Celery + RabbitMQÁ¨¨96Â§©ÔºöËΩØ‰ª∂ÊµãËØïÂíåËá™Âä®ÂåñÊµãËØïÂçïÂÖÉÊµãËØïÊµãËØïÁöÑÁßçÁ±ªÁºñÂÜôÂçïÂÖÉÊµãËØïÔºàunittest„ÄÅpytest„ÄÅnose2„ÄÅtox„ÄÅddt„ÄÅ‚Ä¶‚Ä¶ÔºâÊµãËØïË¶ÜÁõñÁéáÔºàcoverageÔºâDjangoÈ°πÁõÆÈÉ®ÁΩ≤ÈÉ®ÁΩ≤ÂâçÁöÑÂáÜÂ§áÂ∑•‰ΩúÂÖ≥ÈîÆËÆæÁΩÆÔºàSECRET_KEY / DEBUG / ALLOWED_HOSTS / ÁºìÂ≠ò / Êï∞ÊçÆÂ∫ìÔºâHTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECUREÊó•ÂøóÁõ∏ÂÖ≥ÈÖçÁΩÆLinuxÂ∏∏Áî®ÂëΩ‰ª§ÂõûÈ°æLinuxÂ∏∏Áî®ÊúçÂä°ÁöÑÂÆâË£ÖÂíåÈÖçÁΩÆuWSGI/GunicornÂíåNginxÁöÑ‰ΩøÁî®GunicornÂíåuWSGIÁöÑÊØîËæÉÂØπ‰∫é‰∏çÈúÄË¶ÅÂ§ßÈáèÂÆöÂà∂ÂåñÁöÑÁÆÄÂçïÂ∫îÁî®Á®ãÂ∫èÔºåGunicornÊòØ‰∏Ä‰∏™‰∏çÈîôÁöÑÈÄâÊã©ÔºåuWSGIÁöÑÂ≠¶‰π†Êõ≤Á∫øÊØîGunicornË¶ÅÈô°Â≥≠ÂæóÂ§öÔºåGunicornÁöÑÈªòËÆ§ÂèÇÊï∞Â∞±Â∑≤ÁªèËÉΩÂ§üÈÄÇÂ∫îÂ§ßÂ§öÊï∞Â∫îÁî®Á®ãÂ∫è„ÄÇuWSGIÊîØÊåÅÂºÇÊûÑÈÉ®ÁΩ≤„ÄÇÁî±‰∫éNginxÊú¨Ë∫´ÊîØÊåÅuWSGIÔºåÂú®Á∫ø‰∏ä‰∏ÄËà¨ÈÉΩÂ∞ÜNginxÂíåuWSGIÊçÜÁªëÂú®‰∏ÄËµ∑ÈÉ®ÁΩ≤ÔºåËÄå‰∏îuWSGIÂ±û‰∫éÂäüËÉΩÈΩêÂÖ®‰∏îÈ´òÂ∫¶ÂÆöÂà∂ÁöÑWSGI‰∏≠Èó¥‰ª∂„ÄÇÂú®ÊÄßËÉΩ‰∏äÔºåGunicornÂíåuWSGIÂÖ∂ÂÆûË°®Áé∞Áõ∏ÂΩì„ÄÇ‰ΩøÁî®ËôöÊãüÂåñÊäÄÊúØÔºàDockerÔºâÈÉ®ÁΩ≤ÊµãËØïÁéØÂ¢ÉÂíåÁîü‰∫ßÁéØÂ¢ÉÊÄßËÉΩÊµãËØïABÁöÑ‰ΩøÁî®SQLslapÁöÑ‰ΩøÁî®sysbenchÁöÑ‰ΩøÁî®Ëá™Âä®ÂåñÊµãËØï‰ΩøÁî®ShellÂíåPythonËøõË°åËá™Âä®ÂåñÊµãËØï‰ΩøÁî®SeleniumÂÆûÁé∞Ëá™Âä®ÂåñÊµãËØïSelenium IDESelenium WebDriverSelenium Remote ControlÊµãËØïÂ∑•ÂÖ∑Robot Framework‰ªãÁªçÁ¨¨97Â§©ÔºöÁîµÂïÜÁΩëÁ´ôÊäÄÊúØË¶ÅÁÇπÂâñÊûêÁ¨¨98Â§©ÔºöÈ°πÁõÆÈÉ®ÁΩ≤‰∏äÁ∫øÂíåÊÄßËÉΩË∞É‰ºòMySQLÊï∞ÊçÆÂ∫ìË∞É‰ºòWebÊúçÂä°Âô®ÊÄßËÉΩ‰ºòÂåñNginxË¥üËΩΩÂùáË°°ÈÖçÁΩÆKeepalivedÂÆûÁé∞È´òÂèØÁî®‰ª£Á†ÅÊÄßËÉΩË∞É‰ºòÂ§öÁ∫øÁ®ãÂºÇÊ≠•ÂåñÈùôÊÄÅËµÑÊ∫êËÆøÈóÆ‰ºòÂåñ‰∫ëÂ≠òÂÇ®CDNÁ¨¨99Â§©ÔºöÈù¢ËØï‰∏≠ÁöÑÂÖ¨ÂÖ±ÈóÆÈ¢òÁ¨¨100Â§©ÔºöPythonÈù¢ËØïÈ¢òÂÆûÂΩï"
41,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
42,Significant-Gravitas/Auto-GPT,https://github.com/Significant-Gravitas/Auto-GPT/blob/master/README.md,Python,"Auto-GPT: An Autonomous GPT-4 Experimentüí° Get help - Q&A or Discord üí¨üî¥ USE stable not master üî¥Download the latest stable release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.The master branch is under heavy development and may often be in a broken state.Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \""thoughts\"", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI. Demo April 16th 2023               AutoGPTDemo_Subs_WithoutFinalScreen.mp4          Demo made by Blake WerlingerüöÄ Featuresüåê Internet access for searches and information gatheringüíæ Long-term and short-term memory managementüß† GPT-4 instances for text generationüîó Access to popular websites and platformsüóÉÔ∏è File storage and summarization with GPT-3.5üîå Extensibility with PluginsQuickstartCheck out the wikiGet an OpenAI API KeyDownload the latest releaseFollow the installation instructionsConfigure any additional features you want, or install some pluginsRun the appPlease see the documentation for full setup instructions and configuration options.üìñ Documentation‚öôÔ∏è Setupüíª Usageüîå PluginsConfigurationüîç Web Searchüß† Memoryüó£Ô∏è Voice (TTS)üñºÔ∏è Image Generation üíñ Help Fund Auto-GPT's Development üíñIf you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help to push the boundaries of fully autonomous AI!Your support is greatly appreciated. Development of this free, open-source project is made possible by all the contributors and sponsors. If you'd like to sponsor this project and have your avatar or company logo appear below click here.                ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ö†Ô∏è LimitationsThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:Not a polished application or product, just an experimentMay not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!Quite expensive to run, so set and monitor your API key limits with OpenAI!üõ° DisclaimerThis project, Auto-GPT, is an experimental application and is provided \""as-is\"" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.The developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.Please note that the use of the GPT-4 language model can be expensive due to its token usage. By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.As an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.By using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.üê¶ Connect with Us on TwitterStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.Developer: Follow @siggravitas for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!        "
43,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        ÁÆÄ‰Ωì‰∏≠Êñá |        ÁπÅÈ´î‰∏≠Êñá |        ÌïúÍµ≠Ïñ¥ |        Espa√±ol |        Êó•Êú¨Ë™û |        ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    ü§ó Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.üó£Ô∏è Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.ü§ó Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.ü§ó Transformers is backed by the three most popular deep learning libraries ‚Äî Jax, PyTorch and TensorFlow ‚Äî with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install ü§ó Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, ü§ó Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.ü§ó Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by ü§ó Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: ü§ó Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from √âcole polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Su√°rez*, Yoann Dupont, Laurent Romary, √âric Villemonte de la Clergerie, Djam√© Seddah and Beno√Æt Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of G√∂ttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo L√ºddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Herv√© J√©gou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp Kr√§henb√ºhl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, Timoth√©e Darcet, Th√©o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Herv√© Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas Oƒüuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by Ren√© Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre D√©fossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, Lo√Øc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno√Æt Crabb√©, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey √ñhman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo Garc√≠a del R√≠o, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Herv√© J√©gou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by J√∂rg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre D√©fossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noah‚Äôs Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.Nystr√∂mformer (from the University of Wisconsin - Madison) released with the paper Nystr√∂mformer: A Nystr√∂m-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier H√©naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, Jo√£o Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, ≈Åukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Doll√°r.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault F√©vry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of W√ºrzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, Pawe≈Ç Krzysztof Nowak, Thomas M√ºller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll√°r, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Luƒçiƒá, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm√°n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper ‚ÄãXLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the ü§ó Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by ü§ó TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by ü§ó Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the ü§ó Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R√©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
44,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
45,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.‚ö†Ô∏è IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!‚ö†Ô∏è IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means you‚Äôve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the project‚Äôs direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a project‚Äôs website for a ‚Äúteam‚Äù page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participants‚Äô behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, ‚ÄúHow do I‚Ä¶‚Äú or ‚ÄúWhat do you think about‚Ä¶‚Äú instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
46,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answers‚ö†Ô∏è DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]üôè PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!üéâ AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.‚ùì Need help?Open new issueüî• Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accounting‚ùóneeds updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustrator‚ùóneeds updating  7674Adobe-InDesign‚ùóneeds updating  4240Adobe-Lightroom‚ùóneeds updating  2020Adobe-Photoshop‚ùóneeds updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effects‚ùóneeds updating  2413Agile Methodologies‚ùóneeds updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCAD‚ùóneeds updating  7775@djayorAutodesk Fusion 360‚ùóneeds updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambda‚ùóneeds updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++‚ùóneeds updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurity‚ùóneeds updating10196Django7171@PROCW.NET Framework6359@declarckEclipse‚ùóneeds updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSON‚ùóneeds updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excel‚ùóneeds updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Project‚ùóneeds updating4443Microsoft Word‚ùóneeds updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooks‚ùóneeds updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revit‚ùóneeds updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePoint‚ùóneeds updating5338Sketchup22SOLIDWORKS‚ùóneeds updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnity‚ùóneeds updating4746@uno-sebastianVisual Basic for Applications (VBA)‚ùóneeds updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors ‚ú®Thanks goes to these wonderful people (emoji key):            Evgeniiüíª üñã      Sergei Stadniküíª üîç ü§î üìñ      Santhoshüíª      Jacob Dsaüíª üñã      Aaron Meeseüíª üñã      arqarqüíª üñã      Amit Yadavüíª üñã              Javokhir Nazarovüíª üñã      saurav kumarüñã      Chetanüñã      Amir Hossein Shekariüé® üñã üíª      SergDautüé®      Nilotpal Pramaniküé® üíª üñã üíº üìñ üî£ üí°      Abhishek Kumarüé®              Monu Guptaüé®      KARTIKEYA GUPTAüíª üñã      kenkyushaüíª üñã      juandavidtowersüíª üñã      cyber-neticsüíª üñã      jtriswüíª üñã      Renato Regaladoüíª üñã              Matthewüíª üñã      Jan S.üíª üñã      Manoliüíª üñã      Faraz tanveerüíª üñã      mohnishkarriüíª üñã üé®      andyzhuüíª üñã      Vishal Kushwahüíª üñã              Yurii Yakymenkoüíª üñã      Swetabh Sumanüíª üñã      AJAY DANDGEüíª üñã      Mehmet Yesinüé®      Lok Chun Waiüé®      Adria de Juanüé®      GL-Manüé®              Jheel Patelüé®      Sameer Waskarüé®      Alexander Andrewsüé®      Alexander Maxwellüé®      Slavaüé®      Mayur Khatriüé®      Mascantoshüíª üñã üì¢ ü§î              Kivanc Enesüé®      Ritika Dasüé®      Zer07793üé®      Andrew Cheungüé®      Sadhaüé®      tainenkoüé® üíª      github-star-coderüé®              Danilo Oliveiraüé®      lordekoüé®      Shubham Kumarüé® üíª      testtreeüé®      Cheryl Murphyüé® üíª      Bipin Thomasüé®      Abdulrahman Hishamüé®              Dakshitha Dissanayakaüé®      BADR KACIMIüé®      Alex Wangüé®      Maximüé®      GordonGrantüé® üíª      Ephrem Demelashüé®      JonOrcuttüé®              topdev10üé®      cookwellwebsiteüé®      xren935üé®      Nemo Frenkelüé®      MD SAIF ALAMüé®      Boris L√≥pez Arayaüé®      Larry Chiemüé®              Muhammad Bilal Ilyasüé®      AliMilaniüé® üíª      Suraj Sahaniüé®      FlyingSquirrelüé®      Erick Tijeroüé®      Jaskaran Kukrejaüé®      MichaelLüé®              MagicLegendüé®      Dereck Bearsongüé®      Pappu Kumar Pashiüé®      Venkata Kishore Tavvaüé®      Rafat Touqir Rafsunüé®      Snehesh Duttaüé®      Timo K√∂rnerüé® üíª              alexxxanüé®      GGJasonüé®      LeeAnna Ewingüé® ü§î      kamal Jyotwalüé®      Bob-Johnsüé® üíª üñã      yunussalmanlyitüé® üíª      chilcotüé® üíª              Jacky Liüíª üñã üé®      Sarthak Trivediüé®      Ayush Aggarwalüé® üíª      Nic Ballariniüé®      Luigi Zambettiüé® üíª      govindhaswinüé®      Addy Royüíª üé®              Akshat Tamrakarüé® üíª      Sai Bhargava Ramuüé®      Gurkanüíª      Spencer Hayes-Laverdiereüíª      Aniket Soniüíª      tanmay5792üíª      Dina Taklitüíª üé® üñã              Dushyant Singhüíª      Ravi Prakash Singhüíª      Nihal Joshiüíª      Guy Klagesüíª      Arvindüé® üíª      mujeeb91üíª      josercaüé® üíª              Prateek Agrawalüíª      Teoh Tze Chuin(„Çµ„É©)üíª üé®      Jayant Jainüíª      Ayush Sahuüíª      Hridya Krishna Rüíª üé®      Rahul Baliüíª üé®      S.ZHengüé® üíª üíº              Shriya Madanüé® üíª      mahalrupiüé®      Lucas Lermagneüé®      Jeff Deutschüé® üíª      Betoxx1üé®      Wingman4l7üé®      Martin Espericuetaüé®              Mh-Tahirüé®      Zdravko ≈†plajtüé® üíª      Ms3105üé® üíª üñã      Ambika Sidheswareüíª      mundogueroüíª      Darkus24üñã      Sou-786üñã üé®              Banurekhaüñã      ShiraStarLüé®      Ilya Komarovüé®      DemigodMsüñã üìñ      Mekha Hridyaüé® üîç      Andrey Safonovüé® üîç      Tommasoüé® üíª              Jessica Salbertüíª üé®      JAYANTH DOLAIüíª üé®      silverstroomüíª üé® üíº      Furkan Sayƒ±müíª üé®      Sukumar Chandrasekaranüé®      Yejin Parküé® üíª      Ali Nooshabadiüé® üíª              imitavorüé® üíª      Salih Kilicliüé® üíª      Marcelo Menesesüé® üíª      Anton Krekotunüé® üöß üñã üíª üìñ üíº      Arnav Sarmaüíª üí° üé®      meghatikuüíª üé®      Anshu Trivediüé®              Taylor Dorsettüíª üñã üé®      Havit Roviküíª      pushpapuneüíª üé®      Ramtin Radfarüé® ü§î üíº üíµ üíª üñã üí¨      Abdulmajeed Isaüíª üé®      vikassaxena02üé®      RobTablesüé® üíª üíº              Danielüé® üíª üíº üîç      Zahid Aliüíª üé®      Chad Chaiüíª üé®      Marco Biedermannüíª üé® üíº ü§î      Srinidhi Murthyüé®      Miao Caiüíª üé®      Dionicio Diazüé® üíª              Mir Monoarul Alamüé®      Shawn Ohnüíª üé®      Amanbolat Balabekovüé® üíª      black-mamba-codeüíª      Jian-forksüé® üíª      shivani patelüé®      Akash Chowrasiaüé®              yairg98üé®      Jay Gajjarüé®      coolerboolerüíª      Md Zinnatul Islam Morolüé®      shresthashok550üé® üìñ      Alan Pallathüìñ      Adrian Wongüíª              vsDizzyüíª üé®      Frex Cuadilleraüé® üíª      ashish570üíª üé®      ruchpeanutsüíª üé®      Artmasqueüé® üíª      Amirhossein Mojiri Foroushaniüé®      forüíª üé®              Lukeüé® üíª      Hector Espinozaüé®      Adri√°n Buenfilüé® üíª      Amit Kumarüé®      schoppfeüé® üíª      Sofiyal Cüé® üíª      spitlisküíª üé®              PRAVIN SHARMAüé®      NIDZAAA1üé® üíª      John Maiüé® üíª      kimsoyeongüé®      Dona Ghoshüíª      Ryan Hillüé® üíª      j42züé® üíª              Ashish Sangaleüé® üíª      Derek Yangüé® üíª      mohsinmsmüé® üíª      Gokulkrish2302üíª      Bhaavisheküíª üé®      Louis Liaoüé®      sengc92üé® üíª              Alex Marvinüé®      Balkrishna Bhattüé® üíª      Evaldas Lavrinoviƒçiusüé® üíª      Adam Erchegyiüé® üíª      Truman Hungüé® üíª      rzamora11üé®      gaurav0224üé®              Lee GyeongJunüé®      Mireküé® üíª      surajm245üé®      ArisLaodeüé® üíª      RaviDhoriyaüé® üíª      sarai-84üé® üíª      Vishnuüé® üíª              Muhammad Minhajüíª      Chandrika Debüé® üíª      Gitgit101-bitüíª üé®      Hedi Sellamiüíª üé®      saurabhvaish93üíª üé®      Nikola Begovicüíª üé®      Wangüíª üé®              Manuel Eusebio de Paz Carmonaüé®      Basim Al-Jawaheryüé® üíª      RAJA AHMEDüé® üíª      Abhik Lodhüíª      Md. Pial Ahamedüíª üé®      Hassan Shahzadüíª üé®      Christian Sosa Gagoüíª              Hasnain Rasheedüíª üé®      T-Radfordüíª      dahiyashishüíª üé®      RahulSharma468üíª üé®      Jumpod Plekhongthuüíª üé®      Thomas Young-Audetüíª üé®      VinayagamBabuüíª üé®              Deniz Ko√ßüíª üé®      Azhar Khanüíª üé® üñã üìñ üî£ üöß      Jacob Shortüíª üé®      Uchimura85üíª üé®      Leo Nugrahaüíª üé® üìñ      Mujtaba Mehdiüìñ üñã      Jim-dsüíª üé®              Sreehari Küíª üé®      Florian Martinezüíª üé®      Aaronüíª üé®      apoageüé®      Ignacio Guillermo Martinez üíª üé®      AirlineDogüé® üíª      Mekelüé® üíª              hmosharrofüé® üíª      Ben Emamianüíª üé®      babesharküíª üé®      Leonardo Jaquesüíª üé®      Stefanos Apkarianüíª üé®      Ayhan Albayraküíª üé®      KidusMTüíª üé®              hectormarroquin20üíª üé®      Edelweiss35üíª üé®      MihaiDüíª üé®      AnveshReddyAnnemüíª üé®      Hyunjae Parküíª üé®      Rajiv Albinoüíª üé®      Atishayüíª              Yusuf Naheemüé®      Winduüé® üíª      Superv1sorüíª üé®      Karine (:üé® üíª      Eduard Pechüé® üíª      jjeshwaniüé® üíª      Steveüé® üíª              Aleigh Ohslundüíª      Abhinav Sumanüé® üíª      Hamza Ehtesham Farooqüé® üíª      IamNotPeterPanüíª üíµ üé®      Cetgerüé®      pkonopackiüé®      Yang Yangüé® üíª              Muhammad Shoaib Sarwarüíª      Murilo Henriqueüíª üé®      emilianoalvzüé® üíª      Sumana Sahaüé® üíª      Yurii17Küé® üíª      Rupesh Bhandariüé® üíª      salmos3718üíª              John Bakerüé® üíª      SanjaySathirajuüé® üíª      Donat Kabashiüé®      Arul Prasad Jüé® üíª      Qi Chenüé® üíª      Maksym Dmyterkoüé® üíª      ilovepullrequestsüíª              Samira Malekiüé® üíª      NIKITA MAHOVIYAüíª      jesuisdev.Netüé® üíª      Ashraf Nazarüé®      Naveed Ahmadüé®      Ajmain Naqibüé® üíª      Avinash Tingreüíª üé®              nicktidsüé®      Keith Dinhüíª üé®      Andr√© Ferreiraüíª üé®      eliottkespiüíª üé®      praveenpnoüíª üé®      vitowidigdoüíª üé®      Devesh Pratap Singhüíª üé®              Dario Rodriguezüíª üé®      charmander_didiüíª üé®      PHBasinüíª üé®      Ritvik Singh Chauhanüíª üé®      Riya P Mathewüíª üé®      Stephanie Cherubinüíª üé®      BenitesGuiüíª üé®              FarikBearüíª üé®      Dmytro Havrilovüíª üé®      Parvesh Monuüíª üé®      Dipen Panchasaraüíª üé®      gudataüé® üíª      gawadeditorüíª üé®      Kirill Taletskiüé® üíª              Saajanüé® üíª      Kushagra Süé® üíª      Oanh Leüé® üíª      Frane Medvidoviƒáüé® üíª      Yormanüé® üíª      Bill Chanüé® üíª      Pratik Lomteüé® üíª              LOC LAMüé® üíª      TUSAR RANJAN MAHAPATRAüíª      BhargavKanjarlaüíª      Karel De Smetüíª üé®      sidisanüé®      ygnzayarphyoüé® üíª      svansteelandtüíª              Kebechetüé®      Daniel Selvan Düé® üíª      Mahdi Razaviüé® üíª      Niklas Tiedeüíª üé®      narutubaderddinüíª üé®      dylandhoodüíª      Dheeraj Guptaüíª              Pieter Claerhoutüíª üé®      Shivam Agnihotriüíª      RanjithReddy-Narraüíª      Nikita Wadhwaniüé® üíª      rsholokhüíª üé®      Ayaan Hossainüíª üé®      Rajesh Swarnaüíª              Deniz Etkarüé® üíª      pro335üíª üé®      Jakub Radziküíª üé®      Hamza Khanzadaüíª      ARNONüé®      Vikram Singhüíª      Shoxruxbeküíª üé®              Amit Khatriüíª üé®      Wali Ullahüé® üíª      Amit11794üíª üé®      metis-macys-66898üíª üé®      Faisal Maqboolüé® üíª      Kumar Neerajüíª üé®      Maurizio Mariniüé® üíª              Saket Kothariüé® üíª      Szymon Zborowskiüé® üíª      iks3000üé® üíª      Ehsan Seyediüé® üíª      vanekbrüé® üíª      Princy_Müé® üíª      Shijie Zhouüé® üíª              lakshyamcs16üé® üíª      Filippo Faccoüé® üíª      mendel5üé® üíª      Patryküé® üíª      VishwaSanganiüé® üíª      Alvin Zhaoüé® üíª      Lazar Gugletaüé® üíª              vmichoüé® üíª      Sikandar Aliüé® üíª      Raja Babuüé® üíª      faizajahanzebüíª      Guil_AiTüé® üíª      Kushal Dasüé® üíª      Luis Bonillaüé® üíª              jovan1013üé® üíª      Damianüé® üíª      Yash Guptaüíª      lolcatnipüé® üíª      Ikko Ashimineüé® üíª      Farukhüé® üíª      Moksedulüíª üé®              Navneet Kumarüé® üíª      Saqib AlMaliküíª      fahimrahmanüé® üíª      vaibhav patilüé® üíª      Rahul Madanüé® üíª      kartik Kaklotarüé® üíª      ASAHI OCEANüé® üíª              Daniel Jungbluthüé® üíª      Rajdeep Singh Boranaüé® üíª      ankitha19üíª      Linh Tranüíª      islamarrüíª üé®      Mohamed Sabithüé® üíª      Miguel Angel Cruz Acostaüé® üíª              Adebayo Ilerioluwa üé®      Markusüé® üíª      dkonyayevüé® üíª      Kevin A Mathewüé® üíª      David Meloüé® üî£      DFW1Nüé® üíª      Sohaib Ayubüé® üíª              Navvyüé® üíª      bloodiator2üé® üíª      Hanjiüé® üíª      arthur74üé® üíª      Sri Subathra Devi Büé® üíª      Akif Aydogmusüé® üíª      Umer Javaidüé® üíª              Norio Umataüé® üíª      Gazi Hasan Rahmanüé® üíª      Keith Nguyenüé® üíª      Megalomaniacüé® üíª      ShankS3üé® üíª      Farhad Alishovüé® üíª      Ronak J Vanpariyaüé® üíª              azrael0learzaüé® üíª      Pavel Rahmanüé® üíª      chuabernüé® üíª      Rahul Tirkeyüé® üíª      Ruslan Besüé® üíª üí° üöß üñã üî£ üöá      Bohdanüé® üíª      Juzdzewskiüé® üíª              Grigor Minasyanüé® üíª      alvintwcüé® üíª      Anand Natarajanüé® üíª      Kashan Aliüé® üíª      Thomas Meshailüé® üíª      Son Phamüé®      Michael Frenchüí°              Yash Mishraüìñ      Miguel Rodriguezüé® üíª      Philipp Bachmannüé® üíª      sunnyüé® üíª      Siddharth Chatterjeeüé® üíª      Michael Naghavipourüé® üíª      Sahil Gargüé® üíª              MicroLionüé® üíª      wctwcüé® üíª      Rohan Sharmaüî£      AshishBodlaüé® üíª      Taras Pysarskyiüé® üíª      Luqman Bello O.üé® üíª      DyingDownüé® üíª              Diego Chapedelaineüé® üíª      Richleeüé® üíª      Asif Habibüé® üíª      Mazharul Hossainüé® üíª      toniüé® üíª      Pragyanshu Raiüé® üíª      Matthew Ellerüé® üíª              AbhiBijuüé® üíª      Roman Zhornytskiyüé® üíª      Lucas Caminoüé® üíª      Jo√£o Vitor Casarinüé® üíª      Evgeniy Shayüé® üíª      Ehsan Barkhordarüé® üíª      Gabrielüé® üíª              Shibu Mohapatraüé® üíª      Pavel Kirkovskyüé® üíª      Tahir Gulüé® üíª      imDevSalmanüé® üíª      Jordan Donaldsonüé® üíª      js-venusüé® üíª      Faisal Shaikhüé® üíª              ashishbpatilüé® üíª      Tri Leüé® üíª      tomtreffkeüé® üíª      Salah Eddine Lalamiüé® üíª      Mattias Xuüé® üíª      Manas Guptaüé® üíª      wolfsong62üé® üíª              Mehdi Mirzaeiüé® üíª      Van Ba Khanhüé® üíª      Sel Embeeüé® üíª      Suvradip Paulüé® üíª      Shariqueüé®      Seabassüé® üíª      Penny Liuüé® üíª              jatinder bholaüé® üíª      misterqbitüé® üíª      Daniel-VS9üé® üíª      Shruthiüé® üíª      beefydogüé® üíª      Suraj Kumarüé® üíª      hrishikeshpsüé® üíª              Sudarshanüé® üíª      Divyanshüíª üé®      Zyaireüé® üíª      Omar Belkadyüé® üíª      alexiismuaüé® üíª      Eduarda Alvesüé®      pycoachüé® üíª              Ruhulüé® üíª      pmoustopoulosüé® üíª      Lee Hui Tingüíª üé®      bodi1981üé® üíª      Devaraat Joshiüé® üíª      Johnnyüé® üíª      rogue-coderüé® üíª              viiktrüé®      Lalit Mohanüíª      Jo√£o Sousaüíª      Ë®ÄËëâ‰πãÈùàüíª üé®      RJLABSüíª      brittney0522üé® üíª      shamüé® üíª              Glenn Goossensüíª üé®      Cyber Hawküé® üíª üñã üíº      Ankit Yadavüé® üíª      verbalityüíª      Mohammed Siddiquiüé® üíª      AdamKaczor6250üé® üíª      Ram√≥n Martinez Nietoüé® üíª              Grzegorz Dziubaküé® üíª      Ayoub BERDEDDOUCHüé® üíª      nikola-fadvüé® üíª      Akarsh Agrawalüé® üíª      Mitra Mirshafieeüé® üíª      Parker Stephensüé® üíª      alrenee99üíª              Karthick Vankayalaüíª      Iryna üé® üíª      palanugrahüíª      Gwinbleindüé® üíª      Randy Bobandyüé® üíª      Bek Rozikoffüíª      davnguyeüé® üíª              Neel Patelüíª      ehudbeharüé® üíª      nicholas-cod3rüé® üíª      michaelfrankiüé®      Esther Whiteüé® üíª      prathmeshpbüé® üíª      Victor Linüé® üíª              Christine C. Yinüé® üíª      GitLearner-beginüé® üíª      Mesrop Andreasyanüé® üíª      Nathan Garciaüé®      commonsw04üé® üíª      Md. Rashad Tanjimüé® üíª      Ali Maleküíª              PAODLTüé® üíª      Nikhil Bobadeüé® üíª      hyuckjin21üíª      Itasha Modiüé® üíª      Nikitha Reddyüé® üíª      Mahshooq Zubairüé® üíª      Subham Dasüíª              Onkar Birajdarüé® üíª      Nick Titomichelakisüé® üíª      Christian Leo-Pernoldüé®      Matthew Marquiseüé® üíª      baronfacüé® üíª      Abhishek Tilwarüé® üíª      DavidsDvmüé® üíª              Parth Parikhüé® üíª      Hector Castroüé® üíª      Rikky Arisendiüé® üíª      Ali HamXaüé® üíª      Frank.wuüé® üíª      Jatin Kumarüé® üíª üìñ      masterHAWK99üé® üíª              Pushp Jainüé® üíª      Ashutosh Routüé® üíª      Atharva Deshpandeüé® üíª      Teodor Ciripescuüé® üíª      Anmol Bansalüé® üíª      Nikhil Kumar Macharlaüé® üíª      Dexterüé® üíª              Aaronüé® üíª      Yogita Jaswaniüé® üíª üìñ üñã      StoryDevüé® üíª      Mesut Doƒüansoyüé® üíª      Paras Dhawanüé® üíª      Emanuel Zhupaüé® üíª      Aaradhyaa717üé® üíª              jaacko-torusüé® üíª      mBlacküíª      kalrayashwinüìñ üñã üé® üíª      Seraphüíª üé®      ZhiHong Chuaüé® üíª      Amsal Khanüé® üíª üìñ üñã      Raghav Rastogiüé® üíª              Tzilaüìñ      Shahriar Nasim Nafiüìñ      AGüé® üíª      Mojtaba Kamyabiüé® üíª      Ahmad Abdulrahmanüé® üíª      Eclipseüé® üíª      Anshu Palüé® üíª              Denisüé® üíª      mehmet sayinüìñ      WebDEVüé® üíª      Sam Komesarooküé® üíª      Kiran Ghimireüé® üíª      Joshua Davisüé® üíª      Muhammad-Huzaifa-Siddiquiüíª              tobeornottobeadevüé® üíª      VAIBHAV SINGHALüé® üíª      Keiran Pillmanüé® üíª      Max Donchenkoüé® üíª      sgonsalüé® üíª      diksha137üé® üíª      Vigneshüé® üíª              Gabriel Fran√ßaüé® üíª      Josephüé® üíª      Bruno Rafaelüé® üíª      vcamarreüé® üíª      thibault kettererüé® üíª üöß      VictorGonzalezToledoüé® üíª      1911510996üé® üíª              inviduüé® üíª      Nurul Furqonüé® üíª      David Asbillüé® üíª      Niko Birbilisüé® üíª      Mugundan Kottursureshüé®      agrsachin81üé® üíª      Othmane El Alamiüé® üíª              Syed Atif Aliüé® üíª      lakhanjindamüé® üíª      youssef hamdaneüé® üíª      starfaerieüé® üíª      rodrigo0107üé® üíª      Micha≈Ç Gralaküé® üíª      Jewel Mahmudüé® üíª              cwilson830üé® üíª      buun1030üé® üíª      Reda-ELOUAHABIüé® üíª      saad-aksaüé® üíª      Emdadul Haqueüé® üíª      PROCWüé® üíª      cccppp1üé® üíª              Joanna Baileüé® üíª      Ahmed Saberüé® üíª      Masoud Keshavarzüé® üíª      mortazavianüé® üíª      Aniket Pandeyüé® üíª      Vijay Nirmalüé® üíª      Daniel Carvalloüíª              menaechmiüé® üíª      azenyxüé® üíª      Ahmet √ñzrahatüé® üíª      Abdulrahman Abouzaidüé® üíª      jmgnorbecüé® üíª      palinko91üé® üíª      Laisson R. Silveiraüé® üíª              BHARGAVPATEL1244üé® üíª      Candide Uüé® üíª      Sitansh Rajputüé® üíª      Houda Mouttalibüé® üíª      MumuTWüé® üíª      Suave Bajajüé® üíª      Mehdi Parsaeiüé® üíª              Dinko Osreckiüé® üíª      Dhia Djobbiüé® üíª      Mahmoud Galalüé® üíª      Anh Minhüé® üíª      Suvesh Küé® üíª      Petar Todorovüé® üíª      Alexander Nguyenüé® üíª              Morteza Jalalvandüé® üíª      Claudson Martinsüé® üíª      Matt Jacobsonüé® üíª      Rafael Belokurowsüé® üíª       Thomas Gamaufüé® üíª      Rishabh Mahajanüé® üíª      rakeshpdgupta23üé® üíª              Shashidharknaiküé® üíª      taleleumaüé® üíª      Florian B√ºhlerüé® üíª      Raihan Bin Wahidüé® üíª      MOHAMMED NASSERüé® üíª      federicoüé® üíª      Andre Violanteüé® üíª              tcunningham98üé® üíª      Jan Grie√üerüé® üíª      Serkan Alcüé® üíª üñã      Jez McKeanüé® üíª      meisam alifallahiüé® üíª      Mehul Thakkarüé® üíª      Saksham Soniüé® üíª              Pedro Peregrinaüé® üíª      Mintu Choudharyüé® üíª      lucianmoldovanuüé® üíª      John C. Scottüé® üíª      Mia D.üé® üíª      EwenBernardüé® üíª      M. Reza Nasirlooüé® üíª              Jay Agrawalüé® üíª      DeShayüé® üíª      Jay206-Programmerüé® üíª      Elenderüé® üíª üñã      Bobby Byrneüé® üíª      Pirciüé® üíª      Hasanuzzamanüé® üíª              Josh Kautzüé® üíª      Brofarüé® üíª      Mina Karamüé® üíª      Duncan O Nüé® üíª      Sean Tumulak-Nguyenüé® üíª      Artur Trze≈õniewskiüé® üíª      JJaammeessMüé® üíª              shubham agarwalüé® üíª      Michele Righiüé® üíª      Panagiotis Kontosüé® üíª      sumitbathlaüé® üíª      Deepak Mathurüé® üíª      Juho Nyk√§nenüé® üíª      Santiago Gonz√°lez Siordiaüé® üíª              SRIJITA MALLICKüé® üíª      Samriddhi Büé® üíª      Nitzan Papiniüé® üíª      Mario Sanzüé® üíª      Crab^4üé® üíª      Pabloüé® üíª      Gordon Pham-Nguyenüé® üíª              Kristofferüé® üíª      chrisblachüé® üíª      G√°borüé® üíª      Linaüé® üíª      Harrison Wattsüé® üíª      Mario Petriƒçkoüé® üíª      Ben8120üé® üíª              Giovannaüé® üíª      Minal Ahujaüé® üíª      mossfarmerüé® üíª      ThaC0derDreüé® üíª      itwareüé® üíª      Michael Walkerüé® üíª      Tom Jacob Chirayilüé® üíª              Sachin Kumarüé® üíª      adi-rayüé® üíª      Dr-Blank-altüé® üíª      Bogdan Cazacuüé® üíª      Gilson Urbanoüé® üíª      Ninaüé® üíª      Anthonyüé® üíª              manushimjaniüé® üíª      Michael Reyesüé® üíª      Rachel Kennellyüé® üíª      Aakash Gargüé® üíª      Daniel Livingstonüé® üíª      alexrojcoüé® üíª      Minh Nguyenüé® üíª              Mahesh Dattatraya Babarüé® üíª      Jin Zihangüé® üíª      Bikramjit Gangulyüé® üíª      QuestionableGuiseüé® üíª      liq19chüé® üíª      Bruno Rochaüé® üíª      Anand Dyavanapalliüíª üñã              crucian-afküé® üíª      0xgainzüé® üíª      weirdfshüé® üíª      Valan Baptist Mathuranayagamüé® üíª      Paul Kaeferüé® üíª      Yu-Hsiang Wangüé® üíª      Javad Adibüé® üíª              davidliu0930üé® üíª      Achilleas John Yfantisüé® üíª      Omkar Shivadekarüé® üíª üñã üêõ      ToanTranüé® üíª      Gautam Naiküé® üíª      Marcüé® üíª      twix20üé® üíª              Kristian S.üé® üíª      Aleksey Khoroshilovüé® üíª      arjunsrsrüé® üíª      Ali Haiderüé® üíª      Trisha Dringüé® üíª      Andre Marzuloüé® üíª      Krishna Modiüé® üíª              Rosemary Liüé® üíª      Alex Wellerüé® üíª      Tam Nguyenüé® üíª      aquintelaoliveiraüé® üíª      Norbert Brettüé® üíª      rocsogdüé® üíª      0nyrüé® üíª              rethkevinüé® üíª      RickHeadleüé® üíª      Leandreüé® üíª      Natnael Sisayüé® üíª      sbbuüé® üíª      waelüé® üíª      Fabricio Tramontano Piriniüé® üíª              Alexander Stoyanovüé® üíª      Dezx20üé® üíª      southparkkidsüé® üíª      bmstarüé® üíª      kiagamüé® üíª      Juan Castilloüé® üíª      FFenneüé® üíª              Jose Toledoüé® üíª      Pat McGhenüé® üíª      Eiko Wagenknechtüíª üñã üî£      Alan Chalmersüé® üíª      Jean Didierüé® üíª      Andyüé® üíª      pestadieuüé® üíª              Kanishka Chakrabortyüé® üíª      Nandhaüé® üíª      Vahid Mafiüé® üíª üî£ üñã üíº      Akshay Ashoküé® üíª      0x08üé® üíª      Sandeep Mishraüé® üíª      Evann Regnaultüé® üíª              Lenny Zeitounüé® üíª      Eden Boaronüé® üíª      TroyBTCüé® üíª      Aby Sebastianüé® üíª      Matthew Dunnüé® üíª      ckulloüé® üíª üñã üî£      Mohamed Mamdouhüé® üíª              Youssef Bazinaüé® üíª      Frederico K√ºckelhausüíª      Nushan Kodikaraüíª      Zach Cooperüíª      Royüé® üíª      Saurav Panchalüé® üíª      totallynotdavidüé® üíª              goosepirateüé® üíª üí° üíº      KAUTHüé® üíª      Hari Kiran Vusirikalaüé® üíª      Sounak Deyüé® üíª      ziaüíº üé® üíª      Reza Davariüé® üíª      AkshayAjaykumarüé® üíª              x24870üé® üíª      Ko Phoneüé® üíª      Nabstar3üé® üíª      Mateuszüé® üíª      Yunus Emre Emiküíª      Abhinav Sinhaüé® üíª      Hung Nguyenüé® üíª              Maselinoüíª      Shuktika Mahantyüíª      Miko≈Çaj Gawro≈Ñskiüé® üíª      Hussein Habibi Juybariüé® üíª      Sean-McArthurüé® üíª      Osman F Bayramüé® üíª      Benjamin Thomas Blodgettüé® üíª              Chuanlong-Zangüé® üíª      julianüé® üíª      franciscoüé® üíª      aalihhiader9211üé® üíª      Muhammad Zunairüé® üíª      Liyaüé® üíª      BegadTareküé® üíª              etorobotüé® üíª      Hussam Khanüé® üíª      Saikat Chakrabortyüé® üíª      Nicholas Quislerüé® üíª      Evang Poulüé® üíª      Gregg Lindüé® üíª      Deepak Kumarüé® üíª              Callum Leslieüé® üíª      Curtis Barnard Jr.üé® üíª      Deepanshukaimüé® üíª      Manthan Anküé® üíª      hossein varmazyarüé® üíª      Brayan Mu√±oz V.üé® üíª      Kamil Rasheed Siddiquiüíª üé®              mutt0-dsüé® üíª      egbertjküé® üíª      Majid Zojajiüé® üíª      Sean Chenüé® üíª      Herbert Milhommeüé® üíª      A3üé® üíª      Killianüé® üíª              Coakeowüé® üíª      ‡æÖ‡ºª «¨…Äƒß ‡ºÑ‡ºÜ‡Ωâüé® üíª      Pratik Solankiüé® üíª      Sunnyüé® üíª      ssgeüé® üíª      Bernat Frangiüé® üíª      Jeevan Rupachaüé® üíª              amirandapüé® üíª      Deepakshi Mittalüé® üíª      Abhijeet Paridaüé® üíª      Khaled Riyadüé® üíª      Pratap paruiüé® üíª      Prajit Pandayüé® üíª      PipeSierraüé® üíª              Collins Odenüé® üíª      Kshitij Dwivediüé® üíª      Bernardia Vitri Arumsariüé® üíª      √ñmer Faruk Ta≈üdemirüé® üíª      Spencer Stithüé® üíª      Porsche Rodjanasaküé® üíª      Shakeel Sharifüé® üíª              Victoria Chengüé® üíª      Denisüé® üíª      Anand Prakash Tiwariüé® üíª      danijeljw-rpcüé® üíª      Ahmed H Ebrahimüé® üíª      Virginia Gardnerüé® üíª      Jhironsel Diaz A.üé® üíª              Yunus Kidemüé® üíª      MTüé® üíª      Dinesh Zaldekarüé® üíª      adiüé® üíª      Farhan Shaikhüé® üíª      Elvis Salvatierraüé® üíª      Kaushik-Iyerüé® üíª              HocAndresüé® üíª      VictorHugoAguilarAguilarüé® üíª      Murat Can Abayüé® üíª      Chrisüé® üíª      Shivam7-1üé® üíª      Paipai13üé® üíª      Shambles-ioüé® üíª              Abhishek K Müé® üíª      Ezequiel Cuevasüé® üíª      Plamen Ivanovüé® üíª      Yujiüé® üíª      Jean-Philippe Leb≈ìufüé® üíª üî£      Naufanüé® üíª      jadnovüé® üíª              vaxtangensüé® üíª      subashkonar13üé® üíª      Rushi Javiyaüé® üíª      Mert G√ºlüé® üíª      Lilyüé® üíª      Kalinoffüé® üíª      Joel Tonyüé® üíª              Peterüé® üíª      Roozbeh Zareiüé® üíª      Shenüé® üíª      Joonsoo.LEEüé® üíª      Fede.Bregüé® üíª      Rui Costaüé® üíª      Jo√£o Gustavo Bispoüé® üíª              Sami-Iüé® üíª      Tsvetoslav Tsvetkovüé® üíª      Olabode Olaniyi Davidüé® üíª      theRuslanüé® üíª      leighbozüé® üíª      Frank Sossiüé® üíª      Tomasz Adamskiüé® üíª              Mansoor M. Sathirüé® üíª      Golamrabbi Azadüé® üíª      Nahian Ahmedüé® üíª      Rafael de Jesus Silva Monteiroüé® üíª      Odionyebuchukwu Judeüé® üíª      The Nithin Balajiüé® üíª      Knackiiüé® üíª              vittorio-giattiüé® üíª      Guilherme de Carvalho Lima Rebou√ßasüé® üíª      aaref shamiüé® üíª      Andrey Dryupinüé® üíª      Muhanned Nomanüé® üíª      Jan Silvaüé® üíª      emanuele-emüé® üíª üñã              Sanjay TMüé® üíª      Joe Markberg / code editorüé® üíª      Julien Quiaiosüé® üíª      Eric Ramirez Santisüé® üíª      Müé® üíª      Malcataüé® üíª      Athul Muralidharanüé® üíª              Dariusz Ochotaüé® üíª      CHANDAN CHOUDHURYüé® üíª      Deepüé® üíª      Ahmet ƒ∞stemihan √ñZT√úRKüé® üíª      TIMüé® üíª      jakeg814üé® üíª      Leonidosüé® üíª              Abhinandu V Nairüé® üíª      charafeddine01üé® üíª      Jasperüé® üíª      Manish Goyalüé® üíª      SATYAM_SINGHüé® üíª      Fourüé® üíª      Vaishnavi Amira Yadaüé® üíª              ShriKrushna Bhagwatüé® üíª      Rohit Nandagawaliüé® üíª      felipeüé® üíª üöß üñã ‚úÖ üßë‚Äçüè´      Saurabh Mudgalüé® üíª      szenadamüé® üíª      Shubhendra Singhüé® üíª      Yoosuf Sayyidüíª üé®              G√ºven √áetinerlerüé® üíª      Luke Jefferiesüé® üíª      Chrisüé® üíª      L√∫cio Aguiarüíª      Enuma029üíª      yktsang01üíª      maximumn3rdüé® üíª              Jon Galleteroüé® üíª      Thaddeus  Thomasüé® üíª      Aakash Kumarüíª üé®      Ali Müé® üíª      OskyEdzüé® üíª      Ravi Guptaüé® üíª      Rafa Raizerüé® üíª              Abdullah Al Muzakiüé® üíª      Rahul Faujdarüé® üíª      Abhishek Vermaüé® üíª      Ashutosh Shindeüé® üíª      Ganesh Raiüé® üíª      StefanTrpkovicüé® üíª      Erik Blancaüé® üíª              Vedant Madaneüé® üíª      Antra Tripathiüé® üíª      Ethan Knightsüé® üíª      Alexandru Boncutüé® üíª      Pablo Bandinoplaüé® üíª üöß üñã      Robz-99üé® üíª      Harpal Singhüé® üíª              paulboundy99üé® üíª      Mubashir Ahmedüé® üíª      Rohan Hariüé® üíª      Erik Henrique üé® üíª      Leandro Matheusüé® üíª      Deepaküé® üíª      AlishaSinghüé® üíª              Lynn Latt Yatiüé® üíª      San Shweüé® üíª      SKRüé® üíª      msbunnyjaguarüé® üíª      Mohamad Zabiullaüé® üíª      Hatim Zahidüé® üíª      Rauzan Sumaraüé® üíª              Hosein1358üé® üíª      Mohitüé® üíª      Aliüé® üíª      Avinash1765üé® üíª      Sai Teja Madhaüé® üíª      Monsur Ahmed Shafiqüé® üíª      xuxianjin-devüé® üíª              chetnaüé® üíª      Gul Zaibüé® üíª      Nataliaüé® üíª      Dion√≠sio Bragaüé® üíª      Pritish Rajpurohitüé® üíª      incanloveüé® üíª      Innocentüé® üíª              Devin Almonorüé® üíª      antonyveyreüé® üíª      Beltz Anhxtonüé® üíª      Mehdiüé® üíª      Muhammad Usmanüé® üíª      Patrick Dantasüé® üíª      Tak Vannaküé® üíª              Ramzi RADDAOUIüé® üíª      Konstantin-Glukhovüé® üíª      ugurobanüé® üíª      Humberto Alvesüé® üíª      JuangZendratoüé® üíª      James Oluwaleyeüé® üíª      Wasi Sadmanüé® üíª              Pavle Mijatovicüé® üíª      Luiz H. S. Bispoüé® üíª      –°—É—Ö–∞—Å –î—Ö–æ–ª–∑üé® üíª      Alvaro Trujilloüé® üíª      Everton üé® üíª      jfrozasüé® üíª      Shuaaib Badranüé® üíª              Shivam Jhaüé® üíª      Mohamed Tayehüé® üíª      Makendran Güé® üíª      mayank singh tomarüé® üíª      hossam sadanyüé® üíª      Harshbardhan Singhüíª üé®      Fawad Jawaid Maliküé® üíª              Tina Lacatisüé® üíª      TeddyCuoreDolceüé® üíª      bchooxgüé® üíª      Alisha Takkarüé® üíª      Gianluigiüé® üíª      Mehran Javaherianüé® üíª      Benjamin Ololade Adedokunüé® üíª              Md. Abdul Mutalibüé® üíª      Aadil Arsh.S.Rüé® üíª      J. Nathan Allenüé® üíª      Kieran Krugüé® üíª      Seth Addoüé® üíª      Satvik Singh Rathoreüé® üíª      dangothüé® üíª              Maximüé® üíª      Phuong-Cat Ngoüé® üíª      Frenchtoast0üé® üíª      Rakshithüé® üíª      Vaibhav Aroraüé® üíª      zghpüé® üíª      Bedovanüé® üíª              chiaramistroüé® üíª      him2016üé® üíª      HarshitSachdevaüé® üíª      Sadaf Saleemüé® üíª      Aaroh Srivastavaüé® üíª      eloygplazaüé® üíª      Gaurav Kumar Vermaüé® üíª              AndreaCUSüé® üíª      Simranüé® üíª      Prashant Bhapkarüé® üíª      mhaendlerüé® üíª      Gauri Maheshwariüé® üíª      4Lajfüé® üíª      Tanmoy Senguptaüé® üíª              Sharad Tripathiüé® üíª      Niraj Chavanüé® üíª      Luisa Gualdaüé® üíª      Monika-Sivakumar-3üé® üíª      harryfensomeüé® üíª      Shubham Choubeyüé® üíª      Ashwini Patilüé® üíª              cleversonliraüé® üíª      Nurmukhammedüé® üíª      workspace-utkarshüé® üíª      Santosh Phadtareüé® üíª      Prashant Warghudeüé® üíª      Umang Dakhüé® üíª      Shalini Chavanüé® üíª              vinit gurjarüé® üíª      Vishal Kumarüé® üíª      Wonhyeong Seoüé® üíª      Achwale Prajwal Namdevraoüé® üíª      Ankan Banerjeeüé® üíª      bhaumikankanüé® üíª      JamesMacroZhangüé® üíª              Pedro Lopesüé® üíª      diaüé® üíª      tayyabhussain2910üé® üíª      Rajdeep Shrivastava üé® üíª      Mukul Kumarüé® üíª      Mayank Nüé® üíª      jdeluccaüé® üíª              Sneha Mittalüé® üíª      Sarika Kushwahaüé® üíª      farzad-khbüé® üíª      Elijah Shackelfordüé® üíª      The-Only-Raminatorüé® üíª      Keerthana Kasthurilüé® üíª      Viachaslau Auchynnikauüé® üíª              Mohammad Osman Rasooliüé® üíª      mvedovatoüé® üíª      Sonali Rajputüé® üíª      Isha Dheküé® üíª      Ramshad Cheriyeri Peediyakkalüé® üíª      Micahüé® üíª      gauravshukla2203üé® üíª              sndmurthyüé® üíª      Shivam-Singhüé® üíª      M. Ammar Khanüé® üíª      chandolakulüé® üíª      bhatnagar221üé® üíª      Adrian Nie≈õciurüé® üíª      nezi311üé® üíª              scottajevansüé® üíª      Marcelo Antunes Soares Fantiniüé® üíª      Axel De Acetisüé® üíª      Drishti Sahüé® üíª      VipulDhillonüé® üíª      Urmi Janaüé® üíª      Ayush Mokalüé® üíª              Damola Olutokeüé® üíª      Maxüé® üíª      Lakshmi Nüé® üíª      ArtemRevaüé® üíª      Ujjwal Aggarwalüé® üíª      Moüé® üíª      Brianüé® üíª              chamleyüé® üíª      Simone Baptisteüé® üíª      Shekhar Thakurüé® üíª      Smithüé® üíª      codernoob1üé® üíª      lok84üé® üíª      Tobias Riemenschneiderüé® üíª              Tharsanan1üé® üíª      ANURAG SINGHüé® üíª      Yash Santüé® üíª      Krishiv Patelüé® üíª      GGGalaxyüé® üíª      pardeepdhillon661üé® üíª      anujd64üé® üíª              Pedro Pereiraüé® üíª      Master_Saptaküé® üíª      SURANJAN DASüé® üíª      Tripura kantüé® üíª      shabzkhanüé® üíª      Mustafa Poyaüé® üíª      Roshan Jhaüé® üíª              GuillaumeLarueüé® üíª      Tomasz Rodaküé® üíª      Junil Kimüé® üíª      Surbhi Mayanküé® üíª      Nemanja Lekicüé® üíª      HemantMalokarüé® üíª      Felipe M. L√≥pezüé® üíª              bibliofiloüé® üíª      GauthamG2üé® üíª      02_tüé® üíª      Yusuf Abdul-razaqüé® üíª      Vladimirüé® üíª      Sai Chandra Küé® üíª      Soroush Bonabüé® üíª              Giide0nüé® üíª      GGüé® üíª      D√°ger Z√∫√±igaüé® üíª      rsk2üé® üíª      Storozhev DJüé® üíª      Jeevanüé® üíª      Andy Johnsonüé® üíª              An√≠bal Pozoüé® üíª      Jovane de Castroüé® üíª      Muhammad Hamza Amirüé® üíª      tharaka-mtsüé® üíª      Ali KHYARüé® üíª      Caio Araujoüé® üíª      Oscar Dyremyhrüé® üíª              artealityüé® üíª      Daniel Drexlmaierüé® üíª      Marco Montiüé® üíª      mikeycrystalüé® üíª      Veljanovskiiüé® üíª      Ivan Gorbachevüé® üíª      Sahil Rawatüé® üíª              Hasitha Sunethüé® üíª      Yerko Vera Lezamaüé® üíª      Ivan Penchevüé® üíª      Tanver Islam Tonmoyüé® üíª      Xun Caoüé® üíª      Nayan Babariyaüé® üíª      Priyanshu Mauryaüé® üíª              Dylan Tintenfichüé® üíª      Ron Straussüé® üíª      Mohammed AlBannaüé® üíª      Mukund Müé® üíª      Franklin Ohaegbulamüé® üíª      Nisarg Shahüé® üíª      Unik Dahalüé® üíª              Readilyüé® üíª      Alexandre Poitevinüé® üíª      Scaramirüé® üíª      Pruthviüé® üíª      Kalmanqüé® üíª      Alfatah Nesabüé® üíª      arudesaiüé® üíª              Adryenneüé® üíª      El mehdi oudaoudüé® üíª      Jayant Goelüé® üíª      Tsukiüé® üíª      Peter Lemanskiüé® üíª      Annurag-byteüé® üíª      Anthony Vuüé® üíª              Vitaly Nikolaychuküé® üíª      Nathanüé® üíª      Evgenii Petukhovüé® üíª      Loris Guerraüé® üíª      fakhriaunurüé® üíª      Mehdi HYANIüé® üíª      Sarvex Jatasraüé® üíª              santimanuelrüé® üíª      Evgeniy Rezanovüé® üíª      Sonia Müé® üíª      Grzegorz Kmitaüé® üíª      Manuel Caritaüé® üíª      Felipe Cisternas Alvarezüé® üíª      Guo Ciüé® üíª              Marcos Silvaüé® üíª      KKüé® üíª      Shubhanjan Medhiüé® üíª      ArthurFerreiraRodriguesüé® üíª      PabloHermunüé® üíª      disha-baldawaüé® üíª      StaroMoonüé® üíª              Amila T Kumarasekaraüé® üíª      Amoh Princeüé® üíª      AngeloGCüé® üíª      Ebube Glory Ogbondaüé® üíª      Prahalad Belavadiüìñ      Antoni Sarnowski-Trypkaüé® üíª      Alberto Pasqualettoüé® üíª              Amir Babaeiüé® üíª      Syed Abdul Hannanüé® üíª      Srajan Raiüé® üíª      Clarence Mooreüé® üíª      Nguyen Anh Tuanüé® üíª      dar2dar2üé® üíª      Ameer Ibrahimüé® üíª              Tiago Lugattoüé® üíª      raremiroirüé® üíª      Moobieüé® üíª      AlicanDursunüé® üíª      bbalsamüé® üíª      Lubo≈° H√°jeküé® üíª      mrshahzeb7üé® üíª              Wesley Schollüé® üíª      Lawrence Turcotteüé® üíª      Michael DiPaoloüé® üíª      Smart-Codiüé® üíª      Vivek Kumarüé® üíª      Igor Moiseevüé® üíª      B√•rd Pedersenüé® üíª              HOA PHANüé® üíª      GaborModraüé® üíª      vivek-114üé® üíª      Robinüé® üíª      Alexüé® üíª      John Ehrlingerüé® üíª      Roman Zhuravlovüé® üíª              Jordan Mossüé® üíª      RaeShellyüé® üíª      gmollardüé® üíª      Md Kaif Khanüé® üíª      Pablo Romeraüé® üíª      Erik Bustosüé® üíª      trogfieldüé® üíª              simon-aichhornüé® üíª      Tufan G√úLE√áüé® üíª      Uƒüur Berkecan √únl√ºüé® üíª      Revanth Naiküé® üíª      Lia Piresüé® üíª      Igor Mestechkinüé® üíª      Anirudh Karanthüé® üíª              KBobovskiyüé® üíª      zhatiayuaüé® üíª üñã      David Cardonaüé® üíª      Paulo Castilhoüé® üíª      Sebastiano Picchiüé® üíª      pjotarüé® üíª      Rimel CHERIFüíª              Arsal uddinüñã      Dmitry Kasporskyüíª      SoftwareDev1014üé® üíª      @Robvredüé® üíª      Kasun Shanakaüíª      Ahmad M.üé® üíª      Alex Kozinüé® üíª              Mandy Meindersmaüé® üíª      LEGALISE PIRACYüé® üíª      Alex Logvinüé® üíª      Aria Dahlüé® üíª      Mustafa Arifogluüé® üíª      Yevhen Leshchenkoüé® üíª      Anubhav Adhikariüé® üíª              Noah Tatkoüé® üíª      Mohit Gadhaviüé® üíª      Pedro Bas√≠lioüé® üíª      RealSanjeevüé® üíª      Akash Hazraüé® üíª      Christoph Dahlenüé® üíª      Vincent du Plessisüé® üíª              Karen Tamrazyanüé® üíª      Mirza Younus Baigüé® üíª      Ashish Kumarüé® üíª      Unknown6334üé® üíª      flowazüé® üíª      zi-aikraüé® üíª      PAYAL PMüé® üíª              Lennart L√∂scheüé® üíª      Yummy-Yumsüé® üíª      Njuacha Hubert Mikulowskiüé® üíª      Hussein Esmailüé® üíª      Bilgehan Bezirüé® üíª      Muhammed Shittuüé® üíª      Cl√©ment FERNANDESüé® üíª              JaCKoP619üé® üíª      userutf8üé® üíª      Mohamed Ubaidüé® üíª      Justin Yatesüé® üíª      mohammad aliüé® üíª      Madhav Singhüé® üíª      RgbMouse69üé® üíª              Nicholas Leasküé® üíª      parthav0üé® üíª      Sigmaüé® üíª      Evelina Bechevaüé® üíª      Akshit Gulyanüé® üíª      Arpita Janaüé® üíª      Praveen Kumarüé® üíª              Mohammad Samiüé® üíª      eddiestefanescuüé® üíª      Ramesh Yadavüé® üíª      Sarthak Joshiüé® üíª      Nikhil12300üé® üíª      Yevgenüé® üíª      Leoüé® üíª              laurent büé® üíª      Mettchenüé® üíª      Ali Mahdaviüé® üíª      Lucas Dondoüé® üíª      Siddhesh Agarwalüé® üíª      slimerPuncherüé® üíª      saritashhüé® üíª              Iulian-Valeriu CioatƒÉüé® üíª      Szabolcs Nagyüé® üíª      Jarle Kvileüé® üíª      ÂäâËÄÄÂçá Vic Liuüé® üíª      Suryanshüé® üíª      Matthew Oosthuyseüé® üíª      Florin Zamfirüé® üíª              Meleküé® üíª      moesocioüé® üíª      Alan Jamesüé® üíª      Mai Thanh Ph∆∞∆°ngüé® üíª      Neville Dabreüé® üíª      Maksymüé® üíª      tamanna900üé® üíª              Adithya Awatiüé® üíª      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
47,ageitgey/face_recognition,https://github.com/ageitgey/face_recognition/blob/master/README.md,Python,"Face RecognitionYou can also read a translated version of this file in Chinese ÁÆÄ‰Ωì‰∏≠ÊñáÁâà or in Korean ÌïúÍµ≠Ïñ¥ or in Japanese Êó•Êú¨Ë™û.Recognize and manipulate faces from Python or from the command line withthe world's simplest face recognition library.Built using dlib's state-of-the-art face recognitionbuilt with deep learning. The model has an accuracy of 99.38% on theLabeled Faces in the Wild benchmark.This also provides a simple face_recognition command line tool that letsyou do face recognition on a folder of images from the command line!FeaturesFind faces in picturesFind all the faces that appear in a picture:import face_recognitionimage = face_recognition.load_image_file(\""your_file.jpg\"")face_locations = face_recognition.face_locations(image)Find and manipulate facial features in picturesGet the locations and outlines of each person's eyes, nose, mouth and chin.import face_recognitionimage = face_recognition.load_image_file(\""your_file.jpg\"")face_landmarks_list = face_recognition.face_landmarks(image)Finding facial features is super useful for lots of important stuff. But you can also use it for really stupid stufflike applying digital make-up (think 'Meitu'):Identify faces in picturesRecognize who appears in each photo.import face_recognitionknown_image = face_recognition.load_image_file(\""biden.jpg\"")unknown_image = face_recognition.load_image_file(\""unknown.jpg\"")biden_encoding = face_recognition.face_encodings(known_image)[0]unknown_encoding = face_recognition.face_encodings(unknown_image)[0]results = face_recognition.compare_faces([biden_encoding], unknown_encoding)You can even use this library with other Python libraries to do real-time face recognition:See this example for the code.Online DemosUser-contributed shared Jupyter notebook demo (not officially supported): InstallationRequirementsPython 3.3+ or Python 2.7macOS or Linux (Windows not officially supported, but might work)Installation Options:Installing on Mac or LinuxFirst, make sure you have dlib already installed with Python bindings:How to install dlib from source on macOS or UbuntuThen, make sure you have cmake installed:brew install cmakeFinally, install this module from pypi using pip3 (or pip2 for Python 2):pip3 install face_recognitionAlternatively, you can try this library with Docker, see this section.If you are having trouble with installation, you can also try out apre-configured VM.Installing on an Nvidia Jetson Nano boardJetson Nano installation instructionsPlease follow the instructions in the article carefully. There is current a bug in the CUDA libraries on the Jetson Nano that will cause this library to fail silently if you don't follow the instructions in the article to comment out a line in dlib and recompile it.Installing on Raspberry Pi 2+Raspberry Pi 2+ installation instructionsInstalling on FreeBSDpkg install graphics/py-face_recognitionInstalling on WindowsWhile Windows isn't officially supported, helpful users have posted instructions on how to install this library:@masoudr's Windows 10 installation guide (dlib + face_recognition)Installing a pre-configured Virtual Machine imageDownload the pre-configured VM image (for VMware Player or VirtualBox).UsageCommand-Line InterfaceWhen you install face_recognition, you get two simple command-lineprograms:face_recognition - Recognize faces in a photograph or folder full forphotographs.face_detection - Find faces in a photograph or folder full for photographs.face_recognition command line toolThe face_recognition command lets you recognize faces in a photograph orfolder full  for photographs.First, you need to provide a folder with one picture of each person youalready know. There should be one image file for each person with thefiles named according to who is in the picture:Next, you need a second folder with the files you want to identify:Then in you simply run the command face_recognition, passing inthe folder of known people and the folder (or single image) with unknownpeople and it tells you who is in each image:$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama/face_recognition_test/unknown_pictures/unknown.jpg,unknown_personThere's one line in the output for each face. The data is comma-separatedwith the filename and the name of the person found.An unknown_person is a face in the image that didn't match anyone inyour folder of known people.face_detection command line toolThe face_detection command lets you find the location (pixel coordinatates)of any faces in an image.Just run the command face_detection, passing in a folder of imagesto check (or a single image):$ face_detection  ./folder_with_pictures/examples/image1.jpg,65,215,169,112examples/image2.jpg,62,394,211,244examples/image2.jpg,95,941,244,792It prints one line for each face that was detected. The coordinatesreported are the top, right, bottom and left coordinates of the face (in pixels).Adjusting Tolerance / SensitivityIf you are getting multiple matches for the same person, it might be thatthe people in your photos look very similar and a lower tolerance valueis needed to make face comparisons more strict.You can do that with the --tolerance parameter. The default tolerancevalue is 0.6 and lower numbers make face comparisons more strict:$ face_recognition --tolerance 0.54 ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama/face_recognition_test/unknown_pictures/unknown.jpg,unknown_personIf you want to see the face distance calculated for each match in orderto adjust the tolerance setting, you can use --show-distance true:$ face_recognition --show-distance true ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,NoneMore ExamplesIf you simply want to know the names of the people in each photograph but don'tcare about file names, you could do this:$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/ | cut -d ',' -f2Barack Obamaunknown_personSpeeding up Face RecognitionFace recognition can be done in parallel if you have a computer withmultiple CPU cores. For example, if your system has 4 CPU cores, you canprocess about 4 times as many images in the same amount of time by usingall your CPU cores in parallel.If you are using Python 3.4 or newer, pass in a --cpus <number_of_cpu_cores_to_use> parameter:$ face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/You can also pass in --cpus -1 to use all CPU cores in your system.Python ModuleYou can import the face_recognition module and then easily manipulatefaces with just a couple of lines of code. It's super easy!API Docs: https://face-recognition.readthedocs.io.Automatically find all the faces in an imageimport face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_locations = face_recognition.face_locations(image)# face_locations is now an array listing the co-ordinates of each face!See this exampleto try it out.You can also opt-in to a somewhat more accurate deep-learning-based face detection model.Note: GPU acceleration (via NVidia's CUDA library) is required for goodperformance with this model. You'll also want to enable CUDA supportwhen compliling dlib.import face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_locations = face_recognition.face_locations(image, model=\""cnn\"")# face_locations is now an array listing the co-ordinates of each face!See this exampleto try it out.If you have a lot of images and a GPU, you can alsofind faces in batches.Automatically locate the facial features of a person in an imageimport face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_landmarks_list = face_recognition.face_landmarks(image)# face_landmarks_list is now an array with the locations of each facial feature in each face.# face_landmarks_list[0]['left_eye'] would be the location and outline of the first person's left eye.See this exampleto try it out.Recognize faces in images and identify who they areimport face_recognitionpicture_of_me = face_recognition.load_image_file(\""me.jpg\"")my_face_encoding = face_recognition.face_encodings(picture_of_me)[0]# my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!unknown_picture = face_recognition.load_image_file(\""unknown.jpg\"")unknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]# Now we can see the two face encodings are of the same person with `compare_faces`!results = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)if results[0] == True:    print(\""It's a picture of me!\"")else:    print(\""It's not a picture of me!\"")See this exampleto try it out.Python Code ExamplesAll the examples are available here.Face DetectionFind faces in a photographFind faces in a photograph (using deep learning)Find faces in batches of images w/ GPU (using deep learning)Blur all the faces in a live video using your webcam (Requires OpenCV to be installed)Facial FeaturesIdentify specific facial features in a photographApply (horribly ugly) digital make-upFacial RecognitionFind and recognize unknown faces in a photograph based on photographs of known peopleIdentify and draw boxes around each person in a photoCompare faces by numeric face distance instead of only True/False matchesRecognize faces in live video using your webcam - Simple / Slower Version (Requires OpenCV to be installed)Recognize faces in live video using your webcam - Faster Version (Requires OpenCV to be installed)Recognize faces in a video file and write out new video file (Requires OpenCV to be installed)Recognize faces on a Raspberry Pi w/ cameraRun a web service to recognize faces via HTTP (Requires Flask to be installed)Recognize faces with a K-nearest neighbors classifierTrain multiple images per person then recognize faces using a SVMCreating a Standalone ExecutableIf you want to create a standalone executable that can run without the need to install python or face_recognition, you can use PyInstaller. However, it requires some custom configuration to work with this library. See this issue for how to do it.Articles and Guides that cover face_recognitionMy article on how Face Recognition works: Modern Face Recognition with Deep LearningCovers the algorithms and how they generally workFace recognition with OpenCV, Python, and deep learning by Adrian RosebrockCovers how to use face recognition in practiceRaspberry Pi Face Recognition by Adrian RosebrockCovers how to use this on a Raspberry PiFace clustering with Python by Adrian RosebrockCovers how to automatically cluster photos based on who appears in each photo using unsupervised learningHow Face Recognition WorksIf you want to learn how face location and recognition work instead ofdepending on a black box library, read my article.CaveatsThe face recognition model is trained on adults and does not work very well on children. It tends to mixup children quite easy using the default comparison threshold of 0.6.Accuracy may vary between ethnic groups. Please see this wiki page for more details.Deployment to Cloud Hosts (Heroku, AWS, etc)Since face_recognition depends on dlib which is written in C++, it can be tricky to deploy an appusing it to a cloud hosting provider like Heroku or AWS.To make things easier, there's an example Dockerfile in this repo that shows how to run an app built withface_recognition in a Docker container. With that, you should be able to deployto any service that supports Docker images.You can try the Docker image locally by running: docker-compose up --buildThere are also several prebuilt Docker images.Linux users with a GPU (drivers >= 384.81) and Nvidia-Docker installed can run the example on the GPU: Open the docker-compose.yml file and uncomment the dockerfile: Dockerfile.gpu and runtime: nvidia lines.Having problems?If you run into problems, please read the Common Errors section of the wiki before filing a github issue.ThanksMany, many thanks to Davis King (@nulhom)for creating dlib and for providing the trained facial feature detection and face encoding modelsused in this library. For more information on the ResNet that powers the face encodings, check outhis blog post.Thanks to everyone who works on all the awesome Python data science libraries like numpy, scipy, scikit-image,pillow, etc, etc that makes this kind of stuff so easy and fun in Python.Thanks to Cookiecutter and theaudreyr/cookiecutter-pypackage project templatefor making Python project packaging way more tolerable."
48,swisskyrepo/PayloadsAllTheThings,https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/README.md,Python,"Payloads All The ThingsA list of useful payloads and bypasses for Web Application Security.Feel free to improve with your payloads and techniques !I ‚ù§Ô∏è pull requests :)You can also contribute with a üçª IRL, or using the sponsor buttonAn alternative display version is available at PayloadsAllTheThingsWeb.  üìñ DocumentationEvery section contains the following files, you can use the _template_vuln folder to create a new chapter:README.md - vulnerability description and how to exploit it, including several payloadsIntruder - a set of files to give to Burp IntruderImages - pictures for the README.mdFiles - some files referenced in the README.mdYou might also like the Methodology and Resources folder :Methodology and ResourcesActive Directory Attack.mdCloud - AWS Pentest.mdCloud - Azure Pentest.mdCobalt Strike - Cheatsheet.mdLinux - Evasion.mdLinux - Persistence.mdLinux - Privilege Escalation.mdMetasploit - Cheatsheet.mdMethodology and enumeration.mdNetwork Pivoting Techniques.mdNetwork Discovery.mdReverse Shell Cheatsheet.mdSubdomains Enumeration.mdWindows - AMSI Bypass.mdWindows - DPAPI.mdWindows - Download and Execute.mdWindows - Mimikatz.mdWindows - Persistence.mdWindows - Privilege Escalation.mdWindows - Using credentials.mdYou want more ? Check the Books and Youtube videos selections.üë®‚Äçüíª ContributionsBe sure to read CONTRIBUTING.md  Thanks again for your contribution! ‚ù§Ô∏èüßô‚Äç‚ôÇÔ∏è SponsorsThis project is proudly sponsored by these companies."
49,xtekky/gpt4free,https://github.com/xtekky/gpt4free/blob/main/README.md,Python,"By using this repository or any code related to it, you agree to the legal notice. The author is not responsible for any copies, forks, or reuploads made by other users. This is the author's only account and repository. To prevent impersonation or irresponsible actions, you may comply with the GNU GPL license this Repository uses.This (quite censored) New Version of gpt4free, was just released, it may contain bugs, open an issue or contribute a PR when encountering one, some features were disabled.Docker is for now not available but I would be happy if someone contributes a PR. The g4f GUI will be uploaded soon enough.Newpypi package:pip install -U g4fTable of Contents:Getting StartedPrerequisitesSetting up the projectUsageThe g4f Packageinterference openai-proxy apiModelsgpt-3.5 / gpt-4Other ModelsRelated gpt4free projectsContributeChatGPT cloneCopyrightCopyright NoticeStar HistoryGetting StartedPrerequisites:Download and install Python (Version 3.x is recommended).Setting up the project:Install using pypipip install -U g4forClone the GitHub repository:git clone https://github.com/xtekky/gpt4free.gitNavigate to the project directory:cd gpt4free(Recommended) Create a virtual environment to manage Python packages for your project:python3 -m venv venvActivate the virtual environment:On Windows:.\\venv\\Scripts\\activateOn macOS and Linux:source venv/bin/activateInstall the required Python packages from requirements.txt:pip install -r requirements.txtCreate a test.py file in the root folder and start using the repo, further Instructions are belowimport g4f...UsageThe g4f Packageimport g4fprint(g4f.provider.Ails.params)  # supported args# Automatic selection of provider# streamed completionresponse = g4f.ChatCompletion.create(    model=\""gpt-3.5-turbo\"",    messages=[{\""role\"": \""user\"", \""content\"": \""Hello world\""}],    stream=True,)for message in response:    print(message, flush=True, end='')# normal responseresponse = g4f.ChatCompletion.create(    model=g4f.models.gpt_4,    messages=[{\""role\"": \""user\"", \""content\"": \""hi\""}],)  # alterative model settingprint(response)# Set with providerresponse = g4f.ChatCompletion.create(    model=\""gpt-3.5-turbo\"",    provider=g4f.provider.DeepAi,    messages=[{\""role\"": \""user\"", \""content\"": \""Hello world\""}],    stream=True,)for message in response:    print(message)providers:from g4f.provider import (    Acytoo,    Aichat,    Ails,    AiService,    AItianhu,    Bard,    Bing,    ChatgptAi,    ChatgptLogin,    DeepAi,    GetGpt)# usage:response = g4f.ChatCompletion.create(..., provider=ProviderName)interference openai-proxy api (use with openai python package)get requirements:pip install -r interference/requirements.txtrun server:python3 -m interference.appimport openaiopenai.api_key = \""\""openai.api_base = \""http://localhost:1337\""def main():    chat_completion = openai.ChatCompletion.create(        model=\""gpt-3.5-turbo\"",        messages=[{\""role\"": \""user\"", \""content\"": \""write a poem about a tree\""}],        stream=True,    )    if isinstance(chat_completion, dict):        # not stream        print(chat_completion.choices[0].message.content)    else:        # stream        for token in chat_completion:            content = token[\""choices\""][0][\""delta\""].get(\""content\"")            if content != None:                print(content, end=\""\"", flush=True)if __name__ == \""__main__\"":    main()Modelsgpt-3.5 / gpt-4WebsiteProvidergpt-3.5gpt-4StreamingStatusAuthwww.aitianhu.comg4f.provider.AItianhu‚úîÔ∏è‚ùå‚ùå‚ùåchat.acytoo.comg4f.provider.Acytoo‚úîÔ∏è‚ùå‚ùå‚ùåaiservice.vercel.appg4f.provider.AiService‚úîÔ∏è‚ùå‚ùå‚ùåchat-gpt.orgg4f.provider.Aichat‚úîÔ∏è‚ùå‚ùå‚ùåai.lsg4f.provider.Ails‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåbard.google.comg4f.provider.Bard‚ùå‚ùå‚ùå‚úîÔ∏èbing.comg4f.provider.Bing‚ùå‚úîÔ∏è‚ùå‚ùåchatgpt.aig4f.provider.ChatgptAi‚ùå‚úîÔ∏è‚ùå‚ùåchatgptlogin.acg4f.provider.ChatgptLogin‚úîÔ∏è‚ùå‚ùå‚ùådeepai.orgg4f.provider.DeepAi‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåchat.dfehub.comg4f.provider.DfeHub‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåfree.easychat.workg4f.provider.EasyChat‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåforefront.comg4f.provider.Forefront‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåchat.getgpt.worldg4f.provider.GetGpt‚úîÔ∏è‚ùå‚úîÔ∏è‚ùågpt-gm.h2o.aig4f.provider.H2o‚ùå‚ùå‚úîÔ∏è‚ùåliaobots.comg4f.provider.Liaobots‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏èsupertest.lockchat.appg4f.provider.Lockchat‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚ùåopchatgpts.netg4f.provider.Opchatgpts‚úîÔ∏è‚ùå‚ùå‚ùåbackend.raycast.comg4f.provider.Raycast‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏ètheb.aig4f.provider.Theb‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåplay.vercel.aig4f.provider.Vercel‚úîÔ∏è‚ùå‚ùå‚ùåwewordle.orgg4f.provider.Wewordle‚úîÔ∏è‚ùå‚ùå‚ùåyou.comg4f.provider.You‚úîÔ∏è‚ùå‚ùå‚ùåchat9.yqcloud.topg4f.provider.Yqcloud‚úîÔ∏è‚ùå‚ùå‚ùåOther ModelsModelBase ProviderProviderWebsitepalmGoogleg4f.provider.Bardbard.google.comh2ogpt-gm-oasst1-en-2048-falcon-7b-v3Huggingfaceg4f.provider.H2owww.h2o.aih2ogpt-gm-oasst1-en-2048-falcon-40b-v1Huggingfaceg4f.provider.H2owww.h2o.aih2ogpt-gm-oasst1-en-2048-open-llama-13bHuggingfaceg4f.provider.H2owww.h2o.aiclaude-instant-v1Anthropicg4f.provider.Vercelsdk.vercel.aiclaude-v1Anthropicg4f.provider.Vercelsdk.vercel.aiclaude-v2Anthropicg4f.provider.Vercelsdk.vercel.aicommand-light-nightlyCohereg4f.provider.Vercelsdk.vercel.aicommand-nightlyCohereg4f.provider.Vercelsdk.vercel.aigpt-neox-20bHuggingfaceg4f.provider.Vercelsdk.vercel.aioasst-sft-1-pythia-12bHuggingfaceg4f.provider.Vercelsdk.vercel.aioasst-sft-4-pythia-12b-epoch-3.5Huggingfaceg4f.provider.Vercelsdk.vercel.aisantacoderHuggingfaceg4f.provider.Vercelsdk.vercel.aibloomHuggingfaceg4f.provider.Vercelsdk.vercel.aiflan-t5-xxlHuggingfaceg4f.provider.Vercelsdk.vercel.aicode-davinci-002OpenAIg4f.provider.Vercelsdk.vercel.aigpt-3.5-turbo-16kOpenAIg4f.provider.Vercelsdk.vercel.aigpt-3.5-turbo-16k-0613OpenAIg4f.provider.Vercelsdk.vercel.aigpt-4-0613OpenAIg4f.provider.Vercelsdk.vercel.aitext-ada-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-babbage-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-curie-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-davinci-002OpenAIg4f.provider.Vercelsdk.vercel.aitext-davinci-003OpenAIg4f.provider.Vercelsdk.vercel.aillama13b-v2-chatReplicateg4f.provider.Vercelsdk.vercel.aillama7b-v2-chatReplicateg4f.provider.Vercelsdk.vercel.aiRelated gpt4free projects            üéÅ Projects      ‚≠ê Stars      üìö Forks      üõé Issues      üì¨ Pull requests                  gpt4free                                      gpt4free-ts                                      ChatGPT-Clone                                      ChatGpt Discord Bot                                      LangChain gpt4free                                      ChatGpt Telegram Bot                              Contributeto add another provider, its very simple:create a new file in g4f/provider with the name of the ProviderImplement a class that extends BaseProvider.from .base_provider import BaseProviderfrom ..typing import CreateResult, Anyclass HogeService(BaseProvider):    url = \""http://hoge.com\""    working = True    supports_gpt_35_turbo = True    @staticmethod    def create_completion(        model: str,        messages: list[dict[str, str]],        stream: bool,        **kwargs: Any,    ) -> CreateResult:        passHere, you can adjust the settings, for example if the website does support streaming, set working to True...Write code to request the provider in create_completion and yield the response, even if its a one-time response, do not hesitate to look at other providers for inspirationAdd the Provider Name in g4f/provider/init.pyfrom .base_provider import BaseProviderfrom .HogeService import HogeService__all__ = [  HogeService,]You are done !, test the provider by calling it:import g4fresponse = g4f.ChatCompletion.create(model='gpt-3.5-turbo', provider=g4f.provider.PROVIDERNAME,                                    messages=[{\""role\"": \""user\"", \""content\"": \""test\""}], stream=g4f.provider.PROVIDERNAME.supports_stream)for message in response:    print(message, flush=True, end='')ChatGPT cloneCurrently implementing new features and trying to scale it, please be patient it may be unstablehttps://chat.g4f.ai/chatThis site was developed by me and includes gpt-4/3.5, internet access and gpt-jailbreak's like DANRun locally here: https://github.com/xtekky/chatgpt-cloneCopyright:This program is licensed under the GNU GPL v3Copyright Notice:xtekky/gpt4free: Copyright (C) 2023 xtekkyThis program is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program.  If not, see <https://www.gnu.org/licenses/>.Star History         "
50,jackfrued/Python-100-Days,https://github.com/jackfrued/Python-100-Days/blob/master/README.md,Python,"Python - 100Â§©‰ªéÊñ∞ÊâãÂà∞Â§ßÂ∏à‰ΩúËÄÖÔºöÈ™ÜÊòäËØ¥ÊòéÔºö‰ªéÈ°πÁõÆ‰∏äÁ∫øÂà∞Ëé∑Âæó8w+ÊòüÊ†á‰ª•Êù•Ôºå‰∏ÄÁõ¥Êî∂Âà∞ÂèçÈ¶àËØ¥Âü∫Á°ÄÈÉ®ÂàÜÔºàÂâç15Â§©ÁöÑÂÜÖÂÆπÔºâÂØπÊñ∞ÊâãÊù•ËØ¥ÊòØÊØîËæÉÂõ∞ÈöæÁöÑÔºåÂª∫ËÆÆÊúâÈÖçÂ•óËßÜÈ¢ëËøõË°åËÆ≤Ëß£„ÄÇÊúÄËøëÊääÂü∫Á°ÄÈÉ®ÂàÜÁöÑÂÜÖÂÆπÈáçÊñ∞Âà∂‰Ωú‰∫Ü‰∏Ä‰∏™Âêç‰∏∫‚ÄúPython-Core-50-Courses‚ÄùÁöÑÈ°πÁõÆÔºåÁî®Êõ¥‰∏∫ÁÆÄÂçïÈÄö‰øóÁöÑÊñπÂºèÈáçÂÜô‰∫ÜËøôÈÉ®ÂàÜÂÜÖÂÆπÂπ∂ÈôÑÂ∏¶‰∫ÜËßÜÈ¢ëËÆ≤Ëß£ÔºåÂàùÂ≠¶ËÄÖÂèØ‰ª•ÂÖ≥Ê≥®‰∏ãËøô‰∏™Êñ∞È°πÁõÆ„ÄÇÂ¶ÇÊûúÈúÄË¶ÅPythonÂü∫Á°ÄËßÜÈ¢ëÔºåÂèØ‰ª•Âú®‚ÄúBÁ´ô‚ÄùÊêúÁ¥¢„ÄäPythonÈõ∂Âü∫Á°ÄÂø´ÈÄü‰∏äÊâã„ÄãÔºåËøôÂ•óËßÜÈ¢ëÊòØÊàëËÆ≤ËØæÁöÑÊó∂ÂÄôÂΩïÂà∂ÁöÑÈöèÂ†ÇËßÜÈ¢ëÔºåÁîªË¥®Â∞öÂèØ„ÄÅÈü≥Ë¥®‰∏ÄËà¨Ôºå‰ΩÜÊòØÂØπÂàùÂ≠¶ËÄÖÂ∫îËØ•‰ºöÊúâ‰∫õÂ∏ÆÂä©ÔºåÊ¨¢ËøéÂ§ßÂÆ∂ÁïôË®Ä„ÄÅËØÑËÆ∫„ÄÅÂèëÂºπÂπï„ÄÇÂ≠¶‰π†‰πãÂêéËßâÂæóÊúâÊî∂Ëé∑ÁöÑÂ∞è‰ºô‰º¥ÂèØ‰ª•‚Äú‰∏ÄÈîÆ‰∏âËøû‚ÄùÊù•ÊîØÊåÅUP‰∏ªÔºàÂçÉÈîãPythonÔºâ„ÄÇÂõΩÂÜÖÁî®Êà∑Â¶ÇÊûúËÆøÈóÆGitHubÊØîËæÉÊÖ¢ÁöÑËØùÔºåÂèØ‰ª•ÂÖ≥Ê≥®ÊàëÁöÑÁü•‰πéÂè∑Python-JackÔºå‰∏äÈù¢ÁöÑ‚Äú‰ªéÈõ∂ÂºÄÂßãÂ≠¶Python‚Äù‰∏ìÊ†èÊØîËæÉÈÄÇÂêàÂàùÂ≠¶ËÄÖÔºåÂÖ∂‰ªñÁöÑ‰∏ìÊ†è‰πüÂú®ÊåÅÁª≠Âàõ‰ΩúÂíåÊõ¥Êñ∞‰∏≠ÔºåÊ¨¢ËøéÂ§ßÂÆ∂ÂÖ≥Ê≥®Âπ∂ÁÇπËµûËØÑËÆ∫„ÄÇÂàõ‰Ωú‰∏çÊòìÔºåÊÑüË∞¢Â§ßÂÆ∂ÁöÑÊâìËµèÊîØÊåÅÔºåËøô‰∫õÈí±‰∏ç‰ºöÁî®‰∫é‰∏™‰∫∫Ê∂àË¥πÔºà‰æãÂ¶ÇÔºöË¥≠‰π∞ÂíñÂï°ÔºâÔºåËÄåÊòØÈÄöËøáËÖæËÆØÂÖ¨Áõä„ÄÅÁæéÂõ¢ÂÖ¨Áõä„ÄÅÊ∞¥Êª¥Á≠πÁ≠âÂπ≥Âè∞ÊçêËµ†ÁªôÈúÄË¶ÅÂ∏ÆÂä©ÁöÑ‰∫∫ÔºàÁÇπÂáª‰∫ÜËß£ÊçêËµ†ÊÉÖÂÜµÔºâ„ÄÇÈúÄË¶ÅÂä†ÂÖ•QQÂ≠¶‰π†Áæ§ÁöÑÂèØ‰ª•Êâ´Êèè‰∏ãÈù¢ÁöÑ‰∫åÁª¥Á†ÅÔºå‰∏â‰∏™Áæ§Âä†‰∏Ä‰∏™Âç≥ÂèØÔºå‰∏çË¶ÅÈáçÂ§çËøõÁæ§„ÄÇÂ≠¶‰π†Áæ§‰ºö‰∏∫Â§ßÂÆ∂Êèê‰æõÂ≠¶‰π†ËµÑÊ∫êÂíåÈóÆÈ¢òËß£Á≠îÔºåÂ¶ÇÊûúÊúâPython‰ΩìÈ™åËØæÂíåË°å‰∏öÂÖ¨ÂºÄËØæ‰ºöÊèêÂâçÂú®Áæ§ÈáåÈÄöÁü•Â§ßÂÆ∂ÔºåÊ¨¢ËøéÂ§ßÂÆ∂Âä†ÂÖ•„ÄÇÈ°πÁõÆ‚ÄúDay80~90‚ÄùÈÉ®ÂàÜÁõÆÂâç‰ªçÂú®Âàõ‰Ωú‰∏≠ÔºåÂõ†‰∏∫‰ΩúËÄÖÂπ≥Êó∂‰πüÊå§‰∏çÂá∫Â§™Â§öÊó∂Èó¥Êù•ÂÜôÊñáÊ°£ÔºåÂõ†Ê≠§Êõ¥Êñ∞ÁöÑÈÄüÂ∫¶ÊØîËæÉÁºìÊÖ¢ÔºåÊÑüË∞¢Â§ßÂÆ∂ÁöÑÁêÜËß£„ÄÇPythonÂ∫îÁî®È¢ÜÂüüÂíåËÅå‰∏öÂèëÂ±ïÂàÜÊûêÁÆÄÂçïÁöÑËØ¥ÔºåPythonÊòØ‰∏Ä‰∏™‚Äú‰ºòÈõÖ‚Äù„ÄÅ‚ÄúÊòéÁ°Æ‚Äù„ÄÅ‚ÄúÁÆÄÂçï‚ÄùÁöÑÁºñÁ®ãËØ≠Ë®Ä„ÄÇÂ≠¶‰π†Êõ≤Á∫ø‰ΩéÔºåÈùû‰∏ì‰∏ö‰∫∫Â£´‰πüËÉΩ‰∏äÊâãÂºÄÊ∫êÁ≥ªÁªüÔºåÊã•ÊúâÂº∫Â§ßÁöÑÁîüÊÄÅÂúàËß£ÈáäÂûãËØ≠Ë®ÄÔºåÂÆåÁæéÁöÑÂπ≥Âè∞ÂèØÁßªÊ§çÊÄßÂä®ÊÄÅÁ±ªÂûãËØ≠Ë®ÄÔºåÊîØÊåÅÈù¢ÂêëÂØπË±°ÂíåÂáΩÊï∞ÂºèÁºñÁ®ã‰ª£Á†ÅËßÑËåÉÁ®ãÂ∫¶È´òÔºåÂèØËØªÊÄßÂº∫PythonÂú®‰ª•‰∏ãÈ¢ÜÂüüÈÉΩÊúâÁî®Ê≠¶‰πãÂú∞„ÄÇÂêéÁ´ØÂºÄÂèë - Python / Java / Go / PHPDevOps - Python / Shell / RubyÊï∞ÊçÆÈááÈõÜ - Python / C++ / JavaÈáèÂåñ‰∫§Êòì - Python / C++ / RÊï∞ÊçÆÁßëÂ≠¶ - Python / R / Julia / MatlabÊú∫Âô®Â≠¶‰π† - Python / R / C++ / JuliaËá™Âä®ÂåñÊµãËØï - Python / Shell‰Ωú‰∏∫‰∏ÄÂêçPythonÂºÄÂèëËÄÖÔºåÊ†πÊçÆ‰∏™‰∫∫ÁöÑÂñúÂ•ΩÂíåËÅå‰∏öËßÑÂàíÔºåÂèØ‰ª•ÈÄâÊã©ÁöÑÂ∞±‰∏öÈ¢ÜÂüü‰πüÈùûÂ∏∏Â§ö„ÄÇPythonÂêéÁ´ØÂºÄÂèëÂ∑•Á®ãÂ∏àÔºàÊúçÂä°Âô®„ÄÅ‰∫ëÂπ≥Âè∞„ÄÅÊï∞ÊçÆÊé•Âè£ÔºâPythonËøêÁª¥Â∑•Á®ãÂ∏àÔºàËá™Âä®ÂåñËøêÁª¥„ÄÅSRE„ÄÅDevOpsÔºâPythonÊï∞ÊçÆÂàÜÊûêÂ∏àÔºàÊï∞ÊçÆÂàÜÊûê„ÄÅÂïÜ‰∏öÊô∫ËÉΩ„ÄÅÊï∞Â≠óÂåñËøêËê•ÔºâPythonÊï∞ÊçÆÊåñÊéòÂ∑•Á®ãÂ∏àÔºàÊú∫Âô®Â≠¶‰π†„ÄÅÊ∑±Â∫¶Â≠¶‰π†„ÄÅÁÆóÊ≥ï‰∏ìÂÆ∂ÔºâPythonÁà¨Ëô´Â∑•Á®ãÂ∏àPythonÊµãËØïÂ∑•Á®ãÂ∏àÔºàËá™Âä®ÂåñÊµãËØï„ÄÅÊµãËØïÂºÄÂèëÔºâËØ¥ÊòéÔºöÁõÆÂâçÔºåÊï∞ÊçÆÂàÜÊûêÂíåÊï∞ÊçÆÊåñÊéòÊòØÈùûÂ∏∏ÁÉ≠Èó®ÁöÑÊñπÂêëÔºåÂõ†‰∏∫‰∏çÁÆ°ÊòØ‰∫íËÅîÁΩëË°å‰∏öËøòÊòØ‰º†ÁªüË°å‰∏öÈÉΩÂ∑≤ÁªèÁßØÁ¥Ø‰∫ÜÂ§ßÈáèÁöÑÊï∞ÊçÆÔºåÂêÑË°åÂêÑ‰∏öÈÉΩÈúÄË¶ÅÊï∞ÊçÆÂàÜÊûêÂ∏à‰ªéÂ∑≤ÊúâÁöÑÊï∞ÊçÆ‰∏≠ÂèëÁé∞Êõ¥Â§öÁöÑÂïÜ‰∏ö‰ª∑ÂÄºÔºå‰ªéËÄå‰∏∫‰ºÅ‰∏öÁöÑÂÜ≥Á≠ñÊèê‰æõÊï∞ÊçÆÁöÑÊîØÊíëÔºåËøôÂ∞±ÊòØÊâÄË∞ìÁöÑÊï∞ÊçÆÈ©±Âä®ÂÜ≥Á≠ñ„ÄÇÁªôÂàùÂ≠¶ËÄÖÁöÑÂá†‰∏™Âª∫ËÆÆÔºöMake English as your working language. ÔºàËÆ©Ëã±ËØ≠Êàê‰∏∫‰Ω†ÁöÑÂ∑•‰ΩúËØ≠Ë®ÄÔºâPractice makes perfect. ÔºàÁÜüËÉΩÁîüÂ∑ßÔºâAll experience comes from mistakes. ÔºàÊâÄÊúâÁöÑÁªèÈ™åÈÉΩÊ∫ê‰∫é‰Ω†ÁäØËøáÁöÑÈîôËØØÔºâDon't be one of the leeches. Ôºà‰∏çË¶ÅÂΩì‰º∏ÊâãÂÖöÔºâEither outstanding or out. ÔºàË¶Å‰πàÂá∫‰ºóÔºåË¶Å‰πàÂá∫Â±ÄÔºâDay01~15 - PythonËØ≠Ë®ÄÂü∫Á°ÄDay01 - ÂàùËØÜPythonPythonÁÆÄ‰ªã - PythonÁöÑÂéÜÂè≤ / PythonÁöÑ‰ºòÁº∫ÁÇπ / PythonÁöÑÂ∫îÁî®È¢ÜÂüüÊê≠Âª∫ÁºñÁ®ãÁéØÂ¢É - WindowsÁéØÂ¢É / LinuxÁéØÂ¢É / MacOSÁéØÂ¢É‰ªéÁªàÁ´ØËøêË°åPythonÁ®ãÂ∫è - Hello, world / printÂáΩÊï∞ / ËøêË°åÁ®ãÂ∫è‰ΩøÁî®IDLE - ‰∫§‰∫íÂºèÁéØÂ¢É(REPL) / ÁºñÂÜôÂ§öË°å‰ª£Á†Å / ËøêË°åÁ®ãÂ∫è / ÈÄÄÂá∫IDLEÊ≥®Èáä - Ê≥®ÈáäÁöÑ‰ΩúÁî® / ÂçïË°åÊ≥®Èáä / Â§öË°åÊ≥®ÈáäDay02 - ËØ≠Ë®ÄÂÖÉÁ¥†Á®ãÂ∫èÂíåËøõÂà∂ - Êåá‰ª§ÂíåÁ®ãÂ∫è / ÂÜØËØ∫‰æùÊõºÊú∫ / ‰∫åËøõÂà∂ÂíåÂçÅËøõÂà∂ / ÂÖ´ËøõÂà∂ÂíåÂçÅÂÖ≠ËøõÂà∂ÂèòÈáèÂíåÁ±ªÂûã - ÂèòÈáèÁöÑÂëΩÂêç / ÂèòÈáèÁöÑ‰ΩøÁî® / inputÂáΩÊï∞ / Ê£ÄÊü•ÂèòÈáèÁ±ªÂûã / Á±ªÂûãËΩ¨Êç¢Êï∞Â≠óÂíåÂ≠óÁ¨¶‰∏≤ - Êï¥Êï∞ / ÊµÆÁÇπÊï∞ / Â§çÊï∞ / Â≠óÁ¨¶‰∏≤ / Â≠óÁ¨¶‰∏≤Âü∫Êú¨Êìç‰Ωú / Â≠óÁ¨¶ÁºñÁ†ÅËøêÁÆóÁ¨¶ - Êï∞Â≠¶ËøêÁÆóÁ¨¶ / ËµãÂÄºËøêÁÆóÁ¨¶ / ÊØîËæÉËøêÁÆóÁ¨¶ / ÈÄªËæëËøêÁÆóÁ¨¶ / Ë∫´‰ªΩËøêÁÆóÁ¨¶ / ËøêÁÆóÁ¨¶ÁöÑ‰ºòÂÖàÁ∫ßÂ∫îÁî®Ê°à‰æã - ÂçéÊ∞èÊ∏©Â∫¶ËΩ¨Êç¢ÊàêÊëÑÊ∞èÊ∏©Â∫¶ / ËæìÂÖ•ÂúÜÁöÑÂçäÂæÑËÆ°ÁÆóÂë®ÈïøÂíåÈù¢ÁßØ / ËæìÂÖ•Âπ¥‰ªΩÂà§Êñ≠ÊòØÂê¶ÊòØÈó∞Âπ¥Day03 - ÂàÜÊîØÁªìÊûÑÂàÜÊîØÁªìÊûÑÁöÑÂ∫îÁî®Âú∫ÊôØ - Êù°‰ª∂ / Áº©Ëøõ / ‰ª£Á†ÅÂùó / ÊµÅÁ®ãÂõæifËØ≠Âè• - ÁÆÄÂçïÁöÑif / if-elseÁªìÊûÑ / if-elif-elseÁªìÊûÑ / ÂµåÂ•óÁöÑifÂ∫îÁî®Ê°à‰æã - Áî®Êà∑Ë∫´‰ªΩÈ™åËØÅ / Ëã±Âà∂Âçï‰Ωç‰∏éÂÖ¨Âà∂Âçï‰Ωç‰∫íÊç¢ / Êé∑È™∞Â≠êÂÜ≥ÂÆöÂÅö‰ªÄ‰πà / ÁôæÂàÜÂà∂ÊàêÁª©ËΩ¨Á≠âÁ∫ßÂà∂ / ÂàÜÊÆµÂáΩÊï∞Ê±ÇÂÄº / ËæìÂÖ•‰∏âÊù°ËæπÁöÑÈïøÂ∫¶Â¶ÇÊûúËÉΩÊûÑÊàê‰∏âËßíÂΩ¢Â∞±ËÆ°ÁÆóÂë®ÈïøÂíåÈù¢ÁßØDay04 - Âæ™ÁéØÁªìÊûÑÂæ™ÁéØÁªìÊûÑÁöÑÂ∫îÁî®Âú∫ÊôØ - Êù°‰ª∂ / Áº©Ëøõ / ‰ª£Á†ÅÂùó / ÊµÅÁ®ãÂõæwhileÂæ™ÁéØ - Âü∫Êú¨ÁªìÊûÑ / breakËØ≠Âè• / continueËØ≠Âè•forÂæ™ÁéØ - Âü∫Êú¨ÁªìÊûÑ / rangeÁ±ªÂûã / Âæ™ÁéØ‰∏≠ÁöÑÂàÜÊîØÁªìÊûÑ / ÂµåÂ•óÁöÑÂæ™ÁéØ / ÊèêÂâçÁªìÊùüÁ®ãÂ∫èÂ∫îÁî®Ê°à‰æã - 1~100Ê±ÇÂíå / Âà§Êñ≠Á¥†Êï∞ / ÁåúÊï∞Â≠óÊ∏∏Êàè / ÊâìÂç∞‰πù‰πùË°® / ÊâìÂç∞‰∏âËßíÂΩ¢ÂõæÊ°à / Áå¥Â≠êÂêÉÊ°É / ÁôæÈí±ÁôæÈ∏°Day05 - ÊûÑÈÄ†Á®ãÂ∫èÈÄªËæëÁªèÂÖ∏Ê°à‰æãÔºöÊ∞¥‰ªôËä±Êï∞ / ÁôæÈí±ÁôæÈ∏° / CrapsËµåÂçöÊ∏∏ÊàèÁªÉ‰π†È¢òÁõÆÔºöÊñêÊ≥¢ÈÇ£Â•ëÊï∞Âàó / ÂÆåÁæéÊï∞ / Á¥†Êï∞Day06 - ÂáΩÊï∞ÂíåÊ®°ÂùóÁöÑ‰ΩøÁî®ÂáΩÊï∞ÁöÑ‰ΩúÁî® - ‰ª£Á†ÅÁöÑÂùèÂë≥ÈÅì / Áî®ÂáΩÊï∞Â∞ÅË£ÖÂäüËÉΩÊ®°ÂùóÂÆö‰πâÂáΩÊï∞ - defÂÖ≥ÈîÆÂ≠ó / ÂáΩÊï∞Âêç / ÂèÇÊï∞ÂàóË°® / returnËØ≠Âè• / Ë∞ÉÁî®Ëá™ÂÆö‰πâÂáΩÊï∞Ë∞ÉÁî®ÂáΩÊï∞ - PythonÂÜÖÁΩÆÂáΩÊï∞ /  ÂØºÂÖ•Ê®°ÂùóÂíåÂáΩÊï∞ÂáΩÊï∞ÁöÑÂèÇÊï∞ - ÈªòËÆ§ÂèÇÊï∞ / ÂèØÂèòÂèÇÊï∞ / ÂÖ≥ÈîÆÂ≠óÂèÇÊï∞ / ÂëΩÂêçÂÖ≥ÈîÆÂ≠óÂèÇÊï∞ÂáΩÊï∞ÁöÑËøîÂõûÂÄº - Ê≤°ÊúâËøîÂõûÂÄº  / ËøîÂõûÂçï‰∏™ÂÄº / ËøîÂõûÂ§ö‰∏™ÂÄº‰ΩúÁî®ÂüüÈóÆÈ¢ò - Â±ÄÈÉ®‰ΩúÁî®Âüü / ÂµåÂ•ó‰ΩúÁî®Âüü / ÂÖ®Â±Ä‰ΩúÁî®Âüü / ÂÜÖÁΩÆ‰ΩúÁî®Âüü / Âíå‰ΩúÁî®ÂüüÁõ∏ÂÖ≥ÁöÑÂÖ≥ÈîÆÂ≠óÁî®Ê®°ÂùóÁÆ°ÁêÜÂáΩÊï∞ - Ê®°ÂùóÁöÑÊ¶ÇÂøµ / Áî®Ëá™ÂÆö‰πâÊ®°ÂùóÁÆ°ÁêÜÂáΩÊï∞ / ÂëΩÂêçÂÜ≤Á™ÅÁöÑÊó∂ÂÄô‰ºöÊÄéÊ†∑ÔºàÂêå‰∏Ä‰∏™Ê®°ÂùóÂíå‰∏çÂêåÁöÑÊ®°ÂùóÔºâDay07 - Â≠óÁ¨¶‰∏≤ÂíåÂ∏∏Áî®Êï∞ÊçÆÁªìÊûÑÂ≠óÁ¨¶‰∏≤ÁöÑ‰ΩøÁî® - ËÆ°ÁÆóÈïøÂ∫¶ / ‰∏ãÊ†áËøêÁÆó / ÂàáÁâá / Â∏∏Áî®ÊñπÊ≥ïÂàóË°®Âü∫Êú¨Áî®Ê≥ï - ÂÆö‰πâÂàóË°® / Áî®‰∏ãË°®ËÆøÈóÆÂÖÉÁ¥† / ‰∏ãÊ†áË∂äÁïå / Ê∑ªÂä†ÂÖÉÁ¥† / Âà†Èô§ÂÖÉÁ¥† / ‰øÆÊîπÂÖÉÁ¥† / ÂàáÁâá / Âæ™ÁéØÈÅçÂéÜÂàóË°®Â∏∏Áî®Êìç‰Ωú - ËøûÊé• / Â§çÂà∂(Â§çÂà∂ÂÖÉÁ¥†ÂíåÂ§çÂà∂Êï∞ÁªÑ) / ÈïøÂ∫¶ / ÊéíÂ∫è / ÂÄíËΩ¨ / Êü•ÊâæÁîüÊàêÂàóË°® - ‰ΩøÁî®rangeÂàõÂª∫Êï∞Â≠óÂàóË°® / ÁîüÊàêË°®ËææÂºè / ÁîüÊàêÂô®ÂÖÉÁªÑÁöÑ‰ΩøÁî® - ÂÆö‰πâÂÖÉÁªÑ / ‰ΩøÁî®ÂÖÉÁªÑ‰∏≠ÁöÑÂÄº / ‰øÆÊîπÂÖÉÁªÑÂèòÈáè / ÂÖÉÁªÑÂíåÂàóË°®ËΩ¨Êç¢ÈõÜÂêàÂü∫Êú¨Áî®Ê≥ï - ÈõÜÂêàÂíåÂàóË°®ÁöÑÂå∫Âà´ /  ÂàõÂª∫ÈõÜÂêà / Ê∑ªÂä†ÂÖÉÁ¥† / Âà†Èô§ÂÖÉÁ¥† /  Ê∏ÖÁ©∫ÈõÜÂêàÂ∏∏Áî®Êìç‰Ωú - ‰∫§ÈõÜ / Âπ∂ÈõÜ / Â∑ÆÈõÜ / ÂØπÁß∞Â∑Æ / Â≠êÈõÜ / Ë∂ÖÈõÜÂ≠óÂÖ∏ÁöÑÂü∫Êú¨Áî®Ê≥ï - Â≠óÂÖ∏ÁöÑÁâπÁÇπ / ÂàõÂª∫Â≠óÂÖ∏ / Ê∑ªÂä†ÂÖÉÁ¥† / Âà†Èô§ÂÖÉÁ¥† / ÂèñÂÄº / Ê∏ÖÁ©∫Â≠óÂÖ∏Â∏∏Áî®Êìç‰Ωú - keysÊñπÊ≥ï / valuesÊñπÊ≥ï / itemsÊñπÊ≥ï / setdefaultÊñπÊ≥ïÂü∫Á°ÄÁªÉ‰π† - Ë∑ëÈ©¨ÁÅØÊïàÊûú / ÂàóË°®ÊâæÊúÄÂ§ßÂÖÉÁ¥† / ÁªüËÆ°ËÄÉËØïÊàêÁª©ÁöÑÂπ≥ÂùáÂàÜ / FibonacciÊï∞Âàó / Êù®Ëæâ‰∏âËßíÁªºÂêàÊ°à‰æã - ÂèåËâ≤ÁêÉÈÄâÂè∑ / ‰∫ïÂ≠óÊ£ãDay08 - Èù¢ÂêëÂØπË±°ÁºñÁ®ãÂü∫Á°ÄÁ±ªÂíåÂØπË±° - ‰ªÄ‰πàÊòØÁ±ª / ‰ªÄ‰πàÊòØÂØπË±° / Èù¢ÂêëÂØπË±°ÂÖ∂‰ªñÁõ∏ÂÖ≥Ê¶ÇÂøµÂÆö‰πâÁ±ª - Âü∫Êú¨ÁªìÊûÑ / Â±ûÊÄßÂíåÊñπÊ≥ï / ÊûÑÈÄ†Âô® / ÊûêÊûÑÂô® / __str__ÊñπÊ≥ï‰ΩøÁî®ÂØπË±° - ÂàõÂª∫ÂØπË±° / ÁªôÂØπË±°ÂèëÊ∂àÊÅØÈù¢ÂêëÂØπË±°ÁöÑÂõõÂ§ßÊîØÊü± - ÊäΩË±° / Â∞ÅË£Ö / ÁªßÊâø / Â§öÊÄÅÂü∫Á°ÄÁªÉ‰π† - ÂÆö‰πâÂ≠¶ÁîüÁ±ª / ÂÆö‰πâÊó∂ÈíüÁ±ª / ÂÆö‰πâÂõæÂΩ¢Á±ª / ÂÆö‰πâÊ±ΩËΩ¶Á±ªDay09 - Èù¢ÂêëÂØπË±°ËøõÈò∂Â±ûÊÄß - Á±ªÂ±ûÊÄß / ÂÆû‰æãÂ±ûÊÄß / Â±ûÊÄßËÆøÈóÆÂô® / Â±ûÊÄß‰øÆÊîπÂô® / Â±ûÊÄßÂà†Èô§Âô® / ‰ΩøÁî®__slots__Á±ª‰∏≠ÁöÑÊñπÊ≥ï - ÂÆû‰æãÊñπÊ≥ï / Á±ªÊñπÊ≥ï / ÈùôÊÄÅÊñπÊ≥ïËøêÁÆóÁ¨¶ÈáçËΩΩ - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__Á±ª(ÁöÑÂØπË±°)‰πãÈó¥ÁöÑÂÖ≥Á≥ª - ÂÖ≥ËÅî / ÁªßÊâø / ‰æùËµñÁªßÊâøÂíåÂ§öÊÄÅ - ‰ªÄ‰πàÊòØÁªßÊâø / ÁªßÊâøÁöÑËØ≠Ê≥ï / Ë∞ÉÁî®Áà∂Á±ªÊñπÊ≥ï / ÊñπÊ≥ïÈáçÂÜô / Á±ªÂûãÂà§ÂÆö / Â§öÈáçÁªßÊâø / Ëè±ÂΩ¢ÁªßÊâø(ÈíªÁü≥ÁªßÊâø)ÂíåC3ÁÆóÊ≥ïÁªºÂêàÊ°à‰æã - Â∑•ËµÑÁªìÁÆóÁ≥ªÁªü / Âõæ‰π¶Ëá™Âä®ÊäòÊâ£Á≥ªÁªü / Ëá™ÂÆö‰πâÂàÜÊï∞Á±ªDay10 - ÂõæÂΩ¢Áî®Êà∑ÁïåÈù¢ÂíåÊ∏∏ÊàèÂºÄÂèë‰ΩøÁî®tkinterÂºÄÂèëGUIÁ®ãÂ∫è‰ΩøÁî®pygame‰∏âÊñπÂ∫ìÂºÄÂèëÊ∏∏ÊàèÂ∫îÁî®‚ÄúÂ§ßÁêÉÂêÉÂ∞èÁêÉ‚ÄùÊ∏∏ÊàèDay11 - Êñá‰ª∂ÂíåÂºÇÂ∏∏ËØªÊñá‰ª∂ - ËØªÂèñÊï¥‰∏™Êñá‰ª∂ / ÈÄêË°åËØªÂèñ / Êñá‰ª∂Ë∑ØÂæÑÂÜôÊñá‰ª∂ - Ë¶ÜÁõñÂÜôÂÖ• / ËøΩÂä†ÂÜôÂÖ• / ÊñáÊú¨Êñá‰ª∂ / ‰∫åËøõÂà∂Êñá‰ª∂ÂºÇÂ∏∏Â§ÑÁêÜ - ÂºÇÂ∏∏Êú∫Âà∂ÁöÑÈáçË¶ÅÊÄß / try-except‰ª£Á†ÅÂùó / else‰ª£Á†ÅÂùó / finally‰ª£Á†ÅÂùó / ÂÜÖÁΩÆÂºÇÂ∏∏Á±ªÂûã / ÂºÇÂ∏∏Ê†à / raiseËØ≠Âè•Êï∞ÊçÆÊåÅ‰πÖÂåñ - CSVÊñá‰ª∂Ê¶ÇËø∞ / csvÊ®°ÂùóÁöÑÂ∫îÁî® / JSONÊï∞ÊçÆÊ†ºÂºè / jsonÊ®°ÂùóÁöÑÂ∫îÁî®Day12 - Â≠óÁ¨¶‰∏≤ÂíåÊ≠£ÂàôË°®ËææÂºèÂ≠óÁ¨¶‰∏≤È´òÁ∫ßÊìç‰Ωú - ËΩ¨‰πâÂ≠óÁ¨¶ / ÂéüÂßãÂ≠óÁ¨¶‰∏≤ / Â§öË°åÂ≠óÁ¨¶‰∏≤ / inÂíånot inËøêÁÆóÁ¨¶ / is_xxxÊñπÊ≥ï / joinÂíåsplitÊñπÊ≥ï / stripÁõ∏ÂÖ≥ÊñπÊ≥ï / pyperclipÊ®°Âùó / ‰∏çÂèòÂ≠óÁ¨¶‰∏≤ÂíåÂèØÂèòÂ≠óÁ¨¶‰∏≤ / StringIOÁöÑ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÂÖ•Èó® - Ê≠£ÂàôË°®ËææÂºèÁöÑ‰ΩúÁî® / ÂÖÉÂ≠óÁ¨¶ / ËΩ¨‰πâ / ÈáèËØç / ÂàÜÁªÑ / Èõ∂ÂÆΩÊñ≠Ë®Ä /Ë¥™Â©™ÂåπÈÖç‰∏éÊÉ∞ÊÄßÂåπÈÖçÊáíÊÉ∞ / ‰ΩøÁî®reÊ®°ÂùóÂÆûÁé∞Ê≠£ÂàôË°®ËææÂºèÊìç‰ΩúÔºàÂåπÈÖç„ÄÅÊêúÁ¥¢„ÄÅÊõøÊç¢„ÄÅÊçïËé∑Ôºâ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºè - reÊ®°Âùó / compileÂáΩÊï∞ / groupÂíågroupsÊñπÊ≥ï / matchÊñπÊ≥ï / searchÊñπÊ≥ï / findallÂíåfinditerÊñπÊ≥ï / subÂíåsubnÊñπÊ≥ï / splitÊñπÊ≥ïÂ∫îÁî®Ê°à‰æã - ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÈ™åËØÅËæìÂÖ•ÁöÑÂ≠óÁ¨¶‰∏≤Day13 - ËøõÁ®ãÂíåÁ∫øÁ®ãËøõÁ®ãÂíåÁ∫øÁ®ãÁöÑÊ¶ÇÂøµ - ‰ªÄ‰πàÊòØËøõÁ®ã / ‰ªÄ‰πàÊòØÁ∫øÁ®ã / Â§öÁ∫øÁ®ãÁöÑÂ∫îÁî®Âú∫ÊôØ‰ΩøÁî®ËøõÁ®ã - forkÂáΩÊï∞ / multiprocessingÊ®°Âùó / ËøõÁ®ãÊ±† / ËøõÁ®ãÈó¥ÈÄö‰ø°‰ΩøÁî®Á∫øÁ®ã -  threadingÊ®°Âùó / ThreadÁ±ª / RLockÁ±ª / ConditionÁ±ª / Á∫øÁ®ãÊ±†Day14 - ÁΩëÁªúÁºñÁ®ãÂÖ•Èó®ÂíåÁΩëÁªúÂ∫îÁî®ÂºÄÂèëËÆ°ÁÆóÊú∫ÁΩëÁªúÂü∫Á°Ä - ËÆ°ÁÆóÊú∫ÁΩëÁªúÂèëÂ±ïÂè≤ / ‚ÄúTCP-IP‚ÄùÊ®°Âûã / IPÂú∞ÂùÄ / Á´ØÂè£ / ÂçèËÆÆ / ÂÖ∂‰ªñÁõ∏ÂÖ≥Ê¶ÇÂøµÁΩëÁªúÂ∫îÁî®Ê®°Âºè - ‚ÄúÂÆ¢Êà∑Á´Ø-ÊúçÂä°Âô®‚ÄùÊ®°Âºè / ‚ÄúÊµèËßàÂô®-ÊúçÂä°Âô®‚ÄùÊ®°ÂºèÂü∫‰∫éHTTPÂçèËÆÆËÆøÈóÆÁΩëÁªúËµÑÊ∫ê - ÁΩëÁªúAPIÊ¶ÇËø∞ / ËÆøÈóÆURL / requests‰∏âÊñπÂ∫ì / Ëß£ÊûêJSONÊ†ºÂºèÊï∞ÊçÆPythonÁΩëÁªúÁºñÁ®ã - Â•óÊé•Â≠óÁöÑÊ¶ÇÂøµ / socketÊ®°Âùó /  socketÂáΩÊï∞ / ÂàõÂª∫TCPÊúçÂä°Âô® / ÂàõÂª∫TCPÂÆ¢Êà∑Á´Ø / ÂàõÂª∫UDPÊúçÂä°Âô® / ÂàõÂª∫UDPÂÆ¢Êà∑Á´ØÁîµÂ≠êÈÇÆ‰ª∂ - SMTPÂçèËÆÆ / POP3ÂçèËÆÆ / IMAPÂçèËÆÆ / smtplibÊ®°Âùó / poplibÊ®°Âùó / imaplibÊ®°ÂùóÁü≠‰ø°ÊúçÂä° - Ë∞ÉÁî®Áü≠‰ø°ÊúçÂä°ÁΩëÂÖ≥Day15 - ÂõæÂÉèÂíåÊñáÊ°£Â§ÑÁêÜÁî®PillowÂ§ÑÁêÜÂõæÁâá - ÂõæÁâáËØªÂÜô / ÂõæÁâáÂêàÊàê / Âá†‰ΩïÂèòÊç¢ / Ëâ≤ÂΩ©ËΩ¨Êç¢ / Êª§ÈïúÊïàÊûúËØªÂÜôWordÊñáÊ°£ - ÊñáÊú¨ÂÜÖÂÆπÁöÑÂ§ÑÁêÜ / ÊÆµËêΩ / È°µÁúâÂíåÈ°µËÑö / Ê†∑ÂºèÁöÑÂ§ÑÁêÜËØªÂÜôExcelÊñá‰ª∂ - xlrd / xlwt / openpyxlDay16~Day20 - PythonËØ≠Ë®ÄËøõÈò∂ Â∏∏Áî®Êï∞ÊçÆÁªìÊûÑÂáΩÊï∞ÁöÑÈ´òÁ∫ßÁî®Ê≥ï - ‚Äú‰∏ÄÁ≠âÂÖ¨Ê∞ë‚Äù / È´òÈò∂ÂáΩÊï∞ / LambdaÂáΩÊï∞ / ‰ΩúÁî®ÂüüÂíåÈó≠ÂåÖ / Ë£ÖÈ•∞Âô®Èù¢ÂêëÂØπË±°È´òÁ∫ßÁü•ËØÜ - ‚Äú‰∏âÂ§ßÊîØÊü±‚Äù / Á±ª‰∏éÁ±ª‰πãÈó¥ÁöÑÂÖ≥Á≥ª / ÂûÉÂúæÂõûÊî∂ / È≠îÊúØÂ±ûÊÄßÂíåÊñπÊ≥ï / Ê∑∑ÂÖ• / ÂÖÉÁ±ª / Èù¢ÂêëÂØπË±°ËÆæËÆ°ÂéüÂàô / GoFËÆæËÆ°Ê®°ÂºèËø≠‰ª£Âô®ÂíåÁîüÊàêÂô® - Áõ∏ÂÖ≥È≠îÊúØÊñπÊ≥ï / ÂàõÂª∫ÁîüÊàêÂô®ÁöÑ‰∏§ÁßçÊñπÂºè /Âπ∂ÂèëÂíåÂºÇÊ≠•ÁºñÁ®ã - Â§öÁ∫øÁ®ã / Â§öËøõÁ®ã / ÂºÇÊ≠•IO / asyncÂíåawaitDay21~30 - WebÂâçÁ´ØÂÖ•Èó®Áî®HTMLÊ†áÁ≠æÊâøËΩΩÈ°µÈù¢ÂÜÖÂÆπÁî®CSSÊ∏≤ÊüìÈ°µÈù¢Áî®JavaScriptÂ§ÑÁêÜ‰∫§‰∫íÂºèË°å‰∏∫jQueryÂÖ•Èó®ÂíåÊèêÈ´òVue.jsÂÖ•Èó®ElementÁöÑ‰ΩøÁî®BootstrapÁöÑ‰ΩøÁî®Day31~35 - Áé©ËΩ¨LinuxÊìç‰ΩúÁ≥ªÁªüÊìç‰ΩúÁ≥ªÁªüÂèëÂ±ïÂè≤ÂíåLinuxÊ¶ÇËø∞LinuxÂü∫Á°ÄÂëΩ‰ª§Linux‰∏≠ÁöÑÂÆûÁî®Á®ãÂ∫èLinuxÁöÑÊñá‰ª∂Á≥ªÁªüVimÁºñËæëÂô®ÁöÑÂ∫îÁî®ÁéØÂ¢ÉÂèòÈáèÂíåShellÁºñÁ®ãËΩØ‰ª∂ÁöÑÂÆâË£ÖÂíåÊúçÂä°ÁöÑÈÖçÁΩÆÁΩëÁªúËÆøÈóÆÂíåÁÆ°ÁêÜÂÖ∂‰ªñÁõ∏ÂÖ≥ÂÜÖÂÆπDay36~40 - Êï∞ÊçÆÂ∫ìÂü∫Á°ÄÂíåËøõÈò∂ÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÊ¶ÇËø∞MySQLÁöÑÂÆâË£ÖÂíå‰ΩøÁî®SQLÁöÑ‰ΩøÁî®DDL - Êï∞ÊçÆÂÆö‰πâËØ≠Ë®Ä - create / drop / alterDML - Êï∞ÊçÆÊìç‰ΩúËØ≠Ë®Ä - insert / delete / updateDQL - Êï∞ÊçÆÊü•ËØ¢ËØ≠Ë®Ä - selectDCL - Êï∞ÊçÆÊéßÂà∂ËØ≠Ë®Ä - grant / revokeMySQLÊñ∞ÁâπÊÄßÁ™óÂè£ÂáΩÊï∞ÁöÑÂ∫îÁî®JSONÊï∞ÊçÆÁ±ªÂûãÁõ∏ÂÖ≥Áü•ËØÜÊï∞ÊçÆÂÆåÊï¥ÊÄßÂíå‰∏ÄËá¥ÊÄßËßÜÂõæ„ÄÅÂáΩÊï∞„ÄÅËøáÁ®ã„ÄÅËß¶ÂèëÂô®‰∫ãÂä°ÂíåÈîÅÊâßË°åËÆ°ÂàíÂíåÁ¥¢ÂºïËåÉÂºèÁêÜËÆ∫ÂíåÂèçËåÉÂºèËÆæËÆ°Âú®Python‰∏≠Êìç‰ΩúMySQLDay41~55 - ÂÆûÊàòDjangoDay41 - DjangoÂø´ÈÄü‰∏äÊâãWebÂ∫îÁî®Â∑•‰ΩúÊú∫Âà∂HTTPËØ∑Ê±ÇÂíåÂìçÂ∫îDjangoÊ°ÜÊû∂Ê¶ÇËø∞5ÂàÜÈíüÂø´ÈÄü‰∏äÊâãDay42 - Ê∑±ÂÖ•Ê®°ÂûãÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÈÖçÁΩÆ‰ΩøÁî®ORMÂÆåÊàêÂØπÊ®°ÂûãÁöÑCRUDÊìç‰ΩúÁÆ°ÁêÜÂêéÂè∞ÁöÑ‰ΩøÁî®DjangoÊ®°ÂûãÊúÄ‰Ω≥ÂÆûË∑µÊ®°ÂûãÂÆö‰πâÂèÇËÄÉDay43 - ÈùôÊÄÅËµÑÊ∫êÂíåAjaxËØ∑Ê±ÇÂä†ËΩΩÈùôÊÄÅËµÑÊ∫êAjaxÊ¶ÇËø∞Áî®AjaxÂÆûÁé∞ÊäïÁ•®ÂäüËÉΩDay44 - CookieÂíåSessionÂÆûÁé∞Áî®Êà∑Ë∑üË∏™cookieÂíåsessionÁöÑÂÖ≥Á≥ªDjangoÊ°ÜÊû∂ÂØπsessionÁöÑÊîØÊåÅËßÜÂõæÂáΩÊï∞‰∏≠ÁöÑcookieËØªÂÜôÊìç‰ΩúDay45 - Êä•Ë°®ÂíåÊó•ÂøóÈÄöËøáHttpResponse‰øÆÊîπÂìçÂ∫îÂ§¥‰ΩøÁî®StreamingHttpResponseÂ§ÑÁêÜÂ§ßÊñá‰ª∂‰ΩøÁî®xlwtÁîüÊàêExcelÊä•Ë°®‰ΩøÁî®reportlabÁîüÊàêPDFÊä•Ë°®‰ΩøÁî®EChartsÁîüÊàêÂâçÁ´ØÂõæË°®Day46 - Êó•ÂøóÂíåË∞ÉËØïÂ∑•ÂÖ∑Ê†èÈÖçÁΩÆÊó•ÂøóÈÖçÁΩÆDjango-Debug-Toolbar‰ºòÂåñORM‰ª£Á†ÅDay47 - ‰∏≠Èó¥‰ª∂ÁöÑÂ∫îÁî®‰ªÄ‰πàÊòØ‰∏≠Èó¥‰ª∂DjangoÊ°ÜÊû∂ÂÜÖÁΩÆÁöÑ‰∏≠Èó¥‰ª∂Ëá™ÂÆö‰πâ‰∏≠Èó¥‰ª∂ÂèäÂÖ∂Â∫îÁî®Âú∫ÊôØDay48 - ÂâçÂêéÁ´ØÂàÜÁ¶ªÂºÄÂèëÂÖ•Èó®ËøîÂõûJSONÊ†ºÂºèÁöÑÊï∞ÊçÆÁî®Vue.jsÊ∏≤ÊüìÈ°µÈù¢Day49 - RESTfulÊû∂ÊûÑÂíåDRFÂÖ•Èó®Day50 - RESTfulÊû∂ÊûÑÂíåDRFËøõÈò∂Day51 - ‰ΩøÁî®ÁºìÂ≠òÁΩëÁ´ô‰ºòÂåñÁ¨¨‰∏ÄÂÆöÂæãÂú®DjangoÈ°πÁõÆ‰∏≠‰ΩøÁî®RedisÊèê‰æõÁºìÂ≠òÊúçÂä°Âú®ËßÜÂõæÂáΩÊï∞‰∏≠ËØªÂÜôÁºìÂ≠ò‰ΩøÁî®Ë£ÖÈ•∞Âô®ÂÆûÁé∞È°µÈù¢ÁºìÂ≠ò‰∏∫Êï∞ÊçÆÊé•Âè£Êèê‰æõÁºìÂ≠òÊúçÂä°Day52 - Êé•ÂÖ•‰∏âÊñπÂπ≥Âè∞Êñá‰ª∂‰∏ä‰º†Ë°®ÂçïÊéß‰ª∂ÂíåÂõæÁâáÊñá‰ª∂È¢ÑËßàÊúçÂä°Âô®Á´ØÂ¶Ç‰ΩïÂ§ÑÁêÜ‰∏ä‰º†ÁöÑÊñá‰ª∂Day53 - ÂºÇÊ≠•‰ªªÂä°ÂíåÂÆöÊó∂‰ªªÂä°ÁΩëÁ´ô‰ºòÂåñÁ¨¨‰∫åÂÆöÂæãÈÖçÁΩÆÊ∂àÊÅØÈòüÂàóÊúçÂä°Âú®È°πÁõÆ‰∏≠‰ΩøÁî®CeleryÂÆûÁé∞‰ªªÂä°ÂºÇÊ≠•ÂåñÂú®È°πÁõÆ‰∏≠‰ΩøÁî®CeleryÂÆûÁé∞ÂÆöÊó∂‰ªªÂä°Day54 - ÂçïÂÖÉÊµãËØïDay55 - È°πÁõÆ‰∏äÁ∫øPython‰∏≠ÁöÑÂçïÂÖÉÊµãËØïDjangoÊ°ÜÊû∂ÂØπÂçïÂÖÉÊµãËØïÁöÑÊîØÊåÅ‰ΩøÁî®ÁâàÊú¨ÊéßÂà∂Á≥ªÁªüÈÖçÁΩÆÂíå‰ΩøÁî®uWSGIÂä®ÈùôÂàÜÁ¶ªÂíåNginxÈÖçÁΩÆÈÖçÁΩÆHTTPSÈÖçÁΩÆÂüüÂêçËß£ÊûêDay56~60 - Áî®FastAPIÂºÄÂèëÊï∞ÊçÆÊé•Âè£FastAPI‰∫îÂàÜÈíü‰∏äÊâãËØ∑Ê±ÇÂíåÂìçÂ∫îÊé•ÂÖ•ÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ì‰æùËµñÊ≥®ÂÖ•‰∏≠Èó¥‰ª∂ÂºÇÊ≠•ÂåñËôöÊãüÂåñÈÉ®ÁΩ≤ÔºàDockerÔºâÈ°πÁõÆÂÆûÊàòÔºöËΩ¶ËæÜËøùÁ´†Êü•ËØ¢È°πÁõÆDay61~65 - Áà¨Ëô´ÂºÄÂèëDay61 - ÁΩëÁªúÊï∞ÊçÆÈááÈõÜÊ¶ÇËø∞ÁΩëÁªúÁà¨Ëô´ÁöÑÊ¶ÇÂøµÂèäÂÖ∂Â∫îÁî®È¢ÜÂüüÁΩëÁªúÁà¨Ëô´ÁöÑÂêàÊ≥ïÊÄßÊé¢ËÆ®ÂºÄÂèëÁΩëÁªúÁà¨Ëô´ÁöÑÁõ∏ÂÖ≥Â∑•ÂÖ∑‰∏Ä‰∏™Áà¨Ëô´Á®ãÂ∫èÁöÑÊûÑÊàêDay62 - Êï∞ÊçÆÊäìÂèñÂíåËß£Êûê‰ΩøÁî®requests‰∏âÊñπÂ∫ìÂÆûÁé∞Êï∞ÊçÆÊäìÂèñÈ°µÈù¢Ëß£ÊûêÁöÑ‰∏âÁßçÊñπÂºèÊ≠£ÂàôË°®ËææÂºèËß£ÊûêXPathËß£ÊûêCSSÈÄâÊã©Âô®Ëß£ÊûêDay63 - Python‰∏≠ÁöÑÂπ∂ÂèëÁºñÁ®ãÂ§öÁ∫øÁ®ãÂ§öËøõÁ®ãÂºÇÊ≠•I/ODay64 - ‰ΩøÁî®SeleniumÊäìÂèñÁΩëÈ°µÂä®ÊÄÅÂÜÖÂÆπDay65 - Áà¨Ëô´Ê°ÜÊû∂ScrapyÁÆÄ‰ªãDay66~80 - Êï∞ÊçÆÂàÜÊûêDay66 - Êï∞ÊçÆÂàÜÊûêÊ¶ÇËø∞Day67 - ÁéØÂ¢ÉÂáÜÂ§áDay68 - NumPyÁöÑÂ∫îÁî®-1Day69 - NumPyÁöÑÂ∫îÁî®-2Day70 - PandasÁöÑÂ∫îÁî®-1Day71 - PandasÁöÑÂ∫îÁî®-2Day72 - PandasÁöÑÂ∫îÁî®-3Day73 - PandasÁöÑÂ∫îÁî®-4Day74 - PandasÁöÑÂ∫îÁî®-5Day75 - Êï∞ÊçÆÂèØËßÜÂåñ-1Day76 - Êï∞ÊçÆÂèØËßÜÂåñ-2Day77 - Ê¶ÇÁéáÁªüËÆ°Âü∫Á°ÄDay78 - ÊñπÂ∑ÆÂàÜÊûêÂíåÂèÇÊï∞‰º∞ËÆ°Day79 - Áõ∏ÂÖ≥ÂíåÂõûÂΩíDay80 - Êï∞ÊçÆÂàÜÊûêÊñπÊ≥ïËÆ∫Day81~90 - Êú∫Âô®Â≠¶‰π†ÂíåÊ∑±Â∫¶Â≠¶‰π†Day81 - Êú∫Âô®Â≠¶‰π†Âü∫Á°ÄDay82 - kÊúÄËøëÈÇªÂàÜÁ±ªDay83 - ÂÜ≥Á≠ñÊ†ëDay84 - Ë¥ùÂè∂ÊñØÂàÜÁ±ªDay85 - ÊîØÊåÅÂêëÈáèÊú∫Day86 - K-ÂùáÂÄºËÅöÁ±ªDay87 - ÂõûÂΩíÂàÜÊûêDay88 - Ê∑±Â∫¶Â≠¶‰π†ÂÖ•Èó®Day89 - PyTorchÊ¶ÇËø∞Day90 - PyTorchÂÆûÊàòDay91~100 - Âõ¢ÈòüÈ°πÁõÆÂºÄÂèëÁ¨¨91Â§©ÔºöÂõ¢ÈòüÈ°πÁõÆÂºÄÂèëÁöÑÈóÆÈ¢òÂíåËß£ÂÜ≥ÊñπÊ°àËΩØ‰ª∂ËøáÁ®ãÊ®°ÂûãÁªèÂÖ∏ËøáÁ®ãÊ®°ÂûãÔºàÁÄëÂ∏ÉÊ®°ÂûãÔºâÂèØË°åÊÄßÂàÜÊûêÔºàÁ†îÁ©∂ÂÅöËøòÊòØ‰∏çÂÅöÔºâÔºåËæìÂá∫„ÄäÂèØË°åÊÄßÂàÜÊûêÊä•Âëä„Äã„ÄÇÈúÄÊ±ÇÂàÜÊûêÔºàÁ†îÁ©∂ÂÅö‰ªÄ‰πàÔºâÔºåËæìÂá∫„ÄäÈúÄÊ±ÇËßÑÊ†ºËØ¥Êòé‰π¶„ÄãÂíå‰∫ßÂìÅÁïåÈù¢ÂéüÂûãÂõæ„ÄÇÊ¶ÇË¶ÅËÆæËÆ°ÂíåËØ¶ÁªÜËÆæËÆ°ÔºåËæìÂá∫Ê¶ÇÂøµÊ®°ÂûãÂõæÔºàERÂõæÔºâ„ÄÅÁâ©ÁêÜÊ®°ÂûãÂõæ„ÄÅÁ±ªÂõæ„ÄÅÊó∂Â∫èÂõæÁ≠â„ÄÇÁºñÁ†Å / ÊµãËØï„ÄÇ‰∏äÁ∫ø / Áª¥Êä§„ÄÇÁÄëÂ∏ÉÊ®°ÂûãÊúÄÂ§ßÁöÑÁº∫ÁÇπÊòØÊó†Ê≥ïÊã•Êä±ÈúÄÊ±ÇÂèòÂåñÔºåÊï¥Â•óÊµÅÁ®ãÁªìÊùüÂêéÊâçËÉΩÁúãÂà∞‰∫ßÂìÅÔºåÂõ¢ÈòüÂ£´Ê∞î‰ΩéËêΩ„ÄÇÊïèÊç∑ÂºÄÂèëÔºàScrumÔºâ- ‰∫ßÂìÅÊâÄÊúâËÄÖ„ÄÅScrum Master„ÄÅÁ†îÂèë‰∫∫Âëò - Sprint‰∫ßÂìÅÁöÑBacklogÔºàÁî®Êà∑ÊïÖ‰∫ã„ÄÅ‰∫ßÂìÅÂéüÂûãÔºâ„ÄÇËÆ°Âàí‰ºöËÆÆÔºàËØÑ‰º∞ÂíåÈ¢ÑÁÆóÔºâ„ÄÇÊó•Â∏∏ÂºÄÂèëÔºàÁ´ôÁ´ã‰ºöËÆÆ„ÄÅÁï™ËåÑÂ∑•‰ΩúÊ≥ï„ÄÅÁªìÂØπÁºñÁ®ã„ÄÅÊµãËØïÂÖàË°å„ÄÅ‰ª£Á†ÅÈáçÊûÑ‚Ä¶‚Ä¶Ôºâ„ÄÇ‰øÆÂ§çbugÔºàÈóÆÈ¢òÊèèËø∞„ÄÅÈáçÁé∞Ê≠•È™§„ÄÅÊµãËØï‰∫∫Âëò„ÄÅË¢´ÊåáÊ¥æ‰∫∫Ôºâ„ÄÇÂèëÂ∏ÉÁâàÊú¨„ÄÇËØÑÂÆ°‰ºöËÆÆÔºàShowcaseÔºåÁî®Êà∑ÈúÄË¶ÅÂèÇ‰∏éÔºâ„ÄÇÂõûÈ°æ‰ºöËÆÆÔºàÂØπÂΩìÂâçËø≠‰ª£Âë®ÊúüÂÅö‰∏Ä‰∏™ÊÄªÁªìÔºâ„ÄÇË°•ÂÖÖÔºöÊïèÊç∑ËΩØ‰ª∂ÂºÄÂèëÂÆ£Ë®Ä‰∏™‰ΩìÂíå‰∫íÂä® È´ò‰∫é ÊµÅÁ®ãÂíåÂ∑•ÂÖ∑Â∑•‰ΩúÁöÑËΩØ‰ª∂ È´ò‰∫é ËØ¶Â∞ΩÁöÑÊñáÊ°£ÂÆ¢Êà∑Âêà‰Ωú È´ò‰∫é ÂêàÂêåË∞àÂà§ÂìçÂ∫îÂèòÂåñ È´ò‰∫é ÈÅµÂæ™ËÆ°ÂàíËßíËâ≤Ôºö‰∫ßÂìÅÊâÄÊúâËÄÖÔºàÂÜ≥ÂÆöÂÅö‰ªÄ‰πàÔºåËÉΩÂØπÈúÄÊ±ÇÊãçÊùøÁöÑ‰∫∫Ôºâ„ÄÅÂõ¢ÈòüË¥üË¥£‰∫∫ÔºàËß£ÂÜ≥ÂêÑÁßçÈóÆÈ¢òÔºå‰∏ìÊ≥®Â¶Ç‰ΩïÊõ¥Â•ΩÁöÑÂ∑•‰ΩúÔºåÂ±èËîΩÂ§ñÈÉ®ÂØπÂºÄÂèëÂõ¢ÈòüÁöÑÂΩ±ÂìçÔºâ„ÄÅÂºÄÂèëÂõ¢ÈòüÔºàÈ°πÁõÆÊâßË°å‰∫∫ÂëòÔºåÂÖ∑‰ΩìÊåáÂºÄÂèë‰∫∫ÂëòÂíåÊµãËØï‰∫∫ÂëòÔºâ„ÄÇÂáÜÂ§áÂ∑•‰ΩúÔºöÂïÜ‰∏öÊ°à‰æãÂíåËµÑÈáë„ÄÅÂêàÂêå„ÄÅÊÜßÊÜ¨„ÄÅÂàùÂßã‰∫ßÂìÅÈúÄÊ±Ç„ÄÅÂàùÂßãÂèëÂ∏ÉËÆ°Âàí„ÄÅÂÖ•ËÇ°„ÄÅÁªÑÂª∫Âõ¢Èòü„ÄÇÊïèÊç∑Âõ¢ÈòüÈÄöÂ∏∏‰∫∫Êï∞‰∏∫8-10‰∫∫„ÄÇÂ∑•‰ΩúÈáè‰º∞ÁÆóÔºöÂ∞ÜÂºÄÂèë‰ªªÂä°ÈáèÂåñÔºåÂåÖÊã¨ÂéüÂûã„ÄÅLogoËÆæËÆ°„ÄÅUIËÆæËÆ°„ÄÅÂâçÁ´ØÂºÄÂèëÁ≠âÔºåÂ∞ΩÈáèÊääÊØè‰∏™Â∑•‰ΩúÂàÜËß£Âà∞ÊúÄÂ∞è‰ªªÂä°ÈáèÔºåÊúÄÂ∞è‰ªªÂä°ÈáèÊ†áÂáÜ‰∏∫Â∑•‰ΩúÊó∂Èó¥‰∏çËÉΩË∂ÖËøá‰∏§Â§©ÔºåÁÑ∂Âêé‰º∞ÁÆóÊÄª‰ΩìÈ°πÁõÆÊó∂Èó¥„ÄÇÊääÊØè‰∏™‰ªªÂä°ÈÉΩË¥¥Âú®ÁúãÊùø‰∏äÈù¢ÔºåÁúãÊùø‰∏äÂàÜ‰∏âÈÉ®ÂàÜÔºöto doÔºàÂæÖÂÆåÊàêÔºâ„ÄÅin progressÔºàËøõË°å‰∏≠ÔºâÂíådoneÔºàÂ∑≤ÂÆåÊàêÔºâ„ÄÇÈ°πÁõÆÂõ¢ÈòüÁªÑÂª∫Âõ¢ÈòüÁöÑÊûÑÊàêÂíåËßíËâ≤ËØ¥ÊòéÔºöË∞¢Ë∞¢‰ªòÁ••Ëã±Â•≥Â£´Â∏ÆÂä©ÊàëÁªòÂà∂‰∫Ü‰∏ãÈù¢ËøôÂº†Á≤æÁæéÁöÑÂÖ¨Âè∏ÁªÑÁªáÊû∂ÊûÑÂõæ„ÄÇÁºñÁ®ãËßÑËåÉÂíå‰ª£Á†ÅÂÆ°Êü•Ôºàflake8„ÄÅpylintÔºâPython‰∏≠ÁöÑ‰∏Ä‰∫õ‚ÄúÊÉØ‰æã‚ÄùÔºàËØ∑ÂèÇËÄÉ„ÄäPythonÊÉØ‰æã-Â¶Ç‰ΩïÁºñÂÜôPythonicÁöÑ‰ª£Á†Å„ÄãÔºâÂΩ±Âìç‰ª£Á†ÅÂèØËØªÊÄßÁöÑÂéüÂõ†Ôºö‰ª£Á†ÅÊ≥®ÈáäÂ§™Â∞ëÊàñËÄÖÊ≤°ÊúâÊ≥®Èáä‰ª£Á†ÅÁ†¥Âùè‰∫ÜËØ≠Ë®ÄÁöÑÊúÄ‰Ω≥ÂÆûË∑µÂèçÊ®°ÂºèÁºñÁ®ãÔºàÊÑèÂ§ßÂà©Èù¢‰ª£Á†Å„ÄÅÂ§çÂà∂-ÈªèË¥¥ÁºñÁ®ã„ÄÅËá™Ë¥üÁºñÁ®ã„ÄÅ‚Ä¶‚Ä¶ÔºâÂõ¢ÈòüÂºÄÂèëÂ∑•ÂÖ∑‰ªãÁªçÁâàÊú¨ÊéßÂà∂ÔºöGit„ÄÅMercuryÁº∫Èô∑ÁÆ°ÁêÜÔºöGitlab„ÄÅRedmineÊïèÊç∑Èó≠ÁéØÂ∑•ÂÖ∑ÔºöÁ¶ÖÈÅì„ÄÅJIRAÊåÅÁª≠ÈõÜÊàêÔºöJenkins„ÄÅTravis-CIËØ∑ÂèÇËÄÉ„ÄäÂõ¢ÈòüÈ°πÁõÆÂºÄÂèëÁöÑÈóÆÈ¢òÂíåËß£ÂÜ≥ÊñπÊ°à„Äã„ÄÇÈ°πÁõÆÈÄâÈ¢òÂíåÁêÜËß£‰∏öÂä°ÈÄâÈ¢òËåÉÂõ¥ËÆæÂÆöCMSÔºàÁî®Êà∑Á´ØÔºâÔºöÊñ∞ÈóªËÅöÂêàÁΩëÁ´ô„ÄÅÈóÆÁ≠î/ÂàÜ‰∫´Á§æÂå∫„ÄÅÂΩ±ËØÑ/‰π¶ËØÑÁΩëÁ´ôÁ≠â„ÄÇMISÔºàÁî®Êà∑Á´Ø+ÁÆ°ÁêÜÁ´ØÔºâÔºöKMS„ÄÅKPIËÄÉÊ†∏Á≥ªÁªü„ÄÅHRS„ÄÅCRMÁ≥ªÁªü„ÄÅ‰æõÂ∫îÈìæÁ≥ªÁªü„ÄÅ‰ªìÂÇ®ÁÆ°ÁêÜÁ≥ªÁªüÁ≠â„ÄÇAppÂêéÂè∞ÔºàÁÆ°ÁêÜÁ´Ø+Êï∞ÊçÆÊé•Âè£ÔºâÔºö‰∫åÊâã‰∫§ÊòìÁ±ª„ÄÅÊä•ÂàäÊùÇÂøóÁ±ª„ÄÅÂ∞è‰ºóÁîµÂïÜÁ±ª„ÄÅÊñ∞ÈóªËµÑËÆØÁ±ª„ÄÅÊóÖÊ∏∏Á±ª„ÄÅÁ§æ‰∫§Á±ª„ÄÅÈòÖËØªÁ±ªÁ≠â„ÄÇÂÖ∂‰ªñÁ±ªÂûãÔºöËá™Ë∫´Ë°å‰∏öËÉåÊôØÂíåÂ∑•‰ΩúÁªèÈ™å„ÄÅ‰∏öÂä°ÂÆπÊòìÁêÜËß£ÂíåÊääÊéß„ÄÇÈúÄÊ±ÇÁêÜËß£„ÄÅÊ®°ÂùóÂàíÂàÜÂíå‰ªªÂä°ÂàÜÈÖçÈúÄÊ±ÇÁêÜËß£ÔºöÂ§¥ËÑëÈ£éÊö¥ÂíåÁ´ûÂìÅÂàÜÊûê„ÄÇÊ®°ÂùóÂàíÂàÜÔºöÁîªÊÄùÁª¥ÂØºÂõæÔºàXMindÔºâÔºåÊØè‰∏™Ê®°ÂùóÊòØ‰∏Ä‰∏™ÊûùËäÇÁÇπÔºåÊØè‰∏™ÂÖ∑‰ΩìÁöÑÂäüËÉΩÊòØ‰∏Ä‰∏™Âè∂ËäÇÁÇπÔºàÁî®Âä®ËØçË°®Ëø∞ÔºâÔºåÈúÄË¶ÅÁ°Æ‰øùÊØè‰∏™Âè∂ËäÇÁÇπÊó†Ê≥ïÂÜçÁîüÂá∫Êñ∞ËäÇÁÇπÔºåÁ°ÆÂÆöÊØè‰∏™Âè∂Â≠êËäÇÁÇπÁöÑÈáçË¶ÅÊÄß„ÄÅ‰ºòÂÖàÁ∫ßÂíåÂ∑•‰ΩúÈáè„ÄÇ‰ªªÂä°ÂàÜÈÖçÔºöÁî±È°πÁõÆË¥üË¥£‰∫∫Ê†πÊçÆ‰∏äÈù¢ÁöÑÊåáÊ†á‰∏∫ÊØè‰∏™Âõ¢ÈòüÊàêÂëòÂàÜÈÖç‰ªªÂä°„ÄÇÂà∂ÂÆöÈ°πÁõÆËøõÂ∫¶Ë°®ÔºàÊØèÊó•Êõ¥Êñ∞ÔºâÊ®°ÂùóÂäüËÉΩ‰∫∫ÂëòÁä∂ÊÄÅÂÆåÊàêÂ∑•Êó∂ËÆ°ÂàíÂºÄÂßãÂÆûÈôÖÂºÄÂßãËÆ°ÂàíÁªìÊùüÂÆûÈôÖÁªìÊùüÂ§áÊ≥®ËØÑËÆ∫Ê∑ªÂä†ËØÑËÆ∫ÁéãÂ§ßÈî§Ê≠£Âú®ËøõË°å50%42018/8/72018/8/7Âà†Èô§ËØÑËÆ∫ÁéãÂ§ßÈî§Á≠âÂæÖ0%22018/8/72018/8/7Êü•ÁúãËØÑËÆ∫ÁôΩÂÖÉËä≥Ê≠£Âú®ËøõË°å20%42018/8/72018/8/7ÈúÄË¶ÅËøõË°å‰ª£Á†ÅÂÆ°Êü•ËØÑËÆ∫ÊäïÁ•®ÁôΩÂÖÉËä≥Á≠âÂæÖ0%42018/8/82018/8/8OOADÂíåÊï∞ÊçÆÂ∫ìËÆæËÆ°UMLÔºàÁªü‰∏ÄÂª∫Ê®°ËØ≠Ë®ÄÔºâÁöÑÁ±ªÂõæÈÄöËøáÊ®°ÂûãÂàõÂª∫Ë°®ÔºàÊ≠£ÂêëÂ∑•Á®ãÔºâÔºå‰æãÂ¶ÇÂú®DjangoÈ°πÁõÆ‰∏≠ÂèØ‰ª•ÈÄöËøá‰∏ãÈù¢ÁöÑÂëΩ‰ª§ÂàõÂª∫‰∫åÁª¥Ë°®„ÄÇpython manage.py makemigrations apppython manage.py migrate‰ΩøÁî®PowerDesignerÁªòÂà∂Áâ©ÁêÜÊ®°ÂûãÂõæ„ÄÇÈÄöËøáÊï∞ÊçÆË°®ÂàõÂª∫Ê®°ÂûãÔºàÂèçÂêëÂ∑•Á®ãÔºâÔºå‰æãÂ¶ÇÂú®DjangoÈ°πÁõÆ‰∏≠ÂèØ‰ª•ÈÄöËøá‰∏ãÈù¢ÁöÑÂëΩ‰ª§ÁîüÊàêÊ®°Âûã„ÄÇpython manage.py inspectdb > app/models.pyÁ¨¨92Â§©ÔºöDockerÂÆπÂô®ËØ¶Ëß£DockerÁÆÄ‰ªãÂÆâË£ÖDocker‰ΩøÁî®DockerÂàõÂª∫ÂÆπÂô®ÔºàNginx„ÄÅMySQL„ÄÅRedis„ÄÅGitlab„ÄÅJenkinsÔºâÊûÑÂª∫DockerÈïúÂÉèÔºàDockerfileÁöÑÁºñÂÜôÂíåÁõ∏ÂÖ≥Êåá‰ª§ÔºâÂÆπÂô®ÁºñÊéíÔºàDocker-composeÔºâÈõÜÁæ§ÁÆ°ÁêÜÔºàKubernetesÔºâÁ¨¨93Â§©ÔºöMySQLÊÄßËÉΩ‰ºòÂåñÁ¨¨94Â§©ÔºöÁΩëÁªúAPIÊé•Âè£ËÆæËÆ°Á¨¨95Â§©Ôºö[‰ΩøÁî®DjangoÂºÄÂèëÂïÜ‰∏öÈ°πÁõÆ](./Day91-100/95.‰ΩøÁî®DjangoÂºÄÂèëÂïÜ‰∏öÈ°π\tÁõÆ.md)È°πÁõÆÂºÄÂèë‰∏≠ÁöÑÂÖ¨ÂÖ±ÈóÆÈ¢òÊï∞ÊçÆÂ∫ìÁöÑÈÖçÁΩÆÔºàÂ§öÊï∞ÊçÆÂ∫ì„ÄÅ‰∏ª‰ªéÂ§çÂà∂„ÄÅÊï∞ÊçÆÂ∫ìË∑ØÁî±ÔºâÁºìÂ≠òÁöÑÈÖçÁΩÆÔºàÂàÜÂå∫ÁºìÂ≠ò„ÄÅÈîÆËÆæÁΩÆ„ÄÅË∂ÖÊó∂ËÆæÁΩÆ„ÄÅ‰∏ª‰ªéÂ§çÂà∂„ÄÅÊïÖÈöúÊÅ¢Â§çÔºàÂì®ÂÖµÔºâÔºâÊó•ÂøóÁöÑÈÖçÁΩÆÂàÜÊûêÂíåË∞ÉËØïÔºàDjango-Debug-ToolBarÔºâÂ•ΩÁî®ÁöÑPythonÊ®°ÂùóÔºàÊó•ÊúüËÆ°ÁÆó„ÄÅÂõæÂÉèÂ§ÑÁêÜ„ÄÅÊï∞ÊçÆÂä†ÂØÜ„ÄÅ‰∏âÊñπAPIÔºâREST APIËÆæËÆ°RESTfulÊû∂ÊûÑÁêÜËß£RESTfulÊû∂ÊûÑRESTful APIËÆæËÆ°ÊåáÂçóRESTful APIÊúÄ‰Ω≥ÂÆûË∑µAPIÊé•Âè£ÊñáÊ°£ÁöÑÊí∞ÂÜôRAP2YAPIdjango-REST-frameworkÁöÑÂ∫îÁî®È°πÁõÆ‰∏≠ÁöÑÈáçÁÇπÈöæÁÇπÂâñÊûê‰ΩøÁî®ÁºìÂ≠òÁºìËß£Êï∞ÊçÆÂ∫ìÂéãÂäõ - Redis‰ΩøÁî®Ê∂àÊÅØÈòüÂàóÂÅöËß£ËÄ¶ÂêàÂíåÂâäÂ≥∞ - Celery + RabbitMQÁ¨¨96Â§©ÔºöËΩØ‰ª∂ÊµãËØïÂíåËá™Âä®ÂåñÊµãËØïÂçïÂÖÉÊµãËØïÊµãËØïÁöÑÁßçÁ±ªÁºñÂÜôÂçïÂÖÉÊµãËØïÔºàunittest„ÄÅpytest„ÄÅnose2„ÄÅtox„ÄÅddt„ÄÅ‚Ä¶‚Ä¶ÔºâÊµãËØïË¶ÜÁõñÁéáÔºàcoverageÔºâDjangoÈ°πÁõÆÈÉ®ÁΩ≤ÈÉ®ÁΩ≤ÂâçÁöÑÂáÜÂ§áÂ∑•‰ΩúÂÖ≥ÈîÆËÆæÁΩÆÔºàSECRET_KEY / DEBUG / ALLOWED_HOSTS / ÁºìÂ≠ò / Êï∞ÊçÆÂ∫ìÔºâHTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECUREÊó•ÂøóÁõ∏ÂÖ≥ÈÖçÁΩÆLinuxÂ∏∏Áî®ÂëΩ‰ª§ÂõûÈ°æLinuxÂ∏∏Áî®ÊúçÂä°ÁöÑÂÆâË£ÖÂíåÈÖçÁΩÆuWSGI/GunicornÂíåNginxÁöÑ‰ΩøÁî®GunicornÂíåuWSGIÁöÑÊØîËæÉÂØπ‰∫é‰∏çÈúÄË¶ÅÂ§ßÈáèÂÆöÂà∂ÂåñÁöÑÁÆÄÂçïÂ∫îÁî®Á®ãÂ∫èÔºåGunicornÊòØ‰∏Ä‰∏™‰∏çÈîôÁöÑÈÄâÊã©ÔºåuWSGIÁöÑÂ≠¶‰π†Êõ≤Á∫øÊØîGunicornË¶ÅÈô°Â≥≠ÂæóÂ§öÔºåGunicornÁöÑÈªòËÆ§ÂèÇÊï∞Â∞±Â∑≤ÁªèËÉΩÂ§üÈÄÇÂ∫îÂ§ßÂ§öÊï∞Â∫îÁî®Á®ãÂ∫è„ÄÇuWSGIÊîØÊåÅÂºÇÊûÑÈÉ®ÁΩ≤„ÄÇÁî±‰∫éNginxÊú¨Ë∫´ÊîØÊåÅuWSGIÔºåÂú®Á∫ø‰∏ä‰∏ÄËà¨ÈÉΩÂ∞ÜNginxÂíåuWSGIÊçÜÁªëÂú®‰∏ÄËµ∑ÈÉ®ÁΩ≤ÔºåËÄå‰∏îuWSGIÂ±û‰∫éÂäüËÉΩÈΩêÂÖ®‰∏îÈ´òÂ∫¶ÂÆöÂà∂ÁöÑWSGI‰∏≠Èó¥‰ª∂„ÄÇÂú®ÊÄßËÉΩ‰∏äÔºåGunicornÂíåuWSGIÂÖ∂ÂÆûË°®Áé∞Áõ∏ÂΩì„ÄÇ‰ΩøÁî®ËôöÊãüÂåñÊäÄÊúØÔºàDockerÔºâÈÉ®ÁΩ≤ÊµãËØïÁéØÂ¢ÉÂíåÁîü‰∫ßÁéØÂ¢ÉÊÄßËÉΩÊµãËØïABÁöÑ‰ΩøÁî®SQLslapÁöÑ‰ΩøÁî®sysbenchÁöÑ‰ΩøÁî®Ëá™Âä®ÂåñÊµãËØï‰ΩøÁî®ShellÂíåPythonËøõË°åËá™Âä®ÂåñÊµãËØï‰ΩøÁî®SeleniumÂÆûÁé∞Ëá™Âä®ÂåñÊµãËØïSelenium IDESelenium WebDriverSelenium Remote ControlÊµãËØïÂ∑•ÂÖ∑Robot Framework‰ªãÁªçÁ¨¨97Â§©ÔºöÁîµÂïÜÁΩëÁ´ôÊäÄÊúØË¶ÅÁÇπÂâñÊûêÁ¨¨98Â§©ÔºöÈ°πÁõÆÈÉ®ÁΩ≤‰∏äÁ∫øÂíåÊÄßËÉΩË∞É‰ºòMySQLÊï∞ÊçÆÂ∫ìË∞É‰ºòWebÊúçÂä°Âô®ÊÄßËÉΩ‰ºòÂåñNginxË¥üËΩΩÂùáË°°ÈÖçÁΩÆKeepalivedÂÆûÁé∞È´òÂèØÁî®‰ª£Á†ÅÊÄßËÉΩË∞É‰ºòÂ§öÁ∫øÁ®ãÂºÇÊ≠•ÂåñÈùôÊÄÅËµÑÊ∫êËÆøÈóÆ‰ºòÂåñ‰∫ëÂ≠òÂÇ®CDNÁ¨¨99Â§©ÔºöÈù¢ËØï‰∏≠ÁöÑÂÖ¨ÂÖ±ÈóÆÈ¢òÁ¨¨100Â§©ÔºöPythonÈù¢ËØïÈ¢òÂÆûÂΩï"
51,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
52,Significant-Gravitas/Auto-GPT,https://github.com/Significant-Gravitas/Auto-GPT/blob/master/README.md,Python,"Auto-GPT: An Autonomous GPT-4 Experimentüí° Get help - Q&A or Discord üí¨üî¥ USE stable not master üî¥Download the latest stable release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.The master branch is under heavy development and may often be in a broken state.Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \""thoughts\"", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI. Demo April 16th 2023               AutoGPTDemo_Subs_WithoutFinalScreen.mp4          Demo made by Blake WerlingerüöÄ Featuresüåê Internet access for searches and information gatheringüíæ Long-term and short-term memory managementüß† GPT-4 instances for text generationüîó Access to popular websites and platformsüóÉÔ∏è File storage and summarization with GPT-3.5üîå Extensibility with PluginsQuickstartCheck out the wikiGet an OpenAI API KeyDownload the latest releaseFollow the installation instructionsConfigure any additional features you want, or install some pluginsRun the appPlease see the documentation for full setup instructions and configuration options.üìñ Documentation‚öôÔ∏è Setupüíª Usageüîå PluginsConfigurationüîç Web Searchüß† Memoryüó£Ô∏è Voice (TTS)üñºÔ∏è Image Generation üíñ Help Fund Auto-GPT's Development üíñIf you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help to push the boundaries of fully autonomous AI!Your support is greatly appreciated. Development of this free, open-source project is made possible by all the contributors and sponsors. If you'd like to sponsor this project and have your avatar or company logo appear below click here.                ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ö†Ô∏è LimitationsThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:Not a polished application or product, just an experimentMay not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!Quite expensive to run, so set and monitor your API key limits with OpenAI!üõ° DisclaimerThis project, Auto-GPT, is an experimental application and is provided \""as-is\"" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.The developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.Please note that the use of the GPT-4 language model can be expensive due to its token usage. By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.As an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.By using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.üê¶ Connect with Us on TwitterStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.Developer: Follow @siggravitas for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!        "
53,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        ÁÆÄ‰Ωì‰∏≠Êñá |        ÁπÅÈ´î‰∏≠Êñá |        ÌïúÍµ≠Ïñ¥ |        Espa√±ol |        Êó•Êú¨Ë™û |        ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    ü§ó Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.üó£Ô∏è Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.ü§ó Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.ü§ó Transformers is backed by the three most popular deep learning libraries ‚Äî Jax, PyTorch and TensorFlow ‚Äî with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install ü§ó Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, ü§ó Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.ü§ó Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by ü§ó Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: ü§ó Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from √âcole polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Su√°rez*, Yoann Dupont, Laurent Romary, √âric Villemonte de la Clergerie, Djam√© Seddah and Beno√Æt Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of G√∂ttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo L√ºddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Herv√© J√©gou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp Kr√§henb√ºhl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, Timoth√©e Darcet, Th√©o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Herv√© Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas Oƒüuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by Ren√© Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre D√©fossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, Lo√Øc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno√Æt Crabb√©, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey √ñhman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo Garc√≠a del R√≠o, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Herv√© J√©gou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by J√∂rg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre D√©fossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noah‚Äôs Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.Nystr√∂mformer (from the University of Wisconsin - Madison) released with the paper Nystr√∂mformer: A Nystr√∂m-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier H√©naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, Jo√£o Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, ≈Åukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Doll√°r.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault F√©vry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of W√ºrzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, Pawe≈Ç Krzysztof Nowak, Thomas M√ºller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll√°r, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Luƒçiƒá, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm√°n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper ‚ÄãXLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the ü§ó Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by ü§ó TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by ü§ó Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the ü§ó Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R√©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
54,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answers‚ö†Ô∏è DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]üôè PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!üéâ AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.‚ùì Need help?Open new issueüî• Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accounting‚ùóneeds updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustrator‚ùóneeds updating  7674Adobe-InDesign‚ùóneeds updating  4240Adobe-Lightroom‚ùóneeds updating  2020Adobe-Photoshop‚ùóneeds updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effects‚ùóneeds updating  2413Agile Methodologies‚ùóneeds updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCAD‚ùóneeds updating  7775@djayorAutodesk Fusion 360‚ùóneeds updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambda‚ùóneeds updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++‚ùóneeds updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurity‚ùóneeds updating10196Django7171@PROCW.NET Framework6359@declarckEclipse‚ùóneeds updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSON‚ùóneeds updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excel‚ùóneeds updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Project‚ùóneeds updating4443Microsoft Word‚ùóneeds updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooks‚ùóneeds updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revit‚ùóneeds updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePoint‚ùóneeds updating5338Sketchup22SOLIDWORKS‚ùóneeds updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnity‚ùóneeds updating4746@uno-sebastianVisual Basic for Applications (VBA)‚ùóneeds updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors ‚ú®Thanks goes to these wonderful people (emoji key):            Evgeniiüíª üñã      Sergei Stadniküíª üîç ü§î üìñ      Santhoshüíª      Jacob Dsaüíª üñã      Aaron Meeseüíª üñã      arqarqüíª üñã      Amit Yadavüíª üñã              Javokhir Nazarovüíª üñã      saurav kumarüñã      Chetanüñã      Amir Hossein Shekariüé® üñã üíª      SergDautüé®      Nilotpal Pramaniküé® üíª üñã üíº üìñ üî£ üí°      Abhishek Kumarüé®              Monu Guptaüé®      KARTIKEYA GUPTAüíª üñã      kenkyushaüíª üñã      juandavidtowersüíª üñã      cyber-neticsüíª üñã      jtriswüíª üñã      Renato Regaladoüíª üñã              Matthewüíª üñã      Jan S.üíª üñã      Manoliüíª üñã      Faraz tanveerüíª üñã      mohnishkarriüíª üñã üé®      andyzhuüíª üñã      Vishal Kushwahüíª üñã              Yurii Yakymenkoüíª üñã      Swetabh Sumanüíª üñã      AJAY DANDGEüíª üñã      Mehmet Yesinüé®      Lok Chun Waiüé®      Adria de Juanüé®      GL-Manüé®              Jheel Patelüé®      Sameer Waskarüé®      Alexander Andrewsüé®      Alexander Maxwellüé®      Slavaüé®      Mayur Khatriüé®      Mascantoshüíª üñã üì¢ ü§î              Kivanc Enesüé®      Ritika Dasüé®      Zer07793üé®      Andrew Cheungüé®      Sadhaüé®      tainenkoüé® üíª      github-star-coderüé®              Danilo Oliveiraüé®      lordekoüé®      Shubham Kumarüé® üíª      testtreeüé®      Cheryl Murphyüé® üíª      Bipin Thomasüé®      Abdulrahman Hishamüé®              Dakshitha Dissanayakaüé®      BADR KACIMIüé®      Alex Wangüé®      Maximüé®      GordonGrantüé® üíª      Ephrem Demelashüé®      JonOrcuttüé®              topdev10üé®      cookwellwebsiteüé®      xren935üé®      Nemo Frenkelüé®      MD SAIF ALAMüé®      Boris L√≥pez Arayaüé®      Larry Chiemüé®              Muhammad Bilal Ilyasüé®      AliMilaniüé® üíª      Suraj Sahaniüé®      FlyingSquirrelüé®      Erick Tijeroüé®      Jaskaran Kukrejaüé®      MichaelLüé®              MagicLegendüé®      Dereck Bearsongüé®      Pappu Kumar Pashiüé®      Venkata Kishore Tavvaüé®      Rafat Touqir Rafsunüé®      Snehesh Duttaüé®      Timo K√∂rnerüé® üíª              alexxxanüé®      GGJasonüé®      LeeAnna Ewingüé® ü§î      kamal Jyotwalüé®      Bob-Johnsüé® üíª üñã      yunussalmanlyitüé® üíª      chilcotüé® üíª              Jacky Liüíª üñã üé®      Sarthak Trivediüé®      Ayush Aggarwalüé® üíª      Nic Ballariniüé®      Luigi Zambettiüé® üíª      govindhaswinüé®      Addy Royüíª üé®              Akshat Tamrakarüé® üíª      Sai Bhargava Ramuüé®      Gurkanüíª      Spencer Hayes-Laverdiereüíª      Aniket Soniüíª      tanmay5792üíª      Dina Taklitüíª üé® üñã              Dushyant Singhüíª      Ravi Prakash Singhüíª      Nihal Joshiüíª      Guy Klagesüíª      Arvindüé® üíª      mujeeb91üíª      josercaüé® üíª              Prateek Agrawalüíª      Teoh Tze Chuin(„Çµ„É©)üíª üé®      Jayant Jainüíª      Ayush Sahuüíª      Hridya Krishna Rüíª üé®      Rahul Baliüíª üé®      S.ZHengüé® üíª üíº              Shriya Madanüé® üíª      mahalrupiüé®      Lucas Lermagneüé®      Jeff Deutschüé® üíª      Betoxx1üé®      Wingman4l7üé®      Martin Espericuetaüé®              Mh-Tahirüé®      Zdravko ≈†plajtüé® üíª      Ms3105üé® üíª üñã      Ambika Sidheswareüíª      mundogueroüíª      Darkus24üñã      Sou-786üñã üé®              Banurekhaüñã      ShiraStarLüé®      Ilya Komarovüé®      DemigodMsüñã üìñ      Mekha Hridyaüé® üîç      Andrey Safonovüé® üîç      Tommasoüé® üíª              Jessica Salbertüíª üé®      JAYANTH DOLAIüíª üé®      silverstroomüíª üé® üíº      Furkan Sayƒ±müíª üé®      Sukumar Chandrasekaranüé®      Yejin Parküé® üíª      Ali Nooshabadiüé® üíª              imitavorüé® üíª      Salih Kilicliüé® üíª      Marcelo Menesesüé® üíª      Anton Krekotunüé® üöß üñã üíª üìñ üíº      Arnav Sarmaüíª üí° üé®      meghatikuüíª üé®      Anshu Trivediüé®              Taylor Dorsettüíª üñã üé®      Havit Roviküíª      pushpapuneüíª üé®      Ramtin Radfarüé® ü§î üíº üíµ üíª üñã üí¨      Abdulmajeed Isaüíª üé®      vikassaxena02üé®      RobTablesüé® üíª üíº              Danielüé® üíª üíº üîç      Zahid Aliüíª üé®      Chad Chaiüíª üé®      Marco Biedermannüíª üé® üíº ü§î      Srinidhi Murthyüé®      Miao Caiüíª üé®      Dionicio Diazüé® üíª              Mir Monoarul Alamüé®      Shawn Ohnüíª üé®      Amanbolat Balabekovüé® üíª      black-mamba-codeüíª      Jian-forksüé® üíª      shivani patelüé®      Akash Chowrasiaüé®              yairg98üé®      Jay Gajjarüé®      coolerboolerüíª      Md Zinnatul Islam Morolüé®      shresthashok550üé® üìñ      Alan Pallathüìñ      Adrian Wongüíª              vsDizzyüíª üé®      Frex Cuadilleraüé® üíª      ashish570üíª üé®      ruchpeanutsüíª üé®      Artmasqueüé® üíª      Amirhossein Mojiri Foroushaniüé®      forüíª üé®              Lukeüé® üíª      Hector Espinozaüé®      Adri√°n Buenfilüé® üíª      Amit Kumarüé®      schoppfeüé® üíª      Sofiyal Cüé® üíª      spitlisküíª üé®              PRAVIN SHARMAüé®      NIDZAAA1üé® üíª      John Maiüé® üíª      kimsoyeongüé®      Dona Ghoshüíª      Ryan Hillüé® üíª      j42züé® üíª              Ashish Sangaleüé® üíª      Derek Yangüé® üíª      mohsinmsmüé® üíª      Gokulkrish2302üíª      Bhaavisheküíª üé®      Louis Liaoüé®      sengc92üé® üíª              Alex Marvinüé®      Balkrishna Bhattüé® üíª      Evaldas Lavrinoviƒçiusüé® üíª      Adam Erchegyiüé® üíª      Truman Hungüé® üíª      rzamora11üé®      gaurav0224üé®              Lee GyeongJunüé®      Mireküé® üíª      surajm245üé®      ArisLaodeüé® üíª      RaviDhoriyaüé® üíª      sarai-84üé® üíª      Vishnuüé® üíª              Muhammad Minhajüíª      Chandrika Debüé® üíª      Gitgit101-bitüíª üé®      Hedi Sellamiüíª üé®      saurabhvaish93üíª üé®      Nikola Begovicüíª üé®      Wangüíª üé®              Manuel Eusebio de Paz Carmonaüé®      Basim Al-Jawaheryüé® üíª      RAJA AHMEDüé® üíª      Abhik Lodhüíª      Md. Pial Ahamedüíª üé®      Hassan Shahzadüíª üé®      Christian Sosa Gagoüíª              Hasnain Rasheedüíª üé®      T-Radfordüíª      dahiyashishüíª üé®      RahulSharma468üíª üé®      Jumpod Plekhongthuüíª üé®      Thomas Young-Audetüíª üé®      VinayagamBabuüíª üé®              Deniz Ko√ßüíª üé®      Azhar Khanüíª üé® üñã üìñ üî£ üöß      Jacob Shortüíª üé®      Uchimura85üíª üé®      Leo Nugrahaüíª üé® üìñ      Mujtaba Mehdiüìñ üñã      Jim-dsüíª üé®              Sreehari Küíª üé®      Florian Martinezüíª üé®      Aaronüíª üé®      apoageüé®      Ignacio Guillermo Martinez üíª üé®      AirlineDogüé® üíª      Mekelüé® üíª              hmosharrofüé® üíª      Ben Emamianüíª üé®      babesharküíª üé®      Leonardo Jaquesüíª üé®      Stefanos Apkarianüíª üé®      Ayhan Albayraküíª üé®      KidusMTüíª üé®              hectormarroquin20üíª üé®      Edelweiss35üíª üé®      MihaiDüíª üé®      AnveshReddyAnnemüíª üé®      Hyunjae Parküíª üé®      Rajiv Albinoüíª üé®      Atishayüíª              Yusuf Naheemüé®      Winduüé® üíª      Superv1sorüíª üé®      Karine (:üé® üíª      Eduard Pechüé® üíª      jjeshwaniüé® üíª      Steveüé® üíª              Aleigh Ohslundüíª      Abhinav Sumanüé® üíª      Hamza Ehtesham Farooqüé® üíª      IamNotPeterPanüíª üíµ üé®      Cetgerüé®      pkonopackiüé®      Yang Yangüé® üíª              Muhammad Shoaib Sarwarüíª      Murilo Henriqueüíª üé®      emilianoalvzüé® üíª      Sumana Sahaüé® üíª      Yurii17Küé® üíª      Rupesh Bhandariüé® üíª      salmos3718üíª              John Bakerüé® üíª      SanjaySathirajuüé® üíª      Donat Kabashiüé®      Arul Prasad Jüé® üíª      Qi Chenüé® üíª      Maksym Dmyterkoüé® üíª      ilovepullrequestsüíª              Samira Malekiüé® üíª      NIKITA MAHOVIYAüíª      jesuisdev.Netüé® üíª      Ashraf Nazarüé®      Naveed Ahmadüé®      Ajmain Naqibüé® üíª      Avinash Tingreüíª üé®              nicktidsüé®      Keith Dinhüíª üé®      Andr√© Ferreiraüíª üé®      eliottkespiüíª üé®      praveenpnoüíª üé®      vitowidigdoüíª üé®      Devesh Pratap Singhüíª üé®              Dario Rodriguezüíª üé®      charmander_didiüíª üé®      PHBasinüíª üé®      Ritvik Singh Chauhanüíª üé®      Riya P Mathewüíª üé®      Stephanie Cherubinüíª üé®      BenitesGuiüíª üé®              FarikBearüíª üé®      Dmytro Havrilovüíª üé®      Parvesh Monuüíª üé®      Dipen Panchasaraüíª üé®      gudataüé® üíª      gawadeditorüíª üé®      Kirill Taletskiüé® üíª              Saajanüé® üíª      Kushagra Süé® üíª      Oanh Leüé® üíª      Frane Medvidoviƒáüé® üíª      Yormanüé® üíª      Bill Chanüé® üíª      Pratik Lomteüé® üíª              LOC LAMüé® üíª      TUSAR RANJAN MAHAPATRAüíª      BhargavKanjarlaüíª      Karel De Smetüíª üé®      sidisanüé®      ygnzayarphyoüé® üíª      svansteelandtüíª              Kebechetüé®      Daniel Selvan Düé® üíª      Mahdi Razaviüé® üíª      Niklas Tiedeüíª üé®      narutubaderddinüíª üé®      dylandhoodüíª      Dheeraj Guptaüíª              Pieter Claerhoutüíª üé®      Shivam Agnihotriüíª      RanjithReddy-Narraüíª      Nikita Wadhwaniüé® üíª      rsholokhüíª üé®      Ayaan Hossainüíª üé®      Rajesh Swarnaüíª              Deniz Etkarüé® üíª      pro335üíª üé®      Jakub Radziküíª üé®      Hamza Khanzadaüíª      ARNONüé®      Vikram Singhüíª      Shoxruxbeküíª üé®              Amit Khatriüíª üé®      Wali Ullahüé® üíª      Amit11794üíª üé®      metis-macys-66898üíª üé®      Faisal Maqboolüé® üíª      Kumar Neerajüíª üé®      Maurizio Mariniüé® üíª              Saket Kothariüé® üíª      Szymon Zborowskiüé® üíª      iks3000üé® üíª      Ehsan Seyediüé® üíª      vanekbrüé® üíª      Princy_Müé® üíª      Shijie Zhouüé® üíª              lakshyamcs16üé® üíª      Filippo Faccoüé® üíª      mendel5üé® üíª      Patryküé® üíª      VishwaSanganiüé® üíª      Alvin Zhaoüé® üíª      Lazar Gugletaüé® üíª              vmichoüé® üíª      Sikandar Aliüé® üíª      Raja Babuüé® üíª      faizajahanzebüíª      Guil_AiTüé® üíª      Kushal Dasüé® üíª      Luis Bonillaüé® üíª              jovan1013üé® üíª      Damianüé® üíª      Yash Guptaüíª      lolcatnipüé® üíª      Ikko Ashimineüé® üíª      Farukhüé® üíª      Moksedulüíª üé®              Navneet Kumarüé® üíª      Saqib AlMaliküíª      fahimrahmanüé® üíª      vaibhav patilüé® üíª      Rahul Madanüé® üíª      kartik Kaklotarüé® üíª      ASAHI OCEANüé® üíª              Daniel Jungbluthüé® üíª      Rajdeep Singh Boranaüé® üíª      ankitha19üíª      Linh Tranüíª      islamarrüíª üé®      Mohamed Sabithüé® üíª      Miguel Angel Cruz Acostaüé® üíª              Adebayo Ilerioluwa üé®      Markusüé® üíª      dkonyayevüé® üíª      Kevin A Mathewüé® üíª      David Meloüé® üî£      DFW1Nüé® üíª      Sohaib Ayubüé® üíª              Navvyüé® üíª      bloodiator2üé® üíª      Hanjiüé® üíª      arthur74üé® üíª      Sri Subathra Devi Büé® üíª      Akif Aydogmusüé® üíª      Umer Javaidüé® üíª              Norio Umataüé® üíª      Gazi Hasan Rahmanüé® üíª      Keith Nguyenüé® üíª      Megalomaniacüé® üíª      ShankS3üé® üíª      Farhad Alishovüé® üíª      Ronak J Vanpariyaüé® üíª              azrael0learzaüé® üíª      Pavel Rahmanüé® üíª      chuabernüé® üíª      Rahul Tirkeyüé® üíª      Ruslan Besüé® üíª üí° üöß üñã üî£ üöá      Bohdanüé® üíª      Juzdzewskiüé® üíª              Grigor Minasyanüé® üíª      alvintwcüé® üíª      Anand Natarajanüé® üíª      Kashan Aliüé® üíª      Thomas Meshailüé® üíª      Son Phamüé®      Michael Frenchüí°              Yash Mishraüìñ      Miguel Rodriguezüé® üíª      Philipp Bachmannüé® üíª      sunnyüé® üíª      Siddharth Chatterjeeüé® üíª      Michael Naghavipourüé® üíª      Sahil Gargüé® üíª              MicroLionüé® üíª      wctwcüé® üíª      Rohan Sharmaüî£      AshishBodlaüé® üíª      Taras Pysarskyiüé® üíª      Luqman Bello O.üé® üíª      DyingDownüé® üíª              Diego Chapedelaineüé® üíª      Richleeüé® üíª      Asif Habibüé® üíª      Mazharul Hossainüé® üíª      toniüé® üíª      Pragyanshu Raiüé® üíª      Matthew Ellerüé® üíª              AbhiBijuüé® üíª      Roman Zhornytskiyüé® üíª      Lucas Caminoüé® üíª      Jo√£o Vitor Casarinüé® üíª      Evgeniy Shayüé® üíª      Ehsan Barkhordarüé® üíª      Gabrielüé® üíª              Shibu Mohapatraüé® üíª      Pavel Kirkovskyüé® üíª      Tahir Gulüé® üíª      imDevSalmanüé® üíª      Jordan Donaldsonüé® üíª      js-venusüé® üíª      Faisal Shaikhüé® üíª              ashishbpatilüé® üíª      Tri Leüé® üíª      tomtreffkeüé® üíª      Salah Eddine Lalamiüé® üíª      Mattias Xuüé® üíª      Manas Guptaüé® üíª      wolfsong62üé® üíª              Mehdi Mirzaeiüé® üíª      Van Ba Khanhüé® üíª      Sel Embeeüé® üíª      Suvradip Paulüé® üíª      Shariqueüé®      Seabassüé® üíª      Penny Liuüé® üíª              jatinder bholaüé® üíª      misterqbitüé® üíª      Daniel-VS9üé® üíª      Shruthiüé® üíª      beefydogüé® üíª      Suraj Kumarüé® üíª      hrishikeshpsüé® üíª              Sudarshanüé® üíª      Divyanshüíª üé®      Zyaireüé® üíª      Omar Belkadyüé® üíª      alexiismuaüé® üíª      Eduarda Alvesüé®      pycoachüé® üíª              Ruhulüé® üíª      pmoustopoulosüé® üíª      Lee Hui Tingüíª üé®      bodi1981üé® üíª      Devaraat Joshiüé® üíª      Johnnyüé® üíª      rogue-coderüé® üíª              viiktrüé®      Lalit Mohanüíª      Jo√£o Sousaüíª      Ë®ÄËëâ‰πãÈùàüíª üé®      RJLABSüíª      brittney0522üé® üíª      shamüé® üíª              Glenn Goossensüíª üé®      Cyber Hawküé® üíª üñã üíº      Ankit Yadavüé® üíª      verbalityüíª      Mohammed Siddiquiüé® üíª      AdamKaczor6250üé® üíª      Ram√≥n Martinez Nietoüé® üíª              Grzegorz Dziubaküé® üíª      Ayoub BERDEDDOUCHüé® üíª      nikola-fadvüé® üíª      Akarsh Agrawalüé® üíª      Mitra Mirshafieeüé® üíª      Parker Stephensüé® üíª      alrenee99üíª              Karthick Vankayalaüíª      Iryna üé® üíª      palanugrahüíª      Gwinbleindüé® üíª      Randy Bobandyüé® üíª      Bek Rozikoffüíª      davnguyeüé® üíª              Neel Patelüíª      ehudbeharüé® üíª      nicholas-cod3rüé® üíª      michaelfrankiüé®      Esther Whiteüé® üíª      prathmeshpbüé® üíª      Victor Linüé® üíª              Christine C. Yinüé® üíª      GitLearner-beginüé® üíª      Mesrop Andreasyanüé® üíª      Nathan Garciaüé®      commonsw04üé® üíª      Md. Rashad Tanjimüé® üíª      Ali Maleküíª              PAODLTüé® üíª      Nikhil Bobadeüé® üíª      hyuckjin21üíª      Itasha Modiüé® üíª      Nikitha Reddyüé® üíª      Mahshooq Zubairüé® üíª      Subham Dasüíª              Onkar Birajdarüé® üíª      Nick Titomichelakisüé® üíª      Christian Leo-Pernoldüé®      Matthew Marquiseüé® üíª      baronfacüé® üíª      Abhishek Tilwarüé® üíª      DavidsDvmüé® üíª              Parth Parikhüé® üíª      Hector Castroüé® üíª      Rikky Arisendiüé® üíª      Ali HamXaüé® üíª      Frank.wuüé® üíª      Jatin Kumarüé® üíª üìñ      masterHAWK99üé® üíª              Pushp Jainüé® üíª      Ashutosh Routüé® üíª      Atharva Deshpandeüé® üíª      Teodor Ciripescuüé® üíª      Anmol Bansalüé® üíª      Nikhil Kumar Macharlaüé® üíª      Dexterüé® üíª              Aaronüé® üíª      Yogita Jaswaniüé® üíª üìñ üñã      StoryDevüé® üíª      Mesut Doƒüansoyüé® üíª      Paras Dhawanüé® üíª      Emanuel Zhupaüé® üíª      Aaradhyaa717üé® üíª              jaacko-torusüé® üíª      mBlacküíª      kalrayashwinüìñ üñã üé® üíª      Seraphüíª üé®      ZhiHong Chuaüé® üíª      Amsal Khanüé® üíª üìñ üñã      Raghav Rastogiüé® üíª              Tzilaüìñ      Shahriar Nasim Nafiüìñ      AGüé® üíª      Mojtaba Kamyabiüé® üíª      Ahmad Abdulrahmanüé® üíª      Eclipseüé® üíª      Anshu Palüé® üíª              Denisüé® üíª      mehmet sayinüìñ      WebDEVüé® üíª      Sam Komesarooküé® üíª      Kiran Ghimireüé® üíª      Joshua Davisüé® üíª      Muhammad-Huzaifa-Siddiquiüíª              tobeornottobeadevüé® üíª      VAIBHAV SINGHALüé® üíª      Keiran Pillmanüé® üíª      Max Donchenkoüé® üíª      sgonsalüé® üíª      diksha137üé® üíª      Vigneshüé® üíª              Gabriel Fran√ßaüé® üíª      Josephüé® üíª      Bruno Rafaelüé® üíª      vcamarreüé® üíª      thibault kettererüé® üíª üöß      VictorGonzalezToledoüé® üíª      1911510996üé® üíª              inviduüé® üíª      Nurul Furqonüé® üíª      David Asbillüé® üíª      Niko Birbilisüé® üíª      Mugundan Kottursureshüé®      agrsachin81üé® üíª      Othmane El Alamiüé® üíª              Syed Atif Aliüé® üíª      lakhanjindamüé® üíª      youssef hamdaneüé® üíª      starfaerieüé® üíª      rodrigo0107üé® üíª      Micha≈Ç Gralaküé® üíª      Jewel Mahmudüé® üíª              cwilson830üé® üíª      buun1030üé® üíª      Reda-ELOUAHABIüé® üíª      saad-aksaüé® üíª      Emdadul Haqueüé® üíª      PROCWüé® üíª      cccppp1üé® üíª              Joanna Baileüé® üíª      Ahmed Saberüé® üíª      Masoud Keshavarzüé® üíª      mortazavianüé® üíª      Aniket Pandeyüé® üíª      Vijay Nirmalüé® üíª      Daniel Carvalloüíª              menaechmiüé® üíª      azenyxüé® üíª      Ahmet √ñzrahatüé® üíª      Abdulrahman Abouzaidüé® üíª      jmgnorbecüé® üíª      palinko91üé® üíª      Laisson R. Silveiraüé® üíª              BHARGAVPATEL1244üé® üíª      Candide Uüé® üíª      Sitansh Rajputüé® üíª      Houda Mouttalibüé® üíª      MumuTWüé® üíª      Suave Bajajüé® üíª      Mehdi Parsaeiüé® üíª              Dinko Osreckiüé® üíª      Dhia Djobbiüé® üíª      Mahmoud Galalüé® üíª      Anh Minhüé® üíª      Suvesh Küé® üíª      Petar Todorovüé® üíª      Alexander Nguyenüé® üíª              Morteza Jalalvandüé® üíª      Claudson Martinsüé® üíª      Matt Jacobsonüé® üíª      Rafael Belokurowsüé® üíª       Thomas Gamaufüé® üíª      Rishabh Mahajanüé® üíª      rakeshpdgupta23üé® üíª              Shashidharknaiküé® üíª      taleleumaüé® üíª      Florian B√ºhlerüé® üíª      Raihan Bin Wahidüé® üíª      MOHAMMED NASSERüé® üíª      federicoüé® üíª      Andre Violanteüé® üíª              tcunningham98üé® üíª      Jan Grie√üerüé® üíª      Serkan Alcüé® üíª üñã      Jez McKeanüé® üíª      meisam alifallahiüé® üíª      Mehul Thakkarüé® üíª      Saksham Soniüé® üíª              Pedro Peregrinaüé® üíª      Mintu Choudharyüé® üíª      lucianmoldovanuüé® üíª      John C. Scottüé® üíª      Mia D.üé® üíª      EwenBernardüé® üíª      M. Reza Nasirlooüé® üíª              Jay Agrawalüé® üíª      DeShayüé® üíª      Jay206-Programmerüé® üíª      Elenderüé® üíª üñã      Bobby Byrneüé® üíª      Pirciüé® üíª      Hasanuzzamanüé® üíª              Josh Kautzüé® üíª      Brofarüé® üíª      Mina Karamüé® üíª      Duncan O Nüé® üíª      Sean Tumulak-Nguyenüé® üíª      Artur Trze≈õniewskiüé® üíª      JJaammeessMüé® üíª              shubham agarwalüé® üíª      Michele Righiüé® üíª      Panagiotis Kontosüé® üíª      sumitbathlaüé® üíª      Deepak Mathurüé® üíª      Juho Nyk√§nenüé® üíª      Santiago Gonz√°lez Siordiaüé® üíª              SRIJITA MALLICKüé® üíª      Samriddhi Büé® üíª      Nitzan Papiniüé® üíª      Mario Sanzüé® üíª      Crab^4üé® üíª      Pabloüé® üíª      Gordon Pham-Nguyenüé® üíª              Kristofferüé® üíª      chrisblachüé® üíª      G√°borüé® üíª      Linaüé® üíª      Harrison Wattsüé® üíª      Mario Petriƒçkoüé® üíª      Ben8120üé® üíª              Giovannaüé® üíª      Minal Ahujaüé® üíª      mossfarmerüé® üíª      ThaC0derDreüé® üíª      itwareüé® üíª      Michael Walkerüé® üíª      Tom Jacob Chirayilüé® üíª              Sachin Kumarüé® üíª      adi-rayüé® üíª      Dr-Blank-altüé® üíª      Bogdan Cazacuüé® üíª      Gilson Urbanoüé® üíª      Ninaüé® üíª      Anthonyüé® üíª              manushimjaniüé® üíª      Michael Reyesüé® üíª      Rachel Kennellyüé® üíª      Aakash Gargüé® üíª      Daniel Livingstonüé® üíª      alexrojcoüé® üíª      Minh Nguyenüé® üíª              Mahesh Dattatraya Babarüé® üíª      Jin Zihangüé® üíª      Bikramjit Gangulyüé® üíª      QuestionableGuiseüé® üíª      liq19chüé® üíª      Bruno Rochaüé® üíª      Anand Dyavanapalliüíª üñã              crucian-afküé® üíª      0xgainzüé® üíª      weirdfshüé® üíª      Valan Baptist Mathuranayagamüé® üíª      Paul Kaeferüé® üíª      Yu-Hsiang Wangüé® üíª      Javad Adibüé® üíª              davidliu0930üé® üíª      Achilleas John Yfantisüé® üíª      Omkar Shivadekarüé® üíª üñã üêõ      ToanTranüé® üíª      Gautam Naiküé® üíª      Marcüé® üíª      twix20üé® üíª              Kristian S.üé® üíª      Aleksey Khoroshilovüé® üíª      arjunsrsrüé® üíª      Ali Haiderüé® üíª      Trisha Dringüé® üíª      Andre Marzuloüé® üíª      Krishna Modiüé® üíª              Rosemary Liüé® üíª      Alex Wellerüé® üíª      Tam Nguyenüé® üíª      aquintelaoliveiraüé® üíª      Norbert Brettüé® üíª      rocsogdüé® üíª      0nyrüé® üíª              rethkevinüé® üíª      RickHeadleüé® üíª      Leandreüé® üíª      Natnael Sisayüé® üíª      sbbuüé® üíª      waelüé® üíª      Fabricio Tramontano Piriniüé® üíª              Alexander Stoyanovüé® üíª      Dezx20üé® üíª      southparkkidsüé® üíª      bmstarüé® üíª      kiagamüé® üíª      Juan Castilloüé® üíª      FFenneüé® üíª              Jose Toledoüé® üíª      Pat McGhenüé® üíª      Eiko Wagenknechtüíª üñã üî£      Alan Chalmersüé® üíª      Jean Didierüé® üíª      Andyüé® üíª      pestadieuüé® üíª              Kanishka Chakrabortyüé® üíª      Nandhaüé® üíª      Vahid Mafiüé® üíª üî£ üñã üíº      Akshay Ashoküé® üíª      0x08üé® üíª      Sandeep Mishraüé® üíª      Evann Regnaultüé® üíª              Lenny Zeitounüé® üíª      Eden Boaronüé® üíª      TroyBTCüé® üíª      Aby Sebastianüé® üíª      Matthew Dunnüé® üíª      ckulloüé® üíª üñã üî£      Mohamed Mamdouhüé® üíª              Youssef Bazinaüé® üíª      Frederico K√ºckelhausüíª      Nushan Kodikaraüíª      Zach Cooperüíª      Royüé® üíª      Saurav Panchalüé® üíª      totallynotdavidüé® üíª              goosepirateüé® üíª üí° üíº      KAUTHüé® üíª      Hari Kiran Vusirikalaüé® üíª      Sounak Deyüé® üíª      ziaüíº üé® üíª      Reza Davariüé® üíª      AkshayAjaykumarüé® üíª              x24870üé® üíª      Ko Phoneüé® üíª      Nabstar3üé® üíª      Mateuszüé® üíª      Yunus Emre Emiküíª      Abhinav Sinhaüé® üíª      Hung Nguyenüé® üíª              Maselinoüíª      Shuktika Mahantyüíª      Miko≈Çaj Gawro≈Ñskiüé® üíª      Hussein Habibi Juybariüé® üíª      Sean-McArthurüé® üíª      Osman F Bayramüé® üíª      Benjamin Thomas Blodgettüé® üíª              Chuanlong-Zangüé® üíª      julianüé® üíª      franciscoüé® üíª      aalihhiader9211üé® üíª      Muhammad Zunairüé® üíª      Liyaüé® üíª      BegadTareküé® üíª              etorobotüé® üíª      Hussam Khanüé® üíª      Saikat Chakrabortyüé® üíª      Nicholas Quislerüé® üíª      Evang Poulüé® üíª      Gregg Lindüé® üíª      Deepak Kumarüé® üíª              Callum Leslieüé® üíª      Curtis Barnard Jr.üé® üíª      Deepanshukaimüé® üíª      Manthan Anküé® üíª      hossein varmazyarüé® üíª      Brayan Mu√±oz V.üé® üíª      Kamil Rasheed Siddiquiüíª üé®              mutt0-dsüé® üíª      egbertjküé® üíª      Majid Zojajiüé® üíª      Sean Chenüé® üíª      Herbert Milhommeüé® üíª      A3üé® üíª      Killianüé® üíª              Coakeowüé® üíª      ‡æÖ‡ºª «¨…Äƒß ‡ºÑ‡ºÜ‡Ωâüé® üíª      Pratik Solankiüé® üíª      Sunnyüé® üíª      ssgeüé® üíª      Bernat Frangiüé® üíª      Jeevan Rupachaüé® üíª              amirandapüé® üíª      Deepakshi Mittalüé® üíª      Abhijeet Paridaüé® üíª      Khaled Riyadüé® üíª      Pratap paruiüé® üíª      Prajit Pandayüé® üíª      PipeSierraüé® üíª              Collins Odenüé® üíª      Kshitij Dwivediüé® üíª      Bernardia Vitri Arumsariüé® üíª      √ñmer Faruk Ta≈üdemirüé® üíª      Spencer Stithüé® üíª      Porsche Rodjanasaküé® üíª      Shakeel Sharifüé® üíª              Victoria Chengüé® üíª      Denisüé® üíª      Anand Prakash Tiwariüé® üíª      danijeljw-rpcüé® üíª      Ahmed H Ebrahimüé® üíª      Virginia Gardnerüé® üíª      Jhironsel Diaz A.üé® üíª              Yunus Kidemüé® üíª      MTüé® üíª      Dinesh Zaldekarüé® üíª      adiüé® üíª      Farhan Shaikhüé® üíª      Elvis Salvatierraüé® üíª      Kaushik-Iyerüé® üíª              HocAndresüé® üíª      VictorHugoAguilarAguilarüé® üíª      Murat Can Abayüé® üíª      Chrisüé® üíª      Shivam7-1üé® üíª      Paipai13üé® üíª      Shambles-ioüé® üíª              Abhishek K Müé® üíª      Ezequiel Cuevasüé® üíª      Plamen Ivanovüé® üíª      Yujiüé® üíª      Jean-Philippe Leb≈ìufüé® üíª üî£      Naufanüé® üíª      jadnovüé® üíª              vaxtangensüé® üíª      subashkonar13üé® üíª      Rushi Javiyaüé® üíª      Mert G√ºlüé® üíª      Lilyüé® üíª      Kalinoffüé® üíª      Joel Tonyüé® üíª              Peterüé® üíª      Roozbeh Zareiüé® üíª      Shenüé® üíª      Joonsoo.LEEüé® üíª      Fede.Bregüé® üíª      Rui Costaüé® üíª      Jo√£o Gustavo Bispoüé® üíª              Sami-Iüé® üíª      Tsvetoslav Tsvetkovüé® üíª      Olabode Olaniyi Davidüé® üíª      theRuslanüé® üíª      leighbozüé® üíª      Frank Sossiüé® üíª      Tomasz Adamskiüé® üíª              Mansoor M. Sathirüé® üíª      Golamrabbi Azadüé® üíª      Nahian Ahmedüé® üíª      Rafael de Jesus Silva Monteiroüé® üíª      Odionyebuchukwu Judeüé® üíª      The Nithin Balajiüé® üíª      Knackiiüé® üíª              vittorio-giattiüé® üíª      Guilherme de Carvalho Lima Rebou√ßasüé® üíª      aaref shamiüé® üíª      Andrey Dryupinüé® üíª      Muhanned Nomanüé® üíª      Jan Silvaüé® üíª      emanuele-emüé® üíª üñã              Sanjay TMüé® üíª      Joe Markberg / code editorüé® üíª      Julien Quiaiosüé® üíª      Eric Ramirez Santisüé® üíª      Müé® üíª      Malcataüé® üíª      Athul Muralidharanüé® üíª              Dariusz Ochotaüé® üíª      CHANDAN CHOUDHURYüé® üíª      Deepüé® üíª      Ahmet ƒ∞stemihan √ñZT√úRKüé® üíª      TIMüé® üíª      jakeg814üé® üíª      Leonidosüé® üíª              Abhinandu V Nairüé® üíª      charafeddine01üé® üíª      Jasperüé® üíª      Manish Goyalüé® üíª      SATYAM_SINGHüé® üíª      Fourüé® üíª      Vaishnavi Amira Yadaüé® üíª              ShriKrushna Bhagwatüé® üíª      Rohit Nandagawaliüé® üíª      felipeüé® üíª üöß üñã ‚úÖ üßë‚Äçüè´      Saurabh Mudgalüé® üíª      szenadamüé® üíª      Shubhendra Singhüé® üíª      Yoosuf Sayyidüíª üé®              G√ºven √áetinerlerüé® üíª      Luke Jefferiesüé® üíª      Chrisüé® üíª      L√∫cio Aguiarüíª      Enuma029üíª      yktsang01üíª      maximumn3rdüé® üíª              Jon Galleteroüé® üíª      Thaddeus  Thomasüé® üíª      Aakash Kumarüíª üé®      Ali Müé® üíª      OskyEdzüé® üíª      Ravi Guptaüé® üíª      Rafa Raizerüé® üíª              Abdullah Al Muzakiüé® üíª      Rahul Faujdarüé® üíª      Abhishek Vermaüé® üíª      Ashutosh Shindeüé® üíª      Ganesh Raiüé® üíª      StefanTrpkovicüé® üíª      Erik Blancaüé® üíª              Vedant Madaneüé® üíª      Antra Tripathiüé® üíª      Ethan Knightsüé® üíª      Alexandru Boncutüé® üíª      Pablo Bandinoplaüé® üíª üöß üñã      Robz-99üé® üíª      Harpal Singhüé® üíª              paulboundy99üé® üíª      Mubashir Ahmedüé® üíª      Rohan Hariüé® üíª      Erik Henrique üé® üíª      Leandro Matheusüé® üíª      Deepaküé® üíª      AlishaSinghüé® üíª              Lynn Latt Yatiüé® üíª      San Shweüé® üíª      SKRüé® üíª      msbunnyjaguarüé® üíª      Mohamad Zabiullaüé® üíª      Hatim Zahidüé® üíª      Rauzan Sumaraüé® üíª              Hosein1358üé® üíª      Mohitüé® üíª      Aliüé® üíª      Avinash1765üé® üíª      Sai Teja Madhaüé® üíª      Monsur Ahmed Shafiqüé® üíª      xuxianjin-devüé® üíª              chetnaüé® üíª      Gul Zaibüé® üíª      Nataliaüé® üíª      Dion√≠sio Bragaüé® üíª      Pritish Rajpurohitüé® üíª      incanloveüé® üíª      Innocentüé® üíª              Devin Almonorüé® üíª      antonyveyreüé® üíª      Beltz Anhxtonüé® üíª      Mehdiüé® üíª      Muhammad Usmanüé® üíª      Patrick Dantasüé® üíª      Tak Vannaküé® üíª              Ramzi RADDAOUIüé® üíª      Konstantin-Glukhovüé® üíª      ugurobanüé® üíª      Humberto Alvesüé® üíª      JuangZendratoüé® üíª      James Oluwaleyeüé® üíª      Wasi Sadmanüé® üíª              Pavle Mijatovicüé® üíª      Luiz H. S. Bispoüé® üíª      –°—É—Ö–∞—Å –î—Ö–æ–ª–∑üé® üíª      Alvaro Trujilloüé® üíª      Everton üé® üíª      jfrozasüé® üíª      Shuaaib Badranüé® üíª              Shivam Jhaüé® üíª      Mohamed Tayehüé® üíª      Makendran Güé® üíª      mayank singh tomarüé® üíª      hossam sadanyüé® üíª      Harshbardhan Singhüíª üé®      Fawad Jawaid Maliküé® üíª              Tina Lacatisüé® üíª      TeddyCuoreDolceüé® üíª      bchooxgüé® üíª      Alisha Takkarüé® üíª      Gianluigiüé® üíª      Mehran Javaherianüé® üíª      Benjamin Ololade Adedokunüé® üíª              Md. Abdul Mutalibüé® üíª      Aadil Arsh.S.Rüé® üíª      J. Nathan Allenüé® üíª      Kieran Krugüé® üíª      Seth Addoüé® üíª      Satvik Singh Rathoreüé® üíª      dangothüé® üíª              Maximüé® üíª      Phuong-Cat Ngoüé® üíª      Frenchtoast0üé® üíª      Rakshithüé® üíª      Vaibhav Aroraüé® üíª      zghpüé® üíª      Bedovanüé® üíª              chiaramistroüé® üíª      him2016üé® üíª      HarshitSachdevaüé® üíª      Sadaf Saleemüé® üíª      Aaroh Srivastavaüé® üíª      eloygplazaüé® üíª      Gaurav Kumar Vermaüé® üíª              AndreaCUSüé® üíª      Simranüé® üíª      Prashant Bhapkarüé® üíª      mhaendlerüé® üíª      Gauri Maheshwariüé® üíª      4Lajfüé® üíª      Tanmoy Senguptaüé® üíª              Sharad Tripathiüé® üíª      Niraj Chavanüé® üíª      Luisa Gualdaüé® üíª      Monika-Sivakumar-3üé® üíª      harryfensomeüé® üíª      Shubham Choubeyüé® üíª      Ashwini Patilüé® üíª              cleversonliraüé® üíª      Nurmukhammedüé® üíª      workspace-utkarshüé® üíª      Santosh Phadtareüé® üíª      Prashant Warghudeüé® üíª      Umang Dakhüé® üíª      Shalini Chavanüé® üíª              vinit gurjarüé® üíª      Vishal Kumarüé® üíª      Wonhyeong Seoüé® üíª      Achwale Prajwal Namdevraoüé® üíª      Ankan Banerjeeüé® üíª      bhaumikankanüé® üíª      JamesMacroZhangüé® üíª              Pedro Lopesüé® üíª      diaüé® üíª      tayyabhussain2910üé® üíª      Rajdeep Shrivastava üé® üíª      Mukul Kumarüé® üíª      Mayank Nüé® üíª      jdeluccaüé® üíª              Sneha Mittalüé® üíª      Sarika Kushwahaüé® üíª      farzad-khbüé® üíª      Elijah Shackelfordüé® üíª      The-Only-Raminatorüé® üíª      Keerthana Kasthurilüé® üíª      Viachaslau Auchynnikauüé® üíª              Mohammad Osman Rasooliüé® üíª      mvedovatoüé® üíª      Sonali Rajputüé® üíª      Isha Dheküé® üíª      Ramshad Cheriyeri Peediyakkalüé® üíª      Micahüé® üíª      gauravshukla2203üé® üíª              sndmurthyüé® üíª      Shivam-Singhüé® üíª      M. Ammar Khanüé® üíª      chandolakulüé® üíª      bhatnagar221üé® üíª      Adrian Nie≈õciurüé® üíª      nezi311üé® üíª              scottajevansüé® üíª      Marcelo Antunes Soares Fantiniüé® üíª      Axel De Acetisüé® üíª      Drishti Sahüé® üíª      VipulDhillonüé® üíª      Urmi Janaüé® üíª      Ayush Mokalüé® üíª              Damola Olutokeüé® üíª      Maxüé® üíª      Lakshmi Nüé® üíª      ArtemRevaüé® üíª      Ujjwal Aggarwalüé® üíª      Moüé® üíª      Brianüé® üíª              chamleyüé® üíª      Simone Baptisteüé® üíª      Shekhar Thakurüé® üíª      Smithüé® üíª      codernoob1üé® üíª      lok84üé® üíª      Tobias Riemenschneiderüé® üíª              Tharsanan1üé® üíª      ANURAG SINGHüé® üíª      Yash Santüé® üíª      Krishiv Patelüé® üíª      GGGalaxyüé® üíª      pardeepdhillon661üé® üíª      anujd64üé® üíª              Pedro Pereiraüé® üíª      Master_Saptaküé® üíª      SURANJAN DASüé® üíª      Tripura kantüé® üíª      shabzkhanüé® üíª      Mustafa Poyaüé® üíª      Roshan Jhaüé® üíª              GuillaumeLarueüé® üíª      Tomasz Rodaküé® üíª      Junil Kimüé® üíª      Surbhi Mayanküé® üíª      Nemanja Lekicüé® üíª      HemantMalokarüé® üíª      Felipe M. L√≥pezüé® üíª              bibliofiloüé® üíª      GauthamG2üé® üíª      02_tüé® üíª      Yusuf Abdul-razaqüé® üíª      Vladimirüé® üíª      Sai Chandra Küé® üíª      Soroush Bonabüé® üíª              Giide0nüé® üíª      GGüé® üíª      D√°ger Z√∫√±igaüé® üíª      rsk2üé® üíª      Storozhev DJüé® üíª      Jeevanüé® üíª      Andy Johnsonüé® üíª              An√≠bal Pozoüé® üíª      Jovane de Castroüé® üíª      Muhammad Hamza Amirüé® üíª      tharaka-mtsüé® üíª      Ali KHYARüé® üíª      Caio Araujoüé® üíª      Oscar Dyremyhrüé® üíª              artealityüé® üíª      Daniel Drexlmaierüé® üíª      Marco Montiüé® üíª      mikeycrystalüé® üíª      Veljanovskiiüé® üíª      Ivan Gorbachevüé® üíª      Sahil Rawatüé® üíª              Hasitha Sunethüé® üíª      Yerko Vera Lezamaüé® üíª      Ivan Penchevüé® üíª      Tanver Islam Tonmoyüé® üíª      Xun Caoüé® üíª      Nayan Babariyaüé® üíª      Priyanshu Mauryaüé® üíª              Dylan Tintenfichüé® üíª      Ron Straussüé® üíª      Mohammed AlBannaüé® üíª      Mukund Müé® üíª      Franklin Ohaegbulamüé® üíª      Nisarg Shahüé® üíª      Unik Dahalüé® üíª              Readilyüé® üíª      Alexandre Poitevinüé® üíª      Scaramirüé® üíª      Pruthviüé® üíª      Kalmanqüé® üíª      Alfatah Nesabüé® üíª      arudesaiüé® üíª              Adryenneüé® üíª      El mehdi oudaoudüé® üíª      Jayant Goelüé® üíª      Tsukiüé® üíª      Peter Lemanskiüé® üíª      Annurag-byteüé® üíª      Anthony Vuüé® üíª              Vitaly Nikolaychuküé® üíª      Nathanüé® üíª      Evgenii Petukhovüé® üíª      Loris Guerraüé® üíª      fakhriaunurüé® üíª      Mehdi HYANIüé® üíª      Sarvex Jatasraüé® üíª              santimanuelrüé® üíª      Evgeniy Rezanovüé® üíª      Sonia Müé® üíª      Grzegorz Kmitaüé® üíª      Manuel Caritaüé® üíª      Felipe Cisternas Alvarezüé® üíª      Guo Ciüé® üíª              Marcos Silvaüé® üíª      KKüé® üíª      Shubhanjan Medhiüé® üíª      ArthurFerreiraRodriguesüé® üíª      PabloHermunüé® üíª      disha-baldawaüé® üíª      StaroMoonüé® üíª              Amila T Kumarasekaraüé® üíª      Amoh Princeüé® üíª      AngeloGCüé® üíª      Ebube Glory Ogbondaüé® üíª      Prahalad Belavadiüìñ      Antoni Sarnowski-Trypkaüé® üíª      Alberto Pasqualettoüé® üíª              Amir Babaeiüé® üíª      Syed Abdul Hannanüé® üíª      Srajan Raiüé® üíª      Clarence Mooreüé® üíª      Nguyen Anh Tuanüé® üíª      dar2dar2üé® üíª      Ameer Ibrahimüé® üíª              Tiago Lugattoüé® üíª      raremiroirüé® üíª      Moobieüé® üíª      AlicanDursunüé® üíª      bbalsamüé® üíª      Lubo≈° H√°jeküé® üíª      mrshahzeb7üé® üíª              Wesley Schollüé® üíª      Lawrence Turcotteüé® üíª      Michael DiPaoloüé® üíª      Smart-Codiüé® üíª      Vivek Kumarüé® üíª      Igor Moiseevüé® üíª      B√•rd Pedersenüé® üíª              HOA PHANüé® üíª      GaborModraüé® üíª      vivek-114üé® üíª      Robinüé® üíª      Alexüé® üíª      John Ehrlingerüé® üíª      Roman Zhuravlovüé® üíª              Jordan Mossüé® üíª      RaeShellyüé® üíª      gmollardüé® üíª      Md Kaif Khanüé® üíª      Pablo Romeraüé® üíª      Erik Bustosüé® üíª      trogfieldüé® üíª              simon-aichhornüé® üíª      Tufan G√úLE√áüé® üíª      Uƒüur Berkecan √únl√ºüé® üíª      Revanth Naiküé® üíª      Lia Piresüé® üíª      Igor Mestechkinüé® üíª      Anirudh Karanthüé® üíª              KBobovskiyüé® üíª      zhatiayuaüé® üíª üñã      David Cardonaüé® üíª      Paulo Castilhoüé® üíª      Sebastiano Picchiüé® üíª      pjotarüé® üíª      Rimel CHERIFüíª              Arsal uddinüñã      Dmitry Kasporskyüíª      SoftwareDev1014üé® üíª      @Robvredüé® üíª      Kasun Shanakaüíª      Ahmad M.üé® üíª      Alex Kozinüé® üíª              Mandy Meindersmaüé® üíª      LEGALISE PIRACYüé® üíª      Alex Logvinüé® üíª      Aria Dahlüé® üíª      Mustafa Arifogluüé® üíª      Yevhen Leshchenkoüé® üíª      Anubhav Adhikariüé® üíª              Noah Tatkoüé® üíª      Mohit Gadhaviüé® üíª      Pedro Bas√≠lioüé® üíª      RealSanjeevüé® üíª      Akash Hazraüé® üíª      Christoph Dahlenüé® üíª      Vincent du Plessisüé® üíª              Karen Tamrazyanüé® üíª      Mirza Younus Baigüé® üíª      Ashish Kumarüé® üíª      Unknown6334üé® üíª      flowazüé® üíª      zi-aikraüé® üíª      PAYAL PMüé® üíª              Lennart L√∂scheüé® üíª      Yummy-Yumsüé® üíª      Njuacha Hubert Mikulowskiüé® üíª      Hussein Esmailüé® üíª      Bilgehan Bezirüé® üíª      Muhammed Shittuüé® üíª      Cl√©ment FERNANDESüé® üíª              JaCKoP619üé® üíª      userutf8üé® üíª      Mohamed Ubaidüé® üíª      Justin Yatesüé® üíª      mohammad aliüé® üíª      Madhav Singhüé® üíª      RgbMouse69üé® üíª              Nicholas Leasküé® üíª      parthav0üé® üíª      Sigmaüé® üíª      Evelina Bechevaüé® üíª      Akshit Gulyanüé® üíª      Arpita Janaüé® üíª      Praveen Kumarüé® üíª              Mohammad Samiüé® üíª      eddiestefanescuüé® üíª      Ramesh Yadavüé® üíª      Sarthak Joshiüé® üíª      Nikhil12300üé® üíª      Yevgenüé® üíª      Leoüé® üíª              laurent büé® üíª      Mettchenüé® üíª      Ali Mahdaviüé® üíª      Lucas Dondoüé® üíª      Siddhesh Agarwalüé® üíª      slimerPuncherüé® üíª      saritashhüé® üíª              Iulian-Valeriu CioatƒÉüé® üíª      Szabolcs Nagyüé® üíª      Jarle Kvileüé® üíª      ÂäâËÄÄÂçá Vic Liuüé® üíª      Suryanshüé® üíª      Matthew Oosthuyseüé® üíª      Florin Zamfirüé® üíª              Meleküé® üíª      moesocioüé® üíª      Alan Jamesüé® üíª      Mai Thanh Ph∆∞∆°ngüé® üíª      Neville Dabreüé® üíª      Maksymüé® üíª      tamanna900üé® üíª              Adithya Awatiüé® üíª      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
55,matterport/Mask_RCNN,https://github.com/matterport/Mask_RCNN/blob/master/README.md,Python,"Mask R-CNN for Object Detection and SegmentationThis is an implementation of Mask R-CNN on Python 3, Keras, and TensorFlow. The model generates bounding boxes and segmentation masks for each instance of an object in the image. It's based on Feature Pyramid Network (FPN) and a ResNet101 backbone.The repository includes:Source code of Mask R-CNN built on FPN and ResNet101.Training code for MS COCOPre-trained weights for MS COCOJupyter notebooks to visualize the detection pipeline at every stepParallelModel class for multi-GPU trainingEvaluation on MS COCO metrics (AP)Example of training on your own datasetThe code is documented and designed to be easy to extend. If you use it in your research, please consider citing this repository (bibtex below). If you work on 3D vision, you might find our recently released Matterport3D dataset useful as well.This dataset was created from 3D-reconstructed spaces captured by our customers who agreed to make them publicly available for academic use. You can see more examples here.Getting Starteddemo.ipynb Is the easiest way to start. It shows an example of using a model pre-trained on MS COCO to segment objects in your own images.It includes code to run object detection and instance segmentation on arbitrary images.train_shapes.ipynb shows how to train Mask R-CNN on your own dataset. This notebook introduces a toy dataset (Shapes) to demonstrate training on a new dataset.(model.py, utils.py, config.py): These files contain the main Mask RCNN implementation.inspect_data.ipynb. This notebook visualizes the different pre-processing stepsto prepare the training data.inspect_model.ipynb This notebook goes in depth into the steps performed to detect and segment objects. It provides visualizations of every step of the pipeline.inspect_weights.ipynbThis notebooks inspects the weights of a trained model and looks for anomalies and odd patterns.Step by Step DetectionTo help with debugging and understanding the model, there are 3 notebooks(inspect_data.ipynb, inspect_model.ipynb,inspect_weights.ipynb) that provide a lot of visualizations and allow running the model step by step to inspect the output at each point. Here are a few examples:1. Anchor sorting and filteringVisualizes every step of the first stage Region Proposal Network and displays positive and negative anchors along with anchor box refinement.2. Bounding Box RefinementThis is an example of final detection boxes (dotted lines) and the refinement applied to them (solid lines) in the second stage.3. Mask GenerationExamples of generated masks. These then get scaled and placed on the image in the right location.4.Layer activationsOften it's useful to inspect the activations at different layers to look for signs of trouble (all zeros or random noise).5. Weight HistogramsAnother useful debugging tool is to inspect the weight histograms. These are included in the inspect_weights.ipynb notebook.6. Logging to TensorBoardTensorBoard is another great debugging and visualization tool. The model is configured to log losses and save weights at the end of every epoch.6. Composing the different pieces into a final resultTraining on MS COCOWe're providing pre-trained weights for MS COCO to make it easier to start. You canuse those weights as a starting point to train your own variation on the network.Training and evaluation code is in samples/coco/coco.py. You can import thismodule in Jupyter notebook (see the provided notebooks for examples) or youcan run it directly from the command line as such:# Train a new model starting from pre-trained COCO weightspython3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=coco# Train a new model starting from ImageNet weightspython3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=imagenet# Continue training a model that you had trained earlierpython3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=/path/to/weights.h5# Continue training the last model you trained. This will find# the last trained weights in the model directory.python3 samples/coco/coco.py train --dataset=/path/to/coco/ --model=lastYou can also run the COCO evaluation code with:# Run COCO evaluation on the last trained modelpython3 samples/coco/coco.py evaluate --dataset=/path/to/coco/ --model=lastThe training schedule, learning rate, and other parameters should be set in samples/coco/coco.py.Training on Your Own DatasetStart by reading this blog post about the balloon color splash sample. It covers the process starting from annotating images to training to using the results in a sample application.In summary, to train the model on your own dataset you'll need to extend two classes:ConfigThis class contains the default configuration. Subclass it and modify the attributes you need to change.DatasetThis class provides a consistent way to work with any dataset.It allows you to use new datasets for training without having to changethe code of the model. It also supports loading multiple datasets at thesame time, which is useful if the objects you want to detect are notall available in one dataset.See examples in samples/shapes/train_shapes.ipynb, samples/coco/coco.py, samples/balloon/balloon.py, and samples/nucleus/nucleus.py.Differences from the Official PaperThis implementation follows the Mask RCNN paper for the most part, but there are a few cases where we deviated in favor of code simplicity and generalization. These are some of the differences we're aware of. If you encounter other differences, please do let us know.Image Resizing: To support training multiple images per batch we resize all images to the same size. For example, 1024x1024px on MS COCO. We preserve the aspect ratio, so if an image is not square we pad it with zeros. In the paper the resizing is done such that the smallest side is 800px and the largest is trimmed at 1000px.Bounding Boxes: Some datasets provide bounding boxes and some provide masks only. To support training on multiple datasets we opted to ignore the bounding boxes that come with the dataset and generate them on the fly instead. We pick the smallest box that encapsulates all the pixels of the mask as the bounding box. This simplifies the implementation and also makes it easy to apply image augmentations that would otherwise be harder to apply to bounding boxes, such as image rotation.To validate this approach, we compared our computed bounding boxes to those provided by the COCO dataset.We found that ~2% of bounding boxes differed by 1px or more, ~0.05% differed by 5px or more,and only 0.01% differed by 10px or more.Learning Rate: The paper uses a learning rate of 0.02, but we found that to betoo high, and often causes the weights to explode, especially when using a small batchsize. It might be related to differences between how Caffe and TensorFlow computegradients (sum vs mean across batches and GPUs). Or, maybe the official model uses gradientclipping to avoid this issue. We do use gradient clipping, but don't set it too aggressively.We found that smaller learning rates converge faster anyway so we go with that.CitationUse this bibtex to cite this repository:@misc{matterport_maskrcnn_2017,  title={Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow},  author={Waleed Abdulla},  year={2017},  publisher={Github},  journal={GitHub repository},  howpublished={\\url{https://github.com/matterport/Mask_RCNN}},}ContributingContributions to this repository are welcome. Examples of things you can contribute:Speed Improvements. Like re-writing some Python code in TensorFlow or Cython.Training on other datasets.Accuracy Improvements.Visualizations and examples.You can also join our team and help us build even more projects like this one.RequirementsPython 3.4, TensorFlow 1.3, Keras 2.0.8 and other common packages listed in requirements.txt.MS COCO Requirements:To train or test on MS COCO, you'll also need:pycocotools (installation instructions below)MS COCO DatasetDownload the 5K minivaland the 35K validation-minus-minivalsubsets. More details in the original Faster R-CNN implementation.If you use Docker, the code has been verified to work onthis Docker container.InstallationClone this repositoryInstall dependenciespip3 install -r requirements.txtRun setup from the repository root directorypython3 setup.py installDownload pre-trained COCO weights (mask_rcnn_coco.h5) from the releases page.(Optional) To train or test on MS COCO install pycocotools from one of these repos. They are forks of the original pycocotools with fixes for Python3 and Windows (the official repo doesn't seem to be active anymore).Linux: https://github.com/waleedka/cocoWindows: https://github.com/philferriere/cocoapi.You must have the Visual C++ 2015 build tools on your path (see the repo for additional details)Projects Using this ModelIf you extend this model to other datasets or build projects that use it, we'd love to hear from you.4K Video Demo by Karol Majek.Images to OSM: Improve OpenStreetMap by adding baseball, soccer, tennis, football, and basketball fields.Splash of Color. A blog post explaining how to train this model from scratch and use it to implement a color splash effect.Segmenting Nuclei in Microscopy Images. Built for the 2018 Data Science BowlCode is in the samples/nucleus directory.Detection and Segmentation for Surgery Robots by the NUS Control & Mechatronics Lab.Reconstructing 3D buildings from aerial LiDARA proof of concept project by Esri, in collaboration with Nvidia and Miami-Dade County. Along with a great write up and code by Dmitry Kudinov, Daniel Hedges, and Omar Maher.Usiigaci: Label-free Cell Tracking in Phase Contrast MicroscopyA project from Japan to automatically track cells in a microfluidics platform. Paper is pending, but the source code is released. Characterization of Arctic Ice-Wedge Polygons in Very High Spatial Resolution Aerial ImageryResearch project to understand the complex processes between degradations in the Arctic and climate change. By Weixing Zhang, Chandi Witharana, Anna Liljedahl, and Mikhail Kanevskiy.Mask-RCNN ShinyA computer vision class project by HU Shiyu to apply the color pop effect on people with beautiful results.Mapping Challenge: Convert satellite imagery to maps for use by humanitarian organisations.GRASS GIS Addon to generate vector masks from geospatial imagery. Based on a Master's thesis by Ond≈ôej Pe≈°ek."
56,hankcs/HanLP,https://github.com/hankcs/HanLP/blob/doc-zh/README.md,Python,"HanLP: Han Language Processing                                                                                   English |    Êó•Êú¨Ë™û |    ÊñáÊ°£ |    ËÆ∫Êñá |    ËÆ∫Âùõ |    docker |    ‚ñ∂Ô∏èÂú®Á∫øËøêË°åÈù¢ÂêëÁîü‰∫ßÁéØÂ¢ÉÁöÑÂ§öËØ≠ÁßçËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•ÂÖ∑ÂåÖÔºåÂü∫‰∫éPyTorchÂíåTensorFlow 2.xÂèåÂºïÊìéÔºåÁõÆÊ†áÊòØÊôÆÂèäËêΩÂú∞ÊúÄÂâçÊ≤øÁöÑNLPÊäÄÊúØ„ÄÇHanLPÂÖ∑Â§áÂäüËÉΩÂÆåÂñÑ„ÄÅÁ≤æÂ∫¶ÂáÜÁ°Æ„ÄÅÊÄßËÉΩÈ´òÊïà„ÄÅËØ≠ÊñôÊó∂Êñ∞„ÄÅÊû∂ÊûÑÊ∏ÖÊô∞„ÄÅÂèØËá™ÂÆö‰πâÁöÑÁâπÁÇπ„ÄÇÂÄüÂä©‰∏ñÁïå‰∏äÊúÄÂ§ßÁöÑÂ§öËØ≠ÁßçËØ≠ÊñôÂ∫ìÔºåHanLP2.1ÊîØÊåÅÂåÖÊã¨ÁÆÄÁπÅ‰∏≠Ëã±Êó•‰øÑÊ≥ïÂæ∑Âú®ÂÜÖÁöÑ130ÁßçËØ≠Ë®Ä‰∏äÁöÑ10ÁßçËÅîÂêà‰ªªÂä°‰ª•ÂèäÂ§öÁßçÂçï‰ªªÂä°„ÄÇHanLPÈ¢ÑËÆ≠ÁªÉ‰∫ÜÂçÅÂá†Áßç‰ªªÂä°‰∏äÁöÑÊï∞ÂçÅ‰∏™Ê®°ÂûãÂπ∂‰∏îÊ≠£Âú®ÊåÅÁª≠Ëø≠‰ª£ËØ≠ÊñôÂ∫ì‰∏éÊ®°ÂûãÔºöÂäüËÉΩRESTfulÂ§ö‰ªªÂä°Âçï‰ªªÂä°Ê®°ÂûãÊ†áÊ≥®Ê†áÂáÜÂàÜËØçÊïôÁ®ãÊïôÁ®ãÊïôÁ®ãtokÁ≤óÂàÜ„ÄÅÁªÜÂàÜËØçÊÄßÊ†áÊ≥®ÊïôÁ®ãÊïôÁ®ãÊïôÁ®ãposCTB„ÄÅPKU„ÄÅ863ÂëΩÂêçÂÆû‰ΩìËØÜÂà´ÊïôÁ®ãÊïôÁ®ãÊïôÁ®ãnerPKU„ÄÅMSRA„ÄÅOntoNotes‰æùÂ≠òÂè•Ê≥ïÂàÜÊûêÊïôÁ®ãÊïôÁ®ãÊïôÁ®ãdepSD„ÄÅUD„ÄÅPMTÊàêÂàÜÂè•Ê≥ïÂàÜÊûêÊïôÁ®ãÊïôÁ®ãÊïôÁ®ãconChinese Tree BankËØ≠‰πâ‰æùÂ≠òÂàÜÊûêÊïôÁ®ãÊïôÁ®ãÊïôÁ®ãsdpCSDPËØ≠‰πâËßíËâ≤Ê†áÊ≥®ÊïôÁ®ãÊïôÁ®ãÊïôÁ®ãsrlChinese Proposition BankÊäΩË±°ÊÑè‰πâË°®Á§∫ÊïôÁ®ãÊöÇÊó†ÊïôÁ®ãamrCAMRÊåá‰ª£Ê∂àËß£ÊïôÁ®ãÊöÇÊó†ÊöÇÊó†ÊöÇÊó†OntoNotesËØ≠‰πâÊñáÊú¨Áõ∏‰ººÂ∫¶ÊïôÁ®ãÊöÇÊó†ÊïôÁ®ãstsÊöÇÊó†ÊñáÊú¨È£éÊ†ºËΩ¨Êç¢ÊïôÁ®ãÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÂÖ≥ÈîÆËØçÁü≠ËØ≠ÊèêÂèñÊïôÁ®ãÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÊäΩÂèñÂºèËá™Âä®ÊëòË¶ÅÊïôÁ®ãÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÁîüÊàêÂºèËá™Âä®ÊëòË¶ÅÊïôÁ®ãÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÊñáÊú¨ËØ≠Ê≥ïÁ∫†ÈîôÊïôÁ®ãÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÊñáÊú¨ÂàÜÁ±ªÊïôÁ®ãÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÊöÇÊó†ÊÉÖÊÑüÂàÜÊûêÊïôÁ®ãÊöÇÊó†ÊöÇÊó†ÊöÇÊó†[-1,+1]ËØ≠ÁßçÊ£ÄÊµãÊïôÁ®ãÊöÇÊó†ÊïôÁ®ãÊöÇÊó†ISO 639-1ÁºñÁ†ÅËØçÂπ≤ÊèêÂèñ„ÄÅËØçÊ≥ïËØ≠Ê≥ïÁâπÂæÅÊèêÂèñËØ∑ÂèÇËÄÉËã±ÊñáÊïôÁ®ãÔºõËØçÂêëÈáèÂíåÂÆåÂΩ¢Â°´Á©∫ËØ∑ÂèÇËÄÉÁõ∏Â∫îÊñáÊ°£„ÄÇÁÆÄÁπÅËΩ¨Êç¢„ÄÅÊãºÈü≥„ÄÅÊñ∞ËØçÂèëÁé∞„ÄÅÊñáÊú¨ËÅöÁ±ªËØ∑ÂèÇËÄÉ1.xÊïôÁ®ã„ÄÇÈáè‰ΩìË£ÅË°£ÔºåHanLPÊèê‰æõRESTfulÂíånative‰∏§ÁßçAPIÔºåÂàÜÂà´Èù¢ÂêëËΩªÈáèÁ∫ßÂíåÊµ∑ÈáèÁ∫ß‰∏§ÁßçÂú∫ÊôØ„ÄÇÊó†ËÆ∫‰ΩïÁßçAPI‰ΩïÁßçËØ≠Ë®ÄÔºåHanLPÊé•Âè£Âú®ËØ≠‰πâ‰∏ä‰øùÊåÅ‰∏ÄËá¥ÔºåÂú®‰ª£Á†Å‰∏äÂùöÊåÅÂºÄÊ∫ê„ÄÇÂ¶ÇÊûúÊÇ®Âú®Á†îÁ©∂‰∏≠‰ΩøÁî®‰∫ÜHanLPÔºåËØ∑ÂºïÁî®Êàë‰ª¨ÁöÑEMNLPËÆ∫Êñá„ÄÇËΩªÈáèÁ∫ßRESTful API‰ªÖÊï∞KBÔºåÈÄÇÂêàÊïèÊç∑ÂºÄÂèë„ÄÅÁßªÂä®APPÁ≠âÂú∫ÊôØ„ÄÇÁÆÄÂçïÊòìÁî®ÔºåÊó†ÈúÄGPUÈÖçÁéØÂ¢ÉÔºåÁßíÈÄüÂÆâË£Ö„ÄÇËØ≠ÊñôÊõ¥Â§ö„ÄÅÊ®°ÂûãÊõ¥Â§ß„ÄÅÁ≤æÂ∫¶Êõ¥È´òÔºåÂº∫ÁÉàÊé®Ëçê„ÄÇÊúçÂä°Âô®GPUÁÆóÂäõÊúâÈôêÔºåÂåøÂêçÁî®Êà∑ÈÖçÈ¢ùËæÉÂ∞ëÔºåÂª∫ËÆÆÁî≥ËØ∑ÂÖçË¥πÂÖ¨ÁõäAPIÁßòÈí•auth„ÄÇPythonpip install hanlp_restfulÂàõÂª∫ÂÆ¢Êà∑Á´ØÔºåÂ°´ÂÖ•ÊúçÂä°Âô®Âú∞ÂùÄÂíåÁßòÈí•Ôºöfrom hanlp_restful import HanLPClientHanLP = HanLPClient('https://www.hanlp.com/api', auth=None, language='zh') # auth‰∏çÂ°´ÂàôÂåøÂêçÔºåzh‰∏≠ÊñáÔºåmulÂ§öËØ≠ÁßçGolangÂÆâË£Ö go get -u github.com/hankcs/gohanlp@main ÔºåÂàõÂª∫ÂÆ¢Êà∑Á´ØÔºåÂ°´ÂÖ•ÊúçÂä°Âô®Âú∞ÂùÄÂíåÁßòÈí•ÔºöHanLP := hanlp.HanLPClient(hanlp.WithAuth(\""\""),hanlp.WithLanguage(\""zh\"")) // auth‰∏çÂ°´ÂàôÂåøÂêçÔºåzh‰∏≠ÊñáÔºåmulÂ§öËØ≠ÁßçJavaÂú®pom.xml‰∏≠Ê∑ªÂä†‰æùËµñÔºö<dependency>    <groupId>com.hankcs.hanlp.restful</groupId>    <artifactId>hanlp-restful</artifactId>    <version>0.0.12</version></dependency>ÂàõÂª∫ÂÆ¢Êà∑Á´ØÔºåÂ°´ÂÖ•ÊúçÂä°Âô®Âú∞ÂùÄÂíåÁßòÈí•ÔºöHanLPClient HanLP = new HanLPClient(\""https://www.hanlp.com/api\"", null, \""zh\""); // auth‰∏çÂ°´ÂàôÂåøÂêçÔºåzh‰∏≠ÊñáÔºåmulÂ§öËØ≠ÁßçÂø´ÈÄü‰∏äÊâãÊó†ËÆ∫‰ΩïÁßçÂºÄÂèëËØ≠Ë®ÄÔºåË∞ÉÁî®parseÊé•Âè£Ôºå‰º†ÂÖ•‰∏ÄÁØáÊñáÁ´†ÔºåÂæóÂà∞HanLPÁ≤æÂáÜÁöÑÂàÜÊûêÁªìÊûú„ÄÇHanLP.parse(\""2021Âπ¥HanLPv2.1‰∏∫Áîü‰∫ßÁéØÂ¢ÉÂ∏¶Êù•Ê¨°‰∏ñ‰ª£ÊúÄÂÖàËøõÁöÑÂ§öËØ≠ÁßçNLPÊäÄÊúØ„ÄÇÈòøÂ©Ü‰∏ªÊù•Âà∞Âåó‰∫¨Á´ãÊñπÂ∫≠ÂèÇËßÇËá™ÁÑ∂ËØ≠‰πâÁßëÊäÄÂÖ¨Âè∏„ÄÇ\"")Êõ¥Â§öÂäüËÉΩÂåÖÊã¨ËØ≠‰πâÁõ∏‰ººÂ∫¶„ÄÅÈ£éÊ†ºËΩ¨Êç¢„ÄÅÊåá‰ª£Ê∂àËß£Á≠âÔºåËØ∑ÂèÇËÄÉÊñáÊ°£ÂíåÊµãËØïÁî®‰æã„ÄÇÊµ∑ÈáèÁ∫ßnative API‰æùËµñPyTorch„ÄÅTensorFlowÁ≠âÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÔºåÈÄÇÂêà‰∏ì‰∏öNLPÂ∑•Á®ãÂ∏à„ÄÅÁ†îÁ©∂ËÄÖ‰ª•ÂèäÊú¨Âú∞Êµ∑ÈáèÊï∞ÊçÆÂú∫ÊôØ„ÄÇË¶ÅÊ±ÇPython 3.6Ëá≥3.10ÔºåÊîØÊåÅWindowsÔºåÊé®Ëçê*nix„ÄÇÂèØ‰ª•Âú®CPU‰∏äËøêË°åÔºåÊé®ËçêGPU/TPU„ÄÇÂÆâË£ÖPyTorchÁâàÔºöpip install hanlpHanLPÊØèÊ¨°ÂèëÂ∏ÉÈÉΩÈÄöËøá‰∫ÜLinux„ÄÅmacOSÂíåWindows‰∏äPython3.6Ëá≥3.10ÁöÑÂçïÂÖÉÊµãËØïÔºå‰∏çÂ≠òÂú®ÂÆâË£ÖÈóÆÈ¢ò„ÄÇHanLPÂèëÂ∏ÉÁöÑÊ®°ÂûãÂàÜ‰∏∫Â§ö‰ªªÂä°ÂíåÂçï‰ªªÂä°‰∏§ÁßçÔºåÂ§ö‰ªªÂä°ÈÄüÂ∫¶Âø´ÁúÅÊòæÂ≠òÔºåÂçï‰ªªÂä°Á≤æÂ∫¶È´òÊõ¥ÁÅµÊ¥ª„ÄÇÂ§ö‰ªªÂä°Ê®°ÂûãHanLPÁöÑÂ∑•‰ΩúÊµÅÁ®ã‰∏∫Âä†ËΩΩÊ®°ÂûãÁÑ∂ÂêéÂ∞ÜÂÖ∂ÂΩì‰ΩúÂáΩÊï∞Ë∞ÉÁî®Ôºå‰æãÂ¶Ç‰∏ãÂàóËÅîÂêàÂ§ö‰ªªÂä°Ê®°ÂûãÔºöimport hanlpHanLP = hanlp.load(hanlp.pretrained.mtl.CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH) # ‰∏ñÁïåÊúÄÂ§ß‰∏≠ÊñáËØ≠ÊñôÂ∫ìHanLP(['2021Âπ¥HanLPv2.1‰∏∫Áîü‰∫ßÁéØÂ¢ÉÂ∏¶Êù•Ê¨°‰∏ñ‰ª£ÊúÄÂÖàËøõÁöÑÂ§öËØ≠ÁßçNLPÊäÄÊúØ„ÄÇ', 'ÈòøÂ©Ü‰∏ªÊù•Âà∞Âåó‰∫¨Á´ãÊñπÂ∫≠ÂèÇËßÇËá™ÁÑ∂ËØ≠‰πâÁßëÊäÄÂÖ¨Âè∏„ÄÇ'])Native APIÁöÑËæìÂÖ•Âçï‰Ωç‰∏∫Âè•Â≠êÔºåÈúÄ‰ΩøÁî®Â§öËØ≠ÁßçÂàÜÂè•Ê®°ÂûãÊàñÂü∫‰∫éËßÑÂàôÁöÑÂàÜÂè•ÂáΩÊï∞ÂÖàË°åÂàÜÂè•„ÄÇRESTfulÂíånative‰∏§ÁßçAPIÁöÑËØ≠‰πâËÆæËÆ°ÂÆåÂÖ®‰∏ÄËá¥ÔºåÁî®Êà∑ÂèØ‰ª•Êó†Áºù‰∫íÊç¢„ÄÇÁÆÄÊ¥ÅÁöÑÊé•Âè£‰πüÊîØÊåÅÁÅµÊ¥ªÁöÑÂèÇÊï∞ÔºåÂ∏∏Áî®ÁöÑÊäÄÂ∑ßÊúâÔºöÁÅµÊ¥ªÁöÑtasks‰ªªÂä°Ë∞ÉÂ∫¶Ôºå‰ªªÂä°Ë∂äÂ∞ëÔºåÈÄüÂ∫¶Ë∂äÂø´ÔºåËØ¶ËßÅÊïôÁ®ã„ÄÇÂú®ÂÜÖÂ≠òÊúâÈôêÁöÑÂú∫ÊôØ‰∏ãÔºåÁî®Êà∑ËøòÂèØ‰ª•Âà†Èô§‰∏çÈúÄË¶ÅÁöÑ‰ªªÂä°ËææÂà∞Ê®°ÂûãÁò¶Ë∫´ÁöÑÊïàÊûú„ÄÇÈ´òÊïàÁöÑtrieÊ†ëËá™ÂÆö‰πâËØçÂÖ∏Ôºå‰ª•ÂèäÂº∫Âà∂„ÄÅÂêàÂπ∂„ÄÅÊ†°Ê≠£3ÁßçËßÑÂàôÔºåËØ∑ÂèÇËÄÉdemoÂíåÊñáÊ°£„ÄÇËßÑÂàôÁ≥ªÁªüÁöÑÊïàÊûúÂ∞ÜÊó†ÁºùÂ∫îÁî®Âà∞ÂêéÁª≠ÁªüËÆ°Ê®°ÂûãÔºå‰ªéËÄåÂø´ÈÄüÈÄÇÂ∫îÊñ∞È¢ÜÂüü„ÄÇÂçï‰ªªÂä°Ê®°ÂûãÊ†πÊçÆÊàë‰ª¨ÁöÑÊúÄÊñ∞Á†îÁ©∂ÔºåÂ§ö‰ªªÂä°Â≠¶‰π†ÁöÑ‰ºòÂäøÂú®‰∫éÈÄüÂ∫¶ÂíåÊòæÂ≠òÔºåÁÑ∂ËÄåÁ≤æÂ∫¶ÂæÄÂæÄ‰∏çÂ¶ÇÂçï‰ªªÂä°Ê®°Âûã„ÄÇÊâÄ‰ª•ÔºåHanLPÈ¢ÑËÆ≠ÁªÉ‰∫ÜËÆ∏Â§öÂçï‰ªªÂä°Ê®°ÂûãÂπ∂ËÆæËÆ°‰∫Ü‰ºòÈõÖÁöÑÊµÅÊ∞¥Á∫øÊ®°ÂºèÂ∞ÜÂÖ∂ÁªÑË£ÖËµ∑Êù•„ÄÇimport hanlpHanLP = hanlp.pipeline() \\    .append(hanlp.utils.rules.split_sentence, output_key='sentences') \\    .append(hanlp.load('FINE_ELECTRA_SMALL_ZH'), output_key='tok') \\    .append(hanlp.load('CTB9_POS_ELECTRA_SMALL'), output_key='pos') \\    .append(hanlp.load('MSRA_NER_ELECTRA_SMALL_ZH'), output_key='ner', input_key='tok') \\    .append(hanlp.load('CTB9_DEP_ELECTRA_SMALL', conll=0), output_key='dep', input_key='tok')\\    .append(hanlp.load('CTB9_CON_ELECTRA_SMALL'), output_key='con', input_key='tok')HanLP('2021Âπ¥HanLPv2.1‰∏∫Áîü‰∫ßÁéØÂ¢ÉÂ∏¶Êù•Ê¨°‰∏ñ‰ª£ÊúÄÂÖàËøõÁöÑÂ§öËØ≠ÁßçNLPÊäÄÊúØ„ÄÇÈòøÂ©Ü‰∏ªÊù•Âà∞Âåó‰∫¨Á´ãÊñπÂ∫≠ÂèÇËßÇËá™ÁÑ∂ËØ≠‰πâÁßëÊäÄÂÖ¨Âè∏„ÄÇ')Êõ¥Â§öÂäüËÉΩÔºåËØ∑ÂèÇËÄÉdemoÂíåÊñáÊ°£‰∫ÜËß£Êõ¥Â§öÊ®°Âûã‰∏éÁî®Ê≥ï„ÄÇËæìÂá∫Ê†ºÂºèÊó†ËÆ∫‰ΩïÁßçAPI‰ΩïÁßçÂºÄÂèëËØ≠Ë®Ä‰ΩïÁßçËá™ÁÑ∂ËØ≠Ë®ÄÔºåHanLPÁöÑËæìÂá∫Áªü‰∏Ä‰∏∫jsonÊ†ºÂºèÂÖºÂÆπdictÁöÑDocument:{  \""tok/fine\"": [    [\""2021Âπ¥\"", \""HanLPv2.1\"", \""‰∏∫\"", \""Áîü‰∫ß\"", \""ÁéØÂ¢É\"", \""Â∏¶Êù•\"", \""Ê¨°\"", \""‰∏ñ‰ª£\"", \""ÊúÄ\"", \""ÂÖàËøõ\"", \""ÁöÑ\"", \""Â§ö\"", \""ËØ≠Áßç\"", \""NLP\"", \""ÊäÄÊúØ\"", \""„ÄÇ\""],    [\""ÈòøÂ©Ü‰∏ª\"", \""Êù•Âà∞\"", \""Âåó‰∫¨\"", \""Á´ãÊñπÂ∫≠\"", \""ÂèÇËßÇ\"", \""Ëá™ÁÑ∂\"", \""ËØ≠‰πâ\"", \""ÁßëÊäÄ\"", \""ÂÖ¨Âè∏\"", \""„ÄÇ\""]  ],  \""tok/coarse\"": [    [\""2021Âπ¥\"", \""HanLPv2.1\"", \""‰∏∫\"", \""Áîü‰∫ß\"", \""ÁéØÂ¢É\"", \""Â∏¶Êù•\"", \""Ê¨°‰∏ñ‰ª£\"", \""ÊúÄ\"", \""ÂÖàËøõ\"", \""ÁöÑ\"", \""Â§öËØ≠Áßç\"", \""NLP\"", \""ÊäÄÊúØ\"", \""„ÄÇ\""],    [\""ÈòøÂ©Ü‰∏ª\"", \""Êù•Âà∞\"", \""Âåó‰∫¨Á´ãÊñπÂ∫≠\"", \""ÂèÇËßÇ\"", \""Ëá™ÁÑ∂ËØ≠‰πâÁßëÊäÄÂÖ¨Âè∏\"", \""„ÄÇ\""]  ],  \""pos/ctb\"": [    [\""NT\"", \""NR\"", \""P\"", \""NN\"", \""NN\"", \""VV\"", \""JJ\"", \""NN\"", \""AD\"", \""JJ\"", \""DEG\"", \""CD\"", \""NN\"", \""NR\"", \""NN\"", \""PU\""],    [\""NN\"", \""VV\"", \""NR\"", \""NR\"", \""VV\"", \""NN\"", \""NN\"", \""NN\"", \""NN\"", \""PU\""]  ],  \""pos/pku\"": [    [\""t\"", \""nx\"", \""p\"", \""vn\"", \""n\"", \""v\"", \""b\"", \""n\"", \""d\"", \""a\"", \""u\"", \""a\"", \""n\"", \""nx\"", \""n\"", \""w\""],    [\""n\"", \""v\"", \""ns\"", \""ns\"", \""v\"", \""n\"", \""n\"", \""n\"", \""n\"", \""w\""]  ],  \""pos/863\"": [    [\""nt\"", \""w\"", \""p\"", \""v\"", \""n\"", \""v\"", \""a\"", \""nt\"", \""d\"", \""a\"", \""u\"", \""a\"", \""n\"", \""ws\"", \""n\"", \""w\""],    [\""n\"", \""v\"", \""ns\"", \""n\"", \""v\"", \""n\"", \""n\"", \""n\"", \""n\"", \""w\""]  ],  \""ner/pku\"": [    [],    [[\""Âåó‰∫¨Á´ãÊñπÂ∫≠\"", \""ns\"", 2, 4], [\""Ëá™ÁÑ∂ËØ≠‰πâÁßëÊäÄÂÖ¨Âè∏\"", \""nt\"", 5, 9]]  ],  \""ner/msra\"": [    [[\""2021Âπ¥\"", \""DATE\"", 0, 1], [\""HanLPv2.1\"", \""ORGANIZATION\"", 1, 2]],    [[\""Âåó‰∫¨\"", \""LOCATION\"", 2, 3], [\""Á´ãÊñπÂ∫≠\"", \""LOCATION\"", 3, 4], [\""Ëá™ÁÑ∂ËØ≠‰πâÁßëÊäÄÂÖ¨Âè∏\"", \""ORGANIZATION\"", 5, 9]]  ],  \""ner/ontonotes\"": [    [[\""2021Âπ¥\"", \""DATE\"", 0, 1], [\""HanLPv2.1\"", \""ORG\"", 1, 2]],    [[\""Âåó‰∫¨Á´ãÊñπÂ∫≠\"", \""FAC\"", 2, 4], [\""Ëá™ÁÑ∂ËØ≠‰πâÁßëÊäÄÂÖ¨Âè∏\"", \""ORG\"", 5, 9]]  ],  \""srl\"": [    [[[\""2021Âπ¥\"", \""ARGM-TMP\"", 0, 1], [\""HanLPv2.1\"", \""ARG0\"", 1, 2], [\""‰∏∫Áîü‰∫ßÁéØÂ¢É\"", \""ARG2\"", 2, 5], [\""Â∏¶Êù•\"", \""PRED\"", 5, 6], [\""Ê¨°‰∏ñ‰ª£ÊúÄÂÖàËøõÁöÑÂ§öËØ≠ÁßçNLPÊäÄÊúØ\"", \""ARG1\"", 6, 15]], [[\""ÊúÄ\"", \""ARGM-ADV\"", 8, 9], [\""ÂÖàËøõ\"", \""PRED\"", 9, 10], [\""ÊäÄÊúØ\"", \""ARG0\"", 14, 15]]],    [[[\""ÈòøÂ©Ü‰∏ª\"", \""ARG0\"", 0, 1], [\""Êù•Âà∞\"", \""PRED\"", 1, 2], [\""Âåó‰∫¨Á´ãÊñπÂ∫≠\"", \""ARG1\"", 2, 4]], [[\""ÈòøÂ©Ü‰∏ª\"", \""ARG0\"", 0, 1], [\""ÂèÇËßÇ\"", \""PRED\"", 4, 5], [\""Ëá™ÁÑ∂ËØ≠‰πâÁßëÊäÄÂÖ¨Âè∏\"", \""ARG1\"", 5, 9]]]  ],  \""dep\"": [    [[6, \""tmod\""], [6, \""nsubj\""], [6, \""prep\""], [5, \""nn\""], [3, \""pobj\""], [0, \""root\""], [8, \""amod\""], [15, \""nn\""], [10, \""advmod\""], [15, \""rcmod\""], [10, \""assm\""], [13, \""nummod\""], [15, \""nn\""], [15, \""nn\""], [6, \""dobj\""], [6, \""punct\""]],    [[2, \""nsubj\""], [0, \""root\""], [4, \""nn\""], [2, \""dobj\""], [2, \""conj\""], [9, \""nn\""], [9, \""nn\""], [9, \""nn\""], [5, \""dobj\""], [2, \""punct\""]]  ],  \""sdp\"": [    [[[6, \""Time\""]], [[6, \""Exp\""]], [[5, \""mPrep\""]], [[5, \""Desc\""]], [[6, \""Datv\""]], [[13, \""dDesc\""]], [[0, \""Root\""], [8, \""Desc\""], [13, \""Desc\""]], [[15, \""Time\""]], [[10, \""mDegr\""]], [[15, \""Desc\""]], [[10, \""mAux\""]], [[8, \""Quan\""], [13, \""Quan\""]], [[15, \""Desc\""]], [[15, \""Nmod\""]], [[6, \""Pat\""]], [[6, \""mPunc\""]]],    [[[2, \""Agt\""], [5, \""Agt\""]], [[0, \""Root\""]], [[4, \""Loc\""]], [[2, \""Lfin\""]], [[2, \""ePurp\""]], [[8, \""Nmod\""]], [[9, \""Nmod\""]], [[9, \""Nmod\""]], [[5, \""Datv\""]], [[5, \""mPunc\""]]]  ],  \""con\"": [    [\""TOP\"", [[\""IP\"", [[\""NP\"", [[\""NT\"", [\""2021Âπ¥\""]]]], [\""NP\"", [[\""NR\"", [\""HanLPv2.1\""]]]], [\""VP\"", [[\""PP\"", [[\""P\"", [\""‰∏∫\""]], [\""NP\"", [[\""NN\"", [\""Áîü‰∫ß\""]], [\""NN\"", [\""ÁéØÂ¢É\""]]]]]], [\""VP\"", [[\""VV\"", [\""Â∏¶Êù•\""]], [\""NP\"", [[\""ADJP\"", [[\""NP\"", [[\""ADJP\"", [[\""JJ\"", [\""Ê¨°\""]]]], [\""NP\"", [[\""NN\"", [\""‰∏ñ‰ª£\""]]]]]], [\""ADVP\"", [[\""AD\"", [\""ÊúÄ\""]]]], [\""VP\"", [[\""JJ\"", [\""ÂÖàËøõ\""]]]]]], [\""DEG\"", [\""ÁöÑ\""]], [\""NP\"", [[\""QP\"", [[\""CD\"", [\""Â§ö\""]]]], [\""NP\"", [[\""NN\"", [\""ËØ≠Áßç\""]]]]]], [\""NP\"", [[\""NR\"", [\""NLP\""]], [\""NN\"", [\""ÊäÄÊúØ\""]]]]]]]]]], [\""PU\"", [\""„ÄÇ\""]]]]]],    [\""TOP\"", [[\""IP\"", [[\""NP\"", [[\""NN\"", [\""ÈòøÂ©Ü‰∏ª\""]]]], [\""VP\"", [[\""VP\"", [[\""VV\"", [\""Êù•Âà∞\""]], [\""NP\"", [[\""NR\"", [\""Âåó‰∫¨\""]], [\""NR\"", [\""Á´ãÊñπÂ∫≠\""]]]]]], [\""VP\"", [[\""VV\"", [\""ÂèÇËßÇ\""]], [\""NP\"", [[\""NN\"", [\""Ëá™ÁÑ∂\""]], [\""NN\"", [\""ËØ≠‰πâ\""]], [\""NN\"", [\""ÁßëÊäÄ\""]], [\""NN\"", [\""ÂÖ¨Âè∏\""]]]]]]]], [\""PU\"", [\""„ÄÇ\""]]]]]]  ]}ÁâπÂà´Âú∞ÔºåPython RESTfulÂíånative APIÊîØÊåÅÂü∫‰∫éÁ≠âÂÆΩÂ≠ó‰ΩìÁöÑÂèØËßÜÂåñÔºåËÉΩÂ§üÁõ¥Êé•Â∞ÜËØ≠Ë®ÄÂ≠¶ÁªìÊûÑÂú®ÊéßÂà∂Âè∞ÂÜÖÂèØËßÜÂåñÂá∫Êù•ÔºöHanLP(['2021Âπ¥HanLPv2.1‰∏∫Áîü‰∫ßÁéØÂ¢ÉÂ∏¶Êù•Ê¨°‰∏ñ‰ª£ÊúÄÂÖàËøõÁöÑÂ§öËØ≠ÁßçNLPÊäÄÊúØ„ÄÇ', 'ÈòøÂ©Ü‰∏ªÊù•Âà∞Âåó‰∫¨Á´ãÊñπÂ∫≠ÂèÇËßÇËá™ÁÑ∂ËØ≠‰πâÁßëÊäÄÂÖ¨Âè∏„ÄÇ']).pretty_print()Dep Tree    \tToken    \tRelati\tPoS\tTok      \tNER Type        \tTok      \tSRL PA1     \tTok      \tSRL PA2     \tTok      \tPoS    3       4       5       6       7       8       9 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫\t2021Âπ¥    \ttmod  \tNT \t2021Âπ¥    \t‚îÄ‚îÄ‚îÄ‚ñ∫DATE        \t2021Âπ¥    \t‚îÄ‚îÄ‚îÄ‚ñ∫ARGM-TMP\t2021Âπ¥    \t            \t2021Âπ¥    \tNT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫NP ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫\tHanLPv2.1\tnsubj \tNR \tHanLPv2.1\t‚îÄ‚îÄ‚îÄ‚ñ∫ORGANIZATION\tHanLPv2.1\t‚îÄ‚îÄ‚îÄ‚ñ∫ARG0    \tHanLPv2.1\t            \tHanLPv2.1\tNR ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫NP‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îÇ‚îÇ‚îå‚îÄ‚ñ∫‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‰∏∫        \tprep  \tP  \t‰∏∫        \t                \t‰∏∫        \t‚óÑ‚îÄ‚îê         \t‰∏∫        \t            \t‰∏∫        \tP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                       ‚îÇ    ‚îÇ‚îÇ‚îÇ  ‚îÇ  ‚îå‚îÄ‚ñ∫\tÁîü‰∫ß       \tnn    \tNN \tÁîü‰∫ß       \t                \tÁîü‰∫ß       \t  ‚îú‚ñ∫ARG2    \tÁîü‰∫ß       \t            \tÁîü‰∫ß       \tNN ‚îÄ‚îÄ‚îê       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫PP ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ    ‚îÇ‚îÇ‚îÇ  ‚îî‚îÄ‚ñ∫‚îî‚îÄ‚îÄ\tÁéØÂ¢É       \tpobj  \tNN \tÁéØÂ¢É       \t                \tÁéØÂ¢É       \t‚óÑ‚îÄ‚îò         \tÁéØÂ¢É       \t            \tÁéØÂ¢É       \tNN ‚îÄ‚îÄ‚î¥‚ñ∫NP ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ       ‚îÇ   ‚îå‚îº‚î¥‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\tÂ∏¶Êù•       \troot  \tVV \tÂ∏¶Êù•       \t                \tÂ∏¶Êù•       \t‚ïü‚îÄ‚îÄ‚ñ∫PRED    \tÂ∏¶Êù•       \t            \tÂ∏¶Êù•       \tVV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ       ‚îÇ   ‚îÇ‚îÇ       ‚îå‚îÄ‚ñ∫\tÊ¨°        \tamod  \tJJ \tÊ¨°        \t                \tÊ¨°        \t‚óÑ‚îÄ‚îê         \tÊ¨°        \t            \tÊ¨°        \tJJ ‚îÄ‚îÄ‚îÄ‚ñ∫ADJP‚îÄ‚îÄ‚îê                       ‚îÇ       ‚îú‚ñ∫VP‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îÇ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚ñ∫‚îî‚îÄ‚îÄ\t‰∏ñ‰ª£       \tnn    \tNN \t‰∏ñ‰ª£       \t                \t‰∏ñ‰ª£       \t  ‚îÇ         \t‰∏ñ‰ª£       \t            \t‰∏ñ‰ª£       \tNN ‚îÄ‚îÄ‚îÄ‚ñ∫NP ‚îÄ‚îÄ‚îÄ‚î¥‚ñ∫NP ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ       ‚îÇ       ‚îÇ   ‚îÇ‚îÇ  ‚îÇ    ‚îå‚îÄ‚ñ∫\tÊúÄ        \tadvmod\tAD \tÊúÄ        \t                \tÊúÄ        \t  ‚îÇ         \tÊúÄ        \t‚îÄ‚îÄ‚îÄ‚ñ∫ARGM-ADV\tÊúÄ        \tAD ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ADVP‚îÄ‚îÄ‚îº‚ñ∫ADJP‚îÄ‚îÄ‚îê       ‚îú‚ñ∫VP ‚îÄ‚îÄ‚îÄ‚îò       ‚îú‚ñ∫IP‚îÇ‚îÇ  ‚îÇ‚îå‚îÄ‚îÄ‚ñ∫‚îú‚îÄ‚îÄ\tÂÖàËøõ       \trcmod \tJJ \tÂÖàËøõ       \t                \tÂÖàËøõ       \t  ‚îÇ         \tÂÖàËøõ       \t‚ïü‚îÄ‚îÄ‚ñ∫PRED    \tÂÖàËøõ       \tJJ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫VP ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ       ‚îÇ               ‚îÇ   ‚îÇ‚îÇ  ‚îÇ‚îÇ   ‚îî‚îÄ‚ñ∫\tÁöÑ        \tassm  \tDEG\tÁöÑ        \t                \tÁöÑ        \t  ‚îú‚ñ∫ARG1    \tÁöÑ        \t            \tÁöÑ        \tDEG‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§       ‚îÇ               ‚îÇ   ‚îÇ‚îÇ  ‚îÇ‚îÇ   ‚îå‚îÄ‚ñ∫\tÂ§ö        \tnummod\tCD \tÂ§ö        \t                \tÂ§ö        \t  ‚îÇ         \tÂ§ö        \t            \tÂ§ö        \tCD ‚îÄ‚îÄ‚îÄ‚ñ∫QP ‚îÄ‚îÄ‚îÄ‚îê               ‚îú‚ñ∫NP ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ   ‚îÇ‚îÇ  ‚îÇ‚îÇ‚îå‚îÄ‚ñ∫‚îî‚îÄ‚îÄ\tËØ≠Áßç       \tnn    \tNN \tËØ≠Áßç       \t                \tËØ≠Áßç       \t  ‚îÇ         \tËØ≠Áßç       \t            \tËØ≠Áßç       \tNN ‚îÄ‚îÄ‚îÄ‚ñ∫NP ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫NP‚îÄ‚îÄ‚îÄ‚îÄ‚î§                       ‚îÇ   ‚îÇ‚îÇ  ‚îÇ‚îÇ‚îÇ  ‚îå‚îÄ‚ñ∫\tNLP      \tnn    \tNR \tNLP      \t                \tNLP      \t  ‚îÇ         \tNLP      \t            \tNLP      \tNR ‚îÄ‚îÄ‚îê                       ‚îÇ                       ‚îÇ   ‚îÇ‚îî‚îÄ‚ñ∫‚îî‚î¥‚î¥‚îÄ‚îÄ‚î¥‚îÄ‚îÄ\tÊäÄÊúØ       \tdobj  \tNN \tÊäÄÊúØ       \t                \tÊäÄÊúØ       \t‚óÑ‚îÄ‚îò         \tÊäÄÊúØ       \t‚îÄ‚îÄ‚îÄ‚ñ∫ARG0    \tÊäÄÊúØ       \tNN ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫NP ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫\t„ÄÇ        \tpunct \tPU \t„ÄÇ        \t                \t„ÄÇ        \t            \t„ÄÇ        \t            \t„ÄÇ        \tPU ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   Dep Tree    \tTok\tRelat\tPo\tTok\tNER Type        \tTok\tSRL PA1 \tTok\tSRL PA2 \tTok\tPo    3       4       5       6 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ\t‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ         ‚îå‚îÄ‚ñ∫\tÈòøÂ©Ü‰∏ª\tnsubj\tNN\tÈòøÂ©Ü‰∏ª\t                \tÈòøÂ©Ü‰∏ª\t‚îÄ‚îÄ‚îÄ‚ñ∫ARG0\tÈòøÂ©Ü‰∏ª\t‚îÄ‚îÄ‚îÄ‚ñ∫ARG0\tÈòøÂ©Ü‰∏ª\tNN‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫NP ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¥‚îÄ‚îÄ\tÊù•Âà∞ \troot \tVV\tÊù•Âà∞ \t                \tÊù•Âà∞ \t‚ïü‚îÄ‚îÄ‚ñ∫PRED\tÊù•Âà∞ \t        \tÊù•Âà∞ \tVV‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ   ‚îÇ‚îÇ    ‚îÇ  ‚îå‚îÄ‚ñ∫\tÂåó‰∫¨ \tnn   \tNR\tÂåó‰∫¨ \t‚îÄ‚îÄ‚îÄ‚ñ∫LOCATION    \tÂåó‰∫¨ \t‚óÑ‚îÄ‚îê     \tÂåó‰∫¨ \t        \tÂåó‰∫¨ \tNR‚îÄ‚îÄ‚îê       ‚îú‚ñ∫VP ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ   ‚îÇ‚îÇ    ‚îî‚îÄ‚ñ∫‚îî‚îÄ‚îÄ\tÁ´ãÊñπÂ∫≠\tdobj \tNR\tÁ´ãÊñπÂ∫≠\t‚îÄ‚îÄ‚îÄ‚ñ∫LOCATION    \tÁ´ãÊñπÂ∫≠\t‚óÑ‚îÄ‚î¥‚ñ∫ARG1\tÁ´ãÊñπÂ∫≠\t        \tÁ´ãÊñπÂ∫≠\tNR‚îÄ‚îÄ‚î¥‚ñ∫NP ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ       ‚îÇ   ‚îÇ‚îî‚îÄ‚ñ∫‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\tÂèÇËßÇ \tconj \tVV\tÂèÇËßÇ \t                \tÂèÇËßÇ \t        \tÂèÇËßÇ \t‚ïü‚îÄ‚îÄ‚ñ∫PRED\tÂèÇËßÇ \tVV‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îú‚ñ∫VP‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îÇ   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚ñ∫\tËá™ÁÑ∂ \tnn   \tNN\tËá™ÁÑ∂ \t‚óÑ‚îÄ‚îê             \tËá™ÁÑ∂ \t        \tËá™ÁÑ∂ \t‚óÑ‚îÄ‚îê     \tËá™ÁÑ∂ \tNN‚îÄ‚îÄ‚îê       ‚îÇ       ‚îÇ       ‚îú‚ñ∫IP‚îÇ   ‚îÇ  ‚îÇ‚îå‚îÄ‚îÄ‚ñ∫\tËØ≠‰πâ \tnn   \tNN\tËØ≠‰πâ \t  ‚îÇ             \tËØ≠‰πâ \t        \tËØ≠‰πâ \t  ‚îÇ     \tËØ≠‰πâ \tNN  ‚îÇ       ‚îú‚ñ∫VP ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ   ‚îÇ   ‚îÇ  ‚îÇ‚îÇ‚îå‚îÄ‚ñ∫\tÁßëÊäÄ \tnn   \tNN\tÁßëÊäÄ \t  ‚îú‚ñ∫ORGANIZATION\tÁßëÊäÄ \t        \tÁßëÊäÄ \t  ‚îú‚ñ∫ARG1\tÁßëÊäÄ \tNN  ‚îú‚ñ∫NP ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∫‚îî‚î¥‚î¥‚îÄ‚îÄ\tÂÖ¨Âè∏ \tdobj \tNN\tÂÖ¨Âè∏ \t‚óÑ‚îÄ‚îò             \tÂÖ¨Âè∏ \t        \tÂÖ¨Âè∏ \t‚óÑ‚îÄ‚îò     \tÂÖ¨Âè∏ \tNN‚îÄ‚îÄ‚îò                       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫\t„ÄÇ  \tpunct\tPU\t„ÄÇ  \t                \t„ÄÇ  \t        \t„ÄÇ  \t        \t„ÄÇ  \tPU‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ÂÖ≥‰∫éÊ†áÊ≥®ÈõÜÂê´‰πâÔºåËØ∑ÂèÇËÄÉ„ÄäËØ≠Ë®ÄÂ≠¶Ê†áÊ≥®ËßÑËåÉ„ÄãÂèä„ÄäÊ†ºÂºèËßÑËåÉ„Äã„ÄÇÊàë‰ª¨Ë¥≠‰π∞„ÄÅÊ†áÊ≥®ÊàñÈááÁî®‰∫Ü‰∏ñÁïå‰∏äÈáèÁ∫ßÊúÄÂ§ß„ÄÅÁßçÁ±ªÊúÄÂ§öÁöÑËØ≠ÊñôÂ∫ìÁî®‰∫éËÅîÂêàÂ§öËØ≠ÁßçÂ§ö‰ªªÂä°Â≠¶‰π†ÔºåÊâÄ‰ª•HanLPÁöÑÊ†áÊ≥®ÈõÜ‰πüÊòØË¶ÜÁõñÈù¢ÊúÄÂπøÁöÑ„ÄÇËÆ≠ÁªÉ‰Ω†Ëá™Â∑±ÁöÑÈ¢ÜÂüüÊ®°ÂûãÂÜôÊ∑±Â∫¶Â≠¶‰π†Ê®°Âûã‰∏ÄÁÇπÈÉΩ‰∏çÈöæÔºåÈöæÁöÑÊòØÂ§çÁé∞ËæÉÈ´òÁöÑÂáÜÁ°ÆÁéá„ÄÇ‰∏ãÂàó‰ª£Á†ÅÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂú®sighan2005 PKUËØ≠ÊñôÂ∫ì‰∏äËä±6ÂàÜÈíüËÆ≠ÁªÉ‰∏Ä‰∏™Ë∂ÖË∂äÂ≠¶ÊúØÁïåstate-of-the-artÁöÑ‰∏≠ÊñáÂàÜËØçÊ®°Âûã„ÄÇtokenizer = TransformerTaggingTokenizer()save_dir = 'data/model/cws/sighan2005_pku_bert_base_96.73'tokenizer.fit(    SIGHAN2005_PKU_TRAIN_ALL,    SIGHAN2005_PKU_TEST,  # Conventionally, no devset is used. See Tian et al. (2020).    save_dir,    'bert-base-chinese',    max_seq_len=300,    char_level=True,    hard_constraint=True,    sampler_builder=SortingSamplerBuilder(batch_size=32),    epochs=3,    adam_epsilon=1e-6,    warmup_steps=0.1,    weight_decay=0.01,    word_dropout=0.1,    seed=1660853059,)tokenizer.evaluate(SIGHAN2005_PKU_TEST, save_dir)ÂÖ∂‰∏≠ÔºåÁî±‰∫éÊåáÂÆö‰∫ÜÈöèÊú∫Êï∞ÁßçÂ≠êÔºåÁªìÊûú‰∏ÄÂÆöÊòØ96.73„ÄÇ‰∏çÂêå‰∫éÈÇ£‰∫õËôöÂÅáÂÆ£‰º†ÁöÑÂ≠¶ÊúØËÆ∫ÊñáÊàñÂïÜ‰∏öÈ°πÁõÆÔºåHanLP‰øùËØÅÊâÄÊúâÁªìÊûúÂèØÂ§çÁé∞„ÄÇÂ¶ÇÊûú‰Ω†Êúâ‰ªª‰ΩïË¥®ÁñëÔºåÊàë‰ª¨Â∞ÜÂΩì‰ΩúÊúÄÈ´ò‰ºòÂÖàÁ∫ßÁöÑËá¥ÂëΩÊÄßbugÁ¨¨‰∏ÄÊó∂Èó¥ÊéíÊü•ÈóÆÈ¢ò„ÄÇËØ∑ÂèÇËÄÉdemo‰∫ÜËß£Êõ¥Â§öËÆ≠ÁªÉËÑöÊú¨„ÄÇÊÄßËÉΩlangcorporamodeltokposnerdepconsrlsdplemfeaamrfinecoarsectbpku863udpkumsraontonotesSemEval16DMPASPSDmulUD2.7OntoNotes5small98.62----93.23--74.4279.1076.8570.63-91.1993.6785.3487.7184.51-base98.97----90.32--80.3278.7471.2373.63-92.6096.0481.1985.0882.13-zhopensmall97.25-96.66-----95.0084.5787.6273.4084.57------base97.50-97.07-----96.0487.1189.8477.7887.11------closesmall96.7095.9396.8797.5695.05-96.2295.7476.7984.4488.1375.8174.28------base97.5296.4496.9997.5995.29-96.4895.7277.7785.2988.5776.5273.76------ernie96.9597.2996.7697.6495.22-97.3196.4777.9585.6789.1778.5174.10------Ê†πÊçÆÊàë‰ª¨ÁöÑÊúÄÊñ∞Á†îÁ©∂ÔºåÂçï‰ªªÂä°Â≠¶‰π†ÁöÑÊÄßËÉΩÂæÄÂæÄ‰ºò‰∫éÂ§ö‰ªªÂä°Â≠¶‰π†„ÄÇÂú®‰πéÁ≤æÂ∫¶Áîö‰∫éÈÄüÂ∫¶ÁöÑËØùÔºåÂª∫ËÆÆ‰ΩøÁî®Âçï‰ªªÂä°Ê®°Âûã„ÄÇHanLPÈááÁî®ÁöÑÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ‰∏éÊãÜÂàÜÊØî‰æã‰∏éÊµÅË°åÊñπÊ≥ïÊú™ÂøÖÁõ∏ÂêåÔºåÊØîÂ¶ÇHanLPÈááÁî®‰∫ÜÂÆåÊï¥ÁâàÁöÑMSRAÂëΩÂêçÂÆû‰ΩìËØÜÂà´ËØ≠ÊñôÔºåËÄåÈùûÂ§ß‰ºó‰ΩøÁî®ÁöÑÈòâÂâ≤ÁâàÔºõHanLP‰ΩøÁî®‰∫ÜËØ≠Ê≥ïË¶ÜÁõñÊõ¥ÂπøÁöÑStanford DependenciesÊ†áÂáÜÔºåËÄåÈùûÂ≠¶ÊúØÁïåÊ≤øÁî®ÁöÑZhang and Clark (2008)Ê†áÂáÜÔºõHanLPÊèêÂá∫‰∫ÜÂùáÂåÄÂàÜÂâ≤CTBÁöÑÊñπÊ≥ïÔºåËÄå‰∏çÈááÁî®Â≠¶ÊúØÁïå‰∏çÂùáÂåÄ‰∏îÈÅóÊºè‰∫Ü51‰∏™ÈªÑÈáëÊñá‰ª∂ÁöÑÊñπÊ≥ï„ÄÇHanLPÂºÄÊ∫ê‰∫Ü‰∏ÄÊï¥Â•óËØ≠ÊñôÈ¢ÑÂ§ÑÁêÜËÑöÊú¨‰∏éÁõ∏Â∫îËØ≠ÊñôÂ∫ìÔºåÂäõÂõæÊé®Âä®‰∏≠ÊñáNLPÁöÑÈÄèÊòéÂåñ„ÄÇÊÄª‰πãÔºåHanLPÂè™ÂÅöÊàë‰ª¨ËÆ§‰∏∫Ê≠£Á°Æ„ÄÅÂÖàËøõÁöÑ‰∫ãÊÉÖÔºåËÄå‰∏ç‰∏ÄÂÆöÊòØÊµÅË°å„ÄÅÊùÉÂ®ÅÁöÑ‰∫ãÊÉÖ„ÄÇÂºïÁî®Â¶ÇÊûú‰Ω†Âú®Á†îÁ©∂‰∏≠‰ΩøÁî®‰∫ÜHanLPÔºåËØ∑ÊåâÂ¶Ç‰∏ãÊ†ºÂºèÂºïÁî®Ôºö@inproceedings{he-choi-2021-stem,    title = \""The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders\"",    author = \""He, Han and Choi, Jinho D.\"",    booktitle = \""Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\"",    month = nov,    year = \""2021\"",    address = \""Online and Punta Cana, Dominican Republic\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://aclanthology.org/2021.emnlp-main.451\"",    pages = \""5555--5577\"",    abstract = \""Multi-task learning with transformer encoders (MTL) has emerged as a powerful technique to improve performance on closely-related tasks for both accuracy and efficiency while a question still remains whether or not it would perform as well on tasks that are distinct in nature. We first present MTL results on five NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over single-task learning. We then conduct an extensive pruning analysis to show that a certain set of attention heads get claimed by most tasks during MTL, who interfere with one another to fine-tune those heads for their own objectives. Based on this finding, we propose the Stem Cell Hypothesis to reveal the existence of attention heads naturally talented for many tasks that cannot be jointly trained to create adequate embeddings for all of those tasks. Finally, we design novel parameter-free probes to justify our hypothesis and demonstrate how attention heads are transformed across the five tasks during MTL through label analysis.\"",}LicenseÊ∫ê‰ª£Á†ÅHanLPÊ∫ê‰ª£Á†ÅÁöÑÊéàÊùÉÂçèËÆÆ‰∏∫ Apache License 2.0ÔºåÂèØÂÖçË¥πÁî®ÂÅöÂïÜ‰∏öÁî®ÈÄî„ÄÇËØ∑Âú®‰∫ßÂìÅËØ¥Êòé‰∏≠ÈôÑÂä†HanLPÁöÑÈìæÊé•ÂíåÊéàÊùÉÂçèËÆÆ„ÄÇHanLPÂèóÁâàÊùÉÊ≥ï‰øùÊä§Ôºå‰æµÊùÉÂøÖÁ©∂„ÄÇËá™ÁÑ∂ËØ≠‰πâÔºàÈùíÂ≤õÔºâÁßëÊäÄÊúâÈôêÂÖ¨Âè∏HanLP‰ªév1.7ÁâàËµ∑Áã¨Á´ãËøê‰ΩúÔºåÁî±Ëá™ÁÑ∂ËØ≠‰πâÔºàÈùíÂ≤õÔºâÁßëÊäÄÊúâÈôêÂÖ¨Âè∏‰Ωú‰∏∫È°πÁõÆ‰∏ª‰ΩìÔºå‰∏ªÂØºÂêéÁª≠ÁâàÊú¨ÁöÑÂºÄÂèëÔºåÂπ∂Êã•ÊúâÂêéÁª≠ÁâàÊú¨ÁöÑÁâàÊùÉ„ÄÇÂ§ßÂø´ÊêúÁ¥¢HanLP v1.3~v1.65ÁâàÁî±Â§ßÂø´ÊêúÁ¥¢‰∏ªÂØºÂºÄÂèëÔºåÁªßÁª≠ÂÆåÂÖ®ÂºÄÊ∫êÔºåÂ§ßÂø´ÊêúÁ¥¢Êã•ÊúâÁõ∏ÂÖ≥ÁâàÊùÉ„ÄÇ‰∏äÊµ∑ÊûóÂéüÂÖ¨Âè∏HanLP Êó©ÊúüÂæóÂà∞‰∫Ü‰∏äÊµ∑ÊûóÂéüÂÖ¨Âè∏ÁöÑÂ§ßÂäõÊîØÊåÅÔºåÂπ∂Êã•Êúâ1.28ÂèäÂâçÂ∫èÁâàÊú¨ÁöÑÁâàÊùÉÔºåÁõ∏ÂÖ≥ÁâàÊú¨‰πüÊõæÂú®‰∏äÊµ∑ÊûóÂéüÂÖ¨Âè∏ÁΩëÁ´ôÂèëÂ∏É„ÄÇÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑÊéàÊùÉÂú®Ê≥ïÂæã‰∏äÊ≤°ÊúâÂÆöËÆ∫Ôºå‰ΩÜÊú¨ÁùÄÂ∞äÈáçÂºÄÊ∫êËØ≠ÊñôÂ∫ìÂéüÂßãÊéàÊùÉÁöÑÁ≤æÁ•ûÔºåÂ¶Ç‰∏çÁâπÂà´ËØ¥ÊòéÔºåHanLPÁöÑÂ§öËØ≠ÁßçÊ®°ÂûãÊéàÊùÉÊ≤øÁî®CC BY-NC-SA 4.0Ôºå‰∏≠ÊñáÊ®°ÂûãÊéàÊùÉ‰∏∫‰ªÖ‰æõÁ†îÁ©∂‰∏éÊïôÂ≠¶‰ΩøÁî®„ÄÇReferenceshttps://hanlp.hankcs.com/docs/references.html"
57,XX-net/XX-Net,https://github.com/XX-net/XX-Net/blob/master/README.md,Python,"üöÄ XX-Net (ÁøªÂ¢ôVPN)ËøôÊòØ‰∏Ä‰∏™ÂèØÈù†ÁöÑÁøªÂ¢ôÁ≥ªÁªüÔºåÂ∑≤ÁªèËøûÁª≠ËøêË°å 8 Âπ¥ÔºÅÊàë‰ª¨‰∏çÂéªÁ†îÁ©∂Â¢ôÊúâ‰ªÄ‰πàÁº∫Èô∑ÔºåÂõ†‰∏∫ÊâÄÊúâÁöÑÁº∫Èô∑ÈÉΩ‰ºöË¢´ÊÖ¢ÊÖ¢ÁöÑË°•‰∏ä„ÄÇÊàë‰ª¨ÁöÑÁ≠ñÁï•ÊòØÂåñË∫´‰∏∫ÊôÆÈÄöÊµÅÈáèÔºåÂÆåÂÖ®Êó†Ê≥ïÂå∫ÂàÜÔºåÊúÄÁªàÈöêË∫´Âú®Ëå´Ëå´ÁöÑÁΩëÁªúËøûÊé•‰∏≠„ÄÇ„ÄÇ„ÄÇüîå ÂäüËÉΩÁâπÊÄßÊîØÊåÅÂ§öÂπ≥Âè∞Ôºö Android/iOS/Windows/Mac/LinuxÈááÁî®Áã¨ÁâπÁöÑÊ∑∑Ê∑ÜÁÆóÊ≥ïÔºåËÆ©ÊÇ®ÁöÑÊµÅÈáèÂú®ÁΩëÁªú‰∏≠Êó†Ê≥ïË¢´ËØÜÂà´ÂºÄÊ∫êÁªøËâ≤ËΩØ‰ª∂ÔºåÊó†ÈúÄÂÆâË£ÖÔºåÂèØ‰ª•ÊîØÊåÅÂ§öÂè∞ËÆæÂ§áÂêåÊó∂ËøûÊé•Ê®°ÊãüChromeÊµèËßàÂô®Ë°å‰∏∫ÔºåÂÆåÂÖ®Êó†Ê≥ïËØÜÂà´ÔºåÁ®≥ÂÆöÁøªÂ¢ôÂÜÖÁΩÆ ChatGPTÔºåÊØè‰∏™Â•óÈ§êËµ†ÈÄÅ ChatGPT-3.5 ‰∏ÄÁôæ‰∏átokenÂÆòÁΩë‰∏ãËΩΩ: https://xx-net.comTelegram: https://t.me/xxnetshareTwitter: https://twitter.com/XXNetDev‰∏≠ÊñáÂ∏ÆÂä©ÊñáÊ°£ ¬† ¬† ¬†English Document ¬† ¬† ¬†ŸÅÿßÿ±ÿ≥€å ÿµŸÅÿ≠Ÿá ÿßÿµŸÑ€åÊúÄÊñ∞ÂÖ¨ÂëäÔºö2023-08-15Êñ∞Áâà 5.5.0, ÊèêÂçáËøûÊé•ÊÄßËÉΩ5.1.0ÔºåÂÜÖÁΩÆChatGPTÂéüÊù•ÊòØ4.x.x ËÄÅÁâàÊú¨ÁöÑÔºåÈúÄË¶ÅÈáçÊñ∞‰∏ãËΩΩÊñ∞ÁâàÂÆâË£ÖÔºå‰∏çËÉΩÂ∫îÁî®ÂÜÖÂçáÁ∫ß„ÄÇÊèêÁ§∫ÔºöÊúâÈóÆÈ¢òËØ∑ÂÖàÁúãWikiÊñáÊ°£ÊèêÈóÆ ÂâçÔºåËØ∑ÂÖàÁúãÊúÄËøëËÆ®ËÆ∫‰∏ªÈ¢ò ÔºåÈÅøÂÖçÈáçÂ§çÂèëÈóÆ„ÄÇ"
58,donnemartin/data-science-ipython-notebooks,https://github.com/donnemartin/data-science-ipython-notebooks/blob/master/README.md,Python,"      data-science-ipython-notebooksIndexdeep-learningtensorflowtheanokerascaffescikit-learnstatistical-inference-scipypandasmatplotlibnumpypython-datakaggle-and-business-analysessparkmapreduce-pythonamazon web servicescommand linesmiscnotebook-installationcreditscontributingcontact-infolicense  deep-learningIPython Notebook(s) demonstrating deep learning functionality.  tensor-flow-tutorialsAdditional TensorFlow tutorials:pkmital/tensorflow_tutorialsnlintz/TensorFlow-Tutorialsalrojo/tensorflow-tutorialBinRoot/TensorFlow-Booktuanavu/tensorflow-basic-tutorialsNotebookDescriptiontsf-basicsLearn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google.tsf-linearImplement linear regression in TensorFlow.tsf-logisticImplement logistic regression in TensorFlow.tsf-nnImplement nearest neighboars in TensorFlow.tsf-alexImplement AlexNet in TensorFlow.tsf-cnnImplement convolutional neural networks in TensorFlow.tsf-mlpImplement multilayer perceptrons in TensorFlow.tsf-rnnImplement recurrent neural networks in TensorFlow.tsf-gpuLearn about basic multi-GPU computation in TensorFlow.tsf-gvizLearn about graph visualization in TensorFlow.tsf-lvizLearn about loss visualization in TensorFlow.tensor-flow-exercisesNotebookDescriptiontsf-not-mnistLearn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow.tsf-fully-connectedProgressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow.tsf-regularizationExplore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow.tsf-convolutionsCreate convolutional neural networks in TensorFlow.tsf-word2vecTrain a skip-gram model over Text8 data in TensorFlow.tsf-lstmTrain a LSTM character model over Text8 data in TensorFlow.  theano-tutorialsNotebookDescriptiontheano-introIntro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation.theano-scanLearn scans, a mechanism to perform loops in a Theano graph.theano-logisticImplement logistic regression in Theano.theano-rnnImplement recurrent neural networks in Theano.theano-mlpImplement multilayer perceptrons in Theano.  keras-tutorialsNotebookDescriptionkerasKeras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano.setupLearn about the tutorial goals and how to set up your Keras environment.intro-deep-learning-annGet an intro to deep learning with Keras and Artificial Neural Networks (ANN).theanoLearn about Theano by working with weights matrices and gradients.keras-ottoLearn about Keras by looking at the Kaggle Otto challenge.ann-mnistReview a simple implementation of ANN for MNIST using Keras.conv-netsLearn about Convolutional Neural Networks (CNNs) with Keras.conv-net-1Recognize handwritten digits from MNIST using Keras - Part 1.conv-net-2Recognize handwritten digits from MNIST using Keras - Part 2.keras-modelsUse pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras.auto-encodersLearn about Autoencoders with Keras.rnn-lstmLearn about Recurrent Neural Networks (RNNs) with Keras.lstm-sentence-genLearn about RNNs using Long Short Term Memory (LSTM) networks with Keras.deep-learning-miscNotebookDescriptiondeep-dreamCaffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images.  scikit-learnIPython Notebook(s) demonstrating scikit-learn functionality.NotebookDescriptionintroIntro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays.knnImplement k-nearest neighbors in scikit-learn.linear-regImplement linear regression in scikit-learn.svmImplement support vector machine classifiers with and without kernels in scikit-learn.random-forestImplement random forest classifiers and regressors in scikit-learn.k-meansImplement k-means clustering in scikit-learn.pcaImplement principal component analysis in scikit-learn.gmmImplement Gaussian mixture models in scikit-learn.validationImplement validation and model selection in scikit-learn.  statistical-inference-scipyIPython Notebook(s) demonstrating statistical inference with SciPy functionality.NotebookDescriptionscipySciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data.effect-sizeExplore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States.samplingExplore random sampling by analyzing the average weight of men and women in the United States using BRFSS data.hypothesisExplore hypothesis testing by analyzing the difference of first-born babies compared with others.  pandasIPython Notebook(s) demonstrating pandas functionality.NotebookDescriptionpandasSoftware library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series.github-data-wranglingLearn how to load, clean, merge, and feature engineer by analyzing GitHub data from the Viz repo.Introduction-to-PandasIntroduction to Pandas.Introducing-Pandas-ObjectsLearn about Pandas objects.Data Indexing and SelectionLearn about data indexing and selection in Pandas.Operations-in-PandasLearn about operating on data in Pandas.Missing-ValuesLearn about handling missing data in Pandas.Hierarchical-IndexingLearn about hierarchical indexing in Pandas.Concat-And-AppendLearn about combining datasets: concat and append in Pandas.Merge-and-JoinLearn about combining datasets: merge and join in Pandas.Aggregation-and-GroupingLearn about aggregation and grouping in Pandas.Pivot-TablesLearn about pivot tables in Pandas.Working-With-StringsLearn about vectorized string operations in Pandas.Working-with-Time-SeriesLearn about working with time series in pandas.Performance-Eval-and-QueryLearn about high-performance Pandas: eval() and query() in Pandas.  matplotlibIPython Notebook(s) demonstrating matplotlib functionality.NotebookDescriptionmatplotlibPython 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.matplotlib-appliedApply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots.Introduction-To-MatplotlibIntroduction to Matplotlib.Simple-Line-PlotsLearn about simple line plots in Matplotlib.Simple-Scatter-PlotsLearn about simple scatter plots in Matplotlib.Errorbars.ipynbLearn about visualizing errors in Matplotlib.Density-and-Contour-PlotsLearn about density and contour plots in Matplotlib.Histograms-and-BinningsLearn about histograms, binnings, and density in Matplotlib.Customizing-LegendsLearn about customizing plot legends in Matplotlib.Customizing-ColorbarsLearn about customizing colorbars in Matplotlib.Multiple-SubplotsLearn about multiple subplots in Matplotlib.Text-and-AnnotationLearn about text and annotation in Matplotlib.Customizing-TicksLearn about customizing ticks in Matplotlib.Settings-and-StylesheetsLearn about customizing Matplotlib: configurations and stylesheets.Three-Dimensional-PlottingLearn about three-dimensional plotting in Matplotlib.Geographic-Data-With-BasemapLearn about geographic data with basemap in Matplotlib.Visualization-With-SeabornLearn about visualization with Seaborn.  numpyIPython Notebook(s) demonstrating NumPy functionality.NotebookDescriptionnumpyAdds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays.Introduction-to-NumPyIntroduction to NumPy.Understanding-Data-TypesLearn about data types in Python.The-Basics-Of-NumPy-ArraysLearn about the basics of NumPy arrays.Computation-on-arrays-ufuncsLearn about computations on NumPy arrays: universal functions.Computation-on-arrays-aggregatesLearn about aggregations: min, max, and everything in between in NumPy.Computation-on-arrays-broadcastingLearn about computation on arrays: broadcasting in NumPy.Boolean-Arrays-and-MasksLearn about comparisons, masks, and boolean logic in NumPy.Fancy-IndexingLearn about fancy indexing in NumPy.SortingLearn about sorting arrays in NumPy.Structured-Data-NumPyLearn about structured data: NumPy's structured arrays.  python-dataIPython Notebook(s) demonstrating Python functionality geared towards data analysis.NotebookDescriptiondata structuresLearn Python basics with tuples, lists, dicts, sets.data structure utilitiesLearn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions.functionsLearn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools.datetimeLearn how to work with Python dates and times: datetime, strftime, strptime, timedelta.loggingLearn about Python logging with RotatingFileHandler and TimedRotatingFileHandler.pdbLearn how to debug in Python with the interactive source code debugger.unit testsLearn how to test in Python with Nose unit tests.  kaggle-and-business-analysesIPython Notebook(s) used in kaggle competitions and business analyses.NotebookDescriptiontitanicPredict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning.churn-analysisPredict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.  sparkIPython Notebook(s) demonstrating spark and HDFS functionality.NotebookDescriptionsparkIn-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms.hdfsReliably stores very large files across machines in a large cluster.  mapreduce-pythonIPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.NotebookDescriptionmapreduce-pythonRuns MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and mrjob config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  Disco is another python-based alternative.  awsIPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.Also check out:SAWS: A Supercharged AWS command line interface (CLI).Awesome AWS: A curated list of libraries, open source repos, guides, blogs, and other resources.NotebookDescriptionbotoOfficial AWS SDK for Python.s3cmdInteracts with S3 through the command line.s3distcpCombines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster.s3-parallel-putUploads multiple files to S3 in parallel.redshiftActs as a fast data warehouse built on top of technology from massive parallel processing (MPP).kinesisStreams data in real time with the ability to process thousands of data streams per second.lambdaRuns code in response to events, automatically managing compute resources.  commandsIPython Notebook(s) demonstrating various command lines for Linux, Git, etc.NotebookDescriptionlinuxUnix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.anacondaDistribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment.ipython notebookWeb-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document.gitDistributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows.rubyUsed to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages.jekyllSimple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server.pelicanPython-based alternative to Jekyll.djangoHigh-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include Pyramid, Flask, Tornado, and Bottle.miscIPython Notebook(s) demonstrating miscellaneous functionality.NotebookDescriptionregexRegular expression cheat sheet useful in data wrangling.algorithmiaAlgorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.notebook-installationanacondaAnaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.Follow instructions to install Anaconda or the more lightweight miniconda.dev-setupFor detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the dev-setup repo.running-notebooksTo view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found here.$ git clone https://github.com/donnemartin/data-science-ipython-notebooks.git$ cd data-science-ipython-notebooks$ jupyter notebookNotebooks tested with Python 2.7.x.creditsPython for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython by Wes McKinneyPyCon 2015 Scikit-learn Tutorial by Jake VanderPlasPython Data Science Handbook by Jake VanderPlasParallel Machine Learning with scikit-learn and IPython by Olivier GriselStatistical Interference Using Computational Methods in Python by Allen DowneyTensorFlow Examples by Aymeric DamienTensorFlow Tutorials by Parag K MitalTensorFlow Tutorials by Nathan LintzTensorFlow Tutorials by Alexander R JohansenTensorFlow Book by Nishant ShuklaSummer School 2015 by mila-udemKeras tutorials by Valerio MaggioKaggleYhat BlogcontributingContributions are welcome!  For bug reports or requests please submit an issue.contact-infoFeel free to contact me to discuss any issues, questions, or comments.Email: donne.martin@gmail.comTwitter: @donne_martinGitHub: donnemartinLinkedIn: donnemartinWebsite: donnemartin.comlicenseThis repository contains a variety of content; some developed by Donne Martin, and some from third-parties.  The third-party content is distributed under the license provided by those parties.The content developed by Donne Martin is distributed under the following license:I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).Copyright 2015 Donne MartinLicensed under the Apache License, Version 2.0 (the \""License\"");you may not use this file except in compliance with the License.You may obtain a copy of the License at   http://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an \""AS IS\"" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License."
59,jackfrued/Python-100-Days,https://github.com/jackfrued/Python-100-Days/blob/master/README.md,Python,"Python - 100Â§©‰ªéÊñ∞ÊâãÂà∞Â§ßÂ∏à‰ΩúËÄÖÔºöÈ™ÜÊòäËØ¥ÊòéÔºö‰ªéÈ°πÁõÆ‰∏äÁ∫øÂà∞Ëé∑Âæó8w+ÊòüÊ†á‰ª•Êù•Ôºå‰∏ÄÁõ¥Êî∂Âà∞ÂèçÈ¶àËØ¥Âü∫Á°ÄÈÉ®ÂàÜÔºàÂâç15Â§©ÁöÑÂÜÖÂÆπÔºâÂØπÊñ∞ÊâãÊù•ËØ¥ÊòØÊØîËæÉÂõ∞ÈöæÁöÑÔºåÂª∫ËÆÆÊúâÈÖçÂ•óËßÜÈ¢ëËøõË°åËÆ≤Ëß£„ÄÇÊúÄËøëÊääÂü∫Á°ÄÈÉ®ÂàÜÁöÑÂÜÖÂÆπÈáçÊñ∞Âà∂‰Ωú‰∫Ü‰∏Ä‰∏™Âêç‰∏∫‚ÄúPython-Core-50-Courses‚ÄùÁöÑÈ°πÁõÆÔºåÁî®Êõ¥‰∏∫ÁÆÄÂçïÈÄö‰øóÁöÑÊñπÂºèÈáçÂÜô‰∫ÜËøôÈÉ®ÂàÜÂÜÖÂÆπÂπ∂ÈôÑÂ∏¶‰∫ÜËßÜÈ¢ëËÆ≤Ëß£ÔºåÂàùÂ≠¶ËÄÖÂèØ‰ª•ÂÖ≥Ê≥®‰∏ãËøô‰∏™Êñ∞È°πÁõÆ„ÄÇÂ¶ÇÊûúÈúÄË¶ÅPythonÂü∫Á°ÄËßÜÈ¢ëÔºåÂèØ‰ª•Âú®‚ÄúBÁ´ô‚ÄùÊêúÁ¥¢„ÄäPythonÈõ∂Âü∫Á°ÄÂø´ÈÄü‰∏äÊâã„ÄãÔºåËøôÂ•óËßÜÈ¢ëÊòØÊàëËÆ≤ËØæÁöÑÊó∂ÂÄôÂΩïÂà∂ÁöÑÈöèÂ†ÇËßÜÈ¢ëÔºåÁîªË¥®Â∞öÂèØ„ÄÅÈü≥Ë¥®‰∏ÄËà¨Ôºå‰ΩÜÊòØÂØπÂàùÂ≠¶ËÄÖÂ∫îËØ•‰ºöÊúâ‰∫õÂ∏ÆÂä©ÔºåÊ¨¢ËøéÂ§ßÂÆ∂ÁïôË®Ä„ÄÅËØÑËÆ∫„ÄÅÂèëÂºπÂπï„ÄÇÂ≠¶‰π†‰πãÂêéËßâÂæóÊúâÊî∂Ëé∑ÁöÑÂ∞è‰ºô‰º¥ÂèØ‰ª•‚Äú‰∏ÄÈîÆ‰∏âËøû‚ÄùÊù•ÊîØÊåÅUP‰∏ªÔºàÂçÉÈîãPythonÔºâ„ÄÇÂõΩÂÜÖÁî®Êà∑Â¶ÇÊûúËÆøÈóÆGitHubÊØîËæÉÊÖ¢ÁöÑËØùÔºåÂèØ‰ª•ÂÖ≥Ê≥®ÊàëÁöÑÁü•‰πéÂè∑Python-JackÔºå‰∏äÈù¢ÁöÑ‚Äú‰ªéÈõ∂ÂºÄÂßãÂ≠¶Python‚Äù‰∏ìÊ†èÊØîËæÉÈÄÇÂêàÂàùÂ≠¶ËÄÖÔºåÂÖ∂‰ªñÁöÑ‰∏ìÊ†è‰πüÂú®ÊåÅÁª≠Âàõ‰ΩúÂíåÊõ¥Êñ∞‰∏≠ÔºåÊ¨¢ËøéÂ§ßÂÆ∂ÂÖ≥Ê≥®Âπ∂ÁÇπËµûËØÑËÆ∫„ÄÇÂàõ‰Ωú‰∏çÊòìÔºåÊÑüË∞¢Â§ßÂÆ∂ÁöÑÊâìËµèÊîØÊåÅÔºåËøô‰∫õÈí±‰∏ç‰ºöÁî®‰∫é‰∏™‰∫∫Ê∂àË¥πÔºà‰æãÂ¶ÇÔºöË¥≠‰π∞ÂíñÂï°ÔºâÔºåËÄåÊòØÈÄöËøáËÖæËÆØÂÖ¨Áõä„ÄÅÁæéÂõ¢ÂÖ¨Áõä„ÄÅÊ∞¥Êª¥Á≠πÁ≠âÂπ≥Âè∞ÊçêËµ†ÁªôÈúÄË¶ÅÂ∏ÆÂä©ÁöÑ‰∫∫ÔºàÁÇπÂáª‰∫ÜËß£ÊçêËµ†ÊÉÖÂÜµÔºâ„ÄÇÈúÄË¶ÅÂä†ÂÖ•QQÂ≠¶‰π†Áæ§ÁöÑÂèØ‰ª•Êâ´Êèè‰∏ãÈù¢ÁöÑ‰∫åÁª¥Á†ÅÔºå‰∏â‰∏™Áæ§Âä†‰∏Ä‰∏™Âç≥ÂèØÔºå‰∏çË¶ÅÈáçÂ§çËøõÁæ§„ÄÇÂ≠¶‰π†Áæ§‰ºö‰∏∫Â§ßÂÆ∂Êèê‰æõÂ≠¶‰π†ËµÑÊ∫êÂíåÈóÆÈ¢òËß£Á≠îÔºåÂ¶ÇÊûúÊúâPython‰ΩìÈ™åËØæÂíåË°å‰∏öÂÖ¨ÂºÄËØæ‰ºöÊèêÂâçÂú®Áæ§ÈáåÈÄöÁü•Â§ßÂÆ∂ÔºåÊ¨¢ËøéÂ§ßÂÆ∂Âä†ÂÖ•„ÄÇÈ°πÁõÆ‚ÄúDay80~90‚ÄùÈÉ®ÂàÜÁõÆÂâç‰ªçÂú®Âàõ‰Ωú‰∏≠ÔºåÂõ†‰∏∫‰ΩúËÄÖÂπ≥Êó∂‰πüÊå§‰∏çÂá∫Â§™Â§öÊó∂Èó¥Êù•ÂÜôÊñáÊ°£ÔºåÂõ†Ê≠§Êõ¥Êñ∞ÁöÑÈÄüÂ∫¶ÊØîËæÉÁºìÊÖ¢ÔºåÊÑüË∞¢Â§ßÂÆ∂ÁöÑÁêÜËß£„ÄÇPythonÂ∫îÁî®È¢ÜÂüüÂíåËÅå‰∏öÂèëÂ±ïÂàÜÊûêÁÆÄÂçïÁöÑËØ¥ÔºåPythonÊòØ‰∏Ä‰∏™‚Äú‰ºòÈõÖ‚Äù„ÄÅ‚ÄúÊòéÁ°Æ‚Äù„ÄÅ‚ÄúÁÆÄÂçï‚ÄùÁöÑÁºñÁ®ãËØ≠Ë®Ä„ÄÇÂ≠¶‰π†Êõ≤Á∫ø‰ΩéÔºåÈùû‰∏ì‰∏ö‰∫∫Â£´‰πüËÉΩ‰∏äÊâãÂºÄÊ∫êÁ≥ªÁªüÔºåÊã•ÊúâÂº∫Â§ßÁöÑÁîüÊÄÅÂúàËß£ÈáäÂûãËØ≠Ë®ÄÔºåÂÆåÁæéÁöÑÂπ≥Âè∞ÂèØÁßªÊ§çÊÄßÂä®ÊÄÅÁ±ªÂûãËØ≠Ë®ÄÔºåÊîØÊåÅÈù¢ÂêëÂØπË±°ÂíåÂáΩÊï∞ÂºèÁºñÁ®ã‰ª£Á†ÅËßÑËåÉÁ®ãÂ∫¶È´òÔºåÂèØËØªÊÄßÂº∫PythonÂú®‰ª•‰∏ãÈ¢ÜÂüüÈÉΩÊúâÁî®Ê≠¶‰πãÂú∞„ÄÇÂêéÁ´ØÂºÄÂèë - Python / Java / Go / PHPDevOps - Python / Shell / RubyÊï∞ÊçÆÈááÈõÜ - Python / C++ / JavaÈáèÂåñ‰∫§Êòì - Python / C++ / RÊï∞ÊçÆÁßëÂ≠¶ - Python / R / Julia / MatlabÊú∫Âô®Â≠¶‰π† - Python / R / C++ / JuliaËá™Âä®ÂåñÊµãËØï - Python / Shell‰Ωú‰∏∫‰∏ÄÂêçPythonÂºÄÂèëËÄÖÔºåÊ†πÊçÆ‰∏™‰∫∫ÁöÑÂñúÂ•ΩÂíåËÅå‰∏öËßÑÂàíÔºåÂèØ‰ª•ÈÄâÊã©ÁöÑÂ∞±‰∏öÈ¢ÜÂüü‰πüÈùûÂ∏∏Â§ö„ÄÇPythonÂêéÁ´ØÂºÄÂèëÂ∑•Á®ãÂ∏àÔºàÊúçÂä°Âô®„ÄÅ‰∫ëÂπ≥Âè∞„ÄÅÊï∞ÊçÆÊé•Âè£ÔºâPythonËøêÁª¥Â∑•Á®ãÂ∏àÔºàËá™Âä®ÂåñËøêÁª¥„ÄÅSRE„ÄÅDevOpsÔºâPythonÊï∞ÊçÆÂàÜÊûêÂ∏àÔºàÊï∞ÊçÆÂàÜÊûê„ÄÅÂïÜ‰∏öÊô∫ËÉΩ„ÄÅÊï∞Â≠óÂåñËøêËê•ÔºâPythonÊï∞ÊçÆÊåñÊéòÂ∑•Á®ãÂ∏àÔºàÊú∫Âô®Â≠¶‰π†„ÄÅÊ∑±Â∫¶Â≠¶‰π†„ÄÅÁÆóÊ≥ï‰∏ìÂÆ∂ÔºâPythonÁà¨Ëô´Â∑•Á®ãÂ∏àPythonÊµãËØïÂ∑•Á®ãÂ∏àÔºàËá™Âä®ÂåñÊµãËØï„ÄÅÊµãËØïÂºÄÂèëÔºâËØ¥ÊòéÔºöÁõÆÂâçÔºåÊï∞ÊçÆÂàÜÊûêÂíåÊï∞ÊçÆÊåñÊéòÊòØÈùûÂ∏∏ÁÉ≠Èó®ÁöÑÊñπÂêëÔºåÂõ†‰∏∫‰∏çÁÆ°ÊòØ‰∫íËÅîÁΩëË°å‰∏öËøòÊòØ‰º†ÁªüË°å‰∏öÈÉΩÂ∑≤ÁªèÁßØÁ¥Ø‰∫ÜÂ§ßÈáèÁöÑÊï∞ÊçÆÔºåÂêÑË°åÂêÑ‰∏öÈÉΩÈúÄË¶ÅÊï∞ÊçÆÂàÜÊûêÂ∏à‰ªéÂ∑≤ÊúâÁöÑÊï∞ÊçÆ‰∏≠ÂèëÁé∞Êõ¥Â§öÁöÑÂïÜ‰∏ö‰ª∑ÂÄºÔºå‰ªéËÄå‰∏∫‰ºÅ‰∏öÁöÑÂÜ≥Á≠ñÊèê‰æõÊï∞ÊçÆÁöÑÊîØÊíëÔºåËøôÂ∞±ÊòØÊâÄË∞ìÁöÑÊï∞ÊçÆÈ©±Âä®ÂÜ≥Á≠ñ„ÄÇÁªôÂàùÂ≠¶ËÄÖÁöÑÂá†‰∏™Âª∫ËÆÆÔºöMake English as your working language. ÔºàËÆ©Ëã±ËØ≠Êàê‰∏∫‰Ω†ÁöÑÂ∑•‰ΩúËØ≠Ë®ÄÔºâPractice makes perfect. ÔºàÁÜüËÉΩÁîüÂ∑ßÔºâAll experience comes from mistakes. ÔºàÊâÄÊúâÁöÑÁªèÈ™åÈÉΩÊ∫ê‰∫é‰Ω†ÁäØËøáÁöÑÈîôËØØÔºâDon't be one of the leeches. Ôºà‰∏çË¶ÅÂΩì‰º∏ÊâãÂÖöÔºâEither outstanding or out. ÔºàË¶Å‰πàÂá∫‰ºóÔºåË¶Å‰πàÂá∫Â±ÄÔºâDay01~15 - PythonËØ≠Ë®ÄÂü∫Á°ÄDay01 - ÂàùËØÜPythonPythonÁÆÄ‰ªã - PythonÁöÑÂéÜÂè≤ / PythonÁöÑ‰ºòÁº∫ÁÇπ / PythonÁöÑÂ∫îÁî®È¢ÜÂüüÊê≠Âª∫ÁºñÁ®ãÁéØÂ¢É - WindowsÁéØÂ¢É / LinuxÁéØÂ¢É / MacOSÁéØÂ¢É‰ªéÁªàÁ´ØËøêË°åPythonÁ®ãÂ∫è - Hello, world / printÂáΩÊï∞ / ËøêË°åÁ®ãÂ∫è‰ΩøÁî®IDLE - ‰∫§‰∫íÂºèÁéØÂ¢É(REPL) / ÁºñÂÜôÂ§öË°å‰ª£Á†Å / ËøêË°åÁ®ãÂ∫è / ÈÄÄÂá∫IDLEÊ≥®Èáä - Ê≥®ÈáäÁöÑ‰ΩúÁî® / ÂçïË°åÊ≥®Èáä / Â§öË°åÊ≥®ÈáäDay02 - ËØ≠Ë®ÄÂÖÉÁ¥†Á®ãÂ∫èÂíåËøõÂà∂ - Êåá‰ª§ÂíåÁ®ãÂ∫è / ÂÜØËØ∫‰æùÊõºÊú∫ / ‰∫åËøõÂà∂ÂíåÂçÅËøõÂà∂ / ÂÖ´ËøõÂà∂ÂíåÂçÅÂÖ≠ËøõÂà∂ÂèòÈáèÂíåÁ±ªÂûã - ÂèòÈáèÁöÑÂëΩÂêç / ÂèòÈáèÁöÑ‰ΩøÁî® / inputÂáΩÊï∞ / Ê£ÄÊü•ÂèòÈáèÁ±ªÂûã / Á±ªÂûãËΩ¨Êç¢Êï∞Â≠óÂíåÂ≠óÁ¨¶‰∏≤ - Êï¥Êï∞ / ÊµÆÁÇπÊï∞ / Â§çÊï∞ / Â≠óÁ¨¶‰∏≤ / Â≠óÁ¨¶‰∏≤Âü∫Êú¨Êìç‰Ωú / Â≠óÁ¨¶ÁºñÁ†ÅËøêÁÆóÁ¨¶ - Êï∞Â≠¶ËøêÁÆóÁ¨¶ / ËµãÂÄºËøêÁÆóÁ¨¶ / ÊØîËæÉËøêÁÆóÁ¨¶ / ÈÄªËæëËøêÁÆóÁ¨¶ / Ë∫´‰ªΩËøêÁÆóÁ¨¶ / ËøêÁÆóÁ¨¶ÁöÑ‰ºòÂÖàÁ∫ßÂ∫îÁî®Ê°à‰æã - ÂçéÊ∞èÊ∏©Â∫¶ËΩ¨Êç¢ÊàêÊëÑÊ∞èÊ∏©Â∫¶ / ËæìÂÖ•ÂúÜÁöÑÂçäÂæÑËÆ°ÁÆóÂë®ÈïøÂíåÈù¢ÁßØ / ËæìÂÖ•Âπ¥‰ªΩÂà§Êñ≠ÊòØÂê¶ÊòØÈó∞Âπ¥Day03 - ÂàÜÊîØÁªìÊûÑÂàÜÊîØÁªìÊûÑÁöÑÂ∫îÁî®Âú∫ÊôØ - Êù°‰ª∂ / Áº©Ëøõ / ‰ª£Á†ÅÂùó / ÊµÅÁ®ãÂõæifËØ≠Âè• - ÁÆÄÂçïÁöÑif / if-elseÁªìÊûÑ / if-elif-elseÁªìÊûÑ / ÂµåÂ•óÁöÑifÂ∫îÁî®Ê°à‰æã - Áî®Êà∑Ë∫´‰ªΩÈ™åËØÅ / Ëã±Âà∂Âçï‰Ωç‰∏éÂÖ¨Âà∂Âçï‰Ωç‰∫íÊç¢ / Êé∑È™∞Â≠êÂÜ≥ÂÆöÂÅö‰ªÄ‰πà / ÁôæÂàÜÂà∂ÊàêÁª©ËΩ¨Á≠âÁ∫ßÂà∂ / ÂàÜÊÆµÂáΩÊï∞Ê±ÇÂÄº / ËæìÂÖ•‰∏âÊù°ËæπÁöÑÈïøÂ∫¶Â¶ÇÊûúËÉΩÊûÑÊàê‰∏âËßíÂΩ¢Â∞±ËÆ°ÁÆóÂë®ÈïøÂíåÈù¢ÁßØDay04 - Âæ™ÁéØÁªìÊûÑÂæ™ÁéØÁªìÊûÑÁöÑÂ∫îÁî®Âú∫ÊôØ - Êù°‰ª∂ / Áº©Ëøõ / ‰ª£Á†ÅÂùó / ÊµÅÁ®ãÂõæwhileÂæ™ÁéØ - Âü∫Êú¨ÁªìÊûÑ / breakËØ≠Âè• / continueËØ≠Âè•forÂæ™ÁéØ - Âü∫Êú¨ÁªìÊûÑ / rangeÁ±ªÂûã / Âæ™ÁéØ‰∏≠ÁöÑÂàÜÊîØÁªìÊûÑ / ÂµåÂ•óÁöÑÂæ™ÁéØ / ÊèêÂâçÁªìÊùüÁ®ãÂ∫èÂ∫îÁî®Ê°à‰æã - 1~100Ê±ÇÂíå / Âà§Êñ≠Á¥†Êï∞ / ÁåúÊï∞Â≠óÊ∏∏Êàè / ÊâìÂç∞‰πù‰πùË°® / ÊâìÂç∞‰∏âËßíÂΩ¢ÂõæÊ°à / Áå¥Â≠êÂêÉÊ°É / ÁôæÈí±ÁôæÈ∏°Day05 - ÊûÑÈÄ†Á®ãÂ∫èÈÄªËæëÁªèÂÖ∏Ê°à‰æãÔºöÊ∞¥‰ªôËä±Êï∞ / ÁôæÈí±ÁôæÈ∏° / CrapsËµåÂçöÊ∏∏ÊàèÁªÉ‰π†È¢òÁõÆÔºöÊñêÊ≥¢ÈÇ£Â•ëÊï∞Âàó / ÂÆåÁæéÊï∞ / Á¥†Êï∞Day06 - ÂáΩÊï∞ÂíåÊ®°ÂùóÁöÑ‰ΩøÁî®ÂáΩÊï∞ÁöÑ‰ΩúÁî® - ‰ª£Á†ÅÁöÑÂùèÂë≥ÈÅì / Áî®ÂáΩÊï∞Â∞ÅË£ÖÂäüËÉΩÊ®°ÂùóÂÆö‰πâÂáΩÊï∞ - defÂÖ≥ÈîÆÂ≠ó / ÂáΩÊï∞Âêç / ÂèÇÊï∞ÂàóË°® / returnËØ≠Âè• / Ë∞ÉÁî®Ëá™ÂÆö‰πâÂáΩÊï∞Ë∞ÉÁî®ÂáΩÊï∞ - PythonÂÜÖÁΩÆÂáΩÊï∞ /  ÂØºÂÖ•Ê®°ÂùóÂíåÂáΩÊï∞ÂáΩÊï∞ÁöÑÂèÇÊï∞ - ÈªòËÆ§ÂèÇÊï∞ / ÂèØÂèòÂèÇÊï∞ / ÂÖ≥ÈîÆÂ≠óÂèÇÊï∞ / ÂëΩÂêçÂÖ≥ÈîÆÂ≠óÂèÇÊï∞ÂáΩÊï∞ÁöÑËøîÂõûÂÄº - Ê≤°ÊúâËøîÂõûÂÄº  / ËøîÂõûÂçï‰∏™ÂÄº / ËøîÂõûÂ§ö‰∏™ÂÄº‰ΩúÁî®ÂüüÈóÆÈ¢ò - Â±ÄÈÉ®‰ΩúÁî®Âüü / ÂµåÂ•ó‰ΩúÁî®Âüü / ÂÖ®Â±Ä‰ΩúÁî®Âüü / ÂÜÖÁΩÆ‰ΩúÁî®Âüü / Âíå‰ΩúÁî®ÂüüÁõ∏ÂÖ≥ÁöÑÂÖ≥ÈîÆÂ≠óÁî®Ê®°ÂùóÁÆ°ÁêÜÂáΩÊï∞ - Ê®°ÂùóÁöÑÊ¶ÇÂøµ / Áî®Ëá™ÂÆö‰πâÊ®°ÂùóÁÆ°ÁêÜÂáΩÊï∞ / ÂëΩÂêçÂÜ≤Á™ÅÁöÑÊó∂ÂÄô‰ºöÊÄéÊ†∑ÔºàÂêå‰∏Ä‰∏™Ê®°ÂùóÂíå‰∏çÂêåÁöÑÊ®°ÂùóÔºâDay07 - Â≠óÁ¨¶‰∏≤ÂíåÂ∏∏Áî®Êï∞ÊçÆÁªìÊûÑÂ≠óÁ¨¶‰∏≤ÁöÑ‰ΩøÁî® - ËÆ°ÁÆóÈïøÂ∫¶ / ‰∏ãÊ†áËøêÁÆó / ÂàáÁâá / Â∏∏Áî®ÊñπÊ≥ïÂàóË°®Âü∫Êú¨Áî®Ê≥ï - ÂÆö‰πâÂàóË°® / Áî®‰∏ãË°®ËÆøÈóÆÂÖÉÁ¥† / ‰∏ãÊ†áË∂äÁïå / Ê∑ªÂä†ÂÖÉÁ¥† / Âà†Èô§ÂÖÉÁ¥† / ‰øÆÊîπÂÖÉÁ¥† / ÂàáÁâá / Âæ™ÁéØÈÅçÂéÜÂàóË°®Â∏∏Áî®Êìç‰Ωú - ËøûÊé• / Â§çÂà∂(Â§çÂà∂ÂÖÉÁ¥†ÂíåÂ§çÂà∂Êï∞ÁªÑ) / ÈïøÂ∫¶ / ÊéíÂ∫è / ÂÄíËΩ¨ / Êü•ÊâæÁîüÊàêÂàóË°® - ‰ΩøÁî®rangeÂàõÂª∫Êï∞Â≠óÂàóË°® / ÁîüÊàêË°®ËææÂºè / ÁîüÊàêÂô®ÂÖÉÁªÑÁöÑ‰ΩøÁî® - ÂÆö‰πâÂÖÉÁªÑ / ‰ΩøÁî®ÂÖÉÁªÑ‰∏≠ÁöÑÂÄº / ‰øÆÊîπÂÖÉÁªÑÂèòÈáè / ÂÖÉÁªÑÂíåÂàóË°®ËΩ¨Êç¢ÈõÜÂêàÂü∫Êú¨Áî®Ê≥ï - ÈõÜÂêàÂíåÂàóË°®ÁöÑÂå∫Âà´ /  ÂàõÂª∫ÈõÜÂêà / Ê∑ªÂä†ÂÖÉÁ¥† / Âà†Èô§ÂÖÉÁ¥† /  Ê∏ÖÁ©∫ÈõÜÂêàÂ∏∏Áî®Êìç‰Ωú - ‰∫§ÈõÜ / Âπ∂ÈõÜ / Â∑ÆÈõÜ / ÂØπÁß∞Â∑Æ / Â≠êÈõÜ / Ë∂ÖÈõÜÂ≠óÂÖ∏ÁöÑÂü∫Êú¨Áî®Ê≥ï - Â≠óÂÖ∏ÁöÑÁâπÁÇπ / ÂàõÂª∫Â≠óÂÖ∏ / Ê∑ªÂä†ÂÖÉÁ¥† / Âà†Èô§ÂÖÉÁ¥† / ÂèñÂÄº / Ê∏ÖÁ©∫Â≠óÂÖ∏Â∏∏Áî®Êìç‰Ωú - keysÊñπÊ≥ï / valuesÊñπÊ≥ï / itemsÊñπÊ≥ï / setdefaultÊñπÊ≥ïÂü∫Á°ÄÁªÉ‰π† - Ë∑ëÈ©¨ÁÅØÊïàÊûú / ÂàóË°®ÊâæÊúÄÂ§ßÂÖÉÁ¥† / ÁªüËÆ°ËÄÉËØïÊàêÁª©ÁöÑÂπ≥ÂùáÂàÜ / FibonacciÊï∞Âàó / Êù®Ëæâ‰∏âËßíÁªºÂêàÊ°à‰æã - ÂèåËâ≤ÁêÉÈÄâÂè∑ / ‰∫ïÂ≠óÊ£ãDay08 - Èù¢ÂêëÂØπË±°ÁºñÁ®ãÂü∫Á°ÄÁ±ªÂíåÂØπË±° - ‰ªÄ‰πàÊòØÁ±ª / ‰ªÄ‰πàÊòØÂØπË±° / Èù¢ÂêëÂØπË±°ÂÖ∂‰ªñÁõ∏ÂÖ≥Ê¶ÇÂøµÂÆö‰πâÁ±ª - Âü∫Êú¨ÁªìÊûÑ / Â±ûÊÄßÂíåÊñπÊ≥ï / ÊûÑÈÄ†Âô® / ÊûêÊûÑÂô® / __str__ÊñπÊ≥ï‰ΩøÁî®ÂØπË±° - ÂàõÂª∫ÂØπË±° / ÁªôÂØπË±°ÂèëÊ∂àÊÅØÈù¢ÂêëÂØπË±°ÁöÑÂõõÂ§ßÊîØÊü± - ÊäΩË±° / Â∞ÅË£Ö / ÁªßÊâø / Â§öÊÄÅÂü∫Á°ÄÁªÉ‰π† - ÂÆö‰πâÂ≠¶ÁîüÁ±ª / ÂÆö‰πâÊó∂ÈíüÁ±ª / ÂÆö‰πâÂõæÂΩ¢Á±ª / ÂÆö‰πâÊ±ΩËΩ¶Á±ªDay09 - Èù¢ÂêëÂØπË±°ËøõÈò∂Â±ûÊÄß - Á±ªÂ±ûÊÄß / ÂÆû‰æãÂ±ûÊÄß / Â±ûÊÄßËÆøÈóÆÂô® / Â±ûÊÄß‰øÆÊîπÂô® / Â±ûÊÄßÂà†Èô§Âô® / ‰ΩøÁî®__slots__Á±ª‰∏≠ÁöÑÊñπÊ≥ï - ÂÆû‰æãÊñπÊ≥ï / Á±ªÊñπÊ≥ï / ÈùôÊÄÅÊñπÊ≥ïËøêÁÆóÁ¨¶ÈáçËΩΩ - __add__ / __sub__ / __or__ /__getitem__ / __setitem__ / __len__ / __repr__ / __gt__ / __lt__ / __le__ / __ge__ / __eq__ / __ne__ / __contains__Á±ª(ÁöÑÂØπË±°)‰πãÈó¥ÁöÑÂÖ≥Á≥ª - ÂÖ≥ËÅî / ÁªßÊâø / ‰æùËµñÁªßÊâøÂíåÂ§öÊÄÅ - ‰ªÄ‰πàÊòØÁªßÊâø / ÁªßÊâøÁöÑËØ≠Ê≥ï / Ë∞ÉÁî®Áà∂Á±ªÊñπÊ≥ï / ÊñπÊ≥ïÈáçÂÜô / Á±ªÂûãÂà§ÂÆö / Â§öÈáçÁªßÊâø / Ëè±ÂΩ¢ÁªßÊâø(ÈíªÁü≥ÁªßÊâø)ÂíåC3ÁÆóÊ≥ïÁªºÂêàÊ°à‰æã - Â∑•ËµÑÁªìÁÆóÁ≥ªÁªü / Âõæ‰π¶Ëá™Âä®ÊäòÊâ£Á≥ªÁªü / Ëá™ÂÆö‰πâÂàÜÊï∞Á±ªDay10 - ÂõæÂΩ¢Áî®Êà∑ÁïåÈù¢ÂíåÊ∏∏ÊàèÂºÄÂèë‰ΩøÁî®tkinterÂºÄÂèëGUIÁ®ãÂ∫è‰ΩøÁî®pygame‰∏âÊñπÂ∫ìÂºÄÂèëÊ∏∏ÊàèÂ∫îÁî®‚ÄúÂ§ßÁêÉÂêÉÂ∞èÁêÉ‚ÄùÊ∏∏ÊàèDay11 - Êñá‰ª∂ÂíåÂºÇÂ∏∏ËØªÊñá‰ª∂ - ËØªÂèñÊï¥‰∏™Êñá‰ª∂ / ÈÄêË°åËØªÂèñ / Êñá‰ª∂Ë∑ØÂæÑÂÜôÊñá‰ª∂ - Ë¶ÜÁõñÂÜôÂÖ• / ËøΩÂä†ÂÜôÂÖ• / ÊñáÊú¨Êñá‰ª∂ / ‰∫åËøõÂà∂Êñá‰ª∂ÂºÇÂ∏∏Â§ÑÁêÜ - ÂºÇÂ∏∏Êú∫Âà∂ÁöÑÈáçË¶ÅÊÄß / try-except‰ª£Á†ÅÂùó / else‰ª£Á†ÅÂùó / finally‰ª£Á†ÅÂùó / ÂÜÖÁΩÆÂºÇÂ∏∏Á±ªÂûã / ÂºÇÂ∏∏Ê†à / raiseËØ≠Âè•Êï∞ÊçÆÊåÅ‰πÖÂåñ - CSVÊñá‰ª∂Ê¶ÇËø∞ / csvÊ®°ÂùóÁöÑÂ∫îÁî® / JSONÊï∞ÊçÆÊ†ºÂºè / jsonÊ®°ÂùóÁöÑÂ∫îÁî®Day12 - Â≠óÁ¨¶‰∏≤ÂíåÊ≠£ÂàôË°®ËææÂºèÂ≠óÁ¨¶‰∏≤È´òÁ∫ßÊìç‰Ωú - ËΩ¨‰πâÂ≠óÁ¨¶ / ÂéüÂßãÂ≠óÁ¨¶‰∏≤ / Â§öË°åÂ≠óÁ¨¶‰∏≤ / inÂíånot inËøêÁÆóÁ¨¶ / is_xxxÊñπÊ≥ï / joinÂíåsplitÊñπÊ≥ï / stripÁõ∏ÂÖ≥ÊñπÊ≥ï / pyperclipÊ®°Âùó / ‰∏çÂèòÂ≠óÁ¨¶‰∏≤ÂíåÂèØÂèòÂ≠óÁ¨¶‰∏≤ / StringIOÁöÑ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÂÖ•Èó® - Ê≠£ÂàôË°®ËææÂºèÁöÑ‰ΩúÁî® / ÂÖÉÂ≠óÁ¨¶ / ËΩ¨‰πâ / ÈáèËØç / ÂàÜÁªÑ / Èõ∂ÂÆΩÊñ≠Ë®Ä /Ë¥™Â©™ÂåπÈÖç‰∏éÊÉ∞ÊÄßÂåπÈÖçÊáíÊÉ∞ / ‰ΩøÁî®reÊ®°ÂùóÂÆûÁé∞Ê≠£ÂàôË°®ËææÂºèÊìç‰ΩúÔºàÂåπÈÖç„ÄÅÊêúÁ¥¢„ÄÅÊõøÊç¢„ÄÅÊçïËé∑Ôºâ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºè - reÊ®°Âùó / compileÂáΩÊï∞ / groupÂíågroupsÊñπÊ≥ï / matchÊñπÊ≥ï / searchÊñπÊ≥ï / findallÂíåfinditerÊñπÊ≥ï / subÂíåsubnÊñπÊ≥ï / splitÊñπÊ≥ïÂ∫îÁî®Ê°à‰æã - ‰ΩøÁî®Ê≠£ÂàôË°®ËææÂºèÈ™åËØÅËæìÂÖ•ÁöÑÂ≠óÁ¨¶‰∏≤Day13 - ËøõÁ®ãÂíåÁ∫øÁ®ãËøõÁ®ãÂíåÁ∫øÁ®ãÁöÑÊ¶ÇÂøµ - ‰ªÄ‰πàÊòØËøõÁ®ã / ‰ªÄ‰πàÊòØÁ∫øÁ®ã / Â§öÁ∫øÁ®ãÁöÑÂ∫îÁî®Âú∫ÊôØ‰ΩøÁî®ËøõÁ®ã - forkÂáΩÊï∞ / multiprocessingÊ®°Âùó / ËøõÁ®ãÊ±† / ËøõÁ®ãÈó¥ÈÄö‰ø°‰ΩøÁî®Á∫øÁ®ã -  threadingÊ®°Âùó / ThreadÁ±ª / RLockÁ±ª / ConditionÁ±ª / Á∫øÁ®ãÊ±†Day14 - ÁΩëÁªúÁºñÁ®ãÂÖ•Èó®ÂíåÁΩëÁªúÂ∫îÁî®ÂºÄÂèëËÆ°ÁÆóÊú∫ÁΩëÁªúÂü∫Á°Ä - ËÆ°ÁÆóÊú∫ÁΩëÁªúÂèëÂ±ïÂè≤ / ‚ÄúTCP-IP‚ÄùÊ®°Âûã / IPÂú∞ÂùÄ / Á´ØÂè£ / ÂçèËÆÆ / ÂÖ∂‰ªñÁõ∏ÂÖ≥Ê¶ÇÂøµÁΩëÁªúÂ∫îÁî®Ê®°Âºè - ‚ÄúÂÆ¢Êà∑Á´Ø-ÊúçÂä°Âô®‚ÄùÊ®°Âºè / ‚ÄúÊµèËßàÂô®-ÊúçÂä°Âô®‚ÄùÊ®°ÂºèÂü∫‰∫éHTTPÂçèËÆÆËÆøÈóÆÁΩëÁªúËµÑÊ∫ê - ÁΩëÁªúAPIÊ¶ÇËø∞ / ËÆøÈóÆURL / requests‰∏âÊñπÂ∫ì / Ëß£ÊûêJSONÊ†ºÂºèÊï∞ÊçÆPythonÁΩëÁªúÁºñÁ®ã - Â•óÊé•Â≠óÁöÑÊ¶ÇÂøµ / socketÊ®°Âùó /  socketÂáΩÊï∞ / ÂàõÂª∫TCPÊúçÂä°Âô® / ÂàõÂª∫TCPÂÆ¢Êà∑Á´Ø / ÂàõÂª∫UDPÊúçÂä°Âô® / ÂàõÂª∫UDPÂÆ¢Êà∑Á´ØÁîµÂ≠êÈÇÆ‰ª∂ - SMTPÂçèËÆÆ / POP3ÂçèËÆÆ / IMAPÂçèËÆÆ / smtplibÊ®°Âùó / poplibÊ®°Âùó / imaplibÊ®°ÂùóÁü≠‰ø°ÊúçÂä° - Ë∞ÉÁî®Áü≠‰ø°ÊúçÂä°ÁΩëÂÖ≥Day15 - ÂõæÂÉèÂíåÊñáÊ°£Â§ÑÁêÜÁî®PillowÂ§ÑÁêÜÂõæÁâá - ÂõæÁâáËØªÂÜô / ÂõæÁâáÂêàÊàê / Âá†‰ΩïÂèòÊç¢ / Ëâ≤ÂΩ©ËΩ¨Êç¢ / Êª§ÈïúÊïàÊûúËØªÂÜôWordÊñáÊ°£ - ÊñáÊú¨ÂÜÖÂÆπÁöÑÂ§ÑÁêÜ / ÊÆµËêΩ / È°µÁúâÂíåÈ°µËÑö / Ê†∑ÂºèÁöÑÂ§ÑÁêÜËØªÂÜôExcelÊñá‰ª∂ - xlrd / xlwt / openpyxlDay16~Day20 - PythonËØ≠Ë®ÄËøõÈò∂ Â∏∏Áî®Êï∞ÊçÆÁªìÊûÑÂáΩÊï∞ÁöÑÈ´òÁ∫ßÁî®Ê≥ï - ‚Äú‰∏ÄÁ≠âÂÖ¨Ê∞ë‚Äù / È´òÈò∂ÂáΩÊï∞ / LambdaÂáΩÊï∞ / ‰ΩúÁî®ÂüüÂíåÈó≠ÂåÖ / Ë£ÖÈ•∞Âô®Èù¢ÂêëÂØπË±°È´òÁ∫ßÁü•ËØÜ - ‚Äú‰∏âÂ§ßÊîØÊü±‚Äù / Á±ª‰∏éÁ±ª‰πãÈó¥ÁöÑÂÖ≥Á≥ª / ÂûÉÂúæÂõûÊî∂ / È≠îÊúØÂ±ûÊÄßÂíåÊñπÊ≥ï / Ê∑∑ÂÖ• / ÂÖÉÁ±ª / Èù¢ÂêëÂØπË±°ËÆæËÆ°ÂéüÂàô / GoFËÆæËÆ°Ê®°ÂºèËø≠‰ª£Âô®ÂíåÁîüÊàêÂô® - Áõ∏ÂÖ≥È≠îÊúØÊñπÊ≥ï / ÂàõÂª∫ÁîüÊàêÂô®ÁöÑ‰∏§ÁßçÊñπÂºè /Âπ∂ÂèëÂíåÂºÇÊ≠•ÁºñÁ®ã - Â§öÁ∫øÁ®ã / Â§öËøõÁ®ã / ÂºÇÊ≠•IO / asyncÂíåawaitDay21~30 - WebÂâçÁ´ØÂÖ•Èó®Áî®HTMLÊ†áÁ≠æÊâøËΩΩÈ°µÈù¢ÂÜÖÂÆπÁî®CSSÊ∏≤ÊüìÈ°µÈù¢Áî®JavaScriptÂ§ÑÁêÜ‰∫§‰∫íÂºèË°å‰∏∫jQueryÂÖ•Èó®ÂíåÊèêÈ´òVue.jsÂÖ•Èó®ElementÁöÑ‰ΩøÁî®BootstrapÁöÑ‰ΩøÁî®Day31~35 - Áé©ËΩ¨LinuxÊìç‰ΩúÁ≥ªÁªüÊìç‰ΩúÁ≥ªÁªüÂèëÂ±ïÂè≤ÂíåLinuxÊ¶ÇËø∞LinuxÂü∫Á°ÄÂëΩ‰ª§Linux‰∏≠ÁöÑÂÆûÁî®Á®ãÂ∫èLinuxÁöÑÊñá‰ª∂Á≥ªÁªüVimÁºñËæëÂô®ÁöÑÂ∫îÁî®ÁéØÂ¢ÉÂèòÈáèÂíåShellÁºñÁ®ãËΩØ‰ª∂ÁöÑÂÆâË£ÖÂíåÊúçÂä°ÁöÑÈÖçÁΩÆÁΩëÁªúËÆøÈóÆÂíåÁÆ°ÁêÜÂÖ∂‰ªñÁõ∏ÂÖ≥ÂÜÖÂÆπDay36~40 - Êï∞ÊçÆÂ∫ìÂü∫Á°ÄÂíåËøõÈò∂ÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÊ¶ÇËø∞MySQLÁöÑÂÆâË£ÖÂíå‰ΩøÁî®SQLÁöÑ‰ΩøÁî®DDL - Êï∞ÊçÆÂÆö‰πâËØ≠Ë®Ä - create / drop / alterDML - Êï∞ÊçÆÊìç‰ΩúËØ≠Ë®Ä - insert / delete / updateDQL - Êï∞ÊçÆÊü•ËØ¢ËØ≠Ë®Ä - selectDCL - Êï∞ÊçÆÊéßÂà∂ËØ≠Ë®Ä - grant / revokeMySQLÊñ∞ÁâπÊÄßÁ™óÂè£ÂáΩÊï∞ÁöÑÂ∫îÁî®JSONÊï∞ÊçÆÁ±ªÂûãÁõ∏ÂÖ≥Áü•ËØÜÊï∞ÊçÆÂÆåÊï¥ÊÄßÂíå‰∏ÄËá¥ÊÄßËßÜÂõæ„ÄÅÂáΩÊï∞„ÄÅËøáÁ®ã„ÄÅËß¶ÂèëÂô®‰∫ãÂä°ÂíåÈîÅÊâßË°åËÆ°ÂàíÂíåÁ¥¢ÂºïËåÉÂºèÁêÜËÆ∫ÂíåÂèçËåÉÂºèËÆæËÆ°Âú®Python‰∏≠Êìç‰ΩúMySQLDay41~55 - ÂÆûÊàòDjangoDay41 - DjangoÂø´ÈÄü‰∏äÊâãWebÂ∫îÁî®Â∑•‰ΩúÊú∫Âà∂HTTPËØ∑Ê±ÇÂíåÂìçÂ∫îDjangoÊ°ÜÊû∂Ê¶ÇËø∞5ÂàÜÈíüÂø´ÈÄü‰∏äÊâãDay42 - Ê∑±ÂÖ•Ê®°ÂûãÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÈÖçÁΩÆ‰ΩøÁî®ORMÂÆåÊàêÂØπÊ®°ÂûãÁöÑCRUDÊìç‰ΩúÁÆ°ÁêÜÂêéÂè∞ÁöÑ‰ΩøÁî®DjangoÊ®°ÂûãÊúÄ‰Ω≥ÂÆûË∑µÊ®°ÂûãÂÆö‰πâÂèÇËÄÉDay43 - ÈùôÊÄÅËµÑÊ∫êÂíåAjaxËØ∑Ê±ÇÂä†ËΩΩÈùôÊÄÅËµÑÊ∫êAjaxÊ¶ÇËø∞Áî®AjaxÂÆûÁé∞ÊäïÁ•®ÂäüËÉΩDay44 - CookieÂíåSessionÂÆûÁé∞Áî®Êà∑Ë∑üË∏™cookieÂíåsessionÁöÑÂÖ≥Á≥ªDjangoÊ°ÜÊû∂ÂØπsessionÁöÑÊîØÊåÅËßÜÂõæÂáΩÊï∞‰∏≠ÁöÑcookieËØªÂÜôÊìç‰ΩúDay45 - Êä•Ë°®ÂíåÊó•ÂøóÈÄöËøáHttpResponse‰øÆÊîπÂìçÂ∫îÂ§¥‰ΩøÁî®StreamingHttpResponseÂ§ÑÁêÜÂ§ßÊñá‰ª∂‰ΩøÁî®xlwtÁîüÊàêExcelÊä•Ë°®‰ΩøÁî®reportlabÁîüÊàêPDFÊä•Ë°®‰ΩøÁî®EChartsÁîüÊàêÂâçÁ´ØÂõæË°®Day46 - Êó•ÂøóÂíåË∞ÉËØïÂ∑•ÂÖ∑Ê†èÈÖçÁΩÆÊó•ÂøóÈÖçÁΩÆDjango-Debug-Toolbar‰ºòÂåñORM‰ª£Á†ÅDay47 - ‰∏≠Èó¥‰ª∂ÁöÑÂ∫îÁî®‰ªÄ‰πàÊòØ‰∏≠Èó¥‰ª∂DjangoÊ°ÜÊû∂ÂÜÖÁΩÆÁöÑ‰∏≠Èó¥‰ª∂Ëá™ÂÆö‰πâ‰∏≠Èó¥‰ª∂ÂèäÂÖ∂Â∫îÁî®Âú∫ÊôØDay48 - ÂâçÂêéÁ´ØÂàÜÁ¶ªÂºÄÂèëÂÖ•Èó®ËøîÂõûJSONÊ†ºÂºèÁöÑÊï∞ÊçÆÁî®Vue.jsÊ∏≤ÊüìÈ°µÈù¢Day49 - RESTfulÊû∂ÊûÑÂíåDRFÂÖ•Èó®Day50 - RESTfulÊû∂ÊûÑÂíåDRFËøõÈò∂Day51 - ‰ΩøÁî®ÁºìÂ≠òÁΩëÁ´ô‰ºòÂåñÁ¨¨‰∏ÄÂÆöÂæãÂú®DjangoÈ°πÁõÆ‰∏≠‰ΩøÁî®RedisÊèê‰æõÁºìÂ≠òÊúçÂä°Âú®ËßÜÂõæÂáΩÊï∞‰∏≠ËØªÂÜôÁºìÂ≠ò‰ΩøÁî®Ë£ÖÈ•∞Âô®ÂÆûÁé∞È°µÈù¢ÁºìÂ≠ò‰∏∫Êï∞ÊçÆÊé•Âè£Êèê‰æõÁºìÂ≠òÊúçÂä°Day52 - Êé•ÂÖ•‰∏âÊñπÂπ≥Âè∞Êñá‰ª∂‰∏ä‰º†Ë°®ÂçïÊéß‰ª∂ÂíåÂõæÁâáÊñá‰ª∂È¢ÑËßàÊúçÂä°Âô®Á´ØÂ¶Ç‰ΩïÂ§ÑÁêÜ‰∏ä‰º†ÁöÑÊñá‰ª∂Day53 - ÂºÇÊ≠•‰ªªÂä°ÂíåÂÆöÊó∂‰ªªÂä°ÁΩëÁ´ô‰ºòÂåñÁ¨¨‰∫åÂÆöÂæãÈÖçÁΩÆÊ∂àÊÅØÈòüÂàóÊúçÂä°Âú®È°πÁõÆ‰∏≠‰ΩøÁî®CeleryÂÆûÁé∞‰ªªÂä°ÂºÇÊ≠•ÂåñÂú®È°πÁõÆ‰∏≠‰ΩøÁî®CeleryÂÆûÁé∞ÂÆöÊó∂‰ªªÂä°Day54 - ÂçïÂÖÉÊµãËØïDay55 - È°πÁõÆ‰∏äÁ∫øPython‰∏≠ÁöÑÂçïÂÖÉÊµãËØïDjangoÊ°ÜÊû∂ÂØπÂçïÂÖÉÊµãËØïÁöÑÊîØÊåÅ‰ΩøÁî®ÁâàÊú¨ÊéßÂà∂Á≥ªÁªüÈÖçÁΩÆÂíå‰ΩøÁî®uWSGIÂä®ÈùôÂàÜÁ¶ªÂíåNginxÈÖçÁΩÆÈÖçÁΩÆHTTPSÈÖçÁΩÆÂüüÂêçËß£ÊûêDay56~60 - Áî®FastAPIÂºÄÂèëÊï∞ÊçÆÊé•Âè£FastAPI‰∫îÂàÜÈíü‰∏äÊâãËØ∑Ê±ÇÂíåÂìçÂ∫îÊé•ÂÖ•ÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ì‰æùËµñÊ≥®ÂÖ•‰∏≠Èó¥‰ª∂ÂºÇÊ≠•ÂåñËôöÊãüÂåñÈÉ®ÁΩ≤ÔºàDockerÔºâÈ°πÁõÆÂÆûÊàòÔºöËΩ¶ËæÜËøùÁ´†Êü•ËØ¢È°πÁõÆDay61~65 - Áà¨Ëô´ÂºÄÂèëDay61 - ÁΩëÁªúÊï∞ÊçÆÈááÈõÜÊ¶ÇËø∞ÁΩëÁªúÁà¨Ëô´ÁöÑÊ¶ÇÂøµÂèäÂÖ∂Â∫îÁî®È¢ÜÂüüÁΩëÁªúÁà¨Ëô´ÁöÑÂêàÊ≥ïÊÄßÊé¢ËÆ®ÂºÄÂèëÁΩëÁªúÁà¨Ëô´ÁöÑÁõ∏ÂÖ≥Â∑•ÂÖ∑‰∏Ä‰∏™Áà¨Ëô´Á®ãÂ∫èÁöÑÊûÑÊàêDay62 - Êï∞ÊçÆÊäìÂèñÂíåËß£Êûê‰ΩøÁî®requests‰∏âÊñπÂ∫ìÂÆûÁé∞Êï∞ÊçÆÊäìÂèñÈ°µÈù¢Ëß£ÊûêÁöÑ‰∏âÁßçÊñπÂºèÊ≠£ÂàôË°®ËææÂºèËß£ÊûêXPathËß£ÊûêCSSÈÄâÊã©Âô®Ëß£ÊûêDay63 - Python‰∏≠ÁöÑÂπ∂ÂèëÁºñÁ®ãÂ§öÁ∫øÁ®ãÂ§öËøõÁ®ãÂºÇÊ≠•I/ODay64 - ‰ΩøÁî®SeleniumÊäìÂèñÁΩëÈ°µÂä®ÊÄÅÂÜÖÂÆπDay65 - Áà¨Ëô´Ê°ÜÊû∂ScrapyÁÆÄ‰ªãDay66~80 - Êï∞ÊçÆÂàÜÊûêDay66 - Êï∞ÊçÆÂàÜÊûêÊ¶ÇËø∞Day67 - ÁéØÂ¢ÉÂáÜÂ§áDay68 - NumPyÁöÑÂ∫îÁî®-1Day69 - NumPyÁöÑÂ∫îÁî®-2Day70 - PandasÁöÑÂ∫îÁî®-1Day71 - PandasÁöÑÂ∫îÁî®-2Day72 - PandasÁöÑÂ∫îÁî®-3Day73 - PandasÁöÑÂ∫îÁî®-4Day74 - PandasÁöÑÂ∫îÁî®-5Day75 - Êï∞ÊçÆÂèØËßÜÂåñ-1Day76 - Êï∞ÊçÆÂèØËßÜÂåñ-2Day77 - Ê¶ÇÁéáÁªüËÆ°Âü∫Á°ÄDay78 - ÊñπÂ∑ÆÂàÜÊûêÂíåÂèÇÊï∞‰º∞ËÆ°Day79 - Áõ∏ÂÖ≥ÂíåÂõûÂΩíDay80 - Êï∞ÊçÆÂàÜÊûêÊñπÊ≥ïËÆ∫Day81~90 - Êú∫Âô®Â≠¶‰π†ÂíåÊ∑±Â∫¶Â≠¶‰π†Day81 - Êú∫Âô®Â≠¶‰π†Âü∫Á°ÄDay82 - kÊúÄËøëÈÇªÂàÜÁ±ªDay83 - ÂÜ≥Á≠ñÊ†ëDay84 - Ë¥ùÂè∂ÊñØÂàÜÁ±ªDay85 - ÊîØÊåÅÂêëÈáèÊú∫Day86 - K-ÂùáÂÄºËÅöÁ±ªDay87 - ÂõûÂΩíÂàÜÊûêDay88 - Ê∑±Â∫¶Â≠¶‰π†ÂÖ•Èó®Day89 - PyTorchÊ¶ÇËø∞Day90 - PyTorchÂÆûÊàòDay91~100 - Âõ¢ÈòüÈ°πÁõÆÂºÄÂèëÁ¨¨91Â§©ÔºöÂõ¢ÈòüÈ°πÁõÆÂºÄÂèëÁöÑÈóÆÈ¢òÂíåËß£ÂÜ≥ÊñπÊ°àËΩØ‰ª∂ËøáÁ®ãÊ®°ÂûãÁªèÂÖ∏ËøáÁ®ãÊ®°ÂûãÔºàÁÄëÂ∏ÉÊ®°ÂûãÔºâÂèØË°åÊÄßÂàÜÊûêÔºàÁ†îÁ©∂ÂÅöËøòÊòØ‰∏çÂÅöÔºâÔºåËæìÂá∫„ÄäÂèØË°åÊÄßÂàÜÊûêÊä•Âëä„Äã„ÄÇÈúÄÊ±ÇÂàÜÊûêÔºàÁ†îÁ©∂ÂÅö‰ªÄ‰πàÔºâÔºåËæìÂá∫„ÄäÈúÄÊ±ÇËßÑÊ†ºËØ¥Êòé‰π¶„ÄãÂíå‰∫ßÂìÅÁïåÈù¢ÂéüÂûãÂõæ„ÄÇÊ¶ÇË¶ÅËÆæËÆ°ÂíåËØ¶ÁªÜËÆæËÆ°ÔºåËæìÂá∫Ê¶ÇÂøµÊ®°ÂûãÂõæÔºàERÂõæÔºâ„ÄÅÁâ©ÁêÜÊ®°ÂûãÂõæ„ÄÅÁ±ªÂõæ„ÄÅÊó∂Â∫èÂõæÁ≠â„ÄÇÁºñÁ†Å / ÊµãËØï„ÄÇ‰∏äÁ∫ø / Áª¥Êä§„ÄÇÁÄëÂ∏ÉÊ®°ÂûãÊúÄÂ§ßÁöÑÁº∫ÁÇπÊòØÊó†Ê≥ïÊã•Êä±ÈúÄÊ±ÇÂèòÂåñÔºåÊï¥Â•óÊµÅÁ®ãÁªìÊùüÂêéÊâçËÉΩÁúãÂà∞‰∫ßÂìÅÔºåÂõ¢ÈòüÂ£´Ê∞î‰ΩéËêΩ„ÄÇÊïèÊç∑ÂºÄÂèëÔºàScrumÔºâ- ‰∫ßÂìÅÊâÄÊúâËÄÖ„ÄÅScrum Master„ÄÅÁ†îÂèë‰∫∫Âëò - Sprint‰∫ßÂìÅÁöÑBacklogÔºàÁî®Êà∑ÊïÖ‰∫ã„ÄÅ‰∫ßÂìÅÂéüÂûãÔºâ„ÄÇËÆ°Âàí‰ºöËÆÆÔºàËØÑ‰º∞ÂíåÈ¢ÑÁÆóÔºâ„ÄÇÊó•Â∏∏ÂºÄÂèëÔºàÁ´ôÁ´ã‰ºöËÆÆ„ÄÅÁï™ËåÑÂ∑•‰ΩúÊ≥ï„ÄÅÁªìÂØπÁºñÁ®ã„ÄÅÊµãËØïÂÖàË°å„ÄÅ‰ª£Á†ÅÈáçÊûÑ‚Ä¶‚Ä¶Ôºâ„ÄÇ‰øÆÂ§çbugÔºàÈóÆÈ¢òÊèèËø∞„ÄÅÈáçÁé∞Ê≠•È™§„ÄÅÊµãËØï‰∫∫Âëò„ÄÅË¢´ÊåáÊ¥æ‰∫∫Ôºâ„ÄÇÂèëÂ∏ÉÁâàÊú¨„ÄÇËØÑÂÆ°‰ºöËÆÆÔºàShowcaseÔºåÁî®Êà∑ÈúÄË¶ÅÂèÇ‰∏éÔºâ„ÄÇÂõûÈ°æ‰ºöËÆÆÔºàÂØπÂΩìÂâçËø≠‰ª£Âë®ÊúüÂÅö‰∏Ä‰∏™ÊÄªÁªìÔºâ„ÄÇË°•ÂÖÖÔºöÊïèÊç∑ËΩØ‰ª∂ÂºÄÂèëÂÆ£Ë®Ä‰∏™‰ΩìÂíå‰∫íÂä® È´ò‰∫é ÊµÅÁ®ãÂíåÂ∑•ÂÖ∑Â∑•‰ΩúÁöÑËΩØ‰ª∂ È´ò‰∫é ËØ¶Â∞ΩÁöÑÊñáÊ°£ÂÆ¢Êà∑Âêà‰Ωú È´ò‰∫é ÂêàÂêåË∞àÂà§ÂìçÂ∫îÂèòÂåñ È´ò‰∫é ÈÅµÂæ™ËÆ°ÂàíËßíËâ≤Ôºö‰∫ßÂìÅÊâÄÊúâËÄÖÔºàÂÜ≥ÂÆöÂÅö‰ªÄ‰πàÔºåËÉΩÂØπÈúÄÊ±ÇÊãçÊùøÁöÑ‰∫∫Ôºâ„ÄÅÂõ¢ÈòüË¥üË¥£‰∫∫ÔºàËß£ÂÜ≥ÂêÑÁßçÈóÆÈ¢òÔºå‰∏ìÊ≥®Â¶Ç‰ΩïÊõ¥Â•ΩÁöÑÂ∑•‰ΩúÔºåÂ±èËîΩÂ§ñÈÉ®ÂØπÂºÄÂèëÂõ¢ÈòüÁöÑÂΩ±ÂìçÔºâ„ÄÅÂºÄÂèëÂõ¢ÈòüÔºàÈ°πÁõÆÊâßË°å‰∫∫ÂëòÔºåÂÖ∑‰ΩìÊåáÂºÄÂèë‰∫∫ÂëòÂíåÊµãËØï‰∫∫ÂëòÔºâ„ÄÇÂáÜÂ§áÂ∑•‰ΩúÔºöÂïÜ‰∏öÊ°à‰æãÂíåËµÑÈáë„ÄÅÂêàÂêå„ÄÅÊÜßÊÜ¨„ÄÅÂàùÂßã‰∫ßÂìÅÈúÄÊ±Ç„ÄÅÂàùÂßãÂèëÂ∏ÉËÆ°Âàí„ÄÅÂÖ•ËÇ°„ÄÅÁªÑÂª∫Âõ¢Èòü„ÄÇÊïèÊç∑Âõ¢ÈòüÈÄöÂ∏∏‰∫∫Êï∞‰∏∫8-10‰∫∫„ÄÇÂ∑•‰ΩúÈáè‰º∞ÁÆóÔºöÂ∞ÜÂºÄÂèë‰ªªÂä°ÈáèÂåñÔºåÂåÖÊã¨ÂéüÂûã„ÄÅLogoËÆæËÆ°„ÄÅUIËÆæËÆ°„ÄÅÂâçÁ´ØÂºÄÂèëÁ≠âÔºåÂ∞ΩÈáèÊääÊØè‰∏™Â∑•‰ΩúÂàÜËß£Âà∞ÊúÄÂ∞è‰ªªÂä°ÈáèÔºåÊúÄÂ∞è‰ªªÂä°ÈáèÊ†áÂáÜ‰∏∫Â∑•‰ΩúÊó∂Èó¥‰∏çËÉΩË∂ÖËøá‰∏§Â§©ÔºåÁÑ∂Âêé‰º∞ÁÆóÊÄª‰ΩìÈ°πÁõÆÊó∂Èó¥„ÄÇÊääÊØè‰∏™‰ªªÂä°ÈÉΩË¥¥Âú®ÁúãÊùø‰∏äÈù¢ÔºåÁúãÊùø‰∏äÂàÜ‰∏âÈÉ®ÂàÜÔºöto doÔºàÂæÖÂÆåÊàêÔºâ„ÄÅin progressÔºàËøõË°å‰∏≠ÔºâÂíådoneÔºàÂ∑≤ÂÆåÊàêÔºâ„ÄÇÈ°πÁõÆÂõ¢ÈòüÁªÑÂª∫Âõ¢ÈòüÁöÑÊûÑÊàêÂíåËßíËâ≤ËØ¥ÊòéÔºöË∞¢Ë∞¢‰ªòÁ••Ëã±Â•≥Â£´Â∏ÆÂä©ÊàëÁªòÂà∂‰∫Ü‰∏ãÈù¢ËøôÂº†Á≤æÁæéÁöÑÂÖ¨Âè∏ÁªÑÁªáÊû∂ÊûÑÂõæ„ÄÇÁºñÁ®ãËßÑËåÉÂíå‰ª£Á†ÅÂÆ°Êü•Ôºàflake8„ÄÅpylintÔºâPython‰∏≠ÁöÑ‰∏Ä‰∫õ‚ÄúÊÉØ‰æã‚ÄùÔºàËØ∑ÂèÇËÄÉ„ÄäPythonÊÉØ‰æã-Â¶Ç‰ΩïÁºñÂÜôPythonicÁöÑ‰ª£Á†Å„ÄãÔºâÂΩ±Âìç‰ª£Á†ÅÂèØËØªÊÄßÁöÑÂéüÂõ†Ôºö‰ª£Á†ÅÊ≥®ÈáäÂ§™Â∞ëÊàñËÄÖÊ≤°ÊúâÊ≥®Èáä‰ª£Á†ÅÁ†¥Âùè‰∫ÜËØ≠Ë®ÄÁöÑÊúÄ‰Ω≥ÂÆûË∑µÂèçÊ®°ÂºèÁºñÁ®ãÔºàÊÑèÂ§ßÂà©Èù¢‰ª£Á†Å„ÄÅÂ§çÂà∂-ÈªèË¥¥ÁºñÁ®ã„ÄÅËá™Ë¥üÁºñÁ®ã„ÄÅ‚Ä¶‚Ä¶ÔºâÂõ¢ÈòüÂºÄÂèëÂ∑•ÂÖ∑‰ªãÁªçÁâàÊú¨ÊéßÂà∂ÔºöGit„ÄÅMercuryÁº∫Èô∑ÁÆ°ÁêÜÔºöGitlab„ÄÅRedmineÊïèÊç∑Èó≠ÁéØÂ∑•ÂÖ∑ÔºöÁ¶ÖÈÅì„ÄÅJIRAÊåÅÁª≠ÈõÜÊàêÔºöJenkins„ÄÅTravis-CIËØ∑ÂèÇËÄÉ„ÄäÂõ¢ÈòüÈ°πÁõÆÂºÄÂèëÁöÑÈóÆÈ¢òÂíåËß£ÂÜ≥ÊñπÊ°à„Äã„ÄÇÈ°πÁõÆÈÄâÈ¢òÂíåÁêÜËß£‰∏öÂä°ÈÄâÈ¢òËåÉÂõ¥ËÆæÂÆöCMSÔºàÁî®Êà∑Á´ØÔºâÔºöÊñ∞ÈóªËÅöÂêàÁΩëÁ´ô„ÄÅÈóÆÁ≠î/ÂàÜ‰∫´Á§æÂå∫„ÄÅÂΩ±ËØÑ/‰π¶ËØÑÁΩëÁ´ôÁ≠â„ÄÇMISÔºàÁî®Êà∑Á´Ø+ÁÆ°ÁêÜÁ´ØÔºâÔºöKMS„ÄÅKPIËÄÉÊ†∏Á≥ªÁªü„ÄÅHRS„ÄÅCRMÁ≥ªÁªü„ÄÅ‰æõÂ∫îÈìæÁ≥ªÁªü„ÄÅ‰ªìÂÇ®ÁÆ°ÁêÜÁ≥ªÁªüÁ≠â„ÄÇAppÂêéÂè∞ÔºàÁÆ°ÁêÜÁ´Ø+Êï∞ÊçÆÊé•Âè£ÔºâÔºö‰∫åÊâã‰∫§ÊòìÁ±ª„ÄÅÊä•ÂàäÊùÇÂøóÁ±ª„ÄÅÂ∞è‰ºóÁîµÂïÜÁ±ª„ÄÅÊñ∞ÈóªËµÑËÆØÁ±ª„ÄÅÊóÖÊ∏∏Á±ª„ÄÅÁ§æ‰∫§Á±ª„ÄÅÈòÖËØªÁ±ªÁ≠â„ÄÇÂÖ∂‰ªñÁ±ªÂûãÔºöËá™Ë∫´Ë°å‰∏öËÉåÊôØÂíåÂ∑•‰ΩúÁªèÈ™å„ÄÅ‰∏öÂä°ÂÆπÊòìÁêÜËß£ÂíåÊääÊéß„ÄÇÈúÄÊ±ÇÁêÜËß£„ÄÅÊ®°ÂùóÂàíÂàÜÂíå‰ªªÂä°ÂàÜÈÖçÈúÄÊ±ÇÁêÜËß£ÔºöÂ§¥ËÑëÈ£éÊö¥ÂíåÁ´ûÂìÅÂàÜÊûê„ÄÇÊ®°ÂùóÂàíÂàÜÔºöÁîªÊÄùÁª¥ÂØºÂõæÔºàXMindÔºâÔºåÊØè‰∏™Ê®°ÂùóÊòØ‰∏Ä‰∏™ÊûùËäÇÁÇπÔºåÊØè‰∏™ÂÖ∑‰ΩìÁöÑÂäüËÉΩÊòØ‰∏Ä‰∏™Âè∂ËäÇÁÇπÔºàÁî®Âä®ËØçË°®Ëø∞ÔºâÔºåÈúÄË¶ÅÁ°Æ‰øùÊØè‰∏™Âè∂ËäÇÁÇπÊó†Ê≥ïÂÜçÁîüÂá∫Êñ∞ËäÇÁÇπÔºåÁ°ÆÂÆöÊØè‰∏™Âè∂Â≠êËäÇÁÇπÁöÑÈáçË¶ÅÊÄß„ÄÅ‰ºòÂÖàÁ∫ßÂíåÂ∑•‰ΩúÈáè„ÄÇ‰ªªÂä°ÂàÜÈÖçÔºöÁî±È°πÁõÆË¥üË¥£‰∫∫Ê†πÊçÆ‰∏äÈù¢ÁöÑÊåáÊ†á‰∏∫ÊØè‰∏™Âõ¢ÈòüÊàêÂëòÂàÜÈÖç‰ªªÂä°„ÄÇÂà∂ÂÆöÈ°πÁõÆËøõÂ∫¶Ë°®ÔºàÊØèÊó•Êõ¥Êñ∞ÔºâÊ®°ÂùóÂäüËÉΩ‰∫∫ÂëòÁä∂ÊÄÅÂÆåÊàêÂ∑•Êó∂ËÆ°ÂàíÂºÄÂßãÂÆûÈôÖÂºÄÂßãËÆ°ÂàíÁªìÊùüÂÆûÈôÖÁªìÊùüÂ§áÊ≥®ËØÑËÆ∫Ê∑ªÂä†ËØÑËÆ∫ÁéãÂ§ßÈî§Ê≠£Âú®ËøõË°å50%42018/8/72018/8/7Âà†Èô§ËØÑËÆ∫ÁéãÂ§ßÈî§Á≠âÂæÖ0%22018/8/72018/8/7Êü•ÁúãËØÑËÆ∫ÁôΩÂÖÉËä≥Ê≠£Âú®ËøõË°å20%42018/8/72018/8/7ÈúÄË¶ÅËøõË°å‰ª£Á†ÅÂÆ°Êü•ËØÑËÆ∫ÊäïÁ•®ÁôΩÂÖÉËä≥Á≠âÂæÖ0%42018/8/82018/8/8OOADÂíåÊï∞ÊçÆÂ∫ìËÆæËÆ°UMLÔºàÁªü‰∏ÄÂª∫Ê®°ËØ≠Ë®ÄÔºâÁöÑÁ±ªÂõæÈÄöËøáÊ®°ÂûãÂàõÂª∫Ë°®ÔºàÊ≠£ÂêëÂ∑•Á®ãÔºâÔºå‰æãÂ¶ÇÂú®DjangoÈ°πÁõÆ‰∏≠ÂèØ‰ª•ÈÄöËøá‰∏ãÈù¢ÁöÑÂëΩ‰ª§ÂàõÂª∫‰∫åÁª¥Ë°®„ÄÇpython manage.py makemigrations apppython manage.py migrate‰ΩøÁî®PowerDesignerÁªòÂà∂Áâ©ÁêÜÊ®°ÂûãÂõæ„ÄÇÈÄöËøáÊï∞ÊçÆË°®ÂàõÂª∫Ê®°ÂûãÔºàÂèçÂêëÂ∑•Á®ãÔºâÔºå‰æãÂ¶ÇÂú®DjangoÈ°πÁõÆ‰∏≠ÂèØ‰ª•ÈÄöËøá‰∏ãÈù¢ÁöÑÂëΩ‰ª§ÁîüÊàêÊ®°Âûã„ÄÇpython manage.py inspectdb > app/models.pyÁ¨¨92Â§©ÔºöDockerÂÆπÂô®ËØ¶Ëß£DockerÁÆÄ‰ªãÂÆâË£ÖDocker‰ΩøÁî®DockerÂàõÂª∫ÂÆπÂô®ÔºàNginx„ÄÅMySQL„ÄÅRedis„ÄÅGitlab„ÄÅJenkinsÔºâÊûÑÂª∫DockerÈïúÂÉèÔºàDockerfileÁöÑÁºñÂÜôÂíåÁõ∏ÂÖ≥Êåá‰ª§ÔºâÂÆπÂô®ÁºñÊéíÔºàDocker-composeÔºâÈõÜÁæ§ÁÆ°ÁêÜÔºàKubernetesÔºâÁ¨¨93Â§©ÔºöMySQLÊÄßËÉΩ‰ºòÂåñÁ¨¨94Â§©ÔºöÁΩëÁªúAPIÊé•Âè£ËÆæËÆ°Á¨¨95Â§©Ôºö[‰ΩøÁî®DjangoÂºÄÂèëÂïÜ‰∏öÈ°πÁõÆ](./Day91-100/95.‰ΩøÁî®DjangoÂºÄÂèëÂïÜ‰∏öÈ°π\tÁõÆ.md)È°πÁõÆÂºÄÂèë‰∏≠ÁöÑÂÖ¨ÂÖ±ÈóÆÈ¢òÊï∞ÊçÆÂ∫ìÁöÑÈÖçÁΩÆÔºàÂ§öÊï∞ÊçÆÂ∫ì„ÄÅ‰∏ª‰ªéÂ§çÂà∂„ÄÅÊï∞ÊçÆÂ∫ìË∑ØÁî±ÔºâÁºìÂ≠òÁöÑÈÖçÁΩÆÔºàÂàÜÂå∫ÁºìÂ≠ò„ÄÅÈîÆËÆæÁΩÆ„ÄÅË∂ÖÊó∂ËÆæÁΩÆ„ÄÅ‰∏ª‰ªéÂ§çÂà∂„ÄÅÊïÖÈöúÊÅ¢Â§çÔºàÂì®ÂÖµÔºâÔºâÊó•ÂøóÁöÑÈÖçÁΩÆÂàÜÊûêÂíåË∞ÉËØïÔºàDjango-Debug-ToolBarÔºâÂ•ΩÁî®ÁöÑPythonÊ®°ÂùóÔºàÊó•ÊúüËÆ°ÁÆó„ÄÅÂõæÂÉèÂ§ÑÁêÜ„ÄÅÊï∞ÊçÆÂä†ÂØÜ„ÄÅ‰∏âÊñπAPIÔºâREST APIËÆæËÆ°RESTfulÊû∂ÊûÑÁêÜËß£RESTfulÊû∂ÊûÑRESTful APIËÆæËÆ°ÊåáÂçóRESTful APIÊúÄ‰Ω≥ÂÆûË∑µAPIÊé•Âè£ÊñáÊ°£ÁöÑÊí∞ÂÜôRAP2YAPIdjango-REST-frameworkÁöÑÂ∫îÁî®È°πÁõÆ‰∏≠ÁöÑÈáçÁÇπÈöæÁÇπÂâñÊûê‰ΩøÁî®ÁºìÂ≠òÁºìËß£Êï∞ÊçÆÂ∫ìÂéãÂäõ - Redis‰ΩøÁî®Ê∂àÊÅØÈòüÂàóÂÅöËß£ËÄ¶ÂêàÂíåÂâäÂ≥∞ - Celery + RabbitMQÁ¨¨96Â§©ÔºöËΩØ‰ª∂ÊµãËØïÂíåËá™Âä®ÂåñÊµãËØïÂçïÂÖÉÊµãËØïÊµãËØïÁöÑÁßçÁ±ªÁºñÂÜôÂçïÂÖÉÊµãËØïÔºàunittest„ÄÅpytest„ÄÅnose2„ÄÅtox„ÄÅddt„ÄÅ‚Ä¶‚Ä¶ÔºâÊµãËØïË¶ÜÁõñÁéáÔºàcoverageÔºâDjangoÈ°πÁõÆÈÉ®ÁΩ≤ÈÉ®ÁΩ≤ÂâçÁöÑÂáÜÂ§áÂ∑•‰ΩúÂÖ≥ÈîÆËÆæÁΩÆÔºàSECRET_KEY / DEBUG / ALLOWED_HOSTS / ÁºìÂ≠ò / Êï∞ÊçÆÂ∫ìÔºâHTTPS / CSRF_COOKIE_SECUR  / SESSION_COOKIE_SECUREÊó•ÂøóÁõ∏ÂÖ≥ÈÖçÁΩÆLinuxÂ∏∏Áî®ÂëΩ‰ª§ÂõûÈ°æLinuxÂ∏∏Áî®ÊúçÂä°ÁöÑÂÆâË£ÖÂíåÈÖçÁΩÆuWSGI/GunicornÂíåNginxÁöÑ‰ΩøÁî®GunicornÂíåuWSGIÁöÑÊØîËæÉÂØπ‰∫é‰∏çÈúÄË¶ÅÂ§ßÈáèÂÆöÂà∂ÂåñÁöÑÁÆÄÂçïÂ∫îÁî®Á®ãÂ∫èÔºåGunicornÊòØ‰∏Ä‰∏™‰∏çÈîôÁöÑÈÄâÊã©ÔºåuWSGIÁöÑÂ≠¶‰π†Êõ≤Á∫øÊØîGunicornË¶ÅÈô°Â≥≠ÂæóÂ§öÔºåGunicornÁöÑÈªòËÆ§ÂèÇÊï∞Â∞±Â∑≤ÁªèËÉΩÂ§üÈÄÇÂ∫îÂ§ßÂ§öÊï∞Â∫îÁî®Á®ãÂ∫è„ÄÇuWSGIÊîØÊåÅÂºÇÊûÑÈÉ®ÁΩ≤„ÄÇÁî±‰∫éNginxÊú¨Ë∫´ÊîØÊåÅuWSGIÔºåÂú®Á∫ø‰∏ä‰∏ÄËà¨ÈÉΩÂ∞ÜNginxÂíåuWSGIÊçÜÁªëÂú®‰∏ÄËµ∑ÈÉ®ÁΩ≤ÔºåËÄå‰∏îuWSGIÂ±û‰∫éÂäüËÉΩÈΩêÂÖ®‰∏îÈ´òÂ∫¶ÂÆöÂà∂ÁöÑWSGI‰∏≠Èó¥‰ª∂„ÄÇÂú®ÊÄßËÉΩ‰∏äÔºåGunicornÂíåuWSGIÂÖ∂ÂÆûË°®Áé∞Áõ∏ÂΩì„ÄÇ‰ΩøÁî®ËôöÊãüÂåñÊäÄÊúØÔºàDockerÔºâÈÉ®ÁΩ≤ÊµãËØïÁéØÂ¢ÉÂíåÁîü‰∫ßÁéØÂ¢ÉÊÄßËÉΩÊµãËØïABÁöÑ‰ΩøÁî®SQLslapÁöÑ‰ΩøÁî®sysbenchÁöÑ‰ΩøÁî®Ëá™Âä®ÂåñÊµãËØï‰ΩøÁî®ShellÂíåPythonËøõË°åËá™Âä®ÂåñÊµãËØï‰ΩøÁî®SeleniumÂÆûÁé∞Ëá™Âä®ÂåñÊµãËØïSelenium IDESelenium WebDriverSelenium Remote ControlÊµãËØïÂ∑•ÂÖ∑Robot Framework‰ªãÁªçÁ¨¨97Â§©ÔºöÁîµÂïÜÁΩëÁ´ôÊäÄÊúØË¶ÅÁÇπÂâñÊûêÁ¨¨98Â§©ÔºöÈ°πÁõÆÈÉ®ÁΩ≤‰∏äÁ∫øÂíåÊÄßËÉΩË∞É‰ºòMySQLÊï∞ÊçÆÂ∫ìË∞É‰ºòWebÊúçÂä°Âô®ÊÄßËÉΩ‰ºòÂåñNginxË¥üËΩΩÂùáË°°ÈÖçÁΩÆKeepalivedÂÆûÁé∞È´òÂèØÁî®‰ª£Á†ÅÊÄßËÉΩË∞É‰ºòÂ§öÁ∫øÁ®ãÂºÇÊ≠•ÂåñÈùôÊÄÅËµÑÊ∫êËÆøÈóÆ‰ºòÂåñ‰∫ëÂ≠òÂÇ®CDNÁ¨¨99Â§©ÔºöÈù¢ËØï‰∏≠ÁöÑÂÖ¨ÂÖ±ÈóÆÈ¢òÁ¨¨100Â§©ÔºöPythonÈù¢ËØïÈ¢òÂÆûÂΩï"
60,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
61,Significant-Gravitas/Auto-GPT,https://github.com/Significant-Gravitas/Auto-GPT/blob/master/README.md,Python,"Auto-GPT: An Autonomous GPT-4 Experimentüí° Get help - Q&A or Discord üí¨üî¥ USE stable not master üî¥Download the latest stable release from here: https://github.com/Significant-Gravitas/Auto-GPT/releases/latest.The master branch is under heavy development and may often be in a broken state.Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM \""thoughts\"", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI. Demo April 16th 2023               AutoGPTDemo_Subs_WithoutFinalScreen.mp4          Demo made by Blake WerlingerüöÄ Featuresüåê Internet access for searches and information gatheringüíæ Long-term and short-term memory managementüß† GPT-4 instances for text generationüîó Access to popular websites and platformsüóÉÔ∏è File storage and summarization with GPT-3.5üîå Extensibility with PluginsQuickstartCheck out the wikiGet an OpenAI API KeyDownload the latest releaseFollow the installation instructionsConfigure any additional features you want, or install some pluginsRun the appPlease see the documentation for full setup instructions and configuration options.üìñ Documentation‚öôÔ∏è Setupüíª Usageüîå PluginsConfigurationüîç Web Searchüß† Memoryüó£Ô∏è Voice (TTS)üñºÔ∏è Image Generation üíñ Help Fund Auto-GPT's Development üíñIf you can spare a coffee, you can help to cover the costs of developing Auto-GPT and help to push the boundaries of fully autonomous AI!Your support is greatly appreciated. Development of this free, open-source project is made possible by all the contributors and sponsors. If you'd like to sponsor this project and have your avatar or company logo appear below click here.                ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚ö†Ô∏è LimitationsThis experiment aims to showcase the potential of GPT-4 but comes with some limitations:Not a polished application or product, just an experimentMay not perform well in complex, real-world business scenarios. In fact, if it actually does, please share your results!Quite expensive to run, so set and monitor your API key limits with OpenAI!üõ° DisclaimerThis project, Auto-GPT, is an experimental application and is provided \""as-is\"" without any warranty, express or implied. By using this software, you agree to assume all risks associated with its use, including but not limited to data loss, system failure, or any other issues that may arise.The developers and contributors of this project do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as a result of using this software. You are solely responsible for any decisions and actions taken based on the information provided by Auto-GPT.Please note that the use of the GPT-4 language model can be expensive due to its token usage. By utilizing this project, you acknowledge that you are responsible for monitoring and managing your own token usage and the associated costs. It is highly recommended to check your OpenAI API usage regularly and set up any necessary limits or alerts to prevent unexpected charges.As an autonomous experiment, Auto-GPT may generate content or take actions that are not in line with real-world business practices or legal requirements. It is your responsibility to ensure that any actions or decisions made based on the output of this software comply with all applicable laws, regulations, and ethical standards. The developers and contributors of this project shall not be held responsible for any consequences arising from the use of this software.By using Auto-GPT, you agree to indemnify, defend, and hold harmless the developers, contributors, and any affiliated parties from and against any and all claims, damages, losses, liabilities, costs, and expenses (including reasonable attorneys' fees) arising from your use of this software or your violation of these terms.üê¶ Connect with Us on TwitterStay up-to-date with the latest news, updates, and insights about Auto-GPT by following our Twitter accounts. Engage with the developer and the AI's own account for interesting discussions, project updates, and more.Developer: Follow @siggravitas for insights into the development process, project updates, and related topics from the creator of Entrepreneur-GPT.We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!        "
62,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        ÁÆÄ‰Ωì‰∏≠Êñá |        ÁπÅÈ´î‰∏≠Êñá |        ÌïúÍµ≠Ïñ¥ |        Espa√±ol |        Êó•Êú¨Ë™û |        ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    ü§ó Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.üó£Ô∏è Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.ü§ó Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.ü§ó Transformers is backed by the three most popular deep learning libraries ‚Äî Jax, PyTorch and TensorFlow ‚Äî with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install ü§ó Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, ü§ó Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.ü§ó Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by ü§ó Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: ü§ó Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from √âcole polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Su√°rez*, Yoann Dupont, Laurent Romary, √âric Villemonte de la Clergerie, Djam√© Seddah and Beno√Æt Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of G√∂ttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo L√ºddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Herv√© J√©gou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp Kr√§henb√ºhl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, Timoth√©e Darcet, Th√©o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Herv√© Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas Oƒüuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by Ren√© Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre D√©fossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, Lo√Øc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno√Æt Crabb√©, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey √ñhman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo Garc√≠a del R√≠o, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Herv√© J√©gou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by J√∂rg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre D√©fossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noah‚Äôs Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.Nystr√∂mformer (from the University of Wisconsin - Madison) released with the paper Nystr√∂mformer: A Nystr√∂m-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier H√©naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, Jo√£o Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, ≈Åukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Doll√°r.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault F√©vry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of W√ºrzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, Pawe≈Ç Krzysztof Nowak, Thomas M√ºller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll√°r, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Luƒçiƒá, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm√°n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper ‚ÄãXLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the ü§ó Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by ü§ó TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by ü§ó Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the ü§ó Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R√©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
63,shadowsocks/shadowsocks,https://github.com/shadowsocks/shadowsocks/blob/rm/README.md,Python,Removed according to regulations.
64,zero-to-mastery/start-here-guidelines,https://github.com/zero-to-mastery/start-here-guidelines/blob/master/README.md,Python,"One rule of this community:We don't care if you break things. This is a playground, and we encourage failing often. Use this as a practice ground, and enjoy contributing to projects you create with your fellow students. Many students have gained real-world experience \""working in teams\"" by working on these projects.A Guide to Get Started (used to be the 4 step guide)Check out Andrei's videos on github if you haven't watched it already.On the GitHub page for this repository, click on the button \""Fork.\""Clone your forked repository to your computer:For example, run this command inside your terminal:git clone https://github.com/<your-github-username>/start-here-guidelines.gitReplace <your-github-username>!Learn more about forking and cloning a repo.Move to project directory:cd start-here-guidelinesBefore you make any changes, keep your fork in sync to avoid merge conflicts:git remote add upstream https://github.com/zero-to-mastery/start-here-guidelines.gitgit pull upstream masterIf you run into a merge conflict, you have to resolve the conflict. There are a lot of guides online, or you can watch this tutorial.After adding the upstream and checking that all files are up to date, we now will create new branch before editing any files. There are two ways to do so:git checkout -b <branch-name>git branch <branch-name>git switch <branch-name>On your computer, open your text editor, and add your name to the CONTRIBUTORS.md file.‚ö†Ô∏è IMPORTANT NOTE #1: Add your name somewhere in the middle. Not at the top or bottom in order to avoid the chance of you getting a merge conflict!‚ö†Ô∏è IMPORTANT NOTE #2: Please do NOT edit or remove other people from the list, even to fix their indentation etc. This will likely prevent your PR from being merged.Add the changes with git add, git commit (write a good commit message, if possible):git add CONTRIBUTORS.mdgit commit -m \""Add <your-github-username>\""Replace <your-github-username>!Push your changes to your repository:git push origin <branch-name>Go to the GitHub page of your fork, and make a pull request:Read more about pull requests on the GitHub help pages.Wait until Zerobot or one of the maintainers merges your pull request. If there are any conflicts, you will get a notification and be required to resolve the conflict.Go join a project and start contributing or create your own group apps. Don't be shy and enjoy creating things together (We have over 20 projects for all levels of programmers)! Check out this guide for more information on selecting a project.To see the Zero to Mastery Icon in your GitHub profile, follow these steps (you must complete steps 1 and 2 for this to work).Anatomy of an open-source project:Every open-source community is different.Spending years on one open-source project means you‚Äôve gotten to know one open-source project. Move to a different project, and you might find the vocabulary, norms, and communication styles are completely different.That being said, many open-source projects follow a similar organizational structure. Understanding the different community roles and overall process will help you get quickly oriented to any new project.A typical open-source project has the following types of people:Author: The person(s) or organization that created the project.Owner: The person(s) who has administrative ownership over the organization or repository (not always the same as the original author).Maintainers: Contributors who are responsible for driving the vision and managing the organizational aspects of the project (may also be authors or owners of the project).Contributors: Everyone who has contributed something back to the project.Community Members: People who use the project. They might be active in conversations or express their opinion on the project‚Äôs direction.Bigger projects may also have subcommittees or working groups focused on different tasks, such as tooling, triage, community moderation, and event organizing. Look on a project‚Äôs website for a ‚Äúteam‚Äù page or in the repository for governance documentation to find this information.A project also has documentation. These files are usually listed in the top level of a repository.LICENSE: By definition, every open-source project must have an open-source license. If the project does not have a license, it is not open source.README: The README is the instruction manual that welcomes new community members to the project. It explains why the project is useful and how to get started.CONTRIBUTING: Whereas READMEs help people use the project, contributing docs help people contribute to the project. It explains what types of contributions are needed and how the process works. While not every project has a CONTRIBUTING file, its presence signals that this is a welcoming project to contribute to.CODE_OF_CONDUCT: The code of conduct sets ground rules for participants‚Äô behavior and helps to facilitate a friendly, welcoming environment. While not every project has a CODE_OF_CONDUCT file, its presence signals that this is a welcoming project to contribute to.Other documentation: There might be additional documentation such as tutorials, walkthroughs, or governance policies, especially on bigger projects.Finally, open-source projects use the following tools to organize discussion. Reading through the archives will give you a good picture of how the community thinks and works.Issue tracker: Where people discuss issues related to the project.Pull requests: Where people discuss and review changes that are in progress.Discussion forums or mailing lists: Some projects may use these channels for conversational topics (for example, ‚ÄúHow do I‚Ä¶‚Äú or ‚ÄúWhat do you think about‚Ä¶‚Äú instead of bug reports or feature requests). Others use the issue tracker for all conversations.Synchronous chat channel: Some projects use chat channels (such as Discord or IRC) for casual conversation, collaboration, and quick exchanges.Get all the ZTM Courses, for one monthly subscription here."
65,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answers‚ö†Ô∏è DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]üôè PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!üéâ AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.‚ùì Need help?Open new issueüî• Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accounting‚ùóneeds updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustrator‚ùóneeds updating  7674Adobe-InDesign‚ùóneeds updating  4240Adobe-Lightroom‚ùóneeds updating  2020Adobe-Photoshop‚ùóneeds updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effects‚ùóneeds updating  2413Agile Methodologies‚ùóneeds updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCAD‚ùóneeds updating  7775@djayorAutodesk Fusion 360‚ùóneeds updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambda‚ùóneeds updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++‚ùóneeds updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurity‚ùóneeds updating10196Django7171@PROCW.NET Framework6359@declarckEclipse‚ùóneeds updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSON‚ùóneeds updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excel‚ùóneeds updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Project‚ùóneeds updating4443Microsoft Word‚ùóneeds updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooks‚ùóneeds updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revit‚ùóneeds updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePoint‚ùóneeds updating5338Sketchup22SOLIDWORKS‚ùóneeds updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnity‚ùóneeds updating4746@uno-sebastianVisual Basic for Applications (VBA)‚ùóneeds updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors ‚ú®Thanks goes to these wonderful people (emoji key):            Evgeniiüíª üñã      Sergei Stadniküíª üîç ü§î üìñ      Santhoshüíª      Jacob Dsaüíª üñã      Aaron Meeseüíª üñã      arqarqüíª üñã      Amit Yadavüíª üñã              Javokhir Nazarovüíª üñã      saurav kumarüñã      Chetanüñã      Amir Hossein Shekariüé® üñã üíª      SergDautüé®      Nilotpal Pramaniküé® üíª üñã üíº üìñ üî£ üí°      Abhishek Kumarüé®              Monu Guptaüé®      KARTIKEYA GUPTAüíª üñã      kenkyushaüíª üñã      juandavidtowersüíª üñã      cyber-neticsüíª üñã      jtriswüíª üñã      Renato Regaladoüíª üñã              Matthewüíª üñã      Jan S.üíª üñã      Manoliüíª üñã      Faraz tanveerüíª üñã      mohnishkarriüíª üñã üé®      andyzhuüíª üñã      Vishal Kushwahüíª üñã              Yurii Yakymenkoüíª üñã      Swetabh Sumanüíª üñã      AJAY DANDGEüíª üñã      Mehmet Yesinüé®      Lok Chun Waiüé®      Adria de Juanüé®      GL-Manüé®              Jheel Patelüé®      Sameer Waskarüé®      Alexander Andrewsüé®      Alexander Maxwellüé®      Slavaüé®      Mayur Khatriüé®      Mascantoshüíª üñã üì¢ ü§î              Kivanc Enesüé®      Ritika Dasüé®      Zer07793üé®      Andrew Cheungüé®      Sadhaüé®      tainenkoüé® üíª      github-star-coderüé®              Danilo Oliveiraüé®      lordekoüé®      Shubham Kumarüé® üíª      testtreeüé®      Cheryl Murphyüé® üíª      Bipin Thomasüé®      Abdulrahman Hishamüé®              Dakshitha Dissanayakaüé®      BADR KACIMIüé®      Alex Wangüé®      Maximüé®      GordonGrantüé® üíª      Ephrem Demelashüé®      JonOrcuttüé®              topdev10üé®      cookwellwebsiteüé®      xren935üé®      Nemo Frenkelüé®      MD SAIF ALAMüé®      Boris L√≥pez Arayaüé®      Larry Chiemüé®              Muhammad Bilal Ilyasüé®      AliMilaniüé® üíª      Suraj Sahaniüé®      FlyingSquirrelüé®      Erick Tijeroüé®      Jaskaran Kukrejaüé®      MichaelLüé®              MagicLegendüé®      Dereck Bearsongüé®      Pappu Kumar Pashiüé®      Venkata Kishore Tavvaüé®      Rafat Touqir Rafsunüé®      Snehesh Duttaüé®      Timo K√∂rnerüé® üíª              alexxxanüé®      GGJasonüé®      LeeAnna Ewingüé® ü§î      kamal Jyotwalüé®      Bob-Johnsüé® üíª üñã      yunussalmanlyitüé® üíª      chilcotüé® üíª              Jacky Liüíª üñã üé®      Sarthak Trivediüé®      Ayush Aggarwalüé® üíª      Nic Ballariniüé®      Luigi Zambettiüé® üíª      govindhaswinüé®      Addy Royüíª üé®              Akshat Tamrakarüé® üíª      Sai Bhargava Ramuüé®      Gurkanüíª      Spencer Hayes-Laverdiereüíª      Aniket Soniüíª      tanmay5792üíª      Dina Taklitüíª üé® üñã              Dushyant Singhüíª      Ravi Prakash Singhüíª      Nihal Joshiüíª      Guy Klagesüíª      Arvindüé® üíª      mujeeb91üíª      josercaüé® üíª              Prateek Agrawalüíª      Teoh Tze Chuin(„Çµ„É©)üíª üé®      Jayant Jainüíª      Ayush Sahuüíª      Hridya Krishna Rüíª üé®      Rahul Baliüíª üé®      S.ZHengüé® üíª üíº              Shriya Madanüé® üíª      mahalrupiüé®      Lucas Lermagneüé®      Jeff Deutschüé® üíª      Betoxx1üé®      Wingman4l7üé®      Martin Espericuetaüé®              Mh-Tahirüé®      Zdravko ≈†plajtüé® üíª      Ms3105üé® üíª üñã      Ambika Sidheswareüíª      mundogueroüíª      Darkus24üñã      Sou-786üñã üé®              Banurekhaüñã      ShiraStarLüé®      Ilya Komarovüé®      DemigodMsüñã üìñ      Mekha Hridyaüé® üîç      Andrey Safonovüé® üîç      Tommasoüé® üíª              Jessica Salbertüíª üé®      JAYANTH DOLAIüíª üé®      silverstroomüíª üé® üíº      Furkan Sayƒ±müíª üé®      Sukumar Chandrasekaranüé®      Yejin Parküé® üíª      Ali Nooshabadiüé® üíª              imitavorüé® üíª      Salih Kilicliüé® üíª      Marcelo Menesesüé® üíª      Anton Krekotunüé® üöß üñã üíª üìñ üíº      Arnav Sarmaüíª üí° üé®      meghatikuüíª üé®      Anshu Trivediüé®              Taylor Dorsettüíª üñã üé®      Havit Roviküíª      pushpapuneüíª üé®      Ramtin Radfarüé® ü§î üíº üíµ üíª üñã üí¨      Abdulmajeed Isaüíª üé®      vikassaxena02üé®      RobTablesüé® üíª üíº              Danielüé® üíª üíº üîç      Zahid Aliüíª üé®      Chad Chaiüíª üé®      Marco Biedermannüíª üé® üíº ü§î      Srinidhi Murthyüé®      Miao Caiüíª üé®      Dionicio Diazüé® üíª              Mir Monoarul Alamüé®      Shawn Ohnüíª üé®      Amanbolat Balabekovüé® üíª      black-mamba-codeüíª      Jian-forksüé® üíª      shivani patelüé®      Akash Chowrasiaüé®              yairg98üé®      Jay Gajjarüé®      coolerboolerüíª      Md Zinnatul Islam Morolüé®      shresthashok550üé® üìñ      Alan Pallathüìñ      Adrian Wongüíª              vsDizzyüíª üé®      Frex Cuadilleraüé® üíª      ashish570üíª üé®      ruchpeanutsüíª üé®      Artmasqueüé® üíª      Amirhossein Mojiri Foroushaniüé®      forüíª üé®              Lukeüé® üíª      Hector Espinozaüé®      Adri√°n Buenfilüé® üíª      Amit Kumarüé®      schoppfeüé® üíª      Sofiyal Cüé® üíª      spitlisküíª üé®              PRAVIN SHARMAüé®      NIDZAAA1üé® üíª      John Maiüé® üíª      kimsoyeongüé®      Dona Ghoshüíª      Ryan Hillüé® üíª      j42züé® üíª              Ashish Sangaleüé® üíª      Derek Yangüé® üíª      mohsinmsmüé® üíª      Gokulkrish2302üíª      Bhaavisheküíª üé®      Louis Liaoüé®      sengc92üé® üíª              Alex Marvinüé®      Balkrishna Bhattüé® üíª      Evaldas Lavrinoviƒçiusüé® üíª      Adam Erchegyiüé® üíª      Truman Hungüé® üíª      rzamora11üé®      gaurav0224üé®              Lee GyeongJunüé®      Mireküé® üíª      surajm245üé®      ArisLaodeüé® üíª      RaviDhoriyaüé® üíª      sarai-84üé® üíª      Vishnuüé® üíª              Muhammad Minhajüíª      Chandrika Debüé® üíª      Gitgit101-bitüíª üé®      Hedi Sellamiüíª üé®      saurabhvaish93üíª üé®      Nikola Begovicüíª üé®      Wangüíª üé®              Manuel Eusebio de Paz Carmonaüé®      Basim Al-Jawaheryüé® üíª      RAJA AHMEDüé® üíª      Abhik Lodhüíª      Md. Pial Ahamedüíª üé®      Hassan Shahzadüíª üé®      Christian Sosa Gagoüíª              Hasnain Rasheedüíª üé®      T-Radfordüíª      dahiyashishüíª üé®      RahulSharma468üíª üé®      Jumpod Plekhongthuüíª üé®      Thomas Young-Audetüíª üé®      VinayagamBabuüíª üé®              Deniz Ko√ßüíª üé®      Azhar Khanüíª üé® üñã üìñ üî£ üöß      Jacob Shortüíª üé®      Uchimura85üíª üé®      Leo Nugrahaüíª üé® üìñ      Mujtaba Mehdiüìñ üñã      Jim-dsüíª üé®              Sreehari Küíª üé®      Florian Martinezüíª üé®      Aaronüíª üé®      apoageüé®      Ignacio Guillermo Martinez üíª üé®      AirlineDogüé® üíª      Mekelüé® üíª              hmosharrofüé® üíª      Ben Emamianüíª üé®      babesharküíª üé®      Leonardo Jaquesüíª üé®      Stefanos Apkarianüíª üé®      Ayhan Albayraküíª üé®      KidusMTüíª üé®              hectormarroquin20üíª üé®      Edelweiss35üíª üé®      MihaiDüíª üé®      AnveshReddyAnnemüíª üé®      Hyunjae Parküíª üé®      Rajiv Albinoüíª üé®      Atishayüíª              Yusuf Naheemüé®      Winduüé® üíª      Superv1sorüíª üé®      Karine (:üé® üíª      Eduard Pechüé® üíª      jjeshwaniüé® üíª      Steveüé® üíª              Aleigh Ohslundüíª      Abhinav Sumanüé® üíª      Hamza Ehtesham Farooqüé® üíª      IamNotPeterPanüíª üíµ üé®      Cetgerüé®      pkonopackiüé®      Yang Yangüé® üíª              Muhammad Shoaib Sarwarüíª      Murilo Henriqueüíª üé®      emilianoalvzüé® üíª      Sumana Sahaüé® üíª      Yurii17Küé® üíª      Rupesh Bhandariüé® üíª      salmos3718üíª              John Bakerüé® üíª      SanjaySathirajuüé® üíª      Donat Kabashiüé®      Arul Prasad Jüé® üíª      Qi Chenüé® üíª      Maksym Dmyterkoüé® üíª      ilovepullrequestsüíª              Samira Malekiüé® üíª      NIKITA MAHOVIYAüíª      jesuisdev.Netüé® üíª      Ashraf Nazarüé®      Naveed Ahmadüé®      Ajmain Naqibüé® üíª      Avinash Tingreüíª üé®              nicktidsüé®      Keith Dinhüíª üé®      Andr√© Ferreiraüíª üé®      eliottkespiüíª üé®      praveenpnoüíª üé®      vitowidigdoüíª üé®      Devesh Pratap Singhüíª üé®              Dario Rodriguezüíª üé®      charmander_didiüíª üé®      PHBasinüíª üé®      Ritvik Singh Chauhanüíª üé®      Riya P Mathewüíª üé®      Stephanie Cherubinüíª üé®      BenitesGuiüíª üé®              FarikBearüíª üé®      Dmytro Havrilovüíª üé®      Parvesh Monuüíª üé®      Dipen Panchasaraüíª üé®      gudataüé® üíª      gawadeditorüíª üé®      Kirill Taletskiüé® üíª              Saajanüé® üíª      Kushagra Süé® üíª      Oanh Leüé® üíª      Frane Medvidoviƒáüé® üíª      Yormanüé® üíª      Bill Chanüé® üíª      Pratik Lomteüé® üíª              LOC LAMüé® üíª      TUSAR RANJAN MAHAPATRAüíª      BhargavKanjarlaüíª      Karel De Smetüíª üé®      sidisanüé®      ygnzayarphyoüé® üíª      svansteelandtüíª              Kebechetüé®      Daniel Selvan Düé® üíª      Mahdi Razaviüé® üíª      Niklas Tiedeüíª üé®      narutubaderddinüíª üé®      dylandhoodüíª      Dheeraj Guptaüíª              Pieter Claerhoutüíª üé®      Shivam Agnihotriüíª      RanjithReddy-Narraüíª      Nikita Wadhwaniüé® üíª      rsholokhüíª üé®      Ayaan Hossainüíª üé®      Rajesh Swarnaüíª              Deniz Etkarüé® üíª      pro335üíª üé®      Jakub Radziküíª üé®      Hamza Khanzadaüíª      ARNONüé®      Vikram Singhüíª      Shoxruxbeküíª üé®              Amit Khatriüíª üé®      Wali Ullahüé® üíª      Amit11794üíª üé®      metis-macys-66898üíª üé®      Faisal Maqboolüé® üíª      Kumar Neerajüíª üé®      Maurizio Mariniüé® üíª              Saket Kothariüé® üíª      Szymon Zborowskiüé® üíª      iks3000üé® üíª      Ehsan Seyediüé® üíª      vanekbrüé® üíª      Princy_Müé® üíª      Shijie Zhouüé® üíª              lakshyamcs16üé® üíª      Filippo Faccoüé® üíª      mendel5üé® üíª      Patryküé® üíª      VishwaSanganiüé® üíª      Alvin Zhaoüé® üíª      Lazar Gugletaüé® üíª              vmichoüé® üíª      Sikandar Aliüé® üíª      Raja Babuüé® üíª      faizajahanzebüíª      Guil_AiTüé® üíª      Kushal Dasüé® üíª      Luis Bonillaüé® üíª              jovan1013üé® üíª      Damianüé® üíª      Yash Guptaüíª      lolcatnipüé® üíª      Ikko Ashimineüé® üíª      Farukhüé® üíª      Moksedulüíª üé®              Navneet Kumarüé® üíª      Saqib AlMaliküíª      fahimrahmanüé® üíª      vaibhav patilüé® üíª      Rahul Madanüé® üíª      kartik Kaklotarüé® üíª      ASAHI OCEANüé® üíª              Daniel Jungbluthüé® üíª      Rajdeep Singh Boranaüé® üíª      ankitha19üíª      Linh Tranüíª      islamarrüíª üé®      Mohamed Sabithüé® üíª      Miguel Angel Cruz Acostaüé® üíª              Adebayo Ilerioluwa üé®      Markusüé® üíª      dkonyayevüé® üíª      Kevin A Mathewüé® üíª      David Meloüé® üî£      DFW1Nüé® üíª      Sohaib Ayubüé® üíª              Navvyüé® üíª      bloodiator2üé® üíª      Hanjiüé® üíª      arthur74üé® üíª      Sri Subathra Devi Büé® üíª      Akif Aydogmusüé® üíª      Umer Javaidüé® üíª              Norio Umataüé® üíª      Gazi Hasan Rahmanüé® üíª      Keith Nguyenüé® üíª      Megalomaniacüé® üíª      ShankS3üé® üíª      Farhad Alishovüé® üíª      Ronak J Vanpariyaüé® üíª              azrael0learzaüé® üíª      Pavel Rahmanüé® üíª      chuabernüé® üíª      Rahul Tirkeyüé® üíª      Ruslan Besüé® üíª üí° üöß üñã üî£ üöá      Bohdanüé® üíª      Juzdzewskiüé® üíª              Grigor Minasyanüé® üíª      alvintwcüé® üíª      Anand Natarajanüé® üíª      Kashan Aliüé® üíª      Thomas Meshailüé® üíª      Son Phamüé®      Michael Frenchüí°              Yash Mishraüìñ      Miguel Rodriguezüé® üíª      Philipp Bachmannüé® üíª      sunnyüé® üíª      Siddharth Chatterjeeüé® üíª      Michael Naghavipourüé® üíª      Sahil Gargüé® üíª              MicroLionüé® üíª      wctwcüé® üíª      Rohan Sharmaüî£      AshishBodlaüé® üíª      Taras Pysarskyiüé® üíª      Luqman Bello O.üé® üíª      DyingDownüé® üíª              Diego Chapedelaineüé® üíª      Richleeüé® üíª      Asif Habibüé® üíª      Mazharul Hossainüé® üíª      toniüé® üíª      Pragyanshu Raiüé® üíª      Matthew Ellerüé® üíª              AbhiBijuüé® üíª      Roman Zhornytskiyüé® üíª      Lucas Caminoüé® üíª      Jo√£o Vitor Casarinüé® üíª      Evgeniy Shayüé® üíª      Ehsan Barkhordarüé® üíª      Gabrielüé® üíª              Shibu Mohapatraüé® üíª      Pavel Kirkovskyüé® üíª      Tahir Gulüé® üíª      imDevSalmanüé® üíª      Jordan Donaldsonüé® üíª      js-venusüé® üíª      Faisal Shaikhüé® üíª              ashishbpatilüé® üíª      Tri Leüé® üíª      tomtreffkeüé® üíª      Salah Eddine Lalamiüé® üíª      Mattias Xuüé® üíª      Manas Guptaüé® üíª      wolfsong62üé® üíª              Mehdi Mirzaeiüé® üíª      Van Ba Khanhüé® üíª      Sel Embeeüé® üíª      Suvradip Paulüé® üíª      Shariqueüé®      Seabassüé® üíª      Penny Liuüé® üíª              jatinder bholaüé® üíª      misterqbitüé® üíª      Daniel-VS9üé® üíª      Shruthiüé® üíª      beefydogüé® üíª      Suraj Kumarüé® üíª      hrishikeshpsüé® üíª              Sudarshanüé® üíª      Divyanshüíª üé®      Zyaireüé® üíª      Omar Belkadyüé® üíª      alexiismuaüé® üíª      Eduarda Alvesüé®      pycoachüé® üíª              Ruhulüé® üíª      pmoustopoulosüé® üíª      Lee Hui Tingüíª üé®      bodi1981üé® üíª      Devaraat Joshiüé® üíª      Johnnyüé® üíª      rogue-coderüé® üíª              viiktrüé®      Lalit Mohanüíª      Jo√£o Sousaüíª      Ë®ÄËëâ‰πãÈùàüíª üé®      RJLABSüíª      brittney0522üé® üíª      shamüé® üíª              Glenn Goossensüíª üé®      Cyber Hawküé® üíª üñã üíº      Ankit Yadavüé® üíª      verbalityüíª      Mohammed Siddiquiüé® üíª      AdamKaczor6250üé® üíª      Ram√≥n Martinez Nietoüé® üíª              Grzegorz Dziubaküé® üíª      Ayoub BERDEDDOUCHüé® üíª      nikola-fadvüé® üíª      Akarsh Agrawalüé® üíª      Mitra Mirshafieeüé® üíª      Parker Stephensüé® üíª      alrenee99üíª              Karthick Vankayalaüíª      Iryna üé® üíª      palanugrahüíª      Gwinbleindüé® üíª      Randy Bobandyüé® üíª      Bek Rozikoffüíª      davnguyeüé® üíª              Neel Patelüíª      ehudbeharüé® üíª      nicholas-cod3rüé® üíª      michaelfrankiüé®      Esther Whiteüé® üíª      prathmeshpbüé® üíª      Victor Linüé® üíª              Christine C. Yinüé® üíª      GitLearner-beginüé® üíª      Mesrop Andreasyanüé® üíª      Nathan Garciaüé®      commonsw04üé® üíª      Md. Rashad Tanjimüé® üíª      Ali Maleküíª              PAODLTüé® üíª      Nikhil Bobadeüé® üíª      hyuckjin21üíª      Itasha Modiüé® üíª      Nikitha Reddyüé® üíª      Mahshooq Zubairüé® üíª      Subham Dasüíª              Onkar Birajdarüé® üíª      Nick Titomichelakisüé® üíª      Christian Leo-Pernoldüé®      Matthew Marquiseüé® üíª      baronfacüé® üíª      Abhishek Tilwarüé® üíª      DavidsDvmüé® üíª              Parth Parikhüé® üíª      Hector Castroüé® üíª      Rikky Arisendiüé® üíª      Ali HamXaüé® üíª      Frank.wuüé® üíª      Jatin Kumarüé® üíª üìñ      masterHAWK99üé® üíª              Pushp Jainüé® üíª      Ashutosh Routüé® üíª      Atharva Deshpandeüé® üíª      Teodor Ciripescuüé® üíª      Anmol Bansalüé® üíª      Nikhil Kumar Macharlaüé® üíª      Dexterüé® üíª              Aaronüé® üíª      Yogita Jaswaniüé® üíª üìñ üñã      StoryDevüé® üíª      Mesut Doƒüansoyüé® üíª      Paras Dhawanüé® üíª      Emanuel Zhupaüé® üíª      Aaradhyaa717üé® üíª              jaacko-torusüé® üíª      mBlacküíª      kalrayashwinüìñ üñã üé® üíª      Seraphüíª üé®      ZhiHong Chuaüé® üíª      Amsal Khanüé® üíª üìñ üñã      Raghav Rastogiüé® üíª              Tzilaüìñ      Shahriar Nasim Nafiüìñ      AGüé® üíª      Mojtaba Kamyabiüé® üíª      Ahmad Abdulrahmanüé® üíª      Eclipseüé® üíª      Anshu Palüé® üíª              Denisüé® üíª      mehmet sayinüìñ      WebDEVüé® üíª      Sam Komesarooküé® üíª      Kiran Ghimireüé® üíª      Joshua Davisüé® üíª      Muhammad-Huzaifa-Siddiquiüíª              tobeornottobeadevüé® üíª      VAIBHAV SINGHALüé® üíª      Keiran Pillmanüé® üíª      Max Donchenkoüé® üíª      sgonsalüé® üíª      diksha137üé® üíª      Vigneshüé® üíª              Gabriel Fran√ßaüé® üíª      Josephüé® üíª      Bruno Rafaelüé® üíª      vcamarreüé® üíª      thibault kettererüé® üíª üöß      VictorGonzalezToledoüé® üíª      1911510996üé® üíª              inviduüé® üíª      Nurul Furqonüé® üíª      David Asbillüé® üíª      Niko Birbilisüé® üíª      Mugundan Kottursureshüé®      agrsachin81üé® üíª      Othmane El Alamiüé® üíª              Syed Atif Aliüé® üíª      lakhanjindamüé® üíª      youssef hamdaneüé® üíª      starfaerieüé® üíª      rodrigo0107üé® üíª      Micha≈Ç Gralaküé® üíª      Jewel Mahmudüé® üíª              cwilson830üé® üíª      buun1030üé® üíª      Reda-ELOUAHABIüé® üíª      saad-aksaüé® üíª      Emdadul Haqueüé® üíª      PROCWüé® üíª      cccppp1üé® üíª              Joanna Baileüé® üíª      Ahmed Saberüé® üíª      Masoud Keshavarzüé® üíª      mortazavianüé® üíª      Aniket Pandeyüé® üíª      Vijay Nirmalüé® üíª      Daniel Carvalloüíª              menaechmiüé® üíª      azenyxüé® üíª      Ahmet √ñzrahatüé® üíª      Abdulrahman Abouzaidüé® üíª      jmgnorbecüé® üíª      palinko91üé® üíª      Laisson R. Silveiraüé® üíª              BHARGAVPATEL1244üé® üíª      Candide Uüé® üíª      Sitansh Rajputüé® üíª      Houda Mouttalibüé® üíª      MumuTWüé® üíª      Suave Bajajüé® üíª      Mehdi Parsaeiüé® üíª              Dinko Osreckiüé® üíª      Dhia Djobbiüé® üíª      Mahmoud Galalüé® üíª      Anh Minhüé® üíª      Suvesh Küé® üíª      Petar Todorovüé® üíª      Alexander Nguyenüé® üíª              Morteza Jalalvandüé® üíª      Claudson Martinsüé® üíª      Matt Jacobsonüé® üíª      Rafael Belokurowsüé® üíª       Thomas Gamaufüé® üíª      Rishabh Mahajanüé® üíª      rakeshpdgupta23üé® üíª              Shashidharknaiküé® üíª      taleleumaüé® üíª      Florian B√ºhlerüé® üíª      Raihan Bin Wahidüé® üíª      MOHAMMED NASSERüé® üíª      federicoüé® üíª      Andre Violanteüé® üíª              tcunningham98üé® üíª      Jan Grie√üerüé® üíª      Serkan Alcüé® üíª üñã      Jez McKeanüé® üíª      meisam alifallahiüé® üíª      Mehul Thakkarüé® üíª      Saksham Soniüé® üíª              Pedro Peregrinaüé® üíª      Mintu Choudharyüé® üíª      lucianmoldovanuüé® üíª      John C. Scottüé® üíª      Mia D.üé® üíª      EwenBernardüé® üíª      M. Reza Nasirlooüé® üíª              Jay Agrawalüé® üíª      DeShayüé® üíª      Jay206-Programmerüé® üíª      Elenderüé® üíª üñã      Bobby Byrneüé® üíª      Pirciüé® üíª      Hasanuzzamanüé® üíª              Josh Kautzüé® üíª      Brofarüé® üíª      Mina Karamüé® üíª      Duncan O Nüé® üíª      Sean Tumulak-Nguyenüé® üíª      Artur Trze≈õniewskiüé® üíª      JJaammeessMüé® üíª              shubham agarwalüé® üíª      Michele Righiüé® üíª      Panagiotis Kontosüé® üíª      sumitbathlaüé® üíª      Deepak Mathurüé® üíª      Juho Nyk√§nenüé® üíª      Santiago Gonz√°lez Siordiaüé® üíª              SRIJITA MALLICKüé® üíª      Samriddhi Büé® üíª      Nitzan Papiniüé® üíª      Mario Sanzüé® üíª      Crab^4üé® üíª      Pabloüé® üíª      Gordon Pham-Nguyenüé® üíª              Kristofferüé® üíª      chrisblachüé® üíª      G√°borüé® üíª      Linaüé® üíª      Harrison Wattsüé® üíª      Mario Petriƒçkoüé® üíª      Ben8120üé® üíª              Giovannaüé® üíª      Minal Ahujaüé® üíª      mossfarmerüé® üíª      ThaC0derDreüé® üíª      itwareüé® üíª      Michael Walkerüé® üíª      Tom Jacob Chirayilüé® üíª              Sachin Kumarüé® üíª      adi-rayüé® üíª      Dr-Blank-altüé® üíª      Bogdan Cazacuüé® üíª      Gilson Urbanoüé® üíª      Ninaüé® üíª      Anthonyüé® üíª              manushimjaniüé® üíª      Michael Reyesüé® üíª      Rachel Kennellyüé® üíª      Aakash Gargüé® üíª      Daniel Livingstonüé® üíª      alexrojcoüé® üíª      Minh Nguyenüé® üíª              Mahesh Dattatraya Babarüé® üíª      Jin Zihangüé® üíª      Bikramjit Gangulyüé® üíª      QuestionableGuiseüé® üíª      liq19chüé® üíª      Bruno Rochaüé® üíª      Anand Dyavanapalliüíª üñã              crucian-afküé® üíª      0xgainzüé® üíª      weirdfshüé® üíª      Valan Baptist Mathuranayagamüé® üíª      Paul Kaeferüé® üíª      Yu-Hsiang Wangüé® üíª      Javad Adibüé® üíª              davidliu0930üé® üíª      Achilleas John Yfantisüé® üíª      Omkar Shivadekarüé® üíª üñã üêõ      ToanTranüé® üíª      Gautam Naiküé® üíª      Marcüé® üíª      twix20üé® üíª              Kristian S.üé® üíª      Aleksey Khoroshilovüé® üíª      arjunsrsrüé® üíª      Ali Haiderüé® üíª      Trisha Dringüé® üíª      Andre Marzuloüé® üíª      Krishna Modiüé® üíª              Rosemary Liüé® üíª      Alex Wellerüé® üíª      Tam Nguyenüé® üíª      aquintelaoliveiraüé® üíª      Norbert Brettüé® üíª      rocsogdüé® üíª      0nyrüé® üíª              rethkevinüé® üíª      RickHeadleüé® üíª      Leandreüé® üíª      Natnael Sisayüé® üíª      sbbuüé® üíª      waelüé® üíª      Fabricio Tramontano Piriniüé® üíª              Alexander Stoyanovüé® üíª      Dezx20üé® üíª      southparkkidsüé® üíª      bmstarüé® üíª      kiagamüé® üíª      Juan Castilloüé® üíª      FFenneüé® üíª              Jose Toledoüé® üíª      Pat McGhenüé® üíª      Eiko Wagenknechtüíª üñã üî£      Alan Chalmersüé® üíª      Jean Didierüé® üíª      Andyüé® üíª      pestadieuüé® üíª              Kanishka Chakrabortyüé® üíª      Nandhaüé® üíª      Vahid Mafiüé® üíª üî£ üñã üíº      Akshay Ashoküé® üíª      0x08üé® üíª      Sandeep Mishraüé® üíª      Evann Regnaultüé® üíª              Lenny Zeitounüé® üíª      Eden Boaronüé® üíª      TroyBTCüé® üíª      Aby Sebastianüé® üíª      Matthew Dunnüé® üíª      ckulloüé® üíª üñã üî£      Mohamed Mamdouhüé® üíª              Youssef Bazinaüé® üíª      Frederico K√ºckelhausüíª      Nushan Kodikaraüíª      Zach Cooperüíª      Royüé® üíª      Saurav Panchalüé® üíª      totallynotdavidüé® üíª              goosepirateüé® üíª üí° üíº      KAUTHüé® üíª      Hari Kiran Vusirikalaüé® üíª      Sounak Deyüé® üíª      ziaüíº üé® üíª      Reza Davariüé® üíª      AkshayAjaykumarüé® üíª              x24870üé® üíª      Ko Phoneüé® üíª      Nabstar3üé® üíª      Mateuszüé® üíª      Yunus Emre Emiküíª      Abhinav Sinhaüé® üíª      Hung Nguyenüé® üíª              Maselinoüíª      Shuktika Mahantyüíª      Miko≈Çaj Gawro≈Ñskiüé® üíª      Hussein Habibi Juybariüé® üíª      Sean-McArthurüé® üíª      Osman F Bayramüé® üíª      Benjamin Thomas Blodgettüé® üíª              Chuanlong-Zangüé® üíª      julianüé® üíª      franciscoüé® üíª      aalihhiader9211üé® üíª      Muhammad Zunairüé® üíª      Liyaüé® üíª      BegadTareküé® üíª              etorobotüé® üíª      Hussam Khanüé® üíª      Saikat Chakrabortyüé® üíª      Nicholas Quislerüé® üíª      Evang Poulüé® üíª      Gregg Lindüé® üíª      Deepak Kumarüé® üíª              Callum Leslieüé® üíª      Curtis Barnard Jr.üé® üíª      Deepanshukaimüé® üíª      Manthan Anküé® üíª      hossein varmazyarüé® üíª      Brayan Mu√±oz V.üé® üíª      Kamil Rasheed Siddiquiüíª üé®              mutt0-dsüé® üíª      egbertjküé® üíª      Majid Zojajiüé® üíª      Sean Chenüé® üíª      Herbert Milhommeüé® üíª      A3üé® üíª      Killianüé® üíª              Coakeowüé® üíª      ‡æÖ‡ºª «¨…Äƒß ‡ºÑ‡ºÜ‡Ωâüé® üíª      Pratik Solankiüé® üíª      Sunnyüé® üíª      ssgeüé® üíª      Bernat Frangiüé® üíª      Jeevan Rupachaüé® üíª              amirandapüé® üíª      Deepakshi Mittalüé® üíª      Abhijeet Paridaüé® üíª      Khaled Riyadüé® üíª      Pratap paruiüé® üíª      Prajit Pandayüé® üíª      PipeSierraüé® üíª              Collins Odenüé® üíª      Kshitij Dwivediüé® üíª      Bernardia Vitri Arumsariüé® üíª      √ñmer Faruk Ta≈üdemirüé® üíª      Spencer Stithüé® üíª      Porsche Rodjanasaküé® üíª      Shakeel Sharifüé® üíª              Victoria Chengüé® üíª      Denisüé® üíª      Anand Prakash Tiwariüé® üíª      danijeljw-rpcüé® üíª      Ahmed H Ebrahimüé® üíª      Virginia Gardnerüé® üíª      Jhironsel Diaz A.üé® üíª              Yunus Kidemüé® üíª      MTüé® üíª      Dinesh Zaldekarüé® üíª      adiüé® üíª      Farhan Shaikhüé® üíª      Elvis Salvatierraüé® üíª      Kaushik-Iyerüé® üíª              HocAndresüé® üíª      VictorHugoAguilarAguilarüé® üíª      Murat Can Abayüé® üíª      Chrisüé® üíª      Shivam7-1üé® üíª      Paipai13üé® üíª      Shambles-ioüé® üíª              Abhishek K Müé® üíª      Ezequiel Cuevasüé® üíª      Plamen Ivanovüé® üíª      Yujiüé® üíª      Jean-Philippe Leb≈ìufüé® üíª üî£      Naufanüé® üíª      jadnovüé® üíª              vaxtangensüé® üíª      subashkonar13üé® üíª      Rushi Javiyaüé® üíª      Mert G√ºlüé® üíª      Lilyüé® üíª      Kalinoffüé® üíª      Joel Tonyüé® üíª              Peterüé® üíª      Roozbeh Zareiüé® üíª      Shenüé® üíª      Joonsoo.LEEüé® üíª      Fede.Bregüé® üíª      Rui Costaüé® üíª      Jo√£o Gustavo Bispoüé® üíª              Sami-Iüé® üíª      Tsvetoslav Tsvetkovüé® üíª      Olabode Olaniyi Davidüé® üíª      theRuslanüé® üíª      leighbozüé® üíª      Frank Sossiüé® üíª      Tomasz Adamskiüé® üíª              Mansoor M. Sathirüé® üíª      Golamrabbi Azadüé® üíª      Nahian Ahmedüé® üíª      Rafael de Jesus Silva Monteiroüé® üíª      Odionyebuchukwu Judeüé® üíª      The Nithin Balajiüé® üíª      Knackiiüé® üíª              vittorio-giattiüé® üíª      Guilherme de Carvalho Lima Rebou√ßasüé® üíª      aaref shamiüé® üíª      Andrey Dryupinüé® üíª      Muhanned Nomanüé® üíª      Jan Silvaüé® üíª      emanuele-emüé® üíª üñã              Sanjay TMüé® üíª      Joe Markberg / code editorüé® üíª      Julien Quiaiosüé® üíª      Eric Ramirez Santisüé® üíª      Müé® üíª      Malcataüé® üíª      Athul Muralidharanüé® üíª              Dariusz Ochotaüé® üíª      CHANDAN CHOUDHURYüé® üíª      Deepüé® üíª      Ahmet ƒ∞stemihan √ñZT√úRKüé® üíª      TIMüé® üíª      jakeg814üé® üíª      Leonidosüé® üíª              Abhinandu V Nairüé® üíª      charafeddine01üé® üíª      Jasperüé® üíª      Manish Goyalüé® üíª      SATYAM_SINGHüé® üíª      Fourüé® üíª      Vaishnavi Amira Yadaüé® üíª              ShriKrushna Bhagwatüé® üíª      Rohit Nandagawaliüé® üíª      felipeüé® üíª üöß üñã ‚úÖ üßë‚Äçüè´      Saurabh Mudgalüé® üíª      szenadamüé® üíª      Shubhendra Singhüé® üíª      Yoosuf Sayyidüíª üé®              G√ºven √áetinerlerüé® üíª      Luke Jefferiesüé® üíª      Chrisüé® üíª      L√∫cio Aguiarüíª      Enuma029üíª      yktsang01üíª      maximumn3rdüé® üíª              Jon Galleteroüé® üíª      Thaddeus  Thomasüé® üíª      Aakash Kumarüíª üé®      Ali Müé® üíª      OskyEdzüé® üíª      Ravi Guptaüé® üíª      Rafa Raizerüé® üíª              Abdullah Al Muzakiüé® üíª      Rahul Faujdarüé® üíª      Abhishek Vermaüé® üíª      Ashutosh Shindeüé® üíª      Ganesh Raiüé® üíª      StefanTrpkovicüé® üíª      Erik Blancaüé® üíª              Vedant Madaneüé® üíª      Antra Tripathiüé® üíª      Ethan Knightsüé® üíª      Alexandru Boncutüé® üíª      Pablo Bandinoplaüé® üíª üöß üñã      Robz-99üé® üíª      Harpal Singhüé® üíª              paulboundy99üé® üíª      Mubashir Ahmedüé® üíª      Rohan Hariüé® üíª      Erik Henrique üé® üíª      Leandro Matheusüé® üíª      Deepaküé® üíª      AlishaSinghüé® üíª              Lynn Latt Yatiüé® üíª      San Shweüé® üíª      SKRüé® üíª      msbunnyjaguarüé® üíª      Mohamad Zabiullaüé® üíª      Hatim Zahidüé® üíª      Rauzan Sumaraüé® üíª              Hosein1358üé® üíª      Mohitüé® üíª      Aliüé® üíª      Avinash1765üé® üíª      Sai Teja Madhaüé® üíª      Monsur Ahmed Shafiqüé® üíª      xuxianjin-devüé® üíª              chetnaüé® üíª      Gul Zaibüé® üíª      Nataliaüé® üíª      Dion√≠sio Bragaüé® üíª      Pritish Rajpurohitüé® üíª      incanloveüé® üíª      Innocentüé® üíª              Devin Almonorüé® üíª      antonyveyreüé® üíª      Beltz Anhxtonüé® üíª      Mehdiüé® üíª      Muhammad Usmanüé® üíª      Patrick Dantasüé® üíª      Tak Vannaküé® üíª              Ramzi RADDAOUIüé® üíª      Konstantin-Glukhovüé® üíª      ugurobanüé® üíª      Humberto Alvesüé® üíª      JuangZendratoüé® üíª      James Oluwaleyeüé® üíª      Wasi Sadmanüé® üíª              Pavle Mijatovicüé® üíª      Luiz H. S. Bispoüé® üíª      –°—É—Ö–∞—Å –î—Ö–æ–ª–∑üé® üíª      Alvaro Trujilloüé® üíª      Everton üé® üíª      jfrozasüé® üíª      Shuaaib Badranüé® üíª              Shivam Jhaüé® üíª      Mohamed Tayehüé® üíª      Makendran Güé® üíª      mayank singh tomarüé® üíª      hossam sadanyüé® üíª      Harshbardhan Singhüíª üé®      Fawad Jawaid Maliküé® üíª              Tina Lacatisüé® üíª      TeddyCuoreDolceüé® üíª      bchooxgüé® üíª      Alisha Takkarüé® üíª      Gianluigiüé® üíª      Mehran Javaherianüé® üíª      Benjamin Ololade Adedokunüé® üíª              Md. Abdul Mutalibüé® üíª      Aadil Arsh.S.Rüé® üíª      J. Nathan Allenüé® üíª      Kieran Krugüé® üíª      Seth Addoüé® üíª      Satvik Singh Rathoreüé® üíª      dangothüé® üíª              Maximüé® üíª      Phuong-Cat Ngoüé® üíª      Frenchtoast0üé® üíª      Rakshithüé® üíª      Vaibhav Aroraüé® üíª      zghpüé® üíª      Bedovanüé® üíª              chiaramistroüé® üíª      him2016üé® üíª      HarshitSachdevaüé® üíª      Sadaf Saleemüé® üíª      Aaroh Srivastavaüé® üíª      eloygplazaüé® üíª      Gaurav Kumar Vermaüé® üíª              AndreaCUSüé® üíª      Simranüé® üíª      Prashant Bhapkarüé® üíª      mhaendlerüé® üíª      Gauri Maheshwariüé® üíª      4Lajfüé® üíª      Tanmoy Senguptaüé® üíª              Sharad Tripathiüé® üíª      Niraj Chavanüé® üíª      Luisa Gualdaüé® üíª      Monika-Sivakumar-3üé® üíª      harryfensomeüé® üíª      Shubham Choubeyüé® üíª      Ashwini Patilüé® üíª              cleversonliraüé® üíª      Nurmukhammedüé® üíª      workspace-utkarshüé® üíª      Santosh Phadtareüé® üíª      Prashant Warghudeüé® üíª      Umang Dakhüé® üíª      Shalini Chavanüé® üíª              vinit gurjarüé® üíª      Vishal Kumarüé® üíª      Wonhyeong Seoüé® üíª      Achwale Prajwal Namdevraoüé® üíª      Ankan Banerjeeüé® üíª      bhaumikankanüé® üíª      JamesMacroZhangüé® üíª              Pedro Lopesüé® üíª      diaüé® üíª      tayyabhussain2910üé® üíª      Rajdeep Shrivastava üé® üíª      Mukul Kumarüé® üíª      Mayank Nüé® üíª      jdeluccaüé® üíª              Sneha Mittalüé® üíª      Sarika Kushwahaüé® üíª      farzad-khbüé® üíª      Elijah Shackelfordüé® üíª      The-Only-Raminatorüé® üíª      Keerthana Kasthurilüé® üíª      Viachaslau Auchynnikauüé® üíª              Mohammad Osman Rasooliüé® üíª      mvedovatoüé® üíª      Sonali Rajputüé® üíª      Isha Dheküé® üíª      Ramshad Cheriyeri Peediyakkalüé® üíª      Micahüé® üíª      gauravshukla2203üé® üíª              sndmurthyüé® üíª      Shivam-Singhüé® üíª      M. Ammar Khanüé® üíª      chandolakulüé® üíª      bhatnagar221üé® üíª      Adrian Nie≈õciurüé® üíª      nezi311üé® üíª              scottajevansüé® üíª      Marcelo Antunes Soares Fantiniüé® üíª      Axel De Acetisüé® üíª      Drishti Sahüé® üíª      VipulDhillonüé® üíª      Urmi Janaüé® üíª      Ayush Mokalüé® üíª              Damola Olutokeüé® üíª      Maxüé® üíª      Lakshmi Nüé® üíª      ArtemRevaüé® üíª      Ujjwal Aggarwalüé® üíª      Moüé® üíª      Brianüé® üíª              chamleyüé® üíª      Simone Baptisteüé® üíª      Shekhar Thakurüé® üíª      Smithüé® üíª      codernoob1üé® üíª      lok84üé® üíª      Tobias Riemenschneiderüé® üíª              Tharsanan1üé® üíª      ANURAG SINGHüé® üíª      Yash Santüé® üíª      Krishiv Patelüé® üíª      GGGalaxyüé® üíª      pardeepdhillon661üé® üíª      anujd64üé® üíª              Pedro Pereiraüé® üíª      Master_Saptaküé® üíª      SURANJAN DASüé® üíª      Tripura kantüé® üíª      shabzkhanüé® üíª      Mustafa Poyaüé® üíª      Roshan Jhaüé® üíª              GuillaumeLarueüé® üíª      Tomasz Rodaküé® üíª      Junil Kimüé® üíª      Surbhi Mayanküé® üíª      Nemanja Lekicüé® üíª      HemantMalokarüé® üíª      Felipe M. L√≥pezüé® üíª              bibliofiloüé® üíª      GauthamG2üé® üíª      02_tüé® üíª      Yusuf Abdul-razaqüé® üíª      Vladimirüé® üíª      Sai Chandra Küé® üíª      Soroush Bonabüé® üíª              Giide0nüé® üíª      GGüé® üíª      D√°ger Z√∫√±igaüé® üíª      rsk2üé® üíª      Storozhev DJüé® üíª      Jeevanüé® üíª      Andy Johnsonüé® üíª              An√≠bal Pozoüé® üíª      Jovane de Castroüé® üíª      Muhammad Hamza Amirüé® üíª      tharaka-mtsüé® üíª      Ali KHYARüé® üíª      Caio Araujoüé® üíª      Oscar Dyremyhrüé® üíª              artealityüé® üíª      Daniel Drexlmaierüé® üíª      Marco Montiüé® üíª      mikeycrystalüé® üíª      Veljanovskiiüé® üíª      Ivan Gorbachevüé® üíª      Sahil Rawatüé® üíª              Hasitha Sunethüé® üíª      Yerko Vera Lezamaüé® üíª      Ivan Penchevüé® üíª      Tanver Islam Tonmoyüé® üíª      Xun Caoüé® üíª      Nayan Babariyaüé® üíª      Priyanshu Mauryaüé® üíª              Dylan Tintenfichüé® üíª      Ron Straussüé® üíª      Mohammed AlBannaüé® üíª      Mukund Müé® üíª      Franklin Ohaegbulamüé® üíª      Nisarg Shahüé® üíª      Unik Dahalüé® üíª              Readilyüé® üíª      Alexandre Poitevinüé® üíª      Scaramirüé® üíª      Pruthviüé® üíª      Kalmanqüé® üíª      Alfatah Nesabüé® üíª      arudesaiüé® üíª              Adryenneüé® üíª      El mehdi oudaoudüé® üíª      Jayant Goelüé® üíª      Tsukiüé® üíª      Peter Lemanskiüé® üíª      Annurag-byteüé® üíª      Anthony Vuüé® üíª              Vitaly Nikolaychuküé® üíª      Nathanüé® üíª      Evgenii Petukhovüé® üíª      Loris Guerraüé® üíª      fakhriaunurüé® üíª      Mehdi HYANIüé® üíª      Sarvex Jatasraüé® üíª              santimanuelrüé® üíª      Evgeniy Rezanovüé® üíª      Sonia Müé® üíª      Grzegorz Kmitaüé® üíª      Manuel Caritaüé® üíª      Felipe Cisternas Alvarezüé® üíª      Guo Ciüé® üíª              Marcos Silvaüé® üíª      KKüé® üíª      Shubhanjan Medhiüé® üíª      ArthurFerreiraRodriguesüé® üíª      PabloHermunüé® üíª      disha-baldawaüé® üíª      StaroMoonüé® üíª              Amila T Kumarasekaraüé® üíª      Amoh Princeüé® üíª      AngeloGCüé® üíª      Ebube Glory Ogbondaüé® üíª      Prahalad Belavadiüìñ      Antoni Sarnowski-Trypkaüé® üíª      Alberto Pasqualettoüé® üíª              Amir Babaeiüé® üíª      Syed Abdul Hannanüé® üíª      Srajan Raiüé® üíª      Clarence Mooreüé® üíª      Nguyen Anh Tuanüé® üíª      dar2dar2üé® üíª      Ameer Ibrahimüé® üíª              Tiago Lugattoüé® üíª      raremiroirüé® üíª      Moobieüé® üíª      AlicanDursunüé® üíª      bbalsamüé® üíª      Lubo≈° H√°jeküé® üíª      mrshahzeb7üé® üíª              Wesley Schollüé® üíª      Lawrence Turcotteüé® üíª      Michael DiPaoloüé® üíª      Smart-Codiüé® üíª      Vivek Kumarüé® üíª      Igor Moiseevüé® üíª      B√•rd Pedersenüé® üíª              HOA PHANüé® üíª      GaborModraüé® üíª      vivek-114üé® üíª      Robinüé® üíª      Alexüé® üíª      John Ehrlingerüé® üíª      Roman Zhuravlovüé® üíª              Jordan Mossüé® üíª      RaeShellyüé® üíª      gmollardüé® üíª      Md Kaif Khanüé® üíª      Pablo Romeraüé® üíª      Erik Bustosüé® üíª      trogfieldüé® üíª              simon-aichhornüé® üíª      Tufan G√úLE√áüé® üíª      Uƒüur Berkecan √únl√ºüé® üíª      Revanth Naiküé® üíª      Lia Piresüé® üíª      Igor Mestechkinüé® üíª      Anirudh Karanthüé® üíª              KBobovskiyüé® üíª      zhatiayuaüé® üíª üñã      David Cardonaüé® üíª      Paulo Castilhoüé® üíª      Sebastiano Picchiüé® üíª      pjotarüé® üíª      Rimel CHERIFüíª              Arsal uddinüñã      Dmitry Kasporskyüíª      SoftwareDev1014üé® üíª      @Robvredüé® üíª      Kasun Shanakaüíª      Ahmad M.üé® üíª      Alex Kozinüé® üíª              Mandy Meindersmaüé® üíª      LEGALISE PIRACYüé® üíª      Alex Logvinüé® üíª      Aria Dahlüé® üíª      Mustafa Arifogluüé® üíª      Yevhen Leshchenkoüé® üíª      Anubhav Adhikariüé® üíª              Noah Tatkoüé® üíª      Mohit Gadhaviüé® üíª      Pedro Bas√≠lioüé® üíª      RealSanjeevüé® üíª      Akash Hazraüé® üíª      Christoph Dahlenüé® üíª      Vincent du Plessisüé® üíª              Karen Tamrazyanüé® üíª      Mirza Younus Baigüé® üíª      Ashish Kumarüé® üíª      Unknown6334üé® üíª      flowazüé® üíª      zi-aikraüé® üíª      PAYAL PMüé® üíª              Lennart L√∂scheüé® üíª      Yummy-Yumsüé® üíª      Njuacha Hubert Mikulowskiüé® üíª      Hussein Esmailüé® üíª      Bilgehan Bezirüé® üíª      Muhammed Shittuüé® üíª      Cl√©ment FERNANDESüé® üíª              JaCKoP619üé® üíª      userutf8üé® üíª      Mohamed Ubaidüé® üíª      Justin Yatesüé® üíª      mohammad aliüé® üíª      Madhav Singhüé® üíª      RgbMouse69üé® üíª              Nicholas Leasküé® üíª      parthav0üé® üíª      Sigmaüé® üíª      Evelina Bechevaüé® üíª      Akshit Gulyanüé® üíª      Arpita Janaüé® üíª      Praveen Kumarüé® üíª              Mohammad Samiüé® üíª      eddiestefanescuüé® üíª      Ramesh Yadavüé® üíª      Sarthak Joshiüé® üíª      Nikhil12300üé® üíª      Yevgenüé® üíª      Leoüé® üíª              laurent büé® üíª      Mettchenüé® üíª      Ali Mahdaviüé® üíª      Lucas Dondoüé® üíª      Siddhesh Agarwalüé® üíª      slimerPuncherüé® üíª      saritashhüé® üíª              Iulian-Valeriu CioatƒÉüé® üíª      Szabolcs Nagyüé® üíª      Jarle Kvileüé® üíª      ÂäâËÄÄÂçá Vic Liuüé® üíª      Suryanshüé® üíª      Matthew Oosthuyseüé® üíª      Florin Zamfirüé® üíª              Meleküé® üíª      moesocioüé® üíª      Alan Jamesüé® üíª      Mai Thanh Ph∆∞∆°ngüé® üíª      Neville Dabreüé® üíª      Maksymüé® üíª      tamanna900üé® üíª              Adithya Awatiüé® üíª      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
66,ageitgey/face_recognition,https://github.com/ageitgey/face_recognition/blob/master/README.md,Python,"Face RecognitionYou can also read a translated version of this file in Chinese ÁÆÄ‰Ωì‰∏≠ÊñáÁâà or in Korean ÌïúÍµ≠Ïñ¥ or in Japanese Êó•Êú¨Ë™û.Recognize and manipulate faces from Python or from the command line withthe world's simplest face recognition library.Built using dlib's state-of-the-art face recognitionbuilt with deep learning. The model has an accuracy of 99.38% on theLabeled Faces in the Wild benchmark.This also provides a simple face_recognition command line tool that letsyou do face recognition on a folder of images from the command line!FeaturesFind faces in picturesFind all the faces that appear in a picture:import face_recognitionimage = face_recognition.load_image_file(\""your_file.jpg\"")face_locations = face_recognition.face_locations(image)Find and manipulate facial features in picturesGet the locations and outlines of each person's eyes, nose, mouth and chin.import face_recognitionimage = face_recognition.load_image_file(\""your_file.jpg\"")face_landmarks_list = face_recognition.face_landmarks(image)Finding facial features is super useful for lots of important stuff. But you can also use it for really stupid stufflike applying digital make-up (think 'Meitu'):Identify faces in picturesRecognize who appears in each photo.import face_recognitionknown_image = face_recognition.load_image_file(\""biden.jpg\"")unknown_image = face_recognition.load_image_file(\""unknown.jpg\"")biden_encoding = face_recognition.face_encodings(known_image)[0]unknown_encoding = face_recognition.face_encodings(unknown_image)[0]results = face_recognition.compare_faces([biden_encoding], unknown_encoding)You can even use this library with other Python libraries to do real-time face recognition:See this example for the code.Online DemosUser-contributed shared Jupyter notebook demo (not officially supported): InstallationRequirementsPython 3.3+ or Python 2.7macOS or Linux (Windows not officially supported, but might work)Installation Options:Installing on Mac or LinuxFirst, make sure you have dlib already installed with Python bindings:How to install dlib from source on macOS or UbuntuThen, make sure you have cmake installed:brew install cmakeFinally, install this module from pypi using pip3 (or pip2 for Python 2):pip3 install face_recognitionAlternatively, you can try this library with Docker, see this section.If you are having trouble with installation, you can also try out apre-configured VM.Installing on an Nvidia Jetson Nano boardJetson Nano installation instructionsPlease follow the instructions in the article carefully. There is current a bug in the CUDA libraries on the Jetson Nano that will cause this library to fail silently if you don't follow the instructions in the article to comment out a line in dlib and recompile it.Installing on Raspberry Pi 2+Raspberry Pi 2+ installation instructionsInstalling on FreeBSDpkg install graphics/py-face_recognitionInstalling on WindowsWhile Windows isn't officially supported, helpful users have posted instructions on how to install this library:@masoudr's Windows 10 installation guide (dlib + face_recognition)Installing a pre-configured Virtual Machine imageDownload the pre-configured VM image (for VMware Player or VirtualBox).UsageCommand-Line InterfaceWhen you install face_recognition, you get two simple command-lineprograms:face_recognition - Recognize faces in a photograph or folder full forphotographs.face_detection - Find faces in a photograph or folder full for photographs.face_recognition command line toolThe face_recognition command lets you recognize faces in a photograph orfolder full  for photographs.First, you need to provide a folder with one picture of each person youalready know. There should be one image file for each person with thefiles named according to who is in the picture:Next, you need a second folder with the files you want to identify:Then in you simply run the command face_recognition, passing inthe folder of known people and the folder (or single image) with unknownpeople and it tells you who is in each image:$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama/face_recognition_test/unknown_pictures/unknown.jpg,unknown_personThere's one line in the output for each face. The data is comma-separatedwith the filename and the name of the person found.An unknown_person is a face in the image that didn't match anyone inyour folder of known people.face_detection command line toolThe face_detection command lets you find the location (pixel coordinatates)of any faces in an image.Just run the command face_detection, passing in a folder of imagesto check (or a single image):$ face_detection  ./folder_with_pictures/examples/image1.jpg,65,215,169,112examples/image2.jpg,62,394,211,244examples/image2.jpg,95,941,244,792It prints one line for each face that was detected. The coordinatesreported are the top, right, bottom and left coordinates of the face (in pixels).Adjusting Tolerance / SensitivityIf you are getting multiple matches for the same person, it might be thatthe people in your photos look very similar and a lower tolerance valueis needed to make face comparisons more strict.You can do that with the --tolerance parameter. The default tolerancevalue is 0.6 and lower numbers make face comparisons more strict:$ face_recognition --tolerance 0.54 ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama/face_recognition_test/unknown_pictures/unknown.jpg,unknown_personIf you want to see the face distance calculated for each match in orderto adjust the tolerance setting, you can use --show-distance true:$ face_recognition --show-distance true ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,NoneMore ExamplesIf you simply want to know the names of the people in each photograph but don'tcare about file names, you could do this:$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/ | cut -d ',' -f2Barack Obamaunknown_personSpeeding up Face RecognitionFace recognition can be done in parallel if you have a computer withmultiple CPU cores. For example, if your system has 4 CPU cores, you canprocess about 4 times as many images in the same amount of time by usingall your CPU cores in parallel.If you are using Python 3.4 or newer, pass in a --cpus <number_of_cpu_cores_to_use> parameter:$ face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/You can also pass in --cpus -1 to use all CPU cores in your system.Python ModuleYou can import the face_recognition module and then easily manipulatefaces with just a couple of lines of code. It's super easy!API Docs: https://face-recognition.readthedocs.io.Automatically find all the faces in an imageimport face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_locations = face_recognition.face_locations(image)# face_locations is now an array listing the co-ordinates of each face!See this exampleto try it out.You can also opt-in to a somewhat more accurate deep-learning-based face detection model.Note: GPU acceleration (via NVidia's CUDA library) is required for goodperformance with this model. You'll also want to enable CUDA supportwhen compliling dlib.import face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_locations = face_recognition.face_locations(image, model=\""cnn\"")# face_locations is now an array listing the co-ordinates of each face!See this exampleto try it out.If you have a lot of images and a GPU, you can alsofind faces in batches.Automatically locate the facial features of a person in an imageimport face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_landmarks_list = face_recognition.face_landmarks(image)# face_landmarks_list is now an array with the locations of each facial feature in each face.# face_landmarks_list[0]['left_eye'] would be the location and outline of the first person's left eye.See this exampleto try it out.Recognize faces in images and identify who they areimport face_recognitionpicture_of_me = face_recognition.load_image_file(\""me.jpg\"")my_face_encoding = face_recognition.face_encodings(picture_of_me)[0]# my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!unknown_picture = face_recognition.load_image_file(\""unknown.jpg\"")unknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]# Now we can see the two face encodings are of the same person with `compare_faces`!results = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)if results[0] == True:    print(\""It's a picture of me!\"")else:    print(\""It's not a picture of me!\"")See this exampleto try it out.Python Code ExamplesAll the examples are available here.Face DetectionFind faces in a photographFind faces in a photograph (using deep learning)Find faces in batches of images w/ GPU (using deep learning)Blur all the faces in a live video using your webcam (Requires OpenCV to be installed)Facial FeaturesIdentify specific facial features in a photographApply (horribly ugly) digital make-upFacial RecognitionFind and recognize unknown faces in a photograph based on photographs of known peopleIdentify and draw boxes around each person in a photoCompare faces by numeric face distance instead of only True/False matchesRecognize faces in live video using your webcam - Simple / Slower Version (Requires OpenCV to be installed)Recognize faces in live video using your webcam - Faster Version (Requires OpenCV to be installed)Recognize faces in a video file and write out new video file (Requires OpenCV to be installed)Recognize faces on a Raspberry Pi w/ cameraRun a web service to recognize faces via HTTP (Requires Flask to be installed)Recognize faces with a K-nearest neighbors classifierTrain multiple images per person then recognize faces using a SVMCreating a Standalone ExecutableIf you want to create a standalone executable that can run without the need to install python or face_recognition, you can use PyInstaller. However, it requires some custom configuration to work with this library. See this issue for how to do it.Articles and Guides that cover face_recognitionMy article on how Face Recognition works: Modern Face Recognition with Deep LearningCovers the algorithms and how they generally workFace recognition with OpenCV, Python, and deep learning by Adrian RosebrockCovers how to use face recognition in practiceRaspberry Pi Face Recognition by Adrian RosebrockCovers how to use this on a Raspberry PiFace clustering with Python by Adrian RosebrockCovers how to automatically cluster photos based on who appears in each photo using unsupervised learningHow Face Recognition WorksIf you want to learn how face location and recognition work instead ofdepending on a black box library, read my article.CaveatsThe face recognition model is trained on adults and does not work very well on children. It tends to mixup children quite easy using the default comparison threshold of 0.6.Accuracy may vary between ethnic groups. Please see this wiki page for more details.Deployment to Cloud Hosts (Heroku, AWS, etc)Since face_recognition depends on dlib which is written in C++, it can be tricky to deploy an appusing it to a cloud hosting provider like Heroku or AWS.To make things easier, there's an example Dockerfile in this repo that shows how to run an app built withface_recognition in a Docker container. With that, you should be able to deployto any service that supports Docker images.You can try the Docker image locally by running: docker-compose up --buildThere are also several prebuilt Docker images.Linux users with a GPU (drivers >= 384.81) and Nvidia-Docker installed can run the example on the GPU: Open the docker-compose.yml file and uncomment the dockerfile: Dockerfile.gpu and runtime: nvidia lines.Having problems?If you run into problems, please read the Common Errors section of the wiki before filing a github issue.ThanksMany, many thanks to Davis King (@nulhom)for creating dlib and for providing the trained facial feature detection and face encoding modelsused in this library. For more information on the ResNet that powers the face encodings, check outhis blog post.Thanks to everyone who works on all the awesome Python data science libraries like numpy, scipy, scikit-image,pillow, etc, etc that makes this kind of stuff so easy and fun in Python.Thanks to Cookiecutter and theaudreyr/cookiecutter-pypackage project templatefor making Python project packaging way more tolerable."
67,swisskyrepo/PayloadsAllTheThings,https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/README.md,Python,"Payloads All The ThingsA list of useful payloads and bypasses for Web Application Security.Feel free to improve with your payloads and techniques !I ‚ù§Ô∏è pull requests :)You can also contribute with a üçª IRL, or using the sponsor buttonAn alternative display version is available at PayloadsAllTheThingsWeb.  üìñ DocumentationEvery section contains the following files, you can use the _template_vuln folder to create a new chapter:README.md - vulnerability description and how to exploit it, including several payloadsIntruder - a set of files to give to Burp IntruderImages - pictures for the README.mdFiles - some files referenced in the README.mdYou might also like the Methodology and Resources folder :Methodology and ResourcesActive Directory Attack.mdCloud - AWS Pentest.mdCloud - Azure Pentest.mdCobalt Strike - Cheatsheet.mdLinux - Evasion.mdLinux - Persistence.mdLinux - Privilege Escalation.mdMetasploit - Cheatsheet.mdMethodology and enumeration.mdNetwork Pivoting Techniques.mdNetwork Discovery.mdReverse Shell Cheatsheet.mdSubdomains Enumeration.mdWindows - AMSI Bypass.mdWindows - DPAPI.mdWindows - Download and Execute.mdWindows - Mimikatz.mdWindows - Persistence.mdWindows - Privilege Escalation.mdWindows - Using credentials.mdYou want more ? Check the Books and Youtube videos selections.üë®‚Äçüíª ContributionsBe sure to read CONTRIBUTING.md  Thanks again for your contribution! ‚ù§Ô∏èüßô‚Äç‚ôÇÔ∏è SponsorsThis project is proudly sponsored by these companies."
68,xtekky/gpt4free,https://github.com/xtekky/gpt4free/blob/main/README.md,Python,"By using this repository or any code related to it, you agree to the legal notice. The author is not responsible for any copies, forks, or reuploads made by other users. This is the author's only account and repository. To prevent impersonation or irresponsible actions, you may comply with the GNU GPL license this Repository uses.This (quite censored) New Version of gpt4free, was just released, it may contain bugs, open an issue or contribute a PR when encountering one, some features were disabled.Docker is for now not available but I would be happy if someone contributes a PR. The g4f GUI will be uploaded soon enough.Newpypi package:pip install -U g4fTable of Contents:Getting StartedPrerequisitesSetting up the projectUsageThe g4f Packageinterference openai-proxy apiModelsgpt-3.5 / gpt-4Other ModelsRelated gpt4free projectsContributeChatGPT cloneCopyrightCopyright NoticeStar HistoryGetting StartedPrerequisites:Download and install Python (Version 3.x is recommended).Setting up the project:Install using pypipip install -U g4forClone the GitHub repository:git clone https://github.com/xtekky/gpt4free.gitNavigate to the project directory:cd gpt4free(Recommended) Create a virtual environment to manage Python packages for your project:python3 -m venv venvActivate the virtual environment:On Windows:.\\venv\\Scripts\\activateOn macOS and Linux:source venv/bin/activateInstall the required Python packages from requirements.txt:pip install -r requirements.txtCreate a test.py file in the root folder and start using the repo, further Instructions are belowimport g4f...UsageThe g4f Packageimport g4fprint(g4f.provider.Ails.params)  # supported args# Automatic selection of provider# streamed completionresponse = g4f.ChatCompletion.create(    model=\""gpt-3.5-turbo\"",    messages=[{\""role\"": \""user\"", \""content\"": \""Hello world\""}],    stream=True,)for message in response:    print(message, flush=True, end='')# normal responseresponse = g4f.ChatCompletion.create(    model=g4f.models.gpt_4,    messages=[{\""role\"": \""user\"", \""content\"": \""hi\""}],)  # alterative model settingprint(response)# Set with providerresponse = g4f.ChatCompletion.create(    model=\""gpt-3.5-turbo\"",    provider=g4f.provider.DeepAi,    messages=[{\""role\"": \""user\"", \""content\"": \""Hello world\""}],    stream=True,)for message in response:    print(message)providers:from g4f.provider import (    Acytoo,    Aichat,    Ails,    AiService,    AItianhu,    Bard,    Bing,    ChatgptAi,    ChatgptLogin,    DeepAi,    GetGpt)# usage:response = g4f.ChatCompletion.create(..., provider=ProviderName)interference openai-proxy api (use with openai python package)get requirements:pip install -r interference/requirements.txtrun server:python3 -m interference.appimport openaiopenai.api_key = \""\""openai.api_base = \""http://localhost:1337\""def main():    chat_completion = openai.ChatCompletion.create(        model=\""gpt-3.5-turbo\"",        messages=[{\""role\"": \""user\"", \""content\"": \""write a poem about a tree\""}],        stream=True,    )    if isinstance(chat_completion, dict):        # not stream        print(chat_completion.choices[0].message.content)    else:        # stream        for token in chat_completion:            content = token[\""choices\""][0][\""delta\""].get(\""content\"")            if content != None:                print(content, end=\""\"", flush=True)if __name__ == \""__main__\"":    main()Modelsgpt-3.5 / gpt-4WebsiteProvidergpt-3.5gpt-4StreamingStatusAuthwww.aitianhu.comg4f.provider.AItianhu‚úîÔ∏è‚ùå‚ùå‚ùåchat.acytoo.comg4f.provider.Acytoo‚úîÔ∏è‚ùå‚ùå‚ùåaiservice.vercel.appg4f.provider.AiService‚úîÔ∏è‚ùå‚ùå‚ùåchat-gpt.orgg4f.provider.Aichat‚úîÔ∏è‚ùå‚ùå‚ùåai.lsg4f.provider.Ails‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåbard.google.comg4f.provider.Bard‚ùå‚ùå‚ùå‚úîÔ∏èbing.comg4f.provider.Bing‚ùå‚úîÔ∏è‚ùå‚ùåchatgpt.aig4f.provider.ChatgptAi‚ùå‚úîÔ∏è‚ùå‚ùåchatgptlogin.acg4f.provider.ChatgptLogin‚úîÔ∏è‚ùå‚ùå‚ùådeepai.orgg4f.provider.DeepAi‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåchat.dfehub.comg4f.provider.DfeHub‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåfree.easychat.workg4f.provider.EasyChat‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåforefront.comg4f.provider.Forefront‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåchat.getgpt.worldg4f.provider.GetGpt‚úîÔ∏è‚ùå‚úîÔ∏è‚ùågpt-gm.h2o.aig4f.provider.H2o‚ùå‚ùå‚úîÔ∏è‚ùåliaobots.comg4f.provider.Liaobots‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏èsupertest.lockchat.appg4f.provider.Lockchat‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚ùåopchatgpts.netg4f.provider.Opchatgpts‚úîÔ∏è‚ùå‚ùå‚ùåbackend.raycast.comg4f.provider.Raycast‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏ètheb.aig4f.provider.Theb‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåplay.vercel.aig4f.provider.Vercel‚úîÔ∏è‚ùå‚ùå‚ùåwewordle.orgg4f.provider.Wewordle‚úîÔ∏è‚ùå‚ùå‚ùåyou.comg4f.provider.You‚úîÔ∏è‚ùå‚ùå‚ùåchat9.yqcloud.topg4f.provider.Yqcloud‚úîÔ∏è‚ùå‚ùå‚ùåOther ModelsModelBase ProviderProviderWebsitepalmGoogleg4f.provider.Bardbard.google.comh2ogpt-gm-oasst1-en-2048-falcon-7b-v3Huggingfaceg4f.provider.H2owww.h2o.aih2ogpt-gm-oasst1-en-2048-falcon-40b-v1Huggingfaceg4f.provider.H2owww.h2o.aih2ogpt-gm-oasst1-en-2048-open-llama-13bHuggingfaceg4f.provider.H2owww.h2o.aiclaude-instant-v1Anthropicg4f.provider.Vercelsdk.vercel.aiclaude-v1Anthropicg4f.provider.Vercelsdk.vercel.aiclaude-v2Anthropicg4f.provider.Vercelsdk.vercel.aicommand-light-nightlyCohereg4f.provider.Vercelsdk.vercel.aicommand-nightlyCohereg4f.provider.Vercelsdk.vercel.aigpt-neox-20bHuggingfaceg4f.provider.Vercelsdk.vercel.aioasst-sft-1-pythia-12bHuggingfaceg4f.provider.Vercelsdk.vercel.aioasst-sft-4-pythia-12b-epoch-3.5Huggingfaceg4f.provider.Vercelsdk.vercel.aisantacoderHuggingfaceg4f.provider.Vercelsdk.vercel.aibloomHuggingfaceg4f.provider.Vercelsdk.vercel.aiflan-t5-xxlHuggingfaceg4f.provider.Vercelsdk.vercel.aicode-davinci-002OpenAIg4f.provider.Vercelsdk.vercel.aigpt-3.5-turbo-16kOpenAIg4f.provider.Vercelsdk.vercel.aigpt-3.5-turbo-16k-0613OpenAIg4f.provider.Vercelsdk.vercel.aigpt-4-0613OpenAIg4f.provider.Vercelsdk.vercel.aitext-ada-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-babbage-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-curie-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-davinci-002OpenAIg4f.provider.Vercelsdk.vercel.aitext-davinci-003OpenAIg4f.provider.Vercelsdk.vercel.aillama13b-v2-chatReplicateg4f.provider.Vercelsdk.vercel.aillama7b-v2-chatReplicateg4f.provider.Vercelsdk.vercel.aiRelated gpt4free projects            üéÅ Projects      ‚≠ê Stars      üìö Forks      üõé Issues      üì¨ Pull requests                  gpt4free                                      gpt4free-ts                                      ChatGPT-Clone                                      ChatGpt Discord Bot                                      LangChain gpt4free                                      ChatGpt Telegram Bot                              Contributeto add another provider, its very simple:create a new file in g4f/provider with the name of the ProviderImplement a class that extends BaseProvider.from .base_provider import BaseProviderfrom ..typing import CreateResult, Anyclass HogeService(BaseProvider):    url = \""http://hoge.com\""    working = True    supports_gpt_35_turbo = True    @staticmethod    def create_completion(        model: str,        messages: list[dict[str, str]],        stream: bool,        **kwargs: Any,    ) -> CreateResult:        passHere, you can adjust the settings, for example if the website does support streaming, set working to True...Write code to request the provider in create_completion and yield the response, even if its a one-time response, do not hesitate to look at other providers for inspirationAdd the Provider Name in g4f/provider/init.pyfrom .base_provider import BaseProviderfrom .HogeService import HogeService__all__ = [  HogeService,]You are done !, test the provider by calling it:import g4fresponse = g4f.ChatCompletion.create(model='gpt-3.5-turbo', provider=g4f.provider.PROVIDERNAME,                                    messages=[{\""role\"": \""user\"", \""content\"": \""test\""}], stream=g4f.provider.PROVIDERNAME.supports_stream)for message in response:    print(message, flush=True, end='')ChatGPT cloneCurrently implementing new features and trying to scale it, please be patient it may be unstablehttps://chat.g4f.ai/chatThis site was developed by me and includes gpt-4/3.5, internet access and gpt-jailbreak's like DANRun locally here: https://github.com/xtekky/chatgpt-cloneCopyright:This program is licensed under the GNU GPL v3Copyright Notice:xtekky/gpt4free: Copyright (C) 2023 xtekkyThis program is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program.  If not, see <https://www.gnu.org/licenses/>.Star History         "
69,TheAlgorithms/Python,https://github.com/TheAlgorithms/Python/blob/master/README.md,Python,          The Algorithms - Python                                                                  All algorithms implemented in Python - for educationImplementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.Getting StartedRead through our Contribution Guidelines before you contribute.Community ChannelsWe are on Discord and Gitter! Community channels are a great way for you to ask questions and get help. Please join us!List of AlgorithmsSee our directory for easier navigation and a better overview of the project.
70,google/it-cert-automation-practice,https://github.com/google/it-cert-automation-practice/blob/master/README.md,Python,Google IT Automation with Python Professional Certificate - Practice filesThis repository contains the practice files used throughout the courses that arepart of the Google IT Automation with Python Professional CertificateThere's a separate folder for each course.
71,python/cpython,https://github.com/python/cpython/blob/main/README.rst,Python,"This is Python version 3.13.0 alpha 0Copyright ¬© 2001-2023 Python Software Foundation.  All rights reserved.See the end of this file for further copyright and license information.ContentsGeneral InformationContributing to CPythonUsing PythonBuild InstructionsProfile Guided OptimizationLink Time OptimizationWhat's NewDocumentationConverting From Python 2.x to 3.xTestingInstalling multiple versionsRelease ScheduleCopyright and License InformationGeneral InformationWebsite: https://www.python.orgSource code: https://github.com/python/cpythonIssue tracker: https://github.com/python/cpython/issuesDocumentation: https://docs.python.orgDeveloper's Guide: https://devguide.python.org/Contributing to CPythonFor more complete instructions on contributing to CPython development,see the Developer Guide.Using PythonInstallable Python kits, and information about using Python, are available atpython.org.Build InstructionsOn Unix, Linux, BSD, macOS, and Cygwin:./configuremakemake testsudo make installThis will install Python as python3.You can pass many options to the configure script; run ./configure --helpto find out more.  On macOS case-insensitive file systems and on Cygwin,the executable is called python.exe; elsewhere it's just python.Building a complete Python installation requires the use of variousadditional third-party libraries, depending on your build platform andconfigure options.  Not all standard library modules are buildable oruseable on all platforms.  Refer to theInstall dependenciessection of the Developer Guide for current detailed information ondependencies for various Linux distributions and macOS.On macOS, there are additional configure and build options relatedto macOS framework and universal builds.  Refer to Mac/README.rst.On Windows, see PCbuild/readme.txt.If you wish, you can create a subdirectory and invoke configure from there.For example:mkdir debugcd debug../configure --with-pydebugmakemake test(This will fail if you also built at the top-level directory.  You should doa make clean at the top-level first.)To get an optimized build of Python, configure --enable-optimizationsbefore you run make.  This sets the default make targets up to enableProfile Guided Optimization (PGO) and may be used to auto-enable Link TimeOptimization (LTO) on some platforms.  For more details, see the sectionsbelow.Profile Guided OptimizationPGO takes advantage of recent versions of the GCC or Clang compilers.  If used,either via configure --enable-optimizations or by manually runningmake profile-opt regardless of configure flags, the optimized buildprocess will perform the following steps:The entire Python directory is cleaned of temporary files that may haveresulted from a previous compilation.An instrumented version of the interpreter is built, using suitable compilerflags for each flavor. Note that this is just an intermediary step.  Thebinary resulting from this step is not good for real-life workloads as it hasprofiling instructions embedded inside.After the instrumented interpreter is built, the Makefile will run a trainingworkload.  This is necessary in order to profile the interpreter's execution.Note also that any output, both stdout and stderr, that may appear at this stepis suppressed.The final step is to build the actual interpreter, using the informationcollected from the instrumented one.  The end result will be a Python binarythat is optimized; suitable for distribution or production installation.Link Time OptimizationEnabled via configure's --with-lto flag.  LTO takes advantage of theability of recent compiler toolchains to optimize across the otherwisearbitrary .o file boundary when building final executables or sharedlibraries for additional performance gains.What's NewWe have a comprehensive overview of the changes in the What's New in Python3.13 document.  For a moredetailed change log, read Misc/NEWS, but a fullaccounting of changes can only be gleaned from the commit history.If you want to install multiple versions of Python, see the section belowentitled \""Installing multiple versions\"".DocumentationDocumentation for Python 3.13 is online,updated daily.It can also be downloaded in many formats for faster access.  The documentationis downloadable in HTML, PDF, and reStructuredText formats; the latter versionis primarily for documentation authors, translators, and people with specialformatting requirements.For information about building Python's documentation, refer to Doc/README.rst.Converting From Python 2.x to 3.xSignificant backward incompatible changes were made for the release of Python3.0, which may cause programs written for Python 2 to fail when run with Python3.  For more information about porting your code from Python 2 to Python 3, seethe Porting HOWTO.TestingTo test the interpreter, type make test in the top-level directory.  Thetest set produces some output.  You can generally ignore the messages aboutskipped tests due to optional features which can't be imported.  If a messageis printed about a failed test or a traceback or core dump is produced,something is wrong.By default, tests are prevented from overusing resources like disk space andmemory.  To enable these tests, run make testall.If any tests fail, you can re-run the failing test(s) in verbose mode.  Forexample, if test_os and test_gdb failed, you can run:make test TESTOPTS=\""-v test_os test_gdb\""If the failure persists and appears to be a problem with Python rather thanyour environment, you can file a bug report and include relevant output fromthat command to show the issue.See Running & Writing Testsfor more on running tests.Installing multiple versionsOn Unix and Mac systems if you intend to install multiple versions of Pythonusing the same installation prefix (--prefix argument to the configurescript) you must take care that your primary python executable is notoverwritten by the installation of a different version.  All files anddirectories installed using make altinstall contain the major and minorversion and can thus live side-by-side.  make install also creates${prefix}/bin/python3 which refers to ${prefix}/bin/python3.X.  If youintend to install multiple versions using the same prefix you must decide whichversion (if any) is your \""primary\"" version.  Install that version using makeinstall.  Install all other versions using make altinstall.For example, if you want to install Python 2.7, 3.6, and 3.13 with 3.13 being theprimary version, you would execute make install in your 3.13 build directoryand make altinstall in the others.Release ScheduleSee PEP 719 for Python 3.13 release details.Copyright and License InformationCopyright ¬© 2001-2023 Python Software Foundation.  All rights reserved.Copyright ¬© 2000 BeOpen.com.  All rights reserved.Copyright ¬© 1995-2001 Corporation for National Research Initiatives.  Allrights reserved.Copyright ¬© 1991-1995 Stichting Mathematisch Centrum.  All rights reserved.See the LICENSE forinformation on the history of this software, terms & conditions for usage, and aDISCLAIMER OF ALL WARRANTIES.This Python distribution contains no GNU General Public License (GPL) code,so it may be used in proprietary projects.  There are interfaces to some GNUcode but these are entirely optional.All trademarks referenced herein are property of their respective holders."
72,home-assistant/core,https://github.com/home-assistant/core/blob/dev/README.rst,Python,"Home Assistant Open source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server.Check out home-assistant.io for ademo, installation instructions,tutorials and documentation.Featured integrationsThe system is built using a modular approach so support for other devices or actions can be implemented easily. See also the section on architecture and the section on creating your owncomponents.If you run into issues while using Home Assistant or during developmentof a component, check the Home Assistant help section of our website for further help and information."
73,huggingface/transformers,https://github.com/huggingface/transformers/blob/main/README.md,Python,"                                                                                                                    English |        ÁÆÄ‰Ωì‰∏≠Êñá |        ÁπÅÈ´î‰∏≠Êñá |        ÌïúÍµ≠Ïñ¥ |        Espa√±ol |        Êó•Êú¨Ë™û |        ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä        State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow    ü§ó Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.These models can be applied on:üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.üó£Ô∏è Audio, for tasks like speech recognition and audio classification.Transformer models can also perform tasks on several modalities combined, such as table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.ü§ó Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.ü§ó Transformers is backed by the three most popular deep learning libraries ‚Äî Jax, PyTorch and TensorFlow ‚Äî with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.Online demosYou can test most of our models directly on their pages from the model hub. We also offer private model hosting, versioning, & an inference API for public and private models.Here are a few examples:In Natural Language Processing:Masked word completion with BERTName Entity Recognition with ElectraText generation with GPT-2Natural Language Inference with RoBERTaSummarization with BARTQuestion answering with DistilBERTTranslation with T5In Computer Vision:Image classification with ViTObject Detection with DETRSemantic Segmentation with SegFormerPanoptic Segmentation with MaskFormerDepth Estimation with DPTVideo Classification with VideoMAEUniversal Segmentation with OneFormerIn Audio:Automatic Speech Recognition with Wav2Vec2Keyword Spotting with Wav2Vec2Audio Classification with Audio Spectrogram TransformerIn Multimodal tasks:Table Question Answering with TAPASVisual Question Answering with ViLTZero-shot Image Classification with CLIPDocument Question Answering with LayoutLMZero-shot Video Classification with X-CLIP100 projects using TransformersTransformers is more than a toolkit to use pretrained models: it's a community of projects built around it and theHugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyoneelse to build their dream projects.In order to celebrate the 100,000 stars of transformers, we have decided to put the spotlight on thecommunity, and we have created the awesome-transformers page which lists 100incredible projects built in the vicinity of transformers.If you own or use a project that you believe should be part of the list, please open a PR to add it!If you are looking for custom support from the Hugging Face team    Quick tourTo immediately use a model on a given input (text, image, audio, ...), we provide the pipeline API. Pipelines group together a pretrained model with the preprocessing that was used during that model's training. Here is how to quickly use a pipeline to classify positive versus negative texts:>>> from transformers import pipeline# Allocate a pipeline for sentiment-analysis>>> classifier = pipeline('sentiment-analysis')>>> classifier('We are very happy to introduce pipeline to the transformers repository.')[{'label': 'POSITIVE', 'score': 0.9996980428695679}]The second line of code downloads and caches the pretrained model used by the pipeline, while the third evaluates it on the given text. Here the answer is \""positive\"" with a confidence of 99.97%.Many tasks have a pre-trained pipeline ready to go, in NLP but also in computer vision and speech. For example, we can easily extract detected objects in an image:>>> import requests>>> from PIL import Image>>> from transformers import pipeline# Download an image with cute cats>>> url = \""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\"">>> image_data = requests.get(url, stream=True).raw>>> image = Image.open(image_data)# Allocate a pipeline for object detection>>> object_detector = pipeline('object-detection')>>> object_detector(image)[{'score': 0.9982201457023621,  'label': 'remote',  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}}, {'score': 0.9960021376609802,  'label': 'remote',  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}}, {'score': 0.9954745173454285,  'label': 'couch',  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}}, {'score': 0.9988006353378296,  'label': 'cat',  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}}, {'score': 0.9986783862113953,  'label': 'cat',  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]Here we get a list of objects detected in the image, with a box surrounding the object and a confidence score. Here is the original image on the left, with the predictions displayed on the right:        You can learn more about the tasks supported by the pipeline API in this tutorial.In addition to pipeline, to download and use any of the pretrained models on your given task, all it takes is three lines of code. Here is the PyTorch version:>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = AutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""pt\"")>>> outputs = model(**inputs)And here is the equivalent code for TensorFlow:>>> from transformers import AutoTokenizer, TFAutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""bert-base-uncased\"")>>> model = TFAutoModel.from_pretrained(\""bert-base-uncased\"")>>> inputs = tokenizer(\""Hello world!\"", return_tensors=\""tf\"")>>> outputs = model(**inputs)The tokenizer is responsible for all the preprocessing the pretrained model expects, and can be called directly on a single string (as in the above examples) or a list. It will output a dictionary that you can use in downstream code or simply directly pass to your model using the ** argument unpacking operator.The model itself is a regular Pytorch nn.Module or a TensorFlow tf.keras.Model (depending on your backend) which you can use as usual. This tutorial explains how to integrate such a model into a classic PyTorch or TensorFlow training loop, or how to use our Trainer API to quickly fine-tune on a new dataset.Why should I use transformers?Easy-to-use state-of-the-art models:High performance on natural language understanding & generation, computer vision, and audio tasks.Low barrier to entry for educators and practitioners.Few user-facing abstractions with just three classes to learn.A unified API for using all our pretrained models.Lower compute costs, smaller carbon footprint:Researchers can share trained models instead of always retraining.Practitioners can reduce compute time and production costs.Dozens of architectures with over 60,000 pretrained models across all modalities.Choose the right framework for every part of a model's lifetime:Train state-of-the-art models in 3 lines of code.Move a single model between TF2.0/PyTorch/JAX frameworks at will.Seamlessly pick the right framework for training, evaluation and production.Easily customize a model or an example to your needs:We provide examples for each architecture to reproduce the results published by its original authors.Model internals are exposed as consistently as possible.Model files can be used independently of the library for quick experiments.Why shouldn't I use transformers?This library is not a modular toolbox of building blocks for neural nets. The code in the model files is not refactored with additional abstractions on purpose, so that researchers can quickly iterate on each of the models without diving into additional abstractions/files.The training API is not intended to work on any model but is optimized to work with the models provided by the library. For generic machine learning loops, you should use another library (possibly, Accelerate).While we strive to present as many use cases as possible, the scripts in our examples folder are just that: examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs.InstallationWith pipThis repository is tested on Python 3.8+, Flax 0.4.1+, PyTorch 1.10+ and TensorFlow 2.6+.You should install ü§ó Transformers in a virtual environment. If you're unfamiliar with Python virtual environments, check out the user guide.First, create a virtual environment with the version of Python you're going to use and activate it.Then, you will need to install at least one of Flax, PyTorch or TensorFlow.Please refer to TensorFlow installation page, PyTorch installation page and/or Flax and Jax installation pages regarding the specific installation command for your platform.When one of those backends has been installed, ü§ó Transformers can be installed using pip as follows:pip install transformersIf you'd like to play with the examples or need the bleeding edge of the code and can't wait for a new release, you must install the library from source.With condaSince Transformers version v4.0.0, we now have a conda channel: huggingface.ü§ó Transformers can be installed using conda as follows:conda install -c huggingface transformersFollow the installation pages of Flax, PyTorch or TensorFlow to see how to install them with conda.NOTE:  On Windows, you may be prompted to activate Developer Mode in order to benefit from caching. If this is not an option for you, please let us know in this issue.Model architecturesAll the model checkpoints provided by ü§ó Transformers are seamlessly integrated from the huggingface.co model hub where they are uploaded directly by users and organizations.Current number of checkpoints: ü§ó Transformers currently provides the following architectures (see here for a high-level summary of each them):ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.ALIGN (from Google Research) released with the paper Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision by Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yunhsuan Sung, Zhen Li, Tom Duerig.AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.Autoformer (from Tsinghua University) released with the paper Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting by Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.Bark (from Suno) released in the repository suno-ai/bark by Suno AI team.BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.BARThez (from √âcole polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.BLIP-2 (from Salesforce) released with the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi.BLOOM (from BigScience workshop) released by the BigScience Workshop.BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.BridgeTower (from Harbin Institute of Technology/Microsoft Research Asia/Intel Labs) released with the paper BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning by Xiao Xu, Chenfei Wu, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin*, Benjamin Muller*, Pedro Javier Ortiz Su√°rez*, Yoann Dupont, Laurent Romary, √âric Villemonte de la Clergerie, Djam√© Seddah and Beno√Æt Sagot.CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.CLAP (from LAION-AI) released with the paper Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation by Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, Shlomo Dubnov.CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.CLIPSeg (from University of G√∂ttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo L√ºddecke and Alexander Ecker.CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.CPM-Ant (from OpenBMB) released by the OpenBMB.CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar*, Bryan McCann*, Lav R. Varshney, Caiming Xiong and Richard Socher.CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.DeiT (from Facebook) released with the paper Training data-efficient image transformers & distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Herv√© J√©gou.DePlot (from Google AI) released with the paper DePlot: One-shot visual language reasoning by plot-to-table translation by Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier, Yasemin Altun.DETA (from The University of Texas at Austin) released with the paper NMS Strikes Back by Jeffrey Ouyang-Zhang, Jang Hyun Cho, Xingyi Zhou, Philipp Kr√§henb√ºhl.DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.DINOv2 (from Meta AI) released with the paper DINOv2: Learning Robust Visual Features without Supervision by Maxime Oquab, Timoth√©e Darcet, Th√©o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Herv√© Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, Piotr Bojanowski.DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas Oƒüuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by Ren√© Ranftl, Alexey Bochkovskiy, Vladlen Koltun.EfficientFormer (from Snap Research) released with the paper EfficientFormer: Vision Transformers at MobileNetSpeed by Yanyu Li, Geng Yuan, Yang Wen, Ju Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, Jian Ren.EfficientNet (from Google Brain) released with the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan, Quoc V. Le.ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.EnCodec (from Meta AI) released with the paper High Fidelity Neural Audio Compression by Alexandre D√©fossez, Jade Copet, Gabriel Synnaeve, Yossi Adi.EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.ErnieM (from Baidu) released with the paper ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora by Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang.ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.Falcon (from Technology Innovation Institute) by Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme.FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFLAN-UL2 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason WeiFlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, Lo√Øc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno√Æt Crabb√©, Laurent Besacier, Didier Schwab.FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.FocalNet (from Microsoft Research) released with the paper Focal Modulation Networks by Jianwei Yang, Chunyuan Li, Xiyang Dai, Lu Yuan, Jianfeng Gao.Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel WeinbachGPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford*, Jeffrey Wu*, Rewon Child, David Luan, Dario Amodei** and Ilya Sutskever**.GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey √ñhman, Fredrik Carlsson, Magnus Sahlgren.GPTBigCode (from BigCode) released with the paper SantaCoder: don't reach for the stars! by Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo Garc√≠a del R√≠o, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra.GPTSAN-japanese released in the repository tanreinama/GPTSAN by Toshiyuki Sakamoto(tanreinama).Graphormer (from Microsoft) released with the paper Do Transformers Really Perform Bad for Graph Representation? by Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu.GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.Informer (from Beihang University, UC Berkeley, Rutgers University, SEDD Company) released with the paper Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting by Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.InstructBLIP (from Salesforce) released with the paper InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning by Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi.Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Herv√© J√©gou, Matthijs Douze.LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.LLaMA (from The FAIR team of Meta AI) released with the paper LLaMA: Open and Efficient Foundation Language Models by Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample.Llama2 (from The FAIR team of Meta AI) released with the paper Llama2: Open Foundation and Fine-Tuned Chat Models by Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushka rMishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing EllenTan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, Thomas Scialom.Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.MarianMT Machine translation models trained using OPUS data by J√∂rg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.MatCha (from Google AI) released with the paper MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering by Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, Julian Martin Eisenschlos.mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.MEGA (from Meta/USC/CMU/SJTU) released with the paper Mega: Moving Average Equipped Gated Attention by Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer.Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.MGP-STR (from Alibaba Research) released with the paper Multi-Granularity Prediction for Scene Text Recognition by Peng Wang, Cheng Da, and Cong Yao.mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.MMS (from Facebook) released with the paper Scaling Speech Technology to 1,000+ Languages by Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, Michael Auli.MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.MobileViTV2 (from Apple) released with the paper Separable Self-attention for Mobile Vision Transformers by Sachin Mehta and Mohammad Rastegari.MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.MPT (from MosaiML) released with the repository llm-foundry by the MosaicML NLP Team.MRA (from the University of Wisconsin - Madison) released with the paper Multi Resolution Analysis (MRA) for Approximate Self-Attention by Zhanpeng Zeng, Sourav Pal, Jeffery Kline, Glenn M Fung, Vikas Singh.MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.MusicGen (from Meta) released with the paper Simple and Controllable Music Generation by Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi and Alexandre D√©fossez.MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.Nezha (from Huawei Noah‚Äôs Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.NLLB-MOE (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.Nystr√∂mformer (from the University of Wisconsin - Madison) released with the paper Nystr√∂mformer: A Nystr√∂m-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.OneFormer (from SHI Labs) released with the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, Humphrey Shi.OpenLlama (from s-JoL) released in Open-Llama.OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs & Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier H√©naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, Jo√£o Carreira.PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.Pix2Struct (from Google) released with the paper Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding by Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, Kristina Toutanova.PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.PVT (from Nanjing University, The University of Hong Kong etc.) released with the paper Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions by Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao.QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, Sebastian Riedel, Douwe Kiela.REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, ≈Åukasz Kaiser, Anselm Levskaya.RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Doll√°r.RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault F√©vry, Henry Tsai, M. Johnson, Sebastian Ruder.ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.RWKV (from Bo Peng), released on this repo by Bo Peng.SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.Segment Anything (from Meta AI) released with the paper Segment Anything by Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alex Berg, Wan-Yen Lo, Piotr Dollar, Ross Girshick.SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.SpeechT5 (from Microsoft Research) released with the paper SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing by Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei.SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.SwiftFormer (from MBZUAI) released with the paper SwiftFormer: Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications by Abdelrahman Shaker, Muhammad Maaz, Hanoona Rasheed, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan.Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.Swin2SR (from University of W√ºrzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, Pawe≈Ç Krzysztof Nowak, Thomas M√ºller, Francesco Piccinno and Julian Martin Eisenschlos.TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.Time Series Transformer (from HuggingFace).TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey LevineTransformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai*, Zhilin Yang*, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.TVLT (from UNC Chapel Hill) released with the paper TVLT: Textless Vision-Language Transformer by Zineng Tang, Jaemin Cho, Yixin Nie, Mohit Bansal.UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald MetzlerUMT5 (from Google Research) released with the paper UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining by Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, Noah Constant.UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll√°r, Ross Girshick.ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.ViViT (from Google Research) released with the paper ViViT: A Video Vision Transformer by Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Luƒçiƒá, Cordelia Schmid.Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.X-MOD (from Meta AI) released with the paper Lifting the Curse of Multilinguality by Pre-training Modular Transformers by Jonas Pfeiffer, Naman Goyal, Xi Lin, Xian Li, James Cross, Sebastian Riedel, Mikel Artetxe.XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau*, Kartikay Khandelwal*, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm√°n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.XLM-V (from Meta AI) released with the paper XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models by Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa.XLNet (from Google/CMU) released with the paper ‚ÄãXLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang*, Zihang Dai*, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.YOLOS (from Huazhong University of Science & Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.Want to contribute a new model? We have added a detailed guide and templates to guide you in the process of adding a new model. You can find them in the templates folder of the repository. Be sure to check the contributing guidelines and contact the maintainers or open an issue to collect feedbacks before starting your PR.To check if each model has an implementation in Flax, PyTorch or TensorFlow, or has an associated tokenizer backed by the ü§ó Tokenizers library, refer to this table.These implementations have been tested on several datasets (see the example scripts) and should match the performance of the original implementations. You can find more details on performance in the Examples section of the documentation.Learn moreSectionDescriptionDocumentationFull API documentation and tutorialsTask summaryTasks supported by ü§ó TransformersPreprocessing tutorialUsing the Tokenizer class to prepare data for the modelsTraining and fine-tuningUsing the models provided by ü§ó Transformers in a PyTorch/TensorFlow training loop and the Trainer APIQuick tour: Fine-tuning/usage scriptsExample scripts for fine-tuning models on a wide range of tasksModel sharing and uploadingUpload and share your fine-tuned models with the communityCitationWe now have a paper you can cite for the ü§ó Transformers library:@inproceedings{wolf-etal-2020-transformers,    title = \""Transformers: State-of-the-Art Natural Language Processing\"",    author = \""Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R√©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\"",    booktitle = \""Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"",    month = oct,    year = \""2020\"",    address = \""Online\"",    publisher = \""Association for Computational Linguistics\"",    url = \""https://www.aclweb.org/anthology/2020.emnlp-demos.6\"",    pages = \""38--45\""}"
74,keras-team/keras,https://github.com/keras-team/keras/blob/master/README.md,Python,"Keras: Deep Learning for humansThis repository hosts the development of the Keras library.Read the documentation at keras.io.About KerasKeras is a deep learning API written in Python,running on top of the machine learning platform TensorFlow.It was developed with a focus on enabling fast experimentation andproviding a delightful developer experience.The purpose of Keras is to give an unfair advantage to any developer looking to ship ML-powered apps.Keras is:Simple -- but not simplistic. Keras reduces developer cognitive loadto free you to focus on the parts of the problem that really matter.Keras focuses on ease of use, debugging speed, code elegance & conciseness,maintainability, and deployability (via TFServing, TFLite, TF.js).Flexible -- Keras adopts the principle of progressive disclosure ofcomplexity: simple workflows should be quick and easy, while arbitrarilyadvanced workflows should be possible via a clear path that builds uponwhat you've already learned.Powerful -- Keras provides industry-strength performance andscalability: it is used by organizations and companies including NASA,YouTube, and Waymo. That's right -- your YouTube recommendations arepowered by Keras, and so is the world's most advanced driverless vehicle.Keras & TensorFlow 2TensorFlow 2 is an end-to-end, open-source machine learning platform.You can think of it as an infrastructure layer fordifferentiable programming.It combines four key abilities:Efficiently executing low-level tensor operations on CPU, GPU, or TPU.Computing the gradient of arbitrary differentiable expressions.Scaling computation to many devices, such as clusters of hundreds of GPUs.Exporting programs (\""graphs\"") to external runtimes such as servers, browsers, mobile and embedded devices.Keras is the high-level API of TensorFlow 2: an approachable, highly-productive interfacefor solving machine learning problems,with a focus on modern deep learning. It provides essential abstractions and building blocks for developingand shipping machine learning solutions with high iteration velocity.Keras empowers engineers and researchers to take full advantage of the scalabilityand cross-platform capabilities of TensorFlow 2: you can run Keras on TPU or on large clusters of GPUs,and you can export your Keras models to run in the browser or on a mobile device.First contact with KerasThe core data structures of Keras are layers and models.The simplest type of model is the Sequential model, a linear stack of layers.For more complex architectures, you should use the Keras functional API,which allows you to build arbitrary graphs of layers or write models entirely from scratch via subclassing.Here is the Sequential model:from tensorflow.keras.models import Sequentialmodel = Sequential()Stacking layers is as easy as .add():from tensorflow.keras.layers import Densemodel.add(Dense(units=64, activation='relu'))model.add(Dense(units=10, activation='softmax'))Once your model looks good, configure its learning process with .compile():model.compile(loss='categorical_crossentropy',              optimizer='sgd',              metrics=['accuracy'])If you need to, you can further configure your optimizer. The Keras philosophy is to keep simple things simple,while allowing the user to be fully in control when they need to be (the ultimate control being the easy extensibility of the source code via subclassing).model.compile(loss=tf.keras.losses.categorical_crossentropy,              optimizer=tf.keras.optimizers.SGD(                  learning_rate=0.01, momentum=0.9, nesterov=True))You can now iterate on your training data in batches:# x_train and y_train are Numpy arrays.model.fit(x_train, y_train, epochs=5, batch_size=32)Evaluate your test loss and metrics in one line:loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)Or generate predictions on new data:classes = model.predict(x_test, batch_size=128)What you just saw is the most elementary way to use Keras.However, Keras is also a highly-flexible framework suitable to iterate on state-of-the-art research ideas.Keras follows the principle of progressive disclosure of complexity: it makes it easy to get started,yet it makes it possible to handle arbitrarily advanced use cases,only requiring incremental learning at each step.In pretty much the same way that you were able to train & evaluate a simple neural network above in a few lines,you can use Keras to quickly develop new training procedures or exotic model architectures.Here's a low-level training loop example, combining Keras functionality with the TensorFlow GradientTape:import tensorflow as tf# Prepare an optimizer.optimizer = tf.keras.optimizers.Adam()# Prepare a loss function.loss_fn = tf.keras.losses.kl_divergence# Iterate over the batches of a dataset.for inputs, targets in dataset:    # Open a GradientTape.    with tf.GradientTape() as tape:        # Forward pass.        predictions = model(inputs)        # Compute the loss value for this batch.        loss_value = loss_fn(targets, predictions)    # Get gradients of loss wrt the weights.    gradients = tape.gradient(loss_value, model.trainable_weights)    # Update the weights of the model.    optimizer.apply_gradients(zip(gradients, model.trainable_weights))For more in-depth tutorials about Keras, you can check out:Introduction to Keras for engineersIntroduction to Keras for researchersDeveloper guidesOther learning resourcesInstallationKeras comes packaged with TensorFlow 2 as tensorflow.keras.To start using Keras, simply install TensorFlow 2.You can then import Keras as follows:from tensorflow import kerasRelease and compatibilityKeras has nightly releases (keras-nightly on PyPI)and stable releases (keras on PyPI).The nightly Keras releases are usually compatible with the corresponding versionof the tf-nightly releases(e.g. keras-nightly==2.7.0.dev2021100607 should beused with tf-nightly==2.7.0.dev2021100607).We don't maintain backward compatibility for nightly releases.For stable releases, each Kerasversion maps to a specific stable version of TensorFlow.The table below shows the compatibility version mappingbetween TensorFlow versions and Keras versions.All the release branches can be found on GitHub.All the release binaries can be found on Pypi.SupportYou can ask questions and join the development discussion:In the TensorFlow forum.On the Keras mailing list.Opening an issueYou can also post bug reports and feature requests (only)in GitHub issues.Opening a PRWe welcome contributions! Before opening a PR, please readour contributor guide,and the API design guideline."
75,Ebazhanov/linkedin-skill-assessments-quizzes,https://github.com/Ebazhanov/linkedin-skill-assessments-quizzes/blob/main/README.md,Python,"Linkedin Skill assessments - Answers‚ö†Ô∏è DISCLAIMER: The owners of this repository are not liable for any illegal usage of the content provided in this repository. The content is provided for informational and educational purposes only, and any actions taken by users of this repository are the responsibility of the user. By accessing this repository, you agree to hold the owners harmless from any claims, damages, or expenses arising from the use of the information provided.[ Go to see the last contributor ]üôè PLEASEAlways add explanation (or reference link) to your answers. Use online grammar checker.That would help anyone to better learn new concepts!üéâ AnnouncementsColumn Translation have links to quizzes in different languages like Es, Fr, It and De.If you want to meet each other or discuss quiz related problems or maybe ask for skills endorsement just join the Discord chat.Playground before taking quiz using:MD2Practice (Web App)Skill Assessments Quizzes (Web App)LinkedIn Quizzed with Kodyfire (Terminal)Want to contribute? Here is the source code.‚ùì Need help?Open new issueüî• Open in VS Code view here or thereTable of ContentsLinkedin-quiz-questionsPassed/FailedTranslated  in ...QuestionsAnswersYour resource for answers. In case you have doubts please contact this person or add them to review your PR.Accounting‚ùóneeds updating  5049@tujinwei, @mervynteo, @johnfelipeAdobe-Acrobat  2722Adobe-Illustrator‚ùóneeds updating  7674Adobe-InDesign‚ùóneeds updating  4240Adobe-Lightroom‚ùóneeds updating  2020Adobe-Photoshop‚ùóneeds updating  9393@declarckAdobe Premiere Pro  4836Adobe XD  1613After Effects‚ùóneeds updating  2413Agile Methodologies‚ùóneeds updating  116116@its0x08Android  7272@surajsahani, @mr-shoxruxbek, @ItSNeverLateAngular  7965@vanekbr, @aamita96ArcGIS Products55AutoCAD‚ùóneeds updating  7775@djayorAutodesk Fusion 360‚ùóneeds updating  3725@djayor, @tm-sanjayAutodesk Maya3030@marifogluAWS  9999@jokerkeny, @Amsal1AWS-Lambda‚ùóneeds updating  5149Bash  7877@D4RIO, @Amsal1C#6161@LiviuSosu, @RamonMartinezNieto, @declarckC++‚ùóneeds updating7373@Amsal1, @Amsal1C (Programming Language)8383@makifay, @Amsal1, @its0x08CSS122116@BHARGAVPATEL1244Cybersecurity‚ùóneeds updating10196Django7171@PROCW.NET Framework6359@declarckEclipse‚ùóneeds updating3628Front-end Development6868@vanekbr, @ShankS3, @declarckGit134134@Emanuele-emGo (Programming Language)4040@ruslanbes, @monkrusGoogle Ads2925Google Analytics8282Google Cloud Platform (GCP)5250@antra0497Hadoop7154HTML129128@declarckIT Operations5454@asahioceanJava130130@sumanas27, @ruslanbes, @PROCWJavascript131131@taletski, @PROCW, @msteiner96, @declarckjQuery8477@declarckJSON‚ùóneeds updating8786@iHamzaKhanzadaKeynote140Kotlin7878@ItSNeverLate, @HusseinhjLinux8278@D4RIO, @Amsal1Logic Pro8278Machine Learning9898@aaronwangj, @antra0497MATLAB7070@tm-sanjayMaven5350Microsoft Access3028@drmegalomaniacMicrosoft Azure5553@tomtreffke, @ziasistaniMicrosoft Excel‚ùóneeds updating109107@gazihasanrahmanMicrosoft Outlook7956Microsoft Power Automate1402@mervynteoMicrosoft Power BI8180@vittorio-giattiMicrosoft Power Point8577@ckulloMicrosoft Project‚ùóneeds updating4443Microsoft Word‚ùóneeds updating7877MongoDB7777MySQL9797@ruslanbesnode.js7976@pbachmanNoSQL5655objective-c4038OOP10282@declarck, @gaurovgiriPHP8979@ruslanbes, @msteiner96Pro Tools22Python176176@tik9, @Amsal1, @declarck, @TSG405QuickBooks‚ùóneeds updating6739R5252@gregglindReact.js100100@RobTables @bandinoplaREST API6565Revit‚ùóneeds updating140Ruby on Rails5959@gudataRust3232@BobbyByrne @Emanuele-emScala5248Search Engine Optimization (SEO)8181SharePoint‚ùóneeds updating5338Sketchup22SOLIDWORKS‚ùóneeds updating5757@BHARGAVPATEL1244Spring Framework6767Swift6767Transact-SQL (T-SQL)4542@beefydog, @BenVlodgiUnity‚ùóneeds updating4746@uno-sebastianVisual Basic for Applications (VBA)‚ùóneeds updating3634@AdamKaczor6250Visio3535Windows Server6857WordPress8073@ruslanbes, @Amsal1XML4342@ruslanbesContributors ‚ú®Thanks goes to these wonderful people (emoji key):            Evgeniiüíª üñã      Sergei Stadniküíª üîç ü§î üìñ      Santhoshüíª      Jacob Dsaüíª üñã      Aaron Meeseüíª üñã      arqarqüíª üñã      Amit Yadavüíª üñã              Javokhir Nazarovüíª üñã      saurav kumarüñã      Chetanüñã      Amir Hossein Shekariüé® üñã üíª      SergDautüé®      Nilotpal Pramaniküé® üíª üñã üíº üìñ üî£ üí°      Abhishek Kumarüé®              Monu Guptaüé®      KARTIKEYA GUPTAüíª üñã      kenkyushaüíª üñã      juandavidtowersüíª üñã      cyber-neticsüíª üñã      jtriswüíª üñã      Renato Regaladoüíª üñã              Matthewüíª üñã      Jan S.üíª üñã      Manoliüíª üñã      Faraz tanveerüíª üñã      mohnishkarriüíª üñã üé®      andyzhuüíª üñã      Vishal Kushwahüíª üñã              Yurii Yakymenkoüíª üñã      Swetabh Sumanüíª üñã      AJAY DANDGEüíª üñã      Mehmet Yesinüé®      Lok Chun Waiüé®      Adria de Juanüé®      GL-Manüé®              Jheel Patelüé®      Sameer Waskarüé®      Alexander Andrewsüé®      Alexander Maxwellüé®      Slavaüé®      Mayur Khatriüé®      Mascantoshüíª üñã üì¢ ü§î              Kivanc Enesüé®      Ritika Dasüé®      Zer07793üé®      Andrew Cheungüé®      Sadhaüé®      tainenkoüé® üíª      github-star-coderüé®              Danilo Oliveiraüé®      lordekoüé®      Shubham Kumarüé® üíª      testtreeüé®      Cheryl Murphyüé® üíª      Bipin Thomasüé®      Abdulrahman Hishamüé®              Dakshitha Dissanayakaüé®      BADR KACIMIüé®      Alex Wangüé®      Maximüé®      GordonGrantüé® üíª      Ephrem Demelashüé®      JonOrcuttüé®              topdev10üé®      cookwellwebsiteüé®      xren935üé®      Nemo Frenkelüé®      MD SAIF ALAMüé®      Boris L√≥pez Arayaüé®      Larry Chiemüé®              Muhammad Bilal Ilyasüé®      AliMilaniüé® üíª      Suraj Sahaniüé®      FlyingSquirrelüé®      Erick Tijeroüé®      Jaskaran Kukrejaüé®      MichaelLüé®              MagicLegendüé®      Dereck Bearsongüé®      Pappu Kumar Pashiüé®      Venkata Kishore Tavvaüé®      Rafat Touqir Rafsunüé®      Snehesh Duttaüé®      Timo K√∂rnerüé® üíª              alexxxanüé®      GGJasonüé®      LeeAnna Ewingüé® ü§î      kamal Jyotwalüé®      Bob-Johnsüé® üíª üñã      yunussalmanlyitüé® üíª      chilcotüé® üíª              Jacky Liüíª üñã üé®      Sarthak Trivediüé®      Ayush Aggarwalüé® üíª      Nic Ballariniüé®      Luigi Zambettiüé® üíª      govindhaswinüé®      Addy Royüíª üé®              Akshat Tamrakarüé® üíª      Sai Bhargava Ramuüé®      Gurkanüíª      Spencer Hayes-Laverdiereüíª      Aniket Soniüíª      tanmay5792üíª      Dina Taklitüíª üé® üñã              Dushyant Singhüíª      Ravi Prakash Singhüíª      Nihal Joshiüíª      Guy Klagesüíª      Arvindüé® üíª      mujeeb91üíª      josercaüé® üíª              Prateek Agrawalüíª      Teoh Tze Chuin(„Çµ„É©)üíª üé®      Jayant Jainüíª      Ayush Sahuüíª      Hridya Krishna Rüíª üé®      Rahul Baliüíª üé®      S.ZHengüé® üíª üíº              Shriya Madanüé® üíª      mahalrupiüé®      Lucas Lermagneüé®      Jeff Deutschüé® üíª      Betoxx1üé®      Wingman4l7üé®      Martin Espericuetaüé®              Mh-Tahirüé®      Zdravko ≈†plajtüé® üíª      Ms3105üé® üíª üñã      Ambika Sidheswareüíª      mundogueroüíª      Darkus24üñã      Sou-786üñã üé®              Banurekhaüñã      ShiraStarLüé®      Ilya Komarovüé®      DemigodMsüñã üìñ      Mekha Hridyaüé® üîç      Andrey Safonovüé® üîç      Tommasoüé® üíª              Jessica Salbertüíª üé®      JAYANTH DOLAIüíª üé®      silverstroomüíª üé® üíº      Furkan Sayƒ±müíª üé®      Sukumar Chandrasekaranüé®      Yejin Parküé® üíª      Ali Nooshabadiüé® üíª              imitavorüé® üíª      Salih Kilicliüé® üíª      Marcelo Menesesüé® üíª      Anton Krekotunüé® üöß üñã üíª üìñ üíº      Arnav Sarmaüíª üí° üé®      meghatikuüíª üé®      Anshu Trivediüé®              Taylor Dorsettüíª üñã üé®      Havit Roviküíª      pushpapuneüíª üé®      Ramtin Radfarüé® ü§î üíº üíµ üíª üñã üí¨      Abdulmajeed Isaüíª üé®      vikassaxena02üé®      RobTablesüé® üíª üíº              Danielüé® üíª üíº üîç      Zahid Aliüíª üé®      Chad Chaiüíª üé®      Marco Biedermannüíª üé® üíº ü§î      Srinidhi Murthyüé®      Miao Caiüíª üé®      Dionicio Diazüé® üíª              Mir Monoarul Alamüé®      Shawn Ohnüíª üé®      Amanbolat Balabekovüé® üíª      black-mamba-codeüíª      Jian-forksüé® üíª      shivani patelüé®      Akash Chowrasiaüé®              yairg98üé®      Jay Gajjarüé®      coolerboolerüíª      Md Zinnatul Islam Morolüé®      shresthashok550üé® üìñ      Alan Pallathüìñ      Adrian Wongüíª              vsDizzyüíª üé®      Frex Cuadilleraüé® üíª      ashish570üíª üé®      ruchpeanutsüíª üé®      Artmasqueüé® üíª      Amirhossein Mojiri Foroushaniüé®      forüíª üé®              Lukeüé® üíª      Hector Espinozaüé®      Adri√°n Buenfilüé® üíª      Amit Kumarüé®      schoppfeüé® üíª      Sofiyal Cüé® üíª      spitlisküíª üé®              PRAVIN SHARMAüé®      NIDZAAA1üé® üíª      John Maiüé® üíª      kimsoyeongüé®      Dona Ghoshüíª      Ryan Hillüé® üíª      j42züé® üíª              Ashish Sangaleüé® üíª      Derek Yangüé® üíª      mohsinmsmüé® üíª      Gokulkrish2302üíª      Bhaavisheküíª üé®      Louis Liaoüé®      sengc92üé® üíª              Alex Marvinüé®      Balkrishna Bhattüé® üíª      Evaldas Lavrinoviƒçiusüé® üíª      Adam Erchegyiüé® üíª      Truman Hungüé® üíª      rzamora11üé®      gaurav0224üé®              Lee GyeongJunüé®      Mireküé® üíª      surajm245üé®      ArisLaodeüé® üíª      RaviDhoriyaüé® üíª      sarai-84üé® üíª      Vishnuüé® üíª              Muhammad Minhajüíª      Chandrika Debüé® üíª      Gitgit101-bitüíª üé®      Hedi Sellamiüíª üé®      saurabhvaish93üíª üé®      Nikola Begovicüíª üé®      Wangüíª üé®              Manuel Eusebio de Paz Carmonaüé®      Basim Al-Jawaheryüé® üíª      RAJA AHMEDüé® üíª      Abhik Lodhüíª      Md. Pial Ahamedüíª üé®      Hassan Shahzadüíª üé®      Christian Sosa Gagoüíª              Hasnain Rasheedüíª üé®      T-Radfordüíª      dahiyashishüíª üé®      RahulSharma468üíª üé®      Jumpod Plekhongthuüíª üé®      Thomas Young-Audetüíª üé®      VinayagamBabuüíª üé®              Deniz Ko√ßüíª üé®      Azhar Khanüíª üé® üñã üìñ üî£ üöß      Jacob Shortüíª üé®      Uchimura85üíª üé®      Leo Nugrahaüíª üé® üìñ      Mujtaba Mehdiüìñ üñã      Jim-dsüíª üé®              Sreehari Küíª üé®      Florian Martinezüíª üé®      Aaronüíª üé®      apoageüé®      Ignacio Guillermo Martinez üíª üé®      AirlineDogüé® üíª      Mekelüé® üíª              hmosharrofüé® üíª      Ben Emamianüíª üé®      babesharküíª üé®      Leonardo Jaquesüíª üé®      Stefanos Apkarianüíª üé®      Ayhan Albayraküíª üé®      KidusMTüíª üé®              hectormarroquin20üíª üé®      Edelweiss35üíª üé®      MihaiDüíª üé®      AnveshReddyAnnemüíª üé®      Hyunjae Parküíª üé®      Rajiv Albinoüíª üé®      Atishayüíª              Yusuf Naheemüé®      Winduüé® üíª      Superv1sorüíª üé®      Karine (:üé® üíª      Eduard Pechüé® üíª      jjeshwaniüé® üíª      Steveüé® üíª              Aleigh Ohslundüíª      Abhinav Sumanüé® üíª      Hamza Ehtesham Farooqüé® üíª      IamNotPeterPanüíª üíµ üé®      Cetgerüé®      pkonopackiüé®      Yang Yangüé® üíª              Muhammad Shoaib Sarwarüíª      Murilo Henriqueüíª üé®      emilianoalvzüé® üíª      Sumana Sahaüé® üíª      Yurii17Küé® üíª      Rupesh Bhandariüé® üíª      salmos3718üíª              John Bakerüé® üíª      SanjaySathirajuüé® üíª      Donat Kabashiüé®      Arul Prasad Jüé® üíª      Qi Chenüé® üíª      Maksym Dmyterkoüé® üíª      ilovepullrequestsüíª              Samira Malekiüé® üíª      NIKITA MAHOVIYAüíª      jesuisdev.Netüé® üíª      Ashraf Nazarüé®      Naveed Ahmadüé®      Ajmain Naqibüé® üíª      Avinash Tingreüíª üé®              nicktidsüé®      Keith Dinhüíª üé®      Andr√© Ferreiraüíª üé®      eliottkespiüíª üé®      praveenpnoüíª üé®      vitowidigdoüíª üé®      Devesh Pratap Singhüíª üé®              Dario Rodriguezüíª üé®      charmander_didiüíª üé®      PHBasinüíª üé®      Ritvik Singh Chauhanüíª üé®      Riya P Mathewüíª üé®      Stephanie Cherubinüíª üé®      BenitesGuiüíª üé®              FarikBearüíª üé®      Dmytro Havrilovüíª üé®      Parvesh Monuüíª üé®      Dipen Panchasaraüíª üé®      gudataüé® üíª      gawadeditorüíª üé®      Kirill Taletskiüé® üíª              Saajanüé® üíª      Kushagra Süé® üíª      Oanh Leüé® üíª      Frane Medvidoviƒáüé® üíª      Yormanüé® üíª      Bill Chanüé® üíª      Pratik Lomteüé® üíª              LOC LAMüé® üíª      TUSAR RANJAN MAHAPATRAüíª      BhargavKanjarlaüíª      Karel De Smetüíª üé®      sidisanüé®      ygnzayarphyoüé® üíª      svansteelandtüíª              Kebechetüé®      Daniel Selvan Düé® üíª      Mahdi Razaviüé® üíª      Niklas Tiedeüíª üé®      narutubaderddinüíª üé®      dylandhoodüíª      Dheeraj Guptaüíª              Pieter Claerhoutüíª üé®      Shivam Agnihotriüíª      RanjithReddy-Narraüíª      Nikita Wadhwaniüé® üíª      rsholokhüíª üé®      Ayaan Hossainüíª üé®      Rajesh Swarnaüíª              Deniz Etkarüé® üíª      pro335üíª üé®      Jakub Radziküíª üé®      Hamza Khanzadaüíª      ARNONüé®      Vikram Singhüíª      Shoxruxbeküíª üé®              Amit Khatriüíª üé®      Wali Ullahüé® üíª      Amit11794üíª üé®      metis-macys-66898üíª üé®      Faisal Maqboolüé® üíª      Kumar Neerajüíª üé®      Maurizio Mariniüé® üíª              Saket Kothariüé® üíª      Szymon Zborowskiüé® üíª      iks3000üé® üíª      Ehsan Seyediüé® üíª      vanekbrüé® üíª      Princy_Müé® üíª      Shijie Zhouüé® üíª              lakshyamcs16üé® üíª      Filippo Faccoüé® üíª      mendel5üé® üíª      Patryküé® üíª      VishwaSanganiüé® üíª      Alvin Zhaoüé® üíª      Lazar Gugletaüé® üíª              vmichoüé® üíª      Sikandar Aliüé® üíª      Raja Babuüé® üíª      faizajahanzebüíª      Guil_AiTüé® üíª      Kushal Dasüé® üíª      Luis Bonillaüé® üíª              jovan1013üé® üíª      Damianüé® üíª      Yash Guptaüíª      lolcatnipüé® üíª      Ikko Ashimineüé® üíª      Farukhüé® üíª      Moksedulüíª üé®              Navneet Kumarüé® üíª      Saqib AlMaliküíª      fahimrahmanüé® üíª      vaibhav patilüé® üíª      Rahul Madanüé® üíª      kartik Kaklotarüé® üíª      ASAHI OCEANüé® üíª              Daniel Jungbluthüé® üíª      Rajdeep Singh Boranaüé® üíª      ankitha19üíª      Linh Tranüíª      islamarrüíª üé®      Mohamed Sabithüé® üíª      Miguel Angel Cruz Acostaüé® üíª              Adebayo Ilerioluwa üé®      Markusüé® üíª      dkonyayevüé® üíª      Kevin A Mathewüé® üíª      David Meloüé® üî£      DFW1Nüé® üíª      Sohaib Ayubüé® üíª              Navvyüé® üíª      bloodiator2üé® üíª      Hanjiüé® üíª      arthur74üé® üíª      Sri Subathra Devi Büé® üíª      Akif Aydogmusüé® üíª      Umer Javaidüé® üíª              Norio Umataüé® üíª      Gazi Hasan Rahmanüé® üíª      Keith Nguyenüé® üíª      Megalomaniacüé® üíª      ShankS3üé® üíª      Farhad Alishovüé® üíª      Ronak J Vanpariyaüé® üíª              azrael0learzaüé® üíª      Pavel Rahmanüé® üíª      chuabernüé® üíª      Rahul Tirkeyüé® üíª      Ruslan Besüé® üíª üí° üöß üñã üî£ üöá      Bohdanüé® üíª      Juzdzewskiüé® üíª              Grigor Minasyanüé® üíª      alvintwcüé® üíª      Anand Natarajanüé® üíª      Kashan Aliüé® üíª      Thomas Meshailüé® üíª      Son Phamüé®      Michael Frenchüí°              Yash Mishraüìñ      Miguel Rodriguezüé® üíª      Philipp Bachmannüé® üíª      sunnyüé® üíª      Siddharth Chatterjeeüé® üíª      Michael Naghavipourüé® üíª      Sahil Gargüé® üíª              MicroLionüé® üíª      wctwcüé® üíª      Rohan Sharmaüî£      AshishBodlaüé® üíª      Taras Pysarskyiüé® üíª      Luqman Bello O.üé® üíª      DyingDownüé® üíª              Diego Chapedelaineüé® üíª      Richleeüé® üíª      Asif Habibüé® üíª      Mazharul Hossainüé® üíª      toniüé® üíª      Pragyanshu Raiüé® üíª      Matthew Ellerüé® üíª              AbhiBijuüé® üíª      Roman Zhornytskiyüé® üíª      Lucas Caminoüé® üíª      Jo√£o Vitor Casarinüé® üíª      Evgeniy Shayüé® üíª      Ehsan Barkhordarüé® üíª      Gabrielüé® üíª              Shibu Mohapatraüé® üíª      Pavel Kirkovskyüé® üíª      Tahir Gulüé® üíª      imDevSalmanüé® üíª      Jordan Donaldsonüé® üíª      js-venusüé® üíª      Faisal Shaikhüé® üíª              ashishbpatilüé® üíª      Tri Leüé® üíª      tomtreffkeüé® üíª      Salah Eddine Lalamiüé® üíª      Mattias Xuüé® üíª      Manas Guptaüé® üíª      wolfsong62üé® üíª              Mehdi Mirzaeiüé® üíª      Van Ba Khanhüé® üíª      Sel Embeeüé® üíª      Suvradip Paulüé® üíª      Shariqueüé®      Seabassüé® üíª      Penny Liuüé® üíª              jatinder bholaüé® üíª      misterqbitüé® üíª      Daniel-VS9üé® üíª      Shruthiüé® üíª      beefydogüé® üíª      Suraj Kumarüé® üíª      hrishikeshpsüé® üíª              Sudarshanüé® üíª      Divyanshüíª üé®      Zyaireüé® üíª      Omar Belkadyüé® üíª      alexiismuaüé® üíª      Eduarda Alvesüé®      pycoachüé® üíª              Ruhulüé® üíª      pmoustopoulosüé® üíª      Lee Hui Tingüíª üé®      bodi1981üé® üíª      Devaraat Joshiüé® üíª      Johnnyüé® üíª      rogue-coderüé® üíª              viiktrüé®      Lalit Mohanüíª      Jo√£o Sousaüíª      Ë®ÄËëâ‰πãÈùàüíª üé®      RJLABSüíª      brittney0522üé® üíª      shamüé® üíª              Glenn Goossensüíª üé®      Cyber Hawküé® üíª üñã üíº      Ankit Yadavüé® üíª      verbalityüíª      Mohammed Siddiquiüé® üíª      AdamKaczor6250üé® üíª      Ram√≥n Martinez Nietoüé® üíª              Grzegorz Dziubaküé® üíª      Ayoub BERDEDDOUCHüé® üíª      nikola-fadvüé® üíª      Akarsh Agrawalüé® üíª      Mitra Mirshafieeüé® üíª      Parker Stephensüé® üíª      alrenee99üíª              Karthick Vankayalaüíª      Iryna üé® üíª      palanugrahüíª      Gwinbleindüé® üíª      Randy Bobandyüé® üíª      Bek Rozikoffüíª      davnguyeüé® üíª              Neel Patelüíª      ehudbeharüé® üíª      nicholas-cod3rüé® üíª      michaelfrankiüé®      Esther Whiteüé® üíª      prathmeshpbüé® üíª      Victor Linüé® üíª              Christine C. Yinüé® üíª      GitLearner-beginüé® üíª      Mesrop Andreasyanüé® üíª      Nathan Garciaüé®      commonsw04üé® üíª      Md. Rashad Tanjimüé® üíª      Ali Maleküíª              PAODLTüé® üíª      Nikhil Bobadeüé® üíª      hyuckjin21üíª      Itasha Modiüé® üíª      Nikitha Reddyüé® üíª      Mahshooq Zubairüé® üíª      Subham Dasüíª              Onkar Birajdarüé® üíª      Nick Titomichelakisüé® üíª      Christian Leo-Pernoldüé®      Matthew Marquiseüé® üíª      baronfacüé® üíª      Abhishek Tilwarüé® üíª      DavidsDvmüé® üíª              Parth Parikhüé® üíª      Hector Castroüé® üíª      Rikky Arisendiüé® üíª      Ali HamXaüé® üíª      Frank.wuüé® üíª      Jatin Kumarüé® üíª üìñ      masterHAWK99üé® üíª              Pushp Jainüé® üíª      Ashutosh Routüé® üíª      Atharva Deshpandeüé® üíª      Teodor Ciripescuüé® üíª      Anmol Bansalüé® üíª      Nikhil Kumar Macharlaüé® üíª      Dexterüé® üíª              Aaronüé® üíª      Yogita Jaswaniüé® üíª üìñ üñã      StoryDevüé® üíª      Mesut Doƒüansoyüé® üíª      Paras Dhawanüé® üíª      Emanuel Zhupaüé® üíª      Aaradhyaa717üé® üíª              jaacko-torusüé® üíª      mBlacküíª      kalrayashwinüìñ üñã üé® üíª      Seraphüíª üé®      ZhiHong Chuaüé® üíª      Amsal Khanüé® üíª üìñ üñã      Raghav Rastogiüé® üíª              Tzilaüìñ      Shahriar Nasim Nafiüìñ      AGüé® üíª      Mojtaba Kamyabiüé® üíª      Ahmad Abdulrahmanüé® üíª      Eclipseüé® üíª      Anshu Palüé® üíª              Denisüé® üíª      mehmet sayinüìñ      WebDEVüé® üíª      Sam Komesarooküé® üíª      Kiran Ghimireüé® üíª      Joshua Davisüé® üíª      Muhammad-Huzaifa-Siddiquiüíª              tobeornottobeadevüé® üíª      VAIBHAV SINGHALüé® üíª      Keiran Pillmanüé® üíª      Max Donchenkoüé® üíª      sgonsalüé® üíª      diksha137üé® üíª      Vigneshüé® üíª              Gabriel Fran√ßaüé® üíª      Josephüé® üíª      Bruno Rafaelüé® üíª      vcamarreüé® üíª      thibault kettererüé® üíª üöß      VictorGonzalezToledoüé® üíª      1911510996üé® üíª              inviduüé® üíª      Nurul Furqonüé® üíª      David Asbillüé® üíª      Niko Birbilisüé® üíª      Mugundan Kottursureshüé®      agrsachin81üé® üíª      Othmane El Alamiüé® üíª              Syed Atif Aliüé® üíª      lakhanjindamüé® üíª      youssef hamdaneüé® üíª      starfaerieüé® üíª      rodrigo0107üé® üíª      Micha≈Ç Gralaküé® üíª      Jewel Mahmudüé® üíª              cwilson830üé® üíª      buun1030üé® üíª      Reda-ELOUAHABIüé® üíª      saad-aksaüé® üíª      Emdadul Haqueüé® üíª      PROCWüé® üíª      cccppp1üé® üíª              Joanna Baileüé® üíª      Ahmed Saberüé® üíª      Masoud Keshavarzüé® üíª      mortazavianüé® üíª      Aniket Pandeyüé® üíª      Vijay Nirmalüé® üíª      Daniel Carvalloüíª              menaechmiüé® üíª      azenyxüé® üíª      Ahmet √ñzrahatüé® üíª      Abdulrahman Abouzaidüé® üíª      jmgnorbecüé® üíª      palinko91üé® üíª      Laisson R. Silveiraüé® üíª              BHARGAVPATEL1244üé® üíª      Candide Uüé® üíª      Sitansh Rajputüé® üíª      Houda Mouttalibüé® üíª      MumuTWüé® üíª      Suave Bajajüé® üíª      Mehdi Parsaeiüé® üíª              Dinko Osreckiüé® üíª      Dhia Djobbiüé® üíª      Mahmoud Galalüé® üíª      Anh Minhüé® üíª      Suvesh Küé® üíª      Petar Todorovüé® üíª      Alexander Nguyenüé® üíª              Morteza Jalalvandüé® üíª      Claudson Martinsüé® üíª      Matt Jacobsonüé® üíª      Rafael Belokurowsüé® üíª       Thomas Gamaufüé® üíª      Rishabh Mahajanüé® üíª      rakeshpdgupta23üé® üíª              Shashidharknaiküé® üíª      taleleumaüé® üíª      Florian B√ºhlerüé® üíª      Raihan Bin Wahidüé® üíª      MOHAMMED NASSERüé® üíª      federicoüé® üíª      Andre Violanteüé® üíª              tcunningham98üé® üíª      Jan Grie√üerüé® üíª      Serkan Alcüé® üíª üñã      Jez McKeanüé® üíª      meisam alifallahiüé® üíª      Mehul Thakkarüé® üíª      Saksham Soniüé® üíª              Pedro Peregrinaüé® üíª      Mintu Choudharyüé® üíª      lucianmoldovanuüé® üíª      John C. Scottüé® üíª      Mia D.üé® üíª      EwenBernardüé® üíª      M. Reza Nasirlooüé® üíª              Jay Agrawalüé® üíª      DeShayüé® üíª      Jay206-Programmerüé® üíª      Elenderüé® üíª üñã      Bobby Byrneüé® üíª      Pirciüé® üíª      Hasanuzzamanüé® üíª              Josh Kautzüé® üíª      Brofarüé® üíª      Mina Karamüé® üíª      Duncan O Nüé® üíª      Sean Tumulak-Nguyenüé® üíª      Artur Trze≈õniewskiüé® üíª      JJaammeessMüé® üíª              shubham agarwalüé® üíª      Michele Righiüé® üíª      Panagiotis Kontosüé® üíª      sumitbathlaüé® üíª      Deepak Mathurüé® üíª      Juho Nyk√§nenüé® üíª      Santiago Gonz√°lez Siordiaüé® üíª              SRIJITA MALLICKüé® üíª      Samriddhi Büé® üíª      Nitzan Papiniüé® üíª      Mario Sanzüé® üíª      Crab^4üé® üíª      Pabloüé® üíª      Gordon Pham-Nguyenüé® üíª              Kristofferüé® üíª      chrisblachüé® üíª      G√°borüé® üíª      Linaüé® üíª      Harrison Wattsüé® üíª      Mario Petriƒçkoüé® üíª      Ben8120üé® üíª              Giovannaüé® üíª      Minal Ahujaüé® üíª      mossfarmerüé® üíª      ThaC0derDreüé® üíª      itwareüé® üíª      Michael Walkerüé® üíª      Tom Jacob Chirayilüé® üíª              Sachin Kumarüé® üíª      adi-rayüé® üíª      Dr-Blank-altüé® üíª      Bogdan Cazacuüé® üíª      Gilson Urbanoüé® üíª      Ninaüé® üíª      Anthonyüé® üíª              manushimjaniüé® üíª      Michael Reyesüé® üíª      Rachel Kennellyüé® üíª      Aakash Gargüé® üíª      Daniel Livingstonüé® üíª      alexrojcoüé® üíª      Minh Nguyenüé® üíª              Mahesh Dattatraya Babarüé® üíª      Jin Zihangüé® üíª      Bikramjit Gangulyüé® üíª      QuestionableGuiseüé® üíª      liq19chüé® üíª      Bruno Rochaüé® üíª      Anand Dyavanapalliüíª üñã              crucian-afküé® üíª      0xgainzüé® üíª      weirdfshüé® üíª      Valan Baptist Mathuranayagamüé® üíª      Paul Kaeferüé® üíª      Yu-Hsiang Wangüé® üíª      Javad Adibüé® üíª              davidliu0930üé® üíª      Achilleas John Yfantisüé® üíª      Omkar Shivadekarüé® üíª üñã üêõ      ToanTranüé® üíª      Gautam Naiküé® üíª      Marcüé® üíª      twix20üé® üíª              Kristian S.üé® üíª      Aleksey Khoroshilovüé® üíª      arjunsrsrüé® üíª      Ali Haiderüé® üíª      Trisha Dringüé® üíª      Andre Marzuloüé® üíª      Krishna Modiüé® üíª              Rosemary Liüé® üíª      Alex Wellerüé® üíª      Tam Nguyenüé® üíª      aquintelaoliveiraüé® üíª      Norbert Brettüé® üíª      rocsogdüé® üíª      0nyrüé® üíª              rethkevinüé® üíª      RickHeadleüé® üíª      Leandreüé® üíª      Natnael Sisayüé® üíª      sbbuüé® üíª      waelüé® üíª      Fabricio Tramontano Piriniüé® üíª              Alexander Stoyanovüé® üíª      Dezx20üé® üíª      southparkkidsüé® üíª      bmstarüé® üíª      kiagamüé® üíª      Juan Castilloüé® üíª      FFenneüé® üíª              Jose Toledoüé® üíª      Pat McGhenüé® üíª      Eiko Wagenknechtüíª üñã üî£      Alan Chalmersüé® üíª      Jean Didierüé® üíª      Andyüé® üíª      pestadieuüé® üíª              Kanishka Chakrabortyüé® üíª      Nandhaüé® üíª      Vahid Mafiüé® üíª üî£ üñã üíº      Akshay Ashoküé® üíª      0x08üé® üíª      Sandeep Mishraüé® üíª      Evann Regnaultüé® üíª              Lenny Zeitounüé® üíª      Eden Boaronüé® üíª      TroyBTCüé® üíª      Aby Sebastianüé® üíª      Matthew Dunnüé® üíª      ckulloüé® üíª üñã üî£      Mohamed Mamdouhüé® üíª              Youssef Bazinaüé® üíª      Frederico K√ºckelhausüíª      Nushan Kodikaraüíª      Zach Cooperüíª      Royüé® üíª      Saurav Panchalüé® üíª      totallynotdavidüé® üíª              goosepirateüé® üíª üí° üíº      KAUTHüé® üíª      Hari Kiran Vusirikalaüé® üíª      Sounak Deyüé® üíª      ziaüíº üé® üíª      Reza Davariüé® üíª      AkshayAjaykumarüé® üíª              x24870üé® üíª      Ko Phoneüé® üíª      Nabstar3üé® üíª      Mateuszüé® üíª      Yunus Emre Emiküíª      Abhinav Sinhaüé® üíª      Hung Nguyenüé® üíª              Maselinoüíª      Shuktika Mahantyüíª      Miko≈Çaj Gawro≈Ñskiüé® üíª      Hussein Habibi Juybariüé® üíª      Sean-McArthurüé® üíª      Osman F Bayramüé® üíª      Benjamin Thomas Blodgettüé® üíª              Chuanlong-Zangüé® üíª      julianüé® üíª      franciscoüé® üíª      aalihhiader9211üé® üíª      Muhammad Zunairüé® üíª      Liyaüé® üíª      BegadTareküé® üíª              etorobotüé® üíª      Hussam Khanüé® üíª      Saikat Chakrabortyüé® üíª      Nicholas Quislerüé® üíª      Evang Poulüé® üíª      Gregg Lindüé® üíª      Deepak Kumarüé® üíª              Callum Leslieüé® üíª      Curtis Barnard Jr.üé® üíª      Deepanshukaimüé® üíª      Manthan Anküé® üíª      hossein varmazyarüé® üíª      Brayan Mu√±oz V.üé® üíª      Kamil Rasheed Siddiquiüíª üé®              mutt0-dsüé® üíª      egbertjküé® üíª      Majid Zojajiüé® üíª      Sean Chenüé® üíª      Herbert Milhommeüé® üíª      A3üé® üíª      Killianüé® üíª              Coakeowüé® üíª      ‡æÖ‡ºª «¨…Äƒß ‡ºÑ‡ºÜ‡Ωâüé® üíª      Pratik Solankiüé® üíª      Sunnyüé® üíª      ssgeüé® üíª      Bernat Frangiüé® üíª      Jeevan Rupachaüé® üíª              amirandapüé® üíª      Deepakshi Mittalüé® üíª      Abhijeet Paridaüé® üíª      Khaled Riyadüé® üíª      Pratap paruiüé® üíª      Prajit Pandayüé® üíª      PipeSierraüé® üíª              Collins Odenüé® üíª      Kshitij Dwivediüé® üíª      Bernardia Vitri Arumsariüé® üíª      √ñmer Faruk Ta≈üdemirüé® üíª      Spencer Stithüé® üíª      Porsche Rodjanasaküé® üíª      Shakeel Sharifüé® üíª              Victoria Chengüé® üíª      Denisüé® üíª      Anand Prakash Tiwariüé® üíª      danijeljw-rpcüé® üíª      Ahmed H Ebrahimüé® üíª      Virginia Gardnerüé® üíª      Jhironsel Diaz A.üé® üíª              Yunus Kidemüé® üíª      MTüé® üíª      Dinesh Zaldekarüé® üíª      adiüé® üíª      Farhan Shaikhüé® üíª      Elvis Salvatierraüé® üíª      Kaushik-Iyerüé® üíª              HocAndresüé® üíª      VictorHugoAguilarAguilarüé® üíª      Murat Can Abayüé® üíª      Chrisüé® üíª      Shivam7-1üé® üíª      Paipai13üé® üíª      Shambles-ioüé® üíª              Abhishek K Müé® üíª      Ezequiel Cuevasüé® üíª      Plamen Ivanovüé® üíª      Yujiüé® üíª      Jean-Philippe Leb≈ìufüé® üíª üî£      Naufanüé® üíª      jadnovüé® üíª              vaxtangensüé® üíª      subashkonar13üé® üíª      Rushi Javiyaüé® üíª      Mert G√ºlüé® üíª      Lilyüé® üíª      Kalinoffüé® üíª      Joel Tonyüé® üíª              Peterüé® üíª      Roozbeh Zareiüé® üíª      Shenüé® üíª      Joonsoo.LEEüé® üíª      Fede.Bregüé® üíª      Rui Costaüé® üíª      Jo√£o Gustavo Bispoüé® üíª              Sami-Iüé® üíª      Tsvetoslav Tsvetkovüé® üíª      Olabode Olaniyi Davidüé® üíª      theRuslanüé® üíª      leighbozüé® üíª      Frank Sossiüé® üíª      Tomasz Adamskiüé® üíª              Mansoor M. Sathirüé® üíª      Golamrabbi Azadüé® üíª      Nahian Ahmedüé® üíª      Rafael de Jesus Silva Monteiroüé® üíª      Odionyebuchukwu Judeüé® üíª      The Nithin Balajiüé® üíª      Knackiiüé® üíª              vittorio-giattiüé® üíª      Guilherme de Carvalho Lima Rebou√ßasüé® üíª      aaref shamiüé® üíª      Andrey Dryupinüé® üíª      Muhanned Nomanüé® üíª      Jan Silvaüé® üíª      emanuele-emüé® üíª üñã              Sanjay TMüé® üíª      Joe Markberg / code editorüé® üíª      Julien Quiaiosüé® üíª      Eric Ramirez Santisüé® üíª      Müé® üíª      Malcataüé® üíª      Athul Muralidharanüé® üíª              Dariusz Ochotaüé® üíª      CHANDAN CHOUDHURYüé® üíª      Deepüé® üíª      Ahmet ƒ∞stemihan √ñZT√úRKüé® üíª      TIMüé® üíª      jakeg814üé® üíª      Leonidosüé® üíª              Abhinandu V Nairüé® üíª      charafeddine01üé® üíª      Jasperüé® üíª      Manish Goyalüé® üíª      SATYAM_SINGHüé® üíª      Fourüé® üíª      Vaishnavi Amira Yadaüé® üíª              ShriKrushna Bhagwatüé® üíª      Rohit Nandagawaliüé® üíª      felipeüé® üíª üöß üñã ‚úÖ üßë‚Äçüè´      Saurabh Mudgalüé® üíª      szenadamüé® üíª      Shubhendra Singhüé® üíª      Yoosuf Sayyidüíª üé®              G√ºven √áetinerlerüé® üíª      Luke Jefferiesüé® üíª      Chrisüé® üíª      L√∫cio Aguiarüíª      Enuma029üíª      yktsang01üíª      maximumn3rdüé® üíª              Jon Galleteroüé® üíª      Thaddeus  Thomasüé® üíª      Aakash Kumarüíª üé®      Ali Müé® üíª      OskyEdzüé® üíª      Ravi Guptaüé® üíª      Rafa Raizerüé® üíª              Abdullah Al Muzakiüé® üíª      Rahul Faujdarüé® üíª      Abhishek Vermaüé® üíª      Ashutosh Shindeüé® üíª      Ganesh Raiüé® üíª      StefanTrpkovicüé® üíª      Erik Blancaüé® üíª              Vedant Madaneüé® üíª      Antra Tripathiüé® üíª      Ethan Knightsüé® üíª      Alexandru Boncutüé® üíª      Pablo Bandinoplaüé® üíª üöß üñã      Robz-99üé® üíª      Harpal Singhüé® üíª              paulboundy99üé® üíª      Mubashir Ahmedüé® üíª      Rohan Hariüé® üíª      Erik Henrique üé® üíª      Leandro Matheusüé® üíª      Deepaküé® üíª      AlishaSinghüé® üíª              Lynn Latt Yatiüé® üíª      San Shweüé® üíª      SKRüé® üíª      msbunnyjaguarüé® üíª      Mohamad Zabiullaüé® üíª      Hatim Zahidüé® üíª      Rauzan Sumaraüé® üíª              Hosein1358üé® üíª      Mohitüé® üíª      Aliüé® üíª      Avinash1765üé® üíª      Sai Teja Madhaüé® üíª      Monsur Ahmed Shafiqüé® üíª      xuxianjin-devüé® üíª              chetnaüé® üíª      Gul Zaibüé® üíª      Nataliaüé® üíª      Dion√≠sio Bragaüé® üíª      Pritish Rajpurohitüé® üíª      incanloveüé® üíª      Innocentüé® üíª              Devin Almonorüé® üíª      antonyveyreüé® üíª      Beltz Anhxtonüé® üíª      Mehdiüé® üíª      Muhammad Usmanüé® üíª      Patrick Dantasüé® üíª      Tak Vannaküé® üíª              Ramzi RADDAOUIüé® üíª      Konstantin-Glukhovüé® üíª      ugurobanüé® üíª      Humberto Alvesüé® üíª      JuangZendratoüé® üíª      James Oluwaleyeüé® üíª      Wasi Sadmanüé® üíª              Pavle Mijatovicüé® üíª      Luiz H. S. Bispoüé® üíª      –°—É—Ö–∞—Å –î—Ö–æ–ª–∑üé® üíª      Alvaro Trujilloüé® üíª      Everton üé® üíª      jfrozasüé® üíª      Shuaaib Badranüé® üíª              Shivam Jhaüé® üíª      Mohamed Tayehüé® üíª      Makendran Güé® üíª      mayank singh tomarüé® üíª      hossam sadanyüé® üíª      Harshbardhan Singhüíª üé®      Fawad Jawaid Maliküé® üíª              Tina Lacatisüé® üíª      TeddyCuoreDolceüé® üíª      bchooxgüé® üíª      Alisha Takkarüé® üíª      Gianluigiüé® üíª      Mehran Javaherianüé® üíª      Benjamin Ololade Adedokunüé® üíª              Md. Abdul Mutalibüé® üíª      Aadil Arsh.S.Rüé® üíª      J. Nathan Allenüé® üíª      Kieran Krugüé® üíª      Seth Addoüé® üíª      Satvik Singh Rathoreüé® üíª      dangothüé® üíª              Maximüé® üíª      Phuong-Cat Ngoüé® üíª      Frenchtoast0üé® üíª      Rakshithüé® üíª      Vaibhav Aroraüé® üíª      zghpüé® üíª      Bedovanüé® üíª              chiaramistroüé® üíª      him2016üé® üíª      HarshitSachdevaüé® üíª      Sadaf Saleemüé® üíª      Aaroh Srivastavaüé® üíª      eloygplazaüé® üíª      Gaurav Kumar Vermaüé® üíª              AndreaCUSüé® üíª      Simranüé® üíª      Prashant Bhapkarüé® üíª      mhaendlerüé® üíª      Gauri Maheshwariüé® üíª      4Lajfüé® üíª      Tanmoy Senguptaüé® üíª              Sharad Tripathiüé® üíª      Niraj Chavanüé® üíª      Luisa Gualdaüé® üíª      Monika-Sivakumar-3üé® üíª      harryfensomeüé® üíª      Shubham Choubeyüé® üíª      Ashwini Patilüé® üíª              cleversonliraüé® üíª      Nurmukhammedüé® üíª      workspace-utkarshüé® üíª      Santosh Phadtareüé® üíª      Prashant Warghudeüé® üíª      Umang Dakhüé® üíª      Shalini Chavanüé® üíª              vinit gurjarüé® üíª      Vishal Kumarüé® üíª      Wonhyeong Seoüé® üíª      Achwale Prajwal Namdevraoüé® üíª      Ankan Banerjeeüé® üíª      bhaumikankanüé® üíª      JamesMacroZhangüé® üíª              Pedro Lopesüé® üíª      diaüé® üíª      tayyabhussain2910üé® üíª      Rajdeep Shrivastava üé® üíª      Mukul Kumarüé® üíª      Mayank Nüé® üíª      jdeluccaüé® üíª              Sneha Mittalüé® üíª      Sarika Kushwahaüé® üíª      farzad-khbüé® üíª      Elijah Shackelfordüé® üíª      The-Only-Raminatorüé® üíª      Keerthana Kasthurilüé® üíª      Viachaslau Auchynnikauüé® üíª              Mohammad Osman Rasooliüé® üíª      mvedovatoüé® üíª      Sonali Rajputüé® üíª      Isha Dheküé® üíª      Ramshad Cheriyeri Peediyakkalüé® üíª      Micahüé® üíª      gauravshukla2203üé® üíª              sndmurthyüé® üíª      Shivam-Singhüé® üíª      M. Ammar Khanüé® üíª      chandolakulüé® üíª      bhatnagar221üé® üíª      Adrian Nie≈õciurüé® üíª      nezi311üé® üíª              scottajevansüé® üíª      Marcelo Antunes Soares Fantiniüé® üíª      Axel De Acetisüé® üíª      Drishti Sahüé® üíª      VipulDhillonüé® üíª      Urmi Janaüé® üíª      Ayush Mokalüé® üíª              Damola Olutokeüé® üíª      Maxüé® üíª      Lakshmi Nüé® üíª      ArtemRevaüé® üíª      Ujjwal Aggarwalüé® üíª      Moüé® üíª      Brianüé® üíª              chamleyüé® üíª      Simone Baptisteüé® üíª      Shekhar Thakurüé® üíª      Smithüé® üíª      codernoob1üé® üíª      lok84üé® üíª      Tobias Riemenschneiderüé® üíª              Tharsanan1üé® üíª      ANURAG SINGHüé® üíª      Yash Santüé® üíª      Krishiv Patelüé® üíª      GGGalaxyüé® üíª      pardeepdhillon661üé® üíª      anujd64üé® üíª              Pedro Pereiraüé® üíª      Master_Saptaküé® üíª      SURANJAN DASüé® üíª      Tripura kantüé® üíª      shabzkhanüé® üíª      Mustafa Poyaüé® üíª      Roshan Jhaüé® üíª              GuillaumeLarueüé® üíª      Tomasz Rodaküé® üíª      Junil Kimüé® üíª      Surbhi Mayanküé® üíª      Nemanja Lekicüé® üíª      HemantMalokarüé® üíª      Felipe M. L√≥pezüé® üíª              bibliofiloüé® üíª      GauthamG2üé® üíª      02_tüé® üíª      Yusuf Abdul-razaqüé® üíª      Vladimirüé® üíª      Sai Chandra Küé® üíª      Soroush Bonabüé® üíª              Giide0nüé® üíª      GGüé® üíª      D√°ger Z√∫√±igaüé® üíª      rsk2üé® üíª      Storozhev DJüé® üíª      Jeevanüé® üíª      Andy Johnsonüé® üíª              An√≠bal Pozoüé® üíª      Jovane de Castroüé® üíª      Muhammad Hamza Amirüé® üíª      tharaka-mtsüé® üíª      Ali KHYARüé® üíª      Caio Araujoüé® üíª      Oscar Dyremyhrüé® üíª              artealityüé® üíª      Daniel Drexlmaierüé® üíª      Marco Montiüé® üíª      mikeycrystalüé® üíª      Veljanovskiiüé® üíª      Ivan Gorbachevüé® üíª      Sahil Rawatüé® üíª              Hasitha Sunethüé® üíª      Yerko Vera Lezamaüé® üíª      Ivan Penchevüé® üíª      Tanver Islam Tonmoyüé® üíª      Xun Caoüé® üíª      Nayan Babariyaüé® üíª      Priyanshu Mauryaüé® üíª              Dylan Tintenfichüé® üíª      Ron Straussüé® üíª      Mohammed AlBannaüé® üíª      Mukund Müé® üíª      Franklin Ohaegbulamüé® üíª      Nisarg Shahüé® üíª      Unik Dahalüé® üíª              Readilyüé® üíª      Alexandre Poitevinüé® üíª      Scaramirüé® üíª      Pruthviüé® üíª      Kalmanqüé® üíª      Alfatah Nesabüé® üíª      arudesaiüé® üíª              Adryenneüé® üíª      El mehdi oudaoudüé® üíª      Jayant Goelüé® üíª      Tsukiüé® üíª      Peter Lemanskiüé® üíª      Annurag-byteüé® üíª      Anthony Vuüé® üíª              Vitaly Nikolaychuküé® üíª      Nathanüé® üíª      Evgenii Petukhovüé® üíª      Loris Guerraüé® üíª      fakhriaunurüé® üíª      Mehdi HYANIüé® üíª      Sarvex Jatasraüé® üíª              santimanuelrüé® üíª      Evgeniy Rezanovüé® üíª      Sonia Müé® üíª      Grzegorz Kmitaüé® üíª      Manuel Caritaüé® üíª      Felipe Cisternas Alvarezüé® üíª      Guo Ciüé® üíª              Marcos Silvaüé® üíª      KKüé® üíª      Shubhanjan Medhiüé® üíª      ArthurFerreiraRodriguesüé® üíª      PabloHermunüé® üíª      disha-baldawaüé® üíª      StaroMoonüé® üíª              Amila T Kumarasekaraüé® üíª      Amoh Princeüé® üíª      AngeloGCüé® üíª      Ebube Glory Ogbondaüé® üíª      Prahalad Belavadiüìñ      Antoni Sarnowski-Trypkaüé® üíª      Alberto Pasqualettoüé® üíª              Amir Babaeiüé® üíª      Syed Abdul Hannanüé® üíª      Srajan Raiüé® üíª      Clarence Mooreüé® üíª      Nguyen Anh Tuanüé® üíª      dar2dar2üé® üíª      Ameer Ibrahimüé® üíª              Tiago Lugattoüé® üíª      raremiroirüé® üíª      Moobieüé® üíª      AlicanDursunüé® üíª      bbalsamüé® üíª      Lubo≈° H√°jeküé® üíª      mrshahzeb7üé® üíª              Wesley Schollüé® üíª      Lawrence Turcotteüé® üíª      Michael DiPaoloüé® üíª      Smart-Codiüé® üíª      Vivek Kumarüé® üíª      Igor Moiseevüé® üíª      B√•rd Pedersenüé® üíª              HOA PHANüé® üíª      GaborModraüé® üíª      vivek-114üé® üíª      Robinüé® üíª      Alexüé® üíª      John Ehrlingerüé® üíª      Roman Zhuravlovüé® üíª              Jordan Mossüé® üíª      RaeShellyüé® üíª      gmollardüé® üíª      Md Kaif Khanüé® üíª      Pablo Romeraüé® üíª      Erik Bustosüé® üíª      trogfieldüé® üíª              simon-aichhornüé® üíª      Tufan G√úLE√áüé® üíª      Uƒüur Berkecan √únl√ºüé® üíª      Revanth Naiküé® üíª      Lia Piresüé® üíª      Igor Mestechkinüé® üíª      Anirudh Karanthüé® üíª              KBobovskiyüé® üíª      zhatiayuaüé® üíª üñã      David Cardonaüé® üíª      Paulo Castilhoüé® üíª      Sebastiano Picchiüé® üíª      pjotarüé® üíª      Rimel CHERIFüíª              Arsal uddinüñã      Dmitry Kasporskyüíª      SoftwareDev1014üé® üíª      @Robvredüé® üíª      Kasun Shanakaüíª      Ahmad M.üé® üíª      Alex Kozinüé® üíª              Mandy Meindersmaüé® üíª      LEGALISE PIRACYüé® üíª      Alex Logvinüé® üíª      Aria Dahlüé® üíª      Mustafa Arifogluüé® üíª      Yevhen Leshchenkoüé® üíª      Anubhav Adhikariüé® üíª              Noah Tatkoüé® üíª      Mohit Gadhaviüé® üíª      Pedro Bas√≠lioüé® üíª      RealSanjeevüé® üíª      Akash Hazraüé® üíª      Christoph Dahlenüé® üíª      Vincent du Plessisüé® üíª              Karen Tamrazyanüé® üíª      Mirza Younus Baigüé® üíª      Ashish Kumarüé® üíª      Unknown6334üé® üíª      flowazüé® üíª      zi-aikraüé® üíª      PAYAL PMüé® üíª              Lennart L√∂scheüé® üíª      Yummy-Yumsüé® üíª      Njuacha Hubert Mikulowskiüé® üíª      Hussein Esmailüé® üíª      Bilgehan Bezirüé® üíª      Muhammed Shittuüé® üíª      Cl√©ment FERNANDESüé® üíª              JaCKoP619üé® üíª      userutf8üé® üíª      Mohamed Ubaidüé® üíª      Justin Yatesüé® üíª      mohammad aliüé® üíª      Madhav Singhüé® üíª      RgbMouse69üé® üíª              Nicholas Leasküé® üíª      parthav0üé® üíª      Sigmaüé® üíª      Evelina Bechevaüé® üíª      Akshit Gulyanüé® üíª      Arpita Janaüé® üíª      Praveen Kumarüé® üíª              Mohammad Samiüé® üíª      eddiestefanescuüé® üíª      Ramesh Yadavüé® üíª      Sarthak Joshiüé® üíª      Nikhil12300üé® üíª      Yevgenüé® üíª      Leoüé® üíª              laurent büé® üíª      Mettchenüé® üíª      Ali Mahdaviüé® üíª      Lucas Dondoüé® üíª      Siddhesh Agarwalüé® üíª      slimerPuncherüé® üíª      saritashhüé® üíª              Iulian-Valeriu CioatƒÉüé® üíª      Szabolcs Nagyüé® üíª      Jarle Kvileüé® üíª      ÂäâËÄÄÂçá Vic Liuüé® üíª      Suryanshüé® üíª      Matthew Oosthuyseüé® üíª      Florin Zamfirüé® üíª              Meleküé® üíª      moesocioüé® üíª      Alan Jamesüé® üíª      Mai Thanh Ph∆∞∆°ngüé® üíª      Neville Dabreüé® üíª      Maksymüé® üíª      tamanna900üé® üíª              Adithya Awatiüé® üíª      This project follows the all-contributors specification.Contributions of any kind welcome![ Go back to the top of the page ]Contributor Over TimeStargazers over timeVisualisation of this repository by Gourcehttps://www.youtube.com/watch?v=24cZVytc5D4"
76,fighting41love/funNLP,https://github.com/fighting41love/funNLP/blob/master/README.md,Python,"            NLPÊ∞ëÂ∑•ÁöÑ‰πêÂõ≠The Most Powerful NLP-Weapon ArsenalNLPÊ∞ëÂ∑•ÁöÑ‰πêÂõ≠: Âá†‰πéÊúÄÂÖ®ÁöÑ‰∏≠ÊñáNLPËµÑÊ∫êÂ∫ìÂú®ÂÖ•Èó®Âà∞ÁÜüÊÇâNLPÁöÑËøáÁ®ã‰∏≠ÔºåÁî®Âà∞‰∫ÜÂæàÂ§ögithub‰∏äÁöÑÂåÖÔºåÈÅÇÊï¥ÁêÜ‰∫Ü‰∏Ä‰∏ãÔºåÂàÜ‰∫´Âú®ËøôÈáå„ÄÇÂæàÂ§öÂåÖÈùûÂ∏∏ÊúâË∂£ÔºåÂÄºÂæóÊî∂ËóèÔºåÊª°Ë∂≥Â§ßÂÆ∂ÁöÑÊî∂ÈõÜÁôñÔºÅÂ¶ÇÊûúËßâÂæóÊúâÁî®ÔºåËØ∑ÂàÜ‰∫´Âπ∂star‚≠êÔºåË∞¢Ë∞¢ÔºÅÈïøÊúü‰∏çÂÆöÊó∂Êõ¥Êñ∞ÔºåÊ¨¢ËøéwatchÂíåforkÔºÅ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏èüî•üî•üî•üî•üî•üî•üî•üî•üî•üî•   ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†* Á±ªChatGPTÁöÑÊ®°ÂûãËØÑÊµãÂØπÊØî  * Á±ªChatGPTÁöÑËµÑÊñô * Á±ªChatGPTÁöÑÂºÄÊ∫êÊ°ÜÊû∂ * LLMÁöÑËÆ≠ÁªÉ_Êé®ÁêÜ_‰ΩéËµÑÊ∫ê_È´òÊïàËÆ≠ÁªÉ * ÊèêÁ§∫Â∑•Á®ã * Á±ªChatGPTÁöÑÊñáÊ°£ÈóÆÁ≠î * Á±ªChatGPTÁöÑË°å‰∏öÂ∫îÁî® * Á±ªChatGPTÁöÑËØæÁ®ãËµÑÊñô * LLMÁöÑÂÆâÂÖ®ÈóÆÈ¢ò * Â§öÊ®°ÊÄÅLLM * LLMÁöÑÊï∞ÊçÆÈõÜüçÜ üçí üçê üçä   ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†üåª üçì  üçà üçÖ üçç ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†* ËØ≠ÊñôÂ∫ì  * ËØçÂ∫ìÂèäËØçÊ≥ïÂ∑•ÂÖ∑  * È¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã   * ÊäΩÂèñ  * Áü•ËØÜÂõæË∞±    * ÊñáÊú¨ÁîüÊàê    * ÊñáÊú¨ÊëòË¶Å   * Êô∫ËÉΩÈóÆÁ≠î   * ÊñáÊú¨Á∫†Èîô* ÊñáÊ°£Â§ÑÁêÜ    * Ë°®Ê†ºÂ§ÑÁêÜ    * ÊñáÊú¨ÂåπÈÖç    * ÊñáÊú¨Êï∞ÊçÆÂ¢ûÂº∫    * ÊñáÊú¨Ê£ÄÁ¥¢   * ÈòÖËØªÁêÜËß£   * ÊÉÖÊÑüÂàÜÊûê   * Â∏∏Áî®Ê≠£ÂàôË°®ËææÂºè    * ËØ≠Èü≥Â§ÑÁêÜ* Â∏∏Áî®Ê≠£ÂàôË°®ËææÂºè   * ‰∫ã‰ª∂ÊäΩÂèñ  * Êú∫Âô®ÁøªËØë  * Êï∞Â≠óËΩ¨Êç¢   * Êåá‰ª£Ê∂àËß£   * ÊñáÊú¨ËÅöÁ±ª   * ÊñáÊú¨ÂàÜÁ±ª  * Áü•ËØÜÊé®ÁêÜ  * ÂèØËß£ÈáäNLP  * ÊñáÊú¨ÂØπÊäóÊîªÂáª* ÊñáÊú¨ÂèØËßÜÂåñ   * ÊñáÊú¨Ê†áÊ≥®Â∑•ÂÖ∑   * ÁªºÂêàÂ∑•ÂÖ∑  * ÊúâË∂£ÊêûÁ¨ëÂ∑•ÂÖ∑  * ËØæÁ®ãÊä•ÂëäÈù¢ËØïÁ≠â  * ÊØîËµõ  * ÈáëËûçNLP  * ÂåªÁñóNLP  * Ê≥ïÂæãNLP  * ÊñáÊú¨ÁîüÊàêÂõæÂÉè  * ÂÖ∂‰ªñ                        Á±ªChatGPTÁöÑÊ®°ÂûãËØÑÊµãÂØπÊØîËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•ChatALLÔºöÂèØ‰ª•ÂêåÊó∂‰∏éÂ§ö‰∏™AIËÅäÂ§©Êú∫Âô®‰∫∫ÔºàÂê´Ê∏ÖÂçé„ÄÅËÆØÈ£ûÁöÑ‰∫ßÂìÅÔºâÂèØ‰ª•ÂêåÊó∂‰∏éÂ§ö‰∏™AIËÅäÂ§©Êú∫Âô®‰∫∫ÔºàÂ¶ÇChatGPT„ÄÅBing Chat„ÄÅBard„ÄÅAlpaca„ÄÅVincuna„ÄÅClaude„ÄÅChatGLM„ÄÅMOSS„ÄÅiFlytek Spark„ÄÅERNIEÁ≠âÔºâËøõË°åÂØπËØùÁöÑÂ∑•ÂÖ∑„ÄÇÂÆÉÂèØ‰ª•Âπ∂Ë°åÂèëÈÄÅÊèêÁ§∫Áªô‰∏çÂêåÁöÑAIÊú∫Âô®‰∫∫ÔºåÂ∏ÆÂä©Áî®Êà∑ÊâæÂà∞ÊúÄÂ•ΩÁöÑÂõûÁ≠îgithub-ChatALLChatbot ArenaÂÆûÈôÖÂú∫ÊôØÁî®Elo ratingÂØπ LLM ËøõË°åÂü∫ÂáÜÊµãËØï - ‰ªãÁªç‰∫Ü Chatbot ArenaÔºå‰∏ÄÁßçÈíàÂØπÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÂü∫ÂáÜÂπ≥Âè∞ÔºåÈááÁî®ÂåøÂêç„ÄÅÈöèÊú∫ÁöÑÊñπÂºèËøõË°åÂØπÊäóËØÑÊµãÔºåËØÑÊµãÊñπÂºèÂü∫‰∫éÂõΩÈôÖË±°Ê£ãÁ≠âÁ´ûÊäÄÊ∏∏Êàè‰∏≠ÂπøÊ≥õ‰ΩøÁî®ÁöÑ Elo rating system„ÄÇÂèëÂ∏É‰∫Ü9‰∏™ÊµÅË°åÁöÑÂºÄÊ∫ê LLM Ê®°ÂûãÁöÑ Elo rating Âπ∂Êé®Âá∫ÊéíË°åÊ¶ú„ÄÇÂπ≥Âè∞ÈááÁî® FastChat Â§öÊ®°ÂûãÊúçÂä°Á≥ªÁªüÔºåÂú®Â§ö‰∏™ËØ≠Ë®Ä‰∏ãÊèê‰æõ‰∫§‰∫íÂºèÁïåÈù¢ÔºåÊï∞ÊçÆÊù•Ê∫ê‰∫éÁî®Êà∑ÊäïÁ•®„ÄÇÊÄªÁªì‰∫Ü Chatbot Arena ÁöÑ‰ºòÁÇπÂπ∂ËÆ°ÂàíÊèê‰æõÊõ¥Â•ΩÁöÑÈááÊ†∑ÁÆóÊ≥ï„ÄÅÊéíÂêçÂíåÊúçÂä°Á≥ªÁªüÊà™Ê≠¢2023Âπ¥5Êúà3Êó•Á±ªChatGPTÊ®°ÂûãËØÑÊµãÊÄªÁªìÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLM)ÂèóÂà∞ÂπøÊ≥õÂÖ≥Ê≥®ÔºåËøô‰∫õÂº∫Â§ßÁöÑÊ®°ÂûãËÉΩÂ§üÁêÜËß£Â§çÊùÇÁöÑ‰ø°ÊÅØÔºåÂπ∂ÂØπÂêÑÁßçÈóÆÈ¢òÊèê‰æõÁ±ª‰∫∫ÁöÑÂõûÂ∫î„ÄÇÂÖ∂‰∏≠GPT-3ÂíåGPT-4Ë°®Áé∞ÊúÄÂ•ΩÔºåFlan-t5ÂíåLit-LLaMAË°®Áé∞‰πü‰∏çÈîô„ÄÇ‰ΩÜË¶ÅÊ≥®ÊÑèÔºåÊ®°ÂûãÂïÜÁî®ÂèØËÉΩÈúÄË¶Å‰ªòË¥πÂíåÊï∞ÊçÆÂÖ±‰∫´blogÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂ§ßÁõòÁÇπblogÂ§ßÊ®°ÂûãËØÑÊµãÊñπÈù¢ÁöÑÊúÄÊñ∞Á†îÁ©∂ÈïøÊñáÊú¨Âª∫Ê®°‰∏ÄÁõ¥ÊòØChaGPT‰ª§‰∫∫ÊÉäËâ≥ÁöÑËÉΩÂäõ‰πã‰∏ÄÔºåÊàë‰ª¨‰ª•„ÄêÁØáÁ´†ÁøªËØë„Äë‰∏∫ÂÆûÈ™åÂú∫ÊôØÔºåÂØπÂ§ßÊ®°ÂûãÁöÑÁØáÁ´†Âª∫Ê®°ËÉΩÂäõËøõË°åÂÖ®Èù¢„ÄÅÁªÜÁ≤íÂ∫¶ÁöÑÊµãËØï„ÄÇpaper‰∏≠ÊñáÂ§ßÊ®°ÂûãËØÑÊµãÂ∑•ÂÖ∑&ÊéíË°åÊ¶úC-EvalÊòØ‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑ‰∏≠ÊñáËØÑ‰º∞Â•ó‰ª∂ÔºåÈÄÇÁî®‰∫éÂü∫Á°ÄÊ®°Âûã„ÄÇÂÆÉÂåÖÂê´13948‰∏™Â§öÈ°πÈÄâÊã©È¢òÔºåÊ∂µÁõñ52‰∏™‰∏çÂêåÁöÑÂ≠¶ÁßëÂíåÂõõ‰∏™ÈöæÂ∫¶Á∫ßÂà´ÔºåÂÖ∑‰ΩìÂ¶Ç‰∏ãÊâÄÁ§∫„ÄÇËØ∑ËÆøÈóÆÊàë‰ª¨ÁöÑÁΩëÁ´ôÊàñÊü•ÈòÖÊàë‰ª¨ÁöÑËÆ∫ÊñáËé∑ÂèñÊõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇgithubpaperÁ±ªChatGPTÁöÑËµÑÊñôËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Open LLMsÔºöÂèØ‰æõÂïÜ‰∏ö‰ΩøÁî®ÁöÑÂºÄÊîæÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLM)A list of open LLMs available for commercial usegithubLLM Zoo: Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊï∞ÊçÆ„ÄÅÊ®°ÂûãÂíåÂü∫ÂáÜÈõÜÂ∏ÇLLM Zoo: democratizing ChatGPT - a project that provides data, models, and evaluation benchmark for large language modelsgithubÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLM)ËµÑÊñôÂêàÈõÜÁõ∏ÂÖ≥ËÆ∫ÊñáÂàóË°®ÔºåÂåÖÊã¨ÊåáÂØº„ÄÅÊé®ÁêÜ„ÄÅÂÜ≥Á≠ñ„ÄÅÊåÅÁª≠ÊîπËøõÂíåËá™ÊàëÊèêÂçáÁ≠âÊñπÈù¢ÁöÑÁ†îÁ©∂Â∑•‰ΩúLLMËµÑÊñôÂêàÈõÜDecryptPromptÊÄªÁªìPrompt&LLMËÆ∫ÊñáÔºåÂºÄÊ∫êÊï∞ÊçÆ&Ê®°ÂûãÔºåAIGCÂ∫îÁî®githubSmartGPTÊó®Âú®‰∏∫Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã(Â∞§ÂÖ∂ÊòØGPT-3.5ÂíåGPT-4)Êèê‰æõÂÆåÊàêÂ§çÊùÇ‰ªªÂä°ÁöÑËÉΩÂäõÔºåÈÄöËøáÂ∞ÜÂÆÉ‰ª¨ÂàÜËß£ÊàêÊõ¥Â∞èÁöÑÈóÆÈ¢òÔºåÂπ∂‰ΩøÁî®‰∫íËÅîÁΩëÂíåÂÖ∂‰ªñÂ§ñÈÉ®Êù•Ê∫êÊî∂ÈõÜ‰ø°ÊÅØ„ÄÇÁâπÁÇπÂåÖÊã¨Ê®°ÂùóÂåñËÆæËÆ°ÔºåÊòì‰∫éÈÖçÁΩÆÔºå‰ª•ÂèäÂØπÊèí‰ª∂ÁöÑÈ´òÂ∫¶ÊîØÊåÅ„ÄÇSmartGPTÁöÑËøê‰ΩúÂü∫‰∫é\""Autos\""ÁöÑÊ¶ÇÂøµÔºåÂåÖÊã¨\""Runner\""Âíå\""Assistant\""‰∏§ÁßçÁ±ªÂûãÔºåÈÉΩÈÖçÊúâÂ§ÑÁêÜËÆ°Âàí„ÄÅÊé®ÁêÜÂíå‰ªªÂä°ÊâßË°åÁöÑLLM‰ª£ÁêÜ„ÄÇÊ≠§Â§ñÔºåSmartGPTËøòÂÖ∑ÊúâÂÜÖÂ≠òÁÆ°ÁêÜÁ≥ªÁªüÔºå‰ª•ÂèäÂèØ‰ª•ÂÆö‰πâÂêÑÁßçÂëΩ‰ª§ÁöÑÊèí‰ª∂Á≥ªÁªügithub-SmartGPTOpenGPTÁî®‰∫éÂàõÂª∫Âü∫‰∫éÊåá‰ª§ÁöÑÊï∞ÊçÆÈõÜÂπ∂ËÆ≠ÁªÉÂØπËØùÈ¢ÜÂüü‰∏ìÂÆ∂Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLMs)ÁöÑÊ°ÜÊû∂„ÄÇÂ∑≤ÁªèÊàêÂäüÂ∫îÁî®‰∫éËÆ≠ÁªÉÂÅ•Â∫∑Êä§ÁêÜÂØπËØùÊ®°ÂûãNHS-LLMÔºåÂà©Áî®Êù•Ëá™Ëã±ÂõΩÂõΩÂÆ∂Âç´ÁîüÊúçÂä°‰ΩìÁ≥ª(NHS)ÁΩëÁ´ôÁöÑÊï∞ÊçÆÔºåÁîüÊàê‰∫ÜÂ§ßÈáèÁöÑÈóÆÁ≠îÂØπÂíåÁã¨ÁâπÂØπËØùgithub-OpenGPTPaLM 2ÊäÄÊúØÊä•ÂëäGoogleÊúÄÊñ∞ÂèëÂ∏ÉPaLM 2Ôºå‰∏ÄÁßçÊñ∞ÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºåÂÖ∑ÊúâÊõ¥Â•ΩÁöÑÂ§öËØ≠Ë®ÄÂíåÊé®ÁêÜËÉΩÂäõÔºåÂêåÊó∂ÊØîÂÖ∂ÂâçË∫´PaLMÊõ¥ËäÇÁúÅËÆ°ÁÆóËµÑÊ∫ê„ÄÇPaLM 2ÁªºÂêà‰∫ÜÂ§öÈ°πÁ†îÁ©∂ËøõÂ±ïÔºåÂåÖÊã¨ËÆ°ÁÆóÊúÄ‰ºòÁöÑÊ®°ÂûãÂíåÊï∞ÊçÆËßÑÊ®°„ÄÅÊõ¥Â§öÊ†∑ÂåñÂíåÂ§öËØ≠Ë®ÄÁöÑÊï∞ÊçÆÈõÜ„ÄÅ‰ª•ÂèäÊõ¥ÊúâÊïàÁöÑÊ®°ÂûãÊû∂ÊûÑÂíåÁõÆÊ†áÂáΩÊï∞„ÄÇPaLM 2Âú®Â§öÁßç‰ªªÂä°ÂíåËÉΩÂäõ‰∏äËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂåÖÊã¨ËØ≠Ë®ÄÊ∞¥Âπ≥ËÄÉËØï„ÄÅÂàÜÁ±ªÂíåÈóÆÁ≠î„ÄÅÊé®ÁêÜ„ÄÅÁºñÁ®ã„ÄÅÁøªËØëÂíåËá™ÁÑ∂ËØ≠Ë®ÄÁîüÊàêÁ≠â„ÄÇPaLM 2ËøòÂ±ïÁ§∫‰∫ÜÂº∫Â§ßÁöÑÂ§öËØ≠Ë®ÄËÉΩÂäõÔºåËÉΩÂ§üÂ§ÑÁêÜÊï∞ÁôæÁßçËØ≠Ë®ÄÔºåÂπ∂Âú®‰∏çÂêåËØ≠Ë®Ä‰πãÈó¥ËøõË°åÁøªËØëÂíåËß£Èáä„ÄÇPaLM 2ËøòËÄÉËôë‰∫ÜË¥üË¥£‰ªªÁöÑ‰ΩøÁî®ÈóÆÈ¢òÔºåÂåÖÊã¨Êé®ÁêÜÊó∂ÊéßÂà∂ÊØíÊÄß„ÄÅÂáèÂ∞ëËÆ∞ÂøÜÂåñ„ÄÅËØÑ‰º∞ÊΩúÂú®ÁöÑ‰º§ÂÆ≥ÂíåÂÅèËßÅÁ≠âPaLM 2 Technical ReportDB-GPT‰∫évicuna-13bÂíåFastChatÁöÑÂºÄÊ∫êÂÆûÈ™åÈ°πÁõÆÔºåÈááÁî®‰∫ÜlangchainÂíållama-indexÊäÄÊúØËøõË°å‰∏ä‰∏ãÊñáÂ≠¶‰π†ÂíåÈóÆÁ≠î„ÄÇÈ°πÁõÆÂÆåÂÖ®Êú¨Âú∞ÂåñÈÉ®ÁΩ≤Ôºå‰øùËØÅÊï∞ÊçÆÁöÑÈöêÁßÅÂÆâÂÖ®ÔºåËÉΩÁõ¥Êé•ËøûÊé•Âà∞ÁßÅÊúâÊï∞ÊçÆÂ∫ìÂ§ÑÁêÜÁßÅÊúâÊï∞ÊçÆ„ÄÇÂÖ∂ÂäüËÉΩÂåÖÊã¨SQLÁîüÊàê„ÄÅSQLËØäÊñ≠„ÄÅÊï∞ÊçÆÂ∫ìÁü•ËØÜÈóÆÁ≠îÁ≠âgithub-DB-GPTTransformersÁõ∏ÂÖ≥ÊñáÁåÆËµÑÊ∫êÂ§ßÂàóË°®ÂåÖÂê´‰∫ÜÂêÑÁßçÂêÑÊ†∑ÁöÑTransformerÊ®°ÂûãÔºå‰æãÂ¶ÇBERT„ÄÅGPT„ÄÅTransformer-XLÁ≠âÔºåËøô‰∫õÊ®°ÂûãÂ∑≤ÁªèÂú®ËÆ∏Â§öËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°‰∏≠ÂæóÂà∞‰∫ÜÂπøÊ≥õÂ∫îÁî®„ÄÇÊ≠§Â§ñÔºåËØ•ÂàóË°®ËøòÊèê‰æõ‰∫ÜËøô‰∫õÊ®°ÂûãÁöÑÁõ∏ÂÖ≥ËÆ∫ÊñáÂíå‰ª£Á†ÅÈìæÊé•Ôºå‰∏∫Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÈ¢ÜÂüüÁöÑÁ†îÁ©∂‰∫∫ÂëòÂíåÂºÄÂèëËÄÖÊèê‰æõ‰∫ÜÂæàÂ•ΩÁöÑÂèÇËÄÉËµÑÊ∫êgithubGPT-4ÁªàÊûÅÊåáÂçó‰∏Ä‰ªΩÂÖ≥‰∫éÂ¶Ç‰Ωï‰ΩøÁî®GPT3ÂíåGPT4ÁöÑÊåáÂçóÔºåÂÖ∂‰∏≠ÂåÖÊã¨100Â§ö‰∏™ËµÑÊ∫êÔºåÂèØ‰ª•Â∏ÆÂä©Â≠¶‰π†Â¶Ç‰ΩïÁî®ÂÆÉÊù•ÊèêÈ´òÁîüÊ¥ªÊïàÁéá„ÄÇÂåÖÊã¨Â¶Ç‰ΩïÂ≠¶‰π†ChatGPTÂü∫Á°ÄÁü•ËØÜ„ÄÅÂ¶Ç‰ΩïÂ≠¶‰π†ChatGPTÈ´òÁ∫ßÁü•ËØÜ„ÄÅÂ¶Ç‰ΩïÂú®ËØ≠Ë®ÄÂ≠¶‰π†‰∏≠‰ΩøÁî®GPT-3„ÄÅÂ¶Ç‰ΩïÂú®ÊïôÂ≠¶‰∏≠‰ΩøÁî®GPT-3„ÄÅÂ¶Ç‰Ωï‰ΩøÁî®GPT-4Á≠âÔºåËøòÊèê‰æõ‰∫ÜÂ¶Ç‰ΩïÂçáÁ∫ßÂà∞ChatGPT+ËÆ°Âàí‰ª•‰ΩøÁî®GPT-4‰ª•ÂèäÂ¶Ç‰ΩïÂÖçË¥π‰ΩøÁî®GPT-4ÁöÑÊñπÊ≥ïÁ≠âÂÜÖÂÆπ„ÄÇÂêåÊó∂ÔºåËøòÊèê‰æõ‰∫ÜÂ¶Ç‰ΩïÂú®‰∏öÂä°„ÄÅÁîü‰∫ßÂäõ„ÄÅÂèóÁõä„ÄÅÈáëÈí±Á≠âÊñπÈù¢‰ΩøÁî®ChatGPTÁöÑÊåáÂçólinkÂü∫‰∫éLoRAÁöÑLLMÂèÇÊï∞È´òÊïàÂæÆË∞ÉlinkÂ§çÊùÇÊé®ÁêÜÔºöÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂåóÊûÅÊòüËÉΩÂäõÂú® GPT-4 ÂèëÂ∏ÉÂçöÂÆ¢‰∏≠Ôºå‰ΩúËÄÖÂÜôÈÅìÔºö‚ÄúÂú®‰∏ÄÊ¨°ÈöèÊÑèÁöÑË∞àËØù‰∏≠ÔºåGPT-3.5 Âíå GPT-4 ‰πãÈó¥ÁöÑÂå∫Âà´ÂèØËÉΩÊòØÂæÆÂ¶ôÁöÑ„ÄÇÂΩì‰ªªÂä°ÁöÑÂ§çÊùÇÁ®ãÂ∫¶ËææÂà∞Ë∂≥Â§üÁöÑÈòàÂÄºÊó∂ÔºåÂ∑ÆÂºÇÂ∞±‰ºöÊòæÁé∞Âá∫Êù•„ÄÇ‚ÄùËøôÊÑèÂë≥ÁùÄÂ§çÊùÇ‰ªªÂä°ÂæàÂèØËÉΩÊòØÂ§ßÂûãÂíåÂ∞èÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ≥ÈîÆÂ∑ÆÂºÇÂõ†Á¥†„ÄÇÂú®ËøôÁØáÊñáÁ´†‰∏≠ÔºåÊàë‰ª¨Â∞Ü‰ªîÁªÜÂàÜÊûêËÆ®ËÆ∫Â¶Ç‰ΩïËÆ©Â§ßËØ≠Ë®ÄÊ®°ÂûãÊã•ÊúâÂº∫Â§ßÁöÑÂ§çÊùÇÊé®ÁêÜËÉΩÂäõ„ÄÇblogÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ∂åÁé∞ËÉΩÂäõÊòØÂê¶ÊòØÊµ∑Â∏ÇËúÉÊ•ºÔºüÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ∂åÁé∞ËÉΩÂäõ‰∏ÄÁõ¥ÊòØË¢´Â§ßÂÆ∂ËßÜ‰ΩúÂæàÁ•ûÂ•áÁöÑÁé∞Ë±°Ôºå‰ºº‰πéÊòØ‰∏ÄÁßçÂ§ßÂäõÂá∫Â•áËøπÔºå‰ΩÜËøôÁØáËÆ∫ÊñáËÆ§‰∏∫ËøôÂèØËÉΩÂè™ÊòØ‰∏ÄÁßçÈîôËßâ„ÄÇpaperÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ¶ÇÁéáÊÄªÁªìÈùûÂ∏∏ËØ¶Â∞ΩÁöÑLLMÁßëÂ≠¶Ëß£ÈáäÂíåÊÄªÁªìpaperLLaMA Ê®°ÂûãÁÆÄÂè≤LLaMAÊòØMetaÂèëÂ∏ÉÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºåÈááÁî®TransformerÊû∂ÊûÑÔºåÊúâÂ§ö‰∏™ÁâàÊú¨ÔºåÊúÄÂ§ß‰∏∫65BÂèÇÊï∞„ÄÇ‰∏éGPTÁ±ª‰ººÔºåÂèØÁî®‰∫éËøõ‰∏ÄÊ≠•ÂæÆË∞ÉÔºåÈÄÇÁî®‰∫éÂ§öÁßç‰ªªÂä°„ÄÇ‰∏éGPT‰∏çÂêåÁöÑÊòØÔºåLLaMAÊòØÂºÄÊ∫êÁöÑÔºåÂèØ‰ª•Âú®Êú¨Âú∞ËøêË°å„ÄÇÁé∞ÊúâÁöÑLLaMAÊ®°ÂûãÂåÖÊã¨ÔºöAlpaca„ÄÅVicuna„ÄÅKoala„ÄÅGPT4-x-AlpacaÂíåWizardLM„ÄÇÊØè‰∏™Ê®°ÂûãÈÉΩÊúâ‰∏çÂêåÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂíåÊÄßËÉΩË°®Áé∞blogÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂ§çÊùÇÊé®ÁêÜËÆ®ËÆ∫‰∫ÜÂ¶Ç‰ΩïËÆ≠ÁªÉÂÖ∑ÊúâÂº∫Â§ßÂ§çÊùÇÊé®ÁêÜËÉΩÂäõÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºåÂπ∂Êé¢ËÆ®‰∫ÜÂ¶Ç‰ΩïÊúâÊïàÂú∞ÊèêÁ§∫Ê®°Âûã‰ª•ÂÖÖÂàÜÈáäÊîæÂÖ∂ÊΩúÂäõÔºõÈíàÂØπËØ≠Ë®ÄÊ®°ÂûãÂíåÁºñÁ®ãÁöÑËÆ≠ÁªÉÁõ∏‰ººÊÄßÔºåÊèêÂá∫‰∫Ü‰∏âÈò∂ÊÆµÁöÑËÆ≠ÁªÉÔºöÊåÅÁª≠ËÆ≠ÁªÉ„ÄÅÁõëÁù£ÂæÆË∞ÉÂíåÂº∫ÂåñÂ≠¶‰π†Ôºõ‰ªãÁªç‰∫ÜËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊé®ÁêÜËÉΩÂäõÁöÑ‰∏ÄÂ•ó‰ªªÂä°ÈõÜÂêàÔºõËÆ®ËÆ∫‰∫ÜÂ¶Ç‰ΩïËøõË°åÊèêÁ§∫Â∑•Á®ãÔºåÈÄöËøáÊèê‰æõÂêÑÁßçÂ≠¶‰π†Êú∫‰ºö‰ΩøÊ®°ÂûãËé∑ÂæóÊõ¥Â•ΩÁöÑÂ≠¶‰π†ÊïàÊûúÔºåÊúÄÁªàÂÆûÁé∞Êô∫ËÉΩÂåñlinkÂ§ßËØ≠Ë®ÄÊ®°ÂûãËøõÂåñÊ†ëpaperÊùéÂÆèÊØÖÔºöÁ©∑‰∫∫Â¶Ç‰Ωï‰ΩéËµÑÊ∫êÂ§çÂàªËá™Â∑±ÁöÑChatGPTblogËÆ≠ÁªÉChatGPTÁöÑÂøÖÂ§áËµÑÊ∫êÔºöËØ≠Êñô„ÄÅÊ®°ÂûãÂíå‰ª£Á†ÅÂ∫ìÂÆåÂÖ®ÊåáÂçóËµÑÊ∫êÈìæÊé•ËÆ∫ÊñáÂú∞ÂùÄGitHubÂÆùËóèÂ∫ìÔºåÈáåÈù¢Êï¥ÁêÜ‰∫ÜGPTÁõ∏ÂÖ≥ÁöÑÂêÑÁßçÂºÄÊ∫êÈ°πÁõÆgithubChatGPT‰∏≠ÊñáÊåáÂçógitlabÊé¢ËÆ®‰∫ÜChatGPTÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰∏≠ÁöÑÂ∫îÁî®„ÄÅ‰ºòÂäø„ÄÅÈôêÂà∂‰ª•ÂèäÊú™Êù•ÂèëÂ±ïÊñπÂêëÂº∫Ë∞É‰∫ÜÂú®‰ΩøÁî®ËØ•ÊäÄÊúØÊó∂ÁöÑ‰º¶ÁêÜÈÅìÂæ∑ËÄÉÈáèÂíåÊèêÁ§∫Â∑•Á®ãÊäÄÊúØ„ÄÇpaperÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁõ∏ÂÖ≥ÊñáÁåÆËµÑÊ∫êÂàóË°®githubÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊñáÁåÆÁªºËø∞--‰∏≠ÊñáÁâàgithubChatGPT Áõ∏ÂÖ≥ËµÑÊ∫êÂ§ßÂàóË°®githubPre-Training to Learn in ContextpaperLangchainÊû∂ÊûÑÂõæimageLLMÂºÄÂèë‰∫∫ÂëòÈÉΩÂ∫îËØ•Áü•ÈÅìÁöÑÊï∞Â≠ógithubÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂ¶Ç‰ΩïÊûÑÂª∫Âº∫Â§ßÁöÑÂ§çÊùÇÊé®ÁêÜËÉΩÂäõblogLLMs‰πùÂ±ÇÂ¶ñÂ°îÂàÜ‰∫´ÊâìÊÄ™(ChatGLM„ÄÅChinese-LLaMA-Alpaca„ÄÅMiniGPT-4„ÄÅFastChat„ÄÅLLaMA„ÄÅgpt4allÁ≠â)ÂÆûÊàò‰∏éÁªèÈ™ågithubÁ±ªChatGPTÁöÑÂºÄÊ∫êÊ°ÜÊû∂ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•LLM-As-ChatbotËøô‰∏™È°πÁõÆÊääÂ∏ÇÈù¢‰∏äÊúâÁöÑLLMÂÖ®ÈÉ®ÂÅöÊàê‰∫ÜChatbotÔºåÁõ¥Êé•ÂèØ‰ª•Âú®google colabËøêË°åÔºå‰∏çÈúÄË¶ÅËá™Â∑±Êê≠Âª∫ÔºåÈùûÂ∏∏ÈÄÇÁî®‰∫éÊÉ≥‰ΩìÈ™åLLMÁöÑÊúãÂèã‰ª¨„ÄÇÊàëÂàöËØï‰∫ÜÔºåÁúüÁöÑË∂ÖÁÆÄÂçï„ÄÇÊúâ‰∫õLLMÈúÄË¶ÅÁöÑÊòæÂ≠òÊØîËæÉÂ§öÔºåÊâÄ‰ª•ÊúÄÂ•ΩÊòØË¶ÅÊúâcolab proËÆ¢ÈòÖ„ÄÇgithubOpenBuddy‰∏ÄÊ¨æÂº∫Â§ßÁöÑÂºÄÊ∫êÂ§öËØ≠Ë®ÄËÅäÂ§©Êú∫Âô®‰∫∫Ê®°ÂûãÔºåÁõÆÊ†áÊòØÂÖ®ÁêÉÁî®Êà∑ÔºåÈáçÁÇπÊòØÂØπËØùAIÂíåÊµÅÁïÖÁöÑÂ§öËØ≠Ë®ÄÊîØÊåÅÔºåÂåÖÊã¨Ëã±Êñá„ÄÅ‰∏≠ÊñáÁ≠âÂ§öÁßçËØ≠Ë®Ä„ÄÇÂü∫‰∫éFacebookÁöÑLLAMAÊ®°ÂûãÔºåËøõË°å‰∫ÜÂæÆË∞ÉÔºåÂåÖÊã¨Êâ©Â±ïËØçÊ±áË°®„ÄÅÂ¢ûÂä†Â∏∏Áî®Â≠óÁ¨¶ÂíåÂ¢ûÂº∫ÁöÑtoken embeddings„ÄÇÈÄöËøáËøô‰∫õÊîπËøõÂíåÂ§öËΩÆÂØπËØùÊï∞ÊçÆÈõÜÔºåOpenBuddyÊèê‰æõ‰∫Ü‰∏Ä‰∏™Âº∫Â§ßÁöÑÊ®°ÂûãÔºåËÉΩÂõûÁ≠îÈóÆÈ¢òÂπ∂Âú®ÂêÑÁßçËØ≠Ë®Ä‰πãÈó¥ËøõË°åÁøªËØë‰ªªÂä°„ÄÇOpenBuddyÁöÑ‰ΩøÂëΩÊòØÊèê‰æõ‰∏Ä‰∏™ÂÖçË¥π„ÄÅÂºÄÊîæ‰∏îÂèØÁ¶ªÁ∫ø‰ΩøÁî®ÁöÑAIÊ®°ÂûãÔºåËØ•Ê®°ÂûãÂèØ‰ª•Âú®Áî®Êà∑ÁöÑËÆæÂ§á‰∏äËøêË°åÔºåÊó†ËÆ∫‰ªñ‰ª¨ÁöÑËØ≠Ë®ÄÊàñÊñáÂåñËÉåÊôØÂ¶Ç‰Ωï„ÄÇÁõÆÂâçÔºåOpenBuddy-13BÁöÑÊºîÁ§∫ÁâàÊú¨ÂèØ‰ª•Âú®DiscordÊúçÂä°Âô®‰∏äÊâæÂà∞„ÄÇÂÖ∂ÂÖ≥ÈîÆÂäüËÉΩÂåÖÊã¨Â§öËØ≠Ë®ÄÂØπËØùAI(ÂåÖÊã¨‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊó•Êñá„ÄÅÈü©Êñá„ÄÅÊ≥ïÊñáÁ≠â)„ÄÅÂ¢ûÂº∫ÁöÑËØçÊ±áË°®ÂíåÂØπÂ∏∏ËßÅCJKÂ≠óÁ¨¶ÁöÑÊîØÊåÅÔºå‰ª•Âèä‰∏§ÁßçÊ®°ÂûãÁâàÊú¨Ôºö7BÂíå13Bgithub-OpenBuddyPanda: Êµ∑Â§ñ‰∏≠ÊñáÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫‰∫é Llama-7B, -13B, -33B, -65B ËøõË°å‰∏≠ÊñáÈ¢ÜÂüü‰∏äÁöÑÊåÅÁª≠È¢ÑËÆ≠ÁªÉÔºå‰ΩøÁî®‰∫ÜÊé•Ëøë15MÊù°Êï∞ÊçÆÔºåÂπ∂ÈíàÂØπÊé®ÁêÜËÉΩÂäõÂú®‰∏≠Êñábenchmark‰∏äËøõË°å‰∫ÜËØÑÊµãgithub-PandaLMDromedaryÔºö‰∏Ä‰∏™ÂºÄÊ∫êÁöÑËá™ÂØπÈΩêËØ≠Ë®ÄÊ®°ÂûãÔºåÂè™ÈúÄÂ∞ëÈáè‰∫∫Â∑•ÁõëÁù£Âç≥ÂèØËøõË°åËÆ≠ÁªÉgithub-DromedaryLaMini-LM Ëí∏È¶èÁöÑÂ∞èÂûã„ÄÅÈ´òÊïàÁöÑËØ≠Ë®ÄÊ®°ÂûãÈõÜÂêà‰ªé ChatGPT Ëí∏È¶èÁöÑÂ∞èÂûã„ÄÅÈ´òÊïàÁöÑËØ≠Ë®ÄÊ®°ÂûãÈõÜÂêàÔºåÂú®2.58 M Êåá‰ª§Â§ßËßÑÊ®°Êï∞ÊçÆÈõÜ‰∏äËøõË°åËÆ≠ÁªÉgithubLLaMA-Adapter V2‰∏äÊµ∑‰∫∫Â∑•Êô∫ËÉΩÂÆûÈ™åÂÆ§ LLaMA-Adapter V2Ôºå‰ªÖÊ≥®ÂÖ•14MÂèÇÊï∞Ôºå1Â∞èÊó∂Êó∂Èó¥Âç≥ÂèØÂÆåÊàêËÆ≠ÁªÉÔºåÂØπÊØîËæÉÊûúÁ°ÆÂÆûÂæàÊÉäËâ≥Ôºå‰∏îÂÖ∑ÊúâÂ§öÊ®°ÊÄÅÂäüËÉΩÔºàÂØπÂõæÂÉèËøõË°åËß£ÈáäÂíåÈóÆÁ≠îÔºâgithubHuggingChatHugging Face Êé®Âá∫Á¨¨‰∏Ä‰∏™ ChatGPT ÂºÄÊ∫êÊõø‰ª£ÂìÅÔºöHuggingChat„ÄÇÂü∫‰∫é Open Assistant  Â§ßÊ®°ÂûãÊê≠Âª∫ÔºåÊîØÊåÅ‰∏≠ÊñáÂØπËØù‰∏éÁºñÂÜô‰ª£Á†ÅÔºå‰ΩÜÊöÇ‰∏çÊîØÊåÅ‰∏≠ÊñáÂõûÂ§ç„ÄÇÂ∫îÁî®Â∑≤‰∏äÁ∫øÔºåÊó†ÈúÄ‰ª£ÁêÜÔºåÊâìÂºÄÂç≥ÂèØËÆøÈóÆlinkOpen-Chinese-LLaMAÂü∫‰∫é LLaMA-7B ÁªèËøá ‰∏≠ÊñáÊï∞ÊçÆÈõÜÂ¢ûÈáèÈ¢ÑËÆ≠ÁªÉ ‰∫ßÁîüÁöÑ ‰∏≠ÊñáÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫Â∫ßgithubOpenLLaMALLaMAÊ®°ÂûãÁöÑÂºÄÊ∫êÂ§çÁé∞ÔºåÂú®RedPajamaÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÔºå‰ΩøÁî®‰∫Ü‰∏éLLaMAÁõ∏ÂêåÁöÑÈ¢ÑÂ§ÑÁêÜÊ≠•È™§ÂíåË∂ÖÂèÇÊï∞ÔºåÊ®°ÂûãÁªìÊûÑÔºå‰∏ä‰∏ãÊñáÈïøÂ∫¶ÔºåËÆ≠ÁªÉÊ≠•È™§ÔºåÂ≠¶‰π†ÁéáË∞ÉÂ∫¶Âíå‰ºòÂåñÂô®„ÄÇOpenLLaMAÁöÑPyTorchÂíåJaxÊùÉÈáçÂèØ‰ª•Âú®Huggingface Hub‰∏äËé∑Âæó„ÄÇOpenLLaMAÂú®ÂêÑÁßç‰ªªÂä°‰∏≠Â±ïÁé∞Âá∫‰∏éLLaMAÂíåGPT-JÁõ∏‰ººÁöÑË°®Áé∞ÔºåÈÉ®ÂàÜ‰ªªÂä°Ë°®Áé∞‰ºòÂºÇgithubreplit-code-v1-3bBY-SA 4.0ÊéàÊùÉÂèëÂ∏ÉÔºåËøôÊÑèÂë≥ÁùÄÂÖÅËÆ∏ÂïÜ‰∏ö‰ΩøÁî®linkMOSSMOSSÊòØ‰∏Ä‰∏™ÊîØÊåÅ‰∏≠Ëã±ÂèåËØ≠ÂíåÂ§öÁßçÊèí‰ª∂ÁöÑÂºÄÊ∫êÂØπËØùËØ≠Ë®ÄÊ®°ÂûãÔºåmoss-moonÁ≥ªÂàóÊ®°ÂûãÂÖ∑Êúâ160‰∫øÂèÇÊï∞ÔºåÂú®FP16Á≤æÂ∫¶‰∏ãÂèØÂú®ÂçïÂº†A100/A800Êàñ‰∏§Âº†3090ÊòæÂç°ËøêË°åÔºåÂú®INT4/8Á≤æÂ∫¶‰∏ãÂèØÂú®ÂçïÂº†3090ÊòæÂç°ËøêË°å„ÄÇMOSSÂü∫Â∫ßËØ≠Ë®ÄÊ®°ÂûãÂú®Á∫¶‰∏ÉÂçÉ‰∫ø‰∏≠Ëã±Êñá‰ª•Âèä‰ª£Á†ÅÂçïËØç‰∏äÈ¢ÑËÆ≠ÁªÉÂæóÂà∞ÔºåÂêéÁª≠ÁªèËøáÂØπËØùÊåá‰ª§ÂæÆË∞É„ÄÅÊèí‰ª∂Â¢ûÂº∫Â≠¶‰π†Âíå‰∫∫Á±ªÂÅèÂ•ΩËÆ≠ÁªÉÂÖ∑Â§áÂ§öËΩÆÂØπËØùËÉΩÂäõÂèä‰ΩøÁî®Â§öÁßçÊèí‰ª∂ÁöÑËÉΩÂäõ„ÄÇgithubRedPajama1.2 ‰∏á‰∫øtokensÊï∞ÊçÆÈõÜlinkchinese_llama_alpaca_lora ÊäΩÂèñÊ°ÜÊû∂githubScaling Transformer to 1M tokens and beyond with RMTËØ•ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÂêç‰∏∫ RMT ÁöÑÊñ∞ÊäÄÊúØÔºåÊàñËÆ∏ÂèØÂ∞Ü Transform ÁöÑ Token ‰∏äÈôêÊâ©Â±ïËá≥ 100 ‰∏áÔºåÁîöËá≥Êõ¥Â§ö„ÄÇgithubOpen AssistantÂåÖÂê´Â§ßÈáèAIÁîüÊàêÁöÑ„ÄÅ‰∫∫Â∑•Ê†áÊ≥®ÁöÑËØ≠ÊñôÂ∫ìÂíåÂåÖÊã¨Âü∫‰∫éLLaMAÂíåÂü∫‰∫éPythiaÁöÑÂ§öÁßçÊ®°ÂûãÂèØÈÄâ„ÄÇÂèëÂ∏ÉÁöÑÊï∞ÊçÆÈõÜÂåÖÊã¨Ë∂ÖËøá161KËæÉÈ´òË¥®ÈáèÁöÑÔºåÂ§öËææ35ÁßçËØ≠Ë®ÄÁöÑ‰∫∫Â∑•Âä©ÊâãÂûã‰∫§‰∫íÂØπËØùËØ≠ÊñôÂ∫ìdata modelChatGLM Efficient TuningÂü∫‰∫é PEFT ÁöÑÈ´òÊïà ChatGLM ÂæÆË∞ÉgithubDolly‰ªãÁªçnewsBaizeÔºö‰∏ÄÁßçÂØπËá™ËÅäÂ§©Êï∞ÊçÆËøõË°åÂèÇÊï∞È´òÊïàË∞É‰ºòÁöÑÂºÄÊ∫êËÅäÂ§©Ê®°ÂûãBaizeÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑËÅäÂ§©Ê®°ÂûãÔºåÂèØ‰ª•ËøõË°åÂ§öËΩÆÂØπËØù„ÄÇÂÆÉÊòØÈÄöËøá‰ΩøÁî®ChatGPTËá™ÊàëÂØπËØùÁîüÊàêÈ´òË¥®ÈáèÁöÑÂ§öËΩÆËÅäÂ§©ËØ≠ÊñôÂ∫ìÔºåÂπ∂‰ΩøÁî®ÂèÇÊï∞È´òÊïàË∞ÉÊï¥Êù•Â¢ûÂº∫LLaMAÔºà‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºâËÄåÂàõÂª∫ÁöÑ„ÄÇBaizeÊ®°ÂûãÂú®ÂÖ∑ÊúâÊúÄÂ∞èÊΩúÂú®È£éÈô©ÁöÑÊÉÖÂÜµ‰∏ãË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÂ§öËΩÆÂØπËØùÊÄßËÉΩ„ÄÇÂÆÉÂèØ‰ª•Âú®Âçï‰∏™GPU‰∏äËøêË°åÔºå‰ΩøÊõ¥ÂπøÊ≥õÁöÑÁ†îÁ©∂‰∫∫ÂëòÂèØ‰ª•‰ΩøÁî®ÂÆÉ„ÄÇBaizeÊ®°ÂûãÂíåÊï∞ÊçÆ‰ªÖÁî®‰∫éÁ†îÁ©∂ÁõÆÁöÑ„ÄÇËÆ∫ÊñáÂú∞ÂùÄÊ∫êÁ†ÅÂú∞ÂùÄGPTrillion--Êú™ÊâæÂà∞ÂºÄÊ∫ê‰ª£Á†ÅÂåÖÂê´1.5‰∏á‰∫øÔºà1.5TÔºâÂèÇÊï∞ÁöÑÂ§ßÊ®°ÂûãGPTrillionÂºÄÊ∫ê‰∫ÜÔºåÂè∑Áß∞ÊòØÁõÆÂâç‰∏ñÁïå‰∏äÊúÄÂ§ßÁöÑÂºÄÊ∫êLLMgoogle_docCerebras-GPT-13B(ÂèØÂïÜÁî®)hugging_faceChinese-ChatLLaMA‰∏≠ÊñáChatLLaMAÂØπËØùÊ®°ÂûãÔºõÈ¢ÑËÆ≠ÁªÉ/Êåá‰ª§ÂæÆË∞ÉÊï∞ÊçÆÈõÜÔºåÂü∫‰∫é TencentPretrain Â§öÊ®°ÊÄÅÈ¢ÑËÆ≠ÁªÉÊ°ÜÊû∂ÊûÑÂª∫ÔºåÊîØÊåÅÁÆÄÁπÅ‰Ωì‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊó•ÊñáÁ≠âÂ§öËØ≠Ë®ÄgithubLit-LLaMAÂü∫‰∫éApache 2.0ËÆ∏ÂèØËØÅÂÆåÂÖ®ÂºÄÊ∫êÁöÑLLaMAÁã¨Á´ãÂÆûÁé∞ÔºåÂª∫Á´ãÂú®nanoGPT‰πã‰∏äÔºåÊó®Âú®Ëß£ÂÜ≥ÂéüÂßãLLaMA‰ª£Á†ÅÈááÁî®GPLËÆ∏ÂèØËØÅÁöÑÈôêÂà∂Ôºå‰ª•ÂÆûÁé∞Êõ¥ÂπøÊ≥õÁöÑÂ≠¶ÊúØÂíåÂïÜ‰∏öÂ∫îÁî®githubMosaicMLMPT-7B-StoryWriterÔºå65K tokensÔºåÂèØ‰ª•Êää„Ää‰∫Ü‰∏çËµ∑ÁöÑÁõñËå®ÊØî„ÄãÈÉΩ‰∏ÄÊ¨°ÊÄßÊâîËøõÂéª„ÄÇhuggingfaceLangchainÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊ≠£Âú®Êàê‰∏∫‰∏ÄÈ°πÂÖ∑ÊúâÂèòÈù©ÊÄßÁöÑÊäÄÊúØÔºå‰ΩøÂºÄÂèëËÄÖËÉΩÂ§üÊûÑÂª∫‰ª•ÂâçÊó†Ê≥ïÂÆûÁé∞ÁöÑÂ∫îÁî®Á®ãÂ∫è„ÄÇÁÑ∂ËÄåÔºå‰ªÖ‰ªÖ‰ΩøÁî®Ëøô‰∫õÁã¨Á´ãÁöÑLLMsÈÄöÂ∏∏‰∏çË∂≥‰ª•ÂàõÂª∫‰∏Ä‰∏™ÁúüÊ≠£Âº∫Â§ßÁöÑÂ∫îÁî®Á®ãÂ∫è - ÁúüÊ≠£ÁöÑÂäõÈáèÊù•Ëá™‰∫éËÉΩÂ§üÂ∞ÜÂÆÉ‰ª¨‰∏éÂÖ∂‰ªñËÆ°ÁÆóÊàñÁü•ËØÜÊù•Ê∫êÁõ∏ÁªìÂêà„ÄÇgithubGuidanceÂºïÂØºËÉΩÂ§üÊØî‰º†ÁªüÁöÑÊèêÁ§∫ÊàñÈìæÊé•Êõ¥ÊúâÊïàÂú∞ÊéßÂà∂Áé∞‰ª£ËØ≠Ë®ÄÊ®°ÂûãÔºåÂπ∂‰∏îÊõ¥È´òÊïà„ÄÇÂºïÂØºÁ®ãÂ∫èÂÖÅËÆ∏ÊÇ®Â∞ÜÁîüÊàê„ÄÅÊèêÁ§∫ÂíåÈÄªËæëÊéßÂà∂‰∫§ÈîôÂà∞Âçï‰∏ÄËøûÁª≠ÊµÅ‰∏≠Ôºå‰∏éËØ≠Ë®ÄÊ®°ÂûãÂÆûÈôÖÂ§ÑÁêÜÊñáÊú¨ÁöÑÊñπÂºèÁõ∏ÂåπÈÖç„ÄÇÂÉè\""Chain of Thought\""ÂèäÂÖ∂ËÆ∏Â§öÂèò‰ΩìÔºà‰æãÂ¶ÇART„ÄÅAuto-CoTÁ≠âÔºâËøôÊ†∑ÁöÑÁÆÄÂçïËæìÂá∫ÁªìÊûÑÂ∑≤Ë¢´ËØÅÊòéËÉΩÊîπÂñÑËØ≠Ë®ÄÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇÊõ¥Âº∫Â§ßÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºàÂ¶ÇGPT-4ÔºâÁöÑÂá∫Áé∞‰ΩøÂæóÊõ¥‰∏∞ÂØåÁöÑÁªìÊûÑÊàê‰∏∫ÂèØËÉΩÔºåËÄåÂºïÂØºÂàô‰ΩøÂæóÊûÑÂª∫ËøôÁßçÁªìÊûÑÂèòÂæóÊõ¥Âä†ÂÆπÊòìÂíåÁªèÊµé„ÄÇgithubWizardLMËµã‰∫àÂ§ßÂûãÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÈÅµÂæ™Â§çÊùÇÊåá‰ª§ÁöÑËÉΩÂäõÔºå‰ΩøÁî®ÂÆåÊï¥ËøõÂåñÊåá‰ª§ÔºàÁ∫¶300kÔºâËÆ≠ÁªÉÁöÑWizardLM-7BÊ®°ÂûãgithubLLMÁöÑËÆ≠ÁªÉ_Êé®ÁêÜ_‰ΩéËµÑÊ∫ê_È´òÊïàËÆ≠ÁªÉËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•QLoRA--Guanaco‰∏ÄÁßçÈ´òÊïàÁöÑÂæÆË∞ÉÊñπÊ≥ïÔºåÂèØ‰ª•Âú®Âçï‰∏™48GBÁöÑGPU‰∏äÂæÆË∞É‰∏Ä‰∏™Êã•Êúâ65BÂèÇÊï∞ÁöÑÊ®°ÂûãÔºåÂêåÊó∂‰øùÊåÅÂÆåÊï¥ÁöÑ16‰ΩçÂæÆË∞É‰ªªÂä°ÊÄßËÉΩÔºåÂπ∂ÈÄöËøáQLoRAÂ∞ÜÊ¢ØÂ∫¶ÂèçÂêë‰º†Êí≠ÈÄöËøá‰∏Ä‰∏™ÂÜªÁªìÁöÑ„ÄÅ4‰ΩçÈáèÂåñÁöÑÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÂà∞‰ΩéÁß©ÈÄÇÈÖçÂô®ÔºàLoRAÔºâgithubChinese-Guanaco‰∏Ä‰∏™‰∏≠Êñá‰ΩéËµÑÊ∫êÁöÑÈáèÂåñËÆ≠ÁªÉ/ÈÉ®ÁΩ≤ÊñπÊ°àgithubDeepSpeed Chat: ‰∏ÄÈîÆÂºèRLHFËÆ≠ÁªÉgithubLLMTune: Âú®Ê∂àË¥πÁ∫ßGPU‰∏äÂæÆË∞ÉÂ§ßÂûã65B+LLMÂèØ‰ª•Âú®ÊôÆÈÄöÊ∂àË¥πÁ∫ßGPU‰∏äËøõË°å4‰ΩçÂæÆË∞ÉÔºå‰æãÂ¶ÇÊúÄÂ§ßÁöÑ65B LLAMAÊ®°Âûã„ÄÇLLMTuneËøòÂÆûÁé∞‰∫ÜLoRAÁÆóÊ≥ïÂíåGPTQÁÆóÊ≥ïÊù•ÂéãÁº©ÂíåÈáèÂåñLLMÔºåÂπ∂ÈÄöËøáÊï∞ÊçÆÂπ∂Ë°åÂ§ÑÁêÜÂ§ßÂûãÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåLLMTuneÊèê‰æõ‰∫ÜÂëΩ‰ª§Ë°åÁïåÈù¢ÂíåPythonÂ∫ìÁöÑ‰ΩøÁî®ÊñπÂºègithubÂü∫‰∫éChatGLM-6B+LoRAÂú®Êåá‰ª§Êï∞ÊçÆÈõÜ‰∏äËøõË°åÂæÆË∞ÉÂü∫‰∫édeepspeedÊîØÊåÅÂ§öÂç°ÂæÆË∞ÉÔºåÈÄüÂ∫¶Áõ∏ÊØîÂçïÂç°ÊèêÂçá8-9ÂÄçÂÖ∑‰ΩìËÆæÁΩÆÂèØËßÅ ÂæÆË∞É3 Âü∫‰∫éDeepSpeedËøõË°åLoraÂæÆË∞ÉgithubÂæÆËΩØÂèëÂ∏ÉRLHFËÆ≠ÁªÉÂ∑•ÂÖ∑DeepSpeed ChatgithubLlamaChatÔºöMac‰∏äÂü∫‰∫éLLaMaÁöÑËÅäÂ§©Êú∫Âô®‰∫∫githubChatGPT/GPT4ÂºÄÊ∫ê‚ÄúÂπ≥Êõø‚Äù‰ª¨githubËÆ≠ÁªÉÂ§ßÂûãÊú∫Âô®Â≠¶‰π†Ê®°ÂûãÁöÑÂÆûÁî®Âª∫ËÆÆÂíåÊäÄÂ∑ßÂ∏ÆÂä©ÊÇ®ËÆ≠ÁªÉÂ§ßÂûãÊ®°ÂûãÔºà>1B ÂèÇÊï∞Ôºâ„ÄÅÈÅøÂÖç‰∏çÁ®≥ÂÆöÊÄß„ÄÅ‰øùÂ≠òÂºÄÂßãÂ§±Ë¥•ÁöÑÂÆûÈ™åËÄå‰∏ç‰ªé 0 ÈáçÊñ∞ÂºÄÂßãlinkInstruction Tuning with GPT-4paperxturing‰∏Ä‰∏™PythonËΩØ‰ª∂ÂåÖÔºåÁî®‰∫éÈ´òÊïà„ÄÅÂø´ÈÄü„ÄÅÁÆÄÂçïÂú∞ÂæÆË∞ÉLLMÊ®°ÂûãÔºåÊîØÊåÅLLaMA„ÄÅGPT-J„ÄÅGPT-2Á≠âÂ§öÁßçÊ®°ÂûãÔºåÂèØ‰ΩøÁî®ÂçïGPUÂíåÂ§öGPUËÆ≠ÁªÉÔºå‰ΩøÁî®LoRAÁ≠âÈ´òÊïàÂæÆË∞ÉÊäÄÊúØÂèØÂ∞ÜÁ°¨‰ª∂ÊàêÊú¨Èôç‰ΩéÈ´òËææ90%ÔºåÂπ∂Âú®Áü≠Êó∂Èó¥ÂÜÖÂÆåÊàêÊ®°ÂûãËÆ≠ÁªÉgithubGPT4All‰∏Ä‰∏™ÂÖÅËÆ∏Âú®MacbookÊú¨Âú∞ËøêË°åGPTÁöÑÂºÄÊ∫êÈ°πÁõÆ„ÄÇÂü∫‰∫éLLaMa-7BÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊâìÈÄ†ÔºåÂåÖÊã¨Êï∞ÊçÆ„ÄÅ‰ª£Á†ÅÂíådemoÈÉΩÊòØÂºÄÊ∫êÁöÑÔºåÂØπËØùÈ£éÊ†ºÂÅèÂêëAIÂä©ÁêÜgithubÁî®Alpaca-LoRAÂæÆË∞ÉChatGPTÁ±ªÊ®°ÂûãlinkLMFlowÂèØÊâ©Â±ï„ÄÅÊñπ‰æøÊúâÊïàÁöÑÂ∑•ÂÖ∑ÁÆ±ÔºåÁî®‰∫éÂæÆË∞ÉÂ§ßÂûãÊú∫Âô®Â≠¶‰π†Ê®°ÂûãgithubÈóªËææÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãË∞ÉÁî®Âπ≥Âè∞ÁõÆÂâçÊîØÊåÅchatGLM-6B„ÄÅchatRWKV„ÄÅchatYuanÂíåchatGLM-6BÊ®°Âûã‰∏ãÁöÑchatPDFÔºàËá™Âª∫Áü•ËØÜÂ∫ìÊü•ÊâæÔºâ'githubMicro AgentÂ∞èÂûãËá™‰∏ªÊô∫ËÉΩ‰ΩìÂºÄÊ∫êÈ°πÁõÆÔºåÁî±LLM(OpenAI GPT-4)Êèê‰æõÂä®ÂäõÔºåÂèØ‰ª•‰∏∫‰Ω†ÁºñÂÜôËΩØ‰ª∂ÔºåÂè™ÈúÄËÆæÁΩÆ‰∏Ä‰∏™‚ÄúÁõÆÁöÑ‚ÄùÔºåËÆ©ÂÆÉËá™Â∑±Â∑•‰ΩúgithubLlama-XÂºÄÊ∫êÁöÑÂ≠¶ÊúØÁ†îÁ©∂È°πÁõÆÔºåÈÄöËøáÁ§æÂå∫ÂÖ±ÂêåÂä™ÂäõÔºåÈÄêÊ≠•Â∞ÜLLaMAÁöÑÊÄßËÉΩÊèêÈ´òÂà∞SOTA LLMÊ∞¥Âπ≥ÔºåËäÇÁúÅÈáçÂ§çÂ∑•‰ΩúÔºåÂÖ±ÂêåÂàõÈÄ†Êõ¥Â§ö„ÄÅÊõ¥Âø´ÁöÑÂ¢ûÈáègithubChinese-LLaMA-Alpaca‰∏≠ÊñáLLaMA&AlpacaÂ§ßËØ≠Ë®ÄÊ®°Âûã+Êú¨Âú∞ÈÉ®ÁΩ≤ (Chinese LLaMA & Alpaca LLMs) - ÂºÄÊ∫ê‰∫ÜÁªèËøá‰∏≠ÊñáÊñáÊú¨Êï∞ÊçÆÈ¢ÑËÆ≠ÁªÉÁöÑ‰∏≠ÊñáLLaMAÂ§ßÊ®°ÂûãÔºõÂºÄÊ∫ê‰∫ÜËøõ‰∏ÄÊ≠•ÁªèËøáÊåá‰ª§Á≤æË∞ÉÁöÑ‰∏≠ÊñáAlpacaÂ§ßÊ®°ÂûãÔºõÂø´ÈÄüÂú∞‰ΩøÁî®Á¨îËÆ∞Êú¨ÁîµËÑëÔºà‰∏™‰∫∫PCÔºâÊú¨Âú∞ÈÉ®ÁΩ≤Âíå‰ΩìÈ™åÈáèÂåñÁâàÂ§ßÊ®°ÂûãgithubEfficient AlpacaÂü∫‰∫éLLaMAÂÆûÁé∞ÁöÑÂºÄÊ∫êÈ°πÁõÆÔºåÊó®Âú®ÈÄöËøáÂæÆË∞É LLaMA-7BÊ®°ÂûãÂú®ËµÑÊ∫êÊ∂àËÄóÊõ¥Â∞ë„ÄÅÊé®ÁêÜÈÄüÂ∫¶Êõ¥Âø´„ÄÅÊõ¥ÈÄÇÂêàÁ†îÁ©∂ËÄÖ‰ΩøÁî®ÊñπÈù¢ÊèêÈ´òStanford AlpacaÁöÑÊÄßËÉΩgithubChatGLM-6B-SlimË£ÅÂáèÊéâ20KÂõæÁâáTokenÁöÑChatGLM-6BÔºåÂÆåÂÖ®‰∏ÄÊ†∑ÁöÑÊÄßËÉΩÔºåÂç†Áî®Êõ¥Â∞èÁöÑÊòæÂ≠ògithubChinese-Vicuna‰∏Ä‰∏™‰∏≠Êñá‰ΩéËµÑÊ∫êÁöÑllama+loraÊñπÊ°àgithubAlpaca-LoRAÁî®LoRAÂú®Ê∂àË¥πÁ∫ßÁ°¨‰ª∂‰∏äÂ§çÁé∞ÊñØÂù¶Á¶èAlpacaÁöÑÁªìÊûúgithubLLM AcceleratorËÆ©Âü∫Á°ÄÂ§ßÊ®°ÂûãÊõ¥ËÅ™ÊòéÁöÑLLM AcceleratorÊù•‰∫ÜÔºÅÂü∫Á°ÄÂ§ßÊ®°ÂûãÊ≠£Âú®ËØ∏Â§öÂ∫îÁî®‰∏≠ÂèëÊå•ÁùÄÊó•ÁõäÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇÂ§ßÂ§öÊï∞Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËÆ≠ÁªÉÈÉΩÊòØÈááÂèñËá™ÂõûÂΩíÁöÑÊñπÂºèËøõË°åÁîüÊàêÔºåËôΩÁÑ∂Ëá™ÂõûÂΩíÊ®°ÂûãÁîüÊàêÁöÑÊñáÊú¨Ë¥®ÈáèÊúâÊâÄ‰øùËØÅÔºå‰ΩÜÂç¥ÂØºËá¥‰∫ÜÈ´òÊòÇÁöÑÊé®ÁêÜÊàêÊú¨ÂíåÈïøÊó∂Èó¥ÁöÑÂª∂Ëøü„ÄÇÁî±‰∫éÂ§ßÊ®°ÂûãÁöÑÂèÇÊï∞ÈáèÂ∑®Â§ß„ÄÅÊé®ÁêÜÊàêÊú¨È´òÔºåÂõ†Ê≠§Â¶Ç‰ΩïÂú®Â§ßËßÑÊ®°ÈÉ®ÁΩ≤Â§ßÊ®°ÂûãÁöÑËøáÁ®ã‰∏≠Èôç‰ΩéÊàêÊú¨„ÄÅÂáèÂ∞èÂª∂ËøüÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆËØæÈ¢ò„ÄÇÈíàÂØπÊ≠§ÈóÆÈ¢òÔºåÂæÆËΩØ‰∫öÊ¥≤Á†îÁ©∂Èô¢ÁöÑÁ†îÁ©∂Âëò‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßç‰ΩøÁî®ÂèÇËÄÉÊñáÊú¨Êó†ÊçüÂä†ÈÄüÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊé®ÁêÜÁöÑÊñπÊ≥ï LLM AcceleratorÔºåÂú®Â§ßÊ®°ÂûãÂÖ∏ÂûãÁöÑÂ∫îÁî®Âú∫ÊôØ‰∏≠ÂèØ‰ª•ÂèñÂæó‰∏§Âà∞‰∏âÂÄçÁöÑÂä†ÈÄü„ÄÇblogÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂæÆË∞ÉÊäÄÊúØÁ¨îËÆ∞githubPyLLMsÁÆÄÊ¥ÅÁöÑ Python Â∫ìÔºåÁî®‰∫éËøûÊé•ÂêÑÁßç LLM(OpenAI„ÄÅAnthropic„ÄÅGoogle„ÄÅAI21„ÄÅCohere„ÄÅAleph Alpha„ÄÅHuggingfaceHub)ÔºåÂÜÖÁΩÆÊ®°ÂûãÊÄßËÉΩÂü∫ÂáÜ„ÄÇÈùûÂ∏∏ÈÄÇÂêàÂø´ÈÄüÂéüÂûãËÆæËÆ°ÂíåËØÑ‰º∞‰∏çÂêåÊ®°ÂûãÔºåÂÖ∑Êúâ‰ª•‰∏ãÁâπÁÇπÔºöÈÄöËøáÂ∞ëÈáè‰ª£Á†ÅËøûÊé•È°∂Á∫ß LLMÔºõÂìçÂ∫îÂÖÉÊï∞ÊçÆÂåÖÊã¨Â§ÑÁêÜÁöÑToken„ÄÅÊàêÊú¨ÂíåÂª∂ËøüÔºåÂØπÂêÑ‰∏™Ê®°ÂûãËøõË°åÊ†áÂáÜÂåñÔºõÊîØÊåÅÂ§öÊ®°ÂûãÔºöÂêåÊó∂‰ªé‰∏çÂêåÊ®°ÂûãËé∑ÂèñË°•ÂÖ®ÔºõLLM Âü∫ÂáÜÔºöËØÑ‰º∞Ê®°ÂûãÁöÑË¥®Èáè„ÄÅÈÄüÂ∫¶ÂíåÊàêÊú¨githubÁî®Ê∑∑ÂêàÁ≤æÂ∫¶Âä†ÈÄüÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÈÄöËøá‰ΩøÁî®‰ΩéÁ≤æÂ∫¶ÊµÆÁÇπÊï∞ËøêÁÆóÔºåÂèØ‰ª•Â∞ÜËÆ≠ÁªÉÂíåÊé®Êñ≠ÈÄüÂ∫¶ÊèêÂçáÂ§öËææ3ÂÄçÔºåÂêåÊó∂‰∏çÂΩ±ÂìçÊ®°ÂûãÂáÜÁ°ÆÊÄßblogÊñ∞ÁöÑLLMËÆ≠ÁªÉÊñπÊ≥ï FederateÊùúÂÖãÂ§ßÂ≠¶ÂíåÂæÆËΩØ‰∏ÄËµ∑ÂèëÂ∏É‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑLLMËÆ≠ÁªÉÊñπÊ≥ï Federated GPTÔºåËøô‰∏™ËÆ≠ÁªÉÊñπÊ≥ïÊòØÂ∞ÜÂéüÊú¨‰∏≠ÂøÉÂåñÁöÑËÆ≠ÁªÉÊñπÊ≥ïÂàÜÊï£Âà∞‰∏çÂêåÁöÑËæπÁºòËÆæÂ§áÈáåÈù¢Ôºàedge deviceÔºâÔºåÁÑ∂ÂêéËÆ≠ÁªÉÂÆåÊàêÂêéÔºåÂÜç‰∏ä‰º†Âà∞‰∏≠ÂøÉÂéªÂ∞ÜÂêÑÂ≠êÊ®°ÂûãÂêàÂπ∂„ÄÇgithubÊèêÁ§∫Â∑•Á®ãËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•OpenBuprompt-engineering-noteÊèêÁ§∫Â∑•Á®ãÁ¨îËÆ∞(ËØæÁ®ãÊÄªÁªì)„Äã‰ªãÁªç‰∫ÜÈù¢ÂêëÂºÄÂèëËÄÖÁöÑ ChatGPT Prompt Engineering Learning Notes ËØæÁ®ãÔºåËØ•ËØæÁ®ãÊèê‰æõ‰∫ÜËØ≠Ë®ÄÊ®°ÂûãÁöÑÂ∑•‰ΩúÂéüÁêÜÂíåÊèêÁ§∫Â∑•Á®ãÂÆûË∑µÔºåÂπ∂Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞ÜËØ≠Ë®ÄÊ®°Âûã API Â∫îÁî®‰∫éÂêÑÁßç‰ªªÂä°ÁöÑÂ∫îÁî®Á®ãÂ∫è‰∏≠„ÄÇËØæÁ®ãÂåÖÊã¨ÊÄªÁªì„ÄÅÊé®Êñ≠„ÄÅËΩ¨Êç¢„ÄÅÊâ©Â±ïÂíåÊâìÈÄ†ËÅäÂ§©Êú∫Âô®‰∫∫Á≠âÊñπÈù¢ÁöÑÂÜÖÂÆπÔºåÂπ∂ËÆ≤Ëø∞‰∫ÜÂ¶Ç‰ΩïËÆæËÆ°Â•ΩÁöÑÊèêÁ§∫ÂíåÊûÑÂª∫Ëá™ÂÆö‰πâËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇgithub-OpenBupromptÊèêÁ§∫Â∑•Á®ãÊåáÂçólinkAIGCÊèêÁ§∫Â∑•Á®ãÂ≠¶‰π†Á´ô Learn PromptChatGPT/Midjourney/RunwaylinkPrompts Á≤æÈÄâ - ChatGPT ‰ΩøÁî®ÊåáÂçóChatGPT ‰ΩøÁî®ÊåáÂçóÔºåÊèêÂçá ChatGPT ÂèØÁé©ÊÄßÂíåÂèØÁî®ÊÄßgithubÈùûÂÆòÊñπÁöÑChatGPTËµÑÊ∫êËÅöÂêàÂàóË°®ÔºåÊó®Âú®Ê±áÊÄª‰ΩøÁî®ChatGPTÊó®Âú®Ê±áÊÄª‰ΩøÁî®ChatGPTÁöÑÂ∫îÁî®„ÄÅWebÂ∫îÁî®„ÄÅÊµèËßàÂô®Êâ©Â±ï„ÄÅCLIÂ∑•ÂÖ∑„ÄÅÊú∫Âô®‰∫∫„ÄÅÈõÜÊàê„ÄÅËΩØ‰ª∂ÂåÖ„ÄÅÊñáÁ´†Á≠âËµÑÊ∫êgithubSnack PromptÔºöChatGPT PromptÊèêÁ§∫ÂàÜ‰∫´Á§æÂå∫linkChatGPTÊèêÈóÆÊäÄÂ∑ßÂ¶Ç‰ΩïÂêë ChatGPT ÊèêÈóÆ‰ª•Ëé∑ÂæóÈ´òË¥®ÈáèÁ≠îÊ°àÔºöÊèêÁ§∫ÊäÄÂ∑ßÂ∑•Á®ãÂÆåÂÖ®ÊåáÂçógithubrompt-Engineering-Guide-Chinese - ÊèêÁ§∫Â∑•Á®ãÂ∏àÊåáÂçóÊ∫êËá™Ëã±ÊñáÁâàÔºå‰ΩÜÂ¢ûÂä†‰∫ÜAIGCÁöÑpromptÈÉ®ÂàÜgithubOpenPrompt‰∏Ä‰∏™ÂºÄÊîæÁöÑÂÖ±‰∫´PromptÁ§æÂå∫ÔºåÂ§ßÂÆ∂‰∏ÄËµ∑Êé®ËçêÂ•ΩÁî®ÁöÑpromptgithubGPT-PromptsÊïô‰Ω†Â¶Ç‰ΩïÁî®GPTÁîüÊàêPromptsgithubÁ±ªChatGPTÁöÑÊñáÊ°£ÈóÆÁ≠îËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•privateGPTÂü∫‰∫éGPT4All-JÁöÑÁßÅÊúâÂåñÈÉ®ÁΩ≤ÊñáÊ°£ÈóÆÁ≠îÂπ≥Âè∞ÔºåÊó†ÈúÄËÅîÁΩëÔºåËÉΩ100%‰øùËØÅÁî®Êà∑ÁöÑÈöêÁßÅ‰∏çÊ≥ÑÈú≤„ÄÇÊèê‰æõ‰∫Ü‰∏Ä‰∏™APIÔºåÁî®Êà∑ÂèØ‰ª•‰ΩøÁî®Ëá™Â∑±ÁöÑÊñáÊ°£ËøõË°å‰∫§‰∫íÂºèÈóÆÁ≠îÂíåÁîüÊàêÊñáÊú¨„ÄÇÊ≠§Â§ñÔºåÂπ≥Âè∞ÊîØÊåÅËá™ÂÆö‰πâËÆ≠ÁªÉÊï∞ÊçÆÂíåÊ®°ÂûãÂèÇÊï∞Ôºå‰ª•Êª°Ë∂≥‰∏™ÊÄßÂåñÈúÄÊ±Çgithub-privateGPTAuto-evaluatorÊñáÊ°£ÈóÆÁ≠îÁöÑËá™Âä®ËØÑ‰º∞ Ôºõ„ÄÅgithubPDF GP‰∏Ä‰∏™Âü∫‰∫é GPT ÂÆûÁé∞ÁöÑÂºÄÊ∫ê PDF ÊñáÊ°£ËÅäÂ§©ÊñπÊ°à,‰∏ªË¶ÅÂÆûÁé∞‰ª•‰∏ãÂäüËÉΩÔºöË∑ü PDF ÊñáÊ°£ËøõË°å‰∏ÄÂØπ‰∏ÄÂØπËØùÔºõËá™Âä®ÂàáÂâ≤ÂÜÖÂÆπÔºåÂπ∂‰ΩøÁî®Âº∫Â§ßÁöÑÊ∑±Â∫¶Âπ≥ÂùáÁΩëÁªúÁºñÁ†ÅÂô®Êù•ÁîüÊàêÂµåÂÖ•ÔºõÂØπ PDF ÂÜÖÂÆπÊâßË°åËØ≠‰πâÊêúÁ¥¢ÔºåÂπ∂Â∞ÜÊúÄÁõ∏ÂÖ≥ÁöÑÂµåÂÖ•‰º†ÈÄíÁªô Open AIÔºõËá™ÂÆö‰πâÈÄªËæëÔºåÁîüÊàêÊõ¥Á≤æÁ°ÆÁöÑÂìçÂ∫î‰ø°ÊÅØÔºåÈÄüÂ∫¶Ë¶ÅÊØî OpenAI ÁöÑÂø´„ÄÇgithubRedis-LLM-Document-ChatÁî®LlamaIndex„ÄÅRedisÂíåOpenAI‰∏éPDFÊñáÊ°£ËøõË°å‰∫§‰∫íÔºåÂåÖÂê´‰∏Ä‰∏™JupyterÁ¨îËÆ∞Êú¨ÔºåÊºîÁ§∫‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Redis‰Ωú‰∏∫ÂêëÈáèÊï∞ÊçÆÂ∫ìÊù•Â≠òÂÇ®ÂíåÊ£ÄÁ¥¢ÊñáÊ°£ÂêëÈáèÔºåËøòÂ±ïÁ§∫‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®LlamaIndexÂú®ÊñáÊ°£‰∏≠ÊâßË°åËØ≠‰πâÊêúÁ¥¢Ôºå‰ª•ÂèäÂ¶Ç‰ΩïÂà©Áî®OpenAIÊèê‰æõÁ±ª‰ººËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑ‰ΩìÈ™ågithubdoc-chatbotGPT-4 + Pinecone + LangChain + MongoDBÂÆûÁé∞ÁöÑÊñáÊ°£ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂèØÂ§öÊñá‰ª∂„ÄÅÂ§öËØùÈ¢òÂíåÂ§öÁ™óÂè£ËÅäÂ§©ÔºåËÅäÂ§©ÂéÜÂè≤Áî±MongoDB‰øùÂ≠ògithubdocument.aiÂü∫‰∫éÂêëÈáèÊï∞ÊçÆÂ∫ì‰∏éGPT3.5ÁöÑÈÄöÁî®Êú¨Âú∞Áü•ËØÜÂ∫ìÊñπÊ°à(A universal local knowledge base solution based on vector database and GPT3.5)githubDocsGPTDocsGPTÊòØ‰∏ÄÁßçÂ∞ñÁ´ØÁöÑÂºÄÊ∫êËß£ÂÜ≥ÊñπÊ°àÔºåÂèØ‰ª•ÁÆÄÂåñÂú®È°πÁõÆÊñáÊ°£‰∏≠Êü•Êâæ‰ø°ÊÅØÁöÑËøáÁ®ã„ÄÇÈÄöËøáÈõÜÊàêÂº∫Â§ßÁöÑGPTÊ®°ÂûãÔºåÂºÄÂèë‰∫∫ÂëòÂèØ‰ª•ËΩªÊùæÂú∞ÊèêÂá∫ÂÖ≥‰∫éÈ°πÁõÆÁöÑÈóÆÈ¢òÂπ∂Ëé∑ÂæóÂáÜÁ°ÆÁöÑÁ≠îÊ°à„ÄÇgithubChatGPT Retrieval PluginChatGPTÊ£ÄÁ¥¢Êèí‰ª∂Â≠òÂÇ®Â∫ìÊèê‰æõ‰∫Ü‰∏ÄÁßçÁÅµÊ¥ªÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÂèØ‰ª•‰ΩøÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊü•ËØ¢ÂØπ‰∏™‰∫∫ÊàñÁªÑÁªáÊñáÊ°£ËøõË°åËØ≠‰πâÊêúÁ¥¢ÂíåÊ£ÄÁ¥¢„ÄÇgithubLamaIndexlamaIndexÔºàGPTÁ¥¢ÂºïÔºâÊòØÊÇ®ÁöÑLLMÂ∫îÁî®Á®ãÂ∫èÁöÑÊï∞ÊçÆÊ°ÜÊû∂„ÄÇgithubchatWebChatWebÂèØ‰ª•Áà¨Âèñ‰ªªÊÑèÁΩëÈ°µÊàñPDFÔºåDOCXÔºåTXTÊñá‰ª∂Âπ∂ÊèêÂèñÊ≠£ÊñáÔºåÂèØ‰ª•ÁîüÊàêÂµåÂÖ•ÂºèÊ¶ÇË¶ÅÔºåÂèØ‰ª•Ê†πÊçÆÊ≠£ÊñáÂÜÖÂÆπÂõûÁ≠î‰Ω†ÁöÑÈóÆÈ¢ò„ÄÇ Âü∫‰∫égpt3.5ÁöÑchatAPIÂíåembeddingAPIÔºå‰ª•ÂèäÂêëÈáèÊï∞ÊçÆÂ∫ìÂÆûÁé∞„ÄÇgithubÁ±ªChatGPTÁöÑË°å‰∏öÂ∫îÁî®ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Êñ∞ÈóªÊä•ÈÅìËøõË°åÊÉÖÊÑüÂàÜÊûêÁî®ChatGPTÈÄöËøáÂØπ‰∏äÂ∏ÇÂÖ¨Âè∏ÁöÑÊñ∞ÈóªÊä•ÈÅìËøõË°åÊÉÖÊÑüÂàÜÊûêÔºåÂú®15‰∏™ÊúàÊó∂Èó¥ÂÜÖÂú®ËÇ°Á•®Â∏ÇÂú∫(‰∫§ÊòìÊúüÊùÉ)‰∫ßÁîü‰∫Ü500%ÁöÑÂõûÊä•ÔºàÂú®ÂéÜÂè≤Êï∞ÊçÆ‰∏≠ÊµãËØïÂæóÂá∫ÁöÑÁªìÊûúÔºâ‚Äî‚ÄîÊé¢ËÆ®‰∫ÜChatGPTÂú®Âà©Áî®Êñ∞ÈóªÊ†áÈ¢òÁöÑÊÉÖÊÑüÂàÜÊûêÊù•È¢ÑÊµãËÇ°Â∏ÇÂõûÊä•ÊñπÈù¢ÁöÑÊΩúÂäõ„ÄÇÂèëÁé∞ChatGPTÁöÑÊÉÖÊÑüÂàÜÊûêËÉΩÂäõË∂ÖËøá‰∫Ü‰º†ÁªüÁöÑÊñπÊ≥ïÔºåÂπ∂‰∏î‰∏éËÇ°Â∏ÇÂõûÊä•ÂëàÊ≠£Áõ∏ÂÖ≥„ÄÇÊèêÂá∫ChatGPTÂú®ÈáëËûçÁªèÊµéÈ¢ÜÂüüÊúâÂæàÂ§ßÁöÑ‰ª∑ÂÄºÔºåÂπ∂ÂØπÊú™Êù•ÁöÑÁ†îÁ©∂ÂíåÂ∫îÁî®ÊèêÂá∫‰∫Ü‰∏Ä‰∫õÂêØÁ§∫ÂíåÂª∫ËÆÆpaperÁºñÁ®ãËØ≠Ë®ÄÁîüÊàêÊ®°Âûã StarCoderBigCodeÊòØ ServiceNow Inc. Âíå Hugging Face Inc. Âêà‰ΩúÊàêÁ´ãÁöÑ„ÄÇStarCoder ÊúâÂ§ö‰∏™ÁâàÊú¨„ÄÇÊ†∏ÂøÉÁâàÊú¨ StarCoderBase ÂÖ∑Êúâ 155 ‰∫ø‰∏™ÂèÇÊï∞ÔºåÊîØÊåÅ80Â§öÁßçÁºñÁ®ãËØ≠Ë®ÄÔºå8192‰∏™tokenÁöÑ‰∏ä‰∏ãÊñá„ÄÇËßÜÈ¢ë‰∏∫ÂÖ∂vscodeÊèí‰ª∂ÊïàÊûúgithubCodeGen2: Lessons for Training LLMs on Programming and Natural Languagescode generationpaperMedicalGPT-zhÔºö‰∏≠ÊñáÂåªÁñóÈÄöÁî®ËØ≠Ë®ÄÊ®°Âûã‰∏≠ÊñáÂåªÁñóÈÄöÁî®ËØ≠Ë®ÄÊ®°ÂûãÔºåÂü∫‰∫é28‰∏™ÁßëÂÆ§ÁöÑÂåªÁñóÂÖ±ËØÜ‰∏é‰∏¥Â∫äÊåáÂçóÊñáÊú¨ÔºåÊèêÈ´òÊ®°ÂûãÁöÑÂåªÁñóÈ¢ÜÂüüÁü•ËØÜ‰∏éÂØπËØùËÉΩÂäõgithubMagicSlides‰∏çÂ∞ë‰∫∫Ê¢¶ÂØê‰ª•Ê±ÇÁöÑAIËá™‰ΩúPPTÔºåÂÖçË¥πÁâàÊØèÊúàËÉΩÂÅö3‰∏™PPTÔºåÊîØÊåÅ2500Â≠óËæìÂÖ•linkSalesGPT‰ΩøÁî®LLMÂÆûÁé∞‰∏ä‰∏ãÊñáÊÑüÁü•ÁöÑÈîÄÂîÆÂä©ÊâãÔºåÂèØËá™Âä®ÂåñÈîÄÂîÆÊãìÂ±ï‰ª£Ë°®ÁöÑÊ¥ªÂä®ÔºåÂ¶ÇÂ§ñÂëºÈîÄÂîÆÁîµËØùgithubÂçéÈ©º(HuaTuo): Âü∫‰∫é‰∏≠ÊñáÂåªÂ≠¶Áü•ËØÜÁöÑLLaMAÂæÆË∞ÉÊ®°Âûãgithubai-code-translatorÂ∏ÆÂä©‰Ω†Êää‰ª£Á†Å‰ªé‰∏ÄÁßçËØ≠Ë®ÄÁøªËØëÊàêÂè¶‰∏ÄÁßçËØ≠Ë®ÄÔºåËøô‰∫ãÂØπChatGPTÊù•ËØ¥ÁÆÄÁõ¥Â§™ÊìÖÈïø‰∫ÜÔºåÂ∞§ÂÖ∂ÊòØGPT-4ÔºåÁøªËØëË¥®ÈáèÁõ∏ÂΩìÈ´òÔºåËÄå‰∏îtokensÈïøÂ∫¶‰πüÂèØ‰ª•Êõ¥Èïø„ÄÇgithubChatGenTitle‰ΩøÁî®Áôæ‰∏áarXivËÆ∫Êñá‰ø°ÊÅØÂú®LLaMAÊ®°Âûã‰∏äËøõË°åÂæÆË∞ÉÁöÑËÆ∫ÊñáÈ¢òÁõÆÁîüÊàêÊ®°ÂûãgithubRegex.ai‰∏ÄÊ¨æÊâÄËßÅÂç≥ÊâÄÂæóÁöÑÔºåÂü∫‰∫é AI ÁöÑÊ≠£ÂàôË°®ËææÂºèËá™Âä®ÁîüÊàêÂ∑•ÂÖ∑ÔºåÂè™ÈúÄË¶ÅÈÄâÊã©Âá∫Êï∞ÊçÆÔºåÂÆÉÂ∞±ËÉΩÂ∏Æ‰Ω†ÂÜôÊ≠£ÂàôË°®ËææÂºèÔºåÂπ∂Êèê‰æõÂ§öÁßçÊèêÂèñÊï∞ÊçÆÁöÑÊñπÂºèvideoChatDoctor‰∏Ä‰∏™Âü∫‰∫éÂåªÂ≠¶È¢ÜÂüüÁü•ËØÜÂæÆË∞ÉLLaMAÁöÑÂåªÂ≠¶ËÅäÂ§©Ê®°ÂûãÔºåÂÖ∂‰∏≠ÂåªÂ≠¶Êï∞ÊçÆÂåÖÂê´Â§ßÁ∫¶700ÁßçÁñæÁóÖÁöÑÊï∞ÊçÆ„ÄÅ‰ª•ÂèäÂ§ßÁ∫¶5000ÊÆµÂåªÁîüÂíåÁóÖ‰∫∫ÁöÑÂØπËØùËÆ∞ÂΩïpaperCodeGPTÊèêÈ´òÁºñÁ®ãËÉΩÂäõÁöÑÂÖ≥ÈîÆÂú®‰∫éÊï∞ÊçÆ„ÄÇCodeGPTÊòØÈÄöËøáGPTÁîüÊàêÁöÑÁî®‰∫éGPTÁöÑ‰ª£Á†ÅÂØπËØùÊï∞ÊçÆÈõÜ„ÄÇÁé∞Âú®ÂÖ¨ÂºÄ‰∫Ü32KÊù°‰∏≠ÊñáÊï∞ÊçÆÔºåËÆ©Ê®°ÂûãÊõ¥ÊìÖÈïøÁºñÁ®ãgithubLaWGPT‰∏ÄÁ≥ªÂàóÂü∫‰∫é‰∏≠ÊñáÊ≥ïÂæãÁü•ËØÜÁöÑÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°ÂûãgithubLangChain-ChatGLM-WebuiÂèólangchain-ChatGLMÂêØÂèë, Âà©Áî®LangChainÂíåChatGLM-6BÁ≥ªÂàóÊ®°ÂûãÂà∂‰ΩúÁöÑWebui, Êèê‰æõÂü∫‰∫éÊú¨Âú∞Áü•ËØÜÁöÑÂ§ßÊ®°ÂûãÂ∫îÁî®.ÁõÆÂâçÊîØÊåÅ‰∏ä‰º† txt„ÄÅdocx„ÄÅmd„ÄÅpdfÁ≠âÊñáÊú¨Ê†ºÂºèÊñá‰ª∂, Êèê‰æõÂåÖÊã¨ChatGLM-6BÁ≥ªÂàó„ÄÅBelleÁ≥ªÂàóÁ≠âÊ®°ÂûãÊñá‰ª∂‰ª•ÂèäGanymedeNil/text2vec-large-chinese„ÄÅnghuyong/ernie-3.0-base-zh„ÄÅnghuyong/ernie-3.0-nano-zhÁ≠âEmbeddingÊ®°Âûã.githubÁ±ªChatGPTÁöÑËØæÁ®ãËµÑÊñôËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•DatabricksÔºàDollyÊ®°ÂûãÁöÑ‰ΩúËÄÖÔºâÂú®edXÂèëÂ∏É‰∫Ü‰∏§‰∏™ÂÖçË¥πËØæÁ®ãÁ®ãÔºåÂÖ∂‰∏≠Á¨¨‰∫å‰∏™ÊòØÂÖ≥‰∫éLLMÊòØÂ¶Ç‰ΩïÊûÑÂª∫ÁöÑ„ÄÇlinkÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊäÄÊúØÂàÜ‰∫´Á≥ªÂàó‰∏úÂåóÂ§ßÂ≠¶Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂÆûÈ™åÂÆ§videoGPT-4ÊòØÂ¶Ç‰ΩïÂ∑•‰ΩúÁöÑÔºüÂ¶Ç‰ΩïÂà©Áî®GPT-4ÊâìÈÄ†Êô∫ËÉΩÁ®ãÂ∫èÔºüÂìà‰ΩõÂ§ßÂ≠¶CS50ÂÖ¨ÂºÄËØævideoÊèêÁ§∫Â∑•Á®ãÊúÄ‰Ω≥ÂÆûË∑µÔºöAndrew Ng ÊèêÁ§∫Â∑•Á®ãÊñ∞ËØæÊëòË¶Å+LangChainÁªèÈ™åÊÄªÁªìmedium_blogÂæÆË∞ÉLLMÊ®°ÂûãÂ¶ÇÊûú‰Ω†ÂØπÂæÆË∞ÉLLMÊ®°ÂûãÊÑüÂÖ¥Ë∂£Ôºå‰∏ÄÂÆöË¶ÅÂÖ≥Ê≥®Ëøô‰∏™Ê≤πÁÆ°Âçö‰∏ªÔºå‰ªñÊääÂá†‰πé‰∏ñÈù¢‰∏äÊâÄÊúâÁöÑLLMÊ®°ÂûãÈÉΩÂÖ¨ÂºÄ‰∫ÜÂæÆË∞ÉÁöÑÊñπÊ≥ï„ÄÇÊ≤πÁÆ°Âçö‰∏ª Sam WitteveenTransformerÁöÑÊû∂ÊûÑËß£ËØªÈÄö‰øóÊòìÊáÇÁöÑ‰ªãÁªçyoutube1youtube2 youtube3Transformer multi headÊú∫Âà∂ÁöÑËßÜÈ¢ëÂ¶ÇÊûúÊÉ≥Ë¶ÅÁúüÊ≠£ÁêÜËß£Êï¥‰∏™TransformÁöÑÊØè‰∏Ä‰∏™ÁªÜËäÇÔºåÂåÖÊã¨ÈáåÈù¢ÁöÑÊï∞Â≠¶ÂéüÁêÜÔºåÂèØ‰ª•Áúã‰∏Ä‰∏ãËøô‰∏™ËßÜÈ¢ëÔºåÁúüÁöÑÊòØÂâñÊûêÂú∞ÈùûÂ∏∏ËØ¶ÁªÜyoutubeIntroduction to Large Language ModelsÂ§ßËØ≠Ë®ÄÊ®°Âûã‰ªãÁªç‰ªãÁªç‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLarge Language ModelsÔºåLLMsÔºâÁöÑÊ¶ÇÂøµ„ÄÅ‰ΩøÁî®Âú∫ÊôØ„ÄÅÊèêÁ§∫Ë∞ÉÊï¥‰ª•ÂèäGoogleÁöÑGen AIÂºÄÂèëÂ∑•ÂÖ∑„ÄÇLLMÁöÑÂÆâÂÖ®ÈóÆÈ¢òËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•LLMÊ®°ÂûãÂÆâÂÖ®Á†îÁ©∂linkChatbot Injections & ExploitÊî∂ÈõÜ‰∫Ü‰∏Ä‰∫õChatbotÊ≥®ÂÖ•ÂíåÊºèÊ¥ûÁöÑ‰æãÂ≠êÔºå‰ª•Â∏ÆÂä©‰∫∫‰ª¨‰∫ÜËß£ChatbotÁöÑÊΩúÂú®ÊºèÊ¥ûÂíåËÑÜÂº±ÊÄß„ÄÇÊ≥®ÂÖ•ÂíåÊîªÂáªÁöÑÊñπÂºèÂåÖÊã¨ÂëΩ‰ª§Ê≥®ÂÖ•„ÄÅÂ≠óÁ¨¶ÁºñÁ†Å„ÄÅÁ§æ‰∫§Â∑•Á®ã„ÄÅË°®ÊÉÖÁ¨¶Âè∑„ÄÅUnicodeÁ≠â„ÄÇ‰ªìÂ∫ìÊèê‰æõ‰∫Ü‰∏Ä‰∫õÁ§∫‰æãÔºåÂÖ∂‰∏≠‰∏Ä‰∫õÂåÖÊã¨ÂèØÁî®‰∫éÊîªÂáªChatbotÁöÑË°®ÊÉÖÁ¨¶Âè∑ÂàóË°®githubGPTSecurity‰∏Ä‰∏™Ê∂µÁõñ‰∫ÜÂâçÊ≤øÂ≠¶ÊúØÁ†îÁ©∂ÂíåÂÆûË∑µÁªèÈ™åÂàÜ‰∫´ÁöÑÁ§æÂå∫ÔºåÈõÜÊàê‰∫ÜÁîüÊàêÈ¢ÑËÆ≠ÁªÉ TransformerÔºàGPTÔºâ„ÄÅ‰∫∫Â∑•Êô∫ËÉΩÁîüÊàêÂÜÖÂÆπÔºàAIGCÔºâ‰ª•ÂèäÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁ≠âÂÆâÂÖ®È¢ÜÂüüÂ∫îÁî®ÁöÑÁü•ËØÜ„ÄÇÂú®ËøôÈáåÔºåÊÇ®ÂèØ‰ª•ÊâæÂà∞ÂÖ≥‰∫éGPT/AIGC/LLMÊúÄÊñ∞ÁöÑÁ†îÁ©∂ËÆ∫Êñá„ÄÅÂçöÂÆ¢ÊñáÁ´†„ÄÅÂÆûÁî®ÁöÑÂ∑•ÂÖ∑ÂíåÈ¢ÑËÆæÊåá‰ª§ÔºàPromptsÔºâ„ÄÇgithubÂ§öÊ®°ÊÄÅLLMËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•DeepFloyd IFÈ´òÂ∫¶ÈÄºÁúü‰∏îÂÖ∑ÊúâËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõÁöÑÊúÄÊñ∞ÂºÄÊ∫êÊñáÊú¨Âà∞ÂõæÂÉèÊ®°ÂûãÔºåÁî±‰∏Ä‰∏™ÂÜªÁªìÊñáÊú¨ÁºñÁ†ÅÂô®Âíå‰∏â‰∏™ËøûÁª≠ÁöÑÂÉèÁ¥†Êâ©Êï£Ê®°ÂùóÁªÑÊàêÔºåÊòØ‰∏Ä‰∏™È´òÊïàÁöÑÊ®°ÂûãÔºåÊÄßË∂ÖË∂ä‰∫ÜÂΩìÂâçÊúÄÂÖàËøõÁöÑÊ®°ÂûãÔºåÂú®COCOÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÈõ∂Ê†∑Êú¨ÁöÑFIDÂæóÂàÜ‰∏∫6.66githubMulti-modal GPTÁî®Â§öÊ®°ÊÄÅGPTËÆ≠ÁªÉ‰∏Ä‰∏™ËÉΩÂêåÊó∂Êé•Êî∂ËßÜËßâÂíåËØ≠Ë®ÄÊåá‰ª§ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇÂü∫‰∫éOpenFlamingoÂ§öÊ®°ÊÄÅÊ®°ÂûãÔºå‰ΩøÁî®ÂêÑÁßçÂºÄÊîæÊï∞ÊçÆÈõÜÂàõÂª∫ÂêÑÁßçËßÜËßâÊåáÂØºÊï∞ÊçÆÔºåËÅîÂêàËÆ≠ÁªÉËßÜËßâÂíåËØ≠Ë®ÄÊåáÂØºÔºåÊúâÊïàÊèêÈ´òÊ®°ÂûãÊÄßËÉΩgithubAudioGPTUnderstanding and Generating Speech, Music, Sound, and Talking Head' by AIGC-Audiogithubtext2image-prompt-generatorÂü∫‰∫éGPT-2Áî®25‰∏áÊù°MidjourneyÁöÑprompsËÆ≠ÁªÉÂá∫Êù•ÁöÑÂ∞èÊ®°ÂûãÔºåÂèØ‰ª•ÁîüÊàêÈ´òË¥®ÈáèÁöÑMidjourney  promptlink dataÊ±áÊÄª6‰∏™Midjourney‰ª•Â§ñÁöÑÂÖçË¥π‰ª•ÊñáÁîüÂõæÊúçÂä°ÔºöBing Image Creator Playground AI DreamStudio Pixlr Leonardo AI CraiyonBARK‰∏Ä‰∏™ÈùûÂ∏∏Âº∫Â§ßÁöÑTTSÔºàÊñáÂ≠óËΩ¨ËØ≠Èü≥ÔºâÈ°πÁõÆÔºåËøô‰∏™È°πÁõÆÁöÑÁâπÁÇπÊòØÔºåÂÆÉÂèØ‰ª•Âú®ÊñáÂ≠ó‰∏≠Âä†ÂÖ•ÊèêÁ§∫ËØçÔºåÊØîÂ¶Ç‚ÄúÂ§ßÁ¨ë‚Äù„ÄÇËøô‰∏™ÊèêÁ§∫ËØç‰ºöÂèòÊàêÁ¨ëÁöÑÂ£∞Èü≥ÔºåÁÑ∂ÂêéÂêàÊàêÂà∞ËØ≠Èü≥ÈáåÂéª„ÄÇÂÆÉ‰πüÂèØ‰ª•Ê∑∑Âêà‚ÄúÁî∑Â£∞‚ÄùÔºå‚ÄúÂ•≥Â£∞‚ÄùÔºåËøôÊ†∑ÂÜçÂÅöÂ∞±ÂèØ‰ª•‰∏çÁî®ÂÜçÂÅöÊãºÊé•Êìç‰Ωú‰∫ÜgithubwhisperÂú®ËØ≠Èü≥ËΩ¨ÊñáÂ≠óÔºàSTTÔºå‰πüÁß∞ASRÔºâÊñπÈù¢ÔºåwhisperÊòØÊàëÁî®ËøáÁöÑÊúÄÂ•ΩÁöÑÔºåÊúÄÂø´ÁöÑÂ∫ì„ÄÇÊ≤°ÊÉ≥Âà∞ÔºåËøô‰πàÂø´ÁöÑÊ®°ÂûãÔºåËøòËÉΩ70xÁöÑ‰ºòÂåñÁ©∫Èó¥„ÄÇÊàëÂáÜÂ§áÈÉ®ÁΩ≤Ëøô‰∏™Ê®°ÂûãÔºåÂπ∂ÂºÄÊîæÁªôÂ§ßÂÆ∂‰ΩøÁî®ÔºåÂèØ‰ª•Áî®Êù•ËΩ¨ÂΩïÂ§ßÁöÑËØ≠Èü≥Êñá‰ª∂ÔºåÂíåËøõË°åÁøªËØë„ÄÇËøô‰∏™Ê®°ÂûãÊòØÂ§öËØ≠Ë®ÄÁöÑÔºåËÄå‰∏îËÉΩËá™Âä®ËØÜÂà´ÊòØ‰ªÄ‰πàËØ≠Ë®ÄÔºåÁúüÁöÑÈùûÂ∏∏Âº∫Â§ßgithubOFA-ChineseÔºö‰∏≠ÊñáÂ§öÊ®°ÊÄÅÁªü‰∏ÄÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãtransformersÁªìÊûÑÁöÑ‰∏≠ÊñáOFAÊ®°ÂûãgithubÊñáÁîüÂõæÂºÄÊ∫êÊ®°ÂûãËØïÁÇºÂú∫ÂèØÊ†πÊçÆËæìÂÖ•ÊñáÂ≠óÂêåÊó∂Áî®stable-diffusion 1.5„ÄÅstable-diffusion 2.1„ÄÅDALL-E„ÄÅkandinsky-2Á≠âÊ®°ÂûãÁîüÊàêÂõæÂÉèÔºåÊñπ‰æøÊµãËØïÊØîËæÉlinkLLMScoreLLMScoreÊòØ‰∏ÄÁßçÂÖ®Êñ∞ÁöÑÊ°ÜÊû∂ÔºåËÉΩÂ§üÊèê‰æõÂÖ∑ÊúâÂ§öÁ≤íÂ∫¶ÁªÑÂêàÊÄßÁöÑËØÑ‰º∞ÂàÜÊï∞„ÄÇÂÆÉ‰ΩøÁî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊù•ËØÑ‰º∞ÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÊ®°Âûã„ÄÇÈ¶ñÂÖàÔºåÂ∞ÜÂõæÂÉèËΩ¨Âåñ‰∏∫ÂõæÂÉèÁ∫ßÂà´ÂíåÂØπË±°Á∫ßÂà´ÁöÑËßÜËßâÊèèËø∞ÔºåÁÑ∂ÂêéÂ∞ÜËØÑ‰º∞Êåá‰ª§ËæìÂÖ•Âà∞LLM‰∏≠Ôºå‰ª•Ë°°ÈáèÂêàÊàêÂõæÂÉè‰∏éÊñáÊú¨ÁöÑÂØπÈΩêÁ®ãÂ∫¶ÔºåÂπ∂ÊúÄÁªàÁîüÊàê‰∏Ä‰∏™ËØÑÂàÜÂíåËß£Èáä„ÄÇÊàë‰ª¨ÁöÑÂ§ßÈáèÂàÜÊûêÊòæÁ§∫ÔºåLLMScoreÂú®‰ºóÂ§öÊï∞ÊçÆÈõÜ‰∏ä‰∏é‰∫∫Á±ªÂà§Êñ≠ÁöÑÁõ∏ÂÖ≥ÊÄßÊúÄÈ´òÔºåÊòéÊòæ‰ºò‰∫éÂ∏∏Áî®ÁöÑÊñáÊú¨-ÂõæÂÉèÂåπÈÖçÂ∫¶ÈáèÊåáÊ†áCLIPÂíåBLIP„ÄÇpapergithubVisualGLM-6BVisualGLM-6B ÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÔºåÊîØÊåÅÂõæÂÉè„ÄÅ‰∏≠ÊñáÂíåËã±ÊñáÁöÑÂ§öÊ®°ÊÄÅÂØπËØùËØ≠Ë®ÄÊ®°ÂûãÔºåËØ≠Ë®ÄÊ®°ÂûãÂü∫‰∫é ChatGLM-6BÔºåÂÖ∑Êúâ 62 ‰∫øÂèÇÊï∞ÔºõÂõæÂÉèÈÉ®ÂàÜÈÄöËøáËÆ≠ÁªÉ BLIP2-Qformer ÊûÑÂª∫Ëµ∑ËßÜËßâÊ®°Âûã‰∏éËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ°•Ê¢ÅÔºåÊï¥‰ΩìÊ®°ÂûãÂÖ±78‰∫øÂèÇÊï∞„ÄÇgithubLLMÁöÑÊï∞ÊçÆÈõÜËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Ê≠ß‰πâÊï∞ÊçÆÈõÜËÉΩÂê¶Ê≠£Á°ÆÁöÑÊ∂àÈô§Ê≠ß‰πâÊòØË°°ÈáèÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∏Ä‰∏™ÈáçË¶ÅÊåáÊ†á„ÄÇ‰∏çËøá‰∏ÄÁõ¥Ê≤°Êúâ‰∏Ä‰∏™Ê†áÂáÜÂåñÁöÑË°°ÈáèÊñπÊ≥ïÔºåËøôÁØáËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂåÖÂê´1,645‰∏™ÂÖ∑Êúâ‰∏çÂêåÁßçÁ±ªÊ≠ß‰πâÁöÑÊï∞ÊçÆÈõÜÂèäÂØπÂ∫îÁöÑËØÑ‰º∞ÊñπÊ≥ï„ÄÇgithub paperthuÊåá‰ª§ËÆ≠ÁªÉÊï∞ÊçÆËÆæËÆ°‰∫Ü‰∏ÄÂ•óÊµÅÁ®ãÊù•Ëá™Âä®‰∫ßÁîüÂ§öÊ†∑ÂåñÈ´òË¥®ÈáèÁöÑÂ§öËΩÆÊåá‰ª§ÂØπËØùÊï∞ÊçÆUltraChatÔºåÂπ∂ËøõË°å‰∫ÜÁªÜËá¥ÁöÑ‰∫∫Â∑•ÂêéÂ§ÑÁêÜ„ÄÇÁé∞Â∑≤Â∞ÜËã±ÊñáÊï∞ÊçÆÂÖ®ÈÉ®ÂºÄÊ∫êÔºåÂÖ±ËÆ°150‰Ωô‰∏áÊù°ÔºåÊòØÂºÄÊ∫êÁ§æÂå∫Êï∞ÈáèÊúÄÂ§öÁöÑÈ´òË¥®ÈáèÊåá‰ª§Êï∞ÊçÆ‰πã‰∏ÄgithubÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜMMC45.8‰∫øÂõæÁâáÔºå1‰∫øÊñáÊ°£Ôºå400‰∫øtokengithubEleutherAI Êï∞ÊçÆ800gÁöÑÊñáÊú¨ËØ≠ÊñôÁªô‰Ω†Êï¥ÂêàÂ•Ω‰∫ÜÂÖçË¥π‰∏ãËΩΩÔºå‰∏çÁü•ÈÅìtrianÂá∫Êù•ÁöÑmodelË¥®ÈáèÂ¶Ç‰ΩïÔºåÊâìÁÆóËØïËØïÔºöpile data paperUltraChatÂ§ßËßÑÊ®°„ÄÅ‰ø°ÊÅØ‰∏∞ÂØå„ÄÅÂ§öÊ†∑ÂåñÁöÑÂ§öËΩÆÂØπËØùÊï∞ÊçÆgithubConvFinQAÈáëËûçÊï∞ÊçÆÈóÆÁ≠îgithubThe botbots dataset‰∏Ä‰∏™ÂåÖÂê´ÂØπËØùÂÜÖÂÆπÁöÑÊï∞ÊçÆÈõÜÔºåÂØπËØùÂÜÖÂÆπÊù•Ëá™‰∫é‰∏§‰∏™ChatGPTÂÆû‰æã(gpt-3.5-turbo)ÔºåCLTÂëΩ‰ª§ÂíåÂØπËØùÊèêÁ§∫Êù•Ëá™GPT-4ÔºåË¶ÜÁõñÂ§öÁßçÊÉÖÂ¢ÉÂíå‰ªªÂä°ÔºåÁîüÊàêÊàêÊú¨Á∫¶‰∏∫35ÁæéÂÖÉÔºåÂèØÁî®‰∫éÁ†îÁ©∂ÂíåËÆ≠ÁªÉÊõ¥Â∞èÁöÑÂØπËØùÊ®°Âûã(Â¶ÇAlpaca)githubalpaca_chinese_dataset - ‰∫∫Â∑•Á≤æË∞ÉÁöÑ‰∏≠ÊñáÂØπËØùÊï∞ÊçÆÈõÜgithubCodeGPT-dataÊèêÈ´òÁºñÁ®ãËÉΩÂäõÁöÑÂÖ≥ÈîÆÂú®‰∫éÊï∞ÊçÆ„ÄÇCodeGPTÊòØÈÄöËøáGPTÁîüÊàêÁöÑÁî®‰∫éGPTÁöÑ‰ª£Á†ÅÂØπËØùÊï∞ÊçÆÈõÜ„ÄÇÁé∞Âú®ÂÖ¨ÂºÄ‰∫Ü32KÊù°‰∏≠ÊñáÊï∞ÊçÆÔºåËÆ©Ê®°ÂûãÊõ¥ÊìÖÈïøÁºñÁ®ãgithubËØ≠ÊñôÂ∫ìËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•‰∫∫ÂêçËØ≠ÊñôÂ∫ìwainshine/Chinese-Names-CorpusChinese-Word-VectorsÂêÑÁßç‰∏≠ÊñáËØçÂêëÈáègithub repo‰∏≠ÊñáËÅäÂ§©ËØ≠ÊñôËØ•Â∫ìÊêúÈõÜ‰∫ÜÂåÖÂê´Ë±ÜÁì£Â§öËΩÆ, PTTÂÖ´Âç¶ËØ≠Êñô, Èùí‰∫ëËØ≠Êñô, ÁîµËßÜÂâßÂØπÁôΩËØ≠Êñô, Ë¥¥ÂêßËÆ∫ÂùõÂõûÂ∏ñËØ≠Êñô,ÂæÆÂçöËØ≠Êñô,Â∞èÈªÑÈ∏°ËØ≠Êñôlink‰∏≠ÊñáË∞£Ë®ÄÊï∞ÊçÆËØ•Êï∞ÊçÆÊñá‰ª∂‰∏≠ÔºåÊØè‰∏ÄË°å‰∏∫‰∏ÄÊù°jsonÊ†ºÂºèÁöÑË∞£Ë®ÄÊï∞ÊçÆgithub‰∏≠ÊñáÈóÆÁ≠îÊï∞ÊçÆÈõÜÈìæÊé• ÊèêÂèñÁ†Å 2dvaÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ËØ≠Êñô3GËØ≠ÊñôÔºåÂåÖÂê´ÈÉ®ÂàÜÁΩëÁªúÊäìÂèñÁöÑÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÁöÑÊñáÁ´†ÔºåÂ∑≤ÁªèÂéªÈô§HTMLÔºåÂè™ÂåÖÂê´‰∫ÜÁ∫ØÊñáÊú¨„ÄÇÊØèË°å‰∏ÄÁØáÔºåÊòØJSONÊ†ºÂºèÔºånameÊòØÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÂêçÂ≠óÔºåaccountÊòØÂæÆ‰ø°ÂÖ¨‰ºóÂè∑IDÔºåtitleÊòØÈ¢òÁõÆÔºåcontentÊòØÊ≠£Êñágithub‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ ËØ≠Êñô„ÄÅÊï∞ÊçÆÈõÜgithub‰ªªÂä°ÂûãÂØπËØùËã±ÊñáÊï∞ÊçÆÈõÜ„ÄêÊúÄÂÖ®‰ªªÂä°ÂûãÂØπËØùÊï∞ÊçÆÈõÜ„Äë‰∏ªË¶Å‰ªãÁªç‰∫Ü‰∏Ä‰ªΩ‰ªªÂä°ÂûãÂØπËØùÊï∞ÊçÆÈõÜÂ§ßÂÖ®ÔºåËøô‰ªΩÊï∞ÊçÆÈõÜÂ§ßÂÖ®Ê∂µÁõñ‰∫ÜÂà∞ÁõÆÂâçÂú®‰ªªÂä°ÂûãÂØπËØùÈ¢ÜÂüüÁöÑÊâÄÊúâÂ∏∏Áî®Êï∞ÊçÆÈõÜÁöÑ‰∏ªË¶Å‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºå‰∏∫‰∫ÜÂ∏ÆÂä©Á†îÁ©∂ËÄÖÊõ¥Â•ΩÁöÑÊääÊè°È¢ÜÂüüËøõÂ±ïÁöÑËÑâÁªúÔºåÊàë‰ª¨‰ª•LeaderboardÁöÑÂΩ¢ÂºèÁªôÂá∫‰∫ÜÂá†‰∏™Êï∞ÊçÆÈõÜ‰∏äÁöÑState-of-the-artÂÆûÈ™åÁªìÊûú„ÄÇgithubËØ≠Èü≥ËØÜÂà´ËØ≠ÊñôÁîüÊàêÂ∑•ÂÖ∑‰ªéÂÖ∑ÊúâÈü≥È¢ë/Â≠óÂπïÁöÑÂú®Á∫øËßÜÈ¢ëÂàõÂª∫Ëá™Âä®ËØ≠Èü≥ËØÜÂà´(ASR)ËØ≠ÊñôÂ∫ìgithubLitBankNLPÊï∞ÊçÆÈõÜÊîØÊåÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåËÆ°ÁÆó‰∫∫ÊñáÂ≠¶Áßë‰ªªÂä°ÁöÑ100ÈÉ®Â∏¶Ê†áËÆ∞Ëã±ÊñáÂ∞èËØ¥ËØ≠Êñôgithub‰∏≠ÊñáULMFiTÊÉÖÊÑüÂàÜÊûê ÊñáÊú¨ÂàÜÁ±ª ËØ≠ÊñôÂèäÊ®°ÂûãgithubÁúÅÂ∏ÇÂå∫ÈïáË°åÊîøÂå∫ÂàíÊï∞ÊçÆÂ∏¶ÊãºÈü≥Ê†áÊ≥®githubÊïôËÇ≤Ë°å‰∏öÊñ∞Èóª Ëá™Âä®ÊñáÊëò ËØ≠ÊñôÂ∫ìgithub‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊï∞ÊçÆÈõÜgithubÁª¥Âü∫Â§ßËßÑÊ®°Âπ≥Ë°åÊñáÊú¨ËØ≠Êñô85ÁßçËØ≠Ë®Ä„ÄÅ1620ÁßçËØ≠Ë®ÄÂØπ„ÄÅ135MÂØπÁÖßÂè•githubÂè§ËØóËØçÂ∫ìgithub repo Êõ¥ÂÖ®ÁöÑÂè§ËØóËØçÂ∫ì‰ΩéÂÜÖÂ≠òÂä†ËΩΩÁª¥Âü∫ÁôæÁßëÊï∞ÊçÆÁî®Êñ∞ÁâànlpÂ∫ìÂä†ËΩΩ17GB+Ëã±ÊñáÁª¥Âü∫ËØ≠ÊñôÂè™Âç†Áî®9MBÂÜÖÂ≠òÈÅçÂéÜÈÄüÂ∫¶2-3 Gbit/sgithubÂØπËÅîÊï∞ÊçÆ700,000 couplets, Ë∂ÖËøá70‰∏áÂØπÂØπËÅîgithub„ÄäÈÖçËâ≤ËæûÂÖ∏„ÄãÊï∞ÊçÆÈõÜgithub42GBÁöÑJDÂÆ¢ÊúçÂØπËØùÊï∞ÊçÆ(CSDD)github70‰∏áÂØπËÅîÊï∞ÊçÆlinkÁî®Êà∑ÂêçÈªëÂêçÂçïÂàóË°®github‰æùÂ≠òÂè•Ê≥ïÂàÜÊûêËØ≠Êñô4‰∏áÂè•È´òË¥®ÈáèÊ†áÊ≥®Êï∞ÊçÆHomepage‰∫∫Ê∞ëÊó•Êä•ËØ≠ÊñôÂ§ÑÁêÜÂ∑•ÂÖ∑ÈõÜgithubËôöÂÅáÊñ∞ÈóªÊï∞ÊçÆÈõÜ fake news corpusgithubËØóÊ≠åË¥®ÈáèËØÑ‰ª∑/ÁªÜÁ≤íÂ∫¶ÊÉÖÊÑüËØóÊ≠åËØ≠ÊñôÂ∫ìgithub‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁõ∏ÂÖ≥ÁöÑÂºÄÊîæ‰ªªÂä°Êï∞ÊçÆÈõÜ‰ª•ÂèäÂΩìÂâçÊúÄ‰Ω≥ÁªìÊûúgithub‰∏≠ÊñáÁº©ÂÜôÊï∞ÊçÆÈõÜgithub‰∏≠Êñá‰ªªÂä°Âü∫ÂáÜÊµãËØÑ‰ª£Ë°®ÊÄßÁöÑÊï∞ÊçÆÈõÜ-Âü∫ÂáÜ(È¢ÑËÆ≠ÁªÉ)Ê®°Âûã-ËØ≠ÊñôÂ∫ì-baseline-Â∑•ÂÖ∑ÂåÖ-ÊéíË°åÊ¶úgithub‰∏≠ÊñáË∞£Ë®ÄÊï∞ÊçÆÂ∫ìgithubCLUEDatasetSearch‰∏≠Ëã±ÊñáNLPÊï∞ÊçÆÈõÜÊêúÁ¥¢ÊâÄÊúâ‰∏≠ÊñáNLPÊï∞ÊçÆÈõÜÔºåÈôÑÂ∏∏Áî®Ëã±ÊñáNLPÊï∞ÊçÆÈõÜgithubÂ§öÊñáÊ°£ÊëòË¶ÅÊï∞ÊçÆÈõÜgithubËÆ©‰∫∫‰∫∫ÈÉΩÂèòÂæó‚ÄúÂΩ¨ÂΩ¨ÊúâÁ§º‚ÄùÁ§ºË≤åËøÅÁßª‰ªªÂä°Âú®‰øùÁïôÊÑè‰πâÁöÑÂêåÊó∂Â∞ÜÈùûÁ§ºË≤åËØ≠Âè•ËΩ¨Êç¢‰∏∫Á§ºË≤åËØ≠Âè•ÔºåÊèê‰æõÂåÖÂê´139M + ÂÆû‰æãÁöÑÊï∞ÊçÆÈõÜpaper and codeÁ≤§ËØ≠/Ëã±ËØ≠‰ºöËØùÂèåËØ≠ËØ≠ÊñôÂ∫ìgithub‰∏≠ÊñáNLPÊï∞ÊçÆÈõÜÂàóË°®githubÁ±ª‰∫∫Âêç/Âú∞Âêç/ÁªÑÁªáÊú∫ÊûÑÂêçÁöÑÂëΩÂêç‰ΩìËØÜÂà´Êï∞ÊçÆÈõÜgithub‰∏≠ÊñáËØ≠Ë®ÄÁêÜËß£ÊµãËØÑÂü∫ÂáÜÂåÖÊã¨‰ª£Ë°®ÊÄßÁöÑÊï∞ÊçÆÈõÜ&Âü∫ÂáÜÊ®°Âûã&ËØ≠ÊñôÂ∫ì&ÊéíË°åÊ¶úgithubOpenCLaPÂ§öÈ¢ÜÂüüÂºÄÊ∫ê‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã‰ªìÂ∫ìÊ∞ë‰∫ãÊñá‰π¶„ÄÅÂàë‰∫ãÊñá‰π¶„ÄÅÁôæÂ∫¶ÁôæÁßëgithub‰∏≠ÊñáÂÖ®ËØçË¶ÜÁõñBERTÂèä‰∏§‰ªΩÈòÖËØªÁêÜËß£Êï∞ÊçÆDRCDÊï∞ÊçÆÈõÜÔºöÁî±‰∏≠ÂõΩÂè∞ÊπæÂè∞ËææÁ†îÁ©∂Èô¢ÂèëÂ∏ÉÔºåÂÖ∂ÂΩ¢Âºè‰∏éSQuADÁõ∏ÂêåÔºåÊòØÂü∫‰∫éÁπÅ‰Ωì‰∏≠ÊñáÁöÑÊäΩÂèñÂºèÈòÖËØªÁêÜËß£Êï∞ÊçÆÈõÜ„ÄÇCMRC 2018Êï∞ÊçÆÈõÜ:ÂìàÂ∑•Â§ßËÆØÈ£ûËÅîÂêàÂÆûÈ™åÂÆ§ÂèëÂ∏ÉÁöÑ‰∏≠ÊñáÊú∫Âô®ÈòÖËØªÁêÜËß£Êï∞ÊçÆ„ÄÇÊ†πÊçÆÁªôÂÆöÈóÆÈ¢òÔºåÁ≥ªÁªüÈúÄË¶Å‰ªéÁØáÁ´†‰∏≠ÊäΩÂèñÂá∫ÁâáÊÆµ‰Ωú‰∏∫Á≠îÊ°àÔºåÂΩ¢Âºè‰∏éSQuADÁõ∏Âêå„ÄÇgithubDakshinaÊï∞ÊçÆÈõÜÂçÅ‰∫åÁßçÂçó‰∫öËØ≠Ë®ÄÁöÑÊãâ‰∏Å/Êú¨Âú∞ÊñáÂ≠óÂπ≥Ë°åÊï∞ÊçÆÈõÜÂêàgithubOPUS-100‰ª•Ëã±Êñá‰∏∫‰∏≠ÂøÉÁöÑÂ§öËØ≠(100Áßç)Âπ≥Ë°åËØ≠Êñôgithub‰∏≠ÊñáÈòÖËØªÁêÜËß£Êï∞ÊçÆÈõÜgithub‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂêëÈáèÂêàÈõÜgithub‰∏≠ÊñáËØ≠Ë®ÄÁêÜËß£ÊµãËØÑÂü∫ÂáÜÂåÖÊã¨‰ª£Ë°®ÊÄßÁöÑÊï∞ÊçÆÈõÜ„ÄÅÂü∫ÂáÜ(È¢ÑËÆ≠ÁªÉ)Ê®°Âûã„ÄÅËØ≠ÊñôÂ∫ì„ÄÅÊéíË°åÊ¶úgithubNLPÊï∞ÊçÆÈõÜ/Âü∫ÂáÜ‰ªªÂä°Â§ßÂàóË°®githubLitBankNLPÊï∞ÊçÆÈõÜÊîØÊåÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåËÆ°ÁÆó‰∫∫ÊñáÂ≠¶Áßë‰ªªÂä°ÁöÑ100ÈÉ®Â∏¶Ê†áËÆ∞Ëã±ÊñáÂ∞èËØ¥ËØ≠Êñôgithub70‰∏áÂØπËÅîÊï∞ÊçÆgithubÊñáË®ÄÊñáÔºàÂè§ÊñáÔºâ-Áé∞‰ª£ÊñáÂπ≥Ë°åËØ≠ÊñôÁü≠ÁØáÁ´†‰∏≠ÂåÖÊã¨‰∫Ü„ÄäËÆ∫ËØ≠„Äã„ÄÅ„ÄäÂ≠üÂ≠ê„Äã„ÄÅ„ÄäÂ∑¶‰º†„ÄãÁ≠âÁØáÂπÖËæÉÁü≠ÁöÑÂè§Á±çÔºåÂ∑≤Âíå„ÄäËµÑÊ≤ªÈÄöÈâ¥„ÄãÂêàÂπ∂githubCOLDDatesetÔºå‰∏≠ÊñáÂÜíÁäØÊÄßËØ≠Ë®ÄÊ£ÄÊµãÊï∞ÊçÆÈõÜÊ∂µÁõñ‰∫ÜÁßçÊóè„ÄÅÊÄßÂà´ÂíåÂú∞Âå∫Á≠âËØùÈ¢òÂÜÖÂÆπÔºåÊï∞ÊçÆÂæÖËÆ∫ÊñáÂèëË°®ÂêéÊîæÂá∫paperGAOKAO-benchÔºö‰ª•‰∏≠ÂõΩÈ´òËÄÉÈ¢òÁõÆ‰Ωú‰∏∫Êï∞ÊçÆÈõÜ‰ª•‰∏≠ÂõΩÈ´òËÄÉÈ¢òÁõÆ‰Ωú‰∏∫Êï∞ÊçÆÈõÜÔºåËØÑ‰º∞Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõÂíåÈÄªËæëÊé®ÁêÜËÉΩÂäõÁöÑÊµãËØÑÊ°ÜÊû∂ÔºåÂåÖÂê´1781ÈÅìÈÄâÊã©È¢ò„ÄÅ218ÈÅìÂ°´Á©∫È¢òÂíå812ÈÅìËß£Á≠îÈ¢ògithubzero to nlp - ‰∏≠ÊñánlpÂ∫îÁî®Êï∞ÊçÆ„ÄÅÊ®°Âûã„ÄÅËÆ≠ÁªÉ„ÄÅÊé®ÁêÜgithubËØçÂ∫ìÂèäËØçÊ≥ïÂ∑•ÂÖ∑ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•textfilter‰∏≠Ëã±ÊñáÊïèÊÑüËØçËøáÊª§observerss/textfilter‰∫∫ÂêçÊäΩÂèñÂäüËÉΩ‰∏≠ÊñáÔºàÁé∞‰ª£„ÄÅÂè§‰ª£ÔºâÂêçÂ≠ó„ÄÅÊó•ÊñáÂêçÂ≠ó„ÄÅ‰∏≠ÊñáÁöÑÂßìÂíåÂêç„ÄÅÁß∞ÂëºÔºàÂ§ßÂß®Â¶à„ÄÅÂ∞èÂß®Â¶àÁ≠âÔºâ„ÄÅËã±Êñá->‰∏≠ÊñáÂêçÂ≠óÔºàÊùéÁ∫¶Áø∞Ôºâ„ÄÅÊàêËØ≠ËØçÂÖ∏cocoNLP‰∏≠ÊñáÁº©ÂÜôÂ∫ìÂÖ®ÂõΩ‰∫∫Â§ß: ÂÖ®ÂõΩ ‰∫∫Ê∞ë ‰ª£Ë°®Â§ß‰ºö; ‰∏≠ÂõΩ: ‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩ;Â•≥ÁΩëËµõ: Â•≥Â≠ê/n ÁΩëÁêÉ/n ÊØîËµõ/vngithubÊ±âËØ≠ÊãÜÂ≠óËØçÂÖ∏Êº¢Â≠ó\tÊãÜÊ≥ï (‰∏Ä)\tÊãÜÊ≥ï (‰∫å)\tÊãÜÊ≥ï (‰∏â) ÊãÜ\tÊâã Êñ•\tÊâå Êñ•\tÊâç Êñ•kfcd/chaiziËØçÊ±áÊÉÖÊÑüÂÄºÂ±±Ê≥âÊ∞¥:0.400704566541   ÂÖÖÊ≤õ:\t0.37006739587rainarch/SentiBridge‰∏≠ÊñáËØçÂ∫ì„ÄÅÂÅúÁî®ËØç„ÄÅÊïèÊÑüËØçdongxiexidian/Chinesepython-pinyinÊ±âÂ≠óËΩ¨ÊãºÈü≥mozillazg/python-pinyinzhtools‰∏≠ÊñáÁπÅÁÆÄ‰Ωì‰∫íËΩ¨skydark/nstoolsËã±ÊñáÊ®°Êãü‰∏≠ÊñáÂèëÈü≥ÂºïÊìésay wo i ni #ËØ¥ÔºöÊàëÁà±‰Ω†tinyfool/ChineseWithEnglishchinese_dictionaryÂêå‰πâËØçÂ∫ì„ÄÅÂèç‰πâËØçÂ∫ì„ÄÅÂê¶ÂÆöËØçÂ∫ìguotong1988/chinese_dictionarywordninjaÊó†Á©∫Ê†ºËã±Êñá‰∏≤ÂàÜÂâ≤„ÄÅÊäΩÂèñÂçïËØçwordninjaÊ±ΩËΩ¶ÂìÅÁâå„ÄÅÊ±ΩËΩ¶Èõ∂‰ª∂Áõ∏ÂÖ≥ËØçÊ±ádataTHUÊï¥ÁêÜÁöÑËØçÂ∫ìITËØçÂ∫ì„ÄÅË¥¢ÁªèËØçÂ∫ì„ÄÅÊàêËØ≠ËØçÂ∫ì„ÄÅÂú∞ÂêçËØçÂ∫ì„ÄÅÂéÜÂè≤Âêç‰∫∫ËØçÂ∫ì„ÄÅËØóËØçËØçÂ∫ì„ÄÅÂåªÂ≠¶ËØçÂ∫ì„ÄÅÈ•ÆÈ£üËØçÂ∫ì„ÄÅÊ≥ïÂæãËØçÂ∫ì„ÄÅÊ±ΩËΩ¶ËØçÂ∫ì„ÄÅÂä®Áâ©ËØçÂ∫ìlinkÁΩ™ÂêçÊ≥ïÂä°ÂêçËØçÂèäÂàÜÁ±ªÊ®°ÂûãÂåÖÂê´856È°πÁΩ™ÂêçÁü•ËØÜÂõæË∞±, Âü∫‰∫é280‰∏áÁΩ™ÂêçËÆ≠ÁªÉÂ∫ìÁöÑÁΩ™ÂêçÈ¢ÑÊµã,Âü∫‰∫é20WÊ≥ïÂä°ÈóÆÁ≠îÂØπÁöÑ13Á±ªÈóÆÈ¢òÂàÜÁ±ª‰∏éÊ≥ïÂæãËµÑËÆØÈóÆÁ≠îÂäüËÉΩgithubÂàÜËØçËØ≠ÊñôÂ∫ì+‰ª£Á†ÅÁôæÂ∫¶ÁΩëÁõòÈìæÊé•     - ÊèêÂèñÁ†Å pea6Âü∫‰∫éBi-LSTM + CRFÁöÑ‰∏≠ÊñáÂàÜËØç+ËØçÊÄßÊ†áÊ≥®kerasÂÆûÁé∞linkÂü∫‰∫éUniversal Transformer + CRF ÁöÑ‰∏≠ÊñáÂàÜËØçÂíåËØçÊÄßÊ†áÊ≥®linkÂø´ÈÄüÁ•ûÁªèÁΩëÁªúÂàÜËØçÂåÖjava versionchinese-xinhua‰∏≠ÂçéÊñ∞ÂçéÂ≠óÂÖ∏Êï∞ÊçÆÂ∫ìÂèäapiÔºåÂåÖÊã¨Â∏∏Áî®Ê≠áÂêéËØ≠„ÄÅÊàêËØ≠„ÄÅËØçËØ≠ÂíåÊ±âÂ≠ógithubSpaCy ‰∏≠ÊñáÊ®°ÂûãÂåÖÂê´Parser, NER, ËØ≠Ê≥ïÊ†ëÁ≠âÂäüËÉΩ„ÄÇÊúâ‰∏Ä‰∫õËã±Êñápackage‰ΩøÁî®spacyÁöÑËã±ÊñáÊ®°ÂûãÁöÑÔºåÂ¶ÇÊûúË¶ÅÈÄÇÈÖç‰∏≠ÊñáÔºåÂèØËÉΩÈúÄË¶Å‰ΩøÁî®spacy‰∏≠ÊñáÊ®°Âûã„ÄÇgithub‰∏≠ÊñáÂ≠óÁ¨¶Êï∞ÊçÆgithubSynonyms‰∏≠ÊñáËøë‰πâËØçÂ∑•ÂÖ∑ÂåÖgithubHarvestTextÈ¢ÜÂüüËá™ÈÄÇÂ∫îÊñáÊú¨ÊåñÊéòÂ∑•ÂÖ∑ÔºàÊñ∞ËØçÂèëÁé∞-ÊÉÖÊÑüÂàÜÊûê-ÂÆû‰ΩìÈìæÊé•Á≠âÔºâgithubword2wordÊñπ‰æøÊòìÁî®ÁöÑÂ§öËØ≠Ë®ÄËØç-ËØçÂØπÈõÜ62ÁßçËØ≠Ë®Ä/3,564‰∏™Â§öËØ≠Ë®ÄÂØπgithubÂ§öÈü≥Â≠óËØçÂÖ∏Êï∞ÊçÆÂèä‰ª£Á†ÅgithubÊ±âÂ≠ó„ÄÅËØçËØ≠„ÄÅÊàêËØ≠Êü•ËØ¢Êé•Âè£github103976‰∏™Ëã±ËØ≠ÂçïËØçÂ∫ìÂåÖÔºàsqlÁâàÔºåcsvÁâàÔºåExcelÁâàÔºâgithubËã±ÊñáËÑèËØùÂ§ßÂàóË°®githubËØçËØ≠ÊãºÈü≥Êï∞ÊçÆgithub186ÁßçËØ≠Ë®ÄÁöÑÊï∞Â≠óÂè´Ê≥ïÂ∫ìgithub‰∏ñÁïåÂêÑÂõΩÂ§ßËßÑÊ®°‰∫∫ÂêçÂ∫ìgithubÊ±âÂ≠óÂ≠óÁ¨¶ÁâπÂæÅÊèêÂèñÂô® (featurizer)ÊèêÂèñÊ±âÂ≠óÁöÑÁâπÂæÅÔºàÂèëÈü≥ÁâπÂæÅ„ÄÅÂ≠óÂΩ¢ÁâπÂæÅÔºâÁî®ÂÅöÊ∑±Â∫¶Â≠¶‰π†ÁöÑÁâπÂæÅgithubchar_featurizer - Ê±âÂ≠óÂ≠óÁ¨¶ÁâπÂæÅÊèêÂèñÂ∑•ÂÖ∑github‰∏≠Êó•Èü©ÂàÜËØçÂ∫ìmecabÁöÑPythonÊé•Âè£Â∫ìgithubg2pCÂü∫‰∫é‰∏ä‰∏ãÊñáÁöÑÊ±âËØ≠ËØªÈü≥Ëá™Âä®Ê†áËÆ∞Ê®°Âùógithubssc, Sound Shape CodeÈü≥ÂΩ¢Á†Å - Âü∫‰∫é‚ÄúÈü≥ÂΩ¢Á†Å‚ÄùÁöÑ‰∏≠ÊñáÂ≠óÁ¨¶‰∏≤Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ïversion 1version 2blog/introductionÂü∫‰∫éÁôæÁßëÁü•ËØÜÂ∫ìÁöÑ‰∏≠ÊñáËØçËØ≠Â§öËØç‰πâ/‰πâÈ°πËé∑Âèñ‰∏éÁâπÂÆöÂè•Â≠êËØçËØ≠ËØ≠‰πâÊ∂àÊ≠ßgithubTokenizerÂø´ÈÄü„ÄÅÂèØÂÆöÂà∂ÁöÑÊñáÊú¨ËØçÊù°ÂåñÂ∫ìgithubTokenizersÊ≥®ÈáçÊÄßËÉΩ‰∏éÂ§öÂäüËÉΩÊÄßÁöÑÊúÄÂÖàËøõÂàÜËØçÂô®githubÈÄöËøáÂêå‰πâËØçÊõøÊç¢ÂÆûÁé∞ÊñáÊú¨‚ÄúÂèòËÑ∏‚Äùgithubtoken2index‰∏éPyTorch/TensorflowÂÖºÂÆπÁöÑÂº∫Â§ßËΩªÈáèËØçÊù°Á¥¢ÂºïÂ∫ìgithubÁπÅÁÆÄ‰ΩìËΩ¨Êç¢githubÁ≤§ËØ≠NLPÂ∑•ÂÖ∑githubÈ¢ÜÂüüËØçÂÖ∏Â∫ìÊ∂µÁõñ68‰∏™È¢ÜÂüü„ÄÅÂÖ±ËÆ°916‰∏áËØçÁöÑ‰∏ì‰∏öËØçÂÖ∏Áü•ËØÜÂ∫ìgithubÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã&Â§ßÊ®°ÂûãËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•BMListÂ§ßÊ®°ÂûãÂ§ßÂàóË°®githubbertËÆ∫Êñá‰∏≠ÊñáÁøªËØëlinkbertÂéü‰ΩúËÄÖÁöÑslideslinkÊñáÊú¨ÂàÜÁ±ªÂÆûË∑µgithubbert tutorialÊñáÊú¨ÂàÜÁ±ªÊïôÁ®ãgithubbert pytorchÂÆûÁé∞githubbert pytorchÂÆûÁé∞githubBERTÁîüÊàêÂè•ÂêëÈáèÔºåBERTÂÅöÊñáÊú¨ÂàÜÁ±ª„ÄÅÊñáÊú¨Áõ∏‰ººÂ∫¶ËÆ°ÁÆógithubbert„ÄÅELMOÁöÑÂõæËß£githubBERT Pre-trained models and downstream applicationsgithubËØ≠Ë®Ä/Áü•ËØÜË°®Á§∫Â∑•ÂÖ∑BERT & ERNIEgithubKashgari‰∏≠‰ΩøÁî®gpt-2ËØ≠Ë®ÄÊ®°ÂûãgithubFacebook LAMAÁî®‰∫éÂàÜÊûêÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã‰∏≠ÂåÖÂê´ÁöÑ‰∫ãÂÆûÂíåÂ∏∏ËØÜÁü•ËØÜÁöÑÊé¢Èíà„ÄÇËØ≠Ë®ÄÊ®°ÂûãÂàÜÊûêÔºåÊèê‰æõTransformer-XL/BERT/ELMo/GPTÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÁöÑÁªü‰∏ÄËÆøÈóÆÊé•Âè£github‰∏≠ÊñáÁöÑGPT2ËÆ≠ÁªÉ‰ª£Á†ÅgithubXLMFacebookÁöÑË∑®ËØ≠Ë®ÄÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãgithubÊµ∑Èáè‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉALBERTÊ®°ÂûãgithubTransformers 20ÊîØÊåÅTensorFlow 20 Âíå PyTorch ÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûã(BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet‚Ä¶) 8ÁßçÊû∂ÊûÑ/33ÁßçÈ¢ÑËÆ≠ÁªÉÊ®°Âûã/102ÁßçËØ≠Ë®Ägithub8ÁØáËÆ∫ÊñáÊ¢≥ÁêÜBERTÁõ∏ÂÖ≥Ê®°ÂûãËøõÂ±ï‰∏éÂèçÊÄùgithubÊ≥ïÊñáRoBERTaÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÁî®138GBËØ≠ÊñôËÆ≠ÁªÉÁöÑÊ≥ïÊñáRoBERTaÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°Âûãlink‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉ ELECTREA Ê®°ÂûãÂü∫‰∫éÂØπÊäóÂ≠¶‰π† pretrain Chinese Modelgithubalbert-chinese-nerÁî®È¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãALBERTÂÅö‰∏≠ÊñáNERgithubÂºÄÊ∫êÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÂêàÈõÜgithub‰∏≠ÊñáELECTRAÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãgithubÁî®Transformers(BERT, XLNet, Bart, Electra, Roberta, XLM-Roberta)È¢ÑÊµã‰∏ã‰∏Ä‰∏™ËØç(Ê®°ÂûãÊØîËæÉ)githubTensorFlow Hub40+ÁßçËØ≠Ë®ÄÁöÑÊñ∞ËØ≠Ë®ÄÊ®°Âûã(ÂåÖÊã¨‰∏≠Êñá)linkUERÂü∫‰∫é‰∏çÂêåËØ≠Êñô„ÄÅÁºñÁ†ÅÂô®„ÄÅÁõÆÊ†á‰ªªÂä°ÁöÑ‰∏≠ÊñáÈ¢ÑËÆ≠ÁªÉÊ®°Âûã‰ªìÂ∫ìÔºàÂåÖÊã¨BERT„ÄÅGPT„ÄÅELMOÁ≠âÔºâgithubÂºÄÊ∫êÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÂêàÈõÜgithubÂ§öËØ≠Ë®ÄÂè•ÂêëÈáèÂåÖgithubLanguage Model as a Service (LMaaS)ËØ≠Ë®ÄÊ®°ÂûãÂç≥ÊúçÂä°githubÂºÄÊ∫êËØ≠Ë®ÄÊ®°ÂûãGPT-NeoX-20B200‰∫øÂèÇÊï∞ÔºåÊòØÁõÆÂâçÊúÄÂ§ßÁöÑÂèØÂÖ¨ÂºÄËÆøÈóÆÁöÑÈ¢ÑËÆ≠ÁªÉÈÄöÁî®Ëá™ÂõûÂΩíËØ≠Ë®ÄÊ®°Âûãgithub‰∏≠ÊñáÁßëÂ≠¶ÊñáÁåÆÊï∞ÊçÆÈõÜÔºàCSLÔºâÂåÖÂê´ 396,209 ÁØá‰∏≠ÊñáÊ†∏ÂøÉÊúüÂàäËÆ∫ÊñáÂÖÉ‰ø°ÊÅØ ÔºàÊ†áÈ¢ò„ÄÅÊëòË¶Å„ÄÅÂÖ≥ÈîÆËØç„ÄÅÂ≠¶Áßë„ÄÅÈó®Á±ªÔºâ„ÄÇCSL Êï∞ÊçÆÈõÜÂèØ‰ª•‰Ωú‰∏∫È¢ÑËÆ≠ÁªÉËØ≠ÊñôÔºå‰πüÂèØ‰ª•ÊûÑÂª∫ËÆ∏Â§öNLP‰ªªÂä°Ôºå‰æãÂ¶ÇÊñáÊú¨ÊëòË¶ÅÔºàÊ†áÈ¢òÈ¢ÑÊµãÔºâ„ÄÅ ÂÖ≥ÈîÆËØçÁîüÊàêÂíåÊñáÊú¨ÂàÜÁ±ªÁ≠â„ÄÇgithubÂ§ßÊ®°ÂûãÂºÄÂèëÁ•ûÂô®githubÊäΩÂèñËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Êó∂Èó¥ÊäΩÂèñÂ∑≤ÈõÜÊàêÂà∞ python package cocoNLP‰∏≠ÔºåÊ¨¢ËøéËØïÁî®java versionpython versionÁ•ûÁªèÁΩëÁªúÂÖ≥Á≥ªÊäΩÂèñ pytorchÊöÇ‰∏çÊîØÊåÅ‰∏≠ÊñágithubÂü∫‰∫ébertÁöÑÂëΩÂêçÂÆû‰ΩìËØÜÂà´ pytorchÊöÇ‰∏çÊîØÊåÅ‰∏≠ÊñágithubÂÖ≥ÈîÆËØç(Keyphrase)ÊäΩÂèñÂåÖ pkegithubBLINKÊúÄÂÖàËøõÁöÑÂÆû‰ΩìÈìæÊé•Â∫ìgithubBERT/CRFÂÆûÁé∞ÁöÑÂëΩÂêçÂÆû‰ΩìËØÜÂà´githubÊîØÊåÅÊâπÂπ∂Ë°åÁöÑLatticeLSTM‰∏≠ÊñáÂëΩÂêçÂÆû‰ΩìËØÜÂà´githubÊûÑÂª∫ÂåªÁñóÂÆû‰ΩìËØÜÂà´ÁöÑÊ®°ÂûãÂåÖÂê´ËØçÂÖ∏ÂíåËØ≠ÊñôÊ†áÊ≥®ÔºåÂü∫‰∫épythongithubÂü∫‰∫éTensorFlowÂíåBERTÁöÑÁÆ°ÈÅìÂºèÂÆû‰ΩìÂèäÂÖ≥Á≥ªÊäΩÂèñ- Entity and Relation Extraction Based on TensorFlow and BERT Âü∫‰∫éTensorFlowÂíåBERTÁöÑÁÆ°ÈÅìÂºèÂÆû‰ΩìÂèäÂÖ≥Á≥ªÊäΩÂèñÔºå2019ËØ≠Ë®Ä‰∏éÊô∫ËÉΩÊäÄÊúØÁ´ûËµõ‰ø°ÊÅØÊäΩÂèñ‰ªªÂä°Ëß£ÂÜ≥ÊñπÊ°à„ÄÇSchema based Knowledge Extraction, SKE 2019github‰∏≠ÊñáÂëΩÂêçÂÆû‰ΩìËØÜÂà´NeuroNER vs BertNERgithubÂü∫‰∫éBERTÁöÑ‰∏≠ÊñáÂëΩÂêçÂÆû‰ΩìËØÜÂà´github‰∏≠ÊñáÂÖ≥ÈîÆÁü≠ËØ≠ÊäΩÂèñÂ∑•ÂÖ∑githubbertÁî®‰∫é‰∏≠ÊñáÂëΩÂêçÂÆû‰ΩìËØÜÂà´ tensorflowÁâàÊú¨githubbert-KashgariÂü∫‰∫é keras ÁöÑÂ∞ÅË£ÖÂàÜÁ±ªÊ†áÊ≥®Ê°ÜÊû∂ KashgariÔºåÂá†ÂàÜÈíüÂç≥ÂèØÊê≠Âª∫‰∏Ä‰∏™ÂàÜÁ±ªÊàñËÄÖÂ∫èÂàóÊ†áÊ≥®Ê®°ÂûãgithubcocoNLP‰∫∫Âêç„ÄÅÂú∞ÂùÄ„ÄÅÈÇÆÁÆ±„ÄÅÊâãÊú∫Âè∑„ÄÅÊâãÊú∫ÂΩíÂ±ûÂú∞ Á≠â‰ø°ÊÅØÁöÑÊäΩÂèñÔºårakeÁü≠ËØ≠ÊäΩÂèñÁÆóÊ≥ï„ÄÇgithubMicrosoftÂ§öËØ≠Ë®ÄÊï∞Â≠ó/Âçï‰Ωç/Â¶ÇÊó•ÊúüÊó∂Èó¥ËØÜÂà´ÂåÖgithubÁôæÂ∫¶ÂºÄÊ∫êÁöÑÂü∫ÂáÜ‰ø°ÊÅØÊäΩÂèñÁ≥ªÁªügithub‰∏≠ÊñáÂú∞ÂùÄÂàÜËØçÔºàÂú∞ÂùÄÂÖÉÁ¥†ËØÜÂà´‰∏éÊäΩÂèñÔºâÔºåÈÄöËøáÂ∫èÂàóÊ†áÊ≥®ËøõË°åNERgithubÂü∫‰∫é‰æùÂ≠òÂè•Ê≥ïÁöÑÂºÄÊîæÂüüÊñáÊú¨Áü•ËØÜ‰∏âÂÖÉÁªÑÊäΩÂèñÂíåÁü•ËØÜÂ∫ìÊûÑÂª∫githubÂü∫‰∫éÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑ‰∏≠ÊñáÂÖ≥ÈîÆËØçÊäΩÂèñÊñπÊ≥ïgithubchinese_keyphrase_extractor (CKPE)A tool for chinese keyphrase extraction ‰∏Ä‰∏™Âø´ÈÄü‰ªéËá™ÁÑ∂ËØ≠Ë®ÄÊñáÊú¨‰∏≠ÊèêÂèñÂíåËØÜÂà´ÂÖ≥ÈîÆÁü≠ËØ≠ÁöÑÂ∑•ÂÖ∑githubÁÆÄÂçïÁöÑÁÆÄÂéÜËß£ÊûêÂô®ÔºåÁî®Êù•‰ªéÁÆÄÂéÜ‰∏≠ÊèêÂèñÂÖ≥ÈîÆ‰ø°ÊÅØgithubBERT-NER-Pytorch‰∏âÁßç‰∏çÂêåÊ®°ÂºèÁöÑBERT‰∏≠ÊñáNERÂÆûÈ™ågithubÁü•ËØÜÂõæË∞±ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Ê∏ÖÂçéÂ§ßÂ≠¶XLORE‰∏≠Ëã±ÊñáË∑®ËØ≠Ë®ÄÁôæÁßëÁü•ËØÜÂõæË∞±ÁôæÂ∫¶„ÄÅ‰∏≠ÊñáÁª¥Âü∫„ÄÅËã±ÊñáÁª¥Âü∫linkÊñáÊ°£ÂõæË∞±Ëá™Âä®ÁîüÊàêgithubÂü∫‰∫éÂåªÁñóÈ¢ÜÂüüÁü•ËØÜÂõæË∞±ÁöÑÈóÆÁ≠îÁ≥ªÁªügithub ËØ•repoÂèÇËÄÉ‰∫Ügithub‰∏≠Êñá‰∫∫Áâ©ÂÖ≥Á≥ªÁü•ËØÜÂõæË∞±È°πÁõÆgithubAmpliGraph Áü•ËØÜÂõæË∞±Ë°®Á§∫Â≠¶‰π†(Python)Â∫ìÁü•ËØÜÂõæË∞±Ê¶ÇÂøµÈìæÊé•È¢ÑÊµãgithub‰∏≠ÊñáÁü•ËØÜÂõæË∞±ËµÑÊñô„ÄÅÊï∞ÊçÆÂèäÂ∑•ÂÖ∑githubÂü∫‰∫éÁôæÂ∫¶ÁôæÁßëÁöÑ‰∏≠ÊñáÁü•ËØÜÂõæË∞±ÊäΩÂèñ‰∏âÂÖÉÁªÑ‰ø°ÊÅØÔºåÊûÑÂª∫‰∏≠ÊñáÁü•ËØÜÂõæË∞±githubZincbase Áü•ËØÜÂõæË∞±ÊûÑÂª∫Â∑•ÂÖ∑ÂåÖgithubÂü∫‰∫éÁü•ËØÜÂõæË∞±ÁöÑÈóÆÁ≠îÁ≥ªÁªügithubÁü•ËØÜÂõæË∞±Ê∑±Â∫¶Â≠¶‰π†Áõ∏ÂÖ≥ËµÑÊñôÊï¥ÁêÜgithub‰∏úÂçóÂ§ßÂ≠¶„ÄäÁü•ËØÜÂõæË∞±„ÄãÁ†îÁ©∂ÁîüËØæÁ®ã(ËµÑÊñô)githubÁü•ËØÜÂõæË∞±ËΩ¶Èü≥Â∑•‰ΩúÈ°πÁõÆgithub„ÄäÊµ∑Ë¥ºÁéã„ÄãÁü•ËØÜÂõæË∞±github132‰∏™Áü•ËØÜÂõæË∞±ÁöÑÊï∞ÊçÆÈõÜÊ∂µÁõñÂ∏∏ËØÜ„ÄÅÂüéÂ∏Ç„ÄÅÈáëËûç„ÄÅÂÜú‰∏ö„ÄÅÂú∞ÁêÜ„ÄÅÊ∞îË±°„ÄÅÁ§æ‰∫§„ÄÅÁâ©ËÅîÁΩë„ÄÅÂåªÁñó„ÄÅÂ®±‰πê„ÄÅÁîüÊ¥ª„ÄÅÂïÜ‰∏ö„ÄÅÂá∫Ë°å„ÄÅÁßëÊïôlinkÂ§ßËßÑÊ®°„ÄÅÁªìÊûÑÂåñ„ÄÅ‰∏≠Ëã±ÊñáÂèåËØ≠ÁöÑÊñ∞ÂÜ†Áü•ËØÜÂõæË∞±(COKG-19)linkÂü∫‰∫é‰æùÂ≠òÂè•Ê≥ï‰∏éËØ≠‰πâËßíËâ≤Ê†áÊ≥®ÁöÑ‰∫ã‰ª∂‰∏âÂÖÉÁªÑÊäΩÂèñgithubÊäΩË±°Áü•ËØÜÂõæË∞±ÁõÆÂâçËßÑÊ®°50‰∏áÔºåÊîØÊåÅÂêçËØçÊÄßÂÆû‰Ωì„ÄÅÁä∂ÊÄÅÊÄßÊèèËø∞„ÄÅ‰∫ã‰ª∂ÊÄßÂä®‰ΩúËøõË°åÊäΩË±°githubÂ§ßËßÑÊ®°‰∏≠ÊñáÁü•ËØÜÂõæË∞±Êï∞ÊçÆ14‰∫øÂÆû‰ΩìgithubJiaguËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•ÂÖ∑‰ª•BiLSTMÁ≠âÊ®°Âûã‰∏∫Âü∫Á°ÄÔºåÊèê‰æõÁü•ËØÜÂõæË∞±ÂÖ≥Á≥ªÊäΩÂèñ ‰∏≠ÊñáÂàÜËØç ËØçÊÄßÊ†áÊ≥® ÂëΩÂêçÂÆû‰ΩìËØÜÂà´ ÊÉÖÊÑüÂàÜÊûê Êñ∞ËØçÂèëÁé∞ ÂÖ≥ÈîÆËØç ÊñáÊú¨ÊëòË¶Å ÊñáÊú¨ËÅöÁ±ªÁ≠âÂäüËÉΩgithubmedical_NER - ‰∏≠ÊñáÂåªÂ≠¶Áü•ËØÜÂõæË∞±ÂëΩÂêçÂÆû‰ΩìËØÜÂà´githubÁü•ËØÜÂõæË∞±Áõ∏ÂÖ≥Â≠¶‰π†ËµÑÊñô/Êï∞ÊçÆÈõÜ/Â∑•ÂÖ∑ËµÑÊ∫êÂ§ßÂàóË°®githubLibKGEÈù¢ÂêëÂèØÂ§çÁé∞Á†îÁ©∂ÁöÑÁü•ËØÜÂõæË∞±ÂµåÂÖ•Â∫ìgithubÂü∫‰∫émongodbÂ≠òÂÇ®ÁöÑÂÜõ‰∫ãÈ¢ÜÂüüÁü•ËØÜÂõæË∞±ÈóÆÁ≠îÈ°πÁõÆÂåÖÊã¨È£ûË°åÂô®„ÄÅÂ§™Á©∫Ë£ÖÂ§áÁ≠â8Â§ßÁ±ªÔºå100‰ΩôÂ∞èÁ±ªÔºåÂÖ±ËÆ°5800È°πÁöÑÂÜõ‰∫ãÊ≠¶Âô®Áü•ËØÜÂ∫ìÔºåËØ•È°πÁõÆ‰∏ç‰ΩøÁî®ÂõæÊï∞ÊçÆÂ∫ìËøõË°åÂ≠òÂÇ®ÔºåÈÄöËøájiebaËøõË°åÈóÆÂè•Ëß£ÊûêÔºåÈóÆÂè•ÂÆû‰ΩìÈ°πËØÜÂà´ÔºåÂü∫‰∫éÊü•ËØ¢Ê®°ÊùøÂÆåÊàêÂ§öÁ±ªÈóÆÈ¢òÁöÑÊü•ËØ¢Ôºå‰∏ªË¶ÅÊòØÊèê‰æõ‰∏ÄÁßçÂ∑•‰∏öÁïåÁöÑÈóÆÁ≠îÊÄùÊÉ≥demo„ÄÇgithub‰∫¨‰∏úÂïÜÂìÅÁü•ËØÜÂõæË∞±githubÂü∫‰∫éËøúÁõëÁù£ÁöÑ‰∏≠ÊñáÂÖ≥Á≥ªÊäΩÂèñgithubÂü∫‰∫éÂåªËçØÁü•ËØÜÂõæË∞±ÁöÑÊô∫ËÉΩÈóÆÁ≠îÁ≥ªÁªügithubBLINKÊúÄÂÖàËøõÁöÑÂÆû‰ΩìÈìæÊé•Â∫ìgithub‰∏Ä‰∏™Â∞èÂûãÁöÑËØÅÂà∏Áü•ËØÜÂõæË∞±/Áü•ËØÜÂ∫ìgithubdstlrÈùûÁªìÊûÑÂåñÊñáÊú¨ÂèØÊâ©Â±ïÁü•ËØÜÂõæË∞±ÊûÑÂª∫Âπ≥Âè∞githubÁôæÂ∫¶ÁôæÁßë‰∫∫Áâ©ËØçÊù°Â±ûÊÄßÊäΩÂèñÁî®Âü∫‰∫éBERTÁöÑÂæÆË∞ÉÂíåÁâπÂæÅÊèêÂèñÊñπÊ≥ïÊù•ËøõË°åÁü•ËØÜÂõæË∞±githubÊñ∞ÂÜ†ËÇ∫ÁÇéÁõ∏ÂÖ≥Êï∞ÊçÆÊñ∞ÂÜ†ÂèäÂÖ∂‰ªñÁ±ªÂûãËÇ∫ÁÇé‰∏≠ÊñáÂåªÁñóÂØπËØùÊï∞ÊçÆÈõÜÔºõÊ∏ÖÂçéÂ§ßÂ≠¶Á≠âÊú∫ÊûÑÁöÑÂºÄÊîæÊï∞ÊçÆÊ∫êÔºàCOVID-19Ôºâgithub githubDGL-KE ÂõæÂµåÂÖ•Ë°®Á§∫Â≠¶‰π†ÁÆóÊ≥ïgithubÂõ†ÊûúÂÖ≥Á≥ªÂõæË∞±method dataÂü∫‰∫éÂ§öÈ¢ÜÂüüÊñáÊú¨Êï∞ÊçÆÈõÜÁöÑÂõ†Êûú‰∫ã‰ª∂ÂØπlinkÊñáÊú¨ÁîüÊàêËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•TexarToolkit for Text Generation and BeyondgithubEhud ReiterÊïôÊéàÁöÑÂçöÂÆ¢link  ÂåóÂ§ß‰∏áÂ∞èÂÜõÊïôÊéàÂº∫ÂäõÊé®ËçêÔºåËØ•ÂçöÂÆ¢ÂØπNLGÊäÄÊúØ„ÄÅËØÑ‰ª∑‰∏éÂ∫îÁî®ËøõË°å‰∫ÜÊ∑±ÂÖ•ÁöÑÊé¢ËÆ®‰∏éÂèçÊÄù„ÄÇÊñáÊú¨ÁîüÊàêÁõ∏ÂÖ≥ËµÑÊ∫êÂ§ßÂàóË°®githubÂºÄÊîæÂüüÂØπËØùÁîüÊàêÂèäÂú®ÂæÆËΩØÂ∞èÂÜ∞‰∏≠ÁöÑÂÆûË∑µËá™ÁÑ∂ËØ≠Ë®ÄÁîüÊàêËÆ©Êú∫Âô®ÊéåÊè°Ëá™Âä®Âàõ‰ΩúÁöÑÊú¨È¢ÜlinkÊñáÊú¨ÁîüÊàêÊéßÂà∂githubËá™ÁÑ∂ËØ≠Ë®ÄÁîüÊàêÁõ∏ÂÖ≥ËµÑÊ∫êÂ§ßÂàóË°®githubÁî®BLEURTËØÑ‰ª∑Ëá™ÁÑ∂ËØ≠Ë®ÄÁîüÊàêlinkËá™Âä®ÂØπËÅîÊï∞ÊçÆÂèäÊú∫Âô®‰∫∫‰ª£Á†Å link  70‰∏áÂØπËÅîÊï∞ÊçÆËá™Âä®ÁîüÊàêËØÑËÆ∫Áî®TransformerÁºñËß£Á†ÅÊ®°ÂûãÂÆûÁé∞ÁöÑÊ†πÊçÆHacker NewsÊñáÁ´†Ê†áÈ¢òÁîüÊàêËØÑËÆ∫githubËá™ÁÑ∂ËØ≠Ë®ÄÁîüÊàêSQLËØ≠Âè•ÔºàËã±ÊñáÔºâgithubËá™ÁÑ∂ËØ≠Ë®ÄÁîüÊàêËµÑÊ∫êÂ§ßÂÖ®github‰∏≠ÊñáÁîüÊàê‰ªªÂä°Âü∫ÂáÜÊµãËØÑgithubÂü∫‰∫éGPT2ÁöÑÁâπÂÆö‰∏ªÈ¢òÊñáÊú¨ÁîüÊàê/ÊñáÊú¨Â¢ûÂπøgithubÁºñÁ†Å„ÄÅÊ†áËÆ∞ÂíåÂÆûÁé∞‰∏ÄÁßçÂèØÊéßÈ´òÊïàÁöÑÊñáÊú¨ÁîüÊàêÊñπÊ≥ïgithubTextFoolerÈíàÂØπÊñáÊú¨ÂàÜÁ±ª/Êé®ÁêÜÁöÑÂØπÊäóÊñáÊú¨ÁîüÊàêÊ®°ÂùógithubSimBERTÂü∫‰∫éUniLMÊÄùÊÉ≥„ÄÅËûçÊ£ÄÁ¥¢‰∏éÁîüÊàê‰∫é‰∏Ä‰ΩìÁöÑBERTÊ®°ÂûãgithubÊñ∞ËØçÁîüÊàêÂèäÈÄ†Âè•‰∏çÂ≠òÂú®ÁöÑËØçÁî®GPT-2Âèò‰Ωì‰ªéÂ§¥ÁîüÊàêÊñ∞ËØçÂèäÂÖ∂ÂÆö‰πâ„ÄÅ‰æãÂè•githubÁî±ÊñáÊú¨Ëá™Âä®ÁîüÊàêÂ§öÈ°πÈÄâÊã©È¢ògithubÂêàÊàêÊï∞ÊçÆÁîüÊàêÂü∫ÂáÜgithubÊñáÊú¨ÊëòË¶ÅËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•‰∏≠ÊñáÊñáÊú¨ÊëòË¶Å/ÂÖ≥ÈîÆËØçÊèêÂèñgithubÂü∫‰∫éÂëΩÂêçÂÆû‰ΩìËØÜÂà´ÁöÑÁÆÄÂéÜËá™Âä®ÊëòË¶ÅgithubÊñáÊú¨Ëá™Âä®ÊëòË¶ÅÂ∫ìTextTeaser‰ªÖÊîØÊåÅËã±ÊñágithubÂü∫‰∫éBERTÁ≠âÊúÄÊñ∞ËØ≠Ë®ÄÊ®°ÂûãÁöÑÊäΩÂèñÂºèÊëòË¶ÅÊèêÂèñgithubPythonÂà©Áî®Ê∑±Â∫¶Â≠¶‰π†ËøõË°åÊñáÊú¨ÊëòË¶ÅÁöÑÁªºÂêàÊåáÂçólink(Colab)ÊäΩË±°ÊñáÊú¨ÊëòË¶ÅÂÆûÁé∞ÈõÜÈî¶(ÊïôÁ®ãgithubÊô∫ËÉΩÈóÆÁ≠îËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•‰∏≠ÊñáËÅäÂ§©Êú∫Âô®‰∫∫Ê†πÊçÆËá™Â∑±ÁöÑËØ≠ÊñôËÆ≠ÁªÉÂá∫Ëá™Â∑±ÊÉ≥Ë¶ÅÁöÑËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂèØ‰ª•Áî®‰∫éÊô∫ËÉΩÂÆ¢Êúç„ÄÅÂú®Á∫øÈóÆÁ≠î„ÄÅÊô∫ËÉΩËÅäÂ§©Á≠âÂú∫ÊôØgithubÊúâË∂£ÁöÑÊÉÖË∂£robot qingyunqingyun ËÆ≠ÁªÉÂá∫Êù•ÁöÑ‰∏≠ÊñáËÅäÂ§©Êú∫Âô®‰∫∫githubÂºÄÊîæ‰∫ÜÂØπËØùÊú∫Âô®‰∫∫„ÄÅÁü•ËØÜÂõæË∞±„ÄÅËØ≠‰πâÁêÜËß£„ÄÅËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•ÂÖ∑ÂèäÊï∞ÊçÆgithubqaÂØπÁöÑÊú∫Âô®‰∫∫Amodel-for-Retrivalchatbot - ÂÆ¢ÊúçÊú∫Âô®‰∫∫ÔºåChinese Retreival chatbotÔºà‰∏≠ÊñáÊ£ÄÁ¥¢ÂºèÊú∫Âô®‰∫∫ÔºâgitConvLabÂºÄÊ∫êÂ§öÂüüÁ´ØÂà∞Á´ØÂØπËØùÁ≥ªÁªüÂπ≥Âè∞githubÂü∫‰∫éÊúÄÊñ∞ÁâàÊú¨rasaÊê≠Âª∫ÁöÑÂØπËØùÁ≥ªÁªügithubÂü∫‰∫éÈáëËûç-Âè∏Ê≥ïÈ¢ÜÂüü(ÂÖºÊúâÈó≤ËÅäÊÄßË¥®)ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫githubÁ´ØÂà∞Á´ØÁöÑÂ∞ÅÈó≠ÂüüÂØπËØùÁ≥ªÁªügithubMiningZhiDaoQACorpus580‰∏áÁôæÂ∫¶Áü•ÈÅìÈóÆÁ≠îÊï∞ÊçÆÊåñÊéòÈ°πÁõÆÔºåÁôæÂ∫¶Áü•ÈÅìÈóÆÁ≠îËØ≠ÊñôÂ∫ìÔºåÂåÖÊã¨Ë∂ÖËøá580‰∏áÁöÑÈóÆÈ¢òÔºåÊØè‰∏™ÈóÆÈ¢òÂ∏¶ÊúâÈóÆÈ¢òÊ†áÁ≠æ„ÄÇÂü∫‰∫éËØ•ÈóÆÁ≠îËØ≠ÊñôÂ∫ìÔºåÂèØÊîØÊåÅÂ§öÁßçÂ∫îÁî®ÔºåÂ¶ÇÈÄªËæëÊåñÊéògithubÁî®‰∫é‰∏≠ÊñáÈó≤ËÅäÁöÑGPT2Ê®°ÂûãGPT2-chitchatgithubÂü∫‰∫éÊ£ÄÁ¥¢ËÅäÂ§©Êú∫Âô®‰∫∫Â§öËΩÆÂìçÂ∫îÈÄâÊã©Áõ∏ÂÖ≥ËµÑÊ∫êÂàóË°®(Leaderboards„ÄÅDatasets„ÄÅPapers)githubÂæÆËΩØÂØπËØùÊú∫Âô®‰∫∫Ê°ÜÊû∂githubchatbot-listË°å‰∏öÂÜÖÂÖ≥‰∫éÊô∫ËÉΩÂÆ¢Êúç„ÄÅËÅäÂ§©Êú∫Âô®‰∫∫ÁöÑÂ∫îÁî®ÂíåÊû∂ÊûÑ„ÄÅÁÆóÊ≥ïÂàÜ‰∫´Âíå‰ªãÁªçgithubChinese medical dialogue data ‰∏≠ÊñáÂåªÁñóÂØπËØùÊï∞ÊçÆÈõÜgithub‰∏Ä‰∏™Â§ßËßÑÊ®°ÂåªÁñóÂØπËØùÊï∞ÊçÆÈõÜÂåÖÂê´110‰∏áÂåªÂ≠¶Âí®ËØ¢Ôºå400‰∏áÊù°ÂåªÊÇ£ÂØπËØùgithubÂ§ßËßÑÊ®°Ë∑®È¢ÜÂüü‰∏≠Êñá‰ªªÂä°ÂØºÂêëÂ§öËΩÆÂØπËØùÊï∞ÊçÆÈõÜÂèäÊ®°ÂûãCrossWOZpaper & dataÂºÄÊ∫êÂØπËØùÂºè‰ø°ÊÅØÊêúÁ¥¢Âπ≥Âè∞githubÊÉÖÂ¢É‰∫íÂä®Â§öÊ®°ÊÄÅÂØπËØùÊåëÊàò2020(DSTC9 2020)githubÁî®QuoraÈóÆÈ¢òÂØπËÆ≠ÁªÉÁöÑT5ÈóÆÈ¢òÊÑèËØë(Paraphrase)githubGoogleÂèëÂ∏ÉTaskmaster-2Ëá™ÁÑ∂ËØ≠Ë®Ä‰ªªÂä°ÂØπËØùÊï∞ÊçÆÈõÜgithubHaystackÁÅµÊ¥ª„ÄÅÂº∫Â§ßÁöÑÂèØÊâ©Â±ïÈóÆÁ≠î(QA)Ê°ÜÊû∂githubÁ´ØÂà∞Á´ØÁöÑÂ∞ÅÈó≠ÂüüÂØπËØùÁ≥ªÁªügithubAmazonÂèëÂ∏ÉÂü∫‰∫éÁü•ËØÜÁöÑ‰∫∫-‰∫∫ÂºÄÊîæÈ¢ÜÂüüÂØπËØùÊï∞ÊçÆÈõÜgithubÂü∫‰∫éÁôæÂ∫¶webqa‰∏édureaderÊï∞ÊçÆÈõÜËÆ≠ÁªÉÁöÑAlbert Large QAÊ®°ÂûãgithubCommonsenseQAÈù¢ÂêëÂ∏∏ËØÜÁöÑËã±ÊñáQAÊåëÊàòlinkMedQuAD(Ëã±Êñá)ÂåªÂ≠¶ÈóÆÁ≠îÊï∞ÊçÆÈõÜgithubÂü∫‰∫éAlbert„ÄÅElectraÔºåÁî®Áª¥Âü∫ÁôæÁßëÊñáÊú¨‰Ωú‰∏∫‰∏ä‰∏ãÊñáÁöÑÈóÆÁ≠îÂºïÊìégithubÂü∫‰∫é14WÊ≠åÊõ≤Áü•ËØÜÂ∫ìÁöÑÈóÆÁ≠îÂ∞ùËØïÂäüËÉΩÂåÖÊã¨Ê≠åËØçÊé•ÈæôÔºåÂ∑≤Áü•Ê≠åËØçÊâæÊ≠åÊõ≤‰ª•ÂèäÊ≠åÊõ≤Ê≠åÊâãÊ≠åËØç‰∏âËßíÂÖ≥Á≥ªÁöÑÈóÆÁ≠îgithubÊñáÊú¨Á∫†ÈîôËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•‰∏≠ÊñáÊñáÊú¨Á∫†ÈîôÊ®°Âùó‰ª£Á†ÅgithubËã±ÊñáÊãºÂÜôÊ£ÄÊü•Â∫ìgithubpythonÊãºÂÜôÊ£ÄÊü•Â∫ìgithubGitHub Typo CorpusÂ§ßËßÑÊ®°GitHubÂ§öËØ≠Ë®ÄÊãºÂÜôÈîôËØØ/ËØ≠Ê≥ïÈîôËØØÊï∞ÊçÆÈõÜgithubBertPuncÂü∫‰∫éBERTÁöÑÊúÄÂÖàËøõÊ†áÁÇπ‰øÆÂ§çÊ®°Âûãgithub‰∏≠ÊñáÂÜô‰ΩúÊ†°ÂØπÂ∑•ÂÖ∑githubÊñáÊú¨Á∫†ÈîôÊñáÁåÆÂàóË°®Chinese Spell Checking (CSC) and Grammatical Error Correction (GEC)githubÊñáÊú¨Êô∫ËÉΩÊ†°ÂØπÂ§ßËµõÂÜ†ÂÜõÊñπÊ°àÂ∑≤ËêΩÂú∞Â∫îÁî®ÔºåÊù•Ëá™ËãèÂ∑ûÂ§ßÂ≠¶„ÄÅËææÊë©Èô¢Âõ¢ÈòülinkÂ§öÊ®°ÊÄÅËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•‰∏≠ÊñáÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜ„ÄåÊÇüÁ©∫„ÄçÂçé‰∏∫ËØ∫‰∫öÊñπËàüÂÆûÈ™åÂÆ§ÂºÄÊ∫êÂ§ßÂûãÔºåÂåÖÂê´1‰∫øÂõæÊñáÂØπgithub‰∏≠ÊñáÂõæÊñáË°®ÂæÅÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãChinese-CLIP‰∏≠ÊñáÁâàÊú¨CLIPÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºåÂºÄÊ∫êÂ§ö‰∏™Ê®°ÂûãËßÑÊ®°ÔºåÂá†Ë°å‰ª£Á†ÅÊêûÂÆö‰∏≠ÊñáÂõæÊñáË°®ÂæÅÊèêÂèñ & ÂõæÊñáÊ£ÄÁ¥¢githubËØ≠Èü≥Â§ÑÁêÜËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•ASR ËØ≠Èü≥Êï∞ÊçÆÈõÜ + Âü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑ‰∏≠ÊñáËØ≠Èü≥ËØÜÂà´Á≥ªÁªügithubÊ∏ÖÂçéÂ§ßÂ≠¶THCHS30‰∏≠ÊñáËØ≠Èü≥Êï∞ÊçÆÈõÜdata_thchs30tgz-OpenSLRÂõΩÂÜÖÈïúÂÉèdata_thchs30tgz test-noisetgz-OpenSLRÂõΩÂÜÖÈïúÂÉètest-noisetgz resourcetgz-OpenSLRÂõΩÂÜÖÈïúÂÉèresourcetgzFree ST Chinese Mandarin CorpusFree ST Chinese Mandarin CorpusAIShell-1 ÂºÄÊ∫êÁâàÊï∞ÊçÆÈõÜ-OpenSLRÂõΩÂÜÖÈïúÂÉèAIShell-1 ÂºÄÊ∫êÁâàÊï∞ÊçÆÈõÜPrimewords Chinese Corpus Set 1-OpenSLRÂõΩÂÜÖÈïúÂÉèPrimewords Chinese Corpus Set 1Á¨ëÂ£∞Ê£ÄÊµãÂô®githubCommon VoiceËØ≠Èü≥ËØÜÂà´Êï∞ÊçÆÈõÜÊñ∞ÁâàÂåÖÊã¨Êù•Ëá™42,000ÂêçË¥°ÁåÆËÄÖË∂ÖËøá1,400Â∞èÊó∂ÁöÑËØ≠Èü≥Ê†∑Êú¨ÔºåÊ∂µgithublinkspeech-aligner‰ªé‚Äú‰∫∫Â£∞ËØ≠Èü≥‚ÄùÂèäÂÖ∂‚ÄúËØ≠Ë®ÄÊñáÊú¨‚ÄùÔºå‰∫ßÁîüÈü≥Á¥†Á∫ßÂà´Êó∂Èó¥ÂØπÈΩêÊ†áÊ≥®ÁöÑÂ∑•ÂÖ∑githubASRËØ≠Èü≥Â§ßËæûÂÖ∏/ËØçÂÖ∏githubËØ≠Èü≥ÊÉÖÊÑüÂàÜÊûêgithubmasr‰∏≠ÊñáËØ≠Èü≥ËØÜÂà´ÔºåÊèê‰æõÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºåÈ´òËØÜÂà´ÁéágithubÈù¢ÂêëËØ≠Èü≥ËØÜÂà´ÁöÑ‰∏≠ÊñáÊñáÊú¨ËßÑËåÉÂåñgithubËØ≠Èü≥Ë¥®ÈáèËØÑ‰ª∑ÊåáÊ†á(MOSNet, BSSEval, STOI, PESQ, SRMR)githubÈù¢ÂêëËØ≠Èü≥ËØÜÂà´ÁöÑ‰∏≠Êñá/Ëã±ÊñáÂèëÈü≥ËæûÂÖ∏githubCoVoSTFacebookÂèëÂ∏ÉÁöÑÂ§öËØ≠ÁßçËØ≠Èü≥-ÊñáÊú¨ÁøªËØëËØ≠ÊñôÂ∫ìÂåÖÊã¨11ÁßçËØ≠Ë®Ä(Ê≥ïËØ≠„ÄÅÂæ∑ËØ≠„ÄÅËç∑ÂÖ∞ËØ≠„ÄÅ‰øÑËØ≠„ÄÅË•øÁè≠ÁâôËØ≠„ÄÅÊÑèÂ§ßÂà©ËØ≠„ÄÅÂúüËÄ≥ÂÖ∂ËØ≠„ÄÅÊ≥¢ÊñØËØ≠„ÄÅÁëûÂÖ∏ËØ≠„ÄÅËíôÂè§ËØ≠Âíå‰∏≠Êñá)ÁöÑËØ≠Èü≥„ÄÅÊñáÂ≠óËΩ¨ÂΩïÂèäËã±ÊñáËØëÊñágithubParakeetÂü∫‰∫éPaddlePaddleÁöÑÊñáÊú¨-ËØ≠Èü≥ÂêàÊàêgithub(Java)ÂáÜÁ°ÆÁöÑËØ≠Èü≥Ëá™ÁÑ∂ËØ≠Ë®ÄÊ£ÄÊµãÂ∫ìgithubCoVoSTFacebookÂèëÂ∏ÉÁöÑÂ§öËØ≠ÁßçËØ≠Èü≥-ÊñáÊú¨ÁøªËØëËØ≠ÊñôÂ∫ìgithubTensorFlow 2 ÂÆûÁé∞ÁöÑÊñáÊú¨ËØ≠Èü≥ÂêàÊàêgithubPythonÈü≥È¢ëÁâπÂæÅÊèêÂèñÂåÖgithubViSQOLÈü≥È¢ëË¥®ÈáèÊÑüÁü•ÂÆ¢ËßÇ„ÄÅÂÆåÊï¥ÂèÇËÄÉÊåáÊ†áÔºåÂàÜÈü≥È¢ë„ÄÅËØ≠Èü≥‰∏§ÁßçÊ®°ÂºègithubzhrtvcÂ•ΩÁî®ÁöÑ‰∏≠ÊñáËØ≠Èü≥ÂÖãÈöÜÂÖº‰∏≠ÊñáËØ≠Èü≥ÂêàÊàêÁ≥ªÁªügithubaukitÂ•ΩÁî®ÁöÑËØ≠Èü≥Â§ÑÁêÜÂ∑•ÂÖ∑ÁÆ±ÔºåÂåÖÂê´ËØ≠Èü≥ÈôçÂô™„ÄÅÈü≥È¢ëÊ†ºÂºèËΩ¨Êç¢„ÄÅÁâπÂæÅÈ¢ëË∞±ÁîüÊàêÁ≠âÊ®°ÂùógithubphkitÂ•ΩÁî®ÁöÑÈü≥Á¥†Â§ÑÁêÜÂ∑•ÂÖ∑ÁÆ±ÔºåÂåÖÂê´‰∏≠ÊñáÈü≥Á¥†„ÄÅËã±ÊñáÈü≥Á¥†„ÄÅÊñáÊú¨ËΩ¨ÊãºÈü≥„ÄÅÊñáÊú¨Ê≠£ÂàôÂåñÁ≠âÊ®°Âùógithubzhvoice‰∏≠ÊñáËØ≠Èü≥ËØ≠ÊñôÔºåËØ≠Èü≥Êõ¥Âä†Ê∏ÖÊô∞Ëá™ÁÑ∂ÔºåÂåÖÂê´8‰∏™ÂºÄÊ∫êÊï∞ÊçÆÈõÜÔºå3200‰∏™ËØ¥ËØù‰∫∫Ôºå900Â∞èÊó∂ËØ≠Èü≥Ôºå1300‰∏áÂ≠ógithubaudioÈù¢ÂêëËØ≠Èü≥Ë°å‰∏∫Ê£ÄÊµã„ÄÅ‰∫åÂÄºÂåñ„ÄÅËØ¥ËØù‰∫∫ËØÜÂà´„ÄÅËá™Âä®ËØ≠Èü≥ËØÜÂà´„ÄÅÊÉÖÊÑüËØÜÂà´Á≠â‰ªªÂä°ÁöÑÈü≥È¢ëÊ†áÊ≥®Â∑•ÂÖ∑githubÊ∑±Â∫¶Â≠¶‰π†ÊÉÖÊÑüÊñáÊú¨ËØ≠Èü≥ÂêàÊàêgithubPythonÈü≥È¢ëÊï∞ÊçÆÂ¢ûÂπøÂ∫ìgithubÂü∫‰∫éÂ§ßËßÑÊ®°Èü≥È¢ëÊï∞ÊçÆÈõÜAudiosetÁöÑÈü≥È¢ëÂ¢ûÂº∫githubËØ≠Â£∞ËøÅÁßªgithubÊñáÊ°£Â§ÑÁêÜËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•LayoutLM-v3ÊñáÊ°£ÁêÜËß£Ê®°ÂûãgithubPyLaiaÈù¢ÂêëÊâãÂÜôÊñáÊ°£ÂàÜÊûêÁöÑÊ∑±Â∫¶Â≠¶‰π†Â∑•ÂÖ∑ÂåÖgithubÂçïÊñáÊ°£ÈùûÁõëÁù£ÁöÑÂÖ≥ÈîÆËØçÊäΩÂèñgithubDocSearchÂÖçË¥πÊñáÊ°£ÊêúÁ¥¢ÂºïÊìégithubfdfgenËÉΩÂ§üËá™Âä®ÂàõÂª∫pdfÊñáÊ°£ÔºåÂπ∂Â°´ÂÜô‰ø°ÊÅØlinkpdfxËá™Âä®ÊäΩÂèñÂá∫ÂºïÁî®ÂèÇËÄÉÊñáÁåÆÔºåÂπ∂‰∏ãËΩΩÂØπÂ∫îÁöÑpdfÊñá‰ª∂linkinvoice2dataÂèëÁ•®pdf‰ø°ÊÅØÊäΩÂèñinvoice2datapdfÊñáÊ°£‰ø°ÊÅØÊäΩÂèñgithubPDFMinerPDFMinerËÉΩËé∑ÂèñÈ°µÈù¢‰∏≠ÊñáÊú¨ÁöÑÂáÜÁ°Æ‰ΩçÁΩÆÔºå‰ª•ÂèäÂ≠ó‰ΩìÊàñË°åÁ≠âÂÖ∂‰ªñ‰ø°ÊÅØ„ÄÇÂÆÉËøòÊúâ‰∏Ä‰∏™PDFËΩ¨Êç¢Âô®ÔºåÂèØ‰ª•Â∞ÜPDFÊñá‰ª∂ËΩ¨Êç¢ÊàêÂÖ∂‰ªñÊñáÊú¨Ê†ºÂºè(Â¶ÇHTML)„ÄÇËøòÊúâ‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑËß£ÊûêÂô®PDFÔºåÂèØ‰ª•Áî®‰∫éÊñáÊú¨ÂàÜÊûê‰ª•Â§ñÁöÑÂÖ∂‰ªñÁî®ÈÄî„ÄÇlinkPyPDF2PyPDF 2ÊòØ‰∏Ä‰∏™python PDFÂ∫ìÔºåËÉΩÂ§üÂàÜÂâ≤„ÄÅÂêàÂπ∂„ÄÅË£ÅÂâ™ÂíåËΩ¨Êç¢PDFÊñá‰ª∂ÁöÑÈ°µÈù¢„ÄÇÂÆÉËøòÂèØ‰ª•ÂêëPDFÊñá‰ª∂‰∏≠Ê∑ªÂä†Ëá™ÂÆö‰πâÊï∞ÊçÆ„ÄÅÊü•ÁúãÈÄâÈ°πÂíåÂØÜÁ†Å„ÄÇÂÆÉÂèØ‰ª•‰ªéPDFÊ£ÄÁ¥¢ÊñáÊú¨ÂíåÂÖÉÊï∞ÊçÆÔºåËøòÂèØ‰ª•Â∞ÜÊï¥‰∏™Êñá‰ª∂ÂêàÂπ∂Âú®‰∏ÄËµ∑„ÄÇlinkPyPDF2PyPDF 2ÊòØ‰∏Ä‰∏™python PDFÂ∫ìÔºåËÉΩÂ§üÂàÜÂâ≤„ÄÅÂêàÂπ∂„ÄÅË£ÅÂâ™ÂíåËΩ¨Êç¢PDFÊñá‰ª∂ÁöÑÈ°µÈù¢„ÄÇÂÆÉËøòÂèØ‰ª•ÂêëPDFÊñá‰ª∂‰∏≠Ê∑ªÂä†Ëá™ÂÆö‰πâÊï∞ÊçÆ„ÄÅÊü•ÁúãÈÄâÈ°πÂíåÂØÜÁ†Å„ÄÇÂÆÉÂèØ‰ª•‰ªéPDFÊ£ÄÁ¥¢ÊñáÊú¨ÂíåÂÖÉÊï∞ÊçÆÔºåËøòÂèØ‰ª•Â∞ÜÊï¥‰∏™Êñá‰ª∂ÂêàÂπ∂Âú®‰∏ÄËµ∑„ÄÇlinkReportLabReportLabËÉΩÂø´ÈÄüÂàõÂª∫PDF ÊñáÊ°£„ÄÇÁªèËøáÊó∂Èó¥ËØÅÊòéÁöÑ„ÄÅË∂ÖÂ•ΩÁî®ÁöÑÂºÄÊ∫êÈ°πÁõÆÔºåÁî®‰∫éÂàõÂª∫Â§çÊùÇÁöÑ„ÄÅÊï∞ÊçÆÈ©±Âä®ÁöÑPDFÊñáÊ°£ÂíåËá™ÂÆö‰πâÁü¢ÈáèÂõæÂΩ¢„ÄÇÂÆÉÊòØÂÖçË¥πÁöÑÔºåÂºÄÊ∫êÁöÑÔºåÁî®PythonÁºñÂÜôÁöÑ„ÄÇËØ•ËΩØ‰ª∂ÂåÖÊØèÊúà‰∏ãËΩΩ5‰∏áÂ§öÊ¨°ÔºåÊòØÊ†áÂáÜLinuxÂèëË°åÁâàÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÂµåÂÖ•Âà∞ËÆ∏Â§ö‰∫ßÂìÅ‰∏≠ÔºåÂπ∂Ë¢´ÈÄâ‰∏≠‰∏∫WikipediaÁöÑÊâìÂç∞/ÂØºÂá∫ÂäüËÉΩÊèê‰æõÂä®Âäõ„ÄÇlinkSIMPdfPythonÂÜôÁöÑÁÆÄÂçïPDFÊñá‰ª∂ÊñáÂ≠óÁºñËæëÂô®githubpdf-diffPDFÊñá‰ª∂diffÂ∑•ÂÖ∑ ÂèØÊòæÁ§∫‰∏§‰∏™pdfÊñáÊ°£ÁöÑÂ∑ÆÂà´githubË°®Ê†ºÂ§ÑÁêÜËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Áî®unetÂÆûÁé∞ÂØπÊñáÊ°£Ë°®Ê†ºÁöÑËá™Âä®Ê£ÄÊµãÔºåË°®Ê†ºÈáçÂª∫githubpdftabextractÁî®‰∫éOCRËØÜÂà´ÂêéÁöÑË°®Ê†º‰ø°ÊÅØËß£ÊûêÔºåÂæàÂº∫Â§ßlinktabula-pyÁõ¥Êé•Â∞Üpdf‰∏≠ÁöÑË°®Ê†º‰ø°ÊÅØËΩ¨Êç¢‰∏∫pandasÁöÑdataframeÔºåÊúâjavaÂíåpython‰∏§ÁßçÁâàÊú¨‰ª£Á†ÅcamelotpdfË°®Ê†ºËß£ÊûêlinkpdfplumberpdfË°®Ê†ºËß£ÊûêPubLayNetËÉΩÂ§üÂàíÂàÜÊÆµËêΩ„ÄÅËØÜÂà´Ë°®Ê†º„ÄÅÂõæÁâálink‰ªéËÆ∫Êñá‰∏≠ÊèêÂèñË°®Ê†ºÊï∞ÊçÆgithubÁî®BERTÂú®Ë°®Ê†º‰∏≠ÂØªÊâæÁ≠îÊ°àgithubË°®Ê†ºÈóÆÁ≠îÁöÑÁ≥ªÂàóÊñáÁ´†ÁÆÄ‰ªãÊ®°ÂûãÂÆåÁªìÁØá‰ΩøÁî®GANÁîüÊàêË°®Ê†ºÊï∞ÊçÆÔºà‰ªÖÊîØÊåÅËã±ÊñáÔºâgithubcarefree-learn(PyTorch)Ë°®Ê†ºÊï∞ÊçÆÈõÜËá™Âä®ÂåñÊú∫Âô®Â≠¶‰π†(AutoML)ÂåÖgithubÂ∞ÅÈó≠ÂüüÂæÆË∞ÉË°®Ê†ºÊ£ÄÊµãgithubPDFË°®Ê†ºÊï∞ÊçÆÊèêÂèñÂ∑•ÂÖ∑githubTaBERTÁêÜËß£Ë°®Ê†ºÊï∞ÊçÆÊü•ËØ¢ÁöÑÊñ∞Ê®°ÂûãpaperË°®Ê†ºÂ§ÑÁêÜAwesome-Table-RecognitiongithubÊñáÊú¨ÂåπÈÖçËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Âè•Â≠ê„ÄÅQAÁõ∏‰ººÂ∫¶ÂåπÈÖçMatchZooÊñáÊú¨Áõ∏‰ººÂ∫¶ÂåπÈÖçÁÆóÊ≥ïÁöÑÈõÜÂêàÔºåÂåÖÂê´Â§ö‰∏™Ê∑±Â∫¶Â≠¶‰π†ÁöÑÊñπÊ≥ïÔºåÂÄºÂæóÂ∞ùËØï„ÄÇgithub‰∏≠ÊñáÈóÆÈ¢òÂè•Â≠êÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÊØîËµõÂèäÊñπÊ°àÊ±áÊÄªgithubsimilarityÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÂ∑•ÂÖ∑ÂåÖjavaÁºñÂÜô,Áî®‰∫éËØçËØ≠„ÄÅÁü≠ËØ≠„ÄÅÂè•Â≠ê„ÄÅËØçÊ≥ïÂàÜÊûê„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅËØ≠‰πâÂàÜÊûêÁ≠âÁõ∏ÂÖ≥ÁöÑÁõ∏‰ººÂ∫¶ËÆ°ÁÆógithub‰∏≠ÊñáËØçËØ≠Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ïÁªºÂêà‰∫ÜÂêå‰πâËØçËØçÊûóÊâ©Â±ïÁâà‰∏éÁü•ÁΩëÔºàHownetÔºâÁöÑËØçËØ≠Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ïÔºåËØçÊ±áË¶ÜÁõñÊõ¥Â§ö„ÄÅÁªìÊûúÊõ¥ÂáÜÁ°Æ„ÄÇgihtubPythonÂ≠óÁ¨¶‰∏≤Áõ∏‰ººÊÄßÁÆóÊ≥ïÂ∫ìgithubÂü∫‰∫éSiamese bilstmÊ®°ÂûãÁöÑÁõ∏‰ººÂè•Â≠êÂà§ÂÆöÊ®°Âûã,Êèê‰æõËÆ≠ÁªÉÊï∞ÊçÆÈõÜÂíåÊµãËØïÊï∞ÊçÆÈõÜÊèê‰æõ‰∫Ü10‰∏á‰∏™ËÆ≠ÁªÉÊ†∑Êú¨githubÊñáÊú¨Êï∞ÊçÆÂ¢ûÂº∫ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•‰∏≠ÊñáNLPÊï∞ÊçÆÂ¢ûÂº∫ÔºàEDAÔºâÂ∑•ÂÖ∑githubËã±ÊñáNLPÊï∞ÊçÆÂ¢ûÂº∫Â∑•ÂÖ∑github‰∏ÄÈîÆ‰∏≠ÊñáÊï∞ÊçÆÂ¢ûÂº∫Â∑•ÂÖ∑githubÊï∞ÊçÆÂ¢ûÂº∫Âú®Êú∫Âô®ÁøªËØëÂèäÂÖ∂‰ªñnlp‰ªªÂä°‰∏≠ÁöÑÂ∫îÁî®ÂèäÊïàÊûúlinkNLPÊï∞ÊçÆÂ¢ûÂπøËµÑÊ∫êÈõÜgithubÂ∏∏Áî®Ê≠£ÂàôË°®ËææÂºèËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•ÊäΩÂèñemailÁöÑÊ≠£ÂàôË°®ËææÂºèÂ∑≤ÈõÜÊàêÂà∞ python package cocoNLP‰∏≠ÔºåÊ¨¢ËøéËØïÁî®ÊäΩÂèñphone_numberÂ∑≤ÈõÜÊàêÂà∞ python package cocoNLP‰∏≠ÔºåÊ¨¢ËøéËØïÁî®ÊäΩÂèñË∫´‰ªΩËØÅÂè∑ÁöÑÊ≠£ÂàôË°®ËææÂºèIDCards_pattern = r'^([1-9]\\d{5}[12]\\d{3}(0[1-9]|1[012])(0[1-9]|[12][0-9]|3[01])\\d{3}[0-9xX])IDs = re.findall(IDCards_pattern, text, flags=0)IPÂú∞ÂùÄÊ≠£ÂàôË°®ËææÂºè(25[0-5]|  2[0-4]\\d|  [0-1]\\d{2}|  [1-9]?\\d).(25[0-5]|  2[0-4]\\d|  [0-1]\\d{2}|  [1-9]?\\d).(25[0-5]|  2[0-4]\\d|  [0-1]\\d{2}|  [1-9]?\\d).(25[0-5]|  2[0-4]\\d|  [0-1]\\d{2}|  [1-9]?\\d)ËÖæËÆØQQÂè∑Ê≠£ÂàôË°®ËææÂºè[1-9]([0-9]{5,11})ÂõΩÂÜÖÂõ∫ËØùÂè∑Á†ÅÊ≠£ÂàôË°®ËææÂºè[0-9-()ÔºàÔºâ]{7,18}Áî®Êà∑ÂêçÊ≠£ÂàôË°®ËææÂºè[A-Za-z0-9_-\\u4e00-\\u9fa5]+ÂõΩÂÜÖÁîµËØùÂè∑Á†ÅÊ≠£ÂàôÂåπÈÖçÔºà‰∏âÂ§ßËøêËê•ÂïÜ+ËôöÊãüÁ≠âÔºâgithubÊ≠£ÂàôË°®ËææÂºèÊïôÁ®ãgithubÊñáÊú¨Ê£ÄÁ¥¢ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•È´òÊïàÊ®°Á≥äÊêúÁ¥¢Â∑•ÂÖ∑githubÈù¢ÂêëÂêÑËØ≠Áßç/‰ªªÂä°ÁöÑBERTÊ®°ÂûãÂ§ßÂàóË°®/ÊêúÁ¥¢ÂºïÊìélinkDeepmatchÈíàÂØπÊé®Ëçê„ÄÅÂπøÂëäÂíåÊêúÁ¥¢ÁöÑÊ∑±Â∫¶ÂåπÈÖçÊ®°ÂûãÂ∫ìgithubwwsearchÊòØ‰ºÅ‰∏öÂæÆ‰ø°ÂêéÂè∞Ëá™Á†îÁöÑÂÖ®ÊñáÊ£ÄÁ¥¢ÂºïÊìégithubaili - the fastest in-memory index in the East ‰∏úÂçäÁêÉÊúÄÂø´Âπ∂ÂèëÁ¥¢ÂºïgithubÈ´òÊïàÁöÑÂ≠óÁ¨¶‰∏≤ÂåπÈÖçÂ∑•ÂÖ∑ RapidFuzza fast string matching library for Python and C++, which is using the string similarity calculations from FuzzyWuzzygithubÈòÖËØªÁêÜËß£ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•È´òÊïàÊ®°Á≥äÊêúÁ¥¢Â∑•ÂÖ∑githubÈù¢ÂêëÂêÑËØ≠Áßç/‰ªªÂä°ÁöÑBERTÊ®°ÂûãÂ§ßÂàóË°®/ÊêúÁ¥¢ÂºïÊìélinkDeepmatchÈíàÂØπÊé®Ëçê„ÄÅÂπøÂëäÂíåÊêúÁ¥¢ÁöÑÊ∑±Â∫¶ÂåπÈÖçÊ®°ÂûãÂ∫ìgithuballennlpÈòÖËØªÁêÜËß£ÊîØÊåÅÂ§öÁßçÊï∞ÊçÆÂíåÊ®°githubÊÉÖÊÑüÂàÜÊûêËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•ÊñπÈù¢ÊÉÖÊÑüÂàÜÊûêÂåÖgithubawesome-nlp-sentiment-analysisÊÉÖÊÑüÂàÜÊûê„ÄÅÊÉÖÁª™ÂéüÂõ†ËØÜÂà´„ÄÅËØÑ‰ª∑ÂØπË±°ÂíåËØÑ‰ª∑ËØçÊäΩÂèñgithubÊÉÖÊÑüÂàÜÊûêÊäÄÊúØËÆ©Êô∫ËÉΩÂÆ¢ÊúçÊõ¥ÊáÇ‰∫∫Á±ªÊÉÖÊÑügithub‰∫ã‰ª∂ÊäΩÂèñËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•‰∏≠Êñá‰∫ã‰ª∂ÊäΩÂèñgithubNLP‰∫ã‰ª∂ÊèêÂèñÊñáÁåÆËµÑÊ∫êÂàóË°®githubPyTorchÂÆûÁé∞ÁöÑBERT‰∫ã‰ª∂ÊäΩÂèñ(ACE 2005 corpus)githubÊñ∞Èóª‰∫ã‰ª∂Á∫øÁ¥¢ÊäΩÂèñgithubÊú∫Âô®ÁøªËØëËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Êó†ÈÅìËØçÂÖ∏ÊúâÈÅìËØçÂÖ∏ÁöÑÂëΩ‰ª§Ë°åÁâàÊú¨ÔºåÊîØÊåÅËã±Ê±â‰∫íÊü•ÂíåÂú®Á∫øÊü•ËØ¢githubNLLBÊîØÊåÅ200+ÁßçËØ≠Ë®Ä‰ªªÊÑè‰∫íËØëÁöÑËØ≠Ë®ÄÊ®°ÂûãNLLBlinkEasy-TranslateÂú®Êú¨Âú∞ÁøªËØëÂ§ßÊñáÊú¨Êñá‰ª∂ÁöÑËÑöÊú¨ÔºåÂü∫‰∫éFacebook/Meta AIÁöÑ M2M100Ê®°ÂûãÂíåNLLB200Ê®°ÂûãÔºåÊîØÊåÅ200+ÁßçËØ≠Ë®ÄgithubÊï∞Â≠óËΩ¨Êç¢ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•ÊúÄÂ•ΩÁöÑÊ±âÂ≠óÊï∞Â≠ó(‰∏≠ÊñáÊï∞Â≠ó)-ÈòøÊãâ‰ºØÊï∞Â≠óËΩ¨Êç¢Â∑•ÂÖ∑githubÂø´ÈÄüËΩ¨Âåñ„Äå‰∏≠ÊñáÊï∞Â≠ó„ÄçÂíå„ÄåÈòøÊãâ‰ºØÊï∞Â≠ó„ÄçgithubÂ∞ÜËá™ÁÑ∂ËØ≠Ë®ÄÊï∞Â≠ó‰∏≤Ëß£ÊûêËΩ¨Êç¢‰∏∫Êï¥Êï∞ÂíåÊµÆÁÇπÊï∞githubÊåá‰ª£Ê∂àËß£ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•‰∏≠ÊñáÊåá‰ª£Ê∂àËß£Êï∞ÊçÆgithub baidu ink  code a0qqÊñáÊú¨ËÅöÁ±ªËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•TextClusterÁü≠ÊñáÊú¨ËÅöÁ±ªÈ¢ÑÂ§ÑÁêÜÊ®°Âùó Short text clustergithubÊñáÊú¨ÂàÜÁ±ªËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•NeuralNLP-NeuralClassifierËÖæËÆØÂºÄÊ∫êÊ∑±Â∫¶Â≠¶‰π†ÊñáÊú¨ÂàÜÁ±ªÂ∑•ÂÖ∑githubÁü•ËØÜÊé®ÁêÜËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•GraphbrainAIÂºÄÊ∫êËΩØ‰ª∂Â∫ìÂíåÁßëÁ†îÂ∑•ÂÖ∑ÔºåÁõÆÁöÑÊòØ‰øÉËøõËá™Âä®ÊÑè‰πâÊèêÂèñÂíåÊñáÊú¨ÁêÜËß£‰ª•ÂèäÁü•ËØÜÁöÑÊé¢Á¥¢ÂíåÊé®Êñ≠github(Âìà‰Ωõ)ËÆ≤Âõ†ÊûúÊé®ÁêÜÁöÑÂÖçË¥π‰π¶pdfÂèØËß£ÈáäËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•ÊñáÊú¨Êú∫Âô®Â≠¶‰π†Ê®°ÂûãÊúÄÂÖàËøõËß£ÈáäÂô®Â∫ìgithubÊñáÊú¨ÊîªÂáªËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•TextAttackËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊ®°ÂûãÂØπÊäóÊÄßÊîªÂáªÊ°ÜÊû∂githubOpenBackdoor: ÊñáÊú¨ÂêéÈó®ÊîªÈò≤Â∑•ÂÖ∑ÂåÖOpenBackdoorÂü∫‰∫éPythonÂíåPyTorchÂºÄÂèëÔºåÂèØÁî®‰∫éÂ§çÁé∞„ÄÅËØÑ‰º∞ÂíåÂºÄÂèëÊñáÊú¨ÂêéÈó®ÊîªÈò≤ÁöÑÁõ∏ÂÖ≥ÁÆóÊ≥ïgithubÊñáÊú¨ÂèØËßÜÂåñËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Scattertext ÊñáÊú¨ÂèØËßÜÂåñ(python)githubwhatliesËØçÂêëÈáè‰∫§‰∫íÂèØËßÜÂåñspacyÂ∑•ÂÖ∑PySS3Èù¢ÂêëÂèØËß£ÈáäAIÁöÑSS3ÊñáÊú¨ÂàÜÁ±ªÂô®Êú∫Âô®ÂèØËßÜÂåñÂ∑•ÂÖ∑githubÁî®ËÆ∞‰∫ãÊú¨Ê∏≤Êüì3DÂõæÂÉègithubattnvisGPT2„ÄÅBERTÁ≠âtransformerËØ≠Ë®ÄÊ®°ÂûãÊ≥®ÊÑèÂäõ‰∫§‰∫íÂèØËßÜÂåñgithubTextheroÊñáÊú¨Êï∞ÊçÆÈ´òÊïàÂ§ÑÁêÜÂåÖÂåÖÊã¨È¢ÑÂ§ÑÁêÜ„ÄÅÂÖ≥ÈîÆËØçÊèêÂèñ„ÄÅÂëΩÂêçÂÆû‰ΩìËØÜÂà´„ÄÅÂêëÈáèÁ©∫Èó¥ÂàÜÊûê„ÄÅÊñáÊú¨ÂèØËßÜÂåñÁ≠âgithubÊñáÊú¨Ê†áÊ≥®Â∑•ÂÖ∑ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•NLPÊ†áÊ≥®Âπ≥Âè∞ÁªºËø∞githubbrat rapid annotation tool Â∫èÂàóÊ†áÊ≥®Â∑•ÂÖ∑linkPoplarÁΩëÈ°µÁâàËá™ÁÑ∂ËØ≠Ë®ÄÊ†áÊ≥®Â∑•ÂÖ∑githubLIDAËΩªÈáè‰∫§‰∫íÂºèÂØπËØùÊ†áÊ≥®Â∑•ÂÖ∑githubdoccanoÂü∫‰∫éÁΩëÈ°µÁöÑÂºÄÊ∫êÂçèÂêåÂ§öËØ≠Ë®ÄÊñáÊú¨Ê†áÊ≥®Â∑•ÂÖ∑githubDatasaurai Âú®Á∫øÊï∞ÊçÆÊ†áÊ≥®Â∑•‰ΩúÊµÅÁÆ°ÁêÜÂ∑•ÂÖ∑linkËØ≠Ë®ÄÊ£ÄÊµãËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•langid97ÁßçËØ≠Ë®ÄÊ£ÄÊµãhttps://github.com/saffsd/langid.pylangdetectËØ≠Ë®ÄÊ£ÄÊµãhttps://code.google.com/archive/p/language-detection/ÁªºÂêàÂ∑•ÂÖ∑ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•jiebajiebahanlphanlpnlp4han‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•ÂÖ∑ÈõÜ(Êñ≠Âè•/ÂàÜËØç/ËØçÊÄßÊ†áÊ≥®/ÁªÑÂùó/Âè•Ê≥ïÂàÜÊûê/ËØ≠‰πâÂàÜÊûê/NER/NÂÖÉËØ≠Ê≥ï/HMM/‰ª£ËØçÊ∂àËß£/ÊÉÖÊÑüÂàÜÊûê/ÊãºÂÜôÊ£Ägithub‰ªáÊÅ®Ë®ÄËÆ∫Ê£ÄÊµãËøõÂ±ïlinkÂü∫‰∫éPytorchÁöÑBertÂ∫îÁî®ÂåÖÊã¨ÂëΩÂêçÂÆû‰ΩìËØÜÂà´„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅÊñáÊú¨ÂàÜÁ±ª‰ª•ÂèäÊñáÊú¨Áõ∏‰ººÂ∫¶Á≠âgithubnlp4han‰∏≠ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•ÂÖ∑ÈõÜÊñ≠Âè•/ÂàÜËØç/ËØçÊÄßÊ†áÊ≥®/ÁªÑÂùó/Âè•Ê≥ïÂàÜÊûê/ËØ≠‰πâÂàÜÊûê/NER/NÂÖÉËØ≠Ê≥ï/HMM/‰ª£ËØçÊ∂àËß£/ÊÉÖÊÑüÂàÜÊûê/ÊãºÂÜôÊ£ÄÊü•github‰∏Ä‰∫õÂÖ≥‰∫éËá™ÁÑ∂ËØ≠Ë®ÄÁöÑÂü∫Êú¨Ê®°ÂûãgithubÁî®BERTËøõË°åÂ∫èÂàóÊ†áËÆ∞ÂíåÊñáÊú¨ÂàÜÁ±ªÁöÑÊ®°Êùø‰ª£Á†Ågithubjieba_fast Âä†ÈÄüÁâàÁöÑjiebagithubStanfordNLPÁ∫ØPythonÁâàËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂåÖlinkPythonÂè£ËØ≠Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•ÂÖ∑ÈõÜ(Ëã±Êñá)githubPreNLPËá™ÁÑ∂ËØ≠Ë®ÄÈ¢ÑÂ§ÑÁêÜÂ∫ìgithubnlpÁõ∏ÂÖ≥ÁöÑ‰∏Ä‰∫õËÆ∫ÊñáÂèä‰ª£Á†ÅÂåÖÊã¨‰∏ªÈ¢òÊ®°Âûã„ÄÅËØçÂêëÈáè(Word Embedding)„ÄÅÂëΩÂêçÂÆû‰ΩìËØÜÂà´(NER)„ÄÅÊñáÊú¨ÂàÜÁ±ª(Text Classificatin)„ÄÅÊñáÊú¨ÁîüÊàê(Text Generation)„ÄÅÊñáÊú¨Áõ∏‰ººÊÄß(Text Similarity)ËÆ°ÁÆóÁ≠âÔºåÊ∂âÂèäÂà∞ÂêÑÁßç‰∏énlpÁõ∏ÂÖ≥ÁöÑÁÆóÊ≥ïÔºåÂü∫‰∫ékerasÂíåtensorflowgithubPythonÊñáÊú¨ÊåñÊéò/NLPÂÆûÊàòÁ§∫‰æãgithubForteÁÅµÊ¥ªÂº∫Â§ßÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜpipelineÂ∑•ÂÖ∑ÈõÜgithubstanzaÊñØÂù¶Á¶èÂõ¢ÈòüNLPÂ∑•ÂÖ∑ÂèØÂ§ÑÁêÜÂÖ≠ÂçÅÂ§öÁßçËØ≠Ë®ÄgithubFancy-NLPÁî®‰∫éÂª∫ËÆæÂïÜÂìÅÁîªÂÉèÁöÑÊñáÊú¨Áü•ËØÜÊåñÊéòÂ∑•ÂÖ∑githubÂÖ®Èù¢ÁÆÄ‰æøÁöÑ‰∏≠Êñá NLP Â∑•ÂÖ∑ÂåÖgithubÂ∑•‰∏öÁïåÂ∏∏Áî®Âü∫‰∫éDSSMÂêëÈáèÂåñÂè¨ÂõûpipelineÂ§çÁé∞githubTextheroÊñáÊú¨Êï∞ÊçÆÈ´òÊïàÂ§ÑÁêÜÂåÖÂåÖÊã¨È¢ÑÂ§ÑÁêÜ„ÄÅÂÖ≥ÈîÆËØçÊèêÂèñ„ÄÅÂëΩÂêçÂÆû‰ΩìËØÜÂà´„ÄÅÂêëÈáèÁ©∫Èó¥ÂàÜÊûê„ÄÅÊñáÊú¨ÂèØËßÜÂåñÁ≠âgithubnlpgnnÂõæÁ•ûÁªèÁΩëÁªúËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•ÂÖ∑ÁÆ±githubMacadam‰ª•Tensorflow(Keras)Âíåbert4keras‰∏∫Âü∫Á°ÄÔºå‰∏ìÊ≥®‰∫éÊñáÊú¨ÂàÜÁ±ª„ÄÅÂ∫èÂàóÊ†áÊ≥®ÂíåÂÖ≥Á≥ªÊäΩÂèñÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∑•ÂÖ∑ÂåÖgithubLineFlowÈù¢ÂêëÊâÄÊúâÊ∑±Â∫¶Â≠¶‰π†Ê°ÜÊû∂ÁöÑNLPÊï∞ÊçÆÈ´òÊïàÂä†ËΩΩÂô®githubArabicaÔºöPythonÊñáÊú¨Êï∞ÊçÆÊé¢Á¥¢ÊÄßÂàÜÊûêÂ∑•ÂÖ∑ÂåÖgithubPython ÂéãÂäõÊµãËØïÂ∑•ÂÖ∑ÔºöSMSBoomgithubÊúâË∂£ÊêûÁ¨ëÂ∑•ÂÖ∑ËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Ê±™Â≥∞Ê≠åËØçÁîüÊàêÂô®phunterlau/wangfeng-rnnÂ•≥Âèã ÊÉÖÊÑüÊ≥¢Âä®ÂàÜÊûêgithubNLPÂ§™Èöæ‰∫ÜÁ≥ªÂàógithubÂèòÈáèÂëΩÂêçÁ•ûÂô®github linkÂõæÁâáÊñáÂ≠óÂéªÈô§ÔºåÂèØÁî®‰∫éÊº´ÁîªÁøªËØëgithubCoupletAI - ÂØπËÅîÁîüÊàêÂü∫‰∫éCNN+Bi-LSTM+Attention ÁöÑËá™Âä®ÂØπÂØπËÅîÁ≥ªÁªügithubÁî®Á•ûÁªèÁΩëÁªúÁ¨¶Âè∑Êé®ÁêÜÊ±ÇËß£Â§çÊùÇÊï∞Â≠¶ÊñπÁ®ãgithubÂü∫‰∫é14WÊ≠åÊõ≤Áü•ËØÜÂ∫ìÁöÑÈóÆÁ≠îÊú∫Âô®‰∫∫ÂäüËÉΩÂåÖÊã¨Ê≠åËØçÊé•ÈæôÔºåÂ∑≤Áü•Ê≠åËØçÊâæÊ≠åÊõ≤‰ª•ÂèäÊ≠åÊõ≤Ê≠åÊâãÊ≠åËØç‰∏âËßíÂÖ≥Á≥ªÁöÑÈóÆÁ≠îgithubCOPE - Ê†ºÂæãËØóÁºñËæëÁ®ãÂ∫ègithubPaper2GUI‰∏ÄÊ¨æÈù¢ÂêëÊôÆÈÄö‰∫∫ÁöÑAIÊ°åÈù¢APPÂ∑•ÂÖ∑ÁÆ±ÔºåÂÖçÂÆâË£ÖÂç≥ÂºÄÂç≥Áî®ÔºåÂ∑≤ÊîØÊåÅ18+AIÊ®°ÂûãÔºåÂÜÖÂÆπÊ∂µÁõñËØ≠Èü≥ÂêàÊàê„ÄÅËßÜÈ¢ëË°•Â∏ß„ÄÅËßÜÈ¢ëË∂ÖÂàÜ„ÄÅÁõÆÊ†áÊ£ÄÊµã„ÄÅÂõæÁâáÈ£éÊ†ºÂåñ„ÄÅOCRËØÜÂà´Á≠âÈ¢ÜÂüügithubÁ§ºË≤åÁ®ãÂ∫¶‰º∞ÁÆóÂô®Ôºà‰ΩøÁî®Êñ∞Êµ™ÂæÆÂçöÊï∞ÊçÆËÆ≠ÁªÉÔºâgithub paperËçâËüíÔºàPython ‰∏≠ÊñáÁâàÔºâÂÖ•Èó®ÊåáÂçó‰∏≠ÊñáÁºñÁ®ãËØ≠Ë®Ähomepage giteeËØæÁ®ãÊä•ÂëäÈù¢ËØïÁ≠âËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊä•ÂëälinkÁü•ËØÜÂõæË∞±Êä•ÂëälinkÊï∞ÊçÆÊåñÊéòÊä•ÂëälinkËá™Âä®È©æÈ©∂Êä•ÂëälinkÊú∫Âô®ÁøªËØëÊä•ÂëälinkÂå∫ÂùóÈìæÊä•ÂëälinkÊú∫Âô®‰∫∫Êä•ÂëälinkËÆ°ÁÆóÊú∫ÂõæÂΩ¢Â≠¶Êä•Âëälink3DÊâìÂç∞Êä•Âëälink‰∫∫ËÑ∏ËØÜÂà´Êä•Âëälink‰∫∫Â∑•Êô∫ËÉΩËäØÁâáÊä•Âëälinkcs224nÊ∑±Â∫¶Â≠¶‰π†Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜËØæÁ®ãlink ËØæÁ®ã‰∏≠Ê®°ÂûãÁöÑpytorchÂÆûÁé∞ linkÈù¢ÂêëÊ∑±Â∫¶Â≠¶‰π†Á†îÁ©∂‰∫∫ÂëòÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂÆû‰æãÊïôÁ®ãgithub„ÄäNatural Language Processing„Äãby Jacob EisensteingithubML-NLPÊú∫Âô®Â≠¶‰π†(Machine Learning)„ÄÅNLPÈù¢ËØï‰∏≠Â∏∏ËÄÉÂà∞ÁöÑÁü•ËØÜÁÇπÂíå‰ª£Á†ÅÂÆûÁé∞githubNLP‰ªªÂä°Á§∫‰æãÈ°πÁõÆ‰ª£Á†ÅÈõÜgithub2019Âπ¥NLP‰∫ÆÁÇπÂõûÈ°ædownloadnlp-recipesÂæÆËΩØÂá∫ÂìÅ--Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÊúÄ‰Ω≥ÂÆûË∑µÂíåËåÉ‰æãgithubÈù¢ÂêëÊ∑±Â∫¶Â≠¶‰π†Á†îÁ©∂‰∫∫ÂëòÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂÆû‰æãÊïôÁ®ãgithubTransfer Learning in Natural Language Processing (NLP)youtube„ÄäÊú∫Âô®Â≠¶‰π†Á≥ªÁªü„ÄãÂõæ‰π¶link githubÊØîËµõËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•NLPer-ArsenalNLPÁ´ûËµõÔºåÂê´ÂΩìÂâçËµõ‰∫ã‰ø°ÊÅØ„ÄÅËøáÂæÄÁ´ûËµõÊñπÊ°àÁ≠âÔºåÊåÅÁª≠Êõ¥Êñ∞‰∏≠githubÂ§çÁõòÊâÄÊúâNLPÊØîËµõÁöÑTOPÊñπÊ°àgithub2019Âπ¥ÁôæÂ∫¶ÁöÑ‰∏âÂÖÉÁªÑÊäΩÂèñÊØîËµõÔºå‚ÄúÁßëÂ≠¶Á©∫Èó¥Èòü‚ÄùÊ∫êÁ†Å(Á¨¨7Âêç)githubÈáëËûçËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•BDCI2019ÈáëËûçË¥üÈù¢‰ø°ÊÅØÂà§ÂÆögithubÂºÄÊ∫êÁöÑÈáëËûçÊäïËµÑÊï∞ÊçÆÊèêÂèñÂ∑•ÂÖ∑githubÈáëËûçÈ¢ÜÂüüËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁ†îÁ©∂ËµÑÊ∫êÂ§ßÂàóË°®githubÂü∫‰∫éÈáëËûç-Âè∏Ê≥ïÈ¢ÜÂüü(ÂÖºÊúâÈó≤ËÅäÊÄßË¥®)ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫githubÂ∞èÂûãÈáëËûçÁü•ËØÜÂõæË∞±ÊûÑÊµÅÁ®ãÁ§∫ËåÉgithubÂåªÁñóËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•‰∏≠ÊñáÂåªÂ≠¶NLPÂÖ¨ÂºÄËµÑÊ∫êÊï¥ÁêÜgithubspaCy ÂåªÂ≠¶ÊñáÊú¨ÊåñÊéò‰∏é‰ø°ÊÅØÊèêÂèñgithubÊûÑÂª∫ÂåªÁñóÂÆû‰ΩìËØÜÂà´ÁöÑÊ®°ÂûãÂåÖÂê´ËØçÂÖ∏ÂíåËØ≠ÊñôÊ†áÊ≥®ÔºåÂü∫‰∫épythongithubÂü∫‰∫éÂåªÁñóÈ¢ÜÂüüÁü•ËØÜÂõæË∞±ÁöÑÈóÆÁ≠îÁ≥ªÁªügithub ËØ•repoÂèÇËÄÉ‰∫ÜgithubChinese medical dialogue data ‰∏≠ÊñáÂåªÁñóÂØπËØùÊï∞ÊçÆÈõÜgithub‰∏Ä‰∏™Â§ßËßÑÊ®°ÂåªÁñóÂØπËØùÊï∞ÊçÆÈõÜÂåÖÂê´110‰∏áÂåªÂ≠¶Âí®ËØ¢Ôºå400‰∏áÊù°ÂåªÊÇ£ÂØπËØùgithubÊñ∞ÂÜ†ËÇ∫ÁÇéÁõ∏ÂÖ≥Êï∞ÊçÆÊñ∞ÂÜ†ÂèäÂÖ∂‰ªñÁ±ªÂûãËÇ∫ÁÇé‰∏≠ÊñáÂåªÁñóÂØπËØùÊï∞ÊçÆÈõÜÔºõÊ∏ÖÂçéÂ§ßÂ≠¶Á≠âÊú∫ÊûÑÁöÑÂºÄÊîæÊï∞ÊçÆÊ∫êÔºàCOVID-19Ôºâgithub githubÊ≥ïÂæãËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•BlackstoneÈù¢ÂêëÈùûÁªìÊûÑÂåñÊ≥ïÂæãÊñáÊú¨ÁöÑspaCy pipelineÂíåNLPÊ®°ÂûãgithubÊ≥ïÂä°Êô∫ËÉΩÊñáÁåÆËµÑÊ∫êÂàóË°®githubÂü∫‰∫éÈáëËûç-Âè∏Ê≥ïÈ¢ÜÂüü(ÂÖºÊúâÈó≤ËÅäÊÄßË¥®)ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫githubÁΩ™ÂêçÊ≥ïÂä°ÂêçËØçÂèäÂàÜÁ±ªÊ®°ÂûãÂåÖÂê´856È°πÁΩ™ÂêçÁü•ËØÜÂõæË∞±, Âü∫‰∫é280‰∏áÁΩ™ÂêçËÆ≠ÁªÉÂ∫ìÁöÑÁΩ™ÂêçÈ¢ÑÊµã,Âü∫‰∫é20WÊ≥ïÂä°ÈóÆÁ≠îÂØπÁöÑ13Á±ªÈóÆÈ¢òÂàÜÁ±ª‰∏éÊ≥ïÂæãËµÑËÆØÈóÆÁ≠îÂäüËÉΩgithubÊ≥ïÂæãNLPÁõ∏ÂÖ≥ËµÑÊ∫êÂ§ßÂàóË°®githubÊñáÊú¨ÁîüÊàêÂõæÂÉèËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•Dalle-miniÊ†πÊçÆÊñáÊú¨ÊèêÁ§∫ÁîüÊàêÂõæÁâáÁöÑËø∑‰Ω†ÁâàDALL¬∑EgithubÂÖ∂‰ªñËµÑÊ∫êÂêçÔºàNameÔºâÊèèËø∞ÔºàDescriptionÔºâÈìæÊé•phone‰∏≠ÂõΩÊâãÊú∫ÂΩíÂ±ûÂú∞Êü•ËØ¢ls0f/phonephoneÂõΩÈôÖÊâãÊú∫„ÄÅÁîµËØùÂΩíÂ±ûÂú∞Êü•ËØ¢AfterShip/phonengenderÊ†πÊçÆÂêçÂ≠óÂà§Êñ≠ÊÄßÂà´observerss/ngender‰∏≠ÊñáÂØπÊØîËã±ÊñáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜNLPÁöÑÂå∫Âà´ÁªºËø∞linkÂêÑÂ§ßÂÖ¨Âè∏ÂÜÖÈÉ®ÈáåÂ§ßÁâõÂàÜ‰∫´ÁöÑÊäÄÊúØÊñáÊ°£ PDF ÊàñËÄÖ PPTgithubcomparxiv Áî®‰∫éÊØîËæÉarXiv‰∏ä‰∏§Êèê‰∫§ÁâàÊú¨Â∑ÆÂºÇÁöÑÂëΩ‰ª§pypiCHAMELEONÊ∑±Â∫¶Â≠¶‰π†Êñ∞ÈóªÊé®ËçêÁ≥ªÁªüÂÖÉÊû∂ÊûÑgithubÁÆÄÂéÜËá™Âä®Á≠õÈÄâÁ≥ªÁªügithubPythonÂÆûÁé∞ÁöÑÂ§öÁßçÊñáÊú¨ÂèØËØªÊÄßËØÑ‰ª∑ÊåáÊ†ágithub"
77,testerSunshine/12306,https://github.com/testerSunshine/12306/blob/master/README.md,Python,"12306 Ë¥≠Á•®Â∞èÂä©ÊâãpythonÁâàÊú¨ 2.7.10 - 2.7.15 3.6 - 3.7.4 2.7.9Â∑≤ÊúâÂäüËÉΩ Ëá™Âä®ÊâìÁ†Å Ëá™Âä®ÁôªÂΩï ÂáÜÁÇπÈ¢ÑÂîÆÂíåÊç°Êºè Êô∫ËÉΩÂÄôË°• ÈÇÆ‰ª∂ÈÄöÁü• serverÈÖ±ÈÄöÁü•‰æùËµñÂ∫ìÈ™åËØÅÁ†ÅÁõÆÂâçÂèØ‰ª•Êú¨Âú∞ËØÜÂà´ÔºåÈúÄË¶Å‰∏ãËΩΩÊ®°ÂûãÔºåÊîæ‰∫éÈ°πÁõÆÊ†πÁõÆÂΩïÔºåÂÖ®ÈÉ®‰ª£Á†ÅÊù•Ê∫ê‰∫éÊ≠§È°πÁõÆ ‰º†ÈÄÅÈó®ÔºåË°®Á§∫ÊÑüË∞¢  1. Ê®°Âûã‰∏ãËΩΩÈìæÊé•:https://pan.baidu.com/s/1rS155VjweWVWIJogakechA  ÂØÜÁ†Å:bmlm     Áæ§ÈáåÈù¢‰πüÂèØ‰ª•‰∏ãËΩΩ  2. git‰ªìÂ∫ì‰∏ãËΩΩÔºöhttps://github.com/testerSunshine/12306model.gitËá™ÊâòÁÆ°‰∫ëÊâìÁ†ÅÊúçÂä°Âô®Êê≠Âª∫Ôºö12306_code_serverÂ¶ÇÊûúÂ§ßÂÆ∂ÊúâÁ©∫Èó≤ÁöÑÊúçÂä°Âô®ÔºåÂèØÊê≠Âª∫‰πãÂêéÂú®Ëøô‰∏™ issues ÈáåÈù¢Â°´ÂÖ•Ëá™Â∑±ÁöÑÊúçÂä°Âô®(ËØ∑Ê≥®ÊÑèÊúçÂä°Âô®ÂÆâÂÖ®ÔºÅ)È°πÁõÆ‰æùËµñ requirements.txtÂÆâË£ÖÊñπÊ≥ïx:rootÁî®Êà∑(ÈÅøÂÖçÂ§öpythonÁéØÂ¢É‰∫ßÁîüÈóÆÈ¢ò): pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txtÈùûrootÁî®Êà∑ÔºàÈÅøÂÖçÂÆâË£ÖÂíåËøêË°åÊó∂‰ΩøÁî®‰∫Ü‰∏çÂêåÁéØÂ¢ÉÔºâ: pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txtËÆ∏Â§öwindowsÁöÑÁî®Êà∑Ë£Ö‰∏ç‰∫ÜtensorflowÁöÑËØùÔºåÂèØ‰ª•ÈÄÇÂΩìÈôç‰ΩéÁâàÊú¨ÊàñËÄÖÂçáÈ´òÁâàÊú¨ÈÉΩÊòØÂèØ‰ª•ÁöÑ1. tensorflowÁöÑÂÖºÂÆπÁâàÊú¨ 1.14.0rc\\1.14.0rc\\1.15.0\\1.15.0rc‰ª•‰∏äÁâàÊú¨ÈÉΩÊµãËØïÊó†ÈóÆÈ¢ò2. Â¶ÇÊûúpip‰ª£ÁêÜÁöÑÊ∏ÖÂçéÊ∫êÊó†Ê≥ï‰∏ãËΩΩÔºåÂèØ‰ª•Êõ¥Êç¢ÂÖ∂‰ªñÊ∫êËß£ÂÜ≥Ê≠§ÈóÆÈ¢òÈ°πÁõÆ‰ΩøÁî®ËØ¥ÊòéÊúçÂä°Âô®ÂêØÂä®:‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂ÂèØ‰ª•ÈÖçÁΩÆÈÇÆÁÆ±,ÈÖçÁΩÆÈÇÆÁÆ±ÁöÑÊ†ºÂºèÂú®ÈÖçÁΩÆÈáåÈù¢ÂèØ‰ª•ÁúãÂà∞ex# ÊµãËØïÈÇÆÁÆ±ÂíåserverÈÖ±ÊòØÂê¶ÂèØÁî®Ôºå serverÈÖ±ÊµãËØïÁöÑÂâçÊèêÊòØserverÈÖ±ÂºÄÂÖ≥ÂºÄÂêØ# ÂèØ‰ª•ÈÖçÁΩÆserverÈÖ±ÊèêÈÜíÔºàÊé®ËçêÔºâ[ÈÖçÁΩÆÊïôÁ®ã](https://www.jianshu.com/p/8d10b5b9c4e3)# Áî®python3 ËøòÊòØpython ÂÆåÂÖ®ÂèñÂÜ≥‰∫éÂÆâË£ÖÁöÑÊó∂ÂÄôÈÖçÁΩÆÁöÑÁéØÂ¢ÉÂèòÈáèÊòØÂê¶‰∏∫python3,‰ª•‰∏ãÂêØÂä®ÈªòËÆ§ÁéØÂ¢ÉÂèòÈáè‰∏∫python3python3 run.py tÈÖçÁΩÆÈÖçÁΩÆÊñá‰ª∂ÁöÑÊó∂ÂÄôÔºåÈúÄÊ≥®ÊÑèÁ©∫Ê†ºÂíåÈÅµÂæ™pythonËØ≠Ê≥ïÊ†ºÂºèÂêØÂä®ÂâçËØ∑ÂÖàÁ≠õÈÄâcdnÔºåËøôÁÇπÂæàÈáçË¶Åpython3 run.py cÂêØÂä®ÊúçÂä°python3 run.py rÂ¶ÇÊûú‰Ω†‰∏çÁü•ÈÅìÂ¶Ç‰ΩïÊìç‰ΩúÔºå‰∏ãÈù¢ÁöÑÂëΩ‰ª§ÂèØËÉΩ‰ºöÂ∏ÆÂä©‰Ω†python3 run.py -h‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äîsage: run.py [-h] operatepositional arguments:  operate     r: ËøêË°åÊä¢Á•®Á®ãÂ∫è, c: ËøáÊª§cdn, t: ÊµãËØïÈÇÆÁÆ±ÂíåserverÈÖ±ÔºåserverÈÖ±Â¶ÇÊûú‰Ω†ÁöÑÊúçÂä°Âô®ÂÆâË£Ö‰∫Üdocker‰∏édocker-compose, ÈÇ£‰πà‰Ω†ÂèØ‰ª•ÂøΩÁï•‰∏äÈù¢ÁöÑÊâÄÊúâÊ≠•È™§ÔºåÁõ¥Êé•Êåâ‰ª•‰∏ãÊ≠•È™§Êìç‰ΩúÔºåÂç≥ÂèØÂºÄÂßãÊä¢Á•®ÔºöÂâçÊèêÊù°‰ª∂:ËØ∑Á°ÆËÆ§‰Ω†ÂÆâË£ÖÁöÑdockerÁâàÊú¨‰∏∫18.09Âèä‰ª•‰∏ä: docker -vËØ∑Á°ÆËÆ§‰Ω†ÂÆâË£ÖÁöÑdocker-composeÁâàÊú¨‰∏∫1.23.2Âèä‰ª•‰∏ä: docker-compose -vËØ∑Ê†πÊçÆËá™Â∑±ÈúÄË¶Å‰øÆÊîπÂ•ΩÈÖçÁΩÆÊñá‰ª∂:TickerConfig.pyËØ∑‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂TickerConfig.py‰∏≠ÁöÑÂèòÈáèAUTO_CODE_TYPEÂíåHOSTÔºåAUTO_CODE_TYPEÊîπ‰∏∫3, HOSTÊîπ‰∏∫\""captcha:80\""ÔºàËøôÈáåÂæàÈáçË¶ÅÔºåËøôÊòØÊú¨Âú∞ÊâìÁ†ÅÊúçÂä°Âô®ÁöÑÈÖçÁΩÆÔºâËøêË°åÂëΩ‰ª§:ÂºÄÂßãÊä¢Á•®Ôºödocker-compose up --build -dÂÅúÊ≠¢Êä¢Á•®Ôºödocker-compose downÊü•ÁúãÊä¢Á•®log: docker logs --follow ticketÁõÆÂΩïÂØπÂ∫îËØ¥Êòéagency - cdn‰ª£ÁêÜconfig - È°πÁõÆÈÖçÁΩÆverify - Ëá™Âä®ÊâìÁ†Åinit - È°πÁõÆ‰∏ªËøêË°åÁõÆÂΩïinter - Êé•Âè£myException - ÂºÇÂ∏∏myUrllib  requestÁΩëÁªúËØ∑Ê±ÇÂ∫ìÊÄùË∑ØÂõæÈ°πÁõÆÂ£∞ÊòéÔºöÊú¨ËΩØ‰ª∂Âè™‰æõÂ≠¶‰π†‰∫§ÊµÅ‰ΩøÁî®ÔºåÂãø‰Ωú‰∏∫ÂïÜ‰∏öÁî®ÈÄîÔºå‰∫§ÊµÅÁæ§Âè∑1Áæ§Ôºö286271084(Â∑≤Êª°)2Áæ§Ôºö649992274(Â∑≤Êª°)3Áæ§Ôºö632501142(Â∑≤Êª°)4Áæ§: 606340519(Â∑≤Êª°)5Áæ§: 948526733(Â∑≤Êª°)7Áæ§: 660689659(Â∑≤Êª°)8Áæ§: 620629239(Â∑≤Êª°)6Áæ§: 608792930(Êú™Êª°)9Áæ§: 693035807(Êú™Êª°)ËØ∑‰∏çË¶ÅÈáçÂ§çÂä†Áæ§Ôºå‰∏Ä‰∏™Áæ§Â∞±ÂèØ‰ª•‰∫ÜÔºåÊääÊú∫‰ºöÁïôÁªôÊõ¥Â§ö‰∫∫ËøõÁæ§ÂÖàÁúãÂÖ¨ÂëäÔºÅÔºÅÔºÅËøõÁæ§ÂÖàÁúãÂÖ¨ÂëäÔºÅÔºÅÔºÅËøõÁæ§ÂÖàÁúãÂÖ¨ÂëäÔºÅÔºÅÔºÅ ÈáçË¶ÅÁöÑ‰∫ãÊÉÖËØ¥‰∏âÈÅçËÉΩ‰∏∫‰Ω†Êä¢Âà∞‰∏ÄÂº†ÂõûÂÆ∂ÁöÑÁ•®ÔºåÊòØÊàëÊúÄÂ§ßÁöÑÂøÉÊÑøÊó•ÂøóÂàóÂ≠êÊàêÂäülogÔºåÂ¶ÇÊûúÊòØË¥≠Á•®Â§±Ë¥•ÁöÑÔºåËØ∑Â∏¶‰∏äÂ§±Ë¥•ÁöÑlogÁªôÊàëÔºåÊàëÂ∞ΩÂäõÂ∏Æ‰Ω†Ë∞ÉÔºå‰πüÂèØÂä†Áæ§‰∏ÄËµ∑‰∫§ÊµÅÔºåÁ®ãÂ∫èÂè™ÊòØÂä†ÈÄü‰π∞Á•®ÁöÑËøáÁ®ãÔºåÂπ∂‰∏ç‰∏ÄÂÆöËÉΩ‰π∞Âà∞Á•®Ê≠£Âú®Á¨¨355Ê¨°Êü•ËØ¢  ‰πòËΩ¶Êó•Êúü: 2018-02-12  ËΩ¶Ê¨°G4741,G2365,G1371,G1377,G1329 Êü•ËØ¢Êó†Á•®  ‰ª£ÁêÜËÆæÁΩÆ Êó†  ÊÄªËÄóÊó∂429msËΩ¶Ê¨°: G4741 ÂßãÂèëËΩ¶Á´ô: ‰∏äÊµ∑ ÁªàÁÇπÁ´ô: ÈÇµÈò≥ ‰∫åÁ≠âÂ∫ß:ÊúâÊ≠£Âú®Â∞ùËØïÊèê‰∫§ËÆ¢Á•®...Â∞ùËØïÊèê‰∫§ËÆ¢Âçï...Âá∫Á•®ÊàêÂäüÊéíÈòüÊàêÂäü, ÂΩìÂâç‰ΩôÁ•®ËøòÂâ©‰Ωô: 359 Âº†Ê≠£Âú®‰ΩøÁî®Ëá™Âä®ËØÜÂà´È™åËØÅÁ†ÅÂäüËÉΩÈ™åËØÅÁ†ÅÈÄöËøá,Ê≠£Âú®Êèê‰∫§ËÆ¢ÂçïÊèê‰∫§ËÆ¢ÂçïÊàêÂäüÔºÅÊéíÈòüÁ≠âÂæÖÊó∂Èó¥È¢ÑËÆ°ËøòÂâ© -12 msÊéíÈòüÁ≠âÂæÖÊó∂Èó¥È¢ÑËÆ°ËøòÂâ© -6 msÊéíÈòüÁ≠âÂæÖÊó∂Èó¥È¢ÑËÆ°ËøòÂâ© -7 msÊéíÈòüÁ≠âÂæÖÊó∂Èó¥È¢ÑËÆ°ËøòÂâ© -4 msÊéíÈòüÁ≠âÂæÖÊó∂Èó¥È¢ÑËÆ°ËøòÂâ© -4 msÊÅ≠ÂñúÊÇ®ËÆ¢Á•®ÊàêÂäüÔºåËÆ¢ÂçïÂè∑‰∏∫ÔºöEB52743573, ËØ∑Á´ãÂç≥ÊâìÂºÄÊµèËßàÂô®ÁôªÂΩï12306ÔºåËÆøÈóÆ‚ÄòÊú™ÂÆåÊàêËÆ¢Âçï‚ÄôÔºåÂú®30ÂàÜÈíüÂÜÖÂÆåÊàêÊîØ‰ªòÔºÅ‰ΩøÁî®Â∏ÆÂä©(‰∏Ä‰∫õÂÆâË£ÖÈóÆÈ¢òÂíå‰ΩøÁî®ÂèçÈ¶àËæÉÂ§öÁöÑÈóÆÈ¢ò)ÔºöÊµãËØïÈÇÆÁÆ±ÊòØÂê¶ÂèØÁî® ÈÇÆÁÆ±ÈÖçÁΩÆÈóÆÈ¢òÁúãissuesÂ≠¶ÁîüÁ•®issues Â≠¶ÁîüÁ•®‰øÆÊîπ‰æùËµñÂÆâË£Ö‰∏çÂØπÁöÑÈóÆÈ¢òÔºàImportErrorÔºârequirements.txtÈóÆÈ¢òËã•Âø´Ë±ÜÂ≠êÁñëÈóÆ ÁÇπÊàëIOError: „ÄêErrno 0„Äë Error ÈóÆÈ¢ò ÁÇπÊàëÊµãËØï‰∏ãÂçïÊé•Âè£ÊòØÂê¶ÂèØÁî®ÔºåÊúâ‰∏§‰∏™‰∏ãÂçïÊé•Âè£ÔºåÈöè‰æøÁî®Âì™‰∏™ÈÉΩokÂ¶ÇÊûú‰∏ãËΩΩÈ™åËØÅÁ†ÅËøáÊúüÊàñËÄÖ‰∏ãËΩΩÂ§±Ë¥•ÁöÑÈóÆÈ¢òÔºåÂ∫îËØ•ÊòØ12306Â∞ÅipÁöÑÁ≠ñÁï•ÔºåÂ§öÈáçËØïÂá†Ê¨°Ôºå12306Áé∞Âú®Â∞ÅÊúçÂä°Âô®(ÈòøÈáå‰∫ëÂíåËÖæËÆØ‰∫ë)ipÊØîËæÉ‰∏•ÈáçÔºåÂ∞ΩÈáè‰∏çË¶ÅÊîæÂú®ÊúçÂä°Âô®ÈáåÈù¢ÁõÆÂâç12306ÂØπÊúçÂä°Âô®ipÊØîËæÉÊïèÊÑüÔºåÂ§ßÂÆ∂ËøòÊòØÂú®Ëá™Â∑±ÂÆ∂ÈáåÊåÇÁùÄÂêßËá™Âä®Êõ¥Êç¢ipËΩØ‰ª∂ÁõÆÂâçÂ∑≤ÊîØÊåÅTPLINKÂíåÂ∞èÁ±≥Ë∑ØÁî±Âô®ÔºåÂè™ÈôêÂÆ∂Â∫≠ÁΩëÁªúÁÇπÊàëË∑≥ËΩ¨ÊÑüË∞¢‰∏Ä‰∏ãÂ∞è‰ºô‰º¥ÂØπÊú¨È°πÁõÆÊèê‰æõÁöÑÂ∏ÆÂä©@sun7127@126.com@ Êâç@MonsterTan‰ª•ÂèäÊâÄÊúâ‰∏∫Ê≠§È°πÁõÆÊèê‰æõprÁöÑÂêåÂ≠¶Êõ¥Êñ∞Êó•ÂøóÊõ¥Êñ∞Êó•Âøó"
78,google-research/bert,https://github.com/google-research/bert/blob/master/README.md,Python,"BERT***** New March 11th, 2020: Smaller BERT Models *****This is a release of 24 smaller BERT models (English only, uncased, trained with WordPiece masking) referenced in Well-Read Students Learn Better: On the Importance of Pre-training Compact Models.We have shown that the standard BERT recipe (including model architecture and training objective) is effective on a wide range of model sizes, beyond BERT-Base and BERT-Large. The smaller BERT models are intended for environments with restricted computational resources. They can be fine-tuned in the same manner as the original BERT models. However, they are most effective in the context of knowledge distillation, where the fine-tuning labels are produced by a larger and more accurate teacher.Our goal is to enable research in institutions with fewer computational resources and encourage the community to seek directions of innovation alternative to increasing model capacity.You can download all 24 from here, or individually from the table below:H=128H=256H=512H=768L=22/128 (BERT-Tiny)2/2562/5122/768L=44/1284/256 (BERT-Mini)4/512 (BERT-Small)4/768L=66/1286/2566/5126/768L=88/1288/2568/512 (BERT-Medium)8/768L=1010/12810/25610/51210/768L=1212/12812/25612/51212/768 (BERT-Base)Note that the BERT-Base model in this release is included for completeness only; it was re-trained under the same regime as the original model.Here are the corresponding GLUE scores on the test set:ModelScoreCoLASST-2MRPCSTS-BQQPMNLI-mMNLI-mmQNLI(v2)RTEWNLIAXBERT-Tiny64.20.083.281.1/71.174.3/73.662.2/83.470.270.381.557.262.321.0BERT-Mini65.80.085.981.1/71.875.4/73.366.4/86.274.874.384.157.962.326.1BERT-Small71.227.889.783.4/76.278.8/77.068.1/87.077.677.086.461.862.328.6BERT-Medium73.538.089.686.6/81.680.4/78.469.6/87.980.079.187.762.262.330.5For each task, we selected the best fine-tuning hyperparameters from the lists below, and trained for 4 epochs:batch sizes: 8, 16, 32, 64, 128learning rates: 3e-4, 1e-4, 5e-5, 3e-5If you use these models, please cite the following paper:@article{turc2019,  title={Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},  journal={arXiv preprint arXiv:1908.08962v2 },  year={2019}}***** New May 31st, 2019: Whole Word Masking Models *****This is a release of several new models which were the result of an improvementthe pre-processing code.In the original pre-processing code, we randomly select WordPiece tokens tomask. For example:Input Text: the man jumped up , put his basket on phil ##am ##mon ' s headOriginal Masked Input: [MASK] man [MASK] up , put his [MASK] on phil [MASK] ##mon ' s headThe new technique is called Whole Word Masking. In this case, we always maskall of the the tokens corresponding to a word at once. The overall maskingrate remains the same.Whole Word Masked Input: the man [MASK] up , put his basket on [MASK] [MASK] [MASK] ' s headThe training is identical -- we still predict each masked WordPiece tokenindependently. The improvement comes from the fact that the original predictiontask was too 'easy' for words that had been split into multiple WordPieces.This can be enabled during data generation by passing the flag--do_whole_word_mask=True to create_pretraining_data.py.Pre-trained models with Whole Word Masking are linked below. The data andtraining were otherwise identical, and the models have identical structure andvocab to the original models. We only include BERT-Large models. When usingthese models, please make it clear in the paper that you are using the WholeWord Masking variant of BERT-Large.BERT-Large, Uncased (Whole Word Masking):24-layer, 1024-hidden, 16-heads, 340M parametersBERT-Large, Cased (Whole Word Masking):24-layer, 1024-hidden, 16-heads, 340M parametersModelSQUAD 1.1 F1/EMMulti NLI AccuracyBERT-Large, Uncased (Original)91.0/84.386.05BERT-Large, Uncased (Whole Word Masking)92.8/86.787.07BERT-Large, Cased (Original)91.5/84.886.09BERT-Large, Cased (Whole Word Masking)92.9/86.786.46***** New February 7th, 2019: TfHub Module *****BERT has been uploaded to TensorFlow Hub. Seerun_classifier_with_tfhub.py for an example of how to use the TF Hub module,or run an example in the browser onColab.***** New November 23rd, 2018: Un-normalized multilingual model + Thai +Mongolian *****We uploaded a new multilingual model which does not perform any normalizationon the input (no lower casing, accent stripping, or Unicode normalization), andadditionally inclues Thai and Mongolian.It is recommended to use this version for developing multilingual models,especially on languages with non-Latin alphabets.This does not require any code changes, and can be downloaded here:BERT-Base, Multilingual Cased:104 languages, 12-layer, 768-hidden, 12-heads, 110M parameters***** New November 15th, 2018: SOTA SQuAD 2.0 System *****We released code changes to reproduce our 83% F1 SQuAD 2.0 system, which iscurrently 1st place on the leaderboard by 3%. See the SQuAD 2.0 section of theREADME for details.***** New November 5th, 2018: Third-party PyTorch and Chainer versions ofBERT available *****NLP researchers from HuggingFace made aPyTorch version of BERT availablewhich is compatible with our pre-trained checkpoints and is able to reproduceour results. Sosuke Kobayashi also made aChainer version of BERT available(Thanks!) We were not involved in the creation or maintenance of the PyTorchimplementation so please direct any questions towards the authors of thatrepository.***** New November 3rd, 2018: Multilingual and Chinese models available*****We have made two new BERT models available:BERT-Base, Multilingual(Not recommended, use Multilingual Cased instead): 102 languages,12-layer, 768-hidden, 12-heads, 110M parametersBERT-Base, Chinese:Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110MparametersWe use character-based tokenization for Chinese, and WordPiece tokenization forall other languages. Both models should work out-of-the-box without any codechanges. We did update the implementation of BasicTokenizer intokenization.py to support Chinese character tokenization, so please update ifyou forked it. However, we did not change the tokenization API.For more, see theMultilingual README.***** End new information *****IntroductionBERT, or Bidirectional Encoder Representations fromTransformers, is a new method of pre-training language representations whichobtains state-of-the-art results on a wide array of Natural Language Processing(NLP) tasks.Our academic paper which describes BERT in detail and provides full results on anumber of tasks can be found here:https://arxiv.org/abs/1810.04805.To give a few numbers, here are the results on theSQuAD v1.1 question answeringtask:SQuAD v1.1 Leaderboard (Oct 8th 2018)Test EMTest F11st Place Ensemble - BERT87.493.22nd Place Ensemble - nlnet86.091.71st Place Single Model - BERT85.191.82nd Place Single Model - nlnet83.590.1And several natural language inference tasks:SystemMultiNLIQuestion NLISWAGBERT86.791.186.3OpenAI GPT (Prev. SOTA)82.288.175.0Plus many other tasks.Moreover, these results were all obtained with almost no task-specific neuralnetwork architecture design.If you already know what BERT is and you just want to get started, you candownload the pre-trained models andrun a state-of-the-art fine-tuning in only a fewminutes.What is BERT?BERT is a method of pre-training language representations, meaning that we traina general-purpose \""language understanding\"" model on a large text corpus (likeWikipedia), and then use that model for downstream NLP tasks that we care about(like question answering). BERT outperforms previous methods because it is thefirst unsupervised, deeply bidirectional system for pre-training NLP.Unsupervised means that BERT was trained using only a plain text corpus, whichis important because an enormous amount of plain text data is publicly availableon the web in many languages.Pre-trained representations can also either be context-free or contextual,and contextual representations can further be unidirectional orbidirectional. Context-free models such asword2vec orGloVe generate a single \""wordembedding\"" representation for each word in the vocabulary, so bank would havethe same representation in bank deposit and river bank. Contextual modelsinstead generate a representation of each word that is based on the other wordsin the sentence.BERT was built upon recent work in pre-training contextual representations ‚Äîincluding Semi-supervised Sequence Learning,Generative Pre-Training,ELMo, andULMFit‚Äî but crucially these models are all unidirectional or shallowlybidirectional. This means that each word is only contextualized using the wordsto its left (or right). For example, in the sentence I made a bank deposit theunidirectional representation of bank is only based on I made a but notdeposit. Some previous work does combine the representations from separateleft-context and right-context models, but only in a \""shallow\"" manner. BERTrepresents \""bank\"" using both its left and right context ‚Äî I made a ... deposit‚Äî starting from the very bottom of a deep neural network, so it is deeplybidirectional.BERT uses a simple approach for this: We mask out 15% of the words in the input,run the entire sequence through a deep bidirectionalTransformer encoder, and then predict onlythe masked words. For example:Input: the man went to the [MASK1] . he bought a [MASK2] of milk.Labels: [MASK1] = store; [MASK2] = gallonIn order to learn relationships between sentences, we also train on a simpletask which can be generated from any monolingual corpus: Given two sentences Aand B, is B the actual next sentence that comes after A, or just a randomsentence from the corpus?Sentence A: the man went to the store .Sentence B: he bought a gallon of milk .Label: IsNextSentenceSentence A: the man went to the store .Sentence B: penguins are flightless .Label: NotNextSentenceWe then train a large model (12-layer to 24-layer Transformer) on a large corpus(Wikipedia + BookCorpus) for a long time (1Mupdate steps), and that's BERT.Using BERT has two stages: Pre-training and fine-tuning.Pre-training is fairly expensive (four days on 4 to 16 Cloud TPUs), but is aone-time procedure for each language (current models are English-only, butmultilingual models will be released in the near future). We are releasing anumber of pre-trained models from the paper which were pre-trained at Google.Most NLP researchers will never need to pre-train their own model from scratch.Fine-tuning is inexpensive. All of the results in the paper can bereplicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU,starting from the exact same pre-trained model. SQuAD, for example, can betrained in around 30 minutes on a single Cloud TPU to achieve a Dev F1 score of91.0%, which is the single system state-of-the-art.The other important aspect of BERT is that it can be adapted to many types ofNLP tasks very easily. In the paper, we demonstrate state-of-the-art results onsentence-level (e.g., SST-2), sentence-pair-level (e.g., MultiNLI), word-level(e.g., NER), and span-level (e.g., SQuAD) tasks with almost no task-specificmodifications.What has been released in this repository?We are releasing the following:TensorFlow code for the BERT model architecture (which is mostly a standardTransformer architecture).Pre-trained checkpoints for both the lowercase and cased version ofBERT-Base and BERT-Large from the paper.TensorFlow code for push-button replication of the most importantfine-tuning experiments from the paper, including SQuAD, MultiNLI, and MRPC.All of the code in this repository works out-of-the-box with CPU, GPU, and CloudTPU.Pre-trained modelsWe are releasing the BERT-Base and BERT-Large models from the paper.Uncased means that the text has been lowercased before WordPiece tokenization,e.g., John Smith becomes john smith. The Uncased model also strips out anyaccent markers. Cased means that the true case and accent markers arepreserved. Typically, the Uncased model is better unless you know that caseinformation is important for your task (e.g., Named Entity Recognition orPart-of-Speech tagging).These models are all released under the same license as the source code (Apache2.0).For information about the Multilingual and Chinese model, see theMultilingual README.When using a cased model, make sure to pass --do_lower=False to the trainingscripts. (Or pass do_lower_case=False directly to FullTokenizer if you'reusing your own script.)The links to the models are here (right-click, 'Save link as...' on the name):BERT-Large, Uncased (Whole Word Masking):24-layer, 1024-hidden, 16-heads, 340M parametersBERT-Large, Cased (Whole Word Masking):24-layer, 1024-hidden, 16-heads, 340M parametersBERT-Base, Uncased:12-layer, 768-hidden, 12-heads, 110M parametersBERT-Large, Uncased:24-layer, 1024-hidden, 16-heads, 340M parametersBERT-Base, Cased:12-layer, 768-hidden, 12-heads , 110M parametersBERT-Large, Cased:24-layer, 1024-hidden, 16-heads, 340M parametersBERT-Base, Multilingual Cased (New, recommended):104 languages, 12-layer, 768-hidden, 12-heads, 110M parametersBERT-Base, Multilingual Uncased (Orig, not recommended)(Not recommended, use Multilingual Cased instead): 102 languages,12-layer, 768-hidden, 12-heads, 110M parametersBERT-Base, Chinese:Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110MparametersEach .zip file contains three items:A TensorFlow checkpoint (bert_model.ckpt) containing the pre-trainedweights (which is actually 3 files).A vocab file (vocab.txt) to map WordPiece to word id.A config file (bert_config.json) which specifies the hyperparameters ofthe model.Fine-tuning with BERTImportant: All results on the paper were fine-tuned on a single Cloud TPU,which has 64GB of RAM. It is currently not possible to re-produce most of theBERT-Large results on the paper using a GPU with 12GB - 16GB of RAM, becausethe maximum batch size that can fit in memory is too small. We are working onadding code to this repository which allows for much larger effective batch sizeon the GPU. See the section on out-of-memory issues formore details.This code was tested with TensorFlow 1.11.0. It was tested with Python2 andPython3 (but more thoroughly with Python2, since this is what's used internallyin Google).The fine-tuning examples which use BERT-Base should be able to run on a GPUthat has at least 12GB of RAM using the hyperparameters given.Fine-tuning with Cloud TPUsMost of the examples below assumes that you will be running training/evaluationon your local machine, using a GPU like a Titan X or GTX 1080.However, if you have access to a Cloud TPU that you want to train on, just addthe following flags to run_classifier.py or run_squad.py:  --use_tpu=True \\  --tpu_name=$TPU_NAMEPlease see theGoogle Cloud TPU tutorialfor how to use Cloud TPUs. Alternatively, you can use the Google Colab notebook\""BERT FineTuning with Cloud TPUs\"".On Cloud TPUs, the pretrained model and the output directory will need to be onGoogle Cloud Storage. For example, if you have a bucket named some_bucket, youmight use the following flags instead:  --output_dir=gs://some_bucket/my_output_dir/The unzipped pre-trained model files can also be found in the Google CloudStorage folder gs://bert_models/2018_10_18. For example:export BERT_BASE_DIR=gs://bert_models/2018_10_18/uncased_L-12_H-768_A-12Sentence (and sentence-pair) classification tasksBefore running this example you must download theGLUE data by runningthis scriptand unpack it to some directory $GLUE_DIR. Next, download the BERT-Basecheckpoint and unzip it to some directory $BERT_BASE_DIR.This example code fine-tunes BERT-Base on the Microsoft Research ParaphraseCorpus (MRPC) corpus, which only contains 3,600 examples and can fine-tune in afew minutes on most GPUs.export BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12export GLUE_DIR=/path/to/gluepython run_classifier.py \\  --task_name=MRPC \\  --do_train=true \\  --do_eval=true \\  --data_dir=$GLUE_DIR/MRPC \\  --vocab_file=$BERT_BASE_DIR/vocab.txt \\  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\  --max_seq_length=128 \\  --train_batch_size=32 \\  --learning_rate=2e-5 \\  --num_train_epochs=3.0 \\  --output_dir=/tmp/mrpc_output/You should see output like this:***** Eval results *****  eval_accuracy = 0.845588  eval_loss = 0.505248  global_step = 343  loss = 0.505248This means that the Dev set accuracy was 84.55%. Small sets like MRPC have ahigh variance in the Dev set accuracy, even when starting from the samepre-training checkpoint. If you re-run multiple times (making sure to point todifferent output_dir), you should see results between 84% and 88%.A few other pre-trained models are implemented off-the-shelf inrun_classifier.py, so it should be straightforward to follow those examples touse BERT for any single-sentence or sentence-pair classification task.Note: You might see a message Running train on CPU. This really just meansthat it's running on something other than a Cloud TPU, which includes a GPU.Prediction from classifierOnce you have trained your classifier you can use it in inference mode by usingthe --do_predict=true command. You need to have a file named test.tsv in theinput folder. Output will be created in file called test_results.tsv in theoutput folder. Each line will contain output for each sample, columns are theclass probabilities.export BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12export GLUE_DIR=/path/to/glueexport TRAINED_CLASSIFIER=/path/to/fine/tuned/classifierpython run_classifier.py \\  --task_name=MRPC \\  --do_predict=true \\  --data_dir=$GLUE_DIR/MRPC \\  --vocab_file=$BERT_BASE_DIR/vocab.txt \\  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\  --init_checkpoint=$TRAINED_CLASSIFIER \\  --max_seq_length=128 \\  --output_dir=/tmp/mrpc_output/SQuAD 1.1The Stanford Question Answering Dataset (SQuAD) is a popular question answeringbenchmark dataset. BERT (at the time of the release) obtains state-of-the-artresults on SQuAD with almost no task-specific network architecture modificationsor data augmentation. However, it does require semi-complex data pre-processingand post-processing to deal with (a) the variable-length nature of SQuAD contextparagraphs, and (b) the character-level answer annotations which are used forSQuAD training. This processing is implemented and documented in run_squad.py.To run on SQuAD, you will first need to download the dataset. TheSQuAD website does not seem tolink to the v1.1 datasets any longer, but the necessary files can be found here:train-v1.1.jsondev-v1.1.jsonevaluate-v1.1.pyDownload these to some directory $SQUAD_DIR.The state-of-the-art SQuAD results from the paper currently cannot be reproducedon a 12GB-16GB GPU due to memory constraints (in fact, even batch size 1 doesnot seem to fit on a 12GB GPU using BERT-Large). However, a reasonably strongBERT-Base model can be trained on the GPU with these hyperparameters:python run_squad.py \\  --vocab_file=$BERT_BASE_DIR/vocab.txt \\  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\  --do_train=True \\  --train_file=$SQUAD_DIR/train-v1.1.json \\  --do_predict=True \\  --predict_file=$SQUAD_DIR/dev-v1.1.json \\  --train_batch_size=12 \\  --learning_rate=3e-5 \\  --num_train_epochs=2.0 \\  --max_seq_length=384 \\  --doc_stride=128 \\  --output_dir=/tmp/squad_base/The dev set predictions will be saved into a file called predictions.json inthe output_dir:python $SQUAD_DIR/evaluate-v1.1.py $SQUAD_DIR/dev-v1.1.json ./squad/predictions.jsonWhich should produce an output like this:{\""f1\"": 88.41249612335034, \""exact_match\"": 81.2488174077578}You should see a result similar to the 88.5% reported in the paper forBERT-Base.If you have access to a Cloud TPU, you can train with BERT-Large. Here is aset of hyperparameters (slightly different than the paper) which consistentlyobtain around 90.5%-91.0% F1 single-system trained only on SQuAD:python run_squad.py \\  --vocab_file=$BERT_LARGE_DIR/vocab.txt \\  --bert_config_file=$BERT_LARGE_DIR/bert_config.json \\  --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt \\  --do_train=True \\  --train_file=$SQUAD_DIR/train-v1.1.json \\  --do_predict=True \\  --predict_file=$SQUAD_DIR/dev-v1.1.json \\  --train_batch_size=24 \\  --learning_rate=3e-5 \\  --num_train_epochs=2.0 \\  --max_seq_length=384 \\  --doc_stride=128 \\  --output_dir=gs://some_bucket/squad_large/ \\  --use_tpu=True \\  --tpu_name=$TPU_NAMEFor example, one random run with these parameters produces the following Devscores:{\""f1\"": 90.87081895814865, \""exact_match\"": 84.38978240302744}If you fine-tune for one epoch onTriviaQA before this the results willbe even better, but you will need to convert TriviaQA into the SQuAD jsonformat.SQuAD 2.0This model is also implemented and documented in run_squad.py.To run on SQuAD 2.0, you will first need to download the dataset. The necessaryfiles can be found here:train-v2.0.jsondev-v2.0.jsonevaluate-v2.0.pyDownload these to some directory $SQUAD_DIR.On Cloud TPU you can run with BERT-Large as follows:python run_squad.py \\  --vocab_file=$BERT_LARGE_DIR/vocab.txt \\  --bert_config_file=$BERT_LARGE_DIR/bert_config.json \\  --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt \\  --do_train=True \\  --train_file=$SQUAD_DIR/train-v2.0.json \\  --do_predict=True \\  --predict_file=$SQUAD_DIR/dev-v2.0.json \\  --train_batch_size=24 \\  --learning_rate=3e-5 \\  --num_train_epochs=2.0 \\  --max_seq_length=384 \\  --doc_stride=128 \\  --output_dir=gs://some_bucket/squad_large/ \\  --use_tpu=True \\  --tpu_name=$TPU_NAME \\  --version_2_with_negative=TrueWe assume you have copied everything from the output directory to a localdirectory called ./squad/. The initial dev set predictions will be at./squad/predictions.json and the differences between the score of no answer (\""\"")and the best non-null answer for each question will be in the file./squad/null_odds.jsonRun this script to tune a threshold for predicting null versus non-null answers:python $SQUAD_DIR/evaluate-v2.0.py $SQUAD_DIR/dev-v2.0.json./squad/predictions.json --na-prob-file ./squad/null_odds.jsonAssume the script outputs \""best_f1_thresh\"" THRESH. (Typical values are between-1.0 and -5.0). You can now re-run the model to generate predictions with thederived threshold or alternatively you can extract the appropriate answers from./squad/nbest_predictions.json.python run_squad.py \\  --vocab_file=$BERT_LARGE_DIR/vocab.txt \\  --bert_config_file=$BERT_LARGE_DIR/bert_config.json \\  --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt \\  --do_train=False \\  --train_file=$SQUAD_DIR/train-v2.0.json \\  --do_predict=True \\  --predict_file=$SQUAD_DIR/dev-v2.0.json \\  --train_batch_size=24 \\  --learning_rate=3e-5 \\  --num_train_epochs=2.0 \\  --max_seq_length=384 \\  --doc_stride=128 \\  --output_dir=gs://some_bucket/squad_large/ \\  --use_tpu=True \\  --tpu_name=$TPU_NAME \\  --version_2_with_negative=True \\  --null_score_diff_threshold=$THRESHOut-of-memory issuesAll experiments in the paper were fine-tuned on a Cloud TPU, which has 64GB ofdevice RAM. Therefore, when using a GPU with 12GB - 16GB of RAM, you are likelyto encounter out-of-memory issues if you use the same hyperparameters describedin the paper.The factors that affect memory usage are:max_seq_length: The released models were trained with sequence lengthsup to 512, but you can fine-tune with a shorter max sequence length to savesubstantial memory. This is controlled by the max_seq_length flag in ourexample code.train_batch_size: The memory usage is also directly proportional tothe batch size.Model type, BERT-Base vs. BERT-Large: The BERT-Large modelrequires significantly more memory than BERT-Base.Optimizer: The default optimizer for BERT is Adam, which requires a lotof extra memory to store the m and v vectors. Switching to a more memoryefficient optimizer can reduce memory usage, but can also affect theresults. We have not experimented with other optimizers for fine-tuning.Using the default training scripts (run_classifier.py and run_squad.py), webenchmarked the maximum batch size on single Titan X GPU (12GB RAM) withTensorFlow 1.11.0:SystemSeq LengthMax Batch SizeBERT-Base6464...12832...25616...32014...38412...5126BERT-Large6412...1286...2562...3201...3840...5120Unfortunately, these max batch sizes for BERT-Large are so small that theywill actually harm the model accuracy, regardless of the learning rate used. Weare working on adding code to this repository which will allow much largereffective batch sizes to be used on the GPU. The code will be based on one (orboth) of the following techniques:Gradient accumulation: The samples in a minibatch are typicallyindependent with respect to gradient computation (excluding batchnormalization, which is not used here). This means that the gradients ofmultiple smaller minibatches can be accumulated before performing the weightupdate, and this will be exactly equivalent to a single larger update.Gradient checkpointing:The major use of GPU/TPU memory during DNN training is caching theintermediate activations in the forward pass that are necessary forefficient computation in the backward pass. \""Gradient checkpointing\"" tradesmemory for compute time by re-computing the activations in an intelligentway.However, this is not implemented in the current release.Using BERT to extract fixed feature vectors (like ELMo)In certain cases, rather than fine-tuning the entire pre-trained modelend-to-end, it can be beneficial to obtained pre-trained contextualembeddings, which are fixed contextual representations of each input tokengenerated from the hidden layers of the pre-trained model. This should alsomitigate most of the out-of-memory issues.As an example, we include the script extract_features.py which can be usedlike this:# Sentence A and Sentence B are separated by the ||| delimiter for sentence# pair tasks like question answering and entailment.# For single sentence inputs, put one sentence per line and DON'T use the# delimiter.echo 'Who was Jim Henson ? ||| Jim Henson was a puppeteer' > /tmp/input.txtpython extract_features.py \\  --input_file=/tmp/input.txt \\  --output_file=/tmp/output.jsonl \\  --vocab_file=$BERT_BASE_DIR/vocab.txt \\  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\  --layers=-1,-2,-3,-4 \\  --max_seq_length=128 \\  --batch_size=8This will create a JSON file (one line per line of input) containing the BERTactivations from each Transformer layer specified by layers (-1 is the finalhidden layer of the Transformer, etc.)Note that this script will produce very large output files (by default, around15kb for every input token).If you need to maintain alignment between the original and tokenized words (forprojecting training labels), see the Tokenization sectionbelow.Note: You may see a message like Could not find trained model in model_dir: /tmp/tmpuB5g5c, running initialization to predict. This message is expected, itjust means that we are using the init_from_checkpoint() API rather than thesaved model API. If you don't specify a checkpoint or specify an invalidcheckpoint, this script will complain.TokenizationFor sentence-level tasks (or sentence-pair) tasks, tokenization is very simple.Just follow the example code in run_classifier.py and extract_features.py.The basic procedure for sentence-level tasks is:Instantiate an instance of tokenizer = tokenization.FullTokenizerTokenize the raw text with tokens = tokenizer.tokenize(raw_text).Truncate to the maximum sequence length. (You can use up to 512, but youprobably want to use shorter if possible for memory and speed reasons.)Add the [CLS] and [SEP] tokens in the right place.Word-level and span-level tasks (e.g., SQuAD and NER) are more complex, sinceyou need to maintain alignment between your input text and output text so thatyou can project your training labels. SQuAD is a particularly complex examplebecause the input labels are character-based, and SQuAD paragraphs are oftenlonger than our maximum sequence length. See the code in run_squad.py to showhow we handle this.Before we describe the general recipe for handling word-level tasks, it'simportant to understand what exactly our tokenizer is doing. It has three mainsteps:Text normalization: Convert all whitespace characters to spaces, and(for the Uncased model) lowercase the input and strip out accent markers.E.g., John Johanson's, ‚Üí john johanson's,.Punctuation splitting: Split all punctuation characters on both sides(i.e., add whitespace around all punctuation characters). Punctuationcharacters are defined as (a) Anything with a P* Unicode class, (b) anynon-letter/number/space ASCII character (e.g., characters like $ which aretechnically not punctuation). E.g., john johanson's, ‚Üí john johanson ' s ,WordPiece tokenization: Apply whitespace tokenization to the output ofthe above procedure, and applyWordPiecetokenization to each token separately. (Our implementation is directly basedon the one from tensor2tensor, which is linked). E.g., john johanson ' s , ‚Üí john johan ##son ' s ,The advantage of this scheme is that it is \""compatible\"" with most existingEnglish tokenizers. For example, imagine that you have a part-of-speech taggingtask which looks like this:Input:  John Johanson 's   houseLabels: NNP  NNP      POS NNThe tokenized output will look like this:Tokens: john johan ##son ' s houseCrucially, this would be the same output as if the raw text were John Johanson's house (with no space before the 's).If you have a pre-tokenized representation with word-level annotations, you cansimply tokenize each input word independently, and deterministically maintain anoriginal-to-tokenized alignment:### Inputorig_tokens = [\""John\"", \""Johanson\"", \""'s\"",  \""house\""]labels      = [\""NNP\"",  \""NNP\"",      \""POS\"", \""NN\""]### Outputbert_tokens = []# Token map will be an int -> int mapping between the `orig_tokens` index and# the `bert_tokens` index.orig_to_tok_map = []tokenizer = tokenization.FullTokenizer(    vocab_file=vocab_file, do_lower_case=True)bert_tokens.append(\""[CLS]\"")for orig_token in orig_tokens:  orig_to_tok_map.append(len(bert_tokens))  bert_tokens.extend(tokenizer.tokenize(orig_token))bert_tokens.append(\""[SEP]\"")# bert_tokens == [\""[CLS]\"", \""john\"", \""johan\"", \""##son\"", \""'\"", \""s\"", \""house\"", \""[SEP]\""]# orig_to_tok_map == [1, 2, 4, 6]Now orig_to_tok_map can be used to project labels to the tokenizedrepresentation.There are common English tokenization schemes which will cause a slight mismatchbetween how BERT was pre-trained. For example, if your input tokenization splitsoff contractions like do n't, this will cause a mismatch. If it is possible todo so, you should pre-process your data to convert these back to raw-lookingtext, but if it's not possible, this mismatch is likely not a big deal.Pre-training with BERTWe are releasing code to do \""masked LM\"" and \""next sentence prediction\"" on anarbitrary text corpus. Note that this is not the exact code that was used forthe paper (the original code was written in C++, and had some additionalcomplexity), but this code does generate pre-training data as described in thepaper.Here's how to run the data generation. The input is a plain text file, with onesentence per line. (It is important that these be actual sentences for the \""nextsentence prediction\"" task). Documents are delimited by empty lines. The outputis a set of tf.train.Examples serialized into TFRecord file format.You can perform sentence segmentation with an off-the-shelf NLP toolkit such asspaCy. The create_pretraining_data.py script willconcatenate segments until they reach the maximum sequence length to minimizecomputational waste from padding (see the script for more details). However, youmay want to intentionally add a slight amount of noise to your input data (e.g.,randomly truncate 2% of input segments) to make it more robust to non-sententialinput during fine-tuning.This script stores all of the examples for the entire input file in memory, sofor large data files you should shard the input file and call the scriptmultiple times. (You can pass in a file glob to run_pretraining.py, e.g.,tf_examples.tf_record*.)The max_predictions_per_seq is the maximum number of masked LM predictions persequence. You should set this to around max_seq_length * masked_lm_prob (thescript doesn't do that automatically because the exact value needs to be passedto both scripts).python create_pretraining_data.py \\  --input_file=./sample_text.txt \\  --output_file=/tmp/tf_examples.tfrecord \\  --vocab_file=$BERT_BASE_DIR/vocab.txt \\  --do_lower_case=True \\  --max_seq_length=128 \\  --max_predictions_per_seq=20 \\  --masked_lm_prob=0.15 \\  --random_seed=12345 \\  --dupe_factor=5Here's how to run the pre-training. Do not include init_checkpoint if you arepre-training from scratch. The model configuration (including vocab size) isspecified in bert_config_file. This demo code only pre-trains for a smallnumber of steps (20), but in practice you will probably want to setnum_train_steps to 10000 steps or more. The max_seq_length andmax_predictions_per_seq parameters passed to run_pretraining.py must be thesame as create_pretraining_data.py.python run_pretraining.py \\  --input_file=/tmp/tf_examples.tfrecord \\  --output_dir=/tmp/pretraining_output \\  --do_train=True \\  --do_eval=True \\  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\  --train_batch_size=32 \\  --max_seq_length=128 \\  --max_predictions_per_seq=20 \\  --num_train_steps=20 \\  --num_warmup_steps=10 \\  --learning_rate=2e-5This will produce an output like this:***** Eval results *****  global_step = 20  loss = 0.0979674  masked_lm_accuracy = 0.985479  masked_lm_loss = 0.0979328  next_sentence_accuracy = 1.0  next_sentence_loss = 3.45724e-05Note that since our sample_text.txt file is very small, this example trainingwill overfit that data in only a few steps and produce unrealistically highaccuracy numbers.Pre-training tips and caveatsIf using your own vocabulary, make sure to change vocab_size inbert_config.json. If you use a larger vocabulary without changing this,you will likely get NaNs when training on GPU or TPU due to uncheckedout-of-bounds access.If your task has a large domain-specific corpus available (e.g., \""moviereviews\"" or \""scientific papers\""), it will likely be beneficial to runadditional steps of pre-training on your corpus, starting from the BERTcheckpoint.The learning rate we used in the paper was 1e-4. However, if you are doingadditional steps of pre-training starting from an existing BERT checkpoint,you should use a smaller learning rate (e.g., 2e-5).Current BERT models are English-only, but we do plan to release amultilingual model which has been pre-trained on a lot of languages in thenear future (hopefully by the end of November 2018).Longer sequences are disproportionately expensive because attention isquadratic to the sequence length. In other words, a batch of 64 sequences oflength 512 is much more expensive than a batch of 256 sequences oflength 128. The fully-connected/convolutional cost is the same, but theattention cost is far greater for the 512-length sequences. Therefore, onegood recipe is to pre-train for, say, 90,000 steps with a sequence length of128 and then for 10,000 additional steps with a sequence length of 512. Thevery long sequences are mostly needed to learn positional embeddings, whichcan be learned fairly quickly. Note that this does require generating thedata twice with different values of max_seq_length.If you are pre-training from scratch, be prepared that pre-training iscomputationally expensive, especially on GPUs. If you are pre-training fromscratch, our recommended recipe is to pre-train a BERT-Base on a singlepreemptible Cloud TPU v2, whichtakes about 2 weeks at a cost of about $500 USD (based on the pricing inOctober 2018). You will have to scale down the batch size when only trainingon a single Cloud TPU, compared to what was used in the paper. It isrecommended to use the largest batch size that fits into TPU memory.Pre-training dataWe will not be able to release the pre-processed datasets used in the paper.For Wikipedia, the recommended pre-processing is to downloadthe latest dump,extract the text withWikiExtractor.py, and then applyany necessary cleanup to convert it into plain text.Unfortunately the researchers who collected theBookCorpus no longer have it available forpublic download. TheProject Guttenberg Datasetis a somewhat smaller (200M word) collection of older books that are publicdomain.Common Crawl is another very large collection oftext, but you will likely have to do substantial pre-processing and cleanup toextract a usable corpus for pre-training BERT.Learning a new WordPiece vocabularyThis repository does not include code for learning a new WordPiece vocabulary.The reason is that the code used in the paper was implemented in C++ withdependencies on Google's internal libraries. For English, it is almost alwaysbetter to just start with our vocabulary and pre-trained models. For learningvocabularies of other languages, there are a number of open source optionsavailable. However, keep in mind that these are not compatible with ourtokenization.py library:Google's SentencePiece librarytensor2tensor's WordPiece generation scriptRico Sennrich's Byte Pair Encoding libraryUsing BERT in ColabIf you want to use BERT with Colab, you canget started with the notebook\""BERT FineTuning with Cloud TPUs\"".At the time of this writing (October 31st, 2018), Colab users can access aCloud TPU completely for free. Note: One per user, availability limited,requires a Google Cloud Platform account with storage (although storage may bepurchased with free credit for signing up with GCP), and this capability may notlonger be available in the future. Click on the BERT Colab that was just linkedfor more information.FAQIs this code compatible with Cloud TPUs? What about GPUs?Yes, all of the code in this repository works out-of-the-box with CPU, GPU, andCloud TPU. However, GPU training is single-GPU only.I am getting out-of-memory errors, what is wrong?See the section on out-of-memory issues for moreinformation.Is there a PyTorch version available?There is no official PyTorch implementation. However, NLP researchers fromHuggingFace made aPyTorch version of BERT availablewhich is compatible with our pre-trained checkpoints and is able to reproduceour results. We were not involved in the creation or maintenance of the PyTorchimplementation so please direct any questions towards the authors of thatrepository.Is there a Chainer version available?There is no official Chainer implementation. However, Sosuke Kobayashi made aChainer version of BERT availablewhich is compatible with our pre-trained checkpoints and is able to reproduceour results. We were not involved in the creation or maintenance of the Chainerimplementation so please direct any questions towards the authors of thatrepository.Will models in other languages be released?Yes, we plan to release a multi-lingual BERT model in the near future. We cannotmake promises about exactly which languages will be included, but it will likelybe a single model which includes most of the languages which have asignificantly-sized Wikipedia.Will models larger than BERT-Large be released?So far we have not attempted to train anything larger than BERT-Large. It ispossible that we will release larger models if we are able to obtain significantimprovements.What license is this library released under?All code and models are released under the Apache 2.0 license. See theLICENSE file for more information.How do I cite BERT?For now, cite the Arxiv paper:@article{devlin2018bert,  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},  journal={arXiv preprint arXiv:1810.04805},  year={2018}}If we submit the paper to a conference or journal, we will update the BibTeX.DisclaimerThis is not an official Google product.Contact informationFor help or issues using BERT, please submit a GitHub issue.For personal communication related to BERT, please contact Jacob Devlin(jacobdevlin@google.com), Ming-Wei Chang (mingweichang@google.com), orKenton Lee (kentonl@google.com)."
79,ageitgey/face_recognition,https://github.com/ageitgey/face_recognition/blob/master/README.md,Python,"Face RecognitionYou can also read a translated version of this file in Chinese ÁÆÄ‰Ωì‰∏≠ÊñáÁâà or in Korean ÌïúÍµ≠Ïñ¥ or in Japanese Êó•Êú¨Ë™û.Recognize and manipulate faces from Python or from the command line withthe world's simplest face recognition library.Built using dlib's state-of-the-art face recognitionbuilt with deep learning. The model has an accuracy of 99.38% on theLabeled Faces in the Wild benchmark.This also provides a simple face_recognition command line tool that letsyou do face recognition on a folder of images from the command line!FeaturesFind faces in picturesFind all the faces that appear in a picture:import face_recognitionimage = face_recognition.load_image_file(\""your_file.jpg\"")face_locations = face_recognition.face_locations(image)Find and manipulate facial features in picturesGet the locations and outlines of each person's eyes, nose, mouth and chin.import face_recognitionimage = face_recognition.load_image_file(\""your_file.jpg\"")face_landmarks_list = face_recognition.face_landmarks(image)Finding facial features is super useful for lots of important stuff. But you can also use it for really stupid stufflike applying digital make-up (think 'Meitu'):Identify faces in picturesRecognize who appears in each photo.import face_recognitionknown_image = face_recognition.load_image_file(\""biden.jpg\"")unknown_image = face_recognition.load_image_file(\""unknown.jpg\"")biden_encoding = face_recognition.face_encodings(known_image)[0]unknown_encoding = face_recognition.face_encodings(unknown_image)[0]results = face_recognition.compare_faces([biden_encoding], unknown_encoding)You can even use this library with other Python libraries to do real-time face recognition:See this example for the code.Online DemosUser-contributed shared Jupyter notebook demo (not officially supported): InstallationRequirementsPython 3.3+ or Python 2.7macOS or Linux (Windows not officially supported, but might work)Installation Options:Installing on Mac or LinuxFirst, make sure you have dlib already installed with Python bindings:How to install dlib from source on macOS or UbuntuThen, make sure you have cmake installed:brew install cmakeFinally, install this module from pypi using pip3 (or pip2 for Python 2):pip3 install face_recognitionAlternatively, you can try this library with Docker, see this section.If you are having trouble with installation, you can also try out apre-configured VM.Installing on an Nvidia Jetson Nano boardJetson Nano installation instructionsPlease follow the instructions in the article carefully. There is current a bug in the CUDA libraries on the Jetson Nano that will cause this library to fail silently if you don't follow the instructions in the article to comment out a line in dlib and recompile it.Installing on Raspberry Pi 2+Raspberry Pi 2+ installation instructionsInstalling on FreeBSDpkg install graphics/py-face_recognitionInstalling on WindowsWhile Windows isn't officially supported, helpful users have posted instructions on how to install this library:@masoudr's Windows 10 installation guide (dlib + face_recognition)Installing a pre-configured Virtual Machine imageDownload the pre-configured VM image (for VMware Player or VirtualBox).UsageCommand-Line InterfaceWhen you install face_recognition, you get two simple command-lineprograms:face_recognition - Recognize faces in a photograph or folder full forphotographs.face_detection - Find faces in a photograph or folder full for photographs.face_recognition command line toolThe face_recognition command lets you recognize faces in a photograph orfolder full  for photographs.First, you need to provide a folder with one picture of each person youalready know. There should be one image file for each person with thefiles named according to who is in the picture:Next, you need a second folder with the files you want to identify:Then in you simply run the command face_recognition, passing inthe folder of known people and the folder (or single image) with unknownpeople and it tells you who is in each image:$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama/face_recognition_test/unknown_pictures/unknown.jpg,unknown_personThere's one line in the output for each face. The data is comma-separatedwith the filename and the name of the person found.An unknown_person is a face in the image that didn't match anyone inyour folder of known people.face_detection command line toolThe face_detection command lets you find the location (pixel coordinatates)of any faces in an image.Just run the command face_detection, passing in a folder of imagesto check (or a single image):$ face_detection  ./folder_with_pictures/examples/image1.jpg,65,215,169,112examples/image2.jpg,62,394,211,244examples/image2.jpg,95,941,244,792It prints one line for each face that was detected. The coordinatesreported are the top, right, bottom and left coordinates of the face (in pixels).Adjusting Tolerance / SensitivityIf you are getting multiple matches for the same person, it might be thatthe people in your photos look very similar and a lower tolerance valueis needed to make face comparisons more strict.You can do that with the --tolerance parameter. The default tolerancevalue is 0.6 and lower numbers make face comparisons more strict:$ face_recognition --tolerance 0.54 ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama/face_recognition_test/unknown_pictures/unknown.jpg,unknown_personIf you want to see the face distance calculated for each match in orderto adjust the tolerance setting, you can use --show-distance true:$ face_recognition --show-distance true ./pictures_of_people_i_know/ ./unknown_pictures//unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,NoneMore ExamplesIf you simply want to know the names of the people in each photograph but don'tcare about file names, you could do this:$ face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/ | cut -d ',' -f2Barack Obamaunknown_personSpeeding up Face RecognitionFace recognition can be done in parallel if you have a computer withmultiple CPU cores. For example, if your system has 4 CPU cores, you canprocess about 4 times as many images in the same amount of time by usingall your CPU cores in parallel.If you are using Python 3.4 or newer, pass in a --cpus <number_of_cpu_cores_to_use> parameter:$ face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/You can also pass in --cpus -1 to use all CPU cores in your system.Python ModuleYou can import the face_recognition module and then easily manipulatefaces with just a couple of lines of code. It's super easy!API Docs: https://face-recognition.readthedocs.io.Automatically find all the faces in an imageimport face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_locations = face_recognition.face_locations(image)# face_locations is now an array listing the co-ordinates of each face!See this exampleto try it out.You can also opt-in to a somewhat more accurate deep-learning-based face detection model.Note: GPU acceleration (via NVidia's CUDA library) is required for goodperformance with this model. You'll also want to enable CUDA supportwhen compliling dlib.import face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_locations = face_recognition.face_locations(image, model=\""cnn\"")# face_locations is now an array listing the co-ordinates of each face!See this exampleto try it out.If you have a lot of images and a GPU, you can alsofind faces in batches.Automatically locate the facial features of a person in an imageimport face_recognitionimage = face_recognition.load_image_file(\""my_picture.jpg\"")face_landmarks_list = face_recognition.face_landmarks(image)# face_landmarks_list is now an array with the locations of each facial feature in each face.# face_landmarks_list[0]['left_eye'] would be the location and outline of the first person's left eye.See this exampleto try it out.Recognize faces in images and identify who they areimport face_recognitionpicture_of_me = face_recognition.load_image_file(\""me.jpg\"")my_face_encoding = face_recognition.face_encodings(picture_of_me)[0]# my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!unknown_picture = face_recognition.load_image_file(\""unknown.jpg\"")unknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]# Now we can see the two face encodings are of the same person with `compare_faces`!results = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)if results[0] == True:    print(\""It's a picture of me!\"")else:    print(\""It's not a picture of me!\"")See this exampleto try it out.Python Code ExamplesAll the examples are available here.Face DetectionFind faces in a photographFind faces in a photograph (using deep learning)Find faces in batches of images w/ GPU (using deep learning)Blur all the faces in a live video using your webcam (Requires OpenCV to be installed)Facial FeaturesIdentify specific facial features in a photographApply (horribly ugly) digital make-upFacial RecognitionFind and recognize unknown faces in a photograph based on photographs of known peopleIdentify and draw boxes around each person in a photoCompare faces by numeric face distance instead of only True/False matchesRecognize faces in live video using your webcam - Simple / Slower Version (Requires OpenCV to be installed)Recognize faces in live video using your webcam - Faster Version (Requires OpenCV to be installed)Recognize faces in a video file and write out new video file (Requires OpenCV to be installed)Recognize faces on a Raspberry Pi w/ cameraRun a web service to recognize faces via HTTP (Requires Flask to be installed)Recognize faces with a K-nearest neighbors classifierTrain multiple images per person then recognize faces using a SVMCreating a Standalone ExecutableIf you want to create a standalone executable that can run without the need to install python or face_recognition, you can use PyInstaller. However, it requires some custom configuration to work with this library. See this issue for how to do it.Articles and Guides that cover face_recognitionMy article on how Face Recognition works: Modern Face Recognition with Deep LearningCovers the algorithms and how they generally workFace recognition with OpenCV, Python, and deep learning by Adrian RosebrockCovers how to use face recognition in practiceRaspberry Pi Face Recognition by Adrian RosebrockCovers how to use this on a Raspberry PiFace clustering with Python by Adrian RosebrockCovers how to automatically cluster photos based on who appears in each photo using unsupervised learningHow Face Recognition WorksIf you want to learn how face location and recognition work instead ofdepending on a black box library, read my article.CaveatsThe face recognition model is trained on adults and does not work very well on children. It tends to mixup children quite easy using the default comparison threshold of 0.6.Accuracy may vary between ethnic groups. Please see this wiki page for more details.Deployment to Cloud Hosts (Heroku, AWS, etc)Since face_recognition depends on dlib which is written in C++, it can be tricky to deploy an appusing it to a cloud hosting provider like Heroku or AWS.To make things easier, there's an example Dockerfile in this repo that shows how to run an app built withface_recognition in a Docker container. With that, you should be able to deployto any service that supports Docker images.You can try the Docker image locally by running: docker-compose up --buildThere are also several prebuilt Docker images.Linux users with a GPU (drivers >= 384.81) and Nvidia-Docker installed can run the example on the GPU: Open the docker-compose.yml file and uncomment the dockerfile: Dockerfile.gpu and runtime: nvidia lines.Having problems?If you run into problems, please read the Common Errors section of the wiki before filing a github issue.ThanksMany, many thanks to Davis King (@nulhom)for creating dlib and for providing the trained facial feature detection and face encoding modelsused in this library. For more information on the ResNet that powers the face encodings, check outhis blog post.Thanks to everyone who works on all the awesome Python data science libraries like numpy, scipy, scikit-image,pillow, etc, etc that makes this kind of stuff so easy and fun in Python.Thanks to Cookiecutter and theaudreyr/cookiecutter-pypackage project templatefor making Python project packaging way more tolerable."
80,swisskyrepo/PayloadsAllTheThings,https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/README.md,Python,"Payloads All The ThingsA list of useful payloads and bypasses for Web Application Security.Feel free to improve with your payloads and techniques !I ‚ù§Ô∏è pull requests :)You can also contribute with a üçª IRL, or using the sponsor buttonAn alternative display version is available at PayloadsAllTheThingsWeb.  üìñ DocumentationEvery section contains the following files, you can use the _template_vuln folder to create a new chapter:README.md - vulnerability description and how to exploit it, including several payloadsIntruder - a set of files to give to Burp IntruderImages - pictures for the README.mdFiles - some files referenced in the README.mdYou might also like the Methodology and Resources folder :Methodology and ResourcesActive Directory Attack.mdCloud - AWS Pentest.mdCloud - Azure Pentest.mdCobalt Strike - Cheatsheet.mdLinux - Evasion.mdLinux - Persistence.mdLinux - Privilege Escalation.mdMetasploit - Cheatsheet.mdMethodology and enumeration.mdNetwork Pivoting Techniques.mdNetwork Discovery.mdReverse Shell Cheatsheet.mdSubdomains Enumeration.mdWindows - AMSI Bypass.mdWindows - DPAPI.mdWindows - Download and Execute.mdWindows - Mimikatz.mdWindows - Persistence.mdWindows - Privilege Escalation.mdWindows - Using credentials.mdYou want more ? Check the Books and Youtube videos selections.üë®‚Äçüíª ContributionsBe sure to read CONTRIBUTING.md  Thanks again for your contribution! ‚ù§Ô∏èüßô‚Äç‚ôÇÔ∏è SponsorsThis project is proudly sponsored by these companies."
81,xtekky/gpt4free,https://github.com/xtekky/gpt4free/blob/main/README.md,Python,"By using this repository or any code related to it, you agree to the legal notice. The author is not responsible for any copies, forks, or reuploads made by other users. This is the author's only account and repository. To prevent impersonation or irresponsible actions, you may comply with the GNU GPL license this Repository uses.This (quite censored) New Version of gpt4free, was just released, it may contain bugs, open an issue or contribute a PR when encountering one, some features were disabled.Docker is for now not available but I would be happy if someone contributes a PR. The g4f GUI will be uploaded soon enough.Newpypi package:pip install -U g4fTable of Contents:Getting StartedPrerequisitesSetting up the projectUsageThe g4f Packageinterference openai-proxy apiModelsgpt-3.5 / gpt-4Other ModelsRelated gpt4free projectsContributeChatGPT cloneCopyrightCopyright NoticeStar HistoryGetting StartedPrerequisites:Download and install Python (Version 3.x is recommended).Setting up the project:Install using pypipip install -U g4forClone the GitHub repository:git clone https://github.com/xtekky/gpt4free.gitNavigate to the project directory:cd gpt4free(Recommended) Create a virtual environment to manage Python packages for your project:python3 -m venv venvActivate the virtual environment:On Windows:.\\venv\\Scripts\\activateOn macOS and Linux:source venv/bin/activateInstall the required Python packages from requirements.txt:pip install -r requirements.txtCreate a test.py file in the root folder and start using the repo, further Instructions are belowimport g4f...UsageThe g4f Packageimport g4fprint(g4f.provider.Ails.params)  # supported args# Automatic selection of provider# streamed completionresponse = g4f.ChatCompletion.create(    model=\""gpt-3.5-turbo\"",    messages=[{\""role\"": \""user\"", \""content\"": \""Hello world\""}],    stream=True,)for message in response:    print(message, flush=True, end='')# normal responseresponse = g4f.ChatCompletion.create(    model=g4f.models.gpt_4,    messages=[{\""role\"": \""user\"", \""content\"": \""hi\""}],)  # alterative model settingprint(response)# Set with providerresponse = g4f.ChatCompletion.create(    model=\""gpt-3.5-turbo\"",    provider=g4f.provider.DeepAi,    messages=[{\""role\"": \""user\"", \""content\"": \""Hello world\""}],    stream=True,)for message in response:    print(message)providers:from g4f.provider import (    Acytoo,    Aichat,    Ails,    AiService,    AItianhu,    Bard,    Bing,    ChatgptAi,    ChatgptLogin,    DeepAi,    GetGpt)# usage:response = g4f.ChatCompletion.create(..., provider=ProviderName)interference openai-proxy api (use with openai python package)get requirements:pip install -r interference/requirements.txtrun server:python3 -m interference.appimport openaiopenai.api_key = \""\""openai.api_base = \""http://localhost:1337\""def main():    chat_completion = openai.ChatCompletion.create(        model=\""gpt-3.5-turbo\"",        messages=[{\""role\"": \""user\"", \""content\"": \""write a poem about a tree\""}],        stream=True,    )    if isinstance(chat_completion, dict):        # not stream        print(chat_completion.choices[0].message.content)    else:        # stream        for token in chat_completion:            content = token[\""choices\""][0][\""delta\""].get(\""content\"")            if content != None:                print(content, end=\""\"", flush=True)if __name__ == \""__main__\"":    main()Modelsgpt-3.5 / gpt-4WebsiteProvidergpt-3.5gpt-4StreamingStatusAuthwww.aitianhu.comg4f.provider.AItianhu‚úîÔ∏è‚ùå‚ùå‚ùåchat.acytoo.comg4f.provider.Acytoo‚úîÔ∏è‚ùå‚ùå‚ùåaiservice.vercel.appg4f.provider.AiService‚úîÔ∏è‚ùå‚ùå‚ùåchat-gpt.orgg4f.provider.Aichat‚úîÔ∏è‚ùå‚ùå‚ùåai.lsg4f.provider.Ails‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåbard.google.comg4f.provider.Bard‚ùå‚ùå‚ùå‚úîÔ∏èbing.comg4f.provider.Bing‚ùå‚úîÔ∏è‚ùå‚ùåchatgpt.aig4f.provider.ChatgptAi‚ùå‚úîÔ∏è‚ùå‚ùåchatgptlogin.acg4f.provider.ChatgptLogin‚úîÔ∏è‚ùå‚ùå‚ùådeepai.orgg4f.provider.DeepAi‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåchat.dfehub.comg4f.provider.DfeHub‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåfree.easychat.workg4f.provider.EasyChat‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåforefront.comg4f.provider.Forefront‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåchat.getgpt.worldg4f.provider.GetGpt‚úîÔ∏è‚ùå‚úîÔ∏è‚ùågpt-gm.h2o.aig4f.provider.H2o‚ùå‚ùå‚úîÔ∏è‚ùåliaobots.comg4f.provider.Liaobots‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏èsupertest.lockchat.appg4f.provider.Lockchat‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚ùåopchatgpts.netg4f.provider.Opchatgpts‚úîÔ∏è‚ùå‚ùå‚ùåbackend.raycast.comg4f.provider.Raycast‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏ètheb.aig4f.provider.Theb‚úîÔ∏è‚ùå‚úîÔ∏è‚ùåplay.vercel.aig4f.provider.Vercel‚úîÔ∏è‚ùå‚ùå‚ùåwewordle.orgg4f.provider.Wewordle‚úîÔ∏è‚ùå‚ùå‚ùåyou.comg4f.provider.You‚úîÔ∏è‚ùå‚ùå‚ùåchat9.yqcloud.topg4f.provider.Yqcloud‚úîÔ∏è‚ùå‚ùå‚ùåOther ModelsModelBase ProviderProviderWebsitepalmGoogleg4f.provider.Bardbard.google.comh2ogpt-gm-oasst1-en-2048-falcon-7b-v3Huggingfaceg4f.provider.H2owww.h2o.aih2ogpt-gm-oasst1-en-2048-falcon-40b-v1Huggingfaceg4f.provider.H2owww.h2o.aih2ogpt-gm-oasst1-en-2048-open-llama-13bHuggingfaceg4f.provider.H2owww.h2o.aiclaude-instant-v1Anthropicg4f.provider.Vercelsdk.vercel.aiclaude-v1Anthropicg4f.provider.Vercelsdk.vercel.aiclaude-v2Anthropicg4f.provider.Vercelsdk.vercel.aicommand-light-nightlyCohereg4f.provider.Vercelsdk.vercel.aicommand-nightlyCohereg4f.provider.Vercelsdk.vercel.aigpt-neox-20bHuggingfaceg4f.provider.Vercelsdk.vercel.aioasst-sft-1-pythia-12bHuggingfaceg4f.provider.Vercelsdk.vercel.aioasst-sft-4-pythia-12b-epoch-3.5Huggingfaceg4f.provider.Vercelsdk.vercel.aisantacoderHuggingfaceg4f.provider.Vercelsdk.vercel.aibloomHuggingfaceg4f.provider.Vercelsdk.vercel.aiflan-t5-xxlHuggingfaceg4f.provider.Vercelsdk.vercel.aicode-davinci-002OpenAIg4f.provider.Vercelsdk.vercel.aigpt-3.5-turbo-16kOpenAIg4f.provider.Vercelsdk.vercel.aigpt-3.5-turbo-16k-0613OpenAIg4f.provider.Vercelsdk.vercel.aigpt-4-0613OpenAIg4f.provider.Vercelsdk.vercel.aitext-ada-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-babbage-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-curie-001OpenAIg4f.provider.Vercelsdk.vercel.aitext-davinci-002OpenAIg4f.provider.Vercelsdk.vercel.aitext-davinci-003OpenAIg4f.provider.Vercelsdk.vercel.aillama13b-v2-chatReplicateg4f.provider.Vercelsdk.vercel.aillama7b-v2-chatReplicateg4f.provider.Vercelsdk.vercel.aiRelated gpt4free projects            üéÅ Projects      ‚≠ê Stars      üìö Forks      üõé Issues      üì¨ Pull requests                  gpt4free                                      gpt4free-ts                                      ChatGPT-Clone                                      ChatGpt Discord Bot                                      LangChain gpt4free                                      ChatGpt Telegram Bot                              Contributeto add another provider, its very simple:create a new file in g4f/provider with the name of the ProviderImplement a class that extends BaseProvider.from .base_provider import BaseProviderfrom ..typing import CreateResult, Anyclass HogeService(BaseProvider):    url = \""http://hoge.com\""    working = True    supports_gpt_35_turbo = True    @staticmethod    def create_completion(        model: str,        messages: list[dict[str, str]],        stream: bool,        **kwargs: Any,    ) -> CreateResult:        passHere, you can adjust the settings, for example if the website does support streaming, set working to True...Write code to request the provider in create_completion and yield the response, even if its a one-time response, do not hesitate to look at other providers for inspirationAdd the Provider Name in g4f/provider/init.pyfrom .base_provider import BaseProviderfrom .HogeService import HogeService__all__ = [  HogeService,]You are done !, test the provider by calling it:import g4fresponse = g4f.ChatCompletion.create(model='gpt-3.5-turbo', provider=g4f.provider.PROVIDERNAME,                                    messages=[{\""role\"": \""user\"", \""content\"": \""test\""}], stream=g4f.provider.PROVIDERNAME.supports_stream)for message in response:    print(message, flush=True, end='')ChatGPT cloneCurrently implementing new features and trying to scale it, please be patient it may be unstablehttps://chat.g4f.ai/chatThis site was developed by me and includes gpt-4/3.5, internet access and gpt-jailbreak's like DANRun locally here: https://github.com/xtekky/chatgpt-cloneCopyright:This program is licensed under the GNU GPL v3Copyright Notice:xtekky/gpt4free: Copyright (C) 2023 xtekkyThis program is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program.  If not, see <https://www.gnu.org/licenses/>.Star History         "
82,jhao104/proxy_pool,https://github.com/jhao104/proxy_pool/blob/master/README.md,Python,"ProxyPool Áà¨Ëô´‰ª£ÁêÜIPÊ±†______                        ______             _| ___ \\_                      | ___ \\           | || |_/ / \\__ __   __  _ __   _ | |_/ /___   ___  | ||  __/|  _// _ \\ \\ \\/ /| | | ||  __// _ \\ / _ \\ | || |   | | | (_) | >  < \\ |_| || |  | (_) | (_) || |___\\_|   |_|  \\___/ /_/\\_\\ \\__  |\\_|   \\___/ \\___/ \\_____\\                       __ / /                      /___ /ProxyPoolÁà¨Ëô´‰ª£ÁêÜIPÊ±†È°πÁõÆ,‰∏ªË¶ÅÂäüËÉΩ‰∏∫ÂÆöÊó∂ÈááÈõÜÁΩë‰∏äÂèëÂ∏ÉÁöÑÂÖçË¥π‰ª£ÁêÜÈ™åËØÅÂÖ•Â∫ìÔºåÂÆöÊó∂È™åËØÅÂÖ•Â∫ìÁöÑ‰ª£ÁêÜ‰øùËØÅ‰ª£ÁêÜÁöÑÂèØÁî®ÊÄßÔºåÊèê‰æõAPIÂíåCLI‰∏§Áßç‰ΩøÁî®ÊñπÂºè„ÄÇÂêåÊó∂‰Ω†‰πüÂèØ‰ª•Êâ©Â±ï‰ª£ÁêÜÊ∫ê‰ª•Â¢ûÂä†‰ª£ÁêÜÊ±†IPÁöÑË¥®ÈáèÂíåÊï∞Èáè„ÄÇÊñáÊ°£: document ÊîØÊåÅÁâàÊú¨: ÊµãËØïÂú∞ÂùÄ: http://demo.spiderpy.cn (ÂãøÂéãË∞¢Ë∞¢)‰ªòË¥π‰ª£ÁêÜÊé®Ëçê: luminati-china. ÂõΩÂ§ñÁöÑ‰∫ÆÊï∞ÊçÆBrightDataÔºà‰ª•ÂâçÂè´luminatiÔºâË¢´ËÆ§‰∏∫ÊòØ‰ª£ÁêÜÂ∏ÇÂú∫È¢ÜÂØºËÄÖÔºåË¶ÜÁõñÂÖ®ÁêÉÁöÑ7200‰∏áIPÔºåÂ§ßÈÉ®ÂàÜÊòØÁúü‰∫∫‰ΩèÂÆÖIPÔºåÊàêÂäüÁéáÊâõÊâõÁöÑ„ÄÇ‰ªòË¥πÂ•óÈ§êÂ§öÁßçÔºåÈúÄË¶ÅÈ´òË¥®Èáè‰ª£ÁêÜIPÁöÑÂèØ‰ª•Ê≥®ÂÜåÂêéËÅîÁ≥ª‰∏≠ÊñáÂÆ¢ÊúçÔºåÂºÄÈÄöÂêéËµ†ÈÄÅ5ÁæéÈáë‰ΩôÈ¢ùÂíåÊïôÁ®ãÊåáÂºï(PS:Áî®‰∏çÊòéÁôΩÁöÑÂêåÂ≠¶ÂèØ‰ª•ÂèÇËÄÉËøô‰∏™‰ΩøÁî®ÊïôÁ®ã)„ÄÇËøêË°åÈ°πÁõÆ‰∏ãËΩΩ‰ª£Á†Å:git clonegit clone git@github.com:jhao104/proxy_pool.gitreleaseshttps://github.com/jhao104/proxy_pool/releases ‰∏ãËΩΩÂØπÂ∫îzipÊñá‰ª∂ÂÆâË£Ö‰æùËµñ:pip install -r requirements.txtÊõ¥Êñ∞ÈÖçÁΩÆ:# setting.py ‰∏∫È°πÁõÆÈÖçÁΩÆÊñá‰ª∂# ÈÖçÁΩÆAPIÊúçÂä°HOST = \""0.0.0.0\""               # IPPORT = 5000                    # ÁõëÂê¨Á´ØÂè£# ÈÖçÁΩÆÊï∞ÊçÆÂ∫ìDB_CONN = 'redis://:pwd@127.0.0.1:8888/0'# ÈÖçÁΩÆ ProxyFetcherPROXY_FETCHER = [    \""freeProxy01\"",      # ËøôÈáåÊòØÂêØÁî®ÁöÑ‰ª£ÁêÜÊäìÂèñÊñπÊ≥ïÂêçÔºåÊâÄÊúâfetchÊñπÊ≥ï‰Ωç‰∫éfetcher/proxyFetcher.py    \""freeProxy02\"",    # ....]ÂêØÂä®È°πÁõÆ:# Â¶ÇÊûúÂ∑≤ÁªèÂÖ∑Â§áËøêË°åÊù°‰ª∂, ÂèØÁî®ÈÄöËøáproxyPool.pyÂêØÂä®„ÄÇ# Á®ãÂ∫èÂàÜ‰∏∫: schedule Ë∞ÉÂ∫¶Á®ãÂ∫è Âíå server ApiÊúçÂä°# ÂêØÂä®Ë∞ÉÂ∫¶Á®ãÂ∫èpython proxyPool.py schedule# ÂêØÂä®webApiÊúçÂä°python proxyPool.py serverDocker Imagedocker pull jhao104/proxy_pooldocker run --env DB_CONN=redis://:password@ip:port/0 -p 5010:5010 jhao104/proxy_pool:latestdocker-composeÈ°πÁõÆÁõÆÂΩï‰∏ãËøêË°å:docker-compose up -d‰ΩøÁî®ApiÂêØÂä®webÊúçÂä°Âêé, ÈªòËÆ§ÈÖçÁΩÆ‰∏ã‰ºöÂºÄÂêØ http://127.0.0.1:5010 ÁöÑapiÊé•Âè£ÊúçÂä°:apimethodDescriptionparams/GETapi‰ªãÁªçNone/getGETÈöèÊú∫Ëé∑Âèñ‰∏Ä‰∏™‰ª£ÁêÜÂèØÈÄâÂèÇÊï∞: ?type=https ËøáÊª§ÊîØÊåÅhttpsÁöÑ‰ª£ÁêÜ/popGETËé∑ÂèñÂπ∂Âà†Èô§‰∏Ä‰∏™‰ª£ÁêÜÂèØÈÄâÂèÇÊï∞: ?type=https ËøáÊª§ÊîØÊåÅhttpsÁöÑ‰ª£ÁêÜ/allGETËé∑ÂèñÊâÄÊúâ‰ª£ÁêÜÂèØÈÄâÂèÇÊï∞: ?type=https ËøáÊª§ÊîØÊåÅhttpsÁöÑ‰ª£ÁêÜ/countGETÊü•Áúã‰ª£ÁêÜÊï∞ÈáèNone/deleteGETÂà†Èô§‰ª£ÁêÜ?proxy=host:ipÁà¨Ëô´‰ΩøÁî®„ÄÄ„ÄÄÂ¶ÇÊûúË¶ÅÂú®Áà¨Ëô´‰ª£Á†Å‰∏≠‰ΩøÁî®ÁöÑËØùÔºå ÂèØ‰ª•Â∞ÜÊ≠§apiÂ∞ÅË£ÖÊàêÂáΩÊï∞Áõ¥Êé•‰ΩøÁî®Ôºå‰æãÂ¶ÇÔºöimport requestsdef get_proxy():    return requests.get(\""http://127.0.0.1:5010/get/\"").json()def delete_proxy(proxy):    requests.get(\""http://127.0.0.1:5010/delete/?proxy={}\"".format(proxy))# your spider codedef getHtml():    # ....    retry_count = 5    proxy = get_proxy().get(\""proxy\"")    while retry_count > 0:        try:            html = requests.get('http://www.example.com', proxies={\""http\"": \""http://{}\"".format(proxy)})            # ‰ΩøÁî®‰ª£ÁêÜËÆøÈóÆ            return html        except Exception:            retry_count -= 1    # Âà†Èô§‰ª£ÁêÜÊ±†‰∏≠‰ª£ÁêÜ    delete_proxy(proxy)    return NoneÊâ©Â±ï‰ª£ÁêÜ„ÄÄ„ÄÄÈ°πÁõÆÈªòËÆ§ÂåÖÂê´Âá†‰∏™ÂÖçË¥πÁöÑ‰ª£ÁêÜËé∑ÂèñÊ∫êÔºå‰ΩÜÊòØÂÖçË¥πÁöÑÊØïÁ´üË¥®ÈáèÊúâÈôêÔºåÊâÄ‰ª•Â¶ÇÊûúÁõ¥Êé•ËøêË°åÂèØËÉΩÊãøÂà∞ÁöÑ‰ª£ÁêÜË¥®Èáè‰∏çÁêÜÊÉ≥„ÄÇÊâÄ‰ª•ÔºåÊèê‰æõ‰∫Ü‰ª£ÁêÜËé∑ÂèñÁöÑÊâ©Â±ïÊñπÊ≥ï„ÄÇ„ÄÄ„ÄÄÊ∑ªÂä†‰∏Ä‰∏™Êñ∞ÁöÑ‰ª£ÁêÜÊ∫êÊñπÊ≥ïÂ¶Ç‰∏ã:1„ÄÅÈ¶ñÂÖàÂú®ProxyFetcherÁ±ª‰∏≠Ê∑ªÂä†Ëá™ÂÆö‰πâÁöÑËé∑Âèñ‰ª£ÁêÜÁöÑÈùôÊÄÅÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÈúÄË¶Å‰ª•ÁîüÊàêÂô®(yield)ÂΩ¢ÂºèËøîÂõûhost:ipÊ†ºÂºèÁöÑ‰ª£ÁêÜÔºå‰æãÂ¶Ç:class ProxyFetcher(object):    # ....    # Ëá™ÂÆö‰πâ‰ª£ÁêÜÊ∫êËé∑ÂèñÊñπÊ≥ï    @staticmethod    def freeProxyCustom1():  # ÂëΩÂêç‰∏çÂíåÂ∑≤ÊúâÈáçÂ§çÂç≥ÂèØ        # ÈÄöËøáÊüêÁΩëÁ´ôÊàñËÄÖÊüêÊé•Âè£ÊàñÊüêÊï∞ÊçÆÂ∫ìËé∑Âèñ‰ª£ÁêÜ        # ÂÅáËÆæ‰Ω†Â∑≤ÁªèÊãøÂà∞‰∫Ü‰∏Ä‰∏™‰ª£ÁêÜÂàóË°®        proxies = [\""x.x.x.x:3128\"", \""x.x.x.x:80\""]        for proxy in proxies:            yield proxy        # Á°Æ‰øùÊØè‰∏™proxyÈÉΩÊòØ host:ipÊ≠£Á°ÆÁöÑÊ†ºÂºèËøîÂõû2„ÄÅÊ∑ªÂä†Â•ΩÊñπÊ≥ïÂêéÔºå‰øÆÊîπsetting.pyÊñá‰ª∂‰∏≠ÁöÑPROXY_FETCHERÈ°πÔºö„ÄÄ„ÄÄÂú®PROXY_FETCHER‰∏ãÊ∑ªÂä†Ëá™ÂÆö‰πâÊñπÊ≥ïÁöÑÂêçÂ≠ó:PROXY_FETCHER = [    \""freeProxy01\"",        \""freeProxy02\"",    # ....    \""freeProxyCustom1\""  #  # Á°Æ‰øùÂêçÂ≠óÂíå‰Ω†Ê∑ªÂä†ÊñπÊ≥ïÂêçÂ≠ó‰∏ÄËá¥]„ÄÄ„ÄÄschedule ËøõÁ®ã‰ºöÊØèÈöî‰∏ÄÊÆµÊó∂Èó¥ÊäìÂèñ‰∏ÄÊ¨°‰ª£ÁêÜÔºå‰∏ãÊ¨°ÊäìÂèñÊó∂‰ºöËá™Âä®ËØÜÂà´Ë∞ÉÁî®‰Ω†ÂÆö‰πâÁöÑÊñπÊ≥ï„ÄÇÂÖçË¥π‰ª£ÁêÜÊ∫êÁõÆÂâçÂÆûÁé∞ÁöÑÈááÈõÜÂÖçË¥π‰ª£ÁêÜÁΩëÁ´ôÊúâ(ÊéíÂêç‰∏çÂàÜÂÖàÂêé, ‰∏ãÈù¢‰ªÖÊòØÂØπÂÖ∂ÂèëÂ∏ÉÁöÑÂÖçË¥π‰ª£ÁêÜÊÉÖÂÜµ, ‰ªòË¥π‰ª£ÁêÜÊµãËØÑÂèØ‰ª•ÂèÇËÄÉËøôÈáå):‰ª£ÁêÜÂêçÁß∞Áä∂ÊÄÅÊõ¥Êñ∞ÈÄüÂ∫¶ÂèØÁî®ÁéáÂú∞ÂùÄ‰ª£Á†ÅÁ´ôÂ§ßÁà∑‚úî‚òÖ**Âú∞ÂùÄfreeProxy0166‰ª£ÁêÜ‚úî‚òÖ*Âú∞ÂùÄfreeProxy02ÂºÄÂøÉ‰ª£ÁêÜ‚úî‚òÖ*Âú∞ÂùÄfreeProxy03FreeProxyList‚úî‚òÖ*Âú∞ÂùÄfreeProxy04Âø´‰ª£ÁêÜ‚úî‚òÖ*Âú∞ÂùÄfreeProxy05FateZero‚úî‚òÖ‚òÖ*Âú∞ÂùÄfreeProxy06‰∫ë‰ª£ÁêÜ‚úî‚òÖ*Âú∞ÂùÄfreeProxy07Â∞èÂπª‰ª£ÁêÜ‚úî‚òÖ‚òÖ*Âú∞ÂùÄfreeProxy08ÂÖçË¥π‰ª£ÁêÜÂ∫ì‚úî‚òÜ*Âú∞ÂùÄfreeProxy0989‰ª£ÁêÜ‚úî‚òÜ*Âú∞ÂùÄfreeProxy10Á®ªÂ£≥‰ª£ÁêÜ‚úî‚òÖ‚òÖ***Âú∞ÂùÄfreeProxy11Â¶ÇÊûúËøòÊúâÂÖ∂‰ªñÂ•ΩÁöÑÂÖçË¥π‰ª£ÁêÜÁΩëÁ´ô, ÂèØ‰ª•Âú®Êèê‰∫§Âú®issues, ‰∏ãÊ¨°Êõ¥Êñ∞Êó∂‰ºöËÄÉËôëÂú®È°πÁõÆ‰∏≠ÊîØÊåÅ„ÄÇÈóÆÈ¢òÂèçÈ¶à„ÄÄ„ÄÄ‰ªª‰ΩïÈóÆÈ¢òÊ¨¢ËøéÂú®Issues ‰∏≠ÂèçÈ¶àÔºåÂêåÊó∂‰πüÂèØ‰ª•Âà∞ÊàëÁöÑÂçöÂÆ¢‰∏≠ÁïôË®Ä„ÄÇ„ÄÄ„ÄÄ‰Ω†ÁöÑÂèçÈ¶à‰ºöËÆ©Ê≠§È°πÁõÆÂèòÂæóÊõ¥Âä†ÂÆåÁæé„ÄÇË¥°ÁåÆ‰ª£Á†Å„ÄÄ„ÄÄÊú¨È°πÁõÆ‰ªÖ‰Ωú‰∏∫Âü∫Êú¨ÁöÑÈÄöÁî®ÁöÑ‰ª£ÁêÜÊ±†Êû∂ÊûÑÔºå‰∏çÊé•Êî∂ÁâπÊúâÂäüËÉΩ(ÂΩìÁÑ∂,‰∏çÈôê‰∫éÁâπÂà´Â•ΩÁöÑidea)„ÄÇ„ÄÄ„ÄÄÊú¨È°πÁõÆ‰æùÁÑ∂‰∏çÂ§üÂÆåÂñÑÔºåÂ¶ÇÊûúÂèëÁé∞bugÊàñÊúâÊñ∞ÁöÑÂäüËÉΩÊ∑ªÂä†ÔºåËØ∑Âú®Issues‰∏≠Êèê‰∫§bug(ÊàñÊñ∞ÂäüËÉΩ)ÊèèËø∞ÔºåÊàë‰ºöÂ∞ΩÂäõÊîπËøõÔºå‰ΩøÂ•πÊõ¥Âä†ÂÆåÁæé„ÄÇ„ÄÄ„ÄÄËøôÈáåÊÑüË∞¢‰ª•‰∏ãcontributorÁöÑÊó†ÁßÅÂ•âÁåÆÔºö„ÄÄ„ÄÄ@kangnwh | @bobobo80 | @halleywj | @newlyedward | @wang-ye | @gladmo | @bernieyangmh | @PythonYXY | @zuijiawoniu | @netAir | @scil | @tangrela | @highroom | @luocaodan | @vc5 | @1again | @obaiyan | @zsbh | @jiannanya | @Jerry12228Release Noteschangelog"
83,THUDM/ChatGLM-6B,https://github.com/THUDM/ChatGLM-6B/blob/main/README.md,Python,"ChatGLM-6B   üåê Blog ‚Ä¢ ü§ó HF Repo ‚Ä¢ üê¶ Twitter ‚Ä¢ üìÉ [GLM@ACL 22] [GitHub] ‚Ä¢ üìÉ [GLM-130B@ICLR 23] [GitHub]     üëã Âä†ÂÖ•Êàë‰ª¨ÁöÑ Slack Âíå WeChatRead this in English.‰ªãÁªçChatGLM-6B ÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑ„ÄÅÊîØÊåÅ‰∏≠Ëã±ÂèåËØ≠ÁöÑÂØπËØùËØ≠Ë®ÄÊ®°ÂûãÔºåÂü∫‰∫é General Language Model (GLM) Êû∂ÊûÑÔºåÂÖ∑Êúâ 62 ‰∫øÂèÇÊï∞„ÄÇÁªìÂêàÊ®°ÂûãÈáèÂåñÊäÄÊúØÔºåÁî®Êà∑ÂèØ‰ª•Âú®Ê∂àË¥πÁ∫ßÁöÑÊòæÂç°‰∏äËøõË°åÊú¨Âú∞ÈÉ®ÁΩ≤ÔºàINT4 ÈáèÂåñÁ∫ßÂà´‰∏ãÊúÄ‰ΩéÂè™ÈúÄ 6GB ÊòæÂ≠òÔºâ„ÄÇChatGLM-6B ‰ΩøÁî®‰∫ÜÂíå ChatGPT Áõ∏‰ººÁöÑÊäÄÊúØÔºåÈíàÂØπ‰∏≠ÊñáÈóÆÁ≠îÂíåÂØπËØùËøõË°å‰∫Ü‰ºòÂåñ„ÄÇÁªèËøáÁ∫¶ 1T Ê†áËØÜÁ¨¶ÁöÑ‰∏≠Ëã±ÂèåËØ≠ËÆ≠ÁªÉÔºåËæÖ‰ª•ÁõëÁù£ÂæÆË∞É„ÄÅÂèçÈ¶àËá™Âä©„ÄÅ‰∫∫Á±ªÂèçÈ¶àÂº∫ÂåñÂ≠¶‰π†Á≠âÊäÄÊúØÁöÑÂä†ÊåÅÔºå62 ‰∫øÂèÇÊï∞ÁöÑ ChatGLM-6B Â∑≤ÁªèËÉΩÁîüÊàêÁõ∏ÂΩìÁ¨¶Âêà‰∫∫Á±ªÂÅèÂ•ΩÁöÑÂõûÁ≠îÔºåÊõ¥Â§ö‰ø°ÊÅØËØ∑ÂèÇËÄÉÊàë‰ª¨ÁöÑÂçöÂÆ¢„ÄÇÊ¨¢ËøéÈÄöËøá chatglm.cn ‰ΩìÈ™åÊõ¥Â§ßËßÑÊ®°ÁöÑ ChatGLM Ê®°Âûã„ÄÇ‰∏∫‰∫ÜÊñπ‰æø‰∏ãÊ∏∏ÂºÄÂèëËÄÖÈíàÂØπËá™Â∑±ÁöÑÂ∫îÁî®Âú∫ÊôØÂÆöÂà∂Ê®°ÂûãÔºåÊàë‰ª¨ÂêåÊó∂ÂÆûÁé∞‰∫ÜÂü∫‰∫é P-Tuning v2 ÁöÑÈ´òÊïàÂèÇÊï∞ÂæÆË∞ÉÊñπÊ≥ï (‰ΩøÁî®ÊåáÂçó) ÔºåINT4 ÈáèÂåñÁ∫ßÂà´‰∏ãÊúÄ‰ΩéÂè™ÈúÄ 7GB ÊòæÂ≠òÂç≥ÂèØÂêØÂä®ÂæÆË∞É„ÄÇChatGLM-6B ÊùÉÈáçÂØπÂ≠¶ÊúØÁ†îÁ©∂ÂÆåÂÖ®ÂºÄÊîæÔºåÂú®Â°´ÂÜôÈóÆÂç∑ËøõË°åÁôªËÆ∞Âêé‰∫¶ÂÖÅËÆ∏ÂÖçË¥πÂïÜ‰∏ö‰ΩøÁî®„ÄÇÊÉ≥ËÆ© ChatGLM-6B Êõ¥Á¨¶Âêà‰Ω†ÁöÑÂ∫îÁî®Âú∫ÊôØÔºüÊ¨¢ËøéÂèÇ‰∏é Badcase ÂèçÈ¶àËÆ°Âàí„ÄÇChatGLM-6B ÂºÄÊ∫êÊ®°ÂûãÊó®Âú®‰∏éÂºÄÊ∫êÁ§æÂå∫‰∏ÄËµ∑Êé®Âä®Â§ßÊ®°ÂûãÊäÄÊúØÂèëÂ±ïÔºåÊÅ≥ËØ∑ÂºÄÂèëËÄÖÂíåÂ§ßÂÆ∂ÈÅµÂÆàÂºÄÊ∫êÂçèËÆÆÔºåÂãøÂ∞ÜÂºÄÊ∫êÊ®°ÂûãÂíå‰ª£Á†ÅÂèäÂü∫‰∫éÂºÄÊ∫êÈ°πÁõÆ‰∫ßÁîüÁöÑË°çÁîüÁâ©Áî®‰∫é‰ªª‰ΩïÂèØËÉΩÁªôÂõΩÂÆ∂ÂíåÁ§æ‰ºöÂ∏¶Êù•Âç±ÂÆ≥ÁöÑÁî®ÈÄî‰ª•ÂèäÁî®‰∫é‰ªª‰ΩïÊú™ÁªèËøáÂÆâÂÖ®ËØÑ‰º∞ÂíåÂ§áÊ°àÁöÑÊúçÂä°„ÄÇÁõÆÂâçÔºåÊú¨È°πÁõÆÂõ¢ÈòüÊú™Âü∫‰∫é ChatGLM-6B ÂºÄÂèë‰ªª‰ΩïÂ∫îÁî®ÔºåÂåÖÊã¨ÁΩëÈ°µÁ´Ø„ÄÅÂÆâÂçì„ÄÅËãπÊûú iOS Âèä Windows App Á≠âÂ∫îÁî®„ÄÇÂ∞ΩÁÆ°Ê®°ÂûãÂú®ËÆ≠ÁªÉÁöÑÂêÑ‰∏™Èò∂ÊÆµÈÉΩÂ∞ΩÂäõÁ°Æ‰øùÊï∞ÊçÆÁöÑÂêàËßÑÊÄßÂíåÂáÜÁ°ÆÊÄßÔºå‰ΩÜÁî±‰∫é ChatGLM-6B Ê®°ÂûãËßÑÊ®°ËæÉÂ∞èÔºå‰∏îÊ®°ÂûãÂèóÊ¶ÇÁéáÈöèÊú∫ÊÄßÂõ†Á¥†ÂΩ±ÂìçÔºåÊó†Ê≥ï‰øùËØÅËæìÂá∫ÂÜÖÂÆπÁöÑÂáÜÁ°ÆÊÄßÔºå‰∏îÊ®°ÂûãÊòìË¢´ËØØÂØºÔºàËØ¶ËßÅÂ±ÄÈôêÊÄßÔºâ„ÄÇÊú¨È°πÁõÆ‰∏çÊâøÊãÖÂºÄÊ∫êÊ®°ÂûãÂíå‰ª£Á†ÅÂØºËá¥ÁöÑÊï∞ÊçÆÂÆâÂÖ®„ÄÅËàÜÊÉÖÈ£éÈô©ÊàñÂèëÁîü‰ªª‰ΩïÊ®°ÂûãË¢´ËØØÂØº„ÄÅÊª•Áî®„ÄÅ‰º†Êí≠„ÄÅ‰∏çÂΩìÂà©Áî®ËÄå‰∫ßÁîüÁöÑÈ£éÈô©ÂíåË¥£‰ªª„ÄÇÊõ¥Êñ∞‰ø°ÊÅØ[2023/07/25] ÂèëÂ∏É CodeGeeX2 ÔºåÂü∫‰∫é ChatGLM2-6B ÁöÑ‰ª£Á†ÅÁîüÊàêÊ®°ÂûãÔºå‰ª£Á†ÅËÉΩÂäõÂÖ®Èù¢ÊèêÂçáÔºåÊõ¥Â§öÁâπÊÄßÂåÖÊã¨ÔºöÊõ¥Âº∫Â§ßÁöÑ‰ª£Á†ÅËÉΩÂäõÔºöCodeGeeX2-6B Ëøõ‰∏ÄÊ≠•ÁªèËøá‰∫Ü 600B ‰ª£Á†ÅÊï∞ÊçÆÈ¢ÑËÆ≠ÁªÉÔºåÁõ∏ÊØî CodeGeeX ‰∏Ä‰ª£Ê®°ÂûãÔºåÂú®‰ª£Á†ÅËÉΩÂäõ‰∏äÂÖ®Èù¢ÊèêÂçáÔºåHumanEval-X ËØÑÊµãÈõÜÁöÑÂÖ≠ÁßçÁºñÁ®ãËØ≠Ë®ÄÂùáÂ§ßÂπÖÊèêÂçá (Python +57%, C++ +71%, Java +54%, JavaScript +83%, Go +56%, Rust +321%)ÔºåÂú®Python‰∏äËææÂà∞ 35.9% ÁöÑ Pass@1 ‰∏ÄÊ¨°ÈÄöËøáÁéáÔºåË∂ÖË∂äËßÑÊ®°Êõ¥Â§ßÁöÑ StarCoder-15B„ÄÇÊõ¥‰ºòÁßÄÁöÑÊ®°ÂûãÁâπÊÄßÔºöÁªßÊâø ChatGLM2-6B Ê®°ÂûãÁâπÊÄßÔºåCodeGeeX2-6B Êõ¥Â•ΩÊîØÊåÅ‰∏≠Ëã±ÊñáËæìÂÖ•ÔºåÊîØÊåÅÊúÄÂ§ß 8192 Â∫èÂàóÈïøÂ∫¶ÔºåÊé®ÁêÜÈÄüÂ∫¶ËæÉ‰∏Ä‰ª£ Â§ßÂπÖÊèêÂçáÔºåÈáèÂåñÂêé‰ªÖÈúÄ6GBÊòæÂ≠òÂç≥ÂèØËøêË°åÔºåÊîØÊåÅËΩªÈáèÁ∫ßÊú¨Âú∞ÂåñÈÉ®ÁΩ≤„ÄÇÊõ¥ÂÖ®Èù¢ÁöÑAIÁºñÁ®ãÂä©ÊâãÔºöCodeGeeXÊèí‰ª∂ÔºàVS Code, JetbrainsÔºâÂêéÁ´ØÂçáÁ∫ßÔºåÊîØÊåÅË∂ÖËøá100ÁßçÁºñÁ®ãËØ≠Ë®ÄÔºåÊñ∞Â¢û‰∏ä‰∏ãÊñáË°•ÂÖ®„ÄÅË∑®Êñá‰ª∂Ë°•ÂÖ®Á≠âÂÆûÁî®ÂäüËÉΩ„ÄÇÁªìÂêà Ask CodeGeeX ‰∫§‰∫íÂºèAIÁºñÁ®ãÂä©ÊâãÔºåÊîØÊåÅ‰∏≠Ëã±ÊñáÂØπËØùËß£ÂÜ≥ÂêÑÁßçÁºñÁ®ãÈóÆÈ¢òÔºåÂåÖÊã¨‰∏î‰∏çÈôê‰∫é‰ª£Á†ÅËß£Èáä„ÄÅ‰ª£Á†ÅÁøªËØë„ÄÅ‰ª£Á†ÅÁ∫†Èîô„ÄÅÊñáÊ°£ÁîüÊàêÁ≠âÔºåÂ∏ÆÂä©Á®ãÂ∫èÂëòÊõ¥È´òÊïàÂºÄÂèë„ÄÇ[2023/06/25] ÂèëÂ∏É ChatGLM2-6BÔºåChatGLM-6B ÁöÑÂçáÁ∫ßÁâàÊú¨ÔºåÂú®‰øùÁïô‰∫Ü‰∫ÜÂàù‰ª£Ê®°ÂûãÂØπËØùÊµÅÁïÖ„ÄÅÈÉ®ÁΩ≤Èó®ÊßõËæÉ‰ΩéÁ≠â‰ºóÂ§ö‰ºòÁßÄÁâπÊÄßÁöÑÂü∫Á°Ä‰πã‰∏äÔºåChatGLM2-6B ÂºïÂÖ•‰∫ÜÂ¶Ç‰∏ãÊñ∞ÁâπÊÄßÔºöÊõ¥Âº∫Â§ßÁöÑÊÄßËÉΩÔºöÂü∫‰∫é ChatGLM Âàù‰ª£Ê®°ÂûãÁöÑÂºÄÂèëÁªèÈ™åÔºåÊàë‰ª¨ÂÖ®Èù¢ÂçáÁ∫ß‰∫Ü ChatGLM2-6B ÁöÑÂü∫Â∫ßÊ®°Âûã„ÄÇChatGLM2-6B ‰ΩøÁî®‰∫Ü GLM ÁöÑÊ∑∑ÂêàÁõÆÊ†áÂáΩÊï∞ÔºåÁªèËøá‰∫Ü 1.4T ‰∏≠Ëã±Ê†áËØÜÁ¨¶ÁöÑÈ¢ÑËÆ≠ÁªÉ‰∏é‰∫∫Á±ªÂÅèÂ•ΩÂØπÈΩêËÆ≠ÁªÉÔºåËØÑÊµãÁªìÊûúÊòæÁ§∫ÔºåÁõ∏ÊØî‰∫éÂàù‰ª£Ê®°ÂûãÔºåChatGLM2-6B Âú® MMLUÔºà+23%Ôºâ„ÄÅCEvalÔºà+33%Ôºâ„ÄÅGSM8KÔºà+571%Ôºâ „ÄÅBBHÔºà+60%ÔºâÁ≠âÊï∞ÊçÆÈõÜ‰∏äÁöÑÊÄßËÉΩÂèñÂæó‰∫ÜÂ§ßÂπÖÂ∫¶ÁöÑÊèêÂçáÔºåÂú®ÂêåÂ∞∫ÂØ∏ÂºÄÊ∫êÊ®°Âûã‰∏≠ÂÖ∑ÊúâËæÉÂº∫ÁöÑÁ´û‰∫âÂäõ„ÄÇÊõ¥ÈïøÁöÑ‰∏ä‰∏ãÊñáÔºöÂü∫‰∫é FlashAttention ÊäÄÊúØÔºåÊàë‰ª¨Â∞ÜÂü∫Â∫ßÊ®°ÂûãÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ÔºàContext LengthÔºâÁî± ChatGLM-6B ÁöÑ 2K Êâ©Â±ïÂà∞‰∫Ü 32KÔºåÂπ∂Âú®ÂØπËØùÈò∂ÊÆµ‰ΩøÁî® 8K ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶ËÆ≠ÁªÉÔºåÂÖÅËÆ∏Êõ¥Â§öËΩÆÊ¨°ÁöÑÂØπËØù„ÄÇ‰ΩÜÂΩìÂâçÁâàÊú¨ÁöÑ ChatGLM2-6B ÂØπÂçïËΩÆË∂ÖÈïøÊñáÊ°£ÁöÑÁêÜËß£ËÉΩÂäõÊúâÈôêÔºåÊàë‰ª¨‰ºöÂú®ÂêéÁª≠Ëø≠‰ª£ÂçáÁ∫ß‰∏≠ÁùÄÈáçËøõË°å‰ºòÂåñ„ÄÇÊõ¥È´òÊïàÁöÑÊé®ÁêÜÔºöÂü∫‰∫é Multi-Query Attention ÊäÄÊúØÔºåChatGLM2-6B ÊúâÊõ¥È´òÊïàÁöÑÊé®ÁêÜÈÄüÂ∫¶ÂíåÊõ¥‰ΩéÁöÑÊòæÂ≠òÂç†Áî®ÔºöÂú®ÂÆòÊñπÁöÑÊ®°ÂûãÂÆûÁé∞‰∏ãÔºåÊé®ÁêÜÈÄüÂ∫¶Áõ∏ÊØîÂàù‰ª£ÊèêÂçá‰∫Ü 42%ÔºåINT4 ÈáèÂåñ‰∏ãÔºå6G ÊòæÂ≠òÊîØÊåÅÁöÑÂØπËØùÈïøÂ∫¶Áî± 1K ÊèêÂçáÂà∞‰∫Ü 8K„ÄÇÊõ¥Â§ö‰ø°ÊÅØÂèÇËßÅ ChatGLM2-6B„ÄÇ[2023/06/14] ÂèëÂ∏É WebGLMÔºå‰∏ÄÈ°πË¢´Êé•Âèó‰∫éKDD 2023ÁöÑÁ†îÁ©∂Â∑•‰ΩúÔºåÊîØÊåÅÂà©Áî®ÁΩëÁªú‰ø°ÊÅØÁîüÊàêÂ∏¶ÊúâÂáÜÁ°ÆÂºïÁî®ÁöÑÈïøÂõûÁ≠î„ÄÇ[2023/05/17] ÂèëÂ∏É VisualGLM-6BÔºå‰∏Ä‰∏™ÊîØÊåÅÂõæÂÉèÁêÜËß£ÁöÑÂ§öÊ®°ÊÄÅÂØπËØùËØ≠Ë®ÄÊ®°Âûã„ÄÇÂèØ‰ª•ÈÄöËøáÊú¨‰ªìÂ∫ì‰∏≠ÁöÑ cli_demo_vision.py Âíå web_demo_vision.py Êù•ËøêË°åÂëΩ‰ª§Ë°åÂíåÁΩëÈ°µ Demo„ÄÇÊ≥®ÊÑè VisualGLM-6B ÈúÄË¶ÅÈ¢ùÂ§ñÂÆâË£Ö SwissArmyTransformer Âíå torchvision„ÄÇÊõ¥Â§ö‰ø°ÊÅØÂèÇËßÅ VisualGLM-6B„ÄÇ[2023/05/15] Êõ¥Êñ∞ v1.1 ÁâàÊú¨ checkpointÔºåËÆ≠ÁªÉÊï∞ÊçÆÂ¢ûÂä†Ëã±ÊñáÊåá‰ª§ÂæÆË∞ÉÊï∞ÊçÆ‰ª•Âπ≥Ë°°‰∏≠Ëã±ÊñáÊï∞ÊçÆÊØî‰æãÔºåËß£ÂÜ≥Ëã±ÊñáÂõûÁ≠î‰∏≠Â§πÊùÇ‰∏≠ÊñáËØçËØ≠ÁöÑÁé∞Ë±°„ÄÇ‰ª•‰∏ãÊòØÊõ¥Êñ∞ÂâçÂêéÁöÑËã±ÊñáÈóÆÈ¢òÂØπÊØîÔºöÈóÆÈ¢òÔºöDescribe a time when you had to make a difficult decision.v1.0:v1.1:ÈóÆÈ¢òÔºöDescribe the function of a computer motherboardv1.0:v1.1:ÈóÆÈ¢òÔºöDevelop a plan to reduce electricity usage in a home.v1.0:v1.1:ÈóÆÈ¢òÔºöÊú™Êù•ÁöÑNFTÔºåÂèØËÉΩÁúüÂÆûÂÆö‰πâ‰∏ÄÁßçÁé∞ÂÆûÁöÑËµÑ‰∫ßÔºåÂÆÉ‰ºöÊòØ‰∏ÄÂ§ÑÊàø‰∫ßÔºå‰∏ÄËæÜÊ±ΩËΩ¶Ôºå‰∏ÄÁâáÂúüÂú∞Á≠âÁ≠âÔºåËøôÊ†∑ÁöÑÊï∞Â≠óÂá≠ËØÅÂèØËÉΩÊØîÁúüÂÆûÁöÑ‰∏úË•øÊõ¥Êúâ‰ª∑ÂÄºÔºå‰Ω†ÂèØ‰ª•ÈöèÊó∂‰∫§ÊòìÂíå‰ΩøÁî®ÔºåÂú®ËôöÊãüÂíåÁé∞ÂÆû‰∏≠Êó†ÁºùÁöÑËÆ©Êã•ÊúâÁöÑËµÑ‰∫ßÁªßÁª≠ÂàõÈÄ†‰ª∑ÂÄºÔºåÊú™Êù•‰ºöÊòØ‰∏áÁâ©ÂΩíÊàëÊâÄÁî®Ôºå‰ΩÜ‰∏çÂΩíÊàëÊâÄÊúâÁöÑÊó∂‰ª£„ÄÇÁøªËØëÊàê‰∏ì‰∏öÁöÑËã±ËØ≠v1.0:v1.1:Êõ¥Â§öÊõ¥Êñ∞‰ø°ÊÅØÂèÇËßÅ UPDATE.mdÂèãÊÉÖÈìæÊé•ÂØπ ChatGLM ËøõË°åÂä†ÈÄüÁöÑÂºÄÊ∫êÈ°πÁõÆÔºölyraChatGLM: ÂØπ ChatGLM-6B ËøõË°åÊé®ÁêÜÂä†ÈÄüÔºåÊúÄÈ´òÂèØ‰ª•ÂÆûÁé∞ 9000+ tokens/s ÁöÑÊé®ÁêÜÈÄüÂ∫¶ChatGLM-MNN: ‰∏Ä‰∏™Âü∫‰∫é MNN ÁöÑ ChatGLM-6B C++ Êé®ÁêÜÂÆûÁé∞ÔºåÊîØÊåÅÊ†πÊçÆÊòæÂ≠òÂ§ßÂ∞èËá™Âä®ÂàÜÈÖçËÆ°ÁÆó‰ªªÂä°Áªô GPU Âíå CPUJittorLLMsÔºöÊúÄ‰Ωé3GÊòæÂ≠òÊàñËÄÖÊ≤°ÊúâÊòæÂç°ÈÉΩÂèØËøêË°å ChatGLM-6B FP16Ôºå ÊîØÊåÅLinux„ÄÅwindows„ÄÅMacÈÉ®ÁΩ≤InferLLMÔºöËΩªÈáèÁ∫ß C++ Êé®ÁêÜÔºåÂèØ‰ª•ÂÆûÁé∞Êú¨Âú∞ x86ÔºåArm Â§ÑÁêÜÂô®‰∏äÂÆûÊó∂ËÅäÂ§©ÔºåÊâãÊú∫‰∏ä‰πüÂêåÊ†∑ÂèØ‰ª•ÂÆûÊó∂ËøêË°åÔºåËøêË°åÂÜÖÂ≠òÂè™ÈúÄË¶Å 4GÂü∫‰∫éÊàñ‰ΩøÁî®‰∫Ü ChatGLM-6B ÁöÑÂºÄÊ∫êÈ°πÁõÆÔºölangchain-ChatGLMÔºöÂü∫‰∫é langchain ÁöÑ ChatGLM Â∫îÁî®ÔºåÂÆûÁé∞Âü∫‰∫éÂèØÊâ©Â±ïÁü•ËØÜÂ∫ìÁöÑÈóÆÁ≠îÈóªËææÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãË∞ÉÁî®Âπ≥Âè∞ÔºåÂü∫‰∫é ChatGLM-6B ÂÆûÁé∞‰∫ÜÁ±ª ChatPDF ÂäüËÉΩglm-botÔºöÂ∞ÜChatGLMÊé•ÂÖ•KoishiÂèØÂú®ÂêÑÂ§ßËÅäÂ§©Âπ≥Âè∞‰∏äË∞ÉÁî®ChatGLMChuanhu Chat: ‰∏∫ÂêÑ‰∏™Â§ßËØ≠Ë®ÄÊ®°ÂûãÂíåÂú®Á∫øÊ®°ÂûãAPIÊèê‰æõÁæéËßÇÊòìÁî®„ÄÅÂäüËÉΩ‰∏∞ÂØå„ÄÅÂø´ÈÄüÈÉ®ÁΩ≤ÁöÑÁî®Êà∑ÁïåÈù¢ÔºåÊîØÊåÅChatGLM-6B„ÄÇÊîØÊåÅ ChatGLM-6B ÂíåÁõ∏ÂÖ≥Â∫îÁî®Âú®Á∫øËÆ≠ÁªÉÁöÑÁ§∫‰æãÈ°πÁõÆÔºöChatGLM-6B ÁöÑÈÉ®ÁΩ≤‰∏éÂæÆË∞ÉÊïôÁ®ãChatGLM-6B ÁªìÂêà langchain ÂÆûÁé∞Êú¨Âú∞Áü•ËØÜÂ∫ì QA BotÁ¨¨‰∏âÊñπËØÑÊµãÔºöMeasuring Massive Multitask Chinese UnderstandingÊõ¥Â§öÂºÄÊ∫êÈ°πÁõÆÂèÇËßÅ PROJECT.md‰ΩøÁî®ÊñπÂºèÁ°¨‰ª∂ÈúÄÊ±ÇÈáèÂåñÁ≠âÁ∫ßÊúÄ‰Ωé GPU ÊòæÂ≠òÔºàÊé®ÁêÜÔºâÊúÄ‰Ωé GPU ÊòæÂ≠òÔºàÈ´òÊïàÂèÇÊï∞ÂæÆË∞ÉÔºâFP16ÔºàÊó†ÈáèÂåñÔºâ13 GB14 GBINT88 GB9 GBINT46 GB7 GBÁéØÂ¢ÉÂÆâË£Ö‰ΩøÁî® pip ÂÆâË£Ö‰æùËµñÔºöpip install -r requirements.txtÔºåÂÖ∂‰∏≠ transformers Â∫ìÁâàÊú¨Êé®Ëçê‰∏∫ 4.27.1Ôºå‰ΩÜÁêÜËÆ∫‰∏ä‰∏ç‰Ωé‰∫é 4.23.1 Âç≥ÂèØ„ÄÇÊ≠§Â§ñÔºåÂ¶ÇÊûúÈúÄË¶ÅÂú® cpu ‰∏äËøêË°åÈáèÂåñÂêéÁöÑÊ®°ÂûãÔºåËøòÈúÄË¶ÅÂÆâË£Ö gcc ‰∏é openmp„ÄÇÂ§öÊï∞ Linux ÂèëË°åÁâàÈªòËÆ§Â∑≤ÂÆâË£Ö„ÄÇÂØπ‰∫é Windows ÔºåÂèØÂú®ÂÆâË£Ö TDM-GCC Êó∂ÂãæÈÄâ openmp„ÄÇ Windows ÊµãËØïÁéØÂ¢É gcc ÁâàÊú¨‰∏∫ TDM-GCC 10.3.0Ôºå Linux ‰∏∫ gcc 11.3.0„ÄÇÂú® MacOS ‰∏äËØ∑ÂèÇËÄÉ Q1„ÄÇ‰ª£Á†ÅË∞ÉÁî®ÂèØ‰ª•ÈÄöËøáÂ¶Ç‰∏ã‰ª£Á†ÅË∞ÉÁî® ChatGLM-6B Ê®°ÂûãÊù•ÁîüÊàêÂØπËØùÔºö>>> from transformers import AutoTokenizer, AutoModel>>> tokenizer = AutoTokenizer.from_pretrained(\""THUDM/chatglm-6b\"", trust_remote_code=True)>>> model = AutoModel.from_pretrained(\""THUDM/chatglm-6b\"", trust_remote_code=True).half().cuda()>>> model = model.eval()>>> response, history = model.chat(tokenizer, \""‰Ω†Â•Ω\"", history=[])>>> print(response)‰Ω†Â•Ωüëã!ÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM-6B,ÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†,Ê¨¢ËøéÈóÆÊàë‰ªª‰ΩïÈóÆÈ¢ò„ÄÇ>>> response, history = model.chat(tokenizer, \""Êôö‰∏äÁù°‰∏çÁùÄÂ∫îËØ•ÊÄé‰πàÂäû\"", history=history)>>> print(response)Êôö‰∏äÁù°‰∏çÁùÄÂèØËÉΩ‰ºöËÆ©‰Ω†ÊÑüÂà∞ÁÑ¶ËôëÊàñ‰∏çËàíÊúç,‰ΩÜ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÂèØ‰ª•Â∏ÆÂä©‰Ω†ÂÖ•Áù°ÁöÑÊñπÊ≥ï:1. Âà∂ÂÆöËßÑÂæãÁöÑÁù°Áú†Êó∂Èó¥Ë°®:‰øùÊåÅËßÑÂæãÁöÑÁù°Áú†Êó∂Èó¥Ë°®ÂèØ‰ª•Â∏ÆÂä©‰Ω†Âª∫Á´ãÂÅ•Â∫∑ÁöÑÁù°Áú†‰π†ÊÉØ,‰Ωø‰Ω†Êõ¥ÂÆπÊòìÂÖ•Áù°„ÄÇÂ∞ΩÈáèÂú®ÊØèÂ§©ÁöÑÁõ∏ÂêåÊó∂Èó¥‰∏äÂ∫ä,Âπ∂Âú®Âêå‰∏ÄÊó∂Èó¥Ëµ∑Â∫ä„ÄÇ2. ÂàõÈÄ†‰∏Ä‰∏™ËàíÈÄÇÁöÑÁù°Áú†ÁéØÂ¢É:Á°Æ‰øùÁù°Áú†ÁéØÂ¢ÉËàíÈÄÇ,ÂÆâÈùô,ÈªëÊöó‰∏îÊ∏©Â∫¶ÈÄÇÂÆú„ÄÇÂèØ‰ª•‰ΩøÁî®ËàíÈÄÇÁöÑÂ∫ä‰∏äÁî®ÂìÅ,Âπ∂‰øùÊåÅÊàøÈó¥ÈÄöÈ£é„ÄÇ3. ÊîæÊùæË∫´ÂøÉ:Âú®Áù°ÂâçÂÅö‰∫õÊîæÊùæÁöÑÊ¥ªÂä®,‰æãÂ¶ÇÊ≥°‰∏™ÁÉ≠Ê∞¥Êæ°,Âê¨‰∫õËΩªÊüîÁöÑÈü≥‰πê,ÈòÖËØª‰∏Ä‰∫õÊúâË∂£ÁöÑ‰π¶Á±çÁ≠â,ÊúâÂä©‰∫éÁºìËß£Á¥ßÂº†ÂíåÁÑ¶Ëôë,‰Ωø‰Ω†Êõ¥ÂÆπÊòìÂÖ•Áù°„ÄÇ4. ÈÅøÂÖçÈ•ÆÁî®Âê´ÊúâÂíñÂï°Âõ†ÁöÑÈ•ÆÊñô:ÂíñÂï°Âõ†ÊòØ‰∏ÄÁßçÂà∫ÊøÄÊÄßÁâ©Ë¥®,‰ºöÂΩ±Âìç‰Ω†ÁöÑÁù°Áú†Ë¥®Èáè„ÄÇÂ∞ΩÈáèÈÅøÂÖçÂú®Áù°ÂâçÈ•ÆÁî®Âê´ÊúâÂíñÂï°Âõ†ÁöÑÈ•ÆÊñô,‰æãÂ¶ÇÂíñÂï°,Ëå∂ÂíåÂèØ‰πê„ÄÇ5. ÈÅøÂÖçÂú®Â∫ä‰∏äÂÅö‰∏éÁù°Áú†Êó†ÂÖ≥ÁöÑ‰∫ãÊÉÖ:Âú®Â∫ä‰∏äÂÅö‰∫õ‰∏éÁù°Áú†Êó†ÂÖ≥ÁöÑ‰∫ãÊÉÖ,‰æãÂ¶ÇÁúãÁîµÂΩ±,Áé©Ê∏∏ÊàèÊàñÂ∑•‰ΩúÁ≠â,ÂèØËÉΩ‰ºöÂπ≤Êâ∞‰Ω†ÁöÑÁù°Áú†„ÄÇ6. Â∞ùËØïÂëºÂê∏ÊäÄÂ∑ß:Ê∑±ÂëºÂê∏ÊòØ‰∏ÄÁßçÊîæÊùæÊäÄÂ∑ß,ÂèØ‰ª•Â∏ÆÂä©‰Ω†ÁºìËß£Á¥ßÂº†ÂíåÁÑ¶Ëôë,‰Ωø‰Ω†Êõ¥ÂÆπÊòìÂÖ•Áù°„ÄÇËØïÁùÄÊÖ¢ÊÖ¢Âê∏Ê∞î,‰øùÊåÅÂá†ÁßíÈíü,ÁÑ∂ÂêéÁºìÊÖ¢ÂëºÊ∞î„ÄÇÂ¶ÇÊûúËøô‰∫õÊñπÊ≥ïÊó†Ê≥ïÂ∏ÆÂä©‰Ω†ÂÖ•Áù°,‰Ω†ÂèØ‰ª•ËÄÉËôëÂí®ËØ¢ÂåªÁîüÊàñÁù°Áú†‰∏ìÂÆ∂,ÂØªÊ±ÇËøõ‰∏ÄÊ≠•ÁöÑÂª∫ËÆÆ„ÄÇÊ®°ÂûãÁöÑÂÆûÁé∞‰ªçÁÑ∂Â§ÑÂú®ÂèòÂä®‰∏≠„ÄÇÂ¶ÇÊûúÂ∏åÊúõÂõ∫ÂÆö‰ΩøÁî®ÁöÑÊ®°ÂûãÂÆûÁé∞‰ª•‰øùËØÅÂÖºÂÆπÊÄßÔºåÂèØ‰ª•Âú® from_pretrained ÁöÑË∞ÉÁî®‰∏≠Â¢ûÂä† revision=\""v1.1.0\"" ÂèÇÊï∞„ÄÇv1.1.0 ÊòØÂΩìÂâçÊúÄÊñ∞ÁöÑÁâàÊú¨Âè∑ÔºåÂÆåÊï¥ÁöÑÁâàÊú¨ÂàóË°®ÂèÇËßÅ Change Log„ÄÇ‰ªéÊú¨Âú∞Âä†ËΩΩÊ®°Âûã‰ª•‰∏ä‰ª£Á†Å‰ºöÁî± transformers Ëá™Âä®‰∏ãËΩΩÊ®°ÂûãÂÆûÁé∞ÂíåÂèÇÊï∞„ÄÇÂÆåÊï¥ÁöÑÊ®°ÂûãÂÆûÁé∞ÂèØ‰ª•Âú® Hugging Face Hub„ÄÇÂ¶ÇÊûú‰Ω†ÁöÑÁΩëÁªúÁéØÂ¢ÉËæÉÂ∑ÆÔºå‰∏ãËΩΩÊ®°ÂûãÂèÇÊï∞ÂèØËÉΩ‰ºöËä±Ë¥πËæÉÈïøÊó∂Èó¥ÁîöËá≥Â§±Ë¥•„ÄÇÊ≠§Êó∂ÂèØ‰ª•ÂÖàÂ∞ÜÊ®°Âûã‰∏ãËΩΩÂà∞Êú¨Âú∞ÔºåÁÑ∂Âêé‰ªéÊú¨Âú∞Âä†ËΩΩ„ÄÇ‰ªé Hugging Face Hub ‰∏ãËΩΩÊ®°ÂûãÈúÄË¶ÅÂÖàÂÆâË£ÖGit LFSÔºåÁÑ∂ÂêéËøêË°ågit clone https://huggingface.co/THUDM/chatglm-6bÂ¶ÇÊûú‰Ω†‰ªé Hugging Face Hub ‰∏ä‰∏ãËΩΩ checkpoint ÁöÑÈÄüÂ∫¶ËæÉÊÖ¢ÔºåÂèØ‰ª•Âè™‰∏ãËΩΩÊ®°ÂûãÂÆûÁé∞GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/THUDM/chatglm-6bÁÑ∂Âêé‰ªéËøôÈáåÊâãÂä®‰∏ãËΩΩÊ®°ÂûãÂèÇÊï∞Êñá‰ª∂ÔºåÂπ∂Â∞Ü‰∏ãËΩΩÁöÑÊñá‰ª∂ÊõøÊç¢Âà∞Êú¨Âú∞ÁöÑ chatglm-6b ÁõÆÂΩï‰∏ã„ÄÇÂ∞ÜÊ®°Âûã‰∏ãËΩΩÂà∞Êú¨Âú∞‰πãÂêéÔºåÂ∞Ü‰ª•‰∏ä‰ª£Á†Å‰∏≠ÁöÑ THUDM/chatglm-6b ÊõøÊç¢‰∏∫‰Ω†Êú¨Âú∞ÁöÑ chatglm-6b Êñá‰ª∂Â§πÁöÑË∑ØÂæÑÔºåÂç≥ÂèØ‰ªéÊú¨Âú∞Âä†ËΩΩÊ®°Âûã„ÄÇOptional Ê®°ÂûãÁöÑÂÆûÁé∞‰ªçÁÑ∂Â§ÑÂú®ÂèòÂä®‰∏≠„ÄÇÂ¶ÇÊûúÂ∏åÊúõÂõ∫ÂÆö‰ΩøÁî®ÁöÑÊ®°ÂûãÂÆûÁé∞‰ª•‰øùËØÅÂÖºÂÆπÊÄßÔºåÂèØ‰ª•ÊâßË°ågit checkout v1.1.0Demo & APIÊàë‰ª¨Êèê‰æõ‰∫Ü‰∏Ä‰∏™Âü∫‰∫é Gradio ÁöÑÁΩëÈ°µÁâà Demo Âíå‰∏Ä‰∏™ÂëΩ‰ª§Ë°å Demo„ÄÇ‰ΩøÁî®Êó∂È¶ñÂÖàÈúÄË¶Å‰∏ãËΩΩÊú¨‰ªìÂ∫ìÔºögit clone https://github.com/THUDM/ChatGLM-6Bcd ChatGLM-6BÁΩëÈ°µÁâà DemoÈ¶ñÂÖàÂÆâË£Ö GradioÔºöpip install gradioÔºåÁÑ∂ÂêéËøêË°å‰ªìÂ∫ì‰∏≠ÁöÑ web_demo.pyÔºöpython web_demo.pyÁ®ãÂ∫è‰ºöËøêË°å‰∏Ä‰∏™ Web ServerÔºåÂπ∂ËæìÂá∫Âú∞ÂùÄ„ÄÇÂú®ÊµèËßàÂô®‰∏≠ÊâìÂºÄËæìÂá∫ÁöÑÂú∞ÂùÄÂç≥ÂèØ‰ΩøÁî®„ÄÇÊúÄÊñ∞Áâà Demo ÂÆûÁé∞‰∫ÜÊâìÂ≠óÊú∫ÊïàÊûúÔºåÈÄüÂ∫¶‰ΩìÈ™åÂ§ßÂ§ßÊèêÂçá„ÄÇÊ≥®ÊÑèÔºåÁî±‰∫éÂõΩÂÜÖ Gradio ÁöÑÁΩëÁªúËÆøÈóÆËæÉ‰∏∫ÁºìÊÖ¢ÔºåÂêØÁî® demo.queue().launch(share=True, inbrowser=True) Êó∂ÊâÄÊúâÁΩëÁªú‰ºöÁªèËøá Gradio ÊúçÂä°Âô®ËΩ¨ÂèëÔºåÂØºËá¥ÊâìÂ≠óÊú∫‰ΩìÈ™åÂ§ßÂπÖ‰∏ãÈôçÔºåÁé∞Âú®ÈªòËÆ§ÂêØÂä®ÊñπÂºèÂ∑≤ÁªèÊîπ‰∏∫ share=FalseÔºåÂ¶ÇÊúâÈúÄË¶ÅÂÖ¨ÁΩëËÆøÈóÆÁöÑÈúÄÊ±ÇÔºåÂèØ‰ª•ÈáçÊñ∞‰øÆÊîπ‰∏∫ share=True ÂêØÂä®„ÄÇÊÑüË∞¢ @AdamBear ÂÆûÁé∞‰∫ÜÂü∫‰∫é Streamlit ÁöÑÁΩëÈ°µÁâà DemoÔºåËøêË°åÊñπÂºèËßÅ#117.ÂëΩ‰ª§Ë°å DemoËøêË°å‰ªìÂ∫ì‰∏≠ cli_demo.pyÔºöpython cli_demo.pyÁ®ãÂ∫è‰ºöÂú®ÂëΩ‰ª§Ë°å‰∏≠ËøõË°å‰∫§‰∫íÂºèÁöÑÂØπËØùÔºåÂú®ÂëΩ‰ª§Ë°å‰∏≠ËæìÂÖ•ÊåáÁ§∫Âπ∂ÂõûËΩ¶Âç≥ÂèØÁîüÊàêÂõûÂ§çÔºåËæìÂÖ• clear ÂèØ‰ª•Ê∏ÖÁ©∫ÂØπËØùÂéÜÂè≤ÔºåËæìÂÖ• stop ÁªàÊ≠¢Á®ãÂ∫è„ÄÇAPIÈÉ®ÁΩ≤È¶ñÂÖàÈúÄË¶ÅÂÆâË£ÖÈ¢ùÂ§ñÁöÑ‰æùËµñ pip install fastapi uvicornÔºåÁÑ∂ÂêéËøêË°å‰ªìÂ∫ì‰∏≠ÁöÑ api.pyÔºöpython api.pyÈªòËÆ§ÈÉ®ÁΩ≤Âú®Êú¨Âú∞ÁöÑ 8000 Á´ØÂè£ÔºåÈÄöËøá POST ÊñπÊ≥ïËøõË°åË∞ÉÁî®curl -X POST \""http://127.0.0.1:8000\"" \\     -H 'Content-Type: application/json' \\     -d '{\""prompt\"": \""‰Ω†Â•Ω\"", \""history\"": []}'ÂæóÂà∞ÁöÑËøîÂõûÂÄº‰∏∫{  \""response\"":\""‰Ω†Â•ΩüëãÔºÅÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM-6BÔºåÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†ÔºåÊ¨¢ËøéÈóÆÊàë‰ªª‰ΩïÈóÆÈ¢ò„ÄÇ\"",  \""history\"":[[\""‰Ω†Â•Ω\"",\""‰Ω†Â•ΩüëãÔºÅÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM-6BÔºåÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†ÔºåÊ¨¢ËøéÈóÆÊàë‰ªª‰ΩïÈóÆÈ¢ò„ÄÇ\""]],  \""status\"":200,  \""time\"":\""2023-03-23 21:38:40\""}‰ΩéÊàêÊú¨ÈÉ®ÁΩ≤Ê®°ÂûãÈáèÂåñÈªòËÆ§ÊÉÖÂÜµ‰∏ãÔºåÊ®°Âûã‰ª• FP16 Á≤æÂ∫¶Âä†ËΩΩÔºåËøêË°å‰∏äËø∞‰ª£Á†ÅÈúÄË¶ÅÂ§ßÊ¶Ç 13GB ÊòæÂ≠ò„ÄÇÂ¶ÇÊûú‰Ω†ÁöÑ GPU ÊòæÂ≠òÊúâÈôêÔºåÂèØ‰ª•Â∞ùËØï‰ª•ÈáèÂåñÊñπÂºèÂä†ËΩΩÊ®°ÂûãÔºå‰ΩøÁî®ÊñπÊ≥ïÂ¶Ç‰∏ãÔºö# ÊåâÈúÄ‰øÆÊîπÔºåÁõÆÂâçÂè™ÊîØÊåÅ 4/8 bit ÈáèÂåñmodel = AutoModel.from_pretrained(\""THUDM/chatglm-6b\"", trust_remote_code=True).quantize(8).half().cuda()ËøõË°å 2 Ëá≥ 3 ËΩÆÂØπËØùÂêéÔºå8-bit ÈáèÂåñ‰∏ã GPU ÊòæÂ≠òÂç†Áî®Á∫¶‰∏∫ 10GBÔºå4-bit ÈáèÂåñ‰∏ã‰ªÖÈúÄ 6GB Âç†Áî®„ÄÇÈöèÁùÄÂØπËØùËΩÆÊï∞ÁöÑÂ¢ûÂ§öÔºåÂØπÂ∫îÊ∂àËÄóÊòæÂ≠ò‰πüÈöè‰πãÂ¢ûÈïøÔºåÁî±‰∫éÈááÁî®‰∫ÜÁõ∏ÂØπ‰ΩçÁΩÆÁºñÁ†ÅÔºåÁêÜËÆ∫‰∏ä ChatGLM-6B ÊîØÊåÅÊó†ÈôêÈïøÁöÑ context-lengthÔºå‰ΩÜÊÄªÈïøÂ∫¶Ë∂ÖËøá 2048ÔºàËÆ≠ÁªÉÈïøÂ∫¶ÔºâÂêéÊÄßËÉΩ‰ºöÈÄêÊ∏ê‰∏ãÈôç„ÄÇÊ®°ÂûãÈáèÂåñ‰ºöÂ∏¶Êù•‰∏ÄÂÆöÁöÑÊÄßËÉΩÊçüÂ§±ÔºåÁªèËøáÊµãËØïÔºåChatGLM-6B Âú® 4-bit ÈáèÂåñ‰∏ã‰ªçÁÑ∂ËÉΩÂ§üËøõË°åËá™ÁÑ∂ÊµÅÁïÖÁöÑÁîüÊàê„ÄÇ‰ΩøÁî® GPT-Q Á≠âÈáèÂåñÊñπÊ°àÂèØ‰ª•Ëøõ‰∏ÄÊ≠•ÂéãÁº©ÈáèÂåñÁ≤æÂ∫¶/ÊèêÂçáÁõ∏ÂêåÈáèÂåñÁ≤æÂ∫¶‰∏ãÁöÑÊ®°ÂûãÊÄßËÉΩÔºåÊ¨¢ËøéÂ§ßÂÆ∂ÊèêÂá∫ÂØπÂ∫îÁöÑ Pull Request„ÄÇÈáèÂåñËøáÁ®ãÈúÄË¶ÅÂú®ÂÜÖÂ≠ò‰∏≠È¶ñÂÖàÂä†ËΩΩ FP16 Ê†ºÂºèÁöÑÊ®°ÂûãÔºåÊ∂àËÄóÂ§ßÊ¶Ç 13GB ÁöÑÂÜÖÂ≠ò„ÄÇÂ¶ÇÊûú‰Ω†ÁöÑÂÜÖÂ≠ò‰∏çË∂≥ÁöÑËØùÔºåÂèØ‰ª•Áõ¥Êé•Âä†ËΩΩÈáèÂåñÂêéÁöÑÊ®°ÂûãÔºåINT4 ÈáèÂåñÂêéÁöÑÊ®°Âûã‰ªÖÈúÄÂ§ßÊ¶Ç 5.2GB ÁöÑÂÜÖÂ≠òÔºö# INT8 ÈáèÂåñÁöÑÊ®°ÂûãÂ∞Ü\""THUDM/chatglm-6b-int4\""Êîπ‰∏∫\""THUDM/chatglm-6b-int8\""model = AutoModel.from_pretrained(\""THUDM/chatglm-6b-int4\"", trust_remote_code=True).half().cuda()ÈáèÂåñÊ®°ÂûãÁöÑÂèÇÊï∞Êñá‰ª∂‰πüÂèØ‰ª•‰ªéËøôÈáåÊâãÂä®‰∏ãËΩΩ„ÄÇCPU ÈÉ®ÁΩ≤Â¶ÇÊûú‰Ω†Ê≤°Êúâ GPU Á°¨‰ª∂ÁöÑËØùÔºå‰πüÂèØ‰ª•Âú® CPU ‰∏äËøõË°åÊé®ÁêÜÔºå‰ΩÜÊòØÊé®ÁêÜÈÄüÂ∫¶‰ºöÊõ¥ÊÖ¢„ÄÇ‰ΩøÁî®ÊñπÊ≥ïÂ¶Ç‰∏ãÔºàÈúÄË¶ÅÂ§ßÊ¶Ç 32GB ÂÜÖÂ≠òÔºâmodel = AutoModel.from_pretrained(\""THUDM/chatglm-6b\"", trust_remote_code=True).float()Â¶ÇÊûú‰Ω†ÁöÑÂÜÖÂ≠ò‰∏çË∂≥ÔºåÂèØ‰ª•Áõ¥Êé•Âä†ËΩΩÈáèÂåñÂêéÁöÑÊ®°ÂûãÔºö# INT8 ÈáèÂåñÁöÑÊ®°ÂûãÂ∞Ü\""THUDM/chatglm-6b-int4\""Êîπ‰∏∫\""THUDM/chatglm-6b-int8\""model = AutoModel.from_pretrained(\""THUDM/chatglm-6b-int4\"",trust_remote_code=True).float()Â¶ÇÊûúÈÅáÂà∞‰∫ÜÊä•Èîô Could not find module 'nvcuda.dll' ÊàñËÄÖ RuntimeError: Unknown platform: darwin (MacOS) ÔºåËØ∑‰ªéÊú¨Âú∞Âä†ËΩΩÊ®°ÂûãMac ÈÉ®ÁΩ≤ÂØπ‰∫éÊê≠ËΩΩ‰∫Ü Apple Silicon ÊàñËÄÖ AMD GPU ÁöÑMacÔºåÂèØ‰ª•‰ΩøÁî® MPS ÂêéÁ´ØÊù•Âú® GPU ‰∏äËøêË°å ChatGLM-6B„ÄÇÈúÄË¶ÅÂèÇËÄÉ Apple ÁöÑ ÂÆòÊñπËØ¥Êòé ÂÆâË£Ö PyTorch-NightlyÔºàÊ≠£Á°ÆÁöÑÁâàÊú¨Âè∑Â∫îËØ•ÊòØ2.1.0.dev2023xxxxÔºåËÄå‰∏çÊòØ2.0.0Ôºâ„ÄÇÁõÆÂâçÂú® MacOS ‰∏äÂè™ÊîØÊåÅ‰ªéÊú¨Âú∞Âä†ËΩΩÊ®°Âûã„ÄÇÂ∞Ü‰ª£Á†Å‰∏≠ÁöÑÊ®°ÂûãÂä†ËΩΩÊîπ‰∏∫‰ªéÊú¨Âú∞Âä†ËΩΩÔºåÂπ∂‰ΩøÁî® mps ÂêéÁ´ØÔºömodel = AutoModel.from_pretrained(\""your local path\"", trust_remote_code=True).half().to('mps')Âä†ËΩΩÂçäÁ≤æÂ∫¶ÁöÑ ChatGLM-6B Ê®°ÂûãÈúÄË¶ÅÂ§ßÊ¶Ç 13GB ÂÜÖÂ≠ò„ÄÇÂÜÖÂ≠òËæÉÂ∞èÁöÑÊú∫Âô®ÔºàÊØîÂ¶Ç 16GB ÂÜÖÂ≠òÁöÑ MacBook ProÔºâÔºåÂú®Á©∫‰ΩôÂÜÖÂ≠ò‰∏çË∂≥ÁöÑÊÉÖÂÜµ‰∏ã‰ºö‰ΩøÁî®Á°¨Áõò‰∏äÁöÑËôöÊãüÂÜÖÂ≠òÔºåÂØºËá¥Êé®ÁêÜÈÄüÂ∫¶‰∏•ÈáçÂèòÊÖ¢„ÄÇÊ≠§Êó∂ÂèØ‰ª•‰ΩøÁî®ÈáèÂåñÂêéÁöÑÊ®°ÂûãÂ¶Ç chatglm-6b-int4„ÄÇÂõ†‰∏∫ GPU ‰∏äÈáèÂåñÁöÑ kernel ÊòØ‰ΩøÁî® CUDA ÁºñÂÜôÁöÑÔºåÂõ†Ê≠§Êó†Ê≥ïÂú® MacOS ‰∏ä‰ΩøÁî®ÔºåÂè™ËÉΩ‰ΩøÁî® CPU ËøõË°åÊé®ÁêÜ„ÄÇ# INT8 ÈáèÂåñÁöÑÊ®°ÂûãÂ∞Ü\""THUDM/chatglm-6b-int4\""Êîπ‰∏∫\""THUDM/chatglm-6b-int8\""model = AutoModel.from_pretrained(\""THUDM/chatglm-6b-int4\"",trust_remote_code=True).float()‰∏∫‰∫ÜÂÖÖÂàÜ‰ΩøÁî® CPU Âπ∂Ë°åÔºåËøòÈúÄË¶ÅÂçïÁã¨ÂÆâË£Ö OpenMP„ÄÇÂ§öÂç°ÈÉ®ÁΩ≤Â¶ÇÊûú‰Ω†ÊúâÂ§öÂº† GPUÔºå‰ΩÜÊòØÊØèÂº† GPU ÁöÑÊòæÂ≠òÂ§ßÂ∞èÈÉΩ‰∏çË∂≥‰ª•ÂÆπÁ∫≥ÂÆåÊï¥ÁöÑÊ®°ÂûãÔºåÈÇ£‰πàÂèØ‰ª•Â∞ÜÊ®°ÂûãÂàáÂàÜÂú®Â§öÂº†GPU‰∏ä„ÄÇÈ¶ñÂÖàÂÆâË£Ö accelerate: pip install accelerateÔºåÁÑ∂ÂêéÈÄöËøáÂ¶Ç‰∏ãÊñπÊ≥ïÂä†ËΩΩÊ®°ÂûãÔºöfrom utils import load_model_on_gpusmodel = load_model_on_gpus(\""THUDM/chatglm-6b\"", num_gpus=2)Âç≥ÂèØÂ∞ÜÊ®°ÂûãÈÉ®ÁΩ≤Âà∞‰∏§Âº† GPU ‰∏äËøõË°åÊé®ÁêÜ„ÄÇ‰Ω†ÂèØ‰ª•Â∞Ü num_gpus Êîπ‰∏∫‰Ω†Â∏åÊúõ‰ΩøÁî®ÁöÑ GPU Êï∞„ÄÇÈªòËÆ§ÊòØÂùáÂåÄÂàáÂàÜÁöÑÔºå‰Ω†‰πüÂèØ‰ª•‰º†ÂÖ• device_map ÂèÇÊï∞Êù•Ëá™Â∑±ÊåáÂÆö„ÄÇÈ´òÊïàÂèÇÊï∞ÂæÆË∞ÉÂü∫‰∫é P-tuning v2 ÁöÑÈ´òÊïàÂèÇÊï∞ÂæÆË∞É„ÄÇÂÖ∑‰Ωì‰ΩøÁî®ÊñπÊ≥ïËØ¶ËßÅ ptuning/README.md„ÄÇChatGLM-6B Á§∫‰æã‰ª•‰∏ãÊòØ‰∏Ä‰∫õ‰ΩøÁî® web_demo.py ÂæóÂà∞ÁöÑÁ§∫‰æãÊà™Âõæ„ÄÇÊõ¥Â§ö ChatGLM-6B ÁöÑÂèØËÉΩÔºåÁ≠âÂæÖ‰Ω†Êù•Êé¢Á¥¢ÂèëÁé∞ÔºÅËá™ÊàëËÆ§Áü•ÊèêÁ∫≤ÂÜô‰ΩúÊñáÊ°àÂÜô‰ΩúÈÇÆ‰ª∂ÂÜô‰ΩúÂä©Êâã‰ø°ÊÅØÊäΩÂèñËßíËâ≤ÊâÆÊºîËØÑËÆ∫ÊØîËæÉÊóÖÊ∏∏ÂêëÂØºÂ±ÄÈôêÊÄßÁî±‰∫é ChatGLM-6B ÁöÑÂ∞èËßÑÊ®°ÔºåÂÖ∂ËÉΩÂäõ‰ªçÁÑ∂ÊúâËÆ∏Â§öÂ±ÄÈôêÊÄß„ÄÇ‰ª•‰∏ãÊòØÊàë‰ª¨ÁõÆÂâçÂèëÁé∞ÁöÑ‰∏Ä‰∫õÈóÆÈ¢òÔºöÊ®°ÂûãÂÆπÈáèËæÉÂ∞èÔºö6B ÁöÑÂ∞èÂÆπÈáèÔºåÂÜ≥ÂÆö‰∫ÜÂÖ∂Áõ∏ÂØπËæÉÂº±ÁöÑÊ®°ÂûãËÆ∞ÂøÜÂíåËØ≠Ë®ÄËÉΩÂäõ„ÄÇÂú®Èù¢ÂØπËÆ∏Â§ö‰∫ãÂÆûÊÄßÁü•ËØÜ‰ªªÂä°Êó∂ÔºåChatGLM-6B ÂèØËÉΩ‰ºöÁîüÊàê‰∏çÊ≠£Á°ÆÁöÑ‰ø°ÊÅØÔºõÂÆÉ‰πü‰∏çÊìÖÈïøÈÄªËæëÁ±ªÈóÆÈ¢òÔºàÂ¶ÇÊï∞Â≠¶„ÄÅÁºñÁ®ãÔºâÁöÑËß£Á≠î„ÄÇ  ÁÇπÂáªÊü•Áúã‰æãÂ≠ê  ‰∫ßÁîüÊúâÂÆ≥ËØ¥ÊòéÊàñÊúâÂÅèËßÅÁöÑÂÜÖÂÆπÔºöChatGLM-6B Âè™ÊòØ‰∏Ä‰∏™ÂàùÊ≠•‰∏é‰∫∫Á±ªÊÑèÂõæÂØπÈΩêÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºåÂèØËÉΩ‰ºöÁîüÊàêÊúâÂÆ≥„ÄÅÊúâÂÅèËßÅÁöÑÂÜÖÂÆπ„ÄÇÔºàÂÜÖÂÆπÂèØËÉΩÂÖ∑ÊúâÂÜíÁäØÊÄßÔºåÊ≠§Â§Ñ‰∏çÂ±ïÁ§∫ÔºâËã±ÊñáËÉΩÂäõ‰∏çË∂≥ÔºöChatGLM-6B ËÆ≠ÁªÉÊó∂‰ΩøÁî®ÁöÑÊåáÁ§∫/ÂõûÁ≠îÂ§ßÈÉ®ÂàÜÈÉΩÊòØ‰∏≠ÊñáÁöÑÔºå‰ªÖÊúâÊûÅÂ∞è‰∏ÄÈÉ®ÂàÜËã±ÊñáÂÜÖÂÆπ„ÄÇÂõ†Ê≠§ÔºåÂ¶ÇÊûúËæìÂÖ•Ëã±ÊñáÊåáÁ§∫ÔºåÂõûÂ§çÁöÑË¥®ÈáèËøú‰∏çÂ¶Ç‰∏≠ÊñáÔºåÁîöËá≥‰∏é‰∏≠ÊñáÊåáÁ§∫‰∏ãÁöÑÂÜÖÂÆπÁüõÁõæÔºåÂπ∂‰∏îÂá∫Áé∞‰∏≠Ëã±Â§πÊùÇÁöÑÊÉÖÂÜµ„ÄÇÊòìË¢´ËØØÂØºÔºåÂØπËØùËÉΩÂäõËæÉÂº±ÔºöChatGLM-6B ÂØπËØùËÉΩÂäõËøòÊØîËæÉÂº±ÔºåËÄå‰∏î ‚ÄúËá™ÊàëËÆ§Áü•‚Äù Â≠òÂú®ÈóÆÈ¢òÔºåÂπ∂ÂæàÂÆπÊòìË¢´ËØØÂØºÂπ∂‰∫ßÁîüÈîôËØØÁöÑË®ÄËÆ∫„ÄÇ‰æãÂ¶ÇÂΩìÂâçÁâàÊú¨ÁöÑÊ®°ÂûãÂú®Ë¢´ËØØÂØºÁöÑÊÉÖÂÜµ‰∏ãÔºå‰ºöÂú®Ëá™ÊàëËÆ§Áü•‰∏äÂèëÁîüÂÅèÂ∑Æ„ÄÇ  ÁÇπÂáªÊü•Áúã‰æãÂ≠ê  ÂçèËÆÆÊú¨‰ªìÂ∫ìÁöÑ‰ª£Á†Å‰æùÁÖß Apache-2.0 ÂçèËÆÆÂºÄÊ∫êÔºåChatGLM-6B Ê®°ÂûãÁöÑÊùÉÈáçÁöÑ‰ΩøÁî®ÂàôÈúÄË¶ÅÈÅµÂæ™ Model License„ÄÇChatGLM-6B ÊùÉÈáçÂØπÂ≠¶ÊúØÁ†îÁ©∂ÂÆåÂÖ®ÂºÄÊîæÔºåÂú®Â°´ÂÜôÈóÆÂç∑ËøõË°åÁôªËÆ∞Âêé‰∫¶ÂÖÅËÆ∏ÂÖçË¥πÂïÜ‰∏ö‰ΩøÁî®„ÄÇÂºïÁî®Â¶ÇÊûú‰Ω†ËßâÂæóÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊúâÂ∏ÆÂä©ÁöÑËØùÔºåËØ∑ËÄÉËôëÂºïÁî®‰∏ãÂàóËÆ∫Êñá@article{zeng2022glm,  title={Glm-130b: An open bilingual pre-trained model},  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},  journal={arXiv preprint arXiv:2210.02414},  year={2022}}@inproceedings{du2022glm,  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},  pages={320--335},  year={2022}}"
84,miguelgrinberg/flasky,https://github.com/miguelgrinberg/flasky/blob/master/README.md,Python,"FlaskyThis repository contains the source code examples for the second edition of my O'Reilly book Flask Web Development.The commits and tags in this repository were carefully created to match the sequence in which concepts are presented in the book. Please read the section titled \""How to Work with the Example Code\"" in the book's preface for instructions.For Readers of the First Edition of the BookThe code examples for the first edition of the book were moved to a different repository: https://github.com/miguelgrinberg/flasky-first-edition."
85,getredash/redash,https://github.com/getredash/redash/blob/master/README.md,Python,"  Redash is designed to enable anyone, regardless of the level of technical sophistication, to harness the power of data big and small. SQL users leverage Redash to explore, query, visualize, and share data from any data sources. Their work in turn enables anybody in their organization to use the data. Every day, millions of users at thousands of organizations around the world use Redash to develop insights and make data-driven decisions.Redash features:Browser-based: Everything in your browser, with a shareable URL.Ease-of-use: Become immediately productive with data without the need to master complex software.Query editor: Quickly compose SQL and NoSQL queries with a schema browser and auto-complete.Visualization and dashboards: Create beautiful visualizations with drag and drop, and combine them into a single dashboard.Sharing: Collaborate easily by sharing visualizations and their associated queries, enabling peer review of reports and queries.Schedule refreshes: Automatically update your charts and dashboards at regular intervals you define.Alerts: Define conditions and be alerted instantly when your data changes.REST API: Everything that can be done in the UI is also available through REST API.Broad support for data sources: Extensible data source API with native support for a long list of common databases and platforms.Getting StartedSetting up Redash instance (includes links to ready-made AWS/GCE images).Documentation.Supported Data SourcesRedash supports more than 35 SQL and NoSQL data sources. It can also be extended to support more. Below is a list of built-in sources:Amazon AthenaAmazon CloudWatch / InsightsAmazon DynamoDBAmazon RedshiftArangoDBAxibase Time Series DatabaseApache CassandraClickHouseCockroachDBCouchbaseCSVDatabricksDB2 by IBMDgraphApache DrillApache DruidEccenca Corporate MemoryElasticsearchExasolMicrosoft ExcelFireboltDatabendGoogle AnalyticsGoogle BigQueryGoogle SpreadsheetsGraphiteGreenplumApache HiveApache ImpalaInfluxDBIBM Netezza Performance ServerJIRA (JQL)JSONApache KylinOmniSciDB (Formerly MapD)MariaDBMemSQLMicrosoft Azure Data Warehouse / SynapseMicrosoft Azure SQL DatabaseMicrosoft Azure Data Explorer / KustoMicrosoft SQL ServerMongoDBMySQLOracleApache PhoenixApache PinotPostgreSQLPrestoPrometheusPythonQuboleRocksetSalesforceScyllaDBShell ScriptsSnowflakeSPARQLSQLiteTiDBTreasureDataTrinoUptycsVerticaYandex AppMetrricaYandex MetricaGetting HelpIssues: https://github.com/getredash/redash/issuesDiscussion Forum: https://github.com/getredash/redash/discussions/Development Discussion: https://discord.gg/tN5MdmfGBpReporting Bugs and Contributing CodeWant to report a bug or request a feature? Please open an issue.Want to help us build Redash? Fork the project, edit in a dev environment and make a pull request. We need all the help we can get!SecurityPlease email security@redash.io to report any security vulnerabilities. We will acknowledge receipt of your vulnerability and strive to send you regular updates about our progress. If you're curious about the status of your disclosure please feel free to email us again. If you want to encrypt your disclosure email, you can use this PGP key.LicenseBSD-2-Clause."
86,pytorch/tutorials,https://github.com/pytorch/tutorials/blob/main/README.md,Python,"PyTorch TutorialsAll the tutorials are now presented as sphinx style documentation at:https://pytorch.org/tutorialsContributingWe use sphinx-gallery's notebook styled examples to create the tutorials. Syntax is very simple. In essence, you write a slightly well formatted Python file and it shows up as an HTML page. In addition, a Jupyter notebook is autogenerated and available to run in Google Colab.Here is how you can create a new tutorial (for a detailed description, see CONTRIBUTING.md):Create a Python file. If you want it executed while inserted into documentation, save the file with the suffix tutorial so that the file name is your_tutorial.py.Put it in one of the beginner_source, intermediate_source, advanced_source directory based on the level of difficulty. If it is a recipe, add it to recipes_source. For tutorials demonstrating unstable prototype features, add to the prototype_source.For Tutorials (except if it is a prototype feature), include it in the toctree directive and create a customcarditem in index.rst.For Tutorials (except if it is a prototype feature), create a thumbnail in the index.rst file using a command like .. customcarditem:: beginner/your_tutorial.html. For Recipes, create a thumbnail in the recipes_index.rstIf you are starting off with a Jupyter notebook, you can use this script to convert the notebook to Python file. After conversion and addition to the project, please make sure that section headings and other things are in logical order.Building locallyThe tutorial build is very large and requires a GPU. If your machine does not have a GPU device, you can preview your HTML build without actually downloading the data and running the tutorial code:Install required dependencies by running: pip install -r requirements.txt.If you want to use virtualenv, in the root of the repo, run: virtualenv venv, then source venv/bin/activate.If you have a GPU-powered laptop, you can build using make docs. This will download the data, execute the tutorials and build the documentation to docs/ directory. This might take about 60-120 min for systems with GPUs. If you do not have a GPU installed on your system, then see next step.You can skip the computationally intensive graph generation by running make html-noplot to build basic html documentation to _build/html. This way, you can quickly preview your tutorial.If you get ModuleNotFoundError: No module named 'pytorch_sphinx_theme' make: *** [html-noplot] Error 2 from /tutorials/src/pytorch-sphinx-theme or /venv/src/pytorch-sphinx-theme (while using virtualenv), run python setup.py install.Building a single tutorialYou can build a single tutorial by using the GALLERY_PATTERN environment variable. For example to run only neural_style_transfer_tutorial.py, run:GALLERY_PATTERN=\""neural_style_transfer_tutorial.py\"" make htmlorGALLERY_PATTERN=\""neural_style_transfer_tutorial.py\"" sphinx-build . _buildThe GALLERY_PATTERN variable respects regular expressions.About contributing to PyTorch Documentation and TutorialsYou can find information about contributing to PyTorch documentation in thePyTorch Repo README.md file.Additional information can be found in PyTorch CONTRIBUTING.md."
87,httpie/cli,https://github.com/httpie/cli/blob/master/README.md,Python,"                        HTTPie CLI: human-friendly HTTP client for the API eraHTTPie (pronounced aitch-tee-tee-pie) is a command-line HTTP client.Its goal is to make CLI interaction with web services as human-friendly as possible.HTTPie is designed for testing, debugging, and generally interacting with APIs & HTTP servers.The http & https commands allow for creating and sending arbitrary HTTP requests.They use simple and natural syntax and provide formatted and colorized output.We lost 54k GitHub starsPlease note we recently accidentally made this repo private for a moment, and GitHub deleted our community that took a decade to build. Read the full story here: https://httpie.io/blog/stardustGetting startedInstallation instructions ‚ÜíFull documentation ‚ÜíFeaturesExpressive and intuitive syntaxFormatted and colorized terminal outputBuilt-in JSON supportForms and file uploadsHTTPS, proxies, and authenticationArbitrary request dataCustom headersPersistent sessionswget-like downloadsSee all features ‚ÜíExamplesHello World:https httpie.io/helloCustom HTTP method, HTTP headers and JSON data:http PUT pie.dev/put X-API-Token:123 name=JohnBuild and print a request without sending it using offline mode:http --offline pie.dev/post hello=offlineUse GitHub API to post a comment on an Issue with authentication:http -a USERNAME POST https://api.github.com/repos/httpie/cli/issues/83/comments body='HTTPie is awesome! :heart:'See more examples ‚ÜíCommunity & supportVisit the HTTPie website for full documentation and useful links.Join our Discord server is to ask questions, discuss features, and for general API chat.Tweet at @httpie on Twitter.Use StackOverflow to ask questions and include a httpie tag.Create GitHub Issues for bug reports and feature requests.Subscribe to the HTTPie newsletter for occasional updates.ContributingHave a look through existing Issues and Pull Requests that you could help with. If you'd like to request a feature or report a bug, please create a GitHub Issue using one of the templates provided.See contribution guide ‚Üí"
88,localstack/localstack,https://github.com/localstack/localstack/blob/master/README.md,Python,"‚ö° We are thrilled to announce LocalStack 2.2 which brings new features, enhancements and bugfixes ‚ö°                        LocalStack provides an easy-to-use test/mocking framework for developing cloud applications.  Overview ‚Ä¢  Install ‚Ä¢  Example ‚Ä¢  Run ‚Ä¢  Usage ‚Ä¢  Releases ‚Ä¢  Contributing    üìñ Docs ‚Ä¢  üíª Pro version ‚Ä¢  ‚òëÔ∏è LocalStack coverageOverviewLocalStack is a cloud service emulator that runs in a single container on your laptop or in your CI environment. With LocalStack, you can run your AWS applications or Lambdas entirely on your local machine without connecting to a remote cloud provider! Whether you are testing complex CDK applications or Terraform configurations, or just beginning to learn about AWS services, LocalStack helps speed up and simplify your testing and development workflow.LocalStack supports a growing number of AWS services, like AWS Lambda, S3, Dynamodb, Kinesis, SQS, SNS, and many more! The Pro version of LocalStack supports additional APIs and advanced features. You can find a comprehensive list of supported APIs on our ‚òëÔ∏è Feature Coverage page.LocalStack also provides additional features to make your life as a cloud developer easier! Check out LocalStack's Cloud Developer Tools for more information.InstallationThe quickest way get started with LocalStack is by using the LocalStack CLI.It allows you to start and manage the LocalStack Docker container from your command line.Please make sure that you have a working docker environment on your machine before moving on.Brew (MacOS or Linux with Homebrew)Install the LocalStack CLI by using our official LocalStack Brew Tap:$ brew install localstack/tap/localstack-cliBinary download (MacOS, Linux, Windows)If you do not have Brew on your machine, you can directly download the pre-built LocalStack CLI binary for your system:Download the latest release for your platform on localstack/localstack-cli.Extract the archive to a folder in your PATH variable:MacOS / Linux: sudo tar xvzf ~/Downloads/localstack-cli-*-darwin-*-onefile.tar.gz -C /usr/local/binPython package (MacOS, Linux, Windows)LocalStack is built with Python.You can directly install the LocalStack CLI in your Python environment using pip.Prerequisitespython (Python 3.7 up to 3.11 supported)Installationpython3 -m pip install localstackImportant: Do not use sudo or run as root user. LocalStack must be installed and started entirely under a local non-root user. If you have problems with permissions in macOS High Sierra, install with pip install --user localstackExampleStart LocalStack inside a Docker container by running: % localstack start -d     __                     _______ __             __    / /   ____  _________ _/ / ___// /_____ ______/ /__   / /   / __ \\/ ___/ __ `/ /\\__ \\/ __/ __ `/ ___/ //_/  / /___/ /_/ / /__/ /_/ / /___/ / /_/ /_/ / /__/ ,< /_____/\\____/\\___/\\__,_/_//____/\\__/\\__,_/\\___/_/|_| üíª LocalStack CLI 2.2.0[20:22:20] starting LocalStack in Docker mode üê≥[20:22:21] detachingYou can query the status of respective services on LocalStack by running:% localstack status services‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì‚îÉ Service                  ‚îÉ Status      ‚îÉ‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©‚îÇ acm                      ‚îÇ ‚úî available ‚îÇ‚îÇ apigateway               ‚îÇ ‚úî available ‚îÇ‚îÇ cloudformation           ‚îÇ ‚úî available ‚îÇ‚îÇ cloudwatch               ‚îÇ ‚úî available ‚îÇ‚îÇ config                   ‚îÇ ‚úî available ‚îÇ‚îÇ dynamodb                 ‚îÇ ‚úî available ‚îÇ...To use SQS, a fully managed distributed message queuing service, on LocalStack, run:% awslocal sqs create-queue --queue-name sample-queue{    \""QueueUrl\"": \""http://localhost:4566/000000000000/sample-queue\""}Learn more about LocalStack AWS services and using them with LocalStack's awslocal CLI.RunningYou can run LocalStack through the following options:LocalStack CLIDockerDocker ComposeHelmUsageTo start using LocalStack, check out our documentation at https://docs.localstack.cloud.LocalStack ConfigurationLocalStack in CILocalStack IntegrationsLocalStack ToolsUnderstanding LocalStackTroubleshootTo use LocalStack with a graphical user interface, you can use the following UI clients:Commandeer desktop appDynamoDB Admin Web UIReleasesPlease refer to GitHub releases to see the complete list of changes for each release. For extended release notes, please refer to the LocalStack Discuss.ContributingIf you are interested in contributing to LocalStack:Start by reading our contributing guide.Check out our developer guide.Navigate our codebase and open issues.We are thankful for all the contributions and feedback we receive.Get in touchTo get in touch with LocalStack team for bugs/feature requests, support questions or general discussions, please use:LocalStack Slack CommunityLocalStack Discussion PageLocalStack GitHub Issue trackerContributorsWe are thankful to all the people who have contributed to this project.BackersWe are also grateful to all our backers who have donated to the project. You can become a backer on Open Collective.SponsorsYou can also support this project by becoming a sponsor on Open Collective. Your logo will show up here along with a link to your website.LicenseCopyright (c) 2017-2023 LocalStack maintainers and contributors.Copyright (c) 2016 Atlassian and others.This version of LocalStack is released under the Apache License, Version 2.0 (see LICENSE). By downloading and using this software you agree to the End-User License Agreement (EULA). To know about the external software we use, look at our third party software tools page."
